{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import preprocessing as pp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training naive bayes model on MSR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr_data = pd.read_csv('data/msr_dataset.csv', encoding = 'ANSI')\n",
    "y_msr = msr_data['class']\n",
    "msr = msr_data.drop(columns=['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(msr_data['token'], \n",
    "                                                    y_msr, train_size=0.8, \n",
    "                                                    random_state=33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       283\n",
      "           1       0.93      0.79      0.86       278\n",
      "\n",
      "    accuracy                           0.87       561\n",
      "   macro avg       0.88      0.87      0.87       561\n",
      "weighted avg       0.88      0.87      0.87       561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf1 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=1000)),\n",
    "    ('model', MultinomialNB())])\n",
    "\n",
    "text_clf1.fit(X_train, y_train)\n",
    "preds = text_clf1.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('data/new_dataset.csv')\n",
    "#new_data['processed_token'] = pp.preprocess_tokens(new_data)\n",
    "y_new = new_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.70      0.65       724\n",
      "           1       0.65      0.53      0.59       737\n",
      "\n",
      "    accuracy                           0.62      1461\n",
      "   macro avg       0.62      0.62      0.62      1461\n",
      "weighted avg       0.62      0.62      0.61      1461\n",
      "\n",
      "f1 0.585003711952487\n"
     ]
    }
   ],
   "source": [
    "new_preds = text_clf1.predict(new_data['token'])\n",
    "print(classification_report(y_new, new_preds))\n",
    "print('f1', f1_score(y_new, new_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.130079605284166 get\n",
      "-3.8983653086868344 job\n",
      "-3.91694692439897 test\n",
      "-4.017770999047708 action\n",
      "-4.157179397137763 coord\n",
      "-4.21405090809237 assert\n",
      "-4.307813233085981 file\n",
      "-4.314134366649352 to\n",
      "-4.53458655245077 name\n",
      "-4.57656204466834 set\n",
      "-4.649212521554386 the\n",
      "-4.784772312440301 not\n",
      "-4.804250119399873 xml\n",
      "-4.810480669150508 workflow\n",
      "-4.857397588938261 conf\n",
      "-4.8617739635380595 add\n",
      "-4.873908696004053 2009\n",
      "-4.88844221062022 should\n",
      "-4.912374976831849 id\n",
      "-4.957193798477095 create\n",
      "-4.984090285342441 equals\n",
      "-4.999071838958058 for\n",
      "-5.0440955203320135 oozie\n",
      "-5.057340747082034 services\n",
      "-5.073470129011918 table\n",
      "-5.078904924997875 app\n",
      "-5.130628542851866 coordinator\n",
      "-5.133502108047598 is\n",
      "-5.134941993105586 wf\n",
      "-5.143625115679047 assertequals\n",
      "-5.179131804135957 start\n",
      "-5.231694134226812 time\n",
      "-5.234873787144192 in\n",
      "-5.257419025465248 status\n",
      "-5.268885162552892 data\n",
      "-5.321306292916499 path\n",
      "-5.3602492668651065 fail\n",
      "-5.372965151190409 system\n",
      "-5.374794977867485 value\n",
      "-5.41211274087468 have\n",
      "-5.427438711352908 and\n",
      "-5.4588138339206616 record\n",
      "-5.4588138339206616 bundle\n",
      "-5.491205329711897 service\n",
      "-5.501546683506629 dir\n",
      "-5.51199609938097 true\n",
      "-5.528945657694743 fs\n",
      "-5.533228319486745 02\n",
      "-5.539686899526156 been\n",
      "-5.541849062530652 call\n"
     ]
    }
   ],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=50):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    \n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        #print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))\n",
    "        print(coef_2, fn_2)\n",
    "        \n",
    "show_most_informative_features(text_clf1['vectorizer'], text_clf1['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.48      0.51       724\n",
      "           1       0.54      0.61      0.58       737\n",
      "\n",
      "    accuracy                           0.54      1461\n",
      "   macro avg       0.54      0.54      0.54      1461\n",
      "weighted avg       0.54      0.54      0.54      1461\n",
      "\n",
      "f1 0.5752551020408163\n"
     ]
    }
   ],
   "source": [
    "text_clf2 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=1000)),\n",
    "    ('model', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None))])\n",
    "\n",
    "text_clf2.fit(X_train, y_train)\n",
    "new_preds = text_clf2.predict(new_data['token'])\n",
    "print(classification_report(y_new, new_preds))\n",
    "print('f1', f1_score(y_new, new_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
