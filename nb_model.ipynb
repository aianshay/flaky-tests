{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import preprocessing as pp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training naive bayes model on MSR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr_data = pd.read_csv('data/msr/raw_msr_dataset.csv', encoding = 'ANSI')\n",
    "y_msr = msr_data['class']\n",
    "msr = msr_data.drop(columns=['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(msr_data['token'], \n",
    "                                                    y_msr, train_size=0.8, \n",
    "                                                    random_state=33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       283\n",
      "           1       0.96      0.94      0.95       278\n",
      "\n",
      "    accuracy                           0.95       561\n",
      "   macro avg       0.95      0.95      0.95       561\n",
      "weighted avg       0.95      0.95      0.95       561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf1 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('model', MultinomialNB())])\n",
    "\n",
    "text_clf1.fit(X_train, y_train)\n",
    "preds = text_clf1.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('data/new/raw_new_dataset.csv')\n",
    "#new_data['processed_token'] = pp.preprocess_tokens(new_data)\n",
    "y_new = new_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.53      0.58       724\n",
      "           1       0.60      0.70      0.65       737\n",
      "\n",
      "    accuracy                           0.62      1461\n",
      "   macro avg       0.62      0.62      0.61      1461\n",
      "weighted avg       0.62      0.62      0.61      1461\n",
      "\n",
      "f1 0.647834274952919\n"
     ]
    }
   ],
   "source": [
    "new_preds = text_clf1.predict(new_data['token'])\n",
    "print(classification_report(y_new, new_preds))\n",
    "print('f1', f1_score(y_new, new_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.446652136990842 get\n",
      "-4.21493784039351 job\n",
      "-4.233519456105646 test\n",
      "-4.334343530754384 action\n",
      "-4.473751928844439 coord\n",
      "-4.5306234397990455 assert\n",
      "-4.624385764792657 file\n",
      "-4.630706898356028 to\n",
      "-4.8511590841574455 name\n",
      "-4.893134576375016 set\n",
      "-4.965785053261062 the\n",
      "-5.101344844146977 not\n",
      "-5.120822651106549 xml\n",
      "-5.127053200857184 workflow\n",
      "-5.173970120644936 conf\n",
      "-5.178346495244735 add\n",
      "-5.190481227710729 2009\n",
      "-5.205014742326896 should\n",
      "-5.228947508538525 id\n",
      "-5.273766330183771 create\n",
      "-5.300662817049117 equals\n",
      "-5.315644370664734 for\n",
      "-5.360668052038689 oozie\n",
      "-5.37391327878871 services\n",
      "-5.390042660718594 table\n",
      "-5.395477456704551 app\n",
      "-5.447201074558542 coordinator\n",
      "-5.450074639754274 is\n",
      "-5.451514524812262 wf\n",
      "-5.460197647385723 assertequals\n",
      "-5.495704335842633 start\n",
      "-5.548266665933488 time\n",
      "-5.551446318850868 in\n",
      "-5.573991557171924 status\n",
      "-5.585457694259568 data\n",
      "-5.637878824623175 path\n",
      "-5.676821798571782 fail\n",
      "-5.689537682897085 system\n",
      "-5.691367509574161 value\n",
      "-5.728685272581356 have\n",
      "-5.7440112430595835 and\n",
      "-5.775386365627337 record\n",
      "-5.775386365627337 bundle\n",
      "-5.807777861418573 service\n",
      "-5.818119215213305 dir\n",
      "-5.828568631087646 true\n",
      "-5.845518189401419 fs\n",
      "-5.849800851193421 02\n",
      "-5.856259431232832 been\n",
      "-5.858421594237328 call\n"
     ]
    }
   ],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=50):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    \n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        #print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))\n",
    "        print(coef_2, fn_2)\n",
    "        \n",
    "show_most_informative_features(text_clf1['vectorizer'], text_clf1['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.48      0.51       724\n",
      "           1       0.54      0.61      0.58       737\n",
      "\n",
      "    accuracy                           0.54      1461\n",
      "   macro avg       0.54      0.54      0.54      1461\n",
      "weighted avg       0.54      0.54      0.54      1461\n",
      "\n",
      "f1 0.5752551020408163\n"
     ]
    }
   ],
   "source": [
    "text_clf2 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=1000)),\n",
    "    ('model', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None))])\n",
    "\n",
    "text_clf2.fit(X_train, y_train)\n",
    "new_preds = text_clf2.predict(new_data['token'])\n",
    "print(classification_report(y_new, new_preds))\n",
    "print('f1', f1_score(y_new, new_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
