{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import preprocessing as pp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training naive bayes model on MSR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr_data = pd.read_csv('data/msr_dataset.csv', encoding = 'ANSI')\n",
    "y_msr = msr_data['class']\n",
    "msr = msr_data.drop(columns=['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(msr_data['token'], \n",
    "                                                    y_msr, train_size=0.8, \n",
    "                                                    random_state=33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       283\n",
      "           1       0.95      0.94      0.95       278\n",
      "\n",
      "    accuracy                           0.95       561\n",
      "   macro avg       0.95      0.95      0.95       561\n",
      "weighted avg       0.95      0.95      0.95       561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf1 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words=['job', 'oozie', 'id', 'services', 'action', 'table',\n",
    "                                              'xml', 'get', 'workflow', 'getid', 'cluster', 'wf',\n",
    "                                              'service', 'coord'])),\n",
    "    ('model', MultinomialNB())])\n",
    "\n",
    "text_clf1.fit(X_train, y_train)\n",
    "preds = text_clf1.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('data/new_dataset.csv')\n",
    "#new_data['processed_token'] = pp.preprocess_tokens(new_data)\n",
    "y_new = new_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.50      0.56       724\n",
      "           1       0.60      0.72      0.65       737\n",
      "\n",
      "    accuracy                           0.61      1461\n",
      "   macro avg       0.62      0.61      0.61      1461\n",
      "weighted avg       0.62      0.61      0.61      1461\n",
      "\n",
      "f1 0.6531862745098039\n"
     ]
    }
   ],
   "source": [
    "new_preds = text_clf1.predict(new_data['token'])\n",
    "print(classification_report(y_new, new_preds))\n",
    "print('f1', f1_score(y_new, new_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.113309646938952 test\n",
      "-4.410413630632352 assert\n",
      "-4.504175955625963 file\n",
      "-4.510497089189334 to\n",
      "-4.730949274990752 name\n",
      "-4.772924767208322 set\n",
      "-4.845575244094368 the\n",
      "-4.981135034980284 not\n",
      "-5.053760311478243 conf\n",
      "-5.058136686078042 add\n",
      "-5.070271418544035 2009\n",
      "-5.0848049331602025 should\n",
      "-5.1535565210170775 create\n",
      "-5.180453007882424 equals\n",
      "-5.195434561498041 for\n",
      "-5.2752676475378575 app\n",
      "-5.3269912653918485 coordinator\n",
      "-5.329864830587581 is\n",
      "-5.339987838219029 assertequals\n",
      "-5.375494526675939 start\n",
      "-5.428056856766794 time\n",
      "-5.431236509684174 in\n",
      "-5.45378174800523 status\n",
      "-5.465247885092874 data\n",
      "-5.517669015456481 path\n",
      "-5.556611989405089 fail\n",
      "-5.5693278737303915 system\n",
      "-5.5711577004074675 value\n",
      "-5.6084754634146625 have\n",
      "-5.62380143389289 and\n",
      "-5.655176556460644 record\n",
      "-5.655176556460644 bundle\n",
      "-5.697909406046612 dir\n",
      "-5.708358821920952 true\n",
      "-5.7253083802347255 fs\n",
      "-5.729591042026727 02\n",
      "-5.7360496220661386 been\n",
      "-5.738211785070634 call\n",
      "-5.742550186669232 execute\n",
      "-5.746907492038187 end\n",
      "-5.757884550669338 with\n",
      "-5.766753788410118 close\n",
      "-5.787001949240066 of\n",
      "-5.8007321420519675 user\n",
      "-5.816992662923748 node\n",
      "-5.828771362116361 property\n",
      "-5.8551834616561385 date\n",
      "-5.872361798191222 run\n",
      "-5.882312129044391 check\n",
      "-5.897425766854439 size\n"
     ]
    }
   ],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=50):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    \n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        #print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))\n",
    "        print(coef_2, fn_2)\n",
    "        \n",
    "show_most_informative_features(text_clf1['vectorizer'], text_clf1['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.48      0.51       724\n",
      "           1       0.54      0.61      0.58       737\n",
      "\n",
      "    accuracy                           0.54      1461\n",
      "   macro avg       0.54      0.54      0.54      1461\n",
      "weighted avg       0.54      0.54      0.54      1461\n",
      "\n",
      "f1 0.5752551020408163\n"
     ]
    }
   ],
   "source": [
    "text_clf2 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=1000)),\n",
    "    ('model', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None))])\n",
    "\n",
    "text_clf2.fit(X_train, y_train)\n",
    "new_preds = text_clf2.predict(new_data['token'])\n",
    "print(classification_report(y_new, new_preds))\n",
    "print('f1', f1_score(y_new, new_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
