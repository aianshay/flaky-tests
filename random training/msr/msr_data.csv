token,project,flaky
 call testResourceGetPostParamGet POST MyJsonRestServlet GET HttpServletResponse param=true invoke assertEquals runTest ,oozie,1
"cluster createTable getClusterStatus hcd TEST_UTIL getRegionsInTransition  Table that splits like crazy getConfiguration htd setMaxFileSize info  Check that there's no region in flight, HBASE-2515 Expected TABLENAME LOG loadTable getRegionServerOperationQueue assertEquals list m registerRegionServerOperationListener  We disable the table during a split, we will end up here testDisableBetweenSplit ex t size setMemStoreFlushSize addFamily getHBaseCluster getHBaseAdmin getMaster FAMILYNAME ",hadoop,1
fail testSetMaxInvalid Assert setDefaultMaxPerRoute pool setMaxPerRoute IllegalArgumentException should have been thrown ,httpcore,0
" thinks that it is single rack assertSingleSwitch n1 n2 resolve l1 dumpTopology getSwitchMap conf unknown n1=/r1,n2=/r2 StaticMapping testReadNodesFromConfig get resolved info add mapping set switchMap LOG topology newInstance assertEquals setConf /r1 /r2 assertNull size NetworkTopology ",hadoop,0
hcatUri2  checkCoordAction CoordELFunctions hcatUri1 testUpdateCoordTableAdvanced addInitRecords getAvailableDependencyURIs partitionAvailable availableURIs assertTrue get CoordinatorAction mydb src=search;datastamp=11;region=us addMissingDependency newHCatDependency2  second partition available hcat://hcat.server.com:5080/mydb/clicks/datastamp=11;region=us newHCatDependency1 hcat.server.com:5080 assertEquals pdms call Services contains src=search;datastamp=12;region=us assertNull size actionId clicks getPartitionMap fullDeps hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us ,oozie,1
conn setRequestMethod IS_SECURITY_ENABLED testInstrumentation assertTrue json content-type /v1/admin/* Collections runTest JsonTags RestConstants openConnection containsKey HttpServletResponse assertEquals parse getInputStream url JSONValue call getHeaderField GET getResponseCode createURL startsWith ,oozie,1
add next ROW_1 QUALIFIER_1 ROW_2 ROW_3 ROW_4 assertEquals getRow testScanner put puts Bytes assertNull COLUMN_1 assertTrue assertNotNull equals remoteTable scanner VALUE_1 getScanner results close ,hadoop,1
 Wait until has some regions before proceeding.  Balancer will give it some. cluster  this test to succeed.  Start new regionserver. listener Running testKillRSWithOpeningRegion2482 TEST_UTIL assertRegionIsBackOnline  Add a listener on the server.  Make sure the abort server message was sent. getRegionServer sleep countOfMetaRegions Past close  Now wait for regions to come back online. unregisterRegionServerOperationListener closeAllNonCatalogRegions  Go close all non-catalog regions on this new server Past abort send; waiting on all regions to redeploy info minimumRegions LOG getOnlineRegions Started new regionserver:  getRegionServerThreads hrs getRegionServerOperationQueue  Need at least two servers.  Set the listener only after some regions have been opened on new server. m registerRegionServerOperationListener Threads getLiveRegionServerThreads  wait on all regions back online. testKillRSWithOpeningRegion2482 size getHBaseCluster HMsg  come in. startRegionServer toString getMaster addMessageToSendRegionServer ,hadoop,1
" Check for resolved conf /2009/22/ eAction getTestCaseDir property action createActionElement elementList  push deps are not met dryRunCoord printStackTrace workflow populateTable getChild parseXml testDryRunPullAndPushDeps /2009/15/ getPullMissingDependencies testDir hcatDependency fail CoordinatorJob getChildren getNamespace file://,testDir/2009/29 CoordCommandUtils job addRecordToCoordJobTableForWaiting setPushMissingDependencies configuration  Make only pull dependencies available ${coord:dataIn('A')} appPath createCoordinatorActionBean actionXml sleep coord default coord-action-for-action-input-check.xml /2009/08/ get createDir coord-job-for-matd-hcat.xml tablename value actionBean table missDeps XmlUtils e newactionXml getMessage assertEquals e1 setMissingDependencies e2 ${coord:dataOut('LOCAL_A')} getValue /2009/29/ configElem file://,testDir/2009/29,file://,testDir/2009/22,file://,testDir/2009/15,file://,testDir/2009/08 getPushMissingDependencies getCoordActionXml  actionXml only to check whether coord conf got resolved or not db getFsTestCaseDir ",oozie,1
resume END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL oozieUrl MockDagEngineService conf assertEquals wc testResume call OozieClient 1 setProperty createConfiguration SERVLET_CLASSES runTest ,oozie,1
setAppName getMessage iae testConstructor <workflow></workflow> Construction with illegal args failed as expected:  My Test App Assert assertTrue assertNotNull jsonWFJob My Test ID setId ,oozie,1
getName set hdfs://foo:12345/ GenericTestUtils conf Did not fail with fake FS getFileSystem .foo p fail does not use port information assertExceptionContains exists testLogicalUriShouldNotHavePorts DFS_CLIENT_FAILOVER_PROXY_PROVIDER_KEY_PREFIX ioe ,hadoop,1
getServiceComponentHosts cluster handler hi setLastHeartbeatTime setHardwareProfile hm setHostname setNodeStatus getCluster mapHostsToCluster centos5 setComponentName iterator getServiceComponentName handleRegistration reg setResponseId host sch getClustersForHost getHost add addCluster HostState getServerVersion am  Heartbeat will expire and action queue will be flushed testHeartbeatLossWithComponent Role aq setComponentStatus setAgentVersion size State name mock statuses addServiceComponent HDP-0.1 shutdown setDesiredStackVersion next setOS hostNames getServiceName  try to flip statuses back setClusterName System sleep sc hostname1 addService Centos5 setServiceName clusterName HostStatus persist injector clusters setTimestamp getServiceComponent handleHeartBeat cool ambariMetaInfo start Service assertEquals addServiceComponentHost serviceName addHost getService setStatus Thread cs Integer enqueue setOsType getState currentTimeMillis hdfs isClientComponent setState hb getInstance  don't keep marking the host as down ,ambari,1
next deleteTopic KafkaUtils data log keys localZKServer testProduceConsume TOPIC chooseFreePort sleep iterator assertTrue getFirst info localhost add localKafkaBroker Starting consumer thread readData Producing data valueOf kafkaBrokerPort start  Sleep for a while before shutting down producer to let both finish hasNext assertEquals zkPort produce NUM_DATA Thread Integer IOUtils contains getPort doRun size awaitScheduling maybeCreateTopic ,oryx,1
"Unexpected Exception      f->(2,3)     2->decision node->{4,k,4}     3->decision node->{k,5,k}     4->j     5->j      def addNode printStackTrace e f one j k kill three two asList fail testDecisionsToKillForkJoin invokeForkJoin parser four name dummyConf end Arrays five ",oozie,1
testSetKeyValueExpiration ninjaCache parseDuration cache set 10s TimeUtil verify expiration value key ,ninja,0
"DagELFunctions ActionType testELFunctionsReturningMapReduceStats ""REDUCE_INPUT_RECORDS"":2}} createEvaluator {""g"":{""c"":10},""org.apache.hadoop.mapred.JobInProgress$Counter"": ${hadoop:counters('H')['ACTION_TYPE']} context setId action group counters workflow ""REDUCE_OUTPUT_RECORDS"":2,""SPILLED_RECORDS"":4,""MAP_OUTPUT_BYTES"":28, ']} ${hadoop:counters('H')[' 1 ApplicationType ${hadoop:counters('H')[RECORDS][MAP_OUT]} eval ""FILE_BYTES_WRITTEN"":146,""HDFS_BYTES_WRITTEN"":16}, name {""TOTAL_LAUNCHED_REDUCES"":1,""TOTAL_LAUNCHED_MAPS"":2,""DATA_LOCAL_MAPS"":2},""ACTION_TYPE"":""MAP_REDUCE"", evaluate setName addNode ""FileSystemCounters"":{""FILE_BYTES_READ"":38,""HDFS_BYTES_READ"":19, generateId H '][' wi configureEvaluator get ""COMBINE_OUTPUT_RECORDS"":0,""MAP_INPUT_RECORDS"":2,""REDUCE_SHUFFLE_BYTES"":22, <workflow-app/> MapReduceActionExecutor ${hadoop:counters('H')[RECORDS][REDUCE_OUT]} setProtoActionConf setWorkflowInstance ${hadoop:counters('H')[RECORDS][REDUCE_IN]} a c ${hadoop:counters('H')[RECORDS][GROUPS]} ${hadoop:counters('H')[RECORDS][MAP_IN]} setVar g assertEquals ""org.apache.hadoop.mapred.Task$Counter"":{""REDUCE_INPUT_GROUPS"":2, wfApp Services <configuration/> ""MAP_INPUT_BYTES"":12,""MAP_OUTPUT_RECORDS"":2,""COMBINE_INPUT_RECORDS"":0, toString ",oozie,1
WhitelistBasedResolver 10.119.103.112 set 10.113.221.221 SASL_PRIVACY_PROPS 10.221.102.0/23 conf getServerProperties assertEquals setConf testNullIPAddress fixedIps createFileWithEntries setLong variablewhitelist.txt removeFile TestFileBasedIPList wqr variableIps 10.222.0.0/16 fixedwhitelist.txt setBoolean ,hadoop,0
 conn setRequestMethod IS_SECURITY_ENABLED jo /v1/jobs getId put total bundleJobBean assertTrue array get json content-type Job bundle runTest RestConstants openConnection valueOf addRecordToBundleJobTable MockDagEngineService HttpServletResponse assertEquals parse params getInputStream bundleJobId url =BUNDLE-TEST; JSONValue call OozieClient getHeaderField getTestUser xDataTestCase =PREP; GET getResponseCode Long bundlejobs reset createURL testGetBundleJobs = startsWith ,oozie,1
lookupCountryIdentifier MO 000000 assertEquals testLookup 500000 assertNull 472000 US/CA GB support 958000 509000 ,zxing,0
"BYTES  Missing format specification, this should throw. 1T conf  Illegal number  specification, this should throw. 1GB  This call returns the value specified in the Key as a double in MBs. MB setStrings nonKey KB 1k  illegal format specification, this should throw. GB  suffix. key 1TB 1bytes 1PB getStorageSize HadoopGB thrown is 1HB assertThat 64 GB  during read, we also try to read using a different Storage Units. TB 10m valid.key 100 expect testStorageUnit  to MBs are returns that value. 2048b setStorageSize not.a.key ",hadoop,0
"cursor  value5 getName value7 value1 value4 value3  2nd element has 1 parameter testParseHeaderElements  1st element Assert  2nd element parseElements  3rd element name5=value5, name6= ; name7 = value7; name8 = "" value8"" length headerValue assertEquals  value8 name6 name1 = value1; name2; name3=""value3"" , name4=value4;  getValue name5 buf  1st element has 2 getParameters() name4  3rd element has 2 getParameters() name3 name8 elements name7 getParameters  there are 3 elements name2 name1 append ",httpcore,0
getPayloadContent read valueOf testReadFramePartialReads getStreamId assertEquals inBuffer readableChannel ByteBuffer remaining FrameFlag Assert allocate getType payload assertNotNull FrameType of get getFlags frame ,httpcore,0
getFailoversOccurred proxyProvider impl2 start setLatchEnabled assertEquals impl1 RetryProxy  Getting a proxy will now wait on a latch. TypeOfExceptionToFailWith RetryPolicies unreliable create failoverOnNetworkException join t1 testConcurrentMethodFailures t2 ,hadoop,1
valueOf assertFalse assertEquals HTTP Float Assert assertTrue hashCode equals ver2 ver1 http testHttpVersionEquality HttpVersion ,httpcore,0
HttpHeaders 12 addHeader process ProtocolException should have been thrown chunked interceptor Method testRequestContentProtocolException request2 getEntity request1 / fail Assert context ,httpcore,0
setLong DFSConfigKeys fName  Modify defaul filesystem settings conf hFlush_03 customPerChecksumSize customBlockSize setInt doTheJob ,hadoop,1
headers getServerAddress testThatMetaInfIntegrationWorks ninjaTestBrowser newHashMap assertEquals assets/webjars/bootstrap/3.0.0/css/bootstrap.min.css  Some empty headers for now... makeRequestAndGetResponse Maps  /redirect will send a location: redirect in the headers getStatusCode getStatusLine httpResponse ,ninja,1
date dd integerPrimitive equalTo invoke IsUUID IsInteger uuid when put context validation IsDate characterPrimitive ee somethingElseWhatShouldBeSkipped assertViolation thenReturn  some setup for this method: testBodyParserWithValidationErrors longObject  do assertThat characterObject IsFloat floatPrimitive  and test: bodyParserEnginePost getValidation hasViolations assertTrue testObject doublePrimitive map timestamp cc a b c d integerObject e f g h floatObject assertNull Mockito longPrimitive getParameters doubleObject ,ninja,0
/assets/css/app.css /assets/javascripts/main.js /John/photos/2201 buildRoute assertFalse John /assets/{file: .*} robots.txt file assertTrue 2201 get javascripts/main.js id map John/photos/first /assets/robots.txt entrySet getPathParametersEncoded assertEquals matches  regex expressions... pathUnderTest ninjaBaseDirectoryResolver /{name: .+}/photos/{id: [0-9]+}  multiple parameter parsing with regex expressions route size css/app.css basicPlaceholersParametersAndRegexInsideVariableParts GET name routeBuilder ninjaProperties ,ninja,0
getClass getServletContext TOKEN_VALIDITY_SEC assertFalse simple getValidity when getCookiePath asList getInitParameterNames getAttribute Assert assertTrue context init AuthenticationFilter thenReturn isCustomSignerSecretProvider destroy assertEquals isRandomSecret getAuthenticationHandler filter assertNull getInitParameter  minimal configuration & simple auth handler (Pseudo) Mockito getCookieDomain elements mock testFallbackToRandomSecretProvider toString Arrays config ,hadoop,0
END_POINTS IS_SECURITY_ENABLED getContextURL oozieUrl testOozieStatus HeaderTestingVersionServlet clear admin run assertEquals -systemmode args call -oozie -status SERVLET_CLASSES NORMAL runTest ,oozie,1
should enqueue e expected should not enqueue assertEquals run consume trigger capacity testConsumeAll q enqueue times consumeAll assertTrue mock verify  arbitrary element ,hadoop,0
thenReturn true context primBooleanParam create verify invoke primBooleanParamShouldBeParsedToBoolean when param1 mockController getParameter ,ninja,0
"getCurrentUser getGroupNames GROUP_NAMES assertFalse  make sure it is not the same as the login user conf run String assertTrue ugi PERCENTILES_INTERVAL setConfiguration  make sure in the scope of the doAs, the right user is current UserGroupInformation createUserForTesting curUGI set userGroupInfo valueOf assertEquals USER_NAME getLoginUser testLogin verifyGroupMetrics  ensure that doAs works correctly  login from unix doAs equals HADOOP_USER_GROUP_METRICS_PERCENTILES_INTERVALS ",hadoop,0
ROW_1 QUALIFIER_1 value2 value1 QUALIFIER_2 ROW_2  test timerange result Bytes setMaxVersions testGet assertTrue TS_2 assertNotNull TS_1 getTimestamp get  @TS_1 VALUE_1  @TS_2  test maxVersions VALUE_2 setTimeRange addColumn count assertEquals  test timestamp kv list getValue assertNull setTimeStamp COLUMN_2 COLUMN_1 addFamily getFamily equals COLUMN_3 remoteTable ,hadoop,1
appendBits testAppendBitVector appendBitArray  X.XXXXX. XXX.XXXX toString assertEquals v1  beef = 1011 1110 1110 1111 v2 ,zxing,0
addRecordToWfActionTable getId WorkflowInstance _testWfActionSubsetGet System testWfActionSubsetGet 1 2 addRecordToWfJobTable WorkflowAction testWfActionSubsetGet Successful WorkflowJob job ,oozie,1
"getJobTrackerUri </name-node> <configuration> <java> </configuration> getAppPath getActions conf setupActionConf createBaseHadoopConf testACLDefaults_noFalseChange actionXml wfBean test2-acl <property><name>oozie.launcher.mapreduce.job.acl-modify-job</name><value>M</value></property> addRecordToWfJobTable assertNotNull get context action JavaActionExecutor <job-tracker> getNameNodeUri  CASE: launcher specific ACLs configured, but MR job ACLs not configured i.e. null. Check for no false changes to null eActionXml <property><name>oozie.launcher.mapreduce.job.acl-view-job</name><value>V</value></property> actionConf </java> ae XmlUtils parseXml </job-tracker> createLauncherConf <main-class>MAIN-CLASS</main-class> getFileSystem setType <name-node> getType ",oozie,1
"code sessionsAreNotSharedOnSingleResultInstances  request above) got assigned to us! conf/jetty.com.session.conf client2 nullValue client1 client0  should not get a session value back  establish session with a set-cookie header not followRedirects get Set-Cookie RANDOM_PORT HttpRequest Cookie externalConfigurationPath standalone start is assertThat /badRoute port getBaseUrls /getOrCreateSession  call redirect so its session is processed first time (triggers bug for issue #450) header  this test is not really specific to jetty, but its easier to test here shutdown ",ninja,0
address e RANDOM Expected an exception to have been thrown getMessage conf nextLong when mockFactory call fail doThrow contains createSocket stop assertTrue mock client Injected fault testSocketFactoryException 127.0.0.1 ,hadoop,0
svc init stop testServiceNotifications listener start registerServiceListener assertEventCount ,hadoop,0
CoordinatorJobBean jobConf bundleJobGetCmd log submitCmd getId getStatus isPending appPath Configuration parse error. read from DB : getJob sleep testBundleSuspend2 bundleActionsGetCmd assertNotNull get getAuthToken Job waitFor coordGetCmd1 set coordGetCmd2 getConf job2 job1 addRecordToBundleJobTable assertEquals getCoordId execute bundle.xml call Services warn OozieClient size equals toString ErrorCode job jpaService actions evaluate ioe ,oozie,1
hdfs11 submit reader getJobInfo LocalOozie conf inPath getStatus sleep jobId1 getTestCaseDir /workflow.xml file:// workflow.xml testRedeploy WorkflowJob waitFor rerun-el-wf.xml wfClient rerun-elerr-wf.xml start assertEquals getClient reRun /check OozieClient IOUtils getTestUser copyCharStream setProperty getResourceAsReader createConfiguration toString writer File evaluate getFsTestCaseDir checkDir ,oozie,1
"init data writtenSize createFile duSize Thread sleep du file testDU getUsed Invalid on-disk size assertTrue slack  writing 32K  that may store additional file metadata (eg ext attrs).  test without launching thread DU_DIR  let the metadata updater catch up close  test with 0 interval, will not launch thread ",hadoop,0
 getClass testClearingCachedMappings resolve 	/rack2  conf reloadCachedMappings /rack2 /rack1 result .txt get .testClearingCachedMappings Files write deleteOnExit add mapFile mapping getCanonicalPath set  /rack1  asCharSink createTempFile assertEquals setConf NET_TOPOLOGY_TABLE_MAPPING_FILE_KEY names size NetworkTopology hostName2 hostName1 getSimpleName File Charsets ,hadoop,0
eval intercept testEvalDoesWrapIOEs verifyCause ioe ,hadoop,0
"server serverThreads Server assertFalse callIds run conf  contains every expected value. startID get client synchronizedList join perCallerCallCount Collections addr getCallId callerCount add intValue testUniqueSequentialCallIds start assertEquals sort getConnectAddress  list must be synchronized, because multiple server threads will add to it. NetUtils stop size callers expectedCallCount ",hadoop,0
Expected no groups to be returned given a shell command timeout defaultTimeout The groups framework call should   Test the no-timeout (default) configuration assertFalse ran longer than the configured timeout limit conf Expected the logs to carry  shellMappingLog  Test a 1 second max-runtime timeout Expected the group ID executor to carry the configured timeout assertTrue clearOutput executor Expected the group ID executor to carry the default timeout  Test also the parent Groups framework for expected behaviour createGroupExecutor createGroupIDExecutor a message about command timeout but was:  testFiniteGroupResolutionTime have failed with a command timeout getGroups getOutput Expected the group names executor to carry the configured timeout mapping CommonConfigurationKeys testTimeout setClass groups foobarnonexistinguser newInstance assertEquals userName getTimeoutInterval fail setLong contains size commandTimeoutMessage ReflectionUtils Expected the group names executor to carry the default timeout Didn't expect a timeout of command in execution but logs carry it:  ,hadoop,0
fencer MOCK_TARGET testShortNameSshWithUserPort assertFalse sshfence(user:123) fence setupFencer ,hadoop,0
"KeyProvider testRootDir getCurrentKey No password file property, env not set, it should fail key3 conf ourUrl delete unset bar using non existing password file, it should fail testJksProviderPasswordViaConfig file Assert flush provider assertNotNull get options JavaKeyStoreProvider test.jks set getProviders core-site.xml toUri could not create keystore with password file using different password file, it should fail createKey javakeystoreprovider.password fail jksPath ://file toString KeyProviderFactory ",hadoop,0
servicePrincipal handler getOidInstance getName base64 getServerName createContext when requestCredDeleg setHeader Assert getUserName   localhost inToken doAsClient thenReturn GSS_KRB5_MECH_OID eq matches getType GSSContext mock dispose createName request authenticate NT_GSS_KRB5_PRINCIPAL authToken gssContext oid getHeader getExpectedType gssManager KerberosAuthenticator assertTrue GSSManager verify initSecContext  .* testRequestWithAuthorization encodeToString HttpServletResponse outToken assertEquals KerberosTestUtils serviceName KerberosUtil setStatus token call getClientPrincipal requestMutualAuth Mockito response getServerPrincipal getInstance startsWith ,hadoop,0
shutdownTimeoutMillis getCurrentUser submit foo testStopThreads conf sleep Assert updateIntervalSeconds assertNotNull tm1 getDelegationTokenSecretManager sm getSecretConf UserGroupInformation getListenerThreadPool init getConnectString ZKDelegationTokenSecretManager zkServer unchecked destroy createToken es token Thread call setLong zksm  force this to be shutdownNow connectString  it will cause an error. DelegationTokenManager rawtypes ,hadoop,0
thenReturn invoke when param1 dateParam assertTrue context create verify customDateFormatValidationShouldWork mockController validation hasViolation blah getParameter ,ninja,0
cluster conf namenode args getDefaultUri testFsOption build FileSystem testPropertyOption toString testConfOption testDFSCommand /data shutdown -mkdir ,hadoop,1
getProperty priorDefaultEncoding UTF-8 declareProperty writeXml endConfig startConfig conf assertEquals fos System CONFIG_MULTI_BYTE_SAVED testMultiByteCharacters US-ASCII out CONFIG_MULTI_BYTE file.encoding addResource setProperty get name multi_byte_æ„›_name multi_byte_Ù_value value ,hadoop,0
PATH request  Add request. alreadyCheckedResponse put stuffParm Parameters appended to the path should have been put in the query. Assert assertTrue runTests get addTest /stuff parameterInPath adapter test containsKey query unchecked stuff2 assertEquals execute framework QUERY REQUEST newFrameworkAndSetAdapter stuffParm2 /stuff?stuffParm=stuff&stuffParm2=stuff2 stuff ,httpcore,0
 1 1 1 1 1 1 1 0                   0 1 1 1 1 1 1 1  testEmbedBasicPatterns2 MatrixUtil getVersionForNumber  0 0 0 0 0 0 0 0 1               1 0 0 0 1          matrix  1 1 1 1 1 1 1 0                 1 0 1 0 1           1 0 0 0 0 0 1 0                                    Version  0 0 0 0 0 0 0 0                   0 0 0 0 0 0 0 0  clearMatrix  1 1 1 1 1 1 1 0                                                 0                                       1 0 0 0 0 0 1 0                 1 0 0 0 1           1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1               1                   1 1 1 1 1           1 0 1 1 1 0 1 0                   0 1 0 1 1 1 0 1   1 0 1 1 1 0 1 0                 1 1 1 1 1          expected assertEquals embedBasicPatterns              1                                       1 0 1 1 1 0 1 0                                     bottom corner. toString  1 0 0 0 0 0 1 0                   0 1 0 0 0 0 0 1  ,zxing,0
cluster testSeekBugDFS conf getFileSystem seekReadFile smallReadSeek build fileSys file1 seektest.dat close writeFile shutdown cleanupFile ,hadoop,1
server ProxyUsers TestProtocol RPC configureSuperUserIPAddresses getProxySuperuserGroupConfKey getProxy aMethod GROUP_NAMES  via  conf run testRealUserAuthorizationSuccess retVal Assert setStrings REAL_USER_SHORT_NAME refreshConf stopProxy addr UserGroupInformation getServer ret proxyUserUgi printStackTrace e start assertEquals createRemoteUser group1 getConnectAddress REAL_USER_NAME fail proxy doAs NetUtils stop ADDRESS PROXY_USER_NAME realUserUgi createProxyUserForTesting ,hadoop,1
"ensureTimeToPoll testWatchForMultipleEventTypes resolve ImmutableList foo ENTRY_CREATE fs delete createFile path bar foo/bar of getPath createDirectory baz Files createDirectories watcher ENTRY_MODIFY  watcher polls, seeing modification, then polls again, seeing delete  this could be flaky; may need to increase time between polling if so (or just not test it) ENTRY_DELETE register assertWatcherHasEvents ",jimfs,1
"me=;user1=group1;user2=group1,group2 testGroupLookupForStaticUsers assertFalse conf group lookup done for static user assertTrue me getGroups non-empty groups for static user group lookup done for unprivileged user add user1 user2 set CommonConfigurationKeys setClass expected isEmpty groups group2 group1     * Group lookup should not happen for static users     userGroups FakeunPrivilegedGroupMapping equals groups not correct ",hadoop,0
fail process Assert HttpStatus response testResponseConnControlHostInvalidInput interceptor OK IllegalArgumentException should have been thrown ,httpcore,0
p a b test2 size a/b get assertEquals peekLast ,logback,0
"GET_ALL_GROUPS_CMD testStaticMapping assumeNotWindows put HashBiMap uMap  | cut -d: -f1,3 echo ""hdfs:*:11501:hrt_hdfs  uidStaticMap mapred:x:497  get create gMap atm hdfs:x:11501:10787:Grid Distributed File System:/home/hdfs:/bin/bash"" group inverse mapred2:x:498"" GET_ALL_USERS_CMD assertEquals mapred2 ShellBasedIdMapping hdfs :  Maps for id to name map echo ""atm:x:1000:1000:Aaron T. Myers,,,:/home/atm:/bin/bash  user mapred gidStaticMap updateMapInternal ",hadoop,0
assertTrue release isLocked assertFalse start lock run testMultipleThread join acquire competingThread tryLock ,hadoop,0
  df Filesystem     1K-blocks     Used Available Use% Mounted on Expected exception with empty line! Unexpected empty line Fewer lines of output than expected e reader GenericTestUtils testDFMalformedOutput        19222656 10597036   7649060  59% / System / /dev/sda5       19222656 10597036   7649060  59% / fail Filesystem     1K-blocks     Used Available Use% Mounted on  assertExceptionContains Could not parse line:  parseOutput toString parseExecResult Expected exception with missing line! Expected exception with missing field! ,hadoop,0
actionNum getId getStatus addRecordToCoordActionTable addRecordToCoordJobTable _testCoordActionForCorrectColumnValues CoordinatorJob jobId testCoordActionsRunningForColumnValues       * Add a Coordinator action with status RUNNING and check for expected column values       coord-action-get.xml CoordinatorAction action job getPending ,oozie,1
"Assert ContentType getMimeType text/plain; charset="" "" testParseEmptyCharset assertEquals parse getCharset contentType text/plain ",httpcore,0
a${k${zero}}b input node transform nodeToStringTransformer nestedVariable propertyContainer0 makeNode av0b assertEquals ,logback,0
" Wait for the async task to finish  Refill task should add 10 values to get to a full queue test SyncGenerationPolicy k1 Failed in async call. getAtMost  Queue is empty, sync will return a single value and trigger a refill assertEquals getNext drain  Drain completely, no further refills triggered  the prefill to the low watermark, 1 consumed by getNext()) waitForRefill Assert size getTop filler vq  Trigger a prefill (3) and an async refill (8) testgetAtMostPolicyATLEAST_ONE shutdown ",hadoop,0
addRecordToBundleActionTable getId coordActionB addRecordToCoordActionTable bundleJobA bundleJobB children assertNotNull bundleActionB get CoordinatorAction something_different Job coordJobB getAppName setAppName addRecordToBundleJobTable execute addRecordToCoordJobTable checkChildren Services CoordinatorJob coordActionA2 coord-action-get.xml testGetBundleParent coordActionA1 addAll bundleActionA1 bundleActionA2 jpaService coordJobA2 coordJobA1 ,oozie,1
Exception should specify parsing error and invalid umask:  22 99  b set foo getMessage conf iae Shouldn't have been able to parse bad umask fail 1777 assertTrue isCorrectExceptionMessage getUMask FsPermission testBadUmasks ,hadoop,0
"setHandler conn getCurrentUser  proxyuser using raw HTTP, verifying doAs is case insensitive run String /bar Assert /foo/bar FOO_USER ugi context readLines DispatcherType UserGroupInformation ret /foo %s?user.name=%s&DOAS=%s OK_USER openConnection  requests using delegation token as auth do not honor doAs format  unauthorized proxy user using authentication handler authentication setContextPath createJettyServer strUrl createRemoteUser getInputStream toExternalForm doAs stop size addFilter  proxy using delegation token authentication FAIL_USER HttpURLConnection of get jetty /* getJettyURL addToken aUrl addServlet EnumSet start assertEquals testProxyUser url token IOUtils  proxyuser using authentication handler authentication getResponseCode getDelegationToken %s?user.name=%s&doas=%s ",hadoop,0
actionNum CoordinatorJob jobId coord-action-get.xml testCoordActionsNotCompletetedForSize CoordinatorAction _testCoordActionsNotCompletedSize getId job addRecordToCoordActionTable       * Add 2 Coordinator actions which are not completed (status as RUNNING and WAITING) and add 2 Coordinator actions      * which are completed (status as FAILED and KILLED). Then check for expected number of actions retrieved.       addRecordToCoordJobTable ,oozie,1
 positive test getStatus SubWorkflowActionExecutor protoConf createBaseWorkflow getWorkflowClient getTestGroup newConf create </app-path> action setId workflow.xml write getBaseProtoConf waitFor actionConf workflow getFileSystem check childConf testGetGroupFromParent OozieClient       </configuration> WorkflowAction W1 File evaluate  negative test <sub-workflow xmlns='uri:oozie:workflow:0.1' name='subwf'>       <app-path>       <configuration> getJobInfo assertFalse           <name>a</name>         </property> getActions getExternalId fs APP1           <value>A</value> WorkflowActionBean wf W get end close set getConf oozieClient         <property> start defaultConf subWorkflowAppPath subWorkflow assertEquals setConf toXmlString </sub-workflow> writer action1 getFsTestCaseDir ,oozie,1
cluster  start up an empty node with the same capacity and on NODEGROUP2 getProxy racks numOfDatanodes conf sum newNodeGroup TestBalancer testBalancerWithNodeGroup createFile waitActive createProxy createConf NameNodeProxies MiniDFSClusterWithNodeGroup totalCapacity RACK1 NODEGROUP2 builder NODEGROUP1 client  run balancer and validate results capacities RACK0 NODEGROUP0 nodeGroups CAPACITY startDataNodes  fill up the cluster to be 20% full filePath newCapacity assertEquals getFileSystem newRack runBalancer simulatedCapacities totalUsedSpace setNodeGroups numDataNodes shutdown getUri ,hadoop,1
"bb dataOut seed keyInterval allocBloom  we assume only 2 blooms in this test, so exit before a 3rd is made getKeyCount Hash System valid seed =  Bytes  add assertTrue newBf1  check get bloomCount nextBoolean write False positives:  add  test serialization/deserialization getDataWriter set err toBytes falsePositives  allow some tolerance bf1 ByteBuffer keys added =  r contains testDynamicBloom getMetaWriter currentTimeMillis toByteArray metaOut wrap ",hadoop,1
address getLocalPort set socket2 Server max address2 conf - TestRange 0.0.0.0 testBind bind min isBound assertTrue socket close ,hadoop,0
fullCrc testUnstripedIncorrectChunkSize chunkSize  the fullCrc. update assertEquals type crcBytesByChunk newCrcComposer CrcComposer CrcUtil digest calculatedCrc readInt digester assertNotEquals ,hadoop,0
"FS001 FS002 viewfs is a supported scheme. This should not throw exception getErrorCode assertTrue bla get hdfs,viewfs  testing schemes supported hdfs://x/bla init ae testValidatePath destroy getMessage assertEquals validatePath viewfs://bla HadoopAccessorService fail Services E0904 contains ex file://bla setSystemProperty file is not a supported scheme. This should throw exception ",oozie,1
fail IOUtils getResourceAsString abcde testGetResourceAsString assertEquals invalid-resource.txt test-ioutils.txt ,oozie,1
KeyProvider p1 getClass generateEncryptedKey testClassCastException getName kp AuthenticationException foo encryptedKeyVersion createKey conf getCause rollNewVersion contains assertTrue decryptEncryptedKey options mock kms://http@host1:9600/kms/foo ioe ,hadoop,0
add fromList assertEquals l testIterator ,hadoop,0
generateCertificate truststoreLocation BASEDIR put sleep  Wait so that the file modification time is different password jks get SHA1withRSA waitFor RSA init kp createTrustStore getReloadInterval destroy GenericTestUtils assertEquals cert2 certs generateKeyPair cert1 Thread CN=Cert2 /testreload.jks  Add another cert CN=Cert1 tm getAcceptedIssuers testReload ,hadoop,0
checkCoordActions getTime DateUtils parseDateOozieTZ 2009-03-06T10:00Z addRecordToJobTable call jobId CoordinatorJob 2009-03-06T09:58Z pauseTime -testActionMater-C 0000000- startTime endTime 2009-03-06T10:14Z testActionMaterWithPauseTime3 ,oozie,1
cluster assertFalse conf /tmp/testBlockVerification/file1 fs waitReplication  Read the file to trigger reportBadBlocks by client createFile waitActive rand random restartDataNode  its replicas assertTrue block copyBytes DFSTestUtil DFSConfigKeys MiniDFSCluster  and we should get all the replicas  Corrupt random replica of block  Restart the datanode hoping the corrupt block to be reported nextInt getFileSystem corruptReplica testBlockCorruptionPolicy setLong IOUtils build numDataNodes  We have 2 good replicas and block is not corrupt allBlockReplicasCorrupt file1 getFirstBlock open shutdown ,hadoop,1
p1 p2 p3 getName p4 getKMSUrl kp e anyString thenReturn createKey conf any when fail test3 Mockito assertTrue testLoadBalancingWithAllBadNodes mock Should fail since all providers threw an IOException thenThrow ,hadoop,0
given .installed resolve alpha.jar willReturn assertThat asList bravo charlie.jar getNamesOfFilesInLib bravo.jar uninstall install alpha installAndUninstallWithCommonDependencies createTemporaryFile containsInAnyOrder Arrays charlie ,spring-boot,1
_testGetJobInfoForAppName bundleJob1 _testGetJobInfoForUserAndStatus _testGetJobInfoForId _testGetJobInfoForStatus _testGetJobInfoForGroup _testGetJobInfoForUser addRecordToBundleJobTable getId Job testBundleJobInfoGet ,oozie,1
"A Evaluated bad expression ${a:a()} assertFalse Parsed bad expression assertTrue a,a checkForExistence ELEvaluator ${a:a(), a:a()} evaluator a ! ${a:d('foo', 'bar')} ${a:a()},${a:a()} addFunction d ${a:a()}${a:a()}! testCheckForExistence setVariable assertEquals , fail functionD assertNull functionA getCurrent support evaluate ",oozie,1
a fail testNotEmptyElements name notEmptyElements Arrays ParamChecker asList ,oozie,1
" map-reduce-launcher.jar  same for launcher  assertEquals(classes, ae.getLauncherClasses()); /app/job.jar ActionExecutorException conf  absolute path with namenode setupActionConf MR003 protoConf originalUberJarDisabled context action launcherJobConf IF <job-tracker> oozie.action.mapreduce.uber.jar.enable serv ae IN oozie.pipes.inputformat oozie.pipes.partitioner getFileSystem oozie.pipes.program <name-node> ActionExecutorException expected because uber jars are disabled fail  Enable uber jars to test that MapReduceActionExecutor picks up the oozie.mapreduce.uber.jar property correctly contains 2 <streaming> getType <env>ee=EE</env> <map>M</map> <writer>W</writer> oozie.streaming.record-reader RR getClassesForLauncher getActions <streaming></streaming> <inputformat>IF</inputformat> M oozie.pipes.reduce createBaseHadoopConf mr-action P R job.jar getErrorCode assertTrue get W getBoolean <program>PP</program> <record-reader-mapping>RRM2=2</record-reader-mapping> set XmlUtils getMessage oozie.pipes.map assertEquals getJar getLauncherJarName /PP </map-reduce> Services getTestUser assertNull addAll <property><name>mapred.input.dir</name><value>IN</value></property> <env>e=E</env> setBoolean getJobTrackerUri map-reduce oozie.streaming.mapper oozie.streaming.reducer <pipes> </configuration> createBaseWorkflow <reduce>R</reduce> <map-reduce>  doesn't resolve if not set mapred.input.dir  relative path testSetupMethods oozie.pipes.writer add <record-reader-mapping>RRM1=1</record-reader-mapping> parseXml </job-tracker> createLauncherConf </pipes>  same for launcher conf  same for launcher conf (not set) </name-node>  absolute path without namenode </streaming> getErrorType createUberJarActionXML aee <record-reader>RR</record-reader>  ignored for streaming classes /job.jar <reducer>R</reducer> wf actionXml <partitioner>P</partitioner> <mapper>M</mapper> getNameNodeUri  ignored for pipes <property><name>mapred.output.dir</name><value>OUT</value></property> getConf WorkflowAppService  Disable uber jars to test that MapReduceActionExecutor won't allow the oozie.mapreduce.uber.jar property oozie.streaming.env.size <configuration> setType oozie.streaming.record-reader-mapping.size oozie.mapreduce.uber.jar <pipes></pipes> getFsTestCaseDir ",oozie,1
getId assertEquals getStatus execute addRecordToCoordJobTable call CoordinatorJob Services coordJobGetCmd testCoordSuspendAndResumeForPrep assertNotNull get job jpaService ,oozie,1
 SimpleLog log prefix assertFalse resetMessage isWarnEnabled error getCause setLevel fatal trace assertTrue setMsgPrefix isInfoEnabled assertNotNull isErrorEnabled isTraceEnabled xLog debug debug info a b debug XLog getMessage assertEquals debug {0} isFatalEnabled getMsgPrefix warn ops assertNull testXLogFunctionality endsWith isDebugEnabled ,oozie,1
checkCoordJobs toDate getId DateUtils System parseDateOozieTZ addRecordToCoordJobTable call CoordinatorJob 2099-02-03T23:59Z currentTimeMillis startTime endTime job testMatLookupCommand4 ,oozie,1
multiple evaluation murmur hash error !!! murmurHash testHash jenkins error !!! Hash getBytes undefined assertTrue LINE jenkins testHash murmur error !!! multiple evaluation jenkins hash error !!! parseHashType testHash testHash undefine configuration error !!! testHash error jenkin getInstance !!! set hadoop.util.hash.type cfg murmur testHash jenkins configuration error !!! testHash undefined iterations jenkinsHash JenkinsHash assertNull MurmurHash testHash error murmur getInstance !!! getInstance testHash error invalid getInstance !!! hash ,hadoop,0
formatDate DTEND:20080505 END:VEVENT BEGIN:VEVENT SUMMARY:foo DTSTART:20080504T123456   Start time only ParsedResultType   BEGIN:VEVENTSUMMARY:EventDTSTART:20081030T122030ZDTEND:20081030T132030ZEND:VEVENT BEGIN:VEVENT DTEND:20080505T END:VEVENT DTEND:20080505T234555Z END:VEVENT  Local times BEGIN:VEVENT SUMMARY:foo DTSTART:20080504T123456Z END:VEVENT DTEND:20080505T234555 END:VEVENT  Make sure illegal entries without newlines don't crash formatTime doTestResult  UTC times BEGIN:VEVENT SUMMARY:foo DTSTART:20080504 END:VEVENT testVEvent foo  BEGIN:VEVENT SUMMARY:foo DTSTART:20080504T123456Z  BEGIN:VEVENT SUMMARY:foo DTSTART:20080504  BEGIN:VEVENT SUMMARY:foo DTSTART:20080504T123456 END:VEVENT  Date only (all day event) DTEND:20080505T234555Z END:VEVENT END:VCALENDAR BEGIN:VCALENDAR BEGIN:VEVENT SUMMARY:foo DTSTART:20080504T123456Z  ,zxing,0
"getJobTrackerUri  Test oozie server action sharelib setting javaShareLibPath createContext cacheFilesStr context create workflow.xml getCacheFiles <job-tracker> testAddActionShareLib eActionXml workflow ae jar5.jar parseXml </job-tracker> getFileSystem jar5Path <name-node> </name-node> setupLauncherConf setLibFilesArchives OozieClient contains mkdirs jar4Path systemlib Arrays hcatShareLibPath other jobConf jar3.jar getWorkflow cacheFiles other,hcat <java> assertFalse getAppPath jar3Path createBaseHadoopConf actionXml oozie.action.sharelib.for.java jar4.jar java,hcat DistributedCache <job-xml>job.xml</job-xml> assertTrue get <job-xml>job2.xml</job-xml> jar2Path systemLibPath close wfConf hcat getNameNodeUri jar1Path set prettyPrint </java> XmlUtils getConf WorkflowAppService jar1.jar otherShareLibPath  Test per workflow action sharelib setting <main-class>MAIN-CLASS</main-class>  The oozie server setting should have been overridden by workflow setting setConf Services getTestUser toString jar2.jar getFsTestCaseDir setBoolean ",oozie,1
assertFalse context primBooleanParam create verify hasViolations invoke primBooleanParamShouldHandleNull mockController validation ,ninja,0
request getName tokenSigned TOKEN_VALIDITY_SEC setExpires sign secret when asList getInitParameterNames System secretProviderProps invalidtype getCookies secretProvider management.operation.return verifyUnauthorized signer AuthenticatedURL http://foo:8080/bar getRequestURL init chain cookie testDoFilterAuthenticatedInvalidType AuthenticationFilter thenReturn StringSignerSecretProviderCreator WWW-Authenticate destroy token filter p getMockedServletContextWithStringSigner getInitParameter newStringSignerSecretProvider Mockito u response elements currentTimeMillis setProperty true mock toString containsHeader Arrays config ,hadoop,0
getTime getId getStatus coordGetCmd coordJob pauseTime get startTime Job ;pausetime= init false destroy endtime= assertEquals services convertDateToString execute addRecordToCoordJobTable newEndTime call Services CoordinatorJob setSystemProperty StatusTransitService endTime job jpaService testCoordChangeStatus ,oozie,1
getStats shouldLog getMax assertFalse assertEquals testLoggingWithValue advance timer helper getMin assertTrue record LOG_PERIOD action getMean getCount ,hadoop,0
getParameterValues hello_hello1 hello_hello2 needingInjectionParamParserArray hello1 thenReturn invoke when asList param1 context create verify hello2 Arrays mockController ,ninja,0
10.119.103.112 10.113.221.222 10.222.103.121 is  in the list 10.113.221.221 assertFalse 10.222.103.121 is not in the list refresh 10.221.102.0/23 cipl ips 10.222.103.121 createFileWithEntries testAddWithRefresh removeFile assertTrue ips.txt TestFileBasedIPList ips2 10.113.221.222 is in the list 10.222.0.0/16 isIn 10.113.221.222 is not in the list ,hadoop,0
Status _testGetSLAEventsForSeqId testSLAEventsGetForSeqId -TestSLAEventsGetForSeqIdJPAExecutor-W current addRecordToSLAEventTable getTime 0000000- wfId ,oozie,1
"getName oozie.service.ProxyUserService.proxyuser.foo.groups foo conf asList bar Assert StringUtils assertNotNull get join validate localhost init set oozie.service.ProxyUserService.proxyuser.foo.hosts getConf destroy * services , Services testValidateHost proxyUser Arrays ",oozie,1
"request getID assertEquals testDistribution target accept getValue LIST_ID_VALUE_TYPE Assert OryxTest recs get X MediaType Y Z /classificationDistribution/B,0, ",oryx,1
 bodyParserEngineXml thenReturn is invoke getInputStream when testEmptyXmlBody getBytes Mockito assertTrue xmlObjMapper context xmlDocument badRequestThrown close ,ninja,0
addNode one assertEquals asList wf fail ex getErrorCode <worklfow-app/> testSelfTransition end ErrorCode Arrays ,oozie,1
Header ':scheme' must not be set for CONNECT request headers custom converter thrown CONNECT convert www.example.com asList expectMessage expect testConvertFromFieldsConnectPresentScheme :method :scheme http Arrays value :authority ,httpcore,0
" Once resumed, all results should be returned immediately conf  expire the cache two three asList waitForGroupCounters advance timer cacheGroupsAdd four setGetGroupsDelayMs five grps getGroups  3 should get queued and 2 should be running resume  Now run again, this time throwing exceptions but no delay CommonConfigurationKeys clearBlackList one g testBackgroundRefreshCounters groups refresh FakeGroupMapping pause setInt setLong myGroups  populate the cache setThrowException Arrays setBoolean ",hadoop,0
date scriptExecutor session ONE  Given update simple Eq consistencylist containsExactly  When getList of where should_dsl_update_list_setAtIndex id row table executeScriptTemplate RandomUtils manager one nextLong consistencyList_SetAtIndex assertThat TWO execute SimpleEntity/insert_single_row.cql ImmutableMap SELECT consistencylist FROM simple WHERE id =   Then Long buildDateKey fromBaseTable consistencyList dsl ,achilles,1
mapreduce.jobtracker.kerberos.principal mapreduce.jobtracker.address mapred.job.tracker jobConf set yarn.resourcemanager.address assertEquals mapred/localhost@KDC.DOMAIN.COM rm/server.com@KDC.DOMAIN.COM localhost:8032 Services getMRTokenRenewerInternal mapred/_HOST@KDC.DOMAIN.COM 127.0.0.1:50300 get testGetMRDelegationTokenRenewer oozie mr token localhost:50300 has yarn.resourcemanager.principal ,oozie,1
setClassesToBeExcluded testCoordKillForBackwardSupport coordActionGetCmd getId getStatus addRecordToCoordActionTable assertNotNull get CoordinatorAction action init getConf destroy assertEquals services setAppNamespace execute addRecordToCoordJobTable call Services CoordinatorJob coordJobGetCmd coord-action-get.xml excludedServices SchemaService setSystemProperty true StatusTransitService job jpaService ,oozie,1
getEncryptedKeyVersion getName  Generate another EEK and make sure it's different from the first be the same ek1 encryptionKey KeyProviderCryptoExtension Name of EEK should be encryption key name ek2 assertArrayEquals decryptEncryptedKey  Generate a new EEK and check it assertNotNull getEncryptedKeyIv testGenerateEncryptedKey Generated EEKs should have different IVs! generateEncryptedKey getEncryptionKeyName Generated EEKs should have different material! k1 k2 assertEquals kpExt getVersionName Expected encrypted key material  Decrypt it again and it should be the same ENCRYPTION_KEY_NAME getMaterial fail  Decrypt EEK into an EK and check it equals k1a Arrays Version name of EEK should be EEK Length of encryption key material and EEK material should  ,hadoop,0
ContentType getMimeType forName StandardCharsets UTF-8 Charset assertEquals getCharset US-ASCII Assert withCharset testWithCharset name create toString text/plain; charset=UTF-8 text/plain; charset=US-ASCII contentType text/plain ,httpcore,0
 check is using current secret for signing sign Assert setCurrentSecret secretProvider  previous secret no longer valid s1 verifyAndExtract assertNotEquals signer s2 s3  previous secret still valid test assertEquals e1 e2 e3  check not using current secret for signing fail testMultipleSecrets e1b setPreviousSecret secretD secretB t1 secretC t2 secretA t3 ,hadoop,0
test.txt getJobTrackerUri  getName lib subwf reader LocalOozie lib/test.jar conf getStatus output  getting external IDs of all actions on first run </workflow-app> writer2 writer1 getTestCaseDir /workflow.xml create  comparing external IDs of first run and rerun are different. workflow.xml write waitFor nameNode app <start to='end'/> wfClient loadExtIds <end name='end'/> is getFileSystem test.jar reRun  doing a rerun skipping no nodes delPath input OozieClient copyCharStream mkdirs setProperty getResourceAsReader createConfiguration File evaluate extId0 extId1 recovery-wf.xml submit mrclass getJobInfo <workflow-app xmlns='uri:oozie:workflow:0.1' name='app'> getActions appPath fs APP1 jobId1 createJar jobTracker WorkflowJob close getNameNodeUri os subWfApp  getting external IDs of all actions on rerun start subWorkflowAppPath assertEquals getClient testRerun /subwf/workflow.xml IOUtils jarFile copyStream assertNotSame toString writer getFsTestCaseDir  first run ,oozie,1
" ""else"" case: ""B"" is encoded as ASCII AIMAIMAIMÃ‹ AIMAIMAIMÃ« visualized 66 74 78 66 74 66 99 129  ""else"" case: ""b"" is encoded as ASCII assertEquals AIMAIAB AIMAIAb  Encoded as ASCII  Activate when additional rectangulars are available 230 91 11 90 255 254 67 129  ""else"" case 230 91 11 91 11 91 11 254 235 108 encodeHighLevel 230 91 11 91 11 91 11 254 235 76 testC40EncodationBasic2 ",zxing,0
readFields toByteArray action dos testEmptyWriteRead baos write close dis ,oozie,1
play ping  play it back  This ping will not be returned.  verify the peer received what was expected assertEquals acceptFrame sendFrame peer SPDY3  write the mocking script ping4 unexpectedPingIsNotReturned  PING connection ping2 takeFrame ,okhttp,1
getJobTrackerUri conf fs createJobConf getTestGroup assertNotNull get testAccessor has createFileSystem group getNameNodeUri mapred.job.tracker  invalid user set  valid user services uri Services fail createJobClient getTestUser fs.default.name invalid jc user ,oozie,1
setName clearMapping http:// getName  Authorization is disabled by default servlet setFindPort conf MyGroupsProvider asList put setAttribute getHostPortString getConnectorAddress HttpURLConnection testDisabledAuthorizationOfDefaultServlets logLevel Groups myServer getUserToGroupsMappingService serverURL HttpServer2 logs groupB groupA addEndpoint set CommonConfigurationKeys test stacks start assertEquals getHttpStatusCode / userA userB http://localhost:0 NetUtils stop build Arrays user ,hadoop,0
"cluster setupHostsFile writeConfigFile conf HEARTBEAT_INTERVAL waitActive sleep Waiting for datanode to be marked dead getPath client testHostsFile numDatanodes refreshNodes info add DFSConfigKeys hostsFile set getDfsClient datanodeReport LOG invalidhost  Test for a single namenode cluster toUri Number of live nodes should be 0 j assertEquals numNameNodes list getNameNode Thread build numDataNodes  from talking to namenode, resulting in it's shutdown. getNamesystem DatanodeReportType ",hadoop,1
ioSession1 argThat CoreMatchers notNullValue equalTo hasItem connectFuture when impl doAnswer times Assert get verify ofSeconds ArgumentMatchers anyString thenReturn Timeout somehost getArgument testGetSessions completed assertThat eq future3 any execute isDone matches sameInstance invocation future1 getRoutes isOpen future2 answer Mockito callback validateSession connectSession getSession ,httpcore,0
testEmpty ,logback,0
rb1 rb2 Priority.1.CompletedCallVolume DecayRpcSchedulerMetrics2. conf uniqueCaller1 DecayedCallVolume UniqueCallers setupDecayRpcSchedulerandTestServer getLongGauge UniqueCaller: {} CallVolume: {} Priority.0.CompletedCallVolume waitFor info Priority.1.CompletedCallVolume: {} getIntCounter Priority.0.AvgResponseTime rawCallVolume1 LOG GenericTestUtils  Lets Metric system update latest metrics . newSleepRequest proxy DecayedCallVolume: {} stop server .0 ns Priority.1.AvgResponseTime: {} getMetrics getLongCounter beginDecayedCallVolume sleep callVolumePriority1 callVolumePriority0 avgRespTimePriority0 beginUniqueCaller avgRespTimePriority1 addr CommonConfigurationKeys testDecayRpcSchedulerMetrics getClient CallVolume decayedCallVolume1 Priority.0.AvgResponseTime: {} beginRawCallVolume Priority.0.CompletedCallVolume: {} MetricsAsserts getDoubleGauge Priority.1.AvgResponseTime ,hadoop,0
addToken  add token to ugi thenReturn service2 unchecked  from Mockito mocks getCredentials createRemoteUser assertSame when creds getService  check that ugi wasn't modified someone ugi service getToken mock checkTokens testGetCreds t1 t2 UserGroupInformation t3 ,hadoop,0
getVersion testGetStorageClusterVersionXML /version/cluster getBody LOG clusterVersionModel createUnmarshaller success retrieving storage cluster version as XML unmarshal assertTrue response assertNotNull get context client getCode MIMETYPE_XML info ,hadoop,1
wfJobA wfJobB addRecordToWfActionTable getId WorkflowInstance subwfActionB subwfJobB testGetWorkflowParent addRecordToWfJobTable subwfActionA2 children assertNotNull subwfActionA1 get WorkflowJob subwfJobA1 subwfJobA2 execute checkChildren Services 1 WorkflowAction addAll wfActionA jpaService wfActionB ,oozie,1
<workflow-app xmlns='uri:oozie:workflow:0.1' name='test-wf'> lib submit getJobInfo LocalOozie     <end name='end'/> conf wc getStatus fs appPath wf testWorkflowRun </workflow-app> getTestGroup assertNotNull create workflow.xml WorkflowJob write close waitFor app start assertEquals getFileSystem getClient wfApp OozieClient jobId getTestUser stop mkdirs setProperty createConfiguration     <start to='end'/> toString writer File evaluate getFsTestCaseDir ,oozie,1
",, tmparchives  test zero file list length - it should create an exception tmpfile2 tmpfile1 tmpFileOne %s, ,%s  due to URI syntax error argsAndConfNames -libjars conf String URISyntaxException testEmptyFilenames  expect to receive an IllegalArgumentException %s,,%s  working directory being added to ""tmpjars"" (or equivalent) tmpPathOne getFirst arg create tmpjars add argAndConfName  empty string -archives e toURI Expected exception for empty filename format tmpFileTwo tmpPathTwo GenericTestUtils Expected exception for zero file list length testDir args fail Expected exception for filename with space character -files localFs assertExceptionContains toString tmpfiles File name can't be ",hadoop,0
regex validateJSR303WithOptional buildDto context length - too long doCheckValidationFailedLength validationWithOptionalFailedLength ,ninja,0
addRecordToWfActionTable getNumDaysToNotBePurged WorkflowInstance getStatus addRecordToCoordActionTable wfAction5GetCmd wfJob5GetCmd Workflow Job 1 should not have been purged Workflow Action 4 should not have been purged wfAction1GetCmd Coordinator Action 5 should not have been purged coordAction4GetCmd getEndTime coordAction3 coordAction4 assertNotNull coordAction5 CoordinatorAction wfJob2GetCmd coordAction1 coordAction2 Workflow Job 4 should not have been purged wfJob1GetCmd execute Workflow Job 3 should not have been purged Workflow Action 2 should not have been purged CoordinatorJob 1 coordJobGetCmd fail Coordinator Action 3 should not have been purged WorkflowAction coordAction3GetCmd SUCCEEDED wfAction2GetCmd Workflow Action 5 should not have been purged Coordinator Action 4 should not have been purged getId coordAction5GetCmd coordJob wfJob1 wfJob3 wfJob4GetCmd addRecordToWfJobTable wfJob2 wfJob5 get wfJob4 testPurgeCoordWithWFChild2MoreThanLimit coordAction2GetCmd WorkflowJob Workflow Action 3 should not have been purged Coordinator Action 1 should not have been purged wfAction3GetCmd wfAction4GetCmd coordAction1GetCmd assertEquals wfAction1 Coordinator Action 2 should not have been purged wfAction2 addRecordToCoordJobTable wfAction3 Coordinator Job should not have been purged wfAction4 wfAction5 call Services wfJob3GetCmd Workflow Action 1 should not have been purged coord-action-get.xml Workflow Job 5 should not have been purged jpaService Workflow Job 2 should not have been purged ,oozie,1
testCoordReRun2 END_POINTS IS_SECURITY_ENABLED oozieUrl run appPath assertTrue get create SERVLET_CLASSES close runTest app MockCoordinatorEngineService coordinator.xml RestConstants getContextURL assertEquals getFileSystem -rerun args call 1 -date -oozie 2009-12-15T01:00Z::2009-12-16T01:00Z mkdirs job getFsTestCaseDir ,oozie,1
localizedResource localizerEventHandler lr conf createLocalResourceRequest relEvent2 relEvent1  notified with Container Resource Failed Event. relEvent3  Container-3 releasing the resource.  Registering event handlers. Assert  removed after the failed event.  resource  No resource request is initially present in local cache lc2 lc1 dispatcher lc3  exception. test containsKey unchecked localrsrc handle  Container-2 Releases the resource  number of waiting containers should be 1. contains stop size  is coming prior to Container-2's release call.  and the requesting container will be added to its waiting queue. mock cId2 cId3 cId1 localizedPath testLocalResourceCache reqEvent1 createDispatcher reqEvent3 localizedEvent reqEvent2 LocalResourceVisibility  Container 2 requesting the resource times assertTrue isA get tracker verify  Making sure that there is no change in the cache after the release. getRefCount ResourceState resourceFailedEvent  Container 1 requesting local resource. containerEventHandler  send Container Resource Localized Event to waiting containers. newContainerId  Verifying ContainerResourceLocalizedEvent . testuser getMessage assertEquals  Failing resource localization getState /tmp/file1  Container-1 requesting local resource. user BuilderUtils register ,hadoop,1
ss SchedulerService incrementAndGet run counter testInstrumentation Services schedule assertTrue assertNotNull get evaluate waitFor ,oozie,1
@ closeTrx coordClient getStore getTime LocalOozie Could not update db. -testCoordRerun-C getCoordClient rerunScope get beginTrx 1-3 CoordinatorAction reRunCoord actionNum2 commitTrx actionNum1 coord-rerun-action2.xml RestConstants printStackTrace e testCoordRerunActionsNeg1 store actionId2 addRecordToJobTable jobId actionId1 Services fail CoordinatorJob addRecordToActionTable 0000000- Exception expected because one action is missing from db. coord-rerun-action1.xml ,oozie,1
fruitContext print simpleConfigurator StatusPrinter IMPLCIT_DIR verifyFruit doConfigure nestedComplexWithoutClassAtrribute.xml je nestedComplexWithoutClassAtrribute ,logback,0
END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL oozieUrl getJobId MockDagEngineService assertEquals id-valid wc external-valid call assertNull testExternalId external-invalid SERVLET_CLASSES runTest ,oozie,1
parent  default works for cat  cp is working  runCmd default works for ls  run bak  check cp :reptiles  check put du works on remote uri  path ToolRunner -chown -cat test.build.data /tmp srcConf nameDir ret hdfs:///furi /tmp/chownTest createLocalFile dstConf getFileSystem / /furi shell  put is working  herbivores numDataNodes setProperty mkdirs /hadoopdir -chgrp shutdown getUri dfs_tmp_uri/  check chown  check for rm -r dstFs -R  check for ls  check cat reptiles default works for rm/rmr srcCluster argv delete System file -put assertTrue TEST_ROOT_DIR root srcFs -cp /*  check if default hdfs:/// works -rmr writeFile dstCluster  check du getProperty -rmr works on remote uri  ls works on remote uri  assertEquals setConf confirmOwner  cat is working  -ls build furi testURIPaths exists hdfs:/// toString TestDFSShell -du ,hadoop,1
headers custom converter Multiple ':method' request headers are illegal thrown convert www.example.com asList expectMessage / expect :method :scheme GET testConvertFromFieldsMultipleMethod http :path Arrays value :authority ,httpcore,0
init getProperty getConf oozie-site2.xml prepareOozieConfDir oozie- cl user.name destroy assertEquals System testMissingSite assertNull oozie-site-missing.xml oozie.system.id oozie.dummy setSystemProperty get ConfigurationService ,oozie,1
testMockDomainNameResolverCanBeCreated resolver CommonConfigurationKeys addrs DomainNameResolverFactory conf newInstance assertEquals getHostAddress MockDomainNameResolver getAllByDomainName ,hadoop,0
" Assert deleted.  they were deleted. START_KEY getStore ttlInSeconds HConstants createSmallerStoreFile getBytes Bytes scanner STARTROW deleteFamily  assertEquals(cellValues.length, 3); secondRowBytes createStoreFile START_KEY_BYTES containsStartRow count COMPACTION_THRESHOLD getFileSystem getRow  deleted row.  Cell.createSingleCellArray(r.get(STARTROW, COLUMN_FAMILY_TEXT, -1, 100 /*Too many*/)); size addFamily  Do a simple TTL test. getStorefiles  Assert that the second row is still deleted. next  check Compaction Dir for this Regions is cleaned up  Add a bit of data and flush.  Start adding at 'bbb'. assertFalse values  Assert that I can get 3 versions since it is the max I should get delete System result sleep setMaxVersions assertTrue  Always 3 versions if that is what max versions is. get  FIX COLUMN_FAMILY_TEXT row COLUMN_FAMILY getReader famAndQf f  Increment the least significant character so we get to next row. isEmpty assertEquals store addContent  check compaction dir is exists  Force major compaction. flushcache seekTo Thread r  Assert == 3 when we ask for versions. compactStores currentTimeMillis equals exists getKeyValue toString testCompaction  file. getScanner ",hadoop,1
testConcurrencyLimit queueSize XTestCase CLCallable Concurrency : originalRatio queueservice System getConcurrency Services assertTrue get resetConcurrency Callable Queue Size : evaluate waitFor CLCallable queue ,oozie,1
job1 getTime pauseStartRunnable addRecordToBundleJobTable run getId assertEquals getStatus execute Services jobId testStart1 assertNotNull get setKickoffTime Job job jpaService evaluate waitFor ,oozie,1
"cluster NameNodeAdapter ns racks conf /rack2 waitForReplication /rack1 fs     * Like the previous test but the block starts with a single replica,    * and therefore unlike the previous test the block does not start    * off needing replicas.     createFile  Create a file with one block with a replication factor of 1 DFSTestUtil testSufficientlySingleReplBlockUsesNewRack b getConf filePath getFileSystem setReplication REPLICATION_FACTOR getNameNode /testFile build numDataNodes getFirstBlock shutdown getNamesystem ",hadoop,1
"hdfs://p1/p2/2009/08/09/23/59/ CoordELFunctions assertEquals hdfs://p1/p2/${YEAR}/${MONTH}/${DAY}/${MINUTE}/ hdfs://p1/p2/2009/08/09/59/  System.out.println(""OUTPUT ""+ eval.evaluate(expr, String.class)); eval hdfs://p1/p2/${YEAR}/${MONTH}/${DAY}/${HOUR}/${MINUTE}/ evalAndWrap 2009-08-09T23:59Z expr testCreateURIELEvaluator createURIELEvaluator CoordELEvaluator ",oozie,1
rr next TABLE_NAME  are running. There are 5 cases we have to test. Each is described below. scan HConstants conf System result cellCount assertTrue testScanMultipleVersions get TIMESTAMPS  Should get 2 rows. close setTimeRange  (in this case == 1000. Should get 2 rows. count  (in this case > 1000 and < LATEST_TIMESTAMP. Should get 2 rows. j Number of rows should be 2 assertEquals kv  second timestamp (100 < timestamp < 1000). Should get 2 rows. sorted setTimeStamp t addFamily Long unused toString getScanner ROWS  Case 1: scan with LATEST_TIMESTAMP. Should get two rows ,hadoop,1
testIsBefore fromUnixMilliseconds Assert assertTrue currentTimeMillis Deadline nowPlusOneMin deadline System isBefore ,httpcore,0
 ///////////////////////////////////////////////////////////////////// Retrieving articles for a user (Json) replace contentcontent GET_ARTICLES_URL POST_ARTICLE_URL testGetAndPostArticleViaJson We are now getting 4 articles.  one new result: bob@gmail.com new title new title apiResponse makeGetRequest {username} articleDto Now we are authenticated and expect the post to succeed... We get back all 3 articles of that user Posting a new article is a post request to  doLogin If we now fetch the articles again we are getting a new article (the one we have posted successfully buildUri Retrieving all articles of a user is a GET request to  say USER makePostRequest sayNextSection getGsonWithLongToDateParsing assertEqualsAndSay articlesDto Posting new article (Json) Please note that you have to be authenticated in order to be allowed to post. size fromJson You have to be authenticated in order to post articles After successful login we are able to post articles ,ninja,1
testParser wf-loop1-invalid.xml wf-transition-invalid.xml wf-schema-valid.xml wf-loop2-invalid.xml validateAndParse assertEquals fail IOUtils ex wf-unsupported-action.xml parser getErrorCode getResourceAsReader ErrorCode ,oozie,1
cluster other  unmanaged AMs do return AMRM token foo run Assert createYarnClient assertNotNull appId UserGroupInformation createUserForTesting init  managed AMs don't return AMRM token rmClient testAMMRTokens start yarnConf  other users don't get AMRM token createApp testMRAMTokens getConfig YarnClient getAMRMToken waitTillAccepted doAs assertNull stop ,hadoop,1
conn Server inStream getEndpointDetails getContent HTTP/1.1 200 OK Server: test Content-Length: 3  123 when getBytes content bind Assert assertTrue assertNotNull getResponseCount getCode StandardCharsets thenReturn assertEquals getEntity getContentLength getInputStream testReadResponseEntityWithContentLength Mockito response socket containsHeader receiveResponseHeader entity receiveResponseEntity ,httpcore,0
"APP fw1 [org.apache.oozie.core.command.WorkflowRunnerCallable]    f1 streamLog _L23_  Check if the lines of the log contain the expected strings  2012-04-24 22:43:13,961 INFO _L23_:317 - split _L19_ getTestCaseDir  2012-04-24 22:43:13,958 DEBUG _L22_:323 - str2 JOB TOKEN write  from oozie.log setLogLevel _L20_ /  between the start and end times of the job contains reset  pattern and parameters like JobId, Username etc. and/or based on log level like INFO, DEBUG, etc. outFilename  Test for the log retrieval of the job spanning multiple hours oozie.log-2012-04-24-21.gz sb1 writeToGZFile DEBUG|INFO calendarEntry getTime released lock testStreamLogMultipleHours oozie.log-2012-04-24-19.gz _L21_ System sw2  Setting start-time to 2012-04-24-19 for log stream (month-1 passed as parameter since 0=January), and end time is current time out GROUP  Test to check if all gz log files in the range jobStartTime-currentTime are retrieved 14-200904160239--example-forkjoinwf oozie.log defineParameter setParameter logStatement currTime close set oozie.log-2012-04-24-20.gz f  2012-04-24 21:43:13,958 DEBUG _L21_:323 - Calendar /oozie.log XLogStreamer assertEquals USER _L22_ logLines  2012-04-24 19:43:13,958 DEBUG _L19_:323 - xf ACTION  2012-04-24 20:43:13,958 DEBUG _L20_:323 - currentTimeMillis toString getInstance append setLastModified ",oozie,1
bulkInsertCmd createWorkflow addNode auth getAppPath PREP conf getId testToken WorkflowInstance actionGetCmd setInsertList assertNotNull get testApp <workflow-app/> end workflow.xml WorkflowJob app add getStatusStr set  check for expected status after running bulkUpdateJPA insertList wfGetCmd testInserts assertEquals execute appUri OozieClient 1 Services 2 getTestUser WorkflowAction toString createWorkflowAction action1  insert one workflow job and two actions job action2 jpaService ,oozie,1
byteAt assertFalse length isEmpty clear assertEquals capacity b1 b2 Assert assertTrue assertNotNull tmp toByteArray buffer isFull testSimpleAppend append ,httpcore,0
verifyPaths testPartialAuthority myfs://host.a fs ips authorities myfs://host.a.b:123 getVerifiedFS ,hadoop,0
 addNode def testInvalidExecutionPath one start assertEquals WorkflowInstance getStatus asList wf 1 <worklfow-app/> end Arrays job /a/ signal ,oozie,1
duNotADirectoryExpected du4 du3 canRead assertFalse  some target files and containing directory are not accessible: partitioned part-r-00000 System  should never happen since that method never throws InterruptedException. du Assert notADirectory duDoesNotExist tmp doesNotExist 0000 chmod ie QuickBrownFoxJumpsOverTheLazyDog TEST_DIR  is accessible: getProperty  line separator. getAbsolutePath expected length  target file is not a directory: assertEquals  target file does not exist: 0777 line.separator assertNull setupDirs testGetDU getDU FileUtil duNotADirectoryActual  in @After method: ,hadoop,0
initialCallable callables       * Testing an interrupt commands inside a composite callable Assuring it is      * executed before the others       type queueSerial queueservice initialKey assertTrue get initialType lockKey waitFor key EXEC_ORDER add init c initialLockKey retValue CallableQueueService destroy Services 1 testKill setSystemProperty evaluate testInterruptsInCompositeCallable queue ,oozie,1
jobConf lib /libx/maputilx.jar reader authToken /libx /lib/reduceutil.so createProtoActionConf found protoConf getTestCaseDir /workflow.xml get file:// createTestCaseSubDir bla bla Collections write close /lib/maputil.jar testCreateprotoConfWithLibPath add init libx set wf-schema-valid.xml WorkflowAppService expected destroy assertEquals services sort getStrings Services OozieClient IOUtils getTestUser copyCharStream getResourceAsReader writer wps ,oozie,1
"XmlUtils <bundle-app name='NAME' xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance' xmlns='uri:oozie:bundle:0.1'>  <coordinator name='c12'>  e <configuration>  validator <property> <name>START_TIME</name> <value>2009-02-01T00:00Z</value> </property> </configuration>  parseXml newValidator <controls> <kick-off-time>2009-02-02T00:00Z</kick-off-time> </controls>  getSchema BUNDLE_APP Services <app-path>hdfs://localhost:9001/tmp/bundle-apps/coordinator1.xml</app-path> </coordinator></bundle-app> testBundleSchema wss get SchemaName validate  System.out.println(""XML :""+ XmlUtils.prettyPrint(e)); ",oozie,1
assertFalse topic.topic1 sleep isTopicInRetryList isConnectionInRetryList HCatAccessorService  Should not retry again as max attempt is 1 assertTrue publisherAuthority get servicesConf registerForNotification java.naming.factory.initial# jndiPropertiesString init set getJMSConnectionInfo getConf hcatService hcat.server.com:5080 destroy jmsService getNumConnectionAttempts assertEquals services hcat://hcat.server.com:8020 JMSAccessorService ActiveMQConnFactory Thread 1 Services java.naming.provider.url# connInfo setupServicesForHCatalog isListeningToTopic topic retryConnection default= testConnectionRetryMaxAttempt ; tcp://localhost:12345;connectionFactoryNames#ConnectionFactory ,oozie,1
" this will force the creation of concurrent activations in each node 1000 awaitFor createStage statelessTest allMatch actor5 bind assertTrue  it is very likely that there will be more than one activation per stage host. of  each node will have at most one activation of the stateless worker get client TimeUnit Stream  only 25*5 calls => there should not be more than 125 activations join getReference createClient add  We are using "" awaitFor(stagesIdle)"" to ensure no stages are processing any messages.  but was:  set getUniqueActivationId e f forEach clear assertEquals futures stagesIdle actor4 Expecting >4 but was:  Expecting <= actor3 actor2 actor1 size stage3 IActor stage2 isIdle stage4 stage1 ",orbit,1
regions valueOf findMemstoresWithEditsOlderThan count assertEquals l regionsToSeqids getBytes put 0 Bytes 1 2 assertTrue equals Long  Regions returned are not ordered. toString testFindMemstoresWithEditsOlderThan HLog ,hadoop,1
ce foo assertEquals testParseFilterPositive parseFilter frequency unit 300 size FAILED get MINUTE map user frequency=5;unit=hours;user=foo;status=FAILED status ,oozie,1
lib reader /libx /liby /libz /lib/reduceutil.so protoConf getTestCaseDir /workflow.xml file:// createTestCaseSubDir /libx/maputil_x.jar Collections write add init libx liby libz expected destroy sort OozieClient copyCharStream getResourceAsReader /libz/maputil_z.jar wps jobConf authToken testCreateprotoConfWithMulipleLibPath /liby/maputil_y2.jar createProtoActionConf found setStrings get bla bla close /lib/maputil.jar /liby/maputil_y1.jar set wf-schema-valid.xml WorkflowAppService assertEquals services getStrings Services IOUtils getTestUser writer ,oozie,1
cluster FILE_SIZE conf dir /test createFile waitActive webhdfsuri= checkContentSummary /test/test2 /test/test1 exceededQuota :// WebHdfsFileSystem DFSConfigKeys getFileSystem setInt nnAddr numDataNodes mkdirs -setSpaceQuota  total space usage including shutdown Quota is half consumed QUOTA_SIZE testBlockAllocationAdjustsUsageConservatively BLOCK_SIZE admin fs waitReplication System assertTrue get runCommand getSpaceConsumed  used half the quota for the first file. DFSTestUtil c getContentSummary webhdfs assertEquals  Creating a file should use half the quota Quota not exceeded  repl. Integer  Create the directory and set the quota build file2 webhdfsuri toString file1 setBoolean ,hadoop,1
checkCoordActions getTime DateUtils parseDateOozieTZ 2009-03-06T10:00Z addRecordToJobTable call jobId pauseTime -testActionMater-C 0000000- startTime endTime 2009-03-06T10:04Z testActionMaterWithPauseTime1 2009-03-06T10:14Z ,oozie,1
"FILE_SIZE cluster dnR dn rand getAllBlocks DN_N0 blockReport Block  th block is incorrect getDataNodes getBlockPoolId getMethodName blocksAfterReport LOG getBlockListAsLongs GenericTestUtils / prepareForRide getGenerationStamp size oldLengths poolId  before	 isDebugEnabled Number of blocks allocated  .dat tempLen BLOCK_SIZE fs getNumBytes getBlockId get Size  DFSTestUtil b getBlock debug set Length of   all blocks belong to the same file, hence same BP blockReport_01 blocks filePath getBlockName assertEquals nextInt getNameNodeRpc Setting new length  after	  After mods: Number of blocks allocated  METHOD_NAME open getNamesystem getDNRegistrationForBP ",hadoop,1
aa A a XLog createPrefix A[a] start assertEquals run A[-] t testInfoThreadLocal get defineParameter setParameter join ,oozie,1
initialCallable callables testInterruptsWithDistinguishedLockKeys type keyInt queueservice initialKey assertTrue get initialType       * Introducing an interrupt with different keys and assure it will be      * executed in order regardless of the existence of an interrupt command in      * the mix.       lockKey waitFor key EXEC_ORDER add init c initialLockKey retValue CallableQueueService destroy Services 1 testKill intCallable setSystemProperty evaluate queue ,oozie,1
"coord-multiple-input-start-instance1.xml reader testBasicSubmitWithMultipleStartInstancesInputEvent conf getStatus coord-multiple-input-start-instance2.xml appPath getJob sc getErrorCode assertTrue file:// getTestCaseDir UNIT_TESTING  CASE 1: Failure case i.e. multiple data-in start-instances getPath Job coordinator.xml set e getMessage assertEquals Coordinator app definition should not have multiple start-instances call OozieClient fail IOUtils contains getTestUser Expected to catch errors due to incorrectly specified input data set start-instances copyCharStream Unexpected failure:  getResourceAsReader writer ErrorCode File  CASE 2: Success case i.e. Single start instances for input and single start instance for output, but both with "","" ",oozie,1
assertFalse getCurrentDateafterIncrementingInMonths getId run DateUtils getStatus isPending addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob assertNotNull get CoordinatorAction end  Keeping wait time to 20s to ensure status is updated currentDatePlusMonth waitFor start assertEquals XDataTestCase execute addRecordToCoordJobTable CoordinatorJob jobId Services runnable coord-action-get.xml testCoordStatusTransitServiceSuspendedBottomUp job jpaService evaluate ,oozie,1
" server getName getHdfsConf H06.* conf dir asList TestDirHelper createHadoopConf server.services StringUtils get join getFileSystemConfiguration fsAccess fileSystemExecutorNoNameNode init hdfsConf set getAbsolutePath TestHdfsHelper getTestDir hadoopConf services , execute CommonConfigurationKeysPublic u Arrays ",hadoop,1
aaa  findMinMaxLengthsInSymbols assertEquals results emptyStringValuesShouldBeIgnoredByFindMinMaxLengthsInSymbols symbols CharSequenceToRegexMapper ,logback,0
key1 p1 p2 doNothing Should not throw Exception since p2 doesn't throw Exception getKMSUrl kp anyString thenReturn keyName conf testWarmUpEncryptedKeysWhenOneProviderSucceeds when warmUpEncryptedKeys fail doThrow times Mockito mock verify ,hadoop,0
setMax 45 witness setMin fi valueOf assertEquals 4.5 testBasic FormatInfo ,logback,0
 Should see all keys in all group two rows  Match group one rows testValueTwo Bytes FAMILIES  Expect half the rows VALUES  Match all values using regex expectedKeys verifyScanNoEarlyOut testValueOne  Expect all rows expectedRows f ROWS_TWO toBytes kvs testValue((One)|(Two))  Expect group one rows testValueFilter setFilter QUALIFIERS_TWO verifyScanFull  Expect half rows CompareOp  testRowTwo-3  Match group two rows  testRowTwo-2 ,hadoop,1
checkSubworkflowLibHelper childLibs1 expectedLibs1 expectedLibs2 testCreateProtoConfWithSubWorkflowLib1 expectedLibs3 expectedLibs4 expectedLibs5 same.jar childLibs3 parent2.jar childLibs2 childLibs5 child1.jar childLibs4 inheritWF parentLibs2 parentLibs3 parentLibs1 parent1.jar parentLibs4 parentLibs5 inherit child2.so true ,oozie,1
"APP _L3A_Applications  [org.apache.oozie.core.command.WorkflowRunnerCallable]     respectively _L11_ ferr  Check if the lines of the log contain the expected strings _L4_ str1  2009-06-24 02:43:13,958 DEBUG _L10_:323 -  2009-06-24 02:43:13,958 DEBUG _L12_:323 - TOKEN write fwerr  2009-06-24 02:43:13,961 INFO _L9_:317 - See JobConf(Class) or JobConf#setJar(String). testStreamLog  filename date below is equivalent to floor(6 hours ago)  2009-06-24 02:43:13,986 WARN _L3_:539 - / str Use GenericOptionsParser for parsing  contains sberr reset writeToGZFile DEBUG|INFO released lock may not be found.  sw1 End workflow state change sb out GROUP oozie.log  2009-06-24 02:43:14,505 INFO _L5_:317 - USER[oozie] GROUP[oozie] TOKEN[-] APP[-] JOB[-]  defineParameter setParameter logStatement currTime close /testerr.log sw f /oozie.log Number of pending actions [0]   2009-06-24 02:43:13,958 DEBUG _L8_:323 - assertEquals command.WorkflowRunnerCallable]  _L10_  2009-06-24 02:43:13,961 INFO _L2_:317 - 2009-06-24 02:43:13,958 WARN _L1_:323 -  ""oozie.log"" currentTimeMillis oozie.log- toString fw2 _L10 fw1 fw3 f1 streamLog f2 f3  8 hours ago  2009-06-24 02:43:19,344 DEBUG _L6_:323 - USER[oozie] GROUP[oozie] TOKEN[MYtoken] APP[-] JOB[-]  split getTestCaseDir _L8_  2009-06-24 02:43:13,961 INFO _L13_:317 - oozie.log.gz JOB 2009-06-24 02:43:13,958 DEBUG _L1_:323 -  2009-06-24 02:43:13,961 INFO _L11_:317 -  and corresponding log content is retrieved properly should implement Tool for the same.  _L3B_Multi line test ACTION[-] Released Lock .gz setLogLevel [org.apache.oozie.core. format ACTION[-] Number of pending signals to check [0] oozie.log-2011-12-03-15.bz2.gz  between the start and end times of the job _L7_  excluded from log retrieval  pattern and parameters like JobId, Username etc. and/or based on log level like INFO, DEBUG, etc. outFilename sb2 sb1 No job jar file set. User classes  sb3 System /oozie.log.2 /oozie.log.1 14-200904160239--example-forkjoinwf  9 hours ago _L2_  2009-06-24 02:43:29,151 DEBUG _L7_:323 - filenameDateFormatter  Generate and write log content to the GZip file XLogStreamer  2009-06-24 02:43:14,431 INFO _L4_:661 - USER xf ACTION  oozie.log.gz GZip file would always be included in list of files for log retrieval _L1_ the  arguments.  append setLastModified _L9_ ",oozie,1
init getTopicPatternProperties printStackTrace e getMessage destroy jmsTopicService ${username} assertEquals services setupServicesForTopic props fail Services testTopicProperties1 get AppType ,oozie,1
 we still can scan records in an unsorted TFile reader conf vbuf getKeyLength  now try get value first fs advance path testScanRange getLen getFileStatus scanner valueM kbuf getKey getValueLength vlen keyZ isFalse assertThat createScanner valueZ entry getValue klen BUF_SIZE isSorted getEntryCount keyM isEqualTo open  read key and value ,hadoop,0
"getCurrentUser fourth attempt(after timeout), should be different: Should be different group  assertFalse admin run second attempt, should be same: System sleep str_groups Groups getUserToGroupsMappingService get toArray getUserName Should be same group  getGroups UserGroupInformation first attempt: testGroupMappingRefresh groups g1 assertEquals groupRefreshTimeoutSec g2 g3 g4 Should be different group:  Thread args -refreshUserToGroupsMappings size third attempt(after refresh command), should be different: equals  and  toString Arrays config user  test time out ",hadoop,1
getComponentCount size now tracker assertEquals removeStaleComponents empty0 liveKeysAsOrderedList ,logback,0
setName testWaitFor A getName start assertEquals waited testcase tearDown System TESTING currentTimeMillis setUp end testWaitForTimeOut evaluate waitFor ,oozie,1
SELECT * FROM entitywithstaticcolumn WHERE id =  session  Given insert UUIDs uuid crud  When id value static_col val isNotNull static_val actual RandomUtils manager one timeBased getString nextLong assertThat execute  AND uuid =  should_insert  Then Long isEqualTo entity ,achilles,1
" other-user4 conf user5/cron@OTHER.REALM user7@example.com@DEFAULT.REALM HADOOP_SECURITY_AUTH_TO_LOCAL testConstructorSuccess  failure test mit hadoop  security off, but use rules if explicitly set user6@example.com@OTHER.REALM setConfiguration user3/cron@DEFAULT.REALM  with MIT  failures testConstructorWithRules UserGroupInformation user1 RULE:[1:$1@$0](.*@OTHER.REALM)s/(.*)@.*/other-$1/ set user2@DEFAULT.REALM testConstructorFailures HADOOP_SECURITY_AUTH_TO_LOCAL_MECHANISM user4@OTHER.REALM ",hadoop,0
1 testLimitedIO doTestLimitedIO foo bar baz abcd ,hadoop,0
 PATH request adapter responseExpectations execute put ECHO_PATH fail requestHandler Assert Mockito defaultURI mock noMethod WebServerTestingFrameworkException should have been thrown ,httpcore,0
testTooLongChunkHeader dst CodecTestUtils convert metrics2 metrics1 Assert assertTrue MessageConstraintException expected isCompleted read StandardCharsets hasRemaining 5; and some very looooong comment 12345 0  decoder1 clear channel1 inbuf1 assertEquals channel2 decoder2 ByteBuffer inbuf2 fail allocate 12345 ,httpcore,0
createActionDefaultConf action.foo actionx foo * jt assertEquals services createJobConf jtx Services bar assertNull action.bar assertNotNull get action has testService ,oozie,1
play windowUpdateStreamIds data readSendsWindowUpdate headerEntries Math  Send frames summing to windowUpdateThreshold. TYPE_HEADERS variant connection buffer  connection WINDOW UPDATE banana add read  connection in count maxFrameSize sent  stream WINDOW UPDATE contains  SYN_STREAM size getSource synStream  stream newStream android TYPE_WINDOW_UPDATE acceptFrame min stream assertTrue peer DEFAULT_INITIAL_WINDOW_SIZE getResponseHeaders takeFrame windowUpdateThreshold a windowUpdate b synReply setVariantAndClient assertEquals j sendFrame SPDY3  Play it back. ,okhttp,1
 rollover every 15 sec init getAllSecrets rolloverFrequency getCurrentSecret destroy assertEquals secret2 secret3 getBytes secret1 assertArrayEquals Thread doctor sleep testGetAndRollSecrets Assert assertNull currentSecret tardis secretProvider allSecrets who ,hadoop,0
queue size should enqueue e dequeue back queue front assertEquals consume q enqueue size assertTrue testCommon front queue back element ,hadoop,0
ContentType listener CoreMatchers SSL_RSA_EXPORT_WITH_RC2_CBC_40_MD5 cipherSuite setExceptionCallback getCause AsyncServerBootstrap listen instanceOf IOReactorConfig weakCiphersSuites Assert SSL_DH_anon_EXPORT_WITH_RC4_40_MD5 getDuration create https /stuff setLookupRegistry TLS_DH_anon_WITH_AES_128_CBC_SHA requester localhost setStreamListener LoggingExceptionCallback LoggingHttp1StreamListener setIOSessionListener setEnabledCipherSuites resultFuture1 setSoTimeout * Method assertThat execute testWeakCiphersDisabledByDefault LoggingConnPoolListener TLS_ECDHE_ECDSA_WITH_RC4_128_SHA fail ex SecureAllPortsStrategy CloseMode TIMEOUT TLS_RSA_WITH_NULL_SHA256 server SSL_RSA_WITH_3DES_EDE_CBC_SHA TLS_KRB5_EXPORT_WITH_RC4_40_SHA createClientSSLContext setIOReactorConfig cause SSL_RSA_EXPORT_WITH_DES40_CBC_SHA H2RequesterBootstrap bootstrap setConnPoolListener setTlsStrategy TLS_ECDH_anon_WITH_AES_256_CBC_SHA some stuff setIOSessionDecorator SSL_RSA_EXPORT_WITH_RC4_40_MD5 createServerSSLContext get ExecutionException expected getAddress SSL_RSA_WITH_RC4_128_SHA TLS_ECDH_ECDSA_WITH_3DES_EDE_CBC_SHA close SSLTestContexts address SSL_RSA_WITH_NULL_SHA custom start sslEngine target getTimeUnit LoggingIOSessionDecorator getPort build future LoggingIOSessionListener initialize TLS_DH_anon_WITH_AES_256_GCM_SHA384 register ,httpcore,0
add Status smoke getMessage assertEquals getCopyOfStatusList getLevel statusList size assertNotNull get bsm ,logback,0
"getSubject getName getPrivateCredentials evaluateChallenge subject run keytabFile  found  should fail as we send a service ticket instead of tgt to KDC. createSaslClient ugi clientPrincipal host The first ticket is not tgt UserGroupInformation No service ticket for  getServer add test krbtgt fixKerberosTicketOrder props loginUserFromKeytabAndReturnUGI doAs intercept dispose  make sure we can still get new service ticket after the fix. server1Protocol assertFalse getMechanismName isPresent findFirst remove  check if TGT is the first ticket after the fix. stream assertTrue findAny get client  make sure the first ticket is not tgt map Sasl getCanonicalPath c ticket AuthMethod filter  move tgt to the last t The first ticket is still tgt,  the implementation in jdk may have been changed,  server2Protocol please reconsider the problem in HADOOP-13433 startsWith ",hadoop,0
renderable assetsControllerHelper assetsController when resultCaptor mimeTypes getRenderable responseStreams verify ok render result2 serveStatic finalizeHeadersWithoutFlashAndSessionCookie byteArrayOutputStream thenReturn capture testStaticDirectoryClassPathWhenFileNotInFileSystemInDevMode assertEquals normalizePathWithoutLeadingSlash contextRenderable any /assets/testasset.txt httpCacheToolkit getValue getStatusCode Mockito Results isDev mock getOutputStream ninjaProperties  some more setup needed: getRequestPath ,ninja,0
" in the message intercept hello, world testInterceptInterceptStringResultLambda ",hadoop,0
addRecordToWfActionTable getId WorkflowInstance getStatus  update the list for doing bulk writes coordJob wfJob addRecordToWfJobTable assertNotNull get action WorkflowJob updateList add getStatusStr  update the status  check for expected status after running bulkUpdateJPA RUNNING assertEquals execute addRecordToCoordJobTable setStatus CoordinatorJob 1 Services setUpdateList WorkflowAction bulkUpdateCmd SUCCEEDED testUpdates action2 jpaService ,oozie,1
 prefix foo 	   conf appendProperty out CONFIG addResource get postfix   .value endConfig startConfig j assertEquals nextInt n testTrim name RAN append whitespaces ,hadoop,0
inheritWF false parentLibs2 parentLibs3 checkSubworkflowLibHelper parentLibs1 parentLibs4 parentLibs5 childLibs1 expectedLibs1 expectedLibs2 expectedLibs3 expectedLibs4 inherit child2.so expectedLibs5 true testCreateProtoConfWithSubWorkflowLib5 same.jar childLibs3 childLibs2 childLibs5 child1.jar childLibs4 ,oozie,1
"ensureTimeToPoll testWatchForMultipleEventTypes resolve ImmutableList foo ENTRY_CREATE fs delete createFile path bar foo/bar of getPath createDirectory baz Files createDirectories watcher ENTRY_MODIFY  watcher polls, seeing modification, then polls again, seeing delete  this could be flaky; may need to increase time between polling if so (or just not test it) ENTRY_DELETE register assertWatcherHasEvents ",jimfs,1
deleteList Coordinator Action B1 should have been deleted Coordinator Action C2 should have been deleted Coordinator Job C should have been deleted testDeleteCoords getId actionC1 addRecordToCoordActionTable actionC2 actionA1 actionA2 Coordinator Job B should have been deleted jobB jobA getErrorCode Coordinator Job A should have been deleted assertNotNull jobC get CoordinatorAction Coordinator Action C1 should have been deleted add Coordinator Action A2 should have been deleted assertEquals actionB1 execute addRecordToCoordJobTable actionB2 CoordinatorJob Services fail coord-action-get.xml Coordinator Action A1 should have been deleted Coordinator Action B2 should have been deleted ErrorCode je jpaService ,oozie,1
st rte ctx ms waitFor did not throw getMessage Time assertEquals getCause et fail my ioe addThread  expected assertTrue doWork now  the thread throws faster than that testThreadThrowsCheckedException startThreads waitFor Test took  ,hadoop,0
 obtain the service ProxyFeatures I'm SomeServiceActive assertEquals someService  disable the feature flag FeatureContext getSpringBean assertNotNull getFeatureManager whoAreYou someServiceAutoDetectProxyType setFeatureState I'm SomeServiceInactive  first the inactive Service is invoked  calls are now delegated to the other service implementation  enable the feature flag testProxyWithAutoDetectedProxyType ,togglz,1
start.error assertTrue based_on_action_status testStartErrorWithUserRetry error _testErrorWithUserRetry ,oozie,1
actionNum testCoordActionGet getActionNominalTime actionNomialTime getId _testGetActionForNominalTime DateUtils addRecordToCoordActionTable appPath addRecordToCoordJobTable parseDateOozieTZ actionXml CoordinatorJob coord coord-action-get.xml CoordinatorAction action job getCoordActionXml getFsTestCaseDir ,oozie,1
MEMORY:foo NAME1:Sean TEL1:+12125551212  testAddressBookAU doTest foo Sean +12125551212 ,zxing,0
 oozie.launcher.action.main.class set setupMainClass conf assertEquals testSetupMainClass assertNull LauncherMapper  the passed argument (myclass1) should have priority get org.blah.myclass2 org.blah.myclass1 ,oozie,1
setName 23 24 testHoursInDay 25 2010-10-01T00:00Z CoordELFunctions UTC getTimeZone 2009-09-10T23:59Z coord-action-create DateUtils test1 ${coord:hoursInDay(coord:hoursInDay(1))} setFrequency parseDateOozieTZ ds evalAndWrap ${coord:hoursInDay(1)} configureEvaluator ${coord:hoursInDay(0)} setTimeZone Europe/London TimeUnit expr setEndOfDuration init res setNominalTime 2009-11-01T08:00Z ${coord:hoursInDay(-2)} 2009-03-08T08:00Z ${coord:hoursInDay(-1)} setInitInstance assertEquals setType setActualTime appInst 2009-01-01T08:00Z America/Los_Angeles setTimeUnit eval 2009-01-02T00:00Z SYNC ,oozie,1
shutdownDfs ab bbc testFilters getLog prefix toBytes scan HConstants newFilter addContent closeAndDelete createNewHRegion setFilter Bytes rowPrefixFilter rowInclusiveStopFilter getTableDesc stopRow REGION_INFO close ,hadoop,1
"cache generateFixedBlocks blocks  room for 9, will evict getEvictionCount maxSize assertEquals blockSize n System Thread sleep  A single eviction run should have occurred testBackgroundEvictionThread  Let the eviction run cacheBlock Background Evictions run:  calculateBlockSizeDefault assertTrue  Add all the blocks block ",hadoop,1
"<execution>LIFO</execution> </controls> <datasets>  testDoneFlag conf <data-in name=""A"" dataset=""local_a""> <instance>${coord:current(0)}</instance> </data-in>   /workflows/2009/01/_SUCCESS </input-events>  getStatus actionStatus file:// getTestCaseDir UNIT_TESTING CoordinatorAction action missingDeps waitFor <coordinator-app name=""NAME"" frequency=""${coord:days(1)}"" start=""2009-02-01T01:00Z"" end=""2009-02-01T02:00Z"" timezone=""UTC""  <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  <action> <workflow> <app-path>hdfs:///tmp/workflows2/</app-path>  /workflows/${YEAR}/${DAY}</uri-template>  OozieClient jobId size </datasets> <input-events>  File actions evaluate submitJob getMissingDependencies getActions appPath </dataset> System writeToFile appXml <dataset name=""local_a"" frequency=""${coord:days(1)}"" initial-instance=""2009-02-01T01:00Z""  assertTrue get xmlns=""uri:oozie:coordinator:0.1""> <controls> <timeout>10</timeout> <concurrency>2</concurrency>  timezone=""UTC""> <uri-template>file:// getCoordJob Missing deps= coordinator.xml ce set  done flag is not added to the missing dependency list assertEquals </configuration> </workflow> </action> </coordinator-app> getTestUser ",oozie,1
"p0 p1 testInsertionWithFailover ns checkOverflowException ns.  standby exception for client to try another server. conf  add to first queue.  3 queues, 2 slots each. fcq RpcStatusProto  add to first and second full queue spills over to third. addToQueueAndVerify add a b CommonConfigurationKeys unchecked didn't fail mockCall  add to first full queue spills over to second. fail  regular RetriableException if call queue is full. Mockito reset ise  add to second queue. spy  add to second full queue spills over to third. setBoolean ",hadoop,0
date rs Set session  Given update withLwtResultListener should_dsl_update_value_if_exists error Eq  When get where id getAndSet row value onError RandomUtils manager withResultSetAsyncListener one isFalse nextLong assertThat execute isTrue  Then isNull Long ifExists buildDateKey new value fromBaseTable dsl wasApplied SELECT simplemap FROM simple WHERE id =  onSuccess ,achilles,1
getWorkingDirectory assertFalse assertEquals fs blockSize  test getFileStatus on a file getReplication getBlockSize fileSize getLen makeQualified getFileStatus getPath  should be a file toString testGetFileStatusOnFile file1 isDirectory getUri checkFile status ,hadoop,1
p1 p2 p3 p4 getKMSUrl Provider p4 should have answered the request. conf when testClientRetriesWithTimeoutsException times verify thenThrow kp anyString thenReturn createKey eq any setInt CommonConfigurationKeysPublic fail test3 Mockito mock v1 ,hadoop,0
"next headers token2, token5 ,  assertFalse hasNext assertEquals Name token3 , hit Assert ti assertTrue token0 token1  token1 token2 token3 testValueEnd token4,  token4 token5 ",httpcore,0
fakeDnId getDefaultSocketFactory conf blockKeyUpdateInterval ClientDatanodeProtocol getReplicaVisibleLength Num open fds: setBlockToken fdsAtEnd  fds! UserGroupInformation info 1.1.1.1 LOG block3 createRemoteUser proxyToNoWhere getConnectAddress FD_DIR proxy fail blockTokenLifetime createClientDatanodeProtocolProxy stop localhost: Assume server Leaked  testBlockTokenRpcLeak RPC getProxy fakeBlock fake-pool System allOf generateToken getBlockId stopProxy sm countOpenFileDescriptors addr  actually close the TCP connections to the real target DN. createMockDatanode b fake-storage EnumSet DFSUtil start assertEquals fdsAtStart token assumeTrue NetUtils getPort currentTimeMillis exists junk endTime ,hadoop,1
"date https://www.example.com private getDynamicEntry foo=ASDJKHQKBZXOQWEOPIUAXQWEOIU; max-age=3600; version=1 content-encoding assertHeaderEquals dynamicTable setMaxSize getCurrentSize set-cookie Assert get :status cache-control StandardCharsets Mon, 21 Oct 2013 20:13:22 GMT createByteBuffer Mon, 21 Oct 2013 20:13:21 GMT assertEquals headers2 gzip decoder headers3 headers1 200 testResponseDecodingWithHuffmanRFC7541Examples size 302 src1 decodeHeaders location 307 src3 src2 dynamicLength ",httpcore,0
The server is stopped assertFalse changes  An active reconfiguration task is running. getChangedProperties when dummy getEndTime testStartReconfigurationFailureDueToExistingRunningTask getReconfigurationTaskStatus Lists assertTrue Expect to throw IOException countDown getStartTime old1  The first task has finished. new1 stopped PROP1 newArrayList e doReturn GenericTestUtils conf1 Expect to throw IOException. waitAsyncReconfigureTaskFinish status2 any fail hasTask Another reconfiguration task is running assertExceptionContains shutdownReconfigurationTask spy startReconfigurationTask status ,hadoop,0
start.error assertTrue testStartError based_on_action_status error _testError ,oozie,1
<event>  set prettyPrint     <job-data>jd</job-data>  XmlUtils </event>     <job-status>STARTED</job-status>  el toXml     <user>u</user>  assertEquals actualXml   <sequence-id>1</sequence-id>      <sla-id>si</sla-id>    <status>    </status>      <app-name>an</app-name>      <group>gn</group>      <status-timestamp>1970-01-01T00:00Z</status-timestamp>  toString testToXmlStatusEvent bean ,oozie,1
DEFAULT_COMPRESSION_SUFFIX noCompression_FileSet_NoRestart_1 FIRST_PHASE_ONLY toto.log test1 generic ,logback,0
request HttpHeaders HeaderElements conn when setEntity testExecutionEntityEnclosingRequestWithExpectContinueNoResponse times isDataAvailable flush executor context create verify OK Boolean postProcess addHeader process thenReturn ArgumentMatchers Method getEntity execute / anyInt Mockito response HttpCoreContext httprocessor mock preProcess entity receiveResponseHeader sendRequestEntity sendRequestHeader receiveResponseEntity ,httpcore,0
HttpHeaders conn responseCaptor when setEntity Assert executor assertNotNull context create Boolean getCode thenReturn ArgumentMatchers getAllValues capture Method eq execute / anyInt size info1 mock receiveResponseHeader sendRequestHeader info2 request HeaderElements Continue times isDataAvailable flush get verify forClass OK postProcess addHeader process ArgumentCaptor Huh? assertEquals getEntity testExecutionEntityEnclosingRequestWithExpectContinueMultiple1xxResponses Mockito response HttpCoreContext httprocessor callback preProcess entity sendRequestEntity infos receiveResponseEntity ,httpcore,0
ROWS_ONE testPageFilter  testRowOne-2  testRowOne-3  Grab first 2 rows QUALIFIERS_ONE FAMILIES expectedKVs  Grab all 6 rows VALUES  Grab first 4 rows (6 cols per row) expectedKeys  KVs in first 6 rows expectedRows ROWS_TWO copyOf setFilter  testRowTwo-0 QUALIFIERS_TWO verifyScanFull verifyScan  testRowTwo-3 Arrays  testRowTwo-2  Grab first row ,hadoop,1
"cluster conf createFile simulatedStorage waitActive locations =  Error blocks were not cleaned up getFileStatus getNamenode buffer write info localhost   "" datanodeReport  verify that file exists in FS namespace getFileSystem stm setInt shutdownDataNodes Path : ""  wait for the datanode to be declared dead  bad block allocations were cleaned up earlier. Long DFS_HEARTBEAT_INTERVAL_KEY getNameNodePort SimulatedFSDataset shutdown /filestatus.dat getBlockLocations HdfsConstants seed  This should fail because all datanodes are dead.  create cluster  to die. fs System testFileCreationError1: waiting for datanode  sleep assertTrue client addr close DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY randomBytes isFile Encountered expected exception  kill the datanode AppendTestUtil Thread build  should be a file toString locations file1 setBoolean locatedBlockCount testFileCreationError1 ",hadoop,1
END_POINTS IS_SECURITY_ENABLED oozieUrl concurrency=10 run appPath -change -value create SERVLET_CLASSES close runTest app MockCoordinatorEngineService coordinator.xml RestConstants testChangeValue getContextURL assertEquals getFileSystem 0 args call -oozie mkdirs job getFsTestCaseDir ,oozie,1
"bb testBufferWrapperNested EchoRequestProto dos baos writable getDefaultInstance Assert assertTrue writeDelimitedTo write actual RpcWritable assertEquals newInstance  original bb now appears empty, but rpc writable has a slice of the bb. ByteBuffer remaining buf1 buf2 getValue size left toByteArray wrap message2 message1 ",hadoop,0
/invoker.sh System duration Process completed in  isFamilyUnix addArgument sh -c executor os.name startTime setStreamHandler cmdLine getProperty OS  even if command we'll invoke will terminate immediately. setStopTimeout testExec_57 testDir execute The test 'testSyncInvocationOfBackgroundProcess' does not support the following OS :  pumpStreamHandler  millis; above is its output fail Executing  currentTimeMillis Expecting an ExecuteException ,commons-exec,1
"reader LocalOozie conf getStatus  workflow success reflects that rerun configuration contained correctly resolved variable values.       * Test to ensure parameterized configuration variables get resolved in workflow rerun       ${base}/p1 path getTestCaseDir /workflow.xml file:// ${base}/p2 workflow.xml waitFor wfClient dstDir  setting the variables ""srcDir"" and ""dstDir"", used as a file paths in the workflow, to parameterized expressions to test resolution. getFileSystem reRun OozieClient rerun-varsub-wf.xml copyCharStream setProperty getResourceAsReader srcDir createConfiguration File evaluate p2 submit getJobInfo delete jobId1 testRerunVariableSub WorkflowJob nnbase getProperty  Skip executed nodes start false assertEquals getClient kill IOUtils getTestUser toString writer getFsTestCaseDir base ",oozie,1
getTime start run getId assertEquals getStatus execute addRecordToCoordJobTable coordGetCmd coordJob sleep CoordinatorJob Services runnable testCoordMaterializeTriggerService2 get end job jpaService ,oozie,1
init ae destroy Wildcard indicates ALL schemes will be allowed. This should pass * validatePath HadoopAccessorService anyfs://bla Services fail get setSystemProperty testFileSchemeWildcard ,oozie,1
cluster DFSConfigKeys set conf getFileSystem simulatedStorage dfs.datanode.simulateddatastorage 1 build fileSys file1 close smallblocktest.dat writeFile testSmallBlock shutdown cleanupFile setBoolean checkFile ,hadoop,1
conn setRequestMethod IS_SECURITY_ENABLED assertTrue json content-type /v1/admin/* Collections runTest RestConstants java.version openConnection containsKey HttpServletResponse assertEquals parse getInputStream url JSONValue call getHeaderField testJavaSysProps GET getResponseCode createURL startsWith ,oozie,1
next getBlockLocations DIR1 assertFalse FILE1 FILE2 FILE3  test empty directory FILE_LEN assertTrue getLen getPath FsPermission mkdir listFiles writeFile TEST_DIR stat isFile  test more complicated directory getDefault hasNext assertEquals testDirectory  testing directory with 1 file util makeQualified fc itor ,hadoop,1
next END_POINTS IS_SECURITY_ENABLED oozieUrl wc setHeader containsValue getHeader found testHeaders assertTrue get headers does not contain header! SERVLET_CLASSES runTest headers getContextURL test getHeaders validateWSVersion HeaderTestingVersionServlet containsKey clear assertEquals hasNext removeHeader call assertNull equals getHeaderNames header ,oozie,1
getJobTrackerUri map-reduce map-reduce-launcher.jar oozie.streaming.mapper oozie.streaming.reducer <pipes> </configuration> conf setupActionConf protoConf createBaseWorkflow <reduce>R</reduce> <map-reduce> context action mapred.input.dir testSetupMethods IF <job-tracker> oozie.pipes.writer add ae IN <record-reader-mapping>RRM1=1</record-reader-mapping> oozie.pipes.inputformat parseXml oozie.pipes.partitioner </job-tracker> </pipes> oozie.pipes.program <name-node> </name-node> 2 <streaming> getType <env>ee=EE</env> <map>M</map> </streaming> <writer>W</writer> oozie.streaming.record-reader RR <record-reader>RR</record-reader> getClassesForLauncher classes getActions <reducer>R</reducer> <inputformat>IF</inputformat> M oozie.pipes.reduce createBaseHadoopConf mr-action wf actionXml P <partitioner>P</partitioner> R get W <program>PP</program> <mapper>M</mapper> getNameNodeUri <record-reader-mapping>RRM2=2</record-reader-mapping> <property><name>mapred.output.dir</name><value>OUT</value></property> set XmlUtils WorkflowAppService getLauncherClasses oozie.streaming.env.size oozie.pipes.map assertEquals <configuration> setType getLauncherJarName /PP </map-reduce> Services getTestUser addAll <property><name>mapred.input.dir</name><value>IN</value></property> <env>e=E</env> oozie.streaming.record-reader-mapping.size getFsTestCaseDir ,oozie,1
"Thu, 01 Jan 1970 00:00:00 GMT DateUtil testParseHttpDateFormat toString assertEquals Wed, 05 Sep 2012 09:57:57 GMT  some simple tests: parseHttpDateFormat ",ninja,0
init service assertServiceInState listener Service registerServiceListener assertEventCount testStopInInitService ,hadoop,0
"call h3#heading {  font-size: modular-scale(14px, 1, 1.618); } process task e shouldBeThreadSafe WroTestUtils runConcurrently processor ",wroj4,1
request bulkjpa bundle=BUNDLE-ABC;actionstatus=FAILED BundleEngine getMessage execute fail contains testJavaNoRecords assertTrue No bundle entries found parseBulkFilter  exception expected due to no records found for this jex jpaService ,oozie,1
mockRes init mockReq  Object under test thenReturn BROWSER_AGENT  CSRF has not been sent  Objects to verify interactions based on request  Setup the configuration settings of the server getMethod when filterConfig getHeader filter mockChain getInitParameter Mockito doFilter GET testMissingHeaderIgnoreGETMethodConfigGoodRequest mock verify RestCsrfPreventionFilter ,hadoop,0
thenReturn eq fs when delete path testDeleteOnExit /a  delete on close if path does exist assertTrue getFileStatus mock verify reset mockFs close deleteOnExit ,hadoop,0
rw assertFalse channel getBytes head Assert getChannel writeLine dump chbuffer close write fchannel testCodingFromFileChannelSaturated isCompleted testfile StandardCharsets createTempFile assertEquals encoder transfer outbuf header metrics append stuff ,httpcore,0
" addNode def enters WorkflowInstance getStatus asList wf exits testWfFailWithRunningNodes end signal fails a b f start  assertEquals(1, kills.size()); j assertEquals 1 size <worklfow-app/> Arrays job /b/ ",oozie,1
setHandler HTTP/localhost cancelDelegationToken conf getKind getOwner keytabFile getCause dis /bar Assert /foo/bar FOO_USER assertNotNull MiniKdc context randomUUID id UUID DispatcherType /foo OK_USER hadoop.security.authentication setContextPath kdc createJettyServer test.keytab testDir token-kind readFields testKerberosDelegationTokenAuthenticator fail doAs contains ex stop mkdirs  Make sure the token belongs to the right owner 403 createPrincipal doAsUser addFilter doAsKerberosUser getRealm kerberos createConf GSSException assertTrue getIdentifier of java.security.krb5.realm client jetty /* close getJettyURL set aUrl addServlet getAbsolutePath EnumSet renewDelegationToken start KDTAFilter getMessage assertEquals getRealUser KerberosTestUtils url token call target/ buf assertNull toString getDelegationToken ,hadoop,0
    X     X   X X     X X X X     X   X     X X X X   X X   X X   X X X     X   X   X X X   X             X         X X X X X   X   X X   X   X   X X   X   X   X   X           X   X X   X X X X X X   X X X X X X X X X   X     X X           X X X X           X     X     X     X X     X   X X   X X   X         X X       X       X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X     X X X X X               X     X X X   X       X X   X X   X X X X     X X                 X X     X X     X     X     X   X X X         X   X         X   X X         X X   X X   X   X X X X   X X X X X X X X   X   X       X X   X X X X   X X X                 X X X   X     X   X   X               X   X X     X X X   X X                 X X X X   X         X   X X X X X X X X X X X X X X   X       X X   X X   X X       X     X       X         X   X   X       X   X   X     X   X X                           X X     X X X X X   X   X   X X X X X   X   X X X     X X X X   X           X X     X       X       X X X X   X   X X       X   X X   X       X X   X X   X     X     X   X   X         X   X   X               X   X X   X X   X X X     X   X     X   X X     X               X X X X X     X X     X X X X X X X X     X   X   X X     X       X X     X   X X   X X       X             X     X   X X   X           X       X X                 X   X                       X X   X       X         X X X       X   X X       X     X       X   X X X X X X   X X   X X X X X X X X X   X   X   testEncode2     X X   X   X   X X X     X                       X X X   X X   X   X     X           X X   X   X   X X X               X       X       X X     X X   X X       X                 X   X   X X       X X X X X     X X X       X       X X X         X     X X     X     X   X   X   X X   X   X X X X X   X   X X X X X X X       X   X X X   X           X     X X X X     X     X         X         X   X       X X   X X X     X X X X       X       X   X X   X   X       X   X   X     X X X     X X       X X   X             X         X   X X   X X     X     X     X   X   X X X X               X   X   X X   X X X   X         X X     X X X X     X X   X   X     X   X       X             X       X X X   X X     X   X           X   X X X X   X X                     X         X X   X       X     X   X   X       X     X X X     X       X X X X   X     X X     X X X X X X             X X X   X               X   X     X     X X    of nominally square symbols built on a square grid with a  distinctive square bullseye pattern at their center. testEncode   X       X   X     X X   X   X X   X X   X X X X X X   X X           X   X   X X     X   X X X   X X       X X X         X X           X   X   X   X X X   X X     X     X     X X   X   X       X X X X X X X X X X X X X X X   X   X X   X   X X X       X       X         X   X X X X   X     X X     X X     X X           X   X       X     X   X X X   X   X X   X X X   X X X X X X X X X   X X         X X     X X X X       X       X   X     X       X X     X X   X   X   X     X X   X X X   X     X X X   X     X       X X X X X     X   X X X X   X X X     X       X X X X   X   X X   X   X       X           X   X   X     X X   X               X     X     X X X           Aztec Code is a public domain 2D matrix barcode symbology   X   X X X     X   X   X X     X X X   X   X X               X X       X X     X   X X X             X   X         X         X     X     X   X     X X       X   X     ,zxing,0
testDelegationTokenAuthenticatorCallsWithHeader testDelegationTokenAuthenticatorCalls ,hadoop,0
 check Har home path:  ======== Positive tests:  check Har version: getScheme getWorkingDirectory harPath toUri homePath workDirPath0 assertEquals  check working directory: getHarVersion setWorkingDirectory /foo/bar  check Har URI: getHomeDirectory harUri getPath har HarFileSystem harFileSystem getUri  (#setWorkingDirectory should have no effect): testPositiveHarFileSystemBasics ,hadoop,0
getFailoversOccurred proxyProvider impl2 start assertEquals impl1 RetryProxy TypeOfExceptionToFailWith RetryPolicies unreliable create failoverOnNetworkException join t1 testConcurrentMethodFailures t2 ,hadoop,0
I_dont_exist testAutomaticCreationOfColumnFamily getColumnFamily newBuilder TogglzTest keyspace Test Cluster assertNull columnFamily columnFamilyName build CassandraStateRepository assertNotNull autoCreateColumnFamily setThriftPort describeKeyspace ,togglz,1
server requestBytes serverAddress awaitResponseTimeout sendError generateRandomBytes cause conf getCause clientThread Assert awaitInvocation assertTrue get Call succeeded. Was expecting an exception e start clientCallable getConnectAddress DeferredError fail contains NetUtils re stop future testDeferredException toString ,hadoop,0
 test permissions on files that do not exist cluster data GROUP_NAMES conf fin setOwner waitActive CHILD_FILE1 bar CHILD_FILE2 /foo/bar FileSystem create write  illegal file creation info UserGroupInformation createUserForTesting DFSConfigKeys read CHILD_DIR2 LOG  this user does not throw an exception. CHILD_DIR1 /  following dir/file creations are legal numDataNodes mkdirs GOOD: got  canMkdirs  following read is legal shutdown nnfs  illegal mkdir assertFalse foo canRename ROOT_PATH  test illegal file/dir creation out nextBytes FILE_LEN assertTrue get 777 testFilePermision setPermission close dataIn DFSTestUtil  illegal file open userGroupInfo e bytesRead assertEquals USER_NAME canCreate userfs build getFileSystemAs 700 RENAME_PATH canOpen exists RAN open setBoolean ,hadoop,1
getJobTrackerUri map-reduce _testSubmit fs output actionXml <map-reduce> create write close <job-tracker> getMapReduceConfig getNameNodeUri outputDir </job-tracker> dummy  getFileSystem inputDir <name-node> </name-node> </map-reduce> input testMapReduce w toXmlString toString data.txt getFsTestCaseDir ,oozie,1
getBytesTransferred payload2 getMetrics outbuffer inBuffer readableChannel testReadWriteFrame Assert assertNotNull FrameType get FrameConsts getFramesTransferred write getPayloadContent read frame2 getStreamId assertEquals ByteBuffer remaining getValue allocate getType bytes toByteArray getFlags wrap writableChannel frame ,httpcore,0
cs1 cluster getLocatedBlocks getName cs2 conf fs createFile waitActive assertTrue testGetFileChecksum get stopDataNode DFSClient DFSTestUtil locatedblocks  stop the first datanode f  get checksum assertEquals getFileSystem getNameNodeRpc getFileChecksum p build numDataNodes  create a file Long callGetBlockLocations getLocations shutdown first /testGetFileChecksum  get checksum again ,hadoop,1
getJobTrackerUri output1 getName </configuration> _testSubmit <property><name>mapred.reducer.class</name><value> fs actionXml <property><name>mapred.mapper.class</name><value> <map-reduce> create write close <job-tracker> getNameNodeUri outputDir </value></property> <property><name>mapred.input.dir</name><value> ow </job-tracker> <property><name>mapred.output.dir</name><value> dummy  getFileSystem <configuration> inputDir <name-node> </name-node> </map-reduce> input testMapReduce w data.txt getFsTestCaseDir ,oozie,1
job2 job1 checkWorkflows job3  job3 shouldn't be in the list because it has a parent getId WorkflowInstance list execute Services addRecordToWfJobTable addAll assertNotNull get setParentId testWfJobsGetForPurgeWithParent WorkflowJob jpaService ,oozie,1
add executing thread should be a daemon thread. currentThread wait getExecutorService notifyAll isEmpty executingThreads run execute Thread assertTrue isDaemon execSvc get context contextThreadpoolIsDaemonized ,logback,0
OTHER_GROUP_NAMES ProxyUsers refreshSuperUserGroupsConfiguration getProxySuperuserGroupConfKey assertAuthorized GROUP_NAMES DefaultImpersonationProvider  from the other test case!) conf PROXY_IP  From bad IP UserGroupInformation  First try proxying a group that's allowed set proxyUserUgi testWildcardGroup 1.2.3.4 1.2.3.5 * createRemoteUser REAL_USER_NAME assertNotAuthorized getTestProvider  From good IP getProxySuperuserIpConfKey PROXY_USER_NAME realUserUgi createProxyUserForTesting ,hadoop,0
 240 shifts to EDIFACT encodation .A.C1.3.X.X2.. 240 184 27 131 198 236 238 89 240 184 27 131 198 236 238 98 230 31  97 139 152 97 139 152 97 139 152 97 139 152 97 139 152 97 139 152 89 89  <-- this is the temporary unlatch .A.C1.3.X testEDIFACTEncodation .A.C1.3.X.X2. 240 184 27 131 198 236 238 98 230 50 .A.C1.3.X.X .XXX.XXX.XXX.XXX.XXX.XXX.Ã¼XX.XXX.XXX.XXX.XXX.XXX.XXX  124 47 235 125 240 .A.C1.3.X.X2 240 184 27 131 198 236 238 16 21 1 187 28 179 16 21 1 187 28 179 16 21 1 240 184 27 131 198 236 238 98 230 50 47 47 240 185 134 24 185 134 24 185 134 24 185 134 24 185 134 24 185 134 24 visualized .A.C1.3.DATA.123DATA.123DATA assertEquals 240 184 27 131 198 236 238 98 230 50 47 129 240 184 27 131 198 236 238 98 231 192  Checking temporary unlatch from EDIFACT .A.C1.3.X. encodeHighLevel ,zxing,0
setName ${coord:daysInMonth(coord:daysInMonth(1))} 2010-10-01T00:00Z CoordELFunctions UTC getTimeZone 2009-09-10T23:59Z 28 coord-action-create DateUtils  Feb test1 setFrequency parseDateOozieTZ ds evalAndWrap  End of Month ${coord:daysInMonth(-1)} configureEvaluator ${coord:daysInMonth(-3)} setTimeZone  Jan TimeUnit expr setEndOfDuration 30 31 init setNominalTime setInitInstance ${coord:daysInMonth(2)} ${coord:daysInMonth(3)}  Case 1 assertEquals ${coord:daysInMonth(0)} ${coord:daysInMonth(1)} setType setActualTime appInst America/Los_Angeles setTimeUnit 2009-02-01T11:00Z eval testDaysInMonth 2009-01-01T00:00Z 2009-01-02T00:00Z SYNC ,oozie,1
localhost localhost:123 compare NetUtils createSocketAddrForHost localhost: runGoodCases testGoodHostsAndPorts ,hadoop,0
"next shutdownDfs , scanned  getLog setBatch scan  assert that the result set is no larger than BATCH HConstants  assert that the scanner returned all values Bytes total inserted assertTrue getTableDesc get  assert that all results are from the same row REGION_INFO BATCH row close results inserted  info iteration # LOG more clear kv getRow closeAndDelete createNewHRegion r addWideContent testWideScanBatching , results.size= size addFamily equals getScanner ",hadoop,1
"<execution>LIFO</execution> </controls> <datasets>  </property></configuration> </workflow>  checkCoordJobs conf </input-events>  xmlns:sla='uri:oozie:sla:0.1'> <controls> <timeout>${coord:minutes(10)}</timeout>  <concurrency>2</concurrency>  file:// getTestCaseDir UNIT_TESTING <output-events> <data-out name=""LOCAL_A"" dataset=""local_a"">  timezone=""UTC""> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset>  10 <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  <dataset name=""local_a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  SLA_OFFSET OozieClient jobId </datasets> <input-events>  -C <dataset name=""a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  job File  <sla:se-contact>abc@example.com</sla:se-contact> appPath substring sc writeToFile appXml <property> <name>inputB</name> <value>${coord:dataOut('LOCAL_A')}</value>  getTimeout  <sla:info>  <sla:alert-contact>abc@example.com</sla:alert-contact>  <sla:should-end>${ SLA_OFFSET * HOURS}</sla:should-end> testBasicSubmitWithSLA  <sla:dev-contact>abc@example.com</sla:dev-contact> coordinator.xml set  <sla:alert-frequency>LAST_HOUR</sla:alert-frequency> </sla:info> length </action> </coordinator-app>  <sla:should-start>${5 * MINUTES}</sla:should-start> assertEquals  <sla:app-name>test-app</sla:app-name> call <coordinator-app name=""NAME"" frequency=""${coord:days(1)}"" start=""2009-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""   <sla:alert-percentage>10</sla:alert-percentage> getTestUser xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance' xmlns='uri:oozie:coordinator:0.2'  <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>   <sla:nominal-time>${coord:nominalTime()}</sla:nominal-time> <data-in name=""A"" dataset=""a""> <instance>${coord:latest(0)}</instance> </data-in>    <sla:qa-contact>abc@example.com</sla:qa-contact>  <sla:notification-msg>Notifying User for ${coord:nominalTime()} nominal time </sla:notification-msg> ",oozie,1
"cluster /test/mkdirs/TestchunkSizeToView getFileSystem fs DatanodeJspHelper atLeastOnce testFile writerMock print reqMock <input type=""hidden"" name=""genstamp"" value=""987654321""> build Mockito numDataNodes mock generateFileDetails verify testGenStamp CONF setTheMockExpectationsFromReq writeFile shutdown ",hadoop,1
fileName filePath     * This test creates a file with one block replica. Corrupt the block. Make    * DFSClient read the corrupted file. Corrupted block is expected to be    * reported to name node.     verifyFsckBlockCorrupted expectedReplicaCount dfsClientReadFileFromPosition dfsClientReadFile /tmp/testClientReportBadBlock/OneBlockReplica verifyFirstBlockCorrupted createAFileWithCorruptedBlockReplicas  create a file verifyCorruptedBlockCount testOneBlockReplica repl testFsckListCorruptFilesBlocks corruptBlockNumber  corrupted. ,hadoop,1
ser getDeserializer unchecked serializer deserializer assertEquals deser testWritableComparatorJavaSerialization serialize getSerializer orig dob getLength reset dib close open getData deserialize rawtypes ,hadoop,0
aa a A ${a} b set c getProperty d testVarResolutionAndSysProps ${user.name} foo user.name conf assertEquals System ${aa} ${aaa} setSystemProperty get un getRaw ,oozie,1
given .installed resolve alpha.jar willReturn assertThat asList bravo charlie.jar getNamesOfFilesInLib bravo.jar install alpha createTemporaryFile containsInAnyOrder Arrays charlie uninstallAll ,spring-boot,1
server serverThreads Server callIds conf run  contains every expected value.  it. startID get client synchronizedList join perCallerCallCount Collections addr getCallId callerCount add assertReturnValues intValue testUniqueSequentialCallIds start assertEquals sort getConnectAddress NetUtils stop size callers expectedCallCount ,hadoop,0
 server timeOutCreationTime checkCoordAction CoordELFunctions  timeout. assertFalse addPartition addInitRecords getWaitingActions System checkDependencies sleep testTimeOutWithUnresolvedMissingDependencies default /dt=20120430;country=usa assertTrue get CoordinatorAction /dt=20120430;country=uk tablename newHCatDependency table setCoordActionCreationTime newHCatDependency2 newHCatDependency1 hcatService populateTable dt=20120430;country=brazil newHCatDependency3 hcat:// setMissingDependencies pdms isRegisteredForNotification / Thread call Services contains assertNull currentTimeMillis  we are only interested in ensuring CoordActionInputCheckXCommand is run /dt=20120430;country=brazil actionId db ,oozie,1
date session  Given insert should_insert_with_timestamp crud usingTimestamp  When id row value wt isNotNull RandomUtils manager SELECT writetime(value) as wt FROM simple WHERE id =  one nextLong assertThat execute getLong  Then Long buildDateKey isEqualTo entity ,achilles,1
server createTestServer testCreatedServerIsNotAlive assertNotLive ,hadoop,0
"cluster  a chance to take the lock, if it is ever going to. LOG HealthMonitor start waitForHealthState Allowing svc0's elector to re-establish its connection waitForActiveLockHolder  svc0 should get the lock again allowSessionReestablishmentForTests expireActiveLockHolder Thread  Make svc1 unhealthy, and wait for its FC to notice the bad health. getElector sleep setHealthy Expired svc0's ZK session. Waiting a second to give svc1 preventSessionReestablishmentForTests  Expire svc0 testDontFailoverToUnhealthyNode info  Ensure that no one holds the lock. ",hadoop,0
bab addRecordToBundleActionTable getCurrentDateafterIncrementingInMonths getId run DateUtils getStatus addRecordToCoordActionTable parseDateOozieTZ coordJob assertNotNull get CoordinatorAction end currentDatePlusMonth Job waitFor addRecordToBundleJobTable bundleId start assertEquals XDataTestCase execute addRecordToCoordJobTableWithBundle Services CoordinatorJob runnable coord-action-get.xml equals action1 job jpaService evaluate testBundleStatusTransitServiceForTerminalStates ,oozie,1
createExclusion spring-beans excludes unchecked assertEquals asList put args spring-core org.springframework spring-jdbc createDependency dependencyResolutionWithExclusions 3.2.4.RELEASE Arrays grab getURLs ,spring-boot,1
Testing SequenceFile with DefaultCodec LOG Successfully tested SequenceFile with DefaultCodec testZlibSequenceFile compressedSeqFileTest info ,hadoop,0
getBytesTransferred testCodingFragmentBufferingTinyFragments3 CodecTestUtils channel times Assert flush verify more stuff dump write -- ArgumentMatchers StandardCharsets assertEquals encoder - any stuff------more stuff Mockito outbuf metrics spy wrap stuff ,httpcore,0
getBytesTransferred CodecTestUtils channel times Assert flush verify more stuff dump stuff---more stuff write testCodingFragmentBufferingTinyFragments ArgumentMatchers StandardCharsets assertEquals encoder - any Mockito outbuf metrics spy wrap stuff ,httpcore,0
PATH request  Add request. test method nulls  ) put STATUS TestingFramework framework HEADERS REQUEST QUERY runTests CONTENT_TYPE response METHOD addTest RESPONSE BODY  Response ,httpcore,0
doAnEdit  Make sure runtime.exit(...) hasn't been called at all yet. cluster testSingleFailedEditsDirOnFlush assertTrue assertExitInvocations  Invalidate one edits journal. assertFalse  A single journal failure should not result in a call to runtime.exit(...). isInSafeMode invalidateEditsDirAtIndex getNameNode ,hadoop,1
getBytesTransferred a lot more stuff! rw stuff;  CodecTestUtils more stuff;  channel Assert inbuf getChannel pos testBasicDecodingFile stuff; more stuff; a lot more stuff! close fchannel isCompleted testfile StandardCharsets length bytesRead createTempFile assertEquals decoder transfer readFromFile metrics ,httpcore,0
key1 key2 ARG_CONF_PREFIXED bindCommandOptions extracted asList Name argsList extractCommandOptions assertTrue newConf configFile get getBoolean isEmpty conf2 testDualConfArgs conf1 assertEquals args getInt RunningService size 7 args beginning with  true file2 launcher ,hadoop,0
"next joe drwho,joe tardis,users drwho addUser assertFalse acl getAclString iterator drwho  removeUser getUsers isZero addGroup getGroups   isOne groups iter testAddRemoveAPI assertThat drwho tardis users contains size removeGroup tardis isEqualTo ",hadoop,0
addRecordToBundleActionTable addRecordToWfActionTable coordActionGetCmd getNumDaysToNotBePurged testPurgeBundleWithCoordChildWithWFChild2 DateUtils WorkflowInstance getStatus addRecordToCoordActionTable parseDateOozieTZ getEndTime bundleJob BundleJobBean assertNotNull CoordinatorAction Job wfAction wfJobGetCmd Bundle Action should not have been purged execute Bundle Job should not have been purged CoordinatorJob 1 coordJobGetCmd fail WorkflowAction coordAction SUCCEEDED Workflow Action should not have been purged bundleJobGetCmd getId coordJob wfJob addRecordToWfJobTable get Workflow Job should not have been purged WorkflowJob getAppName bundleAction wfActionGetCmd Coordinator Action should not have been purged 2011-01-01T01:00Z addRecordToBundleJobTable assertEquals getLastModifiedTime addRecordToCoordJobTable Coordinator Job should not have been purged call Services coord-action-get.xml jpaService bundleActionGetCmd ,oozie,1
pp getCurrentUser fakeUser run Runtime split trim  get the user name getRuntime UserGroupInformation add toLowerCase getWinUtilsPath createRemoteUser getInputStream loginUserName contains doAs  groups -F foo.bar size : exec whoami  user names are case insensitive on Windows. Make consistent line getGroupNames assertFalse login substring System br Shell  extract only the user name current assertTrue StringUtils tokens sp getShortUserName gi testGetServerSideGroups groups assertEquals readLine userName  get the groups lastIndexOf equals id -Gn  ,hadoop,0
add getStats DummyTestMetric collectThreadLocalStates getMetrics testMetric GenericTestUtils The rolling average of metric2 is not as expected testMutableRollingAveragesMetric rb The rolling average of metric1 is not as expected [Metric2]RollingAvgTesting Assert size assertTrue get [Metric1]RollingAvgTesting create metric1 metric2 metric1Avg metric2Avg getDoubleGauge waitFor ,hadoop,0
"APP fw1 2009-06-24 02:43:13,958 WARN _L8_:323   f1 streamLog End workflow state change  2009-06-24 02:43:13,958 WARN _L10_:323 !@#$%^&*() blah blah  Check if the lines of the log contain the expected strings 2009-06-24 02:43:13,958 DEBUG _L4_:323 ABC split _L4_ getTestCaseDir 2009-06-24 02:43:13,958 DEBUG _L2_:323 + 2009-06-24 02:43:13,958 DEBUG _L3_:323 JOB TOKEN 2009-06-24 02:43:13,958 DEBUG _L1_:323 - write setLogLevel str contains _L3_ reset 2009-06-24 02:43:13,958 WARN _L7_:323 +  checks that this condition is no longer required sb1  filtering shouldn't care whether or not there is a dash while the last five lines don't pass the normal filtering DEBUG|INFO 2009-06-24 02:43:13,958 WARN _L6_:323 - System out GROUP testStreamLogNoDash 14-200904160239--example-forkjoinwf oozie.log _L2_ defineParameter setParameter logStatement currTime close sw /oozie.log XLogStreamer 2009-06-24 02:43:13,958 DEBUG _L5_:323 !@#$%^&*() blah blah assertEquals USER xf 2009-06-24 02:43:13,958 WARN _L9_:323 ABC ACTION currentTimeMillis _L1_ toString _L5_ append setLastModified ",oozie,1
testTwoStepWriteConnectTimeout os expected timeout e LOG connect timed out getMessage TEST_TIMEOUT assertEquals /file fs fail IOUtils cleanup startSingleTemporaryRedirectResponseThread create ,hadoop,1
"getBlockLocations fileName expectedReplicaCount dfsClientReadFileFromPosition dfsClientReadFile replicaCount verifyFirstBlockCorrupted createAFileWithCorruptedBlockReplicas get verifyCorruptedBlockCount getNamenode repl corruptBlocReplicas verifyFsckHealth blocks filePath         * The order of data nodes in LocatedBlock returned by name node is sorted         * by NetworkToplology#pseudoSortByDistance. In current MiniDFSCluster,         * when LocatedBlock is returned, the sorting is based on a random order.        * That is to say, the DFS client and simulated data nodes in mini DFS        * cluster are considered not on the same host nor the same rack.        * Therefore, even we corrupted the first two block replicas based in         * order. When DFSClient read some block replicas, it is not guaranteed         * which block replicas (good/bad) will be returned first. So we try to         * re-read the file until we know the expected replicas numbers is         * returned.         dfs Target Replicas is 3 but found 1 replica /tmp/testClientReportBadBlock/CorruptTwoOutOfThreeReplicas testCorruptTwoOutOfThreeReplicas Long getLocations toString testFsckListCorruptFilesBlocks ",hadoop,1
WORKER_CAPACITY_BYTES CommonUtils WriteType assertFalse getUsedBytes USER_QUOTA_UNIT_BYTES delete getFile TestUtils Assert file assertTrue get fileURI  Delete non-existing files. workers uniqPath getWorkersInfo createByteFile SLEEP_MS assertEquals k sleepMs getCapacityBytes exist getFileId writeBytes deleteFileTest size isInMemory sTfs fileId ,alluxio,1
"<!-- yarn.nodes.exclude -->  excludesLen excludes        getExcludedHosts <host><name>host1</name></host>  assertTrue <host><name>10001</name><timeout>123</timeout></host>  get <hosts>  </hosts>  #Hosts-in-DFS  <host><name>host2</name><timeout>123</timeout></host>  write close getHosts    somehost 	  somehost2   somehost4 host5 host4 hostDetails excludesXmlFile <?xml version=""1.0""?>  host6 host1 containsKey host3 host2 includesFile <host><name>10000</name></host>  assertEquals getHostDetails     * Test if timeout values are provided in HostFile     <host><name>host4,host5, host6</name> hfp getExcludedMap size efw <timeout>1800</timeout></host>     somehost3 	 # somehost5 10000 <host><name>10002</name><timeout>-1</timeout></host>  testHostFileReaderWithTimeout 10002 ifw 10001 <host><name>host3</name><timeout>-1</timeout></host>  includesLen ",hadoop,0
CredentialProviderFactory conf ourUrl testLocalJksProvider delete fs LocalJavaKeyStoreProvider tmpDir path file assertTrue 777 getFileStatus setPermission  check permission retention after explicit change rw------- test.jks unnestUri set getPermission checkSpecificProvider isFile toUri assertEquals getFileSystem  should exist Unexpected permissions:  jksPath ://file checkPermissionRetention toString ProviderUtils ,hadoop,0
inheritWF false parentLibs2 parentLibs3 checkSubworkflowLibHelper parentLibs1 parentLibs4 parentLibs5 childLibs1 expectedLibs1 expectedLibs2 expectedLibs3 expectedLibs4 inherit child2.so expectedLibs5 same.jar childLibs3 childLibs2 childLibs5 child1.jar childLibs4 testCreateProtoConfWithSubWorkflowLib6 ,oozie,1
cancel request A server dispatch setBody newCall execute url getUrl fail /a cancelInFlightBeforeResponseReadThrowsIOE build setDispatcher get client tag ,okhttp,1
" => same timestamp => not modified assertFalse when getHeader  => strange timestamp => modified isModified Thu, 01 Jan 1970 00:00:00 GMT assertTrue Thu, 01 Jan 1971 00:00:00 GMT of context  => no if modified since request => null Optional thenReturn etag_xyz STRANGE_TIMESTAMP  test etag support: httpCacheToolkit  remove etag to test modified timestamp caching:  => older timestamp => modified etag_xyz_modified  same etag => not modified ninjaProperties  new etag => modified  => newer timestamp => not modified testIsModified HttpHeaderConstants ",ninja,0
"checkFatalsAndReset waitForElectorState serverFactory timeout sleep ensureParentZNode  Let elector 1 be standby verify closeSession waitForActiveLockData ========================== Quitting election info getServer  due to receiving the ""expired"" event.  Should enter neutral mode when disconnected zks LOG  by quitting elector 0 and ensuring elector 1 doesn't become active getZKSessionIdForTests  Should re-join the election and go back to STANDBY enterNeutralMode ActiveStandbyElectorTestUtil ========================== Expiring standby's session quitElection Thread never testHandleSessionExpirationOfStandby cbs Mockito becomeActive State joinElection electors  Let elector 0 be active appDatas PARENT_DIR ",hadoop,0
play data  play it back android assertFalse assertStreamData headerEntries  verify the peer received what was expected source acceptFrame stream openStreamCount TYPE_HEADERS assertTrue peer connection writeUtf8 takeFrame banana a b synReply serverClosesClientInputStream assertEquals HeadersMode square  SYN_STREAM sendFrame SPDY3 getSource synStream newStream ,okhttp,1
/blah/my%2fid/and/some/more/stuff entrySet buildRoute  decoded this would be /blah/my/id/and/some/more/stuff getPathParametersEncoded assertEquals my%2fid routeFromServer matches routeWithUrlEncodedSlashGetsChoppedCorrectly route size assertTrue GET get routeBuilder id /blah/{id}/.* ,ninja,0
p1 p2 getKMSUrl conf Should fail since provider p1 threw RuntimeException when times testClientRetriesWithRuntimeException assertTrue verify thenThrow kp e anyString thenReturn createKey eq any setInt CommonConfigurationKeysPublic fail never test3 Mockito mock ,hadoop,0
"getJobTrackerUri </configuration> createContext cacheFilesStr context create getCacheFiles <job-tracker> eActionXml actionLibPath ae  Test adding a directory </value></property> actionlibs parseXml </job-tracker> getFileSystem  Test adding a directory and a file (comma separated) , <name-node> </name-node> setupLauncherConf setLibFilesArchives contains mkdirs Arrays jobConf cacheFiles jar3.jar <java> getAppPath jar3Path testActionLibsPath createBaseHadoopConf actionXml DistributedCache <job-xml>job.xml</job-xml> assertTrue <property><name>oozie.launcher.oozie.libpath</name><value> <job-xml>job2.xml</job-xml> jar2Path close getNameNodeUri jar1Path </java> XmlUtils jar1.jar <main-class>MAIN-CLASS</main-class> <configuration>  Test adding a file toString jar2.jar getFsTestCaseDir ",oozie,1
END_POINTS IS_SECURITY_ENABLED lib pigScriptFile oozieUrl conf wc /test localhost:9001 pig libPath INPUT=input.txt assertTrue testSubmitPig getTestCaseDir get SERVLET_CLASSES write close runTest getContextURL XOozieClient MockDagEngineService hdfs://localhost:9000 assertEquals getFileSystem params submitScriptLanguage call OozieClient mkdirs setProperty wfCount createConfiguration toString writer a = load '${INPUT}';  dump a; getFsTestCaseDir ,oozie,1
"@ closeTrx coordClient getStore getTime LocalOozie Could not update db. -testCoordRerun-C getCoordClient rerunScope getErrorCode assertTrue get beginTrx CoordinatorAction reRunCoord actionNum2 commitTrx actionNum1 coord-rerun-action2.xml 2009-12-15T01:00Z,2009-12-16T01:00Z,2009-12-17T01:00Z RestConstants printStackTrace e store actionId2 addRecordToJobTable jobId actionId1 Services fail CoordinatorJob ex addRecordToActionTable testCoordRerunDateNeg 0000000- toString ErrorCode Exception expected because one action is missing from db. coord-rerun-action1.xml ",oozie,1
calendar add rfsSink set getTime Calendar getTimeInMillis assertEquals testUpdateRollTime getInstance The next roll time should have been 1 second in the future updateFlushTime setTime The next roll time should have been 990 ms in the future ,hadoop,0
"getTime getStatus myapp XML schema error, cvc-pattern-valid: Value '${someParam}'  Expected status was FAILED due to incorrect XML element <start to='${someParam}' /> mytoken getErrorCode assertTrue get me CoordinatorAction action is not facet-valid with respect to pattern -COORD-ActionStartCommand-C@1 myjob testActionStartWithErrorReported assertEquals execute wfApp call Services fail contains addRecordToActionTable actionId toString ErrorCode jpaService getErrorMessage ",oozie,1
play  Verify the peer received what was expected. android Okio TYPE_DATA headerEntries Util getSink out acceptFrame flush TYPE_HEADERS peer variant client connection buffer write close takeFrame banana a b synReply setVariantAndClient  DATA assertEquals frameCount  SYN_STREAM sendFrame clientSendsEmptyDataServerDoesntSendWindowUpdate SPDY3  Play it back. newStream ,okhttp,1
ce createCoordinatorEngine getFilterParams assertEquals streamLog services runJobsImpl filter jobId DagXLogInfoService service get testStreamLog4NullNull ,oozie,1
storePassword getResource toCharArray serverSocket newSingleThreadExecutor Executors serverSslContext asList getServerSocketFactory Assert bind assertNotNull nopassword isWindows create Boolean SSLContextBuilder /test-client.p12 localhost startHandshake localPort loadKeyMaterial loadTrustMaterial resource2 thrown setSoTimeout /test-server.p12 resource1 accept contains testSSLHandshakeProtocolMismatch1 createSocket clientSslContext TIMEOUT Arrays supportedServerProtocols getSupportedProtocols getLocalPort submit supportedClientProtocols clientSocket SSLv3 TLSv1 assertTrue keyPassword close connect setEnabledProtocols call getSocketFactory expect build toMillisecondsIntBound socket getSession createServerSocket ,httpcore,0
conf Should have thrown an exception here asList testEntriesExpireIfBackgroundRefreshFails advance timer cacheGroupsAdd me  stops throw exceptions getGroups  load must be called synchronously as there is no key present CommonConfigurationKeys clearBlackList groups refresh FakeGroupMapping assertThat  will be retrievable until it is evicted after about 10 seconds. fail setLong myGroups size  We make an initial request to populate the cache setThrowException  Now make all calls to the FakeGroupMapper throw exceptions Arrays isEqualTo setBoolean ,hadoop,0
231 44 108 59 226 126 1 141 36 147  231 shifts to Base256 encodation 146 40 194 129 231 55 108 59 226 126 1 104 99 10 161 167 185 142 164 186 208 231 44 108 59 226 126 1 141 36 5 37 187 80 230 123 17 166 60 210 103 253 150  padding necessary at the end 231 63 108 59 226 126 1 141 36 5 37 187 80 230 123 17 166 60 210 103 1 129 231 38 220 2 208 120 20 150 35 Â«Ã¤Ã¶Ã¼Ã©Â» 231 38 219 2 208 120 20 150 35 Â«Ã¤Ã¶Ã¼Ã©Â» 23Â£ 1234567890123456789 146 40 190 87 Â«Ã¤Ã¶Ã¼Ã©Ã Â» assertEndsWith assertStartsWith visualized  Mixed Base256 + ASCII 33 153 235 36 129 assertEquals  220 142 164 186 208 58 129 59 209 104 254 150 45  23Â£ testBase256Encodation 231 44 108 59 226 126 1 104 createBinaryMessage  ASCII only (for reference) 231 51 108 59 226 126 1 104 99 153 53 129 Â«Ã¤Ã¶Ã¼Ã©Ã Ã¡Â» 231 51 108 59 226 126 1 141 254 129 Â«Ã¤Ã¶Ã¼Ã©Â» 234 encodeHighLevel ,zxing,0
/test/mkdirs File does not exist getMessage listStatus  does not exist. assertEquals getFileStatus of non-existent path should fail dir fs File  fail Exception doesn't indicate non-existant path listStatus of non-existent path should fail assertTrue getFileStatus fc testGetFileStatusOnNonExistantFileDir fe startsWith ,hadoop,1
"play User-Agent Baz=baz put setRequestProperty connection Collections write Cookie containsKey Foo setDefault getInputStream / getRequestProperties getUrl Content-type contains requestHeaders CookieHandler setDoOutput assertContainsAll Quux server request foo assertFalse cookieHandlerHeaders result putAll Cookie2 get emptyMap client Content-Length close keySet Quux: quux testHeadersSentToCookieHandler getHeaders takeRequest Cookie: Bar=bar singletonList Connection assertEquals Host Foo: foo Bar=bar       * The API specifies that calling getRequestProperties() on a connected instance should fail      * with an IllegalStateException, but the RI violates the spec and returns a valid map.      * http://www.mail-archive.com/net-dev@openjdk.java.net/msg01768.html       Cookie2: Baz=baz enqueue quux getOutputStream open ",okhttp,1
"deleteList addRecordToBundleActionTable getId actionC1 actionC2 actionA1 actionA2 deactivate Bundle Action A1 should not have been deleted Bundle Job A should not have been deleted Bundle Action A2 should not have been deleted Bundle Action C1 should not have been deleted jobB jobA assertNotNull  Remove fault injection jobC get testDeleteBundlesRollback Job getBundleId Bundle Job B should not have been deleted add Should have skipped commit for failover testing getCoordName Skipping Commit for Failover Testing addRecordToBundleJobTable Bundle Job C should not have been deleted getMessage assertEquals SkipCommitFaultInjection actionB1 execute actionB2 FaultInjection Bundle Action C2 should not have been deleted Services fail re org.apache.oozie.command.SkipCommitFaultInjection setSystemProperty true Bundle Action B1 should not have been deleted Bundle Action B2 should not have been deleted  set fault injection to true, so transaction is roll backed jpaService ",oozie,1
 Construct prepare XML block with the path  Parse the XML to get the node </prepare> doOperations <delete path=' Expected to catch an exception but did not encounter any Expected a LauncherException but received an Exception conf fs delete test/oozietests/testDelete/delete getDocumentFromXML createJobConf path trim Scheme not present in uri  LauncherMapper <prepare> '/> testForNullScheme getNamedItem item getAttributes  Delete the file if it is already there getDocumentElement getMessage assertEquals getFileSystem n getNodeValue fail  Construct a path without scheme newDir  Test for null scheme value in the path for action prepareXML exists doc le PrepareActionsDriver setupLauncherURIHandlerConf getChildNodes ,oozie,1
getBooleanWithDefault test Optional thenReturn NinjaConstant invoke when param1 empty booleanParamWithOptional context create verify booleanParamWithOptionalShouldHandleWrongInputForBooleanInStrictMode ninjaProperties mockController getParameter ,ninja,0
bundleJobGetCmd addRecordToBundleJobTable getId assertEquals getStatus execute call Services assertNotNull get testBundlePauseUnpause2 Job job jpaService ,oozie,1
 getClass </prepare> doOperations Expected to catch an exception but did not encounter any Expected a LauncherException but received an Exception conf fs delete getCause createJobConf Content is not allowed in prolog. LauncherMapper <mkdir path=' '/> actionDir  Delete the file if it is already there getMessage testDoOperationsWithInvalidXML assertEquals getFileSystem prepare>  Test to check if LauncherException is thrown when the prepare XML block is invalid fail newDir prepareXML exists le setupLauncherURIHandlerConf PrepareActionsDriver getFsTestCaseDir ,oozie,1
"setName user2Acl parsedList FsAction Parsed Acl not correct group1Acl parseAclSpec setPermission group::rwx,user:user1:rwx,user:user2:rw-, basicAcl user1 add user2 AclEntryScope AclEntryType expectedList AclEntry user1Acl assertEquals setType group:group1:rw-,default:group:group1:rw- group1 build defaultAcl setScope testMultipleAclSpecParsing ",hadoop,0
badMatrix setRegion expectedMatrix flipMatrix invertedCenterMatrix assertEquals fullMatrix matrix unset fail emptyMatrix clone xor centerMatrix dataMatrix testXOR ,zxing,0
"keys values  remove elements testBasicOperations  the element should not exist after remove  check all elements exist in the set and the data is correct  check the set size put remove  check all elements exist in the set and the data is updated to new value  generate new elements with same key, but new data get isZero getData newElements element isNotNull set generateElements cElements isFalse getKeys assertThat  put all elements isTrue contains size elements isNull  update the set isEqualTo  test LightWeightHashGSet#values ",hadoop,0
addRecordToBundleActionTable addRecordToWfActionTable coordActionGetCmd getNumDaysToNotBePurged testPurgeBundleWithCoordChildWithWFChild1 DateUtils WorkflowInstance getStatus addRecordToCoordActionTable parseDateOozieTZ bundleJob BundleJobBean assertNotNull CoordinatorAction Job wfAction wfJobGetCmd Bundle Action should not have been purged execute Bundle Job should not have been purged CoordinatorJob 1 coordJobGetCmd fail WorkflowAction coordAction SUCCEEDED Workflow Action should not have been purged bundleJobGetCmd getId coordJob wfJob addRecordToWfJobTable get Workflow Job should not have been purged WorkflowJob getAppName bundleAction wfActionGetCmd Coordinator Action should not have been purged 2011-01-01T01:00Z addRecordToBundleJobTable assertEquals getLastModifiedTime addRecordToCoordJobTable Coordinator Job should not have been purged call Services coord-action-get.xml jpaService bundleActionGetCmd ,oozie,1
ssBean getExpectedDuration getActualEnd getTime actEnd assertFalse getEventStatus EventStatus getExpectedStart setInsertList cal bean1 assertNotNull expEnd bean2 get _createSLASummaryBean getActualDuration isStartProcessed getActualStart setTime add getJobStatus actStart RUNNING getJobId _createSLACalcBean isEndProcessed workflow-1 Calendar assertEquals writeCmd expStart list readCmd2 execute readCmd1 scBean getExpectedEnd Services jpaService wfId testInsert ,oozie,1
actionNum testCoordActionGet prettyPrint XmlUtils  Pass expected values getCoordConf getId conf appPath addRecordToCoordJobTable resourceXmlName CoordinatorJob createCoordAction coord coord-action-get.xml _testGetForInputCheckX  Insert the action CoordinatorAction action insertRecordCoordAction toString job getFsTestCaseDir ,oozie,1
cancel addDelegationTokens boom conf Time when fs getRenewQueueLength sleep doAnswer getRenewToken now token1 token2 verify atMost myservice getConf doReturn renewer removeRenewAction assertEquals eq addRenewAction getService Thread testGetNewTokenOnRenewFailure doThrow setDelegationToken answer service mock atLeast renew getDelegationToken RENEW_CYCLE ,hadoop,0
"getConfString 2010-10-01T00:00Z conf DateUtils parseDateOozieTZ createInstancesELEvaluator TimeUnit expr event CoordELEvaluator setNominalTime XmlUtils  System.out.println(""OUTPUT :"" + eval.evaluate(expr, String.class)); parseXml <uri-template>file:///tmp/coord/US/${YEAR}/${MONTH}/${DAY}</uri-template></dataset></data-in> ${coord:current(0)} assertEquals <dataset name=""a"" frequency=""1440"" initial-instance=""2009-01-01T00:00Z"" freq_timeunit=""MINUTE"" timezone=""UTC"" end_of_duration=""NONE""> 2009-09-08T00:00Z setActualTime appInst setTimeUnit eval  -1)); <data-in name=""A"" dataset=""a""><uris>file:///tmp/coord/US/2009/1/30|file:///tmp/coord/US/2009/1/31</uris> testCreateInstancesELEvaluator dataEvntXML evaluate 2009-09-08T01:00Z ",oozie,1
"cluster NameNodeAdapter ns racks conf waitForReplication /rack2 /rack1 fs createFile testUnderReplicatedUsesNewRacks  All datanodes are on the same rack  sure at least one of the hosts on the new rack is used. DFSTestUtil b startDataNodes getConf newRacks filePath getFileSystem setReplication REPLICATION_FACTOR getNameNode /testFile build numDataNodes  Create a file with one block getFirstBlock shutdown getNamesystem     * Creates a block with all datanodes on the same rack. Add additional    * datanodes on a different rack and increase the replication factor,     * making sure there are enough replicas across racks. If the previous    * test passes this one should too, however this test may pass when    * the previous one fails because the replication code is explicitly    * triggered by setting the replication factor.     ",hadoop,1
getName getChecksumFile fsdos  the data file should be moved: dataFileLength  check that the files exist in the new location where they were moved: badFilesDir getFileStatus create checksumFsdis  check the the checksum file is created and not empty: setWritable pathToFile pathname accept dataFileName contains mkdirs fileSys writeUTF dir1files FileUtil isDirectory checksumFileLength foo dataPath dataFileFound badFiles assertTrue getLen retryIsNecessary checksumFileFound testReportChecksumFailure close listFiles  the checksum file should be moved: corruptedData dataFsdis toURI reportChecksumFailure length dir2 canWrite badFile dir1 checksumPath .crc equals  corrupted files storage: exists open base startsWith ,hadoop,0
oldToken testURLSelectTokenIpPort testURLSelectToken ,hadoop,0
date ALL scriptExecutor should_dsl_update_list_prepend session LOCAL_ONE  Given update simple Eq consistencylist consistencyList_PrependTo containsExactly QUORUM  When getList of where id row table executeScriptTemplate RandomUtils manager one nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap SELECT consistencylist FROM simple WHERE id =   Then Long buildDateKey fromBaseTable consistencyList dsl ,achilles,1
"normalizedHosts assertFalse testNormalizeHostName asList Network not resolving  UnknownHost123 oneHost StringUtils  for normalizing a resolvable hostname, resolved ipaddress is expected in return get 1.kanyezone.appspot.com getByName join ] localhost summary hosts normalizeHostNames  when ipaddress is normalized, same address is expected in return assertEquals  normalized [  return the same hostname after normalizing a irresolvable hostname. assumeTrue NetUtils ,   its ipaddress is expected to return equals Element 2 equal  Assume Element 1 equal  original [ Arrays InetAddress 127.0.0.1 ",hadoop,0
cluster  Create threads and make them run workload concurrently. initBuffer testFiles conf fs Waiting for thread  createFile System waitActive globalStatus assertTrue testComplexAppend Worker encountered exceptions.  retry numDatanodes join close replication add   DFSConfigKeys  wait for all transactions to get over start workload getFileSystem nextInt testComplexAppend fileContents stm numThreads AppendTestUtil setInt / testFile numberOfFiles dfs.support.append build numDataNodes  complete.  to complete... shutdown setBoolean .dat ,hadoop,1
getClass getPackage getName set before AvroReflectSerialization conf assertEquals SerializationTestUtil testSerialization after testReflectInnerClass ,hadoop,0
"<execution>LIFO</execution> </controls> <datasets>  xmlns=""uri:oozie:coordinator:0.2""> <controls> <timeout>10</timeout> <concurrency>2</concurrency>  conf </input-events>  appPath sc </property></configuration> </workflow> </action> </coordinator-app> writeToFile appXml <coordinator-app name=""NAME"" frequencyERROR=""10"" start=""2009-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""  <property> <name>inputB</name> <value>${coord:dataOut('LOCAL_A')}</value>  file:// getTestCaseDir UNIT_TESTING <dataset name=""local_a"" frequency=""120"" initial-instance=""2009-02-01T01:00Z""  <output-events> <data-out name=""LOCAL_A"" dataset=""local_a"">  timezone=""UTC""> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset>  coordinator.xml set <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  <dataset name=""a"" frequency=""60"" initial-instance=""2009-02-01T01:00Z""  call OozieClient fail testSchemaError getTestUser </datasets> <input-events>  <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>  Exception expected if schema has errors! <data-in name=""A"" dataset=""a""> <instance>${coord:latest(0)}</instance> </data-in>   File ",oozie,1
"testKeepaliveTimeouts  cached socket, and should have an xceiver on the other side. assertXceiverCount dn  give an EOF. dfsClient fs createFile sleep peer assertNotNull get  Clients that write aren't currently re-used. DFSTestUtil KEEPALIVE_TIMEOUT read assertEquals getInputStream Thread TEST_FILE size  from it again. readFile  and make sure the xceiver died. getDatanodeId ",hadoop,1
END_POINTS IS_SECURITY_ENABLED submit oozieUrl run conf appPath -submit assertNotNull get -config create workflow.xml createPropertiesFileWithTrailingSpaces testPropertiesWithTrailingSpaces SERVLET_CLASSES close confStr runTest app getContextURL getConf MockDagEngineService assertEquals getFileSystem args call OozieClient node -oozie mkdirs reset toString job getFsTestCaseDir ,oozie,1
payload1 payload2 payload3 inBuffer readableChannel Assert assertNotNull FrameType get of testReadFrameMultipleSmallBuffer getPayloadContent read frame3 frame1 valueOf frame2 getStreamId assertEquals ByteBuffer remaining FrameFlag allocate getType getFlags ,httpcore,0
bundleJobGetExecutor addRecordToBundleJobTable getId assertEquals getStatus execute testBundleStart1 call sleep Services size assertNotNull get bundleActionsGetExecutor isCritical Job job getBundleId jpaService actions ,oozie,1
request init chain set getRemoteAddr thenReturn destroy when testMissingHostname filter contains Assert assertNull Mockito HostnameFilter assertTrue doFilter response get mock invoked ??? ,oozie,1
" normalScript createNodeHealthScript timerTask Node health status reported healthy even after timeout assertFalse @echo off ping -n 4 127.0.0.1 >nul echo ""I am fine"" writeNodeHealthScriptFile conf run  Timeout script. NodeHealthScriptRunner  Normal Script runs successfully isHealthy sleep 4 echo ""I am fine"" Shell  Healthy script. Node health status reported unhealthy exit 127 assertTrue timeOutScript  Exit code 127 ERROR init  Error script. errorScript isEmpty getHealthReport assertEquals getTimerTask testNodeHealthScript echo ""I am all fine""  Run timer contains exitCodeScript nodeHealthScriptRunner Node health status reported healthy echo ERROR  echo ""Tracker not healthy"" ",hadoop,0
p@ssw0rd credential1 credential1 has been successfully  testTransientProviderWarning run assertEquals delete setConf deleted. cs user:/// rc -value contains -provider assertTrue transient provider. args1 create -f args2 toString outContent WARNING: you are modifying a  ,hadoop,0
cluster sub getCurrentUser conf lsr run assertTrue ugi root setPermission results UserGroupInformation getShortUserName createUserForTesting createTree tmpUGI getFileSystem runLsr tmpusername testLsr dfs 1 doAs contains build numDataNodes mkdirs zzz shutdown ,hadoop,1
@ :: closeTrx coordClient getStore getTime LocalOozie 2009-12-15T01:00Z Could not update db. getStatus 2009-12-17T01:00Z -testCoordRerun-C getCoordClient rerunScope get beginTrx CoordinatorAction reRunCoord actionNum2 commitTrx actionNum1 coord-rerun-action2.xml RestConstants printStackTrace store1 e store actionId2 addRecordToJobTable jobId actionId1 Services fail CoordinatorJob addRecordToActionTable assertNotSame testCoordRerunDate4 0000000- action1 action2 coord-rerun-action1.xml getCoordinatorAction ,oozie,1
"var-app-name checkCoordJobs </dataset>  </configuration> testBasicSubmitWithIncludeFile includePath conf <action> file:///tmp/include_xml/workflows/${YEAR}/${DAY} end=""2009-02-03T23:59Z"" timezone=""UTC"" xmlns=""uri:oozie:coordinator:0.2""> <controls>  </input-events>  <app-path>hdfs:///tmp/workflows/</app-path>  URI_TEMPLATE_INCLUDE_XML </datasets> <data-in> should be 2. One from coordinator.xml and the other from the include file assertNotNull file:// getTestCaseDir UNIT_TESTING processedJobXml </include> <dataset name=""B"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z"" timezone=""UTC""> </uri-template> getChild parseXml unchecked <execution>LIFO</execution> data-in URI_TEMPLATE_COORD_XML OozieClient jobId getChildren size <property> <name>inputA</name> <value>${coord:dataIn('inputB')}</value> </property>  getNamespace <workflow> -C  <input-events>  datainElements </workflow> <include>  </coordinator-app> </controls> job File <data-in name=""inputB"" dataset=""B""> <instance>${coord:latest(0)}</instance> </data-in>   <dataset name=""A"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z"" timezone=""UTC""> <coordinator-app name=""${appName}-foo"" frequency=""${coord:days(1)}"" start=""2009-02-01T01:00Z""  appPath substring include1.xml sc writeToFile appXml getJobXml uri-template </action> assertTrue get includeXml coordinator.xml set XmlUtils <datasets>  <data-in name=""inputA"" dataset=""A""> <instance>${coord:latest(0)}</instance> </data-in>   appName length <uri-template> assertEquals <configuration> file:///tmp/coord_xml/workflows/${YEAR}/${DAY} input-events call getChildText getTestUser namespace dataset ",oozie,1
fail adapterDoesNotSupport Assert adapter framework callMethod should not have been called runTests newFrameworkAndSetAdapter addTest execute isRequestSupported ,httpcore,0
allowSnapshot before sub1 assertFalse  Before a directory is snapshottable  After a directory is snapshottable path fsdir Assert assertTrue disallowSnapshot testAllowSnapshot hdfs toString after pathStr getINode ,hadoop,1
f0 f1 f2  Test that it can delete more than one file when necessary and that it works with non .gz files f3 f4 setMaxHistory cal f5 f6 f7 f8 oozie.log assertTrue getTestCaseDir blah.txt testDeletingOldFiles waitFor oozieLogPath add .gz  (instead of the time from the filename) Calendar getTimeInMillis  Test that it only deletes the oldest file (f1) getXLogService formatDateForFilename orp  only keep 3 newest logs  mock one instead. oozieLogName isTriggeringEvent exists createNewFile evaluate xls setLastModified ,oozie,1
Should have thrown JPAExecutorException printStackTrace e getId Error code should be E1022 addRecordToCoordActionTable execute addRecordToCoordJobTable System CoordinatorJob Services fail coord-action-get.xml getErrorCode assertNotNull get CoordinatorAction action coordRmvCmd testRunningActionDelete ErrorCode job jpaService ,oozie,1
uriHandlerFactory dt=09 getLauncherConfig handler getURIHandler dt=03 assertFalse uriService getPartitionDir conf delete year=2012;month=12;dt=02;country=us testDelete assertTrue getPartitions month=12;country=us uriHandler hcatURI table country=us dropTestTable assertEquals getFileSystem year=2012;month=12 createTestTable createPartitionForTestDelete getTestUser size location1 location2 exists db year=2012;month=12;dt=03;country=us getHCatURI ,oozie,1
_mkdirs defaultPerm testMkdirs_dirExists ,hadoop,0
add testDirectory testFile pathData getPathData ls options -e processOptions processArguments processPathFileDisplayECPolicyWhenUnsupported ,hadoop,0
"<execution>LIFO</execution> </controls> <datasets>  addRecordToBundleActionTable conf </input-events>  appPath sc </property></configuration> </workflow> </action> </coordinator-app> writeToFile appXml <property> <name>inputB</name> <value>${coord:dataOut('LOCAL_A')}</value>  file:// getTestCaseDir UNIT_TESTING <output-events> <data-out name=""LOCAL_A"" dataset=""local_a"">  Exception expected because namespace is too old when submit coordinator through bundle! Job timezone=""UTC""> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset>  coordinator.xml xmlns=""uri:oozie:coordinator:0.1""> <controls> <concurrency>2</concurrency>  set <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  <dataset name=""local_a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  call <coordinator-app name=""NAME"" frequency=""${coord:days(1)}"" start=""2009-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""  OozieClient fail getTestUser </datasets> <input-events>  <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>  <data-in name=""A"" dataset=""a""> <instance>${coord:latest(0)}</instance> </data-in>   COORD-NAME OOZIE-B <dataset name=""a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  File testBasicSubmitWithWrongNamespace ",oozie,1
cancel play server B dispatch nextResponse  has nothing left to wait for.  Force requests to be executed serially. assertNoResponse assertBody /a  client. /b getPath await client tag requestB requestA Character receiver takeRequest getDispatcher assertEquals setMaxRequests request A setBody request B canceledBeforeResponseReadIsNeverDelivered url getUrl enqueue build setDispatcher toString  yet it never will. ,okhttp,1
"createClient add set getUniqueActivationId 1000 createStage assertEquals  shouldn't collect anything, since clock is moving slowly clock actor1 bind cleanupTest stage size cleanup IActor client TimeUnit toMillis join getReference incrementTimeMillis ",orbit,1
" Brings back the backend user-group mapping service.  It should still get groups from the negative cache.  groups for the user is fetched. Failed to obtain groups from FakeGroupMapping.  In the first attempt, the user will be put in the negative cache. negcache conf  put into the negative cache asList advance timer cacheGroupsAdd  Let the elements in the negative cache expire. getGroups No groups found for user CommonConfigurationKeys e clearBlackList groups refresh GenericTestUtils FakeGroupMapping assertEquals testNegativeGroupCaching failMessage  The second time, the user is in the negative cache. fail setLong The user is still in the negative cache, even  myGroups addToBlackList assertExceptionContains The user is in the negative cache. FakeGroupMapping has resumed. Arrays user Did not throw IOException:  ",hadoop,0
reader skip conf keyX createScanner fs getBytes path fail closeOutput Assert getLen getFileStatus scanner lowerBound close Error on handling negative offset. testFailureNegativeOffset_2 open ,hadoop,0
isOrderSize isUseAtime isHumanReadable  check that default options are correct isOrderReverse ls assertFalse processOptionsNone isDirRecurse isRecursive isPathOnly assertTrue isOrderTime options processOptions isDisplayECPolicy ,hadoop,0
"enableInit ActionExecutor testActionExecutor ae IO start ActionExecutorException convertException cause assertEquals check getCause RMI  not registered, but subclass of IOException resetInitInfo fail ex RuntimeException initActionType getErrorCode rootCause disableInit getErrorType ",oozie,1
"types testContentTypes newArrayList Lists getContentTypes equalTo [application/json, application/x-www-form-urlencoded, application/xml] toString sort Collections assertThat createBodyParserEngineManager ",ninja,0
cluster conf getFileSystem  create two files getTestConfiguration build numDataNodes fileSys create /test/dfsclose/file-1 /test/dfsclose/file-0 testDFSClose close shutdown ,hadoop,1
longParam assertFalse context create verify hasViolations invoke mockController validation longParamShouldHandleNull ,ninja,0
getId assertEquals getStatus execute addRecordToCoordJobTable call CoordinatorJob Services coordJobGetCmd testCoordSuspendNegative assertNotNull get job jpaService ,oozie,1
numAttempts TEST_USER_NAME  Set the first expected url and add it back to the queue LDAP_NUM_ATTEMPTS_BEFORE_FAILOVER_KEY conf decrementAndGet LDAP_NUM_ATTEMPTS_KEY when getGroupsMapping remove search times groupsMapping setStrings assertTrue get verify getGroups add ldap://test set anyString isEmpty serverAttempts groups ldapUrls any setConf setInt DummyLdapCtxFactory nextLdapUrl setExpectedLdapUrl  Test that we made 6 attempts overall answer ldap://test2 ldap://test1 numAttemptsBeforeFailover LDAP_URL_KEY  Take the head of the queue and re-queue it to the back thenAnswer getBaseConf getContext  Number of attempts using a single ldap server url testFailover ,hadoop,0
cluster initBuffer conf testPipelineHeartbeat p= fs timeout System createFile sleep Wrote 1 byte and hflush  hflush  create a new file.  write another byte Failed to slowly write to a file write close DFSConfigKeys getFileSystem fileContents /pipelineHeartbeat/foo stm AppendTestUtil setInt Thread checkFullFile  verify that entire file is good fileLen p build numDataNodes DATANODE_NUM shutdown ,hadoop,1
testCoordSuspendWithErrorAndResumeWithErrorForRunning getId assertEquals getStatus execute addRecordToCoordJobTable call CoordinatorJob Services coordJobGetCmd assertNotNull get job jpaService ,oozie,1
getJobTrackerUri getName <java> testIdSwapSubmitOK createContext actionXml isSuccessful assertTrue context IDSWAP waitFor <job-tracker> getNameNodeUri </java> ae </main-class> <capture-output/> </job-tracker> getMessage runningJob getAction check <name-node> <main-class> </name-node> fail contains ex <arg>id</arg> submitAction evaluate isComplete ,oozie,1
 lm jobConf prepareBlock user.name  string when there is no prepare block in workflow XML or there is one with no prepare actions in it createJobConf oozie.action.prepare.xml 1@a assertTrue get getNameNodeUri testSetupLauncherInfoWithEmptyPrepareXML set actionConf 1@a-0 actionDir getAuthority Services 1 getTestUser equals fs.default.name setupLauncherInfo  Setting up the job configuration getFsTestCaseDir ,oozie,1
job1 getTime pauseStartRunnable addRecordToBundleJobTable run getId assertEquals getStatus execute Services jobId testStart2 assertNotNull get setKickoffTime Job job jpaService evaluate waitFor ,oozie,1
failsIfIdentifierDoesntMatch proxyProvider millisToSleep setIdentifier sleepAtLeastIgnoreInterrupts impl2 start run assertEquals impl1 RetryProxy result TypeOfExceptionToFailWith testFailoverBetweenMultipleStandbys RetryPolicies unreliable create failoverOnNetworkException ThreadUtil renamed-impl1 ,hadoop,0
request conn IllegalArgumentException expected Method testInvalidInput execute / fail Assert Mockito response executor HttpCoreContext context httprocessor create mock preProcess OK postProcess ,httpcore,0
getClientId OperationProto RpcConstants uuid RpcKind makeRpcRequestHeader assertTrue toByteArray equals ClientId ProtoUtil header testRpcClientId Arrays ,hadoop,0
 getParsedType  No null form primitives parseParameter asdfasdf is testPrimitiveDoubleParamParser Matchers assertThat param1 doubleParamParser 0 000 -123 123 0.1 123.1 -123.1 validation ,ninja,0
file   file fileItem  context.getParameterAsFileItem ninjaTestBrowser  Let's upload a simple txt file...   strFile strFile2 fileitem  sb result  compute excepted result file src/test/resources/test_for_upload_2.txt uploadFinishAuto  file fileItems file2  src/test/resources/test_for_upload.txt fileitems  getServerAddress uploadFiles inputstream   file inputstream assertEquals  file testThatUploadWorks IOUtils inputstreams   Let's see if that has worked... file2 toString files  getParameterAsFileItem  append  files  files inputstream  file2 ,ninja,0
testJobsStatus END_POINTS IS_SECURITY_ENABLED getContextURL oozieUrl getJobsInfo getAppPath MockDagEngineService assertEquals getId wc list call size assertNotNull get reset name=x SERVLET_CLASSES runTest ,oozie,1
Services callable assertTrue get testQueuing evaluate waitFor queueservice queue ,oozie,1
hdfs://x FS001 FS002 hdfs://z hdfs://x/ha getErrorCode assertTrue bla get testResolveToFullPath /bla hdfs://x/bla init FS011 ae destroy getMessage assertEquals HadoopAccessorService fail Services E0904 contains ex file://bla setSystemProperty resolveToFullPath ,oozie,1
#DFS-Hosts-excluded  excludesFile excludesLen assertFalse includesFile assertEquals getExcludedHosts     * Check if only comments can be written to hosts file     contains hfp size efw somehost5 #Hosts-in-DFS  ifw testHostFileReaderWithCommentsOnly write close getHosts includesLen ,hadoop,0
_index IOException expected. indexPath delete setOwner foo/bar Assert create harFileSystem setPermission +rwx group harPath testNegativeHarFsModifications rootPath fooPath setReplication +x fail mkdirs localFileSystem startLocalOutput createNewFile user  all the modification methods of HarFS must lead to IOE. copyFromLocalFile completeLocalOutput ,hadoop,0
formatDate play A server readAscii Date:  addHeader openConnection assertEquals source setBody setResponseCode / Cache-Control: max-age=0 enqueue getUrl getHeaderField responseSourceHeaderConditionalCacheNotFetched ResponseSource OkHeaders  304 TimeUnit connection ,okhttp,1
baseUrl a:b c&lt;:d e:&gt;  SERVLET_PATH_ECHO ?a=b&c<=d&e=> testEcho assertEquals ?a=b&c=d a:b c:d  readFromURL ,hadoop,0
"DFSTestUtil  set both of these to port 9000, should fail DFSConfigKeys set dfs.namenode.rpc-address ( e formatNameNode conf hdfs://localhost:9000 Got expected exception:  127.0.0.1:9000 System fail contains Assert setDefaultUri assertTrue Should have throw the exception since the ports match FileSystem toString testThatMatchingRPCandHttpPortsThrowException  verify we're getting the right IOException nameNode ",hadoop,1
"connectionFactoryNames#dynamicFactories/hcat.prod.${1} ctx1 java.naming.factory.initial#org.apache.activemq.jndi.ActiveMQInitialContextFactory;java.naming.provider.url# conf org.apache.activemq.jndi.ActiveMQInitialContextFactory HCatAccessorService get getJNDIPropertiesString vm://localhost?broker.persistent=false;connectionFactoryNames#dynamicFactories/hcat.prod.hcatserver  javax.management.InstanceAlreadyExistsException: org.apache.activemq:BrokerName=localhost,Type=Broker init set hcat://hcatserver.blue.server.com:8020 getJMSConnectionInfo printStackTrace getConf e  set the connection factory name hcatService jmsURL testConnectionContext destroy createConnection assertEquals services broker getJNDIProperties fail hcat://${1}.${2}.server.com:8020=java.naming.factory.initial# ;java.naming.provider.url#vm://localhost?broker.persistent=false; connInfo stop setupServicesForHCatalog Unexpected exception  ",oozie,1
bab addRecordToBundleActionTable cab getUser addRecordToWfActionTable getId WorkflowInstance getTopic addRecordToCoordActionTable coord-action-for-action-input-check.xml addRecordToWfJobTable get CoordinatorAction wab cjb bjb WorkflowJob Job testTopicAsUser getBundleActionId printStackTrace e addRecordToBundleJobTable getMessage jmsTopicService assertEquals addRecordToCoordJobTable fail Services 1 CoordinatorJob WorkflowAction wfj ,oozie,1
charset submit executorService Executors getCause testMultithreadingWriteStreamAbort getBytes writeCompleted sleep Assert 1234567890 getDuration assertTrue tmp get Boolean task1 write task2 outputBuffer newFixedThreadPool StandardCharsets assertEquals Thread getTimeUnit call ex abort TIMEOUT ,httpcore,0
2009-02-02T23:59Z getId run DateUtils WorkflowInstance getStatus addRecordToCoordActionTable parseDateOozieTZ coordJob sleep wfJob addRecordToWfJobTable assertNotNull get CoordinatorAction end testCoordActionRecoveryServiceForKilled WorkflowJob recoveryRunnable waitFor ret RUNNING wfGetCmd 2009-02-01T01:00Z start assertEquals execute addRecordToCoordJobTable CoordinatorJob Services wfJobId coord-action-get.xml jpaService evaluate ,oozie,1
p1 p2 test getKMSUrl kp anyString thenReturn keyName createKey conf eq any when testClientRetriesWithSSLHandshakeExceptionSucceedsSecondTime setInt CommonConfigurationKeysPublic times Mockito mock verify v1 thenThrow ,hadoop,0
" getAndAdvanceCurrentIndex isOne testDefaultPattern  Mux of size 2: 0 0 1 0 0 1 0 0 1, etc  Mux of size 1: 0 0 0 0 0, etc  Size 3: 4x0 2x1 1x2, etc assertThat mux  Size 4: 8x0 4x1 2x2 1x3 isZero isEqualTo ",hadoop,0
"gethgegwgeWgAwIBBaENGwtBQkNERUZHLk9SR6IcMBqgAwIBAKETMBEbBEhU z002pHnGzu/purZ5mOyaQT12vHxJ2T+Cwi8K testServicePrincipalDecode GAhamg9OQpuREIK0pCk3ZSHhJz8qMwduzRZHc4vNCg== spnegoOther GRI0sp9w3hc4IVm8afb3Ggm6PgRIyyGNdTzK/p03v+zA01MJh3htuOgLKUOV gethgegwgeWgAwIBBaENGwtFWEFNUExFLkNPTaIcMBqgAwIBAKETMBEbBEhU VFAbCW90aGVyaG9zdKOBsDCBraADAgERoQMCAQGigaAEgZ23QsT1+16T23ni z002pHnGzu/purZ5mOyaQT12vHxJ2T+Cwi8= krb5Default TjiQwKJckeZ837mXQAURbfJpFc3VLAXGfNkMFCR7ZkWpGA1Vzc3PeUNczn2D VFAbCWxvY2FsaG9zdKOBsDCBraADAgERoQMCAQGigaAEgZ23QsT1+16T23ni getPrincipal YIICCQYGKwYBBQUCoIIB/TCCAfmgDTALBgkqhkiG9xIBAgKhBAMCAXaiggHg FGH5DGGHvYF1CwXPp2l1Jq373vSLQ1kBl6TXl+aKLsZYhVUjKvE7Auippclb 2tOVzgpjFvAu/DETpIG/MIG8oAMCARGigbQEgbGWnbKlV1oo7/gzT4hi/Q41 Iqb7WuPIW3RTkFtwjU9P/oFAbujGPd8h/qkCszroNdvHhUkPntuOqhFBntMo JI1uFRU0FN13hhPSLAl4+oAqpV5s1Z6E+G2VKGx2+rUF21utOdlwUK/J5CKF BIIB3GCCAdgGCSqGSIb3EgECAgEAboIBxzCCAcOgAwIBBaEDAgEOogcDBQAg ff2luDnSxADEmo6M8LC42scsYMLNgU4iLJhuf4YLb7ueh790HrbB6Kdes71/ GwRIVFRQGwlvdGhlcmhvc3SjgbAwga2gAwIBEaEDAgEBooGgBIGdBWbzvV1R GwRIVFRQGwlsb2NhbGhvc3SjgbAwga2gAwIBEaEDAgEBooGgBIGdBWbzvV1R bilgTqNEdDUGvBbfkJaRklNGqT/IAOUV6tlGpBUCXquR5UdPzPpUvGZiVRUu GAhamg9OQpuREIK0pCk3ZSHhJz8qMwduzRZHc4vN gSBiLI2/mn3BqNE43gt94dQ8VFBix4nJCsYnuORYxLJjRSJE+3ImJNsSjqaf DiPfjPIPFOlc7V9GlWvZFyr5NMJSFwspKJXYh/FSNpSVTecfGskjded9TZzR HTTP/otherhost@ABCDEFG.ORG YIIB2AYJKoZIhvcSAQICAQBuggHHMIIBw6ADAgEFoQMCAQ6iBwMFACAAAACj assertEquals HTTP/localhost@EXAMPLE.COM AAAAo4HrYYHoMIHloAMCAQWhDRsLRVhBTVBMRS5DT02iHDAaoAMCAQChEzAR spnegoDefault krb5Other Lpu8sme55HFFQDi/0akW6Lwv/iCrpwIkZPyZPjaEmwLVALu4E8m0Ka3fJkPV YL+35r2762j+OEwZRfcj4xCK7j0mUTcxLtyVGxyY9Ax+ljl5gTwzRhXcJq0T AAAAo4HrYYHoMIHloAMCAQWhDRsLQUJDREVGRy5PUkeiHDAaoAMCAQChEzAR  for principals with the default realm, and a non-default realm. HxM4zfNsmzRFhdk5moJW6AWHuRqGJ9hrZgTxA2vOBIn/tju+n/vJVEcUvW0f hv/GGGex/TcjNH48k47OQaSBvzCBvKADAgERooG0BIGxeChp3TMVtWbCdFGo ",hadoop,0
getName The sink that will wait on putMetric when getTestFilename Test putMetrics find TimeUnit add onTimerEvent mr ms proceedSignal getAllValues capture test.sink.test.class input stop *.period TestMetricsConfig name mock metrics *.queue.capacity save  trigger metric collection first time qSize timeout Iterables doAnswer slowSink times assertTrue get await verify countDown value hadoop-metrics2-test reachedPutMetricSignal registerSink  its queue length should be 1 for the second collection. apply start assertEquals Sink_slowSinkQsize any The sink I'll use to get info about slowSink answer testQSize equals dataSink r1 ,hadoop,0
 localhost setHost //localhost:8443 testTolerateBlankInput setFragment CoreMatchers equalTo setPath setScheme assertThat setPort URI setUserInfo Assert build setCustomQuery create ,httpcore,0
next parent initFileSystem NON_EXISTENT_PATH  case 4: set permission assertFalse generator DEFAULT_UMASK createAndCheckPermission fs DEFAULT_PERMISSION  case 3: use permission 0643 and umask 0222 FILE_DIR_PATH checkPermission uMask  test directory creation setPermission  case 1: use default permission but all possible umasks closeFileSystem op getParent  case 2: use permission 0643 and the default umask getPermission  case 5: test non-existent parent directory permission  check permission setting works correctly for file or directory  expectedPermission testPermissionSetting r NUM_TEST_PERMISSIONS File shouldn't exists  test file creation exists OpType ,hadoop,1
getStats release sleep Assert updateExpiry assertTrue stats assertNotNull get of TimeUnit verify Collections close TimeValue getLeased singleton testCreateNewIfExpired entry1 conn1 assignConnection somehost pool assertEquals totals isDone Thread future1 getRoutes future2 Mockito CloseMode mock lease getTotalStats getAvailable ,httpcore,0
cluster .META. getRegionServerThreads conf testInfoServersAreUp master getRegionServer assertHasExpectedContent regionserver getPort http://localhost: port get /index.html getMaster getInfoServer  give the cluster time to start up ,hadoop,1
"aaa createTable getCachedRegionCount  create many regions for the table. assertFalse conf TEST_UTIL HTable  now we enable cached prefetch. testRegionCachePreWarm FAMILY  the total number of cached regions == region('aaa"") + prefeched regions. Bytes createMultiRegions getConnection  only one region should be cached if the cache prefetch is disabled. getConfiguration  Create table: assertTrue The table is disabled for region cache prefetch get Number of cached region is incorrect   if there is a cache miss, some additional regions should be prefetched. prefetchRegionNumber table  get the configured number of cache read-ahead regions clearRegionCache  disable region cache for the table. HConnectionManager bbb abc testCachePrewarm TABLENAME  A Get is suppose to do a region lookup request toBytes g setRegionCachePrefetch getRegionCachePrefetch assertEquals g2 g3 The table is enabled for region cache prefetch getInt hbase.client.prefetch.limit ",hadoop,1
"map-reduce yarn.resourcemanager.address executeWhileJobTrackerIsShutdown addRecordToWfActionTable  Make the max number of retries lower so the test won't take as long conf WorkflowInstance  It should now continue and finish with SUCCEEDED getJob context waitFor testActionCheckTransientDuringLauncher init getStatusStr job0 job2 job1 RUNNING parseXml destroy mapperId execute jobId 1 maxRetries  Disable ActionCheckerService so it doesn't interfere by triggering any extra ActionCheckXCommands WorkflowAction SUSPENDED SUCCEEDED actionId evaluate JobID setClassesToBeExcluded launcherId START_MANUAL assertFalse actionExecutor user.name getId getExternalId action1a createBaseHadoopConf hasIdSwap createJobConf action1b isSuccessful addRecordToWfJobTable getRetries assertTrue LauncherMapper get  When using YARN, skip this test because it relies on shutting down the job tracker, which isn't used in YARN WorkflowJob  Now, shutdown the job tracker to pretend it has gone down during the launcher job launcherJob getConf XmlUtils forName wfActionGetCmd oozie.action.retries.max org.apache.oozie.service.ActionCheckerService assertEquals services mrJob getExternalStatus Integer call originalLauncherId Services createJobClient setSystemProperty equals toString action0 jobClient action1 action2 jpaService user action3 action4 isComplete action5 ",oozie,1
payload1 payload2 payload3 inBuffer readableChannel Assert assertNotNull FrameType get of testReadFrameMultipleSmallBuffer getPayloadContent read frame3 frame1 valueOf frame2 getStreamId assertEquals ByteBuffer remaining FrameFlag allocate getType getFlags ,httpcore,0
buf Assert formatProtocolVersion HTTP/1.1 toString assertEquals HttpVersion testHttpVersionFormatting ,httpcore,0
server RPC configureSuperUserIPAddresses getProxySuperuserGroupConfKey GROUP_NAMES DefaultImpersonationProvider conf testRealUserAuthorizationSuccess Assert setStrings REAL_USER_SHORT_NAME refreshConf client setProtocolEngine setConfiguration UserGroupInformation proxyUserUgi printStackTrace e createRemoteUser group1 REAL_USER_NAME fail getTestProvider stop checkRemoteUgi setupTestServer PROXY_USER_NAME realUserUgi createProxyUserForTesting ,hadoop,0
play c3po data ping android  play it back assertStreamData headerEntries  verify the peer received what was expected robot acceptFrame stream TYPE_HEADERS peer getResponseHeaders TYPE_PING connection writeUtf8 takeFrame banana a b synReply remoteSendsDataAfterInFinished assertEquals  Ping just to make sure the stream was fastforwarded. HeadersMode  Ignored.  SYN_STREAM sendFrame SPDY3 getSource  PING synStream newStream ,okhttp,1
1 2 3 _testGetActions testWfActionsGet addRecordToWfJobTable WorkflowAction addRecordToWfActionTable getId WorkflowJob WorkflowInstance job ,oozie,1
zero add witness one assertSize clone clear assertEquals Arrays asList cloning cb ,logback,0
reader wfActionsGetCmd wf-test-kill-node-message.xml conf getStatus WorkflowInstance FAILED/KILLED assertNotNull getTestCaseDir /workflow.xml file:// action workflow.xml waitFor wfJobGetCmd bean external-status test testKillNodeErrorMessage execute OozieClient fail jobId size getType WorkflowAction copyCharStream getResourceAsReader job File evaluate actions submitJob end.error getWorkflowInstance error engine getErrorCode get end WorkflowJob TEST_ERROR a set assertEquals n Services IOUtils getTestUser t signal-value u equals writer jpaService getErrorMessage ,oozie,1
coord-rerun-action2.xml :: 2009-12-15T01:00Z 2009-12-16T01:00Z getId CoordUtils assertEquals getCoordActionsFromDates  test retrieval of action corresponding to range of dates (date1::date2); addRecordToCoordActionTable addRecordToCoordJobTable CoordinatorJob jobId testGetCoordActionsFromDateRange rerunScope coordActions size CoordinatorAction actionNum2 job coord-rerun-action1.xml actionNum1 ,oozie,1
docheckValidationFailedRegex validateJSR303WithOptional validationWithOptionalFailedRegex length buildDto context regex!!! ,ninja,0
NameValuePair testNullValuesEquals Assert NameValuePair2 hashCode name assertEquals ,httpcore,0
 save a copy of the headers to make sure they haven't changed at the end of this test. headersCopy deepcopy failed:  e deepMapCopy unchecked getMessage assertEquals put fail TestingFramework Assert HEADERS obj get headersMap deepMap deepcopy  now make sure the default headers have not changed for some unexpected reason. ,httpcore,0
getConnectionContext getEventMessage endDate errorCode conf parseDateUTC DateUtils getStatus coordActionSuccessMessage wf-app-name1 getEndTime caJobId1 caId1 CoordinatorAction 2012-07-22T00:00Z getStartTime MessageType 2011-07-11T00:00Z init printStackTrace getText fail contains createConsumer testOnCoordinatorJobSuccessEvent AppType startDate getParentId getAppType cae session coordEventListener assertFalse JMSMessagingUtils getEventStatus getUser EventStatus getId createSession getTopic onCoordinatorActionEvent jmsContext consumer user1 missingDependency getMessageType nominalTime receive getAppName e errorMessage getMessage assertEquals message setEndTime Session ,oozie,1
" endKey1 getRegionManager metaTableDesc endKey0 getTableDescriptor getStartKey  master.regionManager.onlineMetaRegions already contains first .META. region at key Bytes.toBytes("""") HConstants startKeyX getRegionName testGetFirstMetaRegionForRegionAfterMetaSplit tableDesc metaRegionInfo2 Bytes metaRegionInfo1 metaRegionInfo0 offlineMetaRegionWithStartKey regionInfo0 regionInfo1  } putMetaRegionOnline regionInfoX startKey0 meta2 getFirstMetaRegionForRegion address meta1  1st .META. region will be something like .META.,,1253625700761 meta0 startKey1 f toBytes h j assertEquals  2nd .META. region will be something like .META.,_MY_TABLE_,f,1253625700761,1253625700761  3rd .META. region will be something like .META.,_MY_TABLE_,j,1253625700761,1253625700761 m getMasterAddress master meta endKeyX getMaster _MY_TABLE_ ",hadoop,1
"getFilenum reader HConstants conf compareTo dir getRegionName tableName Bytes hri add val   logSeqId getKey toBytes getRow entry filename size startCacheFlush computeFilename idx next log testAppend fs System getKeyValues getTablename assertTrue  Get next row... the meta flushed row. row tablename close cols timestamp  Now open a reader on the log and assert append worked. COL_COUNT getReader column  1, 2, 3... completeCacheFlush assertEquals closeAndDelete Integer getValue dfs.support.append getFamily currentTimeMillis equals toString HLog append getEdit setBoolean ",hadoop,1
add p@ssw0rd credential1 Passwords don't match run assertEquals setConf rc contains setPasswordReader -provider passwords shell assertTrue testPromptForCredentialWithEmptyPasswd args1 create jceksProvider toString outContent ,hadoop,0
play  ACK android HTTP_20_DRAFT_09 headerEntries shouldntImpactConnection acceptFrame  This stream was created *after* the connection settings were adjusted.  ACK 2 assertTrue stream getInitialWindowSize peer DEFAULT_INITIAL_WINDOW_SIZE TYPE_SETTINGS connection Settings  HEADERS takeFrame settings a set setVariantAndClient initial ackFrame  New Stream is has the most recent initial window size. peerHttp2ServerLowersInitialWindowSize  initial wasn't affected. PERSIST_VALUE assertEquals sendFrame  verify the peer received the ACK newStream ,okhttp,1
"c testFairCallQueueMXBean assertEquals ManagementFactory put QueueSizes mockCall Hadoop:service=ns,name=FairCallQueue call take getAttribute fcq getPlatformMBeanServer mxbeanName mbs queueSizes ",hadoop,0
"testCoordActionsRunningForSize actionNum CoordinatorJob jobId       * Add 2 Coordinator actions with status RUNNING, 1 action with status FAILED and 1 with KILLED. Check for expected      * number of actions retrieved       coord-action-get.xml _testCoordActionsRunningSize CoordinatorAction getId job addRecordToCoordActionTable addRecordToCoordJobTable ",oozie,1
dev and test works. /0/1/2/mode/dev/and/test Request  Server runs in Test mode. This route is Dev & Test. CoreMatchers equalTo testDevAndTestMode012 assertThat makeRequest url path Assert response GET testServerUrl ,ninja,0
coordClient 2009-02-02T23:59Z LocalOozie coordActionGetCmd getId DateUtils getStatus addRecordToCoordActionTable parseDateOozieTZ coordJob getCoordClient testCoordRerunForBackwardSupport2 rerunScope assertNotNull get CoordinatorAction end reRunCoord init RestConstants 2009-02-01T01:00Z start destroy assertEquals services setAppNamespace execute - addRecordToCoordJobTable Integer Services CoordinatorJob coordJobGetCmd SchemaService setSystemProperty assertNotSame true StatusTransitService toString action1 action2 jpaService action3 coord-rerun-action1.xml ,oozie,1
"request conn resolve getRequest testProtocolException responseCaptor sendResponseHeader error when receiveRequestHeader oh, this world is wrong requestHandler Assert httpservice assertNotNull context create forClass verify getCode close process ArgumentCaptor HttpStatus thenReturn capture handle assertEquals sendResponseEntity assertSame getEntity whatever / getValue doThrow responseFactory Mockito response HttpCoreContext newHttpResponse httprocessor handleRequest handlerResolver ",httpcore,0
reader conf run getStatus getJob assertNotNull getTestCaseDir /workflow.xml file:// action workflow.xml waitFor actions2 bean actionCheckRunnable running-mode external-status test execute OozieClient jobId getType copyCharStream getResourceAsReader File evaluate actions submitJob WorkflowActionBean sleep actionsGetExecutor engine get ok WorkflowJob a set WorkflowAppService wf-ext-schema-valid.xml assertEquals async Services IOUtils getTestUser t signal-value based_on_action_status equals writer testActionCheckerService action2 jpaService ,oozie,1
Fbll9BuZDKV16WXeWGq+kTd7ETe7l0fqXjq5EnrifOai0L/pXwVvS2jrFkKQRlRxRGUNaeEBZ2Wy 9aTyR+HGHCfvwoCegc9rAVw/DLaRriSO/jnEXzYK6XLVKH+hx5UXrJ7Oyc7JjZUc3g9kCWORThCX Mzc1xA== parseRSAPublicKey b3AxDTALBgNVBAsTBFRlc3QxEjAQBgNVBAMTCWxvY2FsaG9zdDCBnzANBgkqhkiG9w0BAQEFAAOB PEM header getMessage 7OPuuaHb25J8isiOyA3RiWuJGQlXTdkCAwEAATANBgkqhkiG9w0BAQUFAAOBgQAdRUyCUqE9sdim -----BEGIN CERTIFICATE-----  c3QxEjAQBgNVBAMTCWxvY2FsaG9zdDAeFw0xNTAxMDIyMTE5MjRaFw0xNjAxMDIyMTE5MjRaMF8x C25fmU5H71WGOI1Kle5TFDmIo+hqh5xqu1YNRZz9i6D94g+2AyYr9BpvH4ZfdHs7r9AU7c3kq68V fail MIICOjCCAaOgAwIBAgIJANXi/oWxvJNzMA0GCSqGSIb3DQEBBQUAMF8xCzAJBgNVBAYTAlVTMQ0w  -----END CERTIFICATE----- se contains CzAJBgNVBAYTAlVTMQ0wCwYDVQQIEwRUZXN0MQ0wCwYDVQQHEwRUZXN0MQ8wDQYDVQQKEwZIYWRv assertTrue testInvalidPEMWithHeaderAndFooter jQAwgYkCgYEAwpfpLdi7dWTHNzETt+L7618/dWUQFb/C7o1jIxFgbKOVIB6d5YmvUbJck5PYxFkz CertificateUtil Should not have thrown ServletException pem CwYDVQQIEwRUZXN0MQ0wCwYDVQQHEwRUZXN0MQ8wDQYDVQQKEwZIYWRvb3AxDTALBgNVBAsTBFRl ,hadoop,0
"rpcuser:*:29:  maxint GET_ALL_GROUPS_CMD minint:x:2147483648:2147483648:Grid Distributed File System:/home/minint:/bin/bash  assumeNotWindows nfsnobody:*:4294967294:  daemon:x:2:2:daemon:/sbin:/sbin/nologin"" archivebackup:*:1031:4294967294:Archive Backup:/home/users/archivebackup:/bin/sh  HashBiMap uMap  | cut -d: -f1,3 maxint:x:2147483647:2147483647:Grid Distributed File System:/home/maxint:/bin/bash  maxint:*:2147483647:  assertTrue nfsnobody get create echo "" gMap group hdfs:*:11501:hrt_hdfs  mapred3:x:498"" minint nfsnobody:x:4294967294:4294967294:Anonymous NFS User:/var/lib/nfs:/sbin/nologin  GET_ALL_USERS_CMD assertEquals testIdOutOfIntegerRange daemon mapred3 size hdfs:x:11501:10787:Grid Distributed File System:/home/hdfs:/bin/bash  ShellBasedIdMapping nfsnobody1 hdfs :  Maps for id to name map nfsnobody1:*:4294967295:  user EMPTY_PASS_THROUGH_MAP archivebackup nfsnobody1:x:4294967295:4294967295:Anonymous NFS User:/var/lib/nfs1:/sbin/nologin  minint:*:2147483648:  updateMapInternal rpcuser ",hadoop,0
server /test2/ CuratorFrameworkFactory Reaper session reaper CloseableUtils /test3 /test1 /test2 sleepABit client create creatingParentsIfNeeded isZero connection forPath /test3/ stat getConnectString /test1/ checkExists timing start assertThat addPath newClient Integer forWaiting testMultiPath toString closeQuietly getNumChildren isEqualTo ,hadoop,0
isNullForInexistentPropertyShouldEvaluateToTrue buildAndAssertTrue isNullScriptStr ,logback,0
B END_POINTS IS_SECURITY_ENABLED submit testSubmitWithPropertyArguments oozieUrl assertFalse run appPath -submit get -config X create workflow.xml SERVLET_CLASSES close runTest -Da=X app a createConfigFile b getContextURL MockDagEngineService -Db=B assertEquals getFileSystem args call -oozie mkdirs wfCount toString job getFsTestCaseDir ,oozie,1
 URLEncodedUtils /this//that/%2Fthis%20and%20that this CoreMatchers equalTo testFormatSegments assertThat /this//that / that Assert /this/that /this///that// /this and that formatSegments ,httpcore,0
doCheckValidationFailedWithThreeFields length is now tooooo loooong buildDto context validateJSR303 validationFailedWithThreeFields regex!!! ,ninja,0
wfJobB addRecordToWfActionTable getId coordActionB WorkflowInstance addRecordToCoordActionTable addRecordToWfJobTable children assertNotNull get CoordinatorAction WorkflowJob coordJobB coordJobA wfJobA1 wfJobA2 execute addRecordToCoordJobTable testGetCoordinatorParent checkChildren Services CoordinatorJob 1 coordActionA2 coord-action-get.xml WorkflowAction coordActionA1 addAll SUCCEEDED jpaService wfActionA2 wfActionB wfActionA1 ,oozie,1
date scriptExecutor session  Given update simple Eq SELECT simpleset FROM simple WHERE id =  simpleset should_dsl_update_set_addAll containsExactly Sets  When of where id row simpleSet_AddAllTo table executeScriptTemplate RandomUtils manager getSet one nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap simpleSet newHashSet  Then Long buildDateKey fromBaseTable dsl ,achilles,1
testCoordActionGet _E errorCode getId DateUtils setTrackerUri replaceAll appPath setErrorCode parseDateOozieTZ resourceXmlName actionXml setErrorMessage setTimeOut coord actionNominalTime consoleUrl getTestCaseDir CoordinatorAction action setCreatedTime missDeps actionNum trackerUri  Pass expected values #testDir errorMessage getActionNominalTime setConsoleUrl setExternalStatus  Add some attributes testDir setMissingDependencies addRecordToCoordJobTable _testGetActionsSubset CoordinatorJob createCoordAction coord-action-get.xml file://#testDir/2009/29/_SUCCESS#file://#testDir/2009/22/_SUCCESS#file://#testDir/2009/15/_SUCCESS#file://#testDir/2009/08/_SUCCESS dummyCreationTime  Insert the action insertRecordCoordAction externalStatus job getCoordActionXml getFsTestCaseDir ,oozie,1
testBuildInitial instance setPath assertEquals DIR file assertTrue build getUsed createNewFile setKlass close setInitialUsed ,hadoop,0
request normal I2 assertEquals getID testConsiderKnownItems withConsider I7 target accept getValue considerKnownItems LIST_ID_VALUE_TYPE Assert size FLOAT_EPSILON /recommend/U4 get true MediaType queryParam ,oryx,1
testChunkNoExceed CodecTestUtils StandardCharsets channel assertEquals encoder Assert flush 4 1234 0   outbuf 1234 assertTrue metrics dump complete wrap write isCompleted ,httpcore,0
"END_POINTS IS_SECURITY_ENABLED getContextURL oozieUrl e length assertEquals UNSUPPORTED_VERSION : Supported version [2] or less, Unsupported versions[-11-10] wc substring call testUrls fail wrong version should run throw exception assertTrue v getOozieUrl toString SERVLET_CLASSES getProtocolUrl runTest startsWith ",oozie,1
writeLock gotAsyncCloseException channel Executors handlerLatch getCause sleepUninterruptibly WRITE exc  cause another thread trying to write to block assertTrue executor get await lock countDown write close MILLISECONDS set newFixedThreadPool expected  give enough time to ensure both writes start blocking store completed failed ByteBuffer READ fail allocate testAsyncClose_write future Uninterruptibles shutdown ,jimfs,1
 testFailInStart FailInStartService assertLaunchOutcome ,hadoop,0
intParamShouldBeParsedToInteger thenReturn context create verify invoke when 20 param1 mockController intParam getParameter ,ninja,0
"svc enteredState Injected RTE hm LOG HealthMonitor testCallbackThrowsRTE Mocking bad health check, waiting for UNHEALTHY waitForState addCallback info ",hadoop,0
getJobTrackerUri map-reduce conf getStatus createContext getJob  hadoop.counters will always be set in case of MR action. output Counter getExecutionStats assertNotNull <map-reduce> context create write waitFor <job-tracker> group group.name ae counters parseXml </job-tracker> dummy  getFileSystem check <name-node>  stats write property as false.  Assert for stats info stored in the context. </name-node>  configuration. input contains WorkflowAction SUCCEEDED getOozieActionExternalStatsWriteProperty submitAction getExternalChildIDs testSetExecutionStats_when_user_has_specified_stats_write_FALSE data.txt evaluate JobID launcherId  External Child IDs will always be null in case of MR action. assertFalse user.name getExternalId fs hasIdSwap createBaseHadoopConf actionXml isSuccessful assertTrue LauncherMapper get end close getData getNameNodeUri outputDir launcherJob XmlUtils forName false getAction assertEquals mrJob hadoop.counters inputDir getExternalStatus </map-reduce> Services createJobClient assertNull w toXmlString equals getVar toString jobClient user getFsTestCaseDir isComplete ,oozie,1
"regions log  Merge Region 0 and Region 1 getLog getRegionNameAsString HConstants System FAMILY result Bytes merging regions 0+1 and 2  Close the region and delete the log assertTrue logPath assertNotNull get mergeAndVerify merging regions 0 and 1 testMergeTool  Merge the result of merging regions 0, 1 and 2 with region 3 close  Merge the result of merging regions 0 and 1 with region 2 /tmp _ info LOG oldLogDir merged merging regions 0+1+2 and 3 j rows closeAndDelete  contain the right data. getRegionInfo getValue sorted addFamily bytes equals currentTimeMillis  Create a log that we can reuse when we need to open regions merging regions 0+1+2+3 and 4 toString Creating log   Merge the result of merging regions 0, 1, 2 and 3 with region 4 ",hadoop,1
 a l1 a:1-L a:2-L a:1-U a:2-U l2 start testReadLock assertEquals sb Thread sleep trim finish toString ,oozie,1
" the test is kinit'ed because the test renews _their TGT_.  Relogin every 1 second foo keytab HADOOP_KERBEROS_MIN_SECONDS_BEFORE_RELOGIN conf principals bogus-kinit-cmd hadoop.kerberos.kinit.command System setAuthenticationMethod principal logout ugi getPath await testAutoRenewalThreadRetryWithKdc workDir  TestUserGroupInformation#testGetNextRetryTime setConfiguration value UserGroupInformation info add set getProperty setLogLevel test.dir  no ticket cache, so force the thread to test for failures. count GenericTestUtils kdc loginUserFromKeytab getRenewalFailures loginContext getLoginUser spawnAutoRenewalThreadForUserCreds target foo.keytab setLong Renew failure count is {} LambdaTestUtils createPrincipal Level SecurityUtil setupKdc ",hadoop,0
http://host3:9600/kms/foo/v1/ testCreation kp getKMSUrl getProviders kms://http@host1;host2;host3:9600/kms/foo http://host1:9600/kms/foo/v1/ conf assertEquals createProvider newHashSet assertTrue Sets http://host2:9600/kms/foo/v1/ kms://http@host1:9600/kms/foo providers ,hadoop,0
getBytesTransferred CodecTestUtils channel stuff-more stuff times Assert flush verify dump write more stuff; and a lot more stuff ArgumentMatchers StandardCharsets assertEquals encoder - any never Mockito outbuf metrics spy wrap testCodingFragmentBufferingMultipleFragmentsBeyondContentLimit stuff ,httpcore,0
HConstants conf sessionID System sleep getConnection password getSessionPassword  5 seconds connection getQuorumServers getSessionID close HConnectionManager EmptyWatcher zkw relocateRegion getZooKeeperWrapper connectionZK Thread ZooKeeper should have timed out zk testClientSessionExpired quorumServers sessionTimeout ,hadoop,1
"init ${coord:dateOffset(""2009-09-08T23:59Z"", 2, ""DAY"")} 2009-09-10T23:59Z CoordELFunctions assertEquals coord-action-start ${coord:dateOffset(""2009-09-08T23:59Z"", 1, ""YEAR"")} coord-job-submit-data eval evalAndWrap 2010-09-08T23:59Z ${coord:dateOffset(""2009-09-08T23:59Z"", -1, ""DAY"")} 2009-09-07T23:59Z expr testDateOffset ",oozie,1
test-new.mapfile ERROR_MESSAGE NEW_FILE_NAME MapFile conf fs when Could not rename cleanupWithLogger assertTrue FileSystem close TEST_DIR spyFs testRenameWithException no exception error !!! LOG testRenameWithFalse invalid IOExceptionMessage error !!! thenReturn getMessage oldDir fail IOUtils createWriter ex test-old.mapfile rename testRenameWithFalse getLocal newDir OLD_FILE_NAME toString writer spy startsWith ,hadoop,0
"init getName set oozie.service.ProxyUserService.proxyuser.foo.hosts getConf oozie.service.ProxyUserService.proxyuser.foo.groups destroy conf * services , asList Services fail testWrongHost otherhost StringUtils join Arrays ",oozie,1
next  then buildRoute testThatGlobalFiltersInRouteReplaceGlobalFiltersInConfFilters NinjaConstant equalTo getFilterChain when filterChain result get context getProvider verify injector  when thenReturn filterProvider Matchers assertThat ninjaBaseDirectoryResolver / with never  different setup that uses com.example packages and thus reads the Filters there route Mockito expectedResult GET dummyFilter2 mock routeBuilder com.example ninjaProperties globalFilters ,ninja,0
setKeyManagerFactory isFactoryCreated setKeyStore factoryBean createContext setTrustManagerFactory  verifying that SSL is configured properly KEY_STORE_MESSAGE_PATTERN TRUST_STORE_MESSAGE_PATTERN secureRandom keyManagerFactory assertTrue assertNotNull setSecureRandom context trustManagerFactory setTrustStore SSL_CONFIGURATION_MESSAGE_PATTERN isKeyStoreCreated SECURE_RANDOM_MESSAGE_PATTERN testCreateContext hasInfoMatching keyStore TRUST_MANAGER_FACTORY_MESSAGE_PATTERN trustStore isSecureRandomCreated KEY_MANAGER_FACTORY_MESSAGE_PATTERN ,logback,0
hcatURI1 server addRecordToCoordJobTableForWaiting hcatserver CoordELFunctions hcatURI3 hcatURI2 getId getWaitingActions default /dt=20120430;country=usa coord-action-for-action-input-check.xml assertTrue get CoordinatorAction coord-job-for-action-input-check.xml Z addRecordToCoordActionTableForWaiting testCoordKillRemovePushMissingDeps tablename table init addMissingDependency printStackTrace newHCatDependency2 e newHCatDependency1 newHCatDependency3 hcat:// getMessage destroy services pdms / pushMissingDeps call fail Services CoordinatorJob contains assertNull setupServicesForHCatalog /dt=20120430;country=russia /dt=20120430;country=brazil action1 job action2 db ,oozie,1
privateClone getAllTokens getCredentials getKind getBytes password regular-token ugi  Ensure only non-private tokens are returned tokens PRIVATEUSERS UserGroupInformation createUserForTesting addToken tokenId service1 assertEquals privateUser private-token1 private-token token size  Now add cloned private token service testPrivateTokenExclusion ,hadoop,0
key1 testInvalidProvider ks run assertEquals setConf AES rc contains -provider assertTrue args1 create toString KeyShell -cipher sdff://file/tmp/keystore.jceks outContent ,hadoop,0
 to %s for test.time.warn 23h 1441m DAYS String logDeprecation hchk warnFormat getTimeDuration get  check warn for possible loss of precision add wconf  no warning set test.time.warn warnchk SECONDS format clear setTimeDuration 10us assertEquals message dchk 30m convDAYS HOURS size testTimeDurationWarning 40s wchk MINUTES Possible loss of precision converting %s 40000ms ,hadoop,0
getBuildInfo END_POINTS getProperty IS_SECURITY_ENABLED getContextURL oozieUrl assertEquals wc getServerBuildVersion call testServerBuildVersion BuildInfo SERVLET_CLASSES runTest ,oozie,1
add isOrderSize isUseAtime isHumanReadable isOrderReverse ls assertFalse -u isDirRecurse processOptionsAtime isRecursive isPathOnly  chheck the -u option is recognised assertTrue isOrderTime options processOptions isDisplayECPolicy ,hadoop,0
play def Okio goAway Util headerEntries stream was reset: REFUSED_STREAM getSink getBytes TYPE_HEADERS variant TYPE_PING connection buffer PROTOCOL_ERROR banana expected UTF-8  Ensure that the GO_AWAY has been received. fail Arrays newStream shutdown ping  play it back android TYPE_DATA  verify the peer received what was expected  SYN_STREAM 3  SYN_STREAM 1 cola acceptFrame flush openStreamCount assertTrue receiveGoAway peer roundTripTime writeUtf8 close takeFrame a  DATA STREAM 1 b abc c setVariantAndClient stream1 stream2 data1 getMessage assertEquals synStream1 synStream2 sendFrame SPDY3 equals  PING sink2 abcdef sink1 ,okhttp,1
RestConstants getTime 2009-12-15T01:00Z getId assertEquals coordJobGetExecutor getStatus addRecordToCoordActionTable execute call getPauseTime testCoordRerunInPaused Services pauseTime assertNotNull get CoordinatorAction curr Job job jpaService coord-rerun-action1.xml addRecordToCoordJobTableWithPausedTime ,oozie,1
getClass  fail due to insufficient number of arguments getName validateCommand testCommandOptions assertFalse foo.bar:8080 className DEBUG -foo  fail due to the extra argument -getlevel assertTrue -protocol -setlevel http https  valid command arguments blah ,hadoop,0
Integer set array getBitArray ints assertEquals testGetArray ,zxing,0
handler request getTime jwt alternateAuthentication should NOT have thrown a ServletException:  publicKey setPublicKey JWTRedirectAuthenticationHandler when put alternateAuthentication should NOT have thrown a AuthenticationException se jowt SERVICE_URL Assert getCookies getJWT getUserName getRequestURL testCustomCookieNameJWT init cookie thenReturn getProperties encodeRedirectURL getMessage alternateAuthenticate assertEquals props token fail privateKey serialize bob Mockito response mock ,hadoop,0
setBindAddress setNumHandlers e setProtocol conf setVerbose setPort  Test mandatory field protocol fail Didn't throw HadoopIllegalArgumentException build ADDRESS Expecting HadoopIllegalArgumentException but caught   Test mandatory field conf  Test mandatory field instance testRPCBuilder setInstance ,hadoop,0
"Transfer-Encoding addHeader keepAlive Connection chunked yadda, kEEP-alive, dumdy Assert assertTrue response context testConnectionTokens2  Use HTTP 1.1 reuseStrategy OK ",httpcore,0
urlto:foo:bar.com testURLTOType http://bar.com URLTO::bar.com URLTO::http://bar.com foo http://bar.com URLTO:foo:bar.com ParsedResultType doTestResult ,zxing,0
next Next key should be always equal or more Value: reader prev assertFalse conf  test iteration  Merge all 5 files path iterator assertTrue merge get startValue Collections value TEST_DIR key add TEST_METHOD_KEY testMerge set testMerge.mapfile in  Sort expected values createReader intValue SIZE expected start j assertEquals inputs should be deleted sort getFileSystem . createWriter  inputs should be deleted ITERATIONS expectedIterator reset exists writer append merger ,hadoop,0
Lambdas anyInstanceMethodReference apply getImplClass getImplMethodName replace ()Lninja/Result; getCanonicalName is getKind serializedLambda assertThat getFunctionalInterfaceMethodName getCapturedArgCount home lambda reflect Kind getSerializedLambda getImplMethodSignature lambdaInfo ,ninja,0
add e start getMessage tsl Could not open [  should be greater than or equal to 1 input/joran/ filename size assertTrue doTest CoreTestConstants nothereBLAH.xml get inexistentFile context getStatusManager s0 startsWith ,logback,0
reader getTempPath keyClass conf fs delete path file SequenceFile sequencefile.sync.test stream FileSystem getLen getFileStatus  Uses the default sync interval of 100 KB NUMRECORDS  this sync interval close writeSequenceFile val  try different SequenceFile.Reader constructors in length start GenericTestUtils io.file.buffer.size buffersize input getInt forOffset getLocal valueClass writer compression testDefaultSyncInterval CompressionType open bufferSize ,hadoop,0
request _execQuery getStatus addRecordToCoordActionTable asList FAILED testDefaultStatus get CoordinatorAction Coord3  adding coordinator action #4 to Coord#3 KILLED add assertEquals getAction brList resultStatus coord-action-get.xml size bundleName possibleStatus  4 actions satisfy the conditions toString ; Arrays bundle= ,oozie,1
testTimeUUIDWithClockResolution  than the first one. assertEquals clock compareTo TimeUUIDUtils second createClock createTime  Test improved algorithm. assertTrue getTimeUUID UUIDGen getClockSeqAndNode toString time fromString first ,hector,1
a fail b c resolveFunction testContextFunctions addFunction functionC functionB functionA assertEquals support ,oozie,1
 getParsedType  No null form primitives parseParameter asdfasdf is Matchers assertThat testPrimitiveFloatParamParser param1 0 000 -123 123 0.1 floatParamParser 123.1 -123.1 validation ,ninja,0
verifyZeroInteractions getTemplate thenReturn SecureFilter testUnauthenticatedSession sessionCookie NinjaConstant assertEquals when filterChain result filter basicAuthFilter get context getSession  filter that ,ninja,0
server getLocalPort ContentType createClientSSLContext setSslContext consume bootstrap setConnPoolListener request1 some stuff setEntity createServerSSLContext setSocketConfig sslParameters context create https /stuff setExceptionListener requester localhost SSLTestContexts SocketConfig setStreamListener custom LoggingHttp1StreamListener start * setSoTimeout Method getEntity execute setSslSetupHandler ServerBootstrap testTLSClientAuthFailure target EntityUtils LoggingConnPoolListener build LoggingExceptionListener RequesterBootstrap TIMEOUT response1 setNeedClientAuth register ,httpcore,0
getRecoveryPath chmod1 chmod2 source getStatus createContext getPath context getFileStatus setId action ID id mkdir getPermission ae format <chmod path=''{4}'' permissions=''-rwxrwxrwx''/> getFileSystem check rwxrwx--- ex WorkflowAction testRecovery mkdirs -FS <chmod path=''{5}'' permissions=''-rwxrwx---'' dir-files=''false''/> <mkdir path=''{0}''/> <chmod path=''{5}'' permissions=''222'' dir-files=''false''/> getWorkflow setJobId FS001 assertFalse <fs> getActions child2 fs delete System child1 actionXml getErrorCode assertTrue <move source=''{2}'' target=''{3}''/> get </fs> end OK getData MessageFormat <delete path=''{1}''/> toUri <chmod path=''{4}'' permissions=''111''/> start getAction assertEquals getExternalStatus rwxrwxrwx target assertNull currentTimeMillis equals assertNotSame exists toString getFsTestCaseDir ,oozie,1
" Never flush A B 25, 50, 75 C  4 out of 8 calls ns Hadoop:service= conf forceDecay testPriority ManagementFactory scheduler getAttribute  2 out of 6 calls assertTrue Get expected JMX for CallVolumeSummary after decay Get expected JMX of CallVolumeSummary before decay  0 out of 2 calls getPlatformMBeanServer  1 out of 1 calls  5 out of 9 calls mxbeanName getPriorityIncrementCallCount CallVolumeSummary set  0 out of 4 calls DecayRpcScheduler ,name=DecayRpcScheduler 99999999 assertEquals {""A"":3,""B"":1,""C"":1}  3 out of 7 calls deprecation .  1 out of 3 calls  0 out of 0 calls equals namespace  1 out of 5 calls cvs2 {""A"":6,""B"":2,""C"":2} mbs cvs1 ",hadoop,0
cluster  kill a datanode e filePath getMessage conf getFileSystem nextInt fs AppendTestUtil out /testExcludedNodes fail build numDataNodes testExcludedNodes create write DataNode failure should not result in a block abort:   close stopDataNode ,hadoop,1
"getSubject getCurrentUser getName  create a new ugi instance based on subject from the logged in user. keytab run AuthenticationMethod when logout barrier relogin executor second relogin didn't block! ugi reloginFromKeytab getPath TimeUnit  another concurrent re-login should block. getUserName UserGroupInformation  create a keytab ugi. getUGIFromSubject currentThread  credentials corruption, but getting a ugi for the subject does not block.  is blocked. kdc loginUserFromKeytabAndReturnUGI fail invocation doAs spyLogin isSecurityEnabled createPrincipal  relogin. spy setName  are atomic. doNothing submit getUser assertFalse user1.keytab clonedUgi login principal doAnswer assertTrue get await  knows from its login params that it is supposed to be from a keytab. latch testUser workDir countDown  know it's supposed to be from a keytab. callRealMethod clonedRelogin testConcurrentRelogin assertEquals isDone first relogin didn't block Thread getLogin call answer Mockito setLogin getAuthenticationMethod user loginUgi isFromKeytab ",hadoop,0
actionNum testCoordActionGet _testGetActionForCheck _E getId XDataTestCase addRecordToCoordJobTable CoordinatorJob createCoordAction coord-action-get.xml  Insert the action CoordinatorAction setSlaXml action insertRecordCoordAction job ,oozie,1
FILE_FOOTER FILE_HEADER PRESENTATION_FOOTER headerFooterCheck PRESENTATION_HEADER smoke PRESENTATION_FOOTER  FILE_HEADER  ,logback,0
-timezone END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL oozieUrl testJobStatus MockDagEngineService run assertEquals -localtime -info 0 args PST call 1 2 -oozie size reset job SERVLET_CLASSES runTest ,oozie,1
"request  by the request handler, and a 200 should actually be returned. adapter assertEquals responseExpectations execute put tempResponseExpectations STATUS Assert requestHandler framework runTests response get newFrameworkAndSetAdapter defaultURI addTest changeResponseStatus  It is an unmodifiable map. ",httpcore,0
END_POINTS -doas IS_SECURITY_ENABLED submit oozieUrl run oozie.authentication.simple.anonymous.allowed appPath -submit getTestUser2 -config create workflow.xml SERVLET_CLASSES close runTest app createConfigFile getContextURL testSubmitDoAs false MockDagEngineService assertEquals getFileSystem args call -oozie setSystemProperty mkdirs toString job getFsTestCaseDir ,oozie,1
getResource Configuration value2 value1 jsonStr  add 2 keys testDumpConfiguratioWithoutDefaults mapper jconf appendProperty put out  check the final tag CONFIG addResource prop get  check for case when default resources are not loaded close  check the resource for each property readValue getKey  ensure that no properties are loaded. confDump getProperties endConfig assertEquals startConfig dumpConfiguration  ensure the values are consistent  ensure only 2 keys are loaded getValue getIsFinal outWriter toString test.key1 fileResource config test.key2 ,hadoop,0
"cluster  The block now has sufficient # replicas, across racks testReduceReplFactorDueToRejoinRespectsRackPolicy ns racks  not on the restarted datanode as that would violate the rack policy. dm conf /rack2 getBlockManager waitForReplication /rack1 fs createFile rack2 waitActive     * Test that when the excess replicas of a block are reduced due to    * a node re-joining the cluster the rack policy is not violated.     getDatanodeManager get stopDataNode DFSTestUtil b getDataNodes startDataNodes getConf filePath  to heartbeat by stopping it and calling removeDatanode. assertEquals dnId getFileSystem dataNode  available and only 2 replicas required). REPLICATION_FACTOR getNameNode datanodes /testFile  Last datanode is on a different rack size build removeDatanode numDataNodes  Create a file with one block getFirstBlock shutdown getDatanodeId getNamesystem ",hadoop,1
ninjaCache testSafeAddChecksSerializable safeAdd notSerializable ,ninja,0
getBytesTransferred rw stuff;  CodecTestUtils more stuff;  channel Assert inbuf getChannel pos stuff; more stuff; a lot more stuff! a lot more stuff!!! close fchannel isCompleted testfile StandardCharsets length bytesRead assertEquals createTempFile decoder fill transfer readFromFile metrics testDecodingFileWithBufferedSessionData ,httpcore,0
getConf  TODO: Delete these two lines once uber mode is set back to the default (OOZIE-1385)  default -- should set to true assertFalse false  action conf set to true -- should keep at true conf assertEquals jae mapreduce.job.ubertask.enable testInjectLauncherUseUberMode Services assertNull injectLauncherUseUberMode  action conf set to false -- should keep at false oozie.action.launcher.mapreduce.job.ubertask.enable get true  default -- should not set getBoolean  disable at oozie-site level (default is to be enabled) -- redo above tests setBoolean ,oozie,1
allow assertFalse generateId save principals getUserManager remove createGlobRestriction group2_ path getPrincipal acMgr getTestGroup /* add hasPrivileges createGroup deny readPrivs group3 group2 testGlobRestriction2 privilegesFromName modify childNPath group3_ Privilege superuser ,jackrabbit,1
initialCallable callables type keyInt queueservice initialKey assertTrue get initialType lockKey waitFor key EXEC_ORDER add init c initialLockKey retValue CallableQueueService destroy 0 Services 1 testKill intCallable setSystemProperty       * Assuring the interrupts will not be inserted in the map when it reached      * the max size       evaluate queue testMaxInterruptMapSize ,oozie,1
in getTestString before UTF-8  test that it reads correctly readString assertEquals  generate a random string after3 out after2 testIO  test that it reads correctly with DataInput  write it readUTF UTF8  test that it is compatible with Java's other decoder reset getLength after writeString getData ,hadoop,1
END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL oozieUrl MockDagEngineService conf assertEquals wc kill call OozieClient 1 testKill setProperty createConfiguration SERVLET_CLASSES runTest ,oozie,1
getBytesTransferred CodecTestUtils channel stuff-stuff times Assert flush verify dump write ArgumentMatchers StandardCharsets length assertEquals testCodingFragmentBufferingBufferFlush encoder any -stuff Mockito outbuf metrics spy wrap stuff ,httpcore,0
testDelegationTokenAuthenticatedURLWithNoDT testDelegationTokenAuthenticationURLWithNoDTFilter ,hadoop,0
formatDate request headers addHeader getHeaders clientSuppliedIfModifiedSinceWithCachedResult assertFalse assertClientSuppliedCondition If-Modified-Since:  ETag: v3 Cache-Control: max-age=0 contains assertTrue response ifModifiedSinceDate TimeUnit If-Modified-Since If-None-Match: v3 ,okhttp,1
executeScriptTemplate actual RandomUtils scriptExecutor manager incr session one  Given nextLong SELECT * FROM entity_counter WHERE id =  assertThat execute ImmutableMap crud EntityWithCounterColumn/insert_single_row.cql  When of  Then isNull Long deleteById id should_delete_by_id ,achilles,1
addRecordToBundleActionTable _testGetForJobCount addRecordToBundleJobTable getId action1 Job job action2 action3 testBundleActionsForJobCountGet ,oozie,1
Mandatory request header ':scheme' not found headers testConvertFromFieldsMissingScheme custom converter thrown convert www.example.com asList expectMessage / expect :method GET :path Arrays value :authority ,httpcore,0
10.119.103.112 10.113.221.222 10.222.103.121 is  in the list 10.113.221.221 assertFalse 10.222.103.121 is not in the list 10.221.102.0/23 cipl ips 10.222.103.121 Thread sleep createFileWithEntries removeFile assertTrue ips.txt TestFileBasedIPList ips2 testRemovalWithSleepForCacheTimeout 10.222.0.0/16 10.113.221.222 is in the list 10.113.221.222 is not in the list isIn ,hadoop,0
"RecoveryService getName CoordELFunctions addInitRecords run getWaitingActions getStatus /dt=20120430;country=usa CoordinatorAction newHCatDependency init getJMSConnectionInfo hcatService waitingActions populateTable destroy jmsService ,  dep1 is not available and dep2 is available  Register the missing dependencies to PDMS assuming CoordPushDependencyCheckCommand did this. pdms . / setLong contains size isListeningToTopic /dt=20120430;country=brazil actionId server assertFalse sleep default assertTrue URIHandlerService get tablename recoveryRunnable table ca addMissingDependency set getConf newHCatDependency2 newHCatDependency1 hcat:// hcat. assertEquals services  and newHCatDependency1 should be in PDMS waiting list assertNull setupServicesForHCatalog checkCoordActionDependencies db testCoordActionRecoveryServiceForWaitingRegisterPartition ",oozie,1
next  then buildRoute NinjaConstant equalTo getFilterChain when filterChain result get context getProvider verify injector  when thenReturn dummyFilter filterProvider filters Matchers assertThat ninjaBaseDirectoryResolver / with  different setup that uses com.example packages and thus reads the Filters there route Mockito expectedResult GET mock routeBuilder com.example getInstance ninjaProperties testGlobalFilters ,ninja,0
cluster ncfb getName conf waitActive  Validate we get all the corrupt files  now get the 2nd and 3rd file that is corrupt toArray storageDir equalsIgnoreCase info DFSConfigKeys getBlockPoolId LOG  deliberately remove blocks from a file and validate the list-corrupt-file-blocks API listCorruptFileBlocks  test the paging here Deliberately removing file  count testlistCorruptFileBlocks getFileSystem Cannot remove file. setInt getNameNode blk_ setLong testGetCorruptFiles util size cleanup getInstanceStorageDir idx  datanode scans shutdown /goodData getFinalizedDir bpid /corruptData fs namenode delete sleep assertTrue  delete the blocks listFiles cfb data_dir  validate MiniDFSCluster blocks Namenode has bad files.  nextCorruptFileBlocks getBlockName j corruptFileBlocks  directories Thread createFiles build  (blocks.length > 0)); numCorrupt getNamesystem startsWith ,hadoop,1
failedControllerRegistration with route e assertTrue GET buildRoute /failure routeBuilder DoesNotExist injector ,ninja,0
newMatcher Assert assertTrue matcher UriPatternType testUriPattern ,httpcore,0
cluster getName Starting test testDecommission conf All datanodes must be alive numNamenodes startCluster decommissionedNodes get iteration client testDecommission numDatanodes writeFile cleanupFile info checkFile add  Start decommissioning one namenode at a time getDfsClient LOG datanodeReport replicas decomNode  Decommission one node. Verify that node is decommissioned.  Ensure decommissioned datanode is not automatically shutdown assertEquals getFileSystem getNameNode AdminStates assertNull  are allowed to register with the namenode fileSys file1 namenodeDecomList decommissionNode shutdown testDecommission.dat DatanodeReportType ,hadoop,1
cluster foofs  create cluster conf testFsClose System createFile getBytes waitActive out fpath  create a new file. write close testFsClose successful f getFileSystem TestFileCreation DIR  test closing file system before all file handles are closed. test file system close start something dfs  close file system without closing file build numDataNodes DATANODE_NUM shutdown ,hadoop,1
" this must match /blah/{id}/{id2}/{id3}/morestuff/at/the/end buildRoute assertFalse matches /blah/id/id2/id3/morestuff/at/the/end route assertTrue  this should not match as the last ""end"" is missing GET routeBuilder parametersDontCrossSlashes /blah/id/id2/id3/morestuff/at/the ",ninja,0
"  Defaults vary by number of queues set getThresholds ns DecayRpcScheduler ns. conf deprecation 1, 10, 20, 50, 85 scheduler assertEqualDecimalArrays  Custom testParseThresholds ",hadoop,0
headers getHeaders setMaxEmptyLineCount StandardCharsets newDecoder custom inputStream assertEquals parse inBuffer getBytes getReasonPhrase HTTP/1.1 200 OK  httpresponse testBasicMessageParsingLeadingEmptyLines Assert parser build OK   Server: whatever  getCode Http1Config ,httpcore,0
_test isMainSuccessful actionDir hasOutputData assertFalse testException runningJob isMainDone getFileSystem fs hasIdSwap getIdSwapPath ex isSuccessful assertTrue LauncherMapper getErrorPath exists getOutputDataPath evaluate waitFor getFsTestCaseDir isComplete ,oozie,1
.a.b. testResolverGetByNameUnqualified host .c. .b. . verifyGetByName unknown ,hadoop,0
"Action ID  getMissingDependencies Data should have been in missing dependency list! current list:  Dependency should be available! current list:  getTime TZ /2009/01/29/ getId 2009-02-16T23:59 DateUtils /2009/02/05 parseDateOozieTZ  Missing dependencies recorded by the coordinator action after input check /2009/02/12/ getTestCaseDir get testActionInputMissingDependencies createDir action startTime indexOf 2009-02-15T23:59 /2009/02/12  Expected missing dependencies are /2009/02/05, /2009/01/29, and /2009/01/22. missDepsOrder  specification - /2009/02/12, /2009/02/05, /2009/01/29, /2009/01/22 /2009/01/29 index -TestCoordActionInputCheckXCommand-C execute addRecordToCoordJobTable call jobId @1  was not stored properly in db fail Services  Case when /2009/01/29 exists but checking stops since dataset synchronously expected before i.e. /2009/02/05 is missing 0000000- endTime job jpaService ",oozie,1
conn thenReturn getEndpointDetails assertEquals sendResponseHeader ASCII outStream Go on when testWriteResponse100Head bind Assert flush Mockito response toByteArray getOutputStream HTTP/1.1 100 Go on   socket getResponseCount ,httpcore,0
/scripts/myscript.sh jobConf lib reader authToken ref2 f1 ref1 f2 /lib/reduceutil.so testCreateprotoConf createProtoActionConf Assert protoConf assertTrue getTestCaseDir /workflow.xml get file:// createTestCaseSubDir workflow.xml bla bla scripts write close /lib/maputil.jar init set wf-schema-valid.xml WorkflowAppService destroy assertEquals services getStrings Services OozieClient IOUtils getTestUser copyCharStream equals getResourceAsReader writer wps File ,oozie,1
"cluster Allowing svc1 to become active, expiring svc0 HAServiceState timeout atLeastOnce Faking svc0 unhealthy, should NOT successfully  transitionToActive failover to svc1 verify Faking svc0 healthy again, should go back to svc0 info LOG svc1 start waitForHealthState Making svc1 fail to become active testBecomingActiveFails setFailToBecomeActive waitForActiveLockHolder  to become active (e.g the admin has restarted it) any getService setHealthy waitForHAState Mockito State expireAndVerifyFailover ",hadoop,0
FindClass org.apache.hadoop.util.TestFindClass$PrivateClass run testCreateFailsPrivateClass ,hadoop,0
headers getServerAddress getHeaders ninjaTestBrowser newHashMap assertEquals testThatSettingOfMimeTypeWorks  Some empty headers for now... getValue makeRequestAndGetResponse Maps  /redirect will send a location: redirect in the headers  default charset is always utf-8 by convention. assets/files/test_for_mimetypes.dxf application/dxf; charset=UTF-8 httpResponse Content-Type ,ninja,1
scriptExecutor EntityWithStaticColumn/insert_single_row.cql session  Given SELECT static_col FROM entitywithstaticcolumn WHERE id =  Eq UUIDs uuid deleteStatic  When of staticCol where id static_col executeScriptTemplate isNotNull actual RandomUtils manager one timeBased nextLong assertThat execute ImmutableMap isTrue should_dsl_delete_static  Then isNull Long fromBaseTable dsl ,achilles,1
result not important testThatGetForbiddenRequestContentNegotiation ninjaDefault getForbiddenResult size contextImpl supportedContentTypes equalTo getContentType assertThat ,ninja,0
 testDecision addNode def enters decTrans WorkflowInstance getStatus two three asList exits assertTrue bla end signal add d containsKey one abcde start clear assertEquals / fail size testWf <worklfow-app/> Arrays job ,oozie,1
doAnEdit  Make sure runtime.exit(...) hasn't been called at all yet. cluster assertTrue assertExitInvocations  Invalidate one edits journal. assertFalse testSingleFailedEditsDirOnSetReadyToFlush  A single journal failure should not result in a call to runtime.exit(...). isInSafeMode invalidateEditsDirAtIndex getNameNode ,hadoop,1
next getBlockLocations DIR1 assertFalse FILE1 FILE2 FILE3 fs  test empty directory delete remove FILE_LEN assertTrue getLen getPath listFiles writeFile filesToFind TEST_DIR  unexpected add stat isFile  test more complicated directory isEmpty hasNext assertEquals Path  testDirectory  testing directory with 1 file mkdirs makeQualified itor ,hadoop,0
p1 p2 <property><name>p2</name><value>v2</value></property> p3 p4 v3b v3a <java> v1b v1a </configuration> writeXml parseJobXmlAndConfiguration conf appPath createContext testParseJobXmlAndConfiguration xml get create <job-xml>job2.xml</job-xml> jConf JavaActionExecutor job2.xml close app set </java> XmlUtils os parseXml <java/> job1.xml assertEquals getFileSystem <configuration> str size mkdirs <job-xml>job1.xml</job-xml> v2 v4 <property><name>p1</name><value>v1a</value></property> getFsTestCaseDir ,oozie,1
play ping  play it back assertFalse clientPingsServer  verify the peer received what was expected assertEquals toNanos acceptFrame sendFrame assertTrue peer SPDY3 roundTripTime pingFrame TimeUnit TYPE_PING  PING connection  payload2 ignored in spdy! takeFrame ,okhttp,1
getConnectionContext getEventMessage cae session coordEventListener JMSMessagingUtils getUser conf parseDateUTC coordActionFailMessage DateUtils getStatus createSession getTopic ='user1' wf-app-name1 onCoordinatorActionEvent Assert caJobId1 caId1 CoordinatorAction 2012-07-22T00:00Z selector jmsContext testCoordinatorActionSelectors consumer MessageType 2011-07-11T00:00Z user1 getMessageType init nominalTime receive printStackTrace e getMessage assertEquals message fail JMSHeaderConstants createConsumer startDate Session ,oozie,1
 test for the expected action number getId  Add Coordinator action with nominal time: 2009-12-15T01:00Z addRecordToCoordActionTable addRecordToCoordJobTable CoordinatorJob coord-action-get.xml coord-action-for-action-input-check.xml CoordinatorAction _testGetActionsSubsetOrderBy action action1 job  Check the ordering of actions by nominal time testCoordActionOrderBy  Add Coordinator action with nominal time: 2009-02-01T23:59Z ,oozie,1
getJobTrackerUri getName getStatus createContext getTestCaseDir context create waitFor <job-tracker> test-extra.jar testAdditionalJarSubmitOK ae </job-tracker> is getFileSystem check <name-node> <main-class> </name-node> WorkflowAction <file> SUCCEEDED appJarPath submitAction evaluate <java> assertFalse getAppPath actionXml isSuccessful createJar assertTrue </file> end getData isCompleted getNameNodeUri os </java> </main-class> runningJob getAction assertEquals getExternalStatus IOUtils assertNull jarFile copyStream toString isComplete ,oozie,1
"msg ""db"" : ""default"", ""server"" : ""thrift://localhost:1234"",  check logs to see appropriate error message session logger createTextMessage Exception caused  logMsg Logger HCatConstants out  HCatMessageHandler addAppender assertTrue localhost ""table"" : ""newTable"", process e getMessage getLogger appender ""partitions"" : [{ ""dt"" : ""2012_01_01"", ""grid"" : ""AB"" }] HCatEventMessage layout fail ""timestamp"" : ""123456"", contains hcatHandler testDropEventTypeMessage toString { } setStringProperty ",oozie,1
server Server assertFalse checkResponse conf run Assert client getCallRetryCount  Attach a listener that tracks every call received by the server. addr info getCallId getRetryCount rpcKind start rpcRequest assertEquals createCall getConnectAddress call caller testCallIdAndRetry NetUtils  Override client to store the call info and check response stop header ,hadoop,0
getName  rename it to what looks like a directory assertFalse foo run suffix argv delete -put assertTrue getFileStatus /. dotdotDst isFile  ensure .. is interpreted as a dir srcPath assertEquals  empty out the directory and create to make copy succeed / subdirDstPath shell mkdirs lfs exists toString /foo/..  make copy fail dstPath testRepresentsDir ,hadoop,0
cluster blocksScanned getDataNodes LOG dn Waiting for all blocks to be scanned for bpid= waitActive Thread sleep restartDataNode bpids getBlocksScannedInLastRun get ; Scanned so far= setUp testBlockScannerAfterRestart shutdown info ,hadoop,1
item getConf applyGlob apply n*e /directory/path/name name setup assertEquals mockFs Result  test a matching glob pattern ,hadoop,0
"MyApp123.Path789.myCallback123 period in the front, object function alert(document.cookie) $42.ajaxHandler assertFalse .onResponse object function, path with numbers function call onResponse \u0020 unicode characters assertTrue complex path, $ in identity. simple function TemplateEngineJsonP .MyPath.path 42$.q MyPath.path MyPath.path.path2. wrong first character simple array MyApp.Path.myCallback123 period in the front, simple period in the end, complex path Ext.data.JsonP.callback4 MyPath..path.path2 period in the end, simple isThisASecureCallbackName object function somearray[12345]  Cases not supported by the validator. complex path onResponse. two subsequent periods testIsThisASecureCallbackName \u0062oo ",ninja,0
play server C getSequenceNumber  Connection reused. redirectedBy Location: /b assertCode Location: /c assertBody /a Test Redirect from /b to /c assertContainsHeaders /a has moved! Test: Redirect from /b to /c  Connection reused again! redirect addHeader takeRequest assertEquals setResponseCode setBody /b has moved! url  New connection. enqueue Test: Redirect from /a to /b getUrl build Redirect from /a to /b onSuccess ,okhttp,1
setClassesToBeExcluded addRecordToBundleActionTable assertFalse getId run isPending getStatus bundleJob assertNotNull get Job bundle waitFor init testBundleStatusTransitServiceSuspendedWithError getConf false addRecordToBundleJobTable bundleId destroy assertEquals services execute Services runnable excludedServices setSystemProperty StatusTransitService action1 action2 jpaService evaluate ,oozie,1
assumeFalse getProcess shellCmd destroyAllShellProcesses start GenericTestUtils run sleep 200 execute sleepCommand shexc1 shexc2 shellThread1 testDestroyAllShellProcesses Shell -c get WINDOWS Assume bash toString waitFor append shellThread2 ,hadoop,0
"storePassword getResource toCharArray aliases getName serverSocket newSingleThreadExecutor Executors serverSslContext client2 getServerSocketFactory Assert bind assertNotNull nopassword clientPrincipal create TimeUnit SSLContextBuilder /test-client.p12 write getPeerPrincipal testSSLHandshakeClientAuthenticatedPrivateKeyStrategy localhost startHandshake read localPort loadTrustMaterial loadKeyMaterial resource2 inputStream setSoTimeout getInputStream /test-server.p12 resource1 accept contains createSocket clientSslContext TIMEOUT setNeedClientAuth getLocalPort submit privateKeyStrategy session clientSocket flush keyPassword get chooseAlias outputStream keySet close connect CN=Test Client 2,OU=HttpComponents Project,O=Apache Software Foundation assertEquals call getSocketFactory build future toMillisecondsIntBound getOutputStream socket getSession createServerSocket ",httpcore,0
 Get a token in checkEqual sourceToken out readFields setService  Read the token back destToken assertTrue service  Write it to an output buffer getLength reset testTokenSerialization write getData ,hadoop,0
PREP getId WorkflowInstance actionGetCmd coordJob wfBean addRecordToWfJobTable assertNotNull get  Add two jobs to update list WorkflowJob Job testBulkInsertUpdates updateList add getStatusStr insertList RUNNING wfGetCmd assertEquals  Add two actions to insert list execute addRecordToCoordJobTable setStatus CoordinatorJob 1 Services 2 WorkflowAction bulkUpdateCmd SUCCEEDED createWorkflowAction action1 job action2 jpaService ,oozie,1
"request CommonConfigurationKeys acls testRequiresAuthorizationAccess thenReturn assertFalse conf when any  requires admin access to instrumentation, TRUE getAttribute Assert Mockito assertTrue response isUserAllowed context mock  requires admin access to instrumentation, FALSE by default HttpServer2 isInstrumentationAccessAllowed setBoolean ",hadoop,0
"hello%( %child \(%h\) ) %m Node  ( hello%(%child ) hello%(%child %h) composite )  hello%(%child)   c h testComposite assertEquals parse BARE  System.out.println(""testRecursive part 2""); m setChildNode p witness t  System.out.println(t); hello%(%child %h) %m child ",logback,0
removedHeaderCheck headersCopy  remove a header to force an error remove put STATUS Assert HEADERS runTests  return different headers than expected. get toArray addTest deepcopy keySet WebServerTestingFrameworkException should have been thrown headerName adapter unchecked assertEquals responseExpectations execute fail TestingFramework framework response newFrameworkAndSetAdapter BODY ,httpcore,0
conn responseCaptor when Assert executor assertNotNull context create getCode testExecutionSkipIntermediateResponses thenReturn ArgumentMatchers getResponse getAllValues capture Method eq execute / size info1 mock receiveResponseHeader sendRequestHeader info2 request getRequest Continue times flush get verify forClass OK postProcess process ArgumentCaptor Huh? assertEquals getEntity assertSame Mockito response HttpCoreContext httprocessor callback preProcess infos receiveResponseEntity ,httpcore,0
"cluster NameNodeAdapter ns racks conf /rack2 waitForReplication /rack1 fs  ie we should still have 2 racks after reducing the repl factor. createFile DFSTestUtil b getConf filePath testReduceReplFactorRespectsRackPolicy getFileSystem setReplication REPLICATION_FACTOR getNameNode /testFile build numDataNodes     * Reduce the replication factor of a file, making sure that the only    * cross rack replica is not removed when deleting replicas.      Create a file with one block getFirstBlock shutdown getNamesystem ",hadoop,1
"../boo/bud  ../../foo /boo/bud ../../../../boo/bud ../../../../.. /foo/bar/baz/.././../fud ../../.. .././../foo/bar /foo/bar/baz/boo foo/baz ../../foo/bar baz/bud ../../boo/bud /foo/bar/../baz /foo/bar/./baz foo/bar foo/bar/baz/bud /foo/bar foo/bar/../baz foo/bar/baz ../../../boo/bud /foo/bar/../../baz/boo /foo/bar/baz boo/bud /foo/boo/bud ./foo/bar/baz foo/bar/ foo/boo/bud testDots foo/bar/../../baz/boo assertEquals /foo/baz . /foo/bar/baz/../../fud /baz/boo /foo/fud ../..  Test Path(String) baz/boo  Test Path(Path,Path) toString ../../foo/boo/bud ../../ ",hadoop,0
kills addNode def enters one start testSynchSimple assertEquals WorkflowInstance getStatus asList wf 1 exits size <worklfow-app/> end Arrays job fails ,oozie,1
SELECT * FROM entitywithstaticcolumn WHERE id =  session  Given crud  When id value static_col val isNotNull static_val actual RandomUtils manager one getString nextLong assertThat insertStatic execute should_update_static isTrue  Then isNull Long isEqualTo entity ,achilles,1
resultMetadata first element of optional array should be the first field identifier assertFalse ISO CH testStandardSample1 getOptionalData sampleCodes assertEquals deprecation  we should never reach these getSegmentIndex decodeMacroBlock getFileId CEN BE getAddressee isLastSegment last element of optional array should be the last codeword of the last field getSegmentCount DecodedBitStreamParser ARBX getSender optionalData ,zxing,0
"buildTestModel assertFalse TABLE1 admin toXML tableExists delete put  make sure HBase concurs get client model checkModel  retrieve the schema and validate it getCode fromXML testTableCreateAndDeleteXML  delete the table getBody schemaPath assertEquals TestTableSchemaModel /  make sure HBase concurs, and wait for the table to come online /schema response enableTable MIMETYPE_XML  create the table ",hadoop,1
next NoSuchElementException expected. assertFalse LocalOozie h hasNext setHeader getHeader removeHeader fail getCoordClient hit assertNull v getHeaderNames client testHeaderMethods ,oozie,1
10.241.23.1 10.241.24.0 10.241.23.0 10.119.103.111 assertFalse 10.241.22.255 includes  test for exclusion with an unknown IP  test for inclusion/exclusion testCIDRWith8BitMask CIDR_LIST2 assertTrue  create MachineList with a list of of ip ranges specified in CIDR format 10.241.23.254 10.241.23.255 ml ,hadoop,0
fcq assertCanTake testTakeBlocksWhenEmpty ,hadoop,0
a A getKey b ELConstantsFunctions <x> XmlUtils </x> e map2 & getText parseXml toConfigurationStr conf assertEquals put str entry getValue testToConfigurationStr map ,oozie,1
channel outStream Assert constructString Like hello and stuff flush RUSSIAN_HELLO inbuf tmp writeLine chbuffer s1 s2 s3 StandardCharsets newDecoder SWISS_GERMAN_HELLO clear assertEquals fill readLine outbuf toByteArray newEncoder toString newChannel testMultibyteCodedReadWriteLine append outChannel ,httpcore,0
" aaa ccc Name4=Value+4%26 Name4=Value+4%26+%3D4 Value1 xx,  yy  ,zz Name4 Name5 Assert Name6 Name7=aaa&Name7=b%2Cb&Name7=ccc Name7 Name2= Name8 Name7=aaa;Name7=b%2Cb;Name7=ccc b,b Name8=xx%2C++yy++%2Czz Name1=Value1 Name0 Name1 Name2 add Value+4& bbb Name5=aaa&Name6=bbb URLEncodedUtils StandardCharsets format length clear assertEquals params testFormat Value 4& Name4=Value%2B4%26 Value 4& =4 ",httpcore,0
testSequenceFileDeflateCodec sequenceFileCodecTest conf org.apache.hadoop.io.compress.DeflateCodec ,hadoop,0
"caught No exception was raised getCaught start cause getCause Thread  in exception diagnostics. sleep Assert assertTrue assertNotNull testInterruptedWaitForProxy interrupt join worker  no inner cause, use outer exception as root cause. worker hasn't started ",hadoop,0
 ContentType byteChannel StandardCharsets assertFalse testProduceDataWithBuffering2 assertEquals produce isOpen Assert assertTrue producer 12345 dump 67890 streamChannel ,httpcore,0
wait getLocalPort localClient acceptClient serverSocket start isConnected listener setSoTimeout thread getLocalHost testAcceptClient retries assertTrue assertNotNull client InetAddress close ,logback,0
server getLocalPort ContentType setSslContext consume bootstrap setConnPoolListener request1 some stuff setEntity testTLSTrustFailure createServerSSLContext setSocketConfig context create https /stuff setExceptionListener createDefault requester SSLContexts localhost SSLTestContexts SocketConfig setStreamListener custom LoggingHttp1StreamListener start * setSoTimeout Method getEntity execute ServerBootstrap target EntityUtils LoggingConnPoolListener build LoggingExceptionListener RequesterBootstrap TIMEOUT response1 register ,httpcore,0
excludes ReflectionTestUtils -static/** assertFalse getField unchecked includes foo.jar static/** -**/*.jar asList includedDeltasAndNewEntries contains resourceMatcher assertTrue templates/** **/*.jar Arrays ,spring-boot,1
add  Create lists for status filter RUNNING testCoordActionFilter getId  Add Coordinator action with nominal time: 2009-12-15T01:00Z addRecordToCoordActionTable addRecordToCoordJobTable CoordinatorJob  Check status filters for Coordinator actions coord-action-get.xml _testGetActionsSubsetFilter CoordinatorAction job filterList KILLED  Add Coordinator action with nominal time: 2009-02-01T23:59Z ,oozie,1
currentTime getMask closelyRepeatedCallsShouldCauseMaskToIncrease minDelayThreshold isTooSoon assertTrue DEFAULT_MASK assertFalse gate maxDelayThreshold ,logback,0
 objectWriter  then  fill up deque when timeout deque offer verify write  when addsInfoMessageWhenEventIsBeingDroppedBecauseOfConnectionProblemAndDequeCapacityLimitReached  given max start appender addInfo anyObject some event doThrow reset Dropping event due to socket connection error and maxed out deque capacity TIMEOUT awaitStartOfEventDispatching remainingCapacity append ,logback,1
 see also http://jira.qos.ch/browse/LOGBACK-1164 StatusPrinter assertEquals checker AggregationType orange Citrus bridgeMethodsShouldBeIgnored print context computeAggregationType assertIsWarningOrErrorFree orangeSetter ,logback,0
testClassLoader other assertTrue conf getClassLoader setQuietMode setClassLoader ,hadoop,0
" CoordELFunctions TZ action-actual-time="" testActionInputCheckLatestActionCreationTime DateUtils  Sleep for sometime as it gets requeued with 10ms delay on failure to acquire write lock ${coord:latestRange(-3,0)}  before and after action creation time parseDateOozieTZ Actual:  getTestCaseDir file:// action setCreatedTime indexOf /2009/01/22 /2009/01/08/ resolvedList execute setActionXml jobId contains CoordCommandUtils /2009/02/19/ job getMissingDependencies Expected:  getTime getId 2009-02-16T23:59 </uris> replaceAll /2009/02/05 System substring actionXML sleep /2009/02/12/ <uris> assertTrue get createDir startTime  Update action creation time ""> latest 2009-02-15T23:59 action-actual-time=""2009-02-15T01:00 /2009/03/05/ /2009/01/22/ /2009/02/12 getConf action-actual-time="".*""> /2009/01/08 assertEquals -TestCoordActionInputCheckXCommand-C addRecordToCoordJobTable Thread  Datasets only before action creation/actual time should be picked up. call Services @1 getActionXml 0000000- endTime 2009-02-15T01:00 actionCreationTime jpaService setBoolean /2009/02/05/ ",oozie,1
date scriptExecutor session LOCAL_ONE  Given update simple Eq consistencylist asList containsExactly QUORUM  When getList of should_dsl_update_list_appendAll where id row table executeScriptTemplate RandomUtils manager one consistencyList_AppendAllTo nextLong assertThat TWO execute SimpleEntity/insert_single_row.cql ImmutableMap SELECT consistencylist FROM simple WHERE id =   Then Long buildDateKey fromBaseTable consistencyList dsl THREE ,achilles,1
bundleJobGetCmd addRecordToBundleJobTable getId assertEquals getStatus execute call Services testBundlePauseUnpause3 assertNotNull get Job job jpaService ,oozie,1
getId assertEquals getStatus execute addRecordToCoordJobTable call CoordinatorJob Services coordJobGetCmd assertNotNull get job jpaService testCoordSuspendAndResumeForRunning ,oozie,1
parallel took: {}ms LOG setParallelProcessing serial took: {}ms System endParallel serial parallel assertTrue currentTimeMillis endSerial victim begin testMojoWithConfigurableWroManagerFactoryWithValidConfigFileSet info shouldBeFasterWhenRunningProcessingInParallel ,wroj4,1
"dropDatabase createTable year=2013;month=1;dt=01;country=us part1 part2 assertFalse </prepare> doOperations addPartition <delete path=' year,month,dt,country conf fs year=2012;month=12;dt=02;country=us createJobConf testDelete table1 /db1/table1/year=2013;dt=01 LauncherMapper getPartitions <prepare> '/>  Prepare block that contains delete action /db1/table1/year=2012;month=12 dropTable country=us getMetastoreAuthority hcat:// assertEquals getFileSystem uri2 createDatabase db1 uri1 size prepareXML part3 exists year=2012;month=12;dt=03;country=us setupLauncherURIHandlerConf PrepareActionsDriver ",oozie,1
result testThatCorrectValueIsReturnedWithDefaultSetup equalTo resolveApplicationClassName ninjaProperties Matchers assertThat ninjaBaseDirectoryResolver conf.Filters ,ninja,0
" de conn /app POST /v1/jobs put getJob setRequestProperty libPath2 create workflow.xml libPath1 openConnection conf1 getFileSystem params , getInputStream getDagEngine JSONValue OozieClient size mkdirs reset jobXmlPath1 setDoOutput jobConf setRequestMethod IS_SECURITY_ENABLED assertFalse libpath1 writeXml libpath2 testSubmit appPath fs assertTrue get content-type jobXmlPath runTest sr JsonTags set RestConstants getConf undef MockDagEngineService HttpServletResponse assertEquals parse services url call Services getTestUser obj getResponseCode wfCount createURL toString getOutputStream getFsTestCaseDir ",oozie,1
getTime DateUtils some_bundle_parent_id parseDateOozieTZ insertJob jobId2 jobId1 assertNotNull executor get 00002- setBundleId  job2 shouldn't be in the list because it has a parent job2 2011-01-01T01:00Z assertEquals testCoordJobsGetForPurgeJPAExecutorWithParent execute Services CoordinatorJob -TestCoordJobsGetForPurgeJPAExecutor-C size jobList jpaService 00001- ,oozie,1
credential1 credential1 has been successfully  created. assertFalse run delete -value assertTrue create jceksProvider -f outContent p@ssw0rd assertEquals list setConf deleted. testCredentialSuccessfulLifecycle cs rc contains args5 -provider args1 reset args2 toString ProviderUtils args4 ,hadoop,0
processWatchEvent data mockNoPriorActive when  once in initial joinElection() and one now ZK_LOCK_NAME notifyFatalError Assert  monitoring should be setup again after event is received getPath Ids create  no new watches after fatal error verifyExistCall mockApp thenReturn  make the object go into the monitoring state enterNeutralMode count processResult Code CreateMode getType becomeActive  fatal error means no new connection other than one from constructor mock getSessionId becomeStandby assertFalse times  another joinElection called assertTrue  enterNeutralMode not called when app is standby and leader is lost mockEvent verify Unexpected watch error from Zookeeper stat  bad path name results in fatal error testProcessCallbackEventNode intValue  successful znode creation enters active state and sets monitor assertEquals elector  monitor isMonitorLockNodePending mockZK setEphemeralOwner Mockito joinElection Event ,hadoop,0
cluster createTable admin TEST_UTIL getRegionName registerListener Bytes split aboutToOpen getFirst getTableRegionFromName await TimeUnit countDown proceed TABLENAME cde getTableRegions loadTable toBytes list m pair testMasterOpsWhileSplitting getTableRegionClosest getHBaseCluster HBaseEventHandler getHBaseAdmin getMaster FAMILYNAME ,hadoop,1
 call POST MyJsonRestServlet GET testMultipleResourcesNoResource HttpServletResponse invoke assertEquals /resource1 /resource2 runTest ,oozie,1
END_POINTS IS_SECURITY_ENABLED -action oozieUrl assertFalse 2009-12-15T01:00Z run appPath testCoordReRunNeg4 get -config create SERVLET_CLASSES close runTest app MockCoordinatorEngineService coordinator.xml createConfigFile getContextURL assertEquals getFileSystem -rerun 0 args call 1 -date -oozie assertNull mkdirs toString job getFsTestCaseDir ,oozie,1
testStartNonTransientWithCoordActionUpdate start.non-transient assertTrue start _testNonTransientWithCoordActionUpdate WorkflowActionBean ,oozie,1
"getClass getName makeClassLoaderTestJar testClientClassLoader  it should not throw an exception  create the test jar run when TEST_JAR_2_NAME JarFinder  form the args times TEST_ROOT_DIR verify BUFF_SIZE testJar unJar getAbsolutePath thenReturn  enable the client classloader  third class so they can be loaded by the application classloader systemClasses , - any ApplicationClassLoader  run RunJar args thirdCls getSystemClasses useClientClassLoader mainCls runJar spy ",hadoop,0
<fs/> dir fs createContext -rwxr----- path rwx---r-- testChmod rwx-----x getFileStatus context rwx------ chmod FsPermission setPermission grandchild -rwxr----x -rwx-----x getPermission ae valueOf rwxr----- assertEquals getFileSystem rwxr----x -rwx------ mkdirs toString getFsTestCaseDir child -rwx---r-- ,oozie,1
cluster  write to file conf  does not exist. fs System dfsclient createFile simulatedStorage Testing adbornal client death. assertTrue testDFSClientDeath  This should close all existing file. writeFile close   /clienttest.dat  reopen file system and verify that file exists. getFileSystem Created file clienttest.dat stm AppendTestUtil dfs build createHdfsWithDifferentUsername exists SimulatedFSDataset file1 shutdown setBoolean ,hadoop,1
MICROSECONDS Configuration values NANOSECONDS DAYS conf convert  check default suffix 1d getTimeDuration 30S testTimeDuration get 7s 30 10 MILLISECONDS ptd set test.time.unit SECONDS setTimeDuration assertEquals test.time.a  check suffix insensitive test.time.b test.time.c unit test.time.d HOURS 30s 40s MINUTES 2m test.time.X ,hadoop,0
cluster testCount runCmd conf System localfs TEST_ROOT_DIR root FileSystem runCount close 2/f1 testcount getWorkingDirectory createTree localpath  Verify the counts count localstr assertEquals getFileSystem setConf localstr= dfs 2 -count 2/sub build shell numDataNodes getLocal makeQualified mkdirs toString shutdown getUri ,hadoop,1
add Operator ROWS_ONE  regular expression and substring filters f One clear kvs filters setFilter  Use must pass all testFilterList QUALIFIERS_ONE verifyScanFull addFamily FAMILIES .+-2 VALUES .+Two.+ CompareOp verifyScanNoEarlyOut ,hadoop,1
Transfer-Encoding addHeader determineLength message lenStrategy whatever testEntityWithInvalidTransferEncoding ,httpcore,0
"testBasicSubmit <execution>LIFO</execution> </controls> <datasets>  var-app-name checkCoordJobs conf </input-events>  <coordinator-app name=""${appName}-foo"" frequency=""${coord:days(1)}"" start=""2009-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""  getConcurrency xmlns=""uri:oozie:coordinator:0.2""> <controls>  </property></configuration> </workflow> </action> </coordinator-app> assertNotNull file:// getTestCaseDir UNIT_TESTING <output-events> <data-out name=""LOCAL_A"" dataset=""local_a"">  timezone=""UTC""> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset>  oozie.service.coord.default.concurrency oozie.service.coord.normal.default.timeout <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  <dataset name=""local_a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  OozieClient jobId getInt </datasets> <input-events>  -C <dataset name=""a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  job File var-app-name-foo appPath substring sc writeToFile appXml <property> <name>inputB</name> <value>${coord:dataOut('LOCAL_A')}</value>  getTimeout get coordinator.xml getAppName set getConf appName length assertEquals call Services getTestUser <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>  <data-in name=""A"" dataset=""a""> <instance>${coord:latest(0)}</instance> </data-in>   ",oozie,1
123-value-via-system-property  verify system property overrides it %dev.unit.test.123 unit.test.123 is assertThat 123-value-via-external-conf System clearProperty systemProperties NinjaMode  verify property in external conf is set 123-value-via-prefixed-system-property conf/system_property.conf get setProperty ninjaProperties  verify prefixed system property overrides both ,ninja,0
" Check whether transactions are rolled back or not Expected exception due to commit failure but didn't get any PREP getId WorkflowInstance actionGetCmd deactivate testBulkInsertUpdatesRollback wfBean addRecordToWfJobTable getErrorCode assertNotNull wfUpdateCmd1 get WorkflowJob updateList add getStatusStr insertList Expected exception but didnt get any wfGetCmd assertEquals SkipCommitFaultInjection  Add two actions to insert list execute setStatus FaultInjection 1 Services fail jpaee 2 WorkflowAction org.apache.oozie.command.SkipCommitFaultInjection setSystemProperty true createWorkflowAction action1  set fault injection to true, so transaction is roll backed ErrorCode job action2  Add to update list  status should not be RUNNING jpaService ",oozie,1
add QUALIFIER_1 QUALIFIER_2 ROW_3 ROW_4 testPut put result puts  multiput getValue Bytes COLUMN_2 COLUMN_1 addFamily assertTrue assertNotNull get equals remoteTable VALUE_1 value VALUE_2 ,hadoop,1
_testGetJobInfoForAppName coordinatorJob1 _testGetJobInfoForFrequency _testGetJobInfoForUserAndStatus _testGetJobInfoForStatus _testGetJobInfoForGroup _testGetJobInfoForUser getId addRecordToCoordJobTable _testGetJobInfoForFrequencyAndUnit testCoordJobGet CoordinatorJob _testGetJobInfoForId ,oozie,1
init testGetParameter servletContext  init the context thenReturn defaultValue  this will not work and return null assertEquals httpServletRequest when  and return the parameter map when any parameter is called... context key_not_there  this will work as the value is there... httpServletResponse value  this will return the default value: key getParameter ,ninja,0
23 mapping contains size assertTrue groups zzz testGetNumericGroupsResolvable user groupname getGroups ,hadoop,0
assertCorrectImage2binary  (01)90012345678908(3102)001750(13)100312  ..XXX.X. ........ .X..XXX. X.X.X... XX.XXXXX .XXXX.X. ..XX...X .X.....X .XX..... XXXX.X.. XX.. 17.png testDecodeRow2binary17 ,zxing,0
cluster getWriteOps getCurrentUser getStatistics  readOps and largeReadOps incremented by 1 or more listStatus conf dir Math getStatus /test setOwner ugi getFileStatus testStatistics create getUserName getFileBlockLocations UserGroupInformation DFSConfigKeys writeOps in getFileSystem ceil list getFileChecksum iterations setInt getReadOps mkdirs  Iterative ls test setTimes shutdown status getGroupNames lsLimit getLargeReadOps largeReadOps fs delete out getTestConfiguration file checkStatistics readOps setPermission close  Single iteration in listStatus - no large read operation done  number times listStatus iterates DFSTestUtil getContentSummary setReplication Integer p build rename toString file1 open ,hadoop,1
cluster fileName failed to leave safe mode  Truncate replica of block  and the block to be replicated changeReplicaLength  handled correctly assertFalse  Make sure that truncated block will be deleted conf fs waitReplication getSelfAddr System createFile  Assure the cluster has left safe mode. waitActive assertTrue infoPort get waitForBlockDeleted startTime block waitForVerification DFSTestUtil DFSConfigKeys getDataNodes startDataNodes /file1 failed to find or change length of replica on node 0  format getFileSystem isInSafeMode REPLICATION_FACTOR getNameNode setLong  then truncate it on datanode 0. build numDataNodes getInfoPort  now we have 3 datanodes currentTimeMillis TIMEOUT waitClusterUp getFirstBlock shutdown testTruncatedBlockReport setBoolean ,hadoop,1
"compare ret2 getTestString ret1 compareTo NUM_ITERATIONS  compare two strings by looking at their binary formats out2  reset output buffer Equvalence of data output buffers out3 Equivalence of different txt objects, same content str1 out1 str2 write getData getLongString assertEquals  convert to texts  compare two strings comparator testCompare txt2 txt3 txt1 reset getLength  generate two random strings  serialize them ",hadoop,0
/foo isFile /newDir/newDir2/foo foo assertFalse chrootedTo newDir/foo testCreateDelete fcTarget delete createFile  Create file with a 2 component dirs recursively Assert fileContextTestHelper  Create file assertTrue  Create file with recursive dir exists createFileNonRecursive /newDir/foo fc  Delete the created file newDir/newDir2/foo ,hadoop,0
"getName oozie.service.ProxyUserService.proxyuser.foo.groups testInvalidProxyUser foo conf asList bar Assert StringUtils assertNotNull get join validate localhost init set oozie.service.ProxyUserService.proxyuser.foo.hosts getConf destroy * services , Services fail ex proxyUser toString Arrays ",oozie,1
"value2 value1 value4 value3 this\that Assert param formatElements param=""this\\that"", name3=value3; param=""this,that"",  name4=value4; param, name5 name1=value1; param=regular_stuff, name2=value2;  assertEquals param3 param4 testElementsFormatting param1 param2 name5 name4 buf regular_stuff name3 element1 element2 element3 elements element4 element5 toString name2 name1 this,that ",httpcore,0
reader conf run getStatus getJob getTestGroup assertNotNull getTestCaseDir /workflow.xml file:// action workflow.xml waitFor actions2 bean actionCheckRunnable running-mode actionCheckDelay external-status test testActionCheckerServiceDelay execute OozieClient jobId getType copyCharStream getResourceAsReader setLastCheckTime File evaluate actions submitJob WorkflowActionBean sleep actionsGetExecutor engine setStrings get ok WorkflowJob a set WorkflowAppService wf-ext-schema-valid.xml assertEquals async Services IOUtils getTestUser t signal-value u based_on_action_status equals writer action2 jpaService ,oozie,1
 excludes ReflectionTestUtils getField unchecked includes static/** asList contains resourceMatcher defaults assertTrue **/*.jar Arrays ,spring-boot,1
testAllConstants configuration NinjaConstant assertEquals getString LANGUAGES NAME getInt PREFIX SwissKnife getBoolean SERVER_NAME loadConfigurationInUtf8 conf/all_constants.conf SECRET ,ninja,0
addRecordToBundleActionTable addRecordToWfActionTable coordJob2GetCmd getStatus wfAction5GetCmd Coordinator Job 4 should not have been purged wfJob5GetCmd Workflow Action 4 should not have been purged Coordinator Action 5 should not have been purged coordAction4GetCmd getEndTime bundleJob coordAction3 coordAction4 BundleJobBean assertNotNull coordAction5 CoordinatorAction wfJob2GetCmd coordAction1 coordAction2 Workflow Job 4 should not have been purged bundleAction4 bundleAction5 bundleAction1 bundleAction2 bundleAction3 execute Workflow Job 3 should not have been purged bundleAction1GetCmd CoordinatorJob 1 fail Bundle Action 2 should not have been purged SUCCEEDED wfAction2GetCmd Workflow Action 5 should not have been purged Coordinator Job 3 should not have been purged Coordinator Action 4 should not have been purged bundleJobGetCmd wfJob1 coordJob1GetCmd wfJob3 wfJob4GetCmd wfJob2 wfJob5 get wfJob4 Bundle Action 4 should not have been purged coordAction2GetCmd Workflow Action 3 should not have been purged bundleAction3GetCmd getAppName setAppName coordAction1GetCmd Bundle Action 3 should not have been purged 2011-01-01T01:00Z addRecordToBundleJobTable assertEquals getLastModifiedTime wfAction1 wfAction2 addRecordToCoordJobTable wfAction3 wfAction4 wfAction5 call Services wfJob3GetCmd Coordinator Job 2 should not have been purged jpaService Workflow Job 2 should not have been purged bundleAction2GetCmd Bundle Action 5 should not have been purged getNumDaysToNotBePurged DateUtils WorkflowInstance addRecordToCoordActionTable parseDateOozieTZ Workflow Job 1 should not have been purged wfAction1GetCmd Job coord2 coord3 coord4 coord5 Coordinator Job 1 should not have been purged coordJob3GetCmd wfJob1GetCmd testPurgeBundleWithCoordChildWithWFChild2MoreThanLimit Workflow Action 2 should not have been purged coordJob2 Bundle Job should not have been purged coordJob3 coordJob1 Coordinator Action 3 should not have been purged WorkflowAction coordAction3GetCmd coordJob4 coordJob5 coordJob4GetCmd bundleAction4GetCmd Bundle Action 1 should not have been purged getId coordAction5GetCmd addRecordToWfJobTable WorkflowJob Coordinator Action 1 should not have been purged wfAction3GetCmd wfAction4GetCmd coordJob5GetCmd bundleAction5GetCmd Coordinator Action 2 should not have been purged Workflow Action 1 should not have been purged coord-action-get.xml Workflow Job 5 should not have been purged Coordinator Job 5 should not have been purged ,oozie,1
localhost uribuilder assertEquals uri / setUserInfo result password param=stuff Assert build testSetUserInfo http user http://user:password@localhost:80/?param=stuff ,httpcore,0
END_POINTS IS_SECURITY_ENABLED oozieUrl run createMRProperties appPath testSubmitMapReduce2 assertTrue get -config SERVLET_CLASSES runTest app getContextURL MockDagEngineService assertEquals getFileSystem args call submitMR -oozie mapreduce mkdirs wfCount toString getFsTestCaseDir ,oozie,1
"testUsingWeightedTimeCostProviderWithZeroCostCalls ignored addResponseTime getSchedulerWithWeightedTimeCostProvider assertEquals emptyDetails mockCall scheduler TimeUnit FEW  Since the calls are all ""free"", they should have the same priority MANY getPriorityLevel ",hadoop,0
testRetryDecisionOrdering Assert assertTrue compareTo RetryPolicy ,hadoop,0
genKeyPair handler request getTime jwt getPublic publicKey setPublicKey when REDIRECT_LOCATION alternateAuthentication should NOT have thrown a AuthenticationException SERVICE_URL  verify the signature - in order to make it fail verification... getCookies getJWT verify getRequestURL RSA init kpg cookie kp alternateAuthentication should NOT have thrown a ServletException thenReturn getProperties hadoop-jwt encodeRedirectURL alternateAuthenticate KeyPairGenerator testFailedSignatureValidationJWT sendRedirect props token fail privateKey serialize bob Mockito response mock getInstance initialize ,hadoop,0
testUnknownLengthConstructor Assert EmptyInputStream assertEquals getContentLength entity ,httpcore,0
"22 ab with ""quotes""   c"" d ""e  a b "" c\"" d \""e "" "" c\"" d \""e "" joinPMMLDelimited TextUtils assertEquals testJoinPMMLDelimited asList ab ""a b"" ""with \""quotes\"" "" 1 3 1 22 3 Arrays ",oryx,1
SASL_PRIVACY_PROPS conf 10.221.103.121 10.222.103.121 variablewhitelist.txt removeFile getByName wqr 10.222.0.0/16 WhitelistBasedResolver 10.119.103.112 set 10.119.103.113 10.113.221.222 10.113.221.221 10.221.102.0/23 getServerProperties assertEquals 10.221.104.0 setConf fixedIps createFileWithEntries setLong testFixedAndLocalWhiteList TestFileBasedIPList variableIps getDefaultProperties InetAddress fixedwhitelist.txt 127.0.0.1 setBoolean 10.223.104.0 ,hadoop,0
optionalIntegerParamEmpty Optional thenReturn invoke when param1 empty context create verify optionalIntegerParam mockController getParameter ,ninja,0
date scriptExecutor session LOCAL_ONE  Given update simple Eq consistencylist containsExactly  When getList of where id row table executeScriptTemplate RandomUtils manager consistencyList_RemoveAtIndex one nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap SELECT consistencylist FROM simple WHERE id =   Then should_dsl_update_list_removeAtIndex Long buildDateKey fromBaseTable consistencyList dsl ,achilles,1
 addNode def enters WorkflowInstance getStatus asList wf assertTrue end ERROR OK signal testActionOKError a b c containsKey start clear assertEquals / 1 <worklfow-app/> Arrays job ,oozie,1
cluster tries getName Checked if node was recommissioned  conf All datanodes must be alive numNamenodes startCluster sleep decommissionedNodes  wait for the block to be deleted assertTrue  times before recommissioned get client numDatanodes writeFile cleanupFile info checkFile add tried:  getDfsClient LOG datanodeReport replicas decomNode  Decommission one node. Verify that node is decommissioned.  Ensure decommissioned datanode is not automatically shutdown assertEquals getFileSystem testRecommission getNameNode Thread AdminStates assertNull recomissionNode fileSys file1 Starting test testRecommission namenodeDecomList  stop decommission and check if the new replicas are removed  times. decommissionNode shutdown testDecommission.dat DatanodeReportType ,hadoop,1
randomPort assertFalse topic.topic1  Start the broker and check if listening to topic now sleep random brokerURl isTopicInRetryList ConnectionFactory isConnectionInRetryList HCatAccessorService assertTrue tcp://localhost: connectionFactoryNames# publisherAuthority get servicesConf registerForNotification default=java.naming.factory.initial# init set getJMSConnectionInfo getConf hcatService testConnectionRetry hcat.server.com:5080 start destroy jmsService services nextInt hcat://hcat.server.com:8020 broker JMSAccessorService addConnector ActiveMQConnFactory Thread 1 Services 3 java.naming.provider.url# connInfo stop setupServicesForHCatalog isListeningToTopic topic ; ,oozie,1
p  fail Assert t u testConstructor ,hadoop,0
 kills addNode def enters one start testAsynchSimple assertEquals WorkflowInstance getStatus asList wf / 1 exits size <worklfow-app/> end Arrays job signal fails ,oozie,1
doAnEdit  Make sure runtime.exit(...) hasn't been called at all yet.  have halted the NN.  Invalidate both edits journals. assertTrue assertExitInvocations testAllEditsDirFailOnWrite invalidateEditsDirAtIndex ,hadoop,1
play assertContainsAll testCookiesSentIgnoresCase server request assertFalse Baz=baz put result get COOKIE: Bar=bar Collections cooKIE2 Quux: quux getHeaders takeRequest singletonList Bar=bar setDefault / enqueue contains COOKIE CookieHandler cooKIE2: Baz=baz ,okhttp,1
actionDir assertFalse  Delete the file if it is already there </prepare> doOperations <delete path=' conf getFileSystem fs delete  Test for delete as prepare action createJobConf testDelete LauncherMapper newDir <prepare> '/> mkdirs prepareXML exists  Prepare block that contains delete action setupLauncherURIHandlerConf PrepareActionsDriver getFsTestCaseDir ,oozie,1
"add request ;actionstatus=FAILED,KILLED; _execQuery assertEquals getAction brList getStatus  3 actions satisfy the conditions asList testMultipleRecords resultStatus startcreatedtime=2012-07-21T00:00Z;endcreatedtime=2012-07-22T02:00Z size FAILED get bundleName possibleStatus toString Arrays bundle= KILLED ",oozie,1
play A server readAscii cacheCanUseCriteriaBesidesVariantObeyed addHeader B getRequestCount openConnection assertEquals setBody url addRequestProperty / enqueue getUrl InMemoryResponseCache Cache-Control: max-age=60 connection1 connection4 connection3 connection2 ,okhttp,1
" ret getLocalBlock getBlock  The DN should have register to both NNs. waitForInitialization registerDatanode start assertEquals any  When we receive a block, it should report it to both NNs mockNN1 waitForBlockReport  Should get block reports from both NNs waitForBlockReceived testBasicFunctionality stop Mockito verify notifyNamenodeReceivedBlock bpos mockNN2 setupBPOSForNNs FAKE_BLOCK ",hadoop,1
JMSTopicService bab addRecordToBundleActionTable cab oozie. addRecordToWfActionTable getId WorkflowInstance getTopic addRecordToCoordActionTable setupServicesForTopic coord-action-for-action-input-check.xml addRecordToWfJobTable get TOPIC_PREFIX CoordinatorAction wab cjb bjb WorkflowJob Job init set getBundleActionId printStackTrace getConf e addRecordToBundleJobTable getMessage destroy jmsTopicService assertEquals services addRecordToCoordJobTable fail getValue Services 1 CoordinatorJob WorkflowAction getTopicPrefix testTopicAsJobId default= wfj ,oozie,1
testAnyAIDecoder3 data numeric10 isoiec6462alpha expected numeric2alpha alpha2isoiec646 alphaA alpha2numeric i646B (10)BCA10 i646C header assertCorrectBinaryString ,zxing,0
c ABC Hello StatusPrinter testComposite assertEquals parse p head result print t compile converterMap setContext context %(ABC %hello) write  } ,logback,0
actionNum nominalTime testCoordActionGet getTime getActionNominalTime actionNomialTime getId DateUtils cleanUpDBTables addRecordToCoordActionTable appPath d1 addRecordToCoordJobTable parseDateOozieTZ d2 actionXml CoordinatorJob coord coord-action-get.xml _testGetActionForDates CoordinatorAction job getCoordActionXml getFsTestCaseDir ,oozie,1
srcConf set assertEquals targetConf XConfiguration testParameter1 testParameter2 testParameter3 valueFromTarget get testCopy copy valueFromSource ,oozie,1
subwf getStatus SubWorkflowActionExecutor protoConf createBaseWorkflow getWorkflowClient newConf create action </app-path> workflow.xml getBaseProtoConf write waitFor workflow getFileSystem check childConf OozieClient lib/subwfLibrary.jar WorkflowAction wps File evaluate <sub-workflow xmlns='uri:oozie:workflow:0.1' name='subwf'>       <app-path> getJobInfo authToken subwfLibJar getActions getExternalId fs APP1 testSubworkflowLib wf createProtoActionConf assertTrue W lib/parentLibrary.jar get end WorkflowJob close getParent set getConf WorkflowAppService oozieClient start defaultConf subWorkflowAppPath subWorkflow assertEquals JOB_TIMEOUT parentLibJar setConf Services toXmlString exists toString </sub-workflow> writer getFsTestCaseDir ,oozie,1
testCompressorStream Assert file  cleanup after test case assertTrue closed shoud be true testClose close delete Expected IOException System ,hadoop,0
simulatedTime compare getName }-clean.%i bytesPerPeriod f0 f1 compareTo simulatedNumberOfPeriods System  2016-03-05 00:14:39 CET context setMaxFileSize \d{4}-\d{2}-\d{2}-clean(\.\d) Collections dailySizeBasedRolloverWithSizeCap s0 s1 computeSlashCount checkFileCount foundFiles ticksPerPeriod StatusPrinter fileNamePattern maxHistory sort params sizeCap expectedFileCount print fileSize randomOutputDir /%d{ tbfnatp logOverMultiplePeriods toString findFilesByPattern DAILY_DATE_PATTERN sizeAndTimeBasedFNATP ,logback,0
@ closeTrx coordClient getStore getTime LocalOozie Could not update db. getStatus -testCoordRerun-C getCoordClient assertTrue get beginTrx CoordinatorAction reRunCoord commitTrx waitFor bean coord-rerun-action3.xml actionNum RestConstants printStackTrace e store2 testCoordRerunCleanupNoOutputEvents store addRecordToJobTable Integer jobId Services fail CoordinatorJob addRecordToActionTable getCoordActionInfo assertNotSame actionId 0000000- toString action2 evaluate getCoordinatorAction ,oozie,1
r nextInt testShortOperationsSuccess newCall testOperations  There is no entry in cache expected when the first operation starts ,hadoop,0
banana play a b synReply android headerEntries assertEquals acceptFrame  SYN_STREAM sendFrame stream openStreamCount peer SPDY3 getResponseHeaders connection headersOnlyStreamIsClosedAfterReplyHeaders newStream ,okhttp,1
call fail addRecordToBundleJobTable bundle-id testBundleStartNegative1 Job Job doesn't exist. Should fail. ,oozie,1
MECARD:ADR:76 9th Ave;N:Sean Owen;URL:google.com;EMAIL:srowen@example.org; MECARD:N:Sean Owen;; Sean Owen 76 9th Ave srowen@example.org google.com Sean Owen +12125551212 google.com N:Sean Owen;TEL:+12125551212;; Sean Owen srowen@example.org google.com 19760520 ParsedResultType doTestResult MECARD:TEL:+12125551212;N:Sean Owen;URL:google.com;; MECARD:BDAY:19760520;N:Sean Owen;URL:google.com;EMAIL:srowen@example.org; Sean Owen srowen@example.org google.com ZXing Team MECARD:NOTE:ZXing Team;N:Sean Owen;URL:google.com;EMAIL:srowen@example.org; Sean Owen MECARD:ORG:Google;N:Sean Owen;URL:google.com;EMAIL:srowen@example.org; Sean Owen Google srowen@example.org google.com Sean Owen +12125551212 Sean Owen +12125551212 srowen@example.org google.com MECARD:TEL:+12125551212;N:Sean Owen;URL:google.com;EMAIL:srowen@example.org; MECARD:TEL:+12125551212;N:Sean Owen;; testAddressBookType ,zxing,0
date scriptExecutor session  Given update simple should_dsl_update_set_add Eq SELECT simpleset FROM simple WHERE id =  simpleset containsExactly simpleSet_AddTo  When of where id row table executeScriptTemplate RandomUtils manager getSet one nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap simpleSet  Then Long buildDateKey fromBaseTable dsl ,achilles,1
 @ Locale  send uppercase hostname When lowercase hostname is sent getDefaultRealmProtected  check that the test environment is as expected testGetServerPrincipal FooBar When uppercase hostname is sent TestKerberosUtil atDefaultRealm When no hostname is sent 0.0.0.0 localHostname Assert When empty hostname is sent  send lowercase hostname getLocalHostName testGetServerPrincipal assumes localhost realm is default  send empty hostname toLowerCase When 0.0.0.0 hostname is sent assertEquals testGetServerPrincipal assumes realm of testHost 'FooBar' is default KerberosUtil  send null hostname  send 0.0.0.0 hostname / defaultRealm service equals testHost getDomainRealm getServicePrincipal ,hadoop,0
seList Status increment inc.xml assertEquals statusChecker getHighestLevel 1 getValue se testAttributeProcessing getAttributeByName size doTest assertTrue assertNotNull get attr ,logback,0
getName getContextURL oozieUrl false admin run assertEquals oozie.authentication.simple.anonymous.allowed Authenticator4Test testClientWithCustomAuthenticator args call -oozie assertTrue setSystemProperty authenticator.class -status runTest ,oozie,1
 ParseException should have been thrown  : blah clear header : blah fail buf Assert testInvalidHeaderParsing    : : : blah append blah ,httpcore,0
"  ForTestingActionExecutor set  Retrieval to enlist the codes properly, otherwise whitespaces cause the key-value lookup to return false getConf  		     testConf allowedRetryCodes errorCodeWithWhitespaces Services contains assertTrue get LiteWorkflowStoreService  Introducing whitespaces in the error codes string  Setting configuration parameter for error codes testRetry getUserRetryErrorCode ",oozie,1
testing stale checksum getChecksumFile  checksum didn't change on disk testing 1 2 3 getBytes getRawFileSystem out  write a file to generate checksum assertTrue TEST_ROOT_DIR assertNotNull getFileStatus create got checksum error write close stat ce e testCorruptChecksum assertEquals setVerifyChecksum checksumPath str localFs testPath readFile  alter file directly so checksum is invalid exists testCorruptedChecksum ,hadoop,0
"srowen@example.org mailto:?cc=srowen@example.org doTest testCCs mailto:?cc=srowen@example.org,bob@example.org bob@example.org ",zxing,0
 Further lookups will have a delay conf asList advance sleep timer cacheGroupsAdd me setGetGroupsDelayMs getGroups grp3 getRequestCount CommonConfigurationKeys  add another groups clearBlackList groups refresh FakeGroupMapping assertEquals  have completed  Then expire that entry assertThat  a request to getGroups yet.  Another call to get groups should give 3 groups instead of 2 Thread setLong testThreadNotBlockedWhenExpiredEntryExistsWithBackgroundRefresh myGroups size  We make an initial request to populate the cache startingRequestCount Arrays isEqualTo setBoolean ,hadoop,0
cluster initBuffer  verify that full blocks are sane testComplexFlush conf fs System createFile simulatedStorage Exception : hflush  create a new file. close write /complexFlush.dat checkFile Read 2 Created file complexFlush.dat printStackTrace e Throwable : start getFileSystem fileContents stm AppendTestUtil checkFullFile  verify that entire file is good Throwable :  build SimulatedFSDataset file1 shutdown setBoolean ,hadoop,1
"testFutureGetWithTimeout server  GenericTestUtils.setLogLevel(AsyncGetFuture.LOG, Level.ALL); assertReturnValues start conf run getConnectAddress caller NetUtils stop client TimeUnit addr ",hadoop,0
"getJobTrackerUri map-reduce rootArchive rootSo soFile.so.1  with leading and trailing spaces createContext setupActionConf filesInCache <map-reduce> context getPath create jar rootJar getCacheFiles       <main-class>CLASS</main-class>       <job-tracker> eActionXml       <file> ae </file>  parseXml </job-tracker> archive getFileSystem ,   , archive  </name-node> setLibFilesArchives  found in classpath soFile.so rootSoFile.so  not found in cache jobConf archive.tar       <archive> assertFalse getAppPath appPath createBaseHadoopConf actionXml rootSo1 rootJar.jar file found so1 DistributedCache assertTrue root so filesInClasspath close getNameNodeUri getFileClassPaths rootArchive.tar c XmlUtils rootSoFile.so.1  </archive>  toUri testCommaSeparatedFilesAndArchives archivesInCache file  getSymlink  not found in classpath </map-reduce> p getCacheArchives ,  equals rootFile toString       <name-node> getFsTestCaseDir jar.jar ",oozie,1
chmod1 chmod2 chmod3 source createContext grandchild1 grandchild3 xml getPath getFileStatus testDoOperations mkdir <root><mkdir path=''{0}''/> getPermission ae format parseXml <chmod path=''{4}'' permissions=''-rwxrwxrwx''/> getFileSystem </root> str rwxrwx--- mkdirs <chmod path=''{5}'' permissions=''-rwxrwx---'' dir-files=''false''/> newFile2 <fs/> newFile1 assertFalse doOperations <touchz path=''{7}''/> child2 fs delete child3 child1 assertTrue <move source=''{2}'' target=''{3}''/> MessageFormat XmlUtils <delete path=''{1}''/> toUri assertEquals rwxrwxrwx target <touchz path=''{6}''/> assertNotSame exists toString createNewFile getFsTestCaseDir <chmod path=''{8}'' permissions=''-rwxrwx---''> <recursive/> </chmod> ,oozie,1
getJobTrackerUri A getName <java> getStatus createContext actionXml isSuccessful load assertTrue assertNotNull get context end <arg>out</arg> waitFor <job-tracker> getData sr getNameNodeUri a </java> ae </main-class> <capture-output/> </job-tracker> runningJob getAction assertEquals check testOutputSubmitOK getExternalStatus <name-node> <main-class> props </name-node> WorkflowAction SUCCEEDED submitAction evaluate isComplete ,oozie,1
play  play it back headerEntries  verify the peer received what was expected TYPE_RST_STREAM timeout System acceptFrame elapsedNanos stream openStreamCount TYPE_HEADERS peer nanoTime getResponseHeaders TimeUnit connection toMillis getResponseHeadersTimesOut takeFrame banana b assertEquals  RST_STREAM fail  SYN_STREAM SPDY3 readTimeout newStream startNanos ,okhttp,1
" cee bee  unparseable ""frequency"" value:  ""unit"" specified, but ""frequency"" is not:  empty String:  null argument: parseFilter  no eq sign in token:  incorrect ""status"" key value: winniethepooh getErrorCode assertNotNull map testParseFilterNegative ce FreQuency=foo  unparseable ""unit"" value: kk=vv=zz status=foo foo=moo assertEquals fail unit=minutes  incorrect k=v: size UniT=foo  unknown key in key=value pair: CoordinatorEngineException expected. ErrorCode ",oozie,1
date value_tenant3 scriptExecutor tableNameFor session  Given insert tableName crud SELECT * FROM  provider  When of id row simple_insert_with_schema_name value table SimpleEntity/create_simple_mirror_table.cql executeScriptTemplate withSchemaNameProvider isNotNull RandomUtils manager should_insert_with_schema_name_provider one  WHERE id =  getString nextLong assertThat execute ImmutableMap keyspaceFor  Then Long buildDateKey isEqualTo entity DEFAULT_CASSANDRA_EMBEDDED_KEYSPACE_NAME ,achilles,1
cluster conf run testHflushWhileClosing fs  Close it while the flushing threads are still flushing createFile hflush get /hflush-and-close.dat join flusher close write  Wait for the flushers to all die. add set flushers start  else. thrown getFileSystem stm p contains t build toString DFSOutputStream is closed  Write some data shutdown ioe ,hadoop,1
"addToken  one duplicate with different value, one new getSecretKey numberOfSecretKeys  new token & secret should be added assertEquals secret creds  non-duplicate token & secret should be present getBytes token addAll numberOfTokens service credsToAdd getToken addSecretKey  existing token & secret should be overwritten ",hadoop,0
kills a b addNode def f enters start j assertEquals WorkflowInstance getStatus asList wf 1 fail exits size <worklfow-app/> testFailWithRunningNodes end Arrays job fails ,oozie,1
subwfAction5 addRecordToWfActionTable getId WorkflowInstance testGetCoordinatorParentTooMany wfJob addRecordToWfJobTable children assertNotNull get subwfJob1  Get the next 3 (though there's only 2 more) WorkflowJob subwfJob5 subwfAction1 subwfJob4 subwfAction2 subwfJob3 subwfAction3 subwfJob2 subwfAction4  Get the first 3 assertEquals wfAction1 wfAction2 execute wfAction3 wfAction4 wfAction5 checkChildren Services 1 2 3 4 size WorkflowAction 5 addAll jpaService ,oozie,1
EXEC_ORDER callable2 callable3 callables callable1 c QueueUniquenessWithDiffKey asList queueservice Services assertTrue QueueUniquenessWithDiffKey2 QueueUniquenessWithDiffKey1 get QueueUniquenessWithDiffKey3 testQueueUniquenessWithDiffKey Arrays evaluate waitFor queue ,oozie,1
getSecretKey getCurrentUser otherSet getTokens TheDoctor getCredentials run when creds remove TheTARDIS ugiCreds assertTrue Shouldn't be able to modify token collection from UGI ugi  ensure that the tokens are passed through doAs addSecretKey UserGroupInformation createUserForTesting shhh addToken secretName secretKey addCredentials numberOfSecretKeys thenReturn unchecked  from Mockito mocks assertEquals assertSame getService testUGITokens fail contains doAs size mock z t1 t2 ,hadoop,0
enumParam assertFalse context enumParamShouldHandleNull create verify hasViolations invoke mockController validation ,ninja,0
addRecordToBundleActionTable getCurrentDateafterIncrementingInMonths getId run DateUtils getStatus parseDateOozieTZ bundleJob assertNotNull get end currentDatePlusMonth Job bundle waitFor testBundleStatusTransitServiceKilled1 addRecordToBundleJobTable bundleId start assertEquals XDataTestCase execute addRecordToCoordJobTableWithBundle call Services CoordinatorJob runnable action1 action2 jpaService evaluate ,oozie,1
addRecordToBundleActionTable getCurrentDateafterIncrementingInMonths run DateUtils WorkflowInstance getStatus addRecordToCoordActionTable parseDateOozieTZ bundleJob assertNotNull CoordinatorAction currentDatePlusMonth Job waitFor init bundleAction1 bundleAction2 destroy XDataTestCase execute addRecordToCoordJobTableWithBundle coordJob2 CoordinatorJob coordJob1 evaluate setClassesToBeExcluded assertFalse getId getExternalId isPending wfJob addRecordToWfJobTable assertTrue get end coordAction1_3 WorkflowJob coordAction1_4 bundle coordAction1_1 coordAction1_2 getConf false addRecordToBundleJobTable bundleId start assertEquals services testBundleStatusTransitServiceRunningWithError call Services runnable coord-action-get.xml excludedServices setSystemProperty equals StatusTransitService action1 action2 jpaService ,oozie,1
" getCurrentUser conf run echo testRpcMetrics assertQuantileGauges lockAndSleep assertGauge RpcLockWaitTimeNumOps proxy2 RpcQueueTimeNumOps UserGroupInformation "" getStringMetric printStackTrace RpcQueueTime createRemoteUser RpcProcessingTime newSleepRequest proxy doAs RpcProcessingTimeNumOps contains stop name RpcLockWaitTimeAvgTime interval Expected correct rpc lock wait count getRpcMetrics server RPC getProxy ping actualUserVsCon getMetrics newEmptyRequest getListenerAddress getLongCounter NumOpenConnectionsPerUser anotherUser Expected zero rpc lock wait time assertTrue stopProxy "":1 testUser addr getShortUserName Expected correct rpc processing count set CommonConfigurationKeys e Expected correct rpc queue count assertEquals getClient rpcMetrics proxyUser setupTestServer MetricsAsserts getDoubleGauge newEchoRequest setBoolean ",hadoop,0
"map-reduce yarn.resourcemanager.address executeWhileJobTrackerIsShutdown addRecordToWfActionTable  Make the max number of retries lower so the test won't take as long conf WorkflowInstance  It should now continue and finish with SUCCEEDED getJob context waitFor init getStatusStr job0 job2 launcherJob2 job1 RUNNING parseXml destroy mapperId testActionCheckTransientDuringMRAction execute jobId 1 maxRetries  Disable ActionCheckerService so it doesn't interfere by triggering any extra ActionCheckXCommands WorkflowAction SUSPENDED SUCCEEDED actionId evaluate JobID setClassesToBeExcluded  Now, shutdown the job tracker to pretend it has gone down during the map-reduce job launcherId START_MANUAL assertFalse actionExecutor user.name getId originalMapperId getExternalId createBaseHadoopConf hasIdSwap action1a createJobConf action1b sleep isSuccessful addRecordToWfJobTable assertTrue LauncherMapper getRetries get  When using YARN, skip this test because it relies on shutting down the job tracker, which isn't used in YARN WorkflowJob launcherJob getConf XmlUtils forName wfActionGetCmd oozie.action.retries.max org.apache.oozie.service.ActionCheckerService assertEquals services mrJob getExternalStatus Integer call originalLauncherId Services createJobClient setSystemProperty equals toString action0 jobClient action1 action2 jpaService user action3 action4 isComplete action5 ",oozie,1
offer c size fcq assertEquals remainingCapacity mockedPriorities mockCall testAllQueuesFullRemainingCapacity ,hadoop,0
writeRecords getValueLength reader testFailureReadValueManyTimes vlen skip conf vbuf assertEquals VALUE createScanner fs Cannot get the value mlutiple times. path entry getValue fail Assert getLen getFileStatus scanner BUF_SIZE close open ,hadoop,0
"getJobTrackerUri _testSubmit       <pipes> output <map-reduce> create write <job-tracker>         <program> currentThread </job-tracker> is dummy  getFileSystem getPipesConfig <name-node> </name-node> input getContextClassLoader </program> <file> data.txt testPipes wordcount-simple       </pipes> fs binary 'wordcount-simple' not available in the classpath System actionXml </file> close pipes getNameNodeUri outputDir SKIPPING TEST: TestMapReduceActionExecutor.testPipes(),  os getResourceAsStream inputDir Thread </map-reduce> IOUtils programPath copyStream w #wordcount-simple toXmlString toString getFsTestCaseDir ",oozie,1
getConnectionContext getEventMessage conf parseDateUTC DateUtils getStatus wf-app-name1 caId1 2012-07-22T00:00Z wfId1 getStartTime MessageType init printStackTrace getText destroy wfEventListener fail contains onWorkflowJobEvent createConsumer AppType startDate getParentId getAppType session assertFalse JMSMessagingUtils getEventStatus getUser EventStatus getId createSession getTopic testOnWorkflowJobSuspendEvent getErrorCode WorkflowJob jmsContext consumer user1 getMessageType receive getAppName e getMessage assertEquals message assertNull wfe wfFailMessage endTime Session getErrorMessage ,oozie,1
"Status  half of it, so no CHECKSUM_OK reader sendReadResult FILE_SIZE_K testIncompleteRead never readAndCheckEOS util testBlock getBlockReader verify spy close ",hadoop,1
/test/testGetFileBlockLocations cluster computed f expected assertEquals  the following are new tests (i.e. not over-riding the super class methods) getFileSystem testGetFileBlockLocations fs createFile path toString getFileBlockLocations ,hadoop,1
"startServerProduceConsumeTopics getName otherID ConfigUtils put assertArrayEquals features iterator getFirst testALSSpeed UP id knownUsersItems expected oryx.speed.streaming.block-interval-sec unchecked MockALSModelUpdateGenerator oryx.als.hyperparams.features size overlayOn isDebugEnabled getExtensionValue buildMatrix next       * User 100 - 104 are solutions to eye(5)*Y*pinv(Y'*Y), but default scaling      * will produce values that are 3/4 of this since they are brand new.      * That is, it's really the solution to (0.75*eye(5))*Y*pinv(Y'*Y)      * Likewise 105 - 108 are (0.75*eye(4))*X*pinv(X'*X)       PMMLUtils log update updates startMessaging convertValue  10 original updates. 9 generate just 1 update since user or item is new. expectedKnownUsersItems assertTrue get X Y MAPPER readValue {} debug containsAll AppPMMLUtils assertEquals MODEL getConfig isX Integer parseInt oryx.speed.streaming.generation-interval-sec equals getSecond overlayConfig toString fromString oryx.speed.model-manager-class config ",oryx,1
"rollMasterKey retrievePassword bi newPasswd  compare the passwords oldPasswd  after rolling, the length of the keys list must increase sleep generateDelegationToken Assert  wait for keys to expire getAllKeys assertTrue isGreaterThanOrEqualTo getIdentifier dtSecretManager startThreads prevNumKeys createIdentifier identifier JobTracker assertEquals stopThreads assertThat token Thread readFields SomeUser getPassword currNumKeys  is not valid)  store the length of the keys list testRollMasterKey  generate a token and store the password ",hadoop,0
testWritable testByteWritable ,hadoop,0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0  embedDataBits  1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0  MatrixUtil getVersionForNumber expected bits testEmbedDataBits  1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0  assertEquals matrix embedBasicPatterns  1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1   1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 1  Version  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0   1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0   Cells other than basic patterns should be filled with zero. clearMatrix  1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1   0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  toString  1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1  ,zxing,0
"checkCoordJobs <coordinator-app name=""NAME"" frequency=""10"" start=""2009-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""  conf appPath substring sc writeToFile appXml file:// getTestCaseDir UNIT_TESTING xmlns=""uri:oozie:coordinator:0.2"">  <configuration> <property> <name>inputA</name> <value>blah</value> </property>  coordinator.xml set length assertEquals testSubmitNoControls </configuration> </workflow> </action> </coordinator-app> call OozieClient jobId getTestUser -C <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>  File ",oozie,1
"Unexpected Exception def addNode printStackTrace e f one j k testDecisionForkJoin kill three two asList fail invokeForkJoin parser four name dummyConf end      f->(2,3)     2->decision node->{4,5,4}     4->j     5->j     3->j      Arrays five ",oozie,1
nextFloat random rand1 rand2 testRandomFloat ,hadoop,0
getCurrentDateafterIncrementingInMonths testCoordStatusTransitServiceSucceeded getId run DateUtils getStatus addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob sleep get CoordinatorAction end currentDatePlusMonth start assertEquals XDataTestCase execute addRecordToCoordJobTable CoordinatorJob Services runnable coord-action-get.xml job jpaService ,oozie,1
20080504T123456Z doTest testGeo BEGIN:VCALENDAR BEGIN:VEVENT  GEO:-12.345;-45.678  DTSTART:20080504T123456Z  END:VEVENT END:VCALENDAR ,zxing,0
new_val scriptExecutor SELECT * FROM entitywithstaticcolumn WHERE id =  EntityWithStaticColumn/insert_single_row.cql session  Given update UUIDs uuid crud should_update new_static  When of id value static_col executeScriptTemplate isNotNull actual RandomUtils manager one timeBased getString nextLong assertThat execute ImmutableMap  AND uuid =   Then Long isEqualTo entity ,achilles,1
getJobsInfo getJobInfo testGetJobsInfo foo LocalOozie assertEquals OozieClientException expected. oce fail getCoordClient getErrorCode client toString ErrorCode foo-id ,oozie,1
 test that the addChildren method is called verifyNoMoreInteractions test unchecked addChildren mock verify expr expressions ,hadoop,0
Action should be purged. Should fail. Job should be purged. Should fail. getCurrentDateafterIncrementingInMonths getId run DateUtils coordJobGetExecutor getStatus addRecordToCoordActionTable parseDateOozieTZ testPurgeServiceForCoordinator coordActionGetExecutor engine assertNotNull get CoordinatorAction action purgeRunnable end currentDatePlusMonth waitFor getCoordJob a start assertEquals XDataTestCase execute addRecordToCoordJobTable CoordinatorJob jobId Services fail coord-action-get.xml u job jpaService evaluate ,oozie,1
"numWindows replaceScheduledTask rollingTotal anyDouble monotonicNow  insert value  Time rollingAverages           * #1 window with a series of 1 1000          * times, e.g. [1, 1...1], similarly, #2 window, e.g. [2, 2...2],          * #3 window, e.g. [3, 3...3]           sleep  5s roll over interval times TimeUnit Rolling average time for foo2 verify  Verify the metrics were added the right number of times   one empty window or all 2 windows full  foo2 numOpsPerIteration info add windowSizeMs  Verify that the window reset, check it has the values we pushed in  addGauge start  Push values for three intervals  j eq rollingSum Thread rb [Foo2]RollingAvgTime testRollingAveragesRollover mockMetricsRecordBuilder name snapshot ",hadoop,0
cluster  close the file and the counter should go to zero. dm dn getBlockManager fs testBlocksScheduledCounter waitActive out  open a file an write a few bytes: hflush getDatanodeManager get /testBlockScheduledCounter create write fetchDatanodes close dnList  flush to make sure a block is allocated. assertEquals getFileSystem getWrappedStream build getBlocksScheduled getNamesystem ,hadoop,1
fail expected timeout e testRedirectConnectTimeout connect timed out startSingleTemporaryRedirectResponseThread getMessage TEST_TIMEOUT assertEquals getFileChecksum /file fs ,hadoop,1
_test isMainSuccessful actionDir hasOutputData assertFalse runningJob isMainDone getFileSystem fs hasIdSwap getIdSwapPath isSuccessful assertTrue LauncherMapper getErrorPath exists getOutputDataPath id testNewId evaluate waitFor getFsTestCaseDir isComplete ,oozie,1
testFactoryForNanoseconds TimeUnit testFactory ,httpcore,0
conn setRequestMethod IS_SECURITY_ENABLED /v0/admin/* assertTrue get testStatus json content-type Collections runTest JsonTags RestConstants openConnection HttpServletResponse assertEquals parse getInputStream url JSONValue call getHeaderField GET getResponseCode createURL startsWith ,oozie,1
play  Verify the peer received what was expected. data Okio TYPE_DATA assertFlushBlocks HTTP_20_DRAFT_09 headerEntries  receiving a window update on the connection isn't enough. getSink out acceptFrame flush  Check that we've filled the window for both the stream and also the connection. stream TYPE_HEADERS DEFAULT_INITIAL_WINDOW_SIZE peer connection getStream framesThatFillWindow buffer roundUp write writeAwaitsWindowUpdate takeFrame banana windowUpdate b writeByte  DATA we won't be able to flush until a window update.  DATA assertEquals maxFrameSize  SYN_STREAM SPDY3  Play it back. synStream newStream  receiving a window update on the stream will unblock the stream. ,okhttp,1
testWfKillFailed wfActionGetCmd getWorkflowInstance addRecordToWfActionTable getId assertEquals WorkflowInstance getStatus execute call 1 Services addRecordToWfJobTable WorkflowAction assertNotNull get action WorkflowJob job wfInstance jpaService wfJobGetCmd ,oozie,1
 Horizontal 10111010000.  Horizontal 00001011101. set applyMaskPenaltyRule3  Vertical 00001011101. testApplyMaskPenaltyRule3 assertEquals  Vertical 10111010000. matrix MaskUtil ,zxing,0
/newfile3 /newfile1 /newfile2  Test touchz on a non-zero length file fs2 <fs/> fs1 is a directory assertFalse f1 dir f2 fs createContext f3 assertTrue getLen context getFileStatus create write close must be a zero-length file touchz ae testTouchz getMessage getFileSystem dir1 fail contains ex mkdirs exists writer createNewFile This is not a zero length file getFsTestCaseDir isDir ,oozie,1
"createClient clear createStage assertEquals poll  actor.addReminder(""bla"", 0, 20, TimeUnit.MILLISECONDS).join(); actor 1 bind assertNull stop bla addReminder IActor TimeUnit stage2 join remindersReceived getReference persistedTimerTest stage1 frontend ",orbit,1
addNode def testLoopFork f one start j assertEquals WorkflowInstance getStatus three two asList wf 1 fail ex getErrorCode four <worklfow-app/> end ErrorCode Arrays job ,oozie,1
encode X X X X X X X X   X   X   X       X X X X   X   X         X         X   X X     X     X X X X X X     X X X           X   X X       X   X X X   X           X X     X     X X X X X X   X   X   X X X       X X X X X X X   X       X   X     X   X X X X X X X X   X   X   X       X   X   X X X X     X X X X       X         X X       X X     X     X   X     X X X X       X X X X   X       X X       X X         X   X X   X   X X X X     X X X X X   X X X X X X X   X       X   X     X   hints BarcodeFormat expected Hello Google assertEquals matrix X X X X X X X X   X   X   X       X   X   X     X X X X             X   X X X       X       X X       X     X X   X X     X X X X       X X       X X X X X     X     X   X   X   X         X X X X         X X X X X X X   X       X   X     X   X X X X X X X X   X   X   X       X X   X   X X X           X       X X     X       X X X     X       X X X X X X   X X   X     X X     X   X X X   X     X X X X X       X X X   X   X X X     X X         X X X X X X X   X       X   X     X   put X X X X X X X X   X   X   X       X X X X   X   X   X X X X         X X   X   X           X X         X X X X   X X     X     X X X     X X   X           X       X X     X X X X X   X   X   X X X X X     X X X X X X X   X       X   X     X   X X X X X X X X   X   X   X       X X X X X   X   X X X X   X X     X           X   X       X X X X   X       X   X         X X X X     X           X X X   X       X X   X X X X   X   X X X X X   X X     X X X X X X X   X       X   X     X   EncodeHintType size testDataMatrixImageWriter assertNotNull toString writer ,zxing,0
HTTP/1.1 200  testSLFormatting HttpStatus clear assertEquals formatStatusLine buf Assert statusline1 toString OK HttpVersion HTTP/1.1 200 OK statusline2 ,httpcore,0
"cluster getCurrentUser half conf run HARD_LEASE_LIMIT waitActive ugi FileSystem create  d. On M2, open file and read 1 block of data from it. Close file. setLeasePeriod write checkFile info UserGroupInformation createUserForTesting  of data can be read successfully. DFSConfigKeys interruptAndJoin newInstance getFileSystem dfs getInt setLong getWrappedStream doAs  hflush numDataNodes pipeline_02_03 shutdown  create cluster  wait for the cluster BLOCK_SIZE fs out leasechecker.interruptAndJoin() sleep  enable append current  sleep to let the lease is expired. hflush  Do not close file yet.  c. On M1, append another half block of data.  Close file on M1. close SOFT_LEASE_LIMIT getShortUserName supergroup getConf DIR io.file.buffer.size AppendTestUtil Thread p build file1  change the lease limits. append setBoolean ",hadoop,1
monotonicNow incrementAndGet logWarning  t = 0 readWriteLock get lock suppressed wsuppresed set unlock getMethodName wlogged LOG mclock readLock assertEquals testReadLockLongHoldingReport testname  t = 900 name  t = 500 time  t = 100  t = 3000 ,hadoop,0
coordActionGetCmd getCurrentDateafterIncrementingInMonths getId DateUtils getStatus addRecordToCoordActionTable parseDateOozieTZ assertNotNull get CoordinatorAction action end currentDatePlusMonth start assertEquals XDataTestCase execute addRecordToCoordJobTable call CoordinatorJob Services coordJobGetCmd coord-action-get.xml testCoordKillSuccess1 job jpaService ,oozie,1
expectedContents inputs L barcodeContents asList result assertNotNull ResultMetadataType processStructuredAppend testProcessStructuredAppend results SA1SA2SA3 QRCodeMultiReader add SA1 sa1 SA3 sa3 SA2 sa2 BarcodeFormat getText assertEquals size putMetadata Arrays nsa NotSA ,zxing,0
bundleJobGetExecutor cJob1 addRecordToBundleActionTable pauseStartRunnable getCurrentDateafterIncrementingInMonths getId run DateUtils getStatus parseDateOozieTZ setPauseTime assertNotNull get setBundleId end currentDatePlusMonth Job waitFor bJob1 bundleAction1 bundleAction2 addRecordToBundleJobTable start assertEquals testUnpauseBundleAndCoordinator XDataTestCase execute addRecordToCoordJobTable coordJob2 Services CoordinatorJob jobId coordJob1 coordJobId1 coordJobId2 action1 job action2 jpaService evaluate ,oozie,1
checkCoordActions getId DateUtils parseDateOozieTZ addRecordToCoordJobTable 2009-03-06T10:00Z call CoordinatorJob pauseTime startTime endTime 2009-03-06T10:04Z job testActionMaterWithPauseTime1 2009-03-06T10:14Z ,oozie,1
date scriptExecutor AND date = '2015-10-01 00:00:00+0000' session  Given update simple UPDATE simple SET simpleset = simpleset + {3} WHERE id =  Eq SELECT simpleset FROM simple WHERE id =  simpleset containsExactly Sets  When of where id row table executeScriptTemplate RandomUtils manager getSet one nextLong simpleSet_RemoveAllFrom assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap simpleSet newHashSet  Then should_dsl_update_set_removeAll Long buildDateKey fromBaseTable dsl ,achilles,1
"  bcb  bc ef ELConstantsFunctions acd aefefd assertEquals , replaceAll testReplaceAll ayyycd d1 d2 d3 abcbcd yyy XYZ d1,d2,d3 ",oozie,1
getElementById disabledDiv getPage assertFalse Text for ENABLED feature! index.jsf url enabledDiv  this part is disabled contains assertNull assertTrue  this part of the page is rendered Text for DISABLED feature! assertNotNull  one div can be found the other not client page asText testJSFFeatureMap ,togglz,1
a b getVariables testVariables assertEquals counter addVariable 1 getValue 2 size inst get ,oozie,1
init a generateChildId generateId destroy getId assertEquals counter services childId uuid getChildName ApplicationType random testChildId setSystemProperty get UUIDService id ,oozie,1
testFields Number of ops for rs1 Average time for s1 Number of ops for r1 getMetrics R1AvgTime G1 source G2 G3 S1AvgTime G4 C1 addCounter rs1 Counter2 desc verify Average time for rs1 info g3 desc add addGauge R1NumOps Number of ops for s1 incr Average time for r1 g4 desc Rs1AvgTime rb makeSource MetricsAnnotations S1NumOps metrics Counter2 Rs1NumOps ,hadoop,0
"regex length buildDto context doCheckValidationPassed validateJSR303 validationPassed  @Length(min = 5, max = 10) String param2, @Min(3) @Max(10) int param3); ",ninja,0
date LOCAL_ONE  Given simple 0 AM SELECT * FROM simple WHERE id =  asList consistencyList_Set ConsistencyLevel  When getList id isNotNull RandomUtils assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap usingTimeToLive hasSize  Then Long buildDateKey fromBaseTable consistencyList Arrays dsl Set scriptExecutor getTime session update Eq consistencylist usingTimestamp sleep containsExactly QUORUM of where row value table executeScriptTemplate manager one should_dsl_update_with_ttl getString nextLong Thread new value isEqualTo  AND date = '2015-10-01 00:00:00.000+0000' ,achilles,1
_testTransient testStartTransient assertTrue start start.transient WorkflowActionBean ,oozie,1
2009-02-01T01:00Z start run getId assertEquals DateUtils getStatus execute parseDateOozieTZ addRecordToCoordJobTable coordGetCmd coordJob sleep getMatThrottling CoordinatorJob Services runnable testCoordMaterializeTriggerService1 get numWaitingActions end 2009-02-20T23:59Z job jpaService ,oozie,1
fail stop assertNotNull LocalOozie start getOozieUrl assertEquals getClient wc testLocalOozieInitDestroy localoozie ,oozie,1
jobConf submit log submit result should not contain -->  appPath Configuration parse error. read from DB : getJob result  result includes bundle-submit-job.xml file instead of jobId since this is a dryRun mode assertTrue assertNotNull get  bundle-submit-job.xml contains the Apache license but this result should not contain the comment block CREATE_TIME setStartTime Job bundleBean <!-- --> testJobXmlCommentRemoved set getConf addRecordToBundleJobTable bundle.xml command call Services warn OozieClient contains submit result should not contain <!--  setEndTime  this retrieves bundle-submit-job.xml toString ErrorCode job jpaService ioe ,oozie,1
"test.txt watchDir newTxtFile  add a new file  windows may mod a file more than once watcherThread run (.*)included.txt DEFAULT_EXCLUDE_PATTERNS delete newIncludedTxtFile asList timeout getBytes included.txt  modify the file assets  indicates exclusion rule for modified files didn't work interrupt test.png verify  trigger should have been called soon atMost after close write watcher  indicates exclusion rule for new files didn't work  windows may do 2 mods so we need to check range  file that would be excluded in assets directory, but we'll include a rule to include it os target/fake-watch-dir start newPngFile trigger restartTrigger Hello! never toPath Mockito mkdirs assetsDir mock reset atLeast Arrays shutdown  make sure file does not yet exist ",ninja,0
"deleteList testDeleteCoordsRollback Coordinator Action C2 should not have been deleted getId actionC1 addRecordToCoordActionTable actionC2 actionA1 Coordinator Job A should not have been deleted actionA2 deactivate jobB jobA assertNotNull  Remove fault injection jobC get Coordinator Action C1 should not have been deleted CoordinatorAction Coordinator Action A2 should not have been deleted add Should have skipped commit for failover testing Coordinator Action A1 should not have been deleted Skipping Commit for Failover Testing Coordinator Job C should not have been deleted getMessage Coordinator Action B2 should not have been deleted assertEquals SkipCommitFaultInjection actionB1 execute addRecordToCoordJobTable actionB2 FaultInjection CoordinatorJob Services fail coord-action-get.xml re org.apache.oozie.command.SkipCommitFaultInjection setSystemProperty true Coordinator Action B1 should not have been deleted  set fault injection to true, so transaction is roll backed Coordinator Job B should not have been deleted jpaService ",oozie,1
bodyParserEngineXml testXmlBodyWithMissingVariables thenReturn <form><firstName>%s</firstName><lastName>%s</lastName></form> BodyParserEngineXmlTest format equalTo testForm is invoke String assertThat getInputStream when getBytes Mockito assertTrue xmlObjMapper context xmlDocument close ,ninja,0
 a testWriteReadLock l1 l2 start assertEquals sb Thread sleep a:1-L a:1-U a:2-L a:2-U trim finish toString ,oozie,1
date rs %msg - [%thread]%n ASYNC_LOGGER_STRING session  Given insert SELECT * FROM simple WHERE id =  crud prepareLogLevel should_insert_async  When getTimestamp get await id latch countDown row value executeAsync info logAsserter all RandomUtils manager withResultSetAsyncListener getString nextLong rows assertThat execute assertContains getLong CALLED hasSize  Then Long LOGGER Called - [achilles-default-executor isEqualTo entity ,achilles,1
Optional  ONE DEFAULT LOCALE thenReturn NinjaConstant getStringArray language getLocaleFromStringOrDefault ninjaProperties lang when testGetLocaleFromStringOrDefaultISEWhenNoApplicationLanguageDefined empty ,ninja,0
jobConf getName reader authToken testSchema assertNotNull getTestCaseDir /workflow.xml get file:// workflow.xml test-wf parseDef app init set wf-schema-valid.xml destroy assertEquals services wf-schema-invalid.xml OozieClient fail IOUtils getTestUser copyCharStream getResourceAsReader writer wps File ,oozie,1
testExpand h h1 h2 assertEquals h3 h4 fifoBuffer assertSame removeLast getLast n 1 2 3 Assert 4 size getFirst get addFirst ,httpcore,0
rw assertFalse channel header stuff;more stuff testCodingFromFileFlushBuffer getBytes stuff; Assert getChannel writeLine more stuff dump chbuffer close write fchannel isCompleted testfile StandardCharsets createTempFile assertEquals encoder transfer outbuf header metrics append ,httpcore,0
BB  Make a configuration file with a final property A prop;  Ignoring. loggingEvent getLog logger declareProperty conf Logger getRenderedMessage getBytes out removeAppender  Make sure the appender is removed addAppender did not see expected string inside message  assertTrue addResource prop get overriding a final parameter should cause logging getRootLogger  Make a second config file with a final property with a different value events should see the first value endConfig  Attach our own log appender so we can verify output startConfig appender assertEquals in2 in1 contains size bytes an attempt to override final parameter:  toString writer  Add the 2 different resources - this should generate a warning testFinalWarnings bytes2 renderedMessage ,hadoop,0
conn setRequestMethod IS_SECURITY_ENABLED assertTrue json content-type /v1/admin/* Collections runTest RestConstants openConnection containsKey HttpServletResponse assertEquals parse USER getInputStream url JSONValue call testOsEnv getHeaderField GET getResponseCode createURL startsWith ,oozie,1
@ closeTrx coordClient getStore getTime LocalOozie Could not update db. getStatus -testCoordRerun-C getCoordClient get beginTrx CoordinatorAction reRunCoord commitTrx actionNum RestConstants printStackTrace store1 e store2 assertEquals store testCoordRerunActions1 addRecordToJobTable Integer jobId Services fail CoordinatorJob addRecordToActionTable assertNotSame actionId 0000000- toString action1 action2 coord-rerun-action1.xml getCoordinatorAction ,oozie,1
testNoError clone PDF417_TEST_WITH_EC received checkDecode  no errors ,zxing,0
myFile fileName getName  Create a file with a new name listStatus conf run emptierThread FileSystem  should've been deleted and Current might not have been recreated yet getPath interrupt join emptier mkdir TEST_DIR val add init FS_TRASH_INTERVAL_KEY -rm  Delete the file to trash trashDir trash test/mkdirs/myFile FS_TRASH_CHECKPOINT_INTERVAL_KEY size  12 seconds shell  First create a new directory with mkdirs  Start Emptier in background fs.default.name files  Scan files in .Trash and add them to set of checkpoints getUri myPath testTrashEmptier  6 seconds getLocalizedMessage fs System sleep file assertTrue getCurrentTrashDir  If checkpoints has 4 objects it is Current + 3 checkpoint directories writeFile getParent set fileIndex e setClass start checkpoints setConf Thread args 0.1 0.2 Exception raised from Trash.run  getLocal getEmptier test/mkdirs toString fs.file.impl ,hadoop,0
child_value scriptExecutor session  Given simple Eq delete  When of where id EntityAsChild/insert_single_row.cql SELECT * FROM entity_child WHERE id =  row value table anotherValue executeScriptTemplate isNotNull val RandomUtils manager one should_dsl_delete getString nextLong assertThat execute ImmutableMap isTrue  Then isNull Long fromBaseTable dsl isEqualTo ,achilles,1
"add a b c set getStringCollection assertEquals  a, b , c   Check that the result is mutable assertArrayEquals strs size does-not-exist  Make sure same is true for missing config toArray getTrimmedStringCollection z testGetStringCollection ",hadoop,0
conn inStream getContent assertEquals createIncomingEntity message getContentLength content ContentLengthStrategy Assert isChunked Mockito assertTrue assertNotNull mock testCreateEntityInputChunked OK entity ,httpcore,0
createUserForTesting  IP_RANGE set  now set a blocked MachineList drwho refresh BLOCKED_HOST_CONFIG conf testBlockedMachineList drwho@EXAMPLE.COM group2 group1 serviceAuthorizationManager fail  reset blocked MachineList  test without setting a blocked MachineList getByName InetAddress authorize 10.222.0.0 UserGroupInformation ,hadoop,0
app set RestConstants conf getFileSystem testReRun appPath OozieClient getTestUser _testAction mkdirs create workflow.xml toString close getFsTestCaseDir ,oozie,1
Non-unique bundles present for same bundle name request 00002-12345-B assertTrue testMultipleBundleIdsForName setId setStartTime jex bundle bundleInsert setAppName  exception expected due to >1 records found for same bulkjpa BundleEngine getMessage  Adding another bundle having same name execute setStatus fail contains parseBulkFilter bundleName BundleJob jpaService bundle= ,oozie,1
cluster 1.x1 scriptArgs dg scriptFile2 scriptFile1 DIR_STRUCTURE_FIRST_LINE -maxDelayBetweenOps   run /test waitActive MAX_DELAY_BETWEEN_OPS SCRIPT_TEST_DIR script2 -readProbability ELAPSED_TIME write 10 -root READ_PROBABILITY 2 .22 .33  -1 oldArg DIR_STRUCTURE_FILE -scriptFile loadgenscript script / 0 1 1.1 numDataNodes OUT_DIR Long CONF -startTime shutdown TEST_SPACE_ROOT START_TIME  Test with good script FILE_STRUCTURE_SECOND_LINE NUM_OF_THREADS -writeProbability Time delete -elapsedTime fw now 6 0 .7  FILE_STRUCTURE_FIRST_LINE close -inDir  Test with bad script getAbsolutePath FILE_STRUCTURE_FILE assertEquals setConf -numOfThreads args -1.1 loadgenscript2 build 0.3 3 .10 .6  3 blah blah blah .6  DIR_STRUCTURE_SECOND_LINE WRITE_PROBABILITY toString writer lg 0.9 testLoadGenerator ,hadoop,1
request conn getRequest when Assert flush executor context create verify OK postProcess process thenReturn getResponse Method getEntity assertSame execute testBasicExecution / Mockito response HttpCoreContext httprocessor mock preProcess receiveResponseHeader sendRequestHeader receiveResponseEntity ,httpcore,0
" interval is 1 hours, so we just test if these metrics exist. ReadWriteDiskValidator WriteLatency3600sNumOps WriteLatency3600s50thPercentileLatencyMicros getFileReadQuantiles getMetrics getEstimator source WriteLatency864000sNumOps LastFailureTime metrics of file read is not right System getFileWriteQuantiles collector ReadLatency3600s50thPercentileLatencyMicros checkStatus Assert ReadWriteDiskValidatorMetrics get getRecords ReadLatency864000sNumOps assertMetric testReadWriteDiskValidator test.build.data getCount WriteLatency86400sNumOps getProperty FailureCount MetricsRecords ms count readWriteDiskValidator assertEquals ReadLatency3600sNumOps testDir The count number of estimator in MutableQuantiles metric DiskValidatorFactory getSource toString getInstance getMetric sourceName ReadLatency86400sNumOps assertMetricNotNull metrics of file write is not right ",hadoop,0
getBytesTransferred rw CodecTestUtils assertFalse channel  transferred from buffer stuff; more stuff;  Assert inbuf getChannel pos assertTrue stuff; more stuff; a lot more stuff! a lot more stuff!!! close fchannel isCompleted  transferred from channel testfile StandardCharsets bytesRead assertEquals createTempFile decoder fill transfer readFromFile metrics testDecodingFileWithLimit ,httpcore,0
wfActionGetCmd getWorkflowInstance addRecordToWfActionTable getId assertEquals testWfKillSuccess1 WorkflowInstance getStatus execute call 1 Services addRecordToWfJobTable WorkflowAction assertNotNull get action WorkflowJob job wfInstance jpaService wfJobGetCmd ,oozie,1
fail Assert outbuf channel testInvalidConstructor metrics IllegalArgumentException should have been thrown ,httpcore,0
ALWAYS_FNFE intercept assertExceptionContains MISSING ioe testInterceptSuccess ,hadoop,0
" aaa ccc Value1 xx,  yy  ,zz Name8=xx%2C%20%20yy%20%20%2Czz result Name3 Value 4! Name4 Name5 Assert Name4=Value%204%21 Name6 Name7=aaa&Name7=b%2Cb&Name7=ccc Name7 assertTrue Name2= Name8 price get b,b Name1=Value1 Name4=Value%204%21%20%214 Name0 testParseURLCodedContentString Name1 Name2 a b""c bbb Name5=aaa&Name6=bbb d e isEmpty assertEquals Name4=Value%2B4%21 Value+4! parse price=10%20%E2%82%AC a=b""c&d=e assertNameValuePair size parseString Value 4! !4 10 â‚¬ ",httpcore,0
getVersionForNumber <<  >>  testToString2 matrix  ecLevel: H  qrCode Version  0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0  setMatrix setMaskPattern  1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1  setECLevel set setVersion  matrix:  Mode expected setMode assertEquals  maskPattern: 3   version: 1   mode: BYTE  y toString ErrorCorrectionLevel ,zxing,0
assertNull isTextual contextType assertFalse getSubType nullContext ContentTypeUtil ,logback,0
"svc testMonitor LOG hm HealthMonitor Returning an IOException, as if node went down assertFalse createProxyCount Returning to healthy state, waiting for HEALTHY countBefore  Should retry several times waitForState Thread sleep isAlive get Mocking bad health check, waiting for UNHEALTHY join  should expect many rapid retries shutdown info ",hadoop,0
compress gzCompare checker isErrorFree test2 CompressionMode compress2.txt.gz assertTrue CoreTestConstants compress2.txt context setContext Compare input/compress2.txt compressor witness/compress2.txt.gz ,logback,0
getAuthenticationHandlerConfiguration _testAuthentication testAuthenticationAnonymousDisallowed auth AuthenticatorTestCase setAuthenticationHandlerConfig ,hadoop,0
msg setNativeZlibLoaded This is the message in the file! testGzipCodecRead.txt.gz  Ensure that the CodecPool has a BuiltInZlibInflater in it. line returnDecompressor getTempPath ccf conf fs br Didn't get the same message back! testGzipCodecRead ZlibFactory getZlibDecompressor assertTrue bw assertNotNull FileSystem ZlibFactory returned unexpected inflator write close CodecPool decompressor getCodec f zlibDecompressor GenericTestUtils is assertEquals readLine createInputStream getDecompressor  Now create a GZip text file. codec  Don't use native libs for this test.  decompressor to use. getLocal toString zlibDecompressor is null! open ,hadoop,0
 Assert toString assertEquals buffer append testAppendNullByteArray ,httpcore,0
"expectedIOE disconnect  the open connection checks above ensure correct behavior.  fuzz the client. keepalive unwrapRemoteException testing123 getInternalState conf getCause  the connection closing. TestDisconnect request[ RpcStatusProto lastConn info setQueueSizePerHandler request[ testReaderExceptions LOG rseError authMetric  willDisconnect=  verify whether the connection should have been reused. expectedAuths proxy fail re rseFatal stop getConnections getRpcStatusProto getRpcMetrics server newServerBuilder  shouldConnect= ping newEmptyRequest  if it wasn't fatal, verify there's only one open connection. isDisconnected  correctly. current shouldClose assertTrue builder ThreadLocalRandom rpcAuthorizationSuccesses addr ] value conns setNumHandlers ]  e FakeRequestClass assertEquals getClient nextInt setVerbose assertSame Whitebox r reqName serial assertNotSame rpcRequestClass doDisconnect setupTestServer  didn't fail setInternalState ",hadoop,0
"play server request Cookie: $Version=""1"";  setDomain android ACCEPT_ORIGINAL_SERVER a=""android"";$Path=""/"";$Domain="" receivedHeaders get cookieA cookieManager getCookieStore cookieB add banana a b "" getHeaders takeRequest toURI "";  setPath setDefault assertContains testSendingCookiesFromStore / enqueue getUrl getCookieDomain b=""banana"";$Path=""/"";$Domain="" CookieHandler ",okhttp,1
_testNonTransient testEndNonTransient end.non-transient assertTrue end WorkflowActionBean ,oozie,1
"headers getServerAddress /_non_existing_url Oops. Not found. ninjaTestBrowser testThatNotFoundWorks newHashMap assertEquals  Check that we get a working ""not found"" template from views/system/404notFound.ftl.html makeRequest  Some empty headers for now...  Get raw response  make sure the status code is correct: content makeRequestAndGetResponse contains Maps getStatusCode assertTrue  Now get the content in another request... getStatusLine httpResponse ",ninja,1
" still works, but leaves the breadcrumb in place. cluster getZKFCProxy  Check that the old node was fenced start conf assertEquals waitForActiveLockHolder setFailToBecomeStandby getService stop gracefulFailover testGracefulFailoverFailBecomingStandby ",hadoop,1
cluster FILE_SIZE BLOCK_SIZE conf when  No seek; just read doAnswer client pread close info localhost anyBoolean  Read again and verify that the socket is the same opened  Starting testReadFromOneDN() LOG in anyString testReadFromOneDN unchecked Matchers dataBuf anyObject anyInt testFile answer Mockito anyLong getNameNodePort getBlockReader  Initial read toString spy open ,hadoop,1
handler request jwt publicKey setPublicKey when alternateAuthentication should NOT have thrown a AuthenticationException SERVICE_URL Assert assertNotNull getCookies getJWT getUserName getRequestURL init cookie alternateAuthentication should NOT have thrown a ServletException thenReturn getProperties hadoop-jwt encodeRedirectURL testNoExpirationJWT alternateAuthenticate assertEquals props token fail privateKey serialize bob Mockito Token should not be null. response mock ,hadoop,0
stream is not input checker in assertFalse setVerifyChecksum getWrappedStream localFs testPath assertTrue TEST_ROOT_DIR testStreamType create stream is input checker close open ,hadoop,0
getDynamicEntry assertHeaderEquals no-cache dynamicTable custom-value getCurrentSize Assert :scheme get testRequestDecodingWithoutHuffmanRFC7541Examples https cache-control :authority custom-key StandardCharsets createByteBuffer assertEquals headers2 decoder headers3 headers1 www.example.com / size :method GET src1 decodeHeaders http :path src3 src2 /index.html dynamicLength ,httpcore,0
pair1 getName rssExpandedReader retrieveNextPair getBlackRow readImage pair3 pair2 getHeight assertNotNull finderPattern  the previous was the last pair binaryMap row rowNumber testFindFinderPatterns previousPairs add image getFinderPattern assertEquals getValue fail  expected 2.png ,zxing,0
getJobTrackerUri getName <arg>exit1</arg> isMainSuccessful <java> assertFalse getStatus createContext actionXml FAILED/KILLED testExit1SubmitError isSuccessful assertTrue LauncherMapper getErrorCode context end waitFor <job-tracker> getData isCompleted getNameNodeUri </java> ae </main-class> </job-tracker> runningJob getAction assertEquals check getExternalStatus <name-node> <main-class> </name-node> 1 assertNull WorkflowAction submitAction evaluate isComplete ,oozie,1
testGetIndex fifoLinkedList getIndex h h1 h2 assertEquals h3 h4 assertSame node1 removeLast node4 1 2 node2 3 node3 Assert 4 size get addFirst ,httpcore,0
MILLISECONDS writeLock  ensure time for operations to start blocking expected channel store Executors futures newCachedThreadPool getCause sleepUninterruptibly WRITE READ fail queueAllBlockingOperations assertTrue executor future get lock  ensure all operations on the channel will block Uninterruptibles close testAsynchronousClose ,jimfs,1
handler request testValidJWT getTime jwt alice publicKey setPublicKey when SERVICE_URL Assert assertNotNull getCookies getJWT getUserName alternateAuthentication should NOT have thrown an AuthenticationException getRequestURL init cookie thenReturn getProperties hadoop-jwt encodeRedirectURL alternateAuthenticate assertEquals props token fail privateKey serialize Mockito Token should not be null. response mock alternateAuthentication should NOT have thrown a ServletException. ,hadoop,0
createStage poll System counting 4 observer counting 3 counting 2 counting 1 startCountdown assertTrue assertNotNull get TimeUnit join timerTest getReference counting 5 createClient counting start  some timer must have elapsed! 1 getRight assertNull  ensures no new messages are received currentTimeMillis IActor stage1 frontend chatRoom ,orbit,1
getForbiddenResult thenReturn session foo NinjaConstant when filterChain testAuthenticityFail getAuthenticityToken filter bar ninjaDefault Mockito context verify getSession getParameter ,ninja,0
encode charset submit executorService update Executors Assert 1234567890 getDuration tmp get verify testMultithreadingRead Boolean task1 task2 capacityChannel inputBuffer read newFixedThreadPool StandardCharsets valueOf assertEquals fill getTimeUnit call Integer updateCapacity Mockito mock reset TIMEOUT ,httpcore,0
110.113.221.222 ipl assertFalse 110.113.221.222 is in the list isIn testFileNotSpecified ,hadoop,0
END_POINTS testCoordReRun1 IS_SECURITY_ENABLED -action oozieUrl run appPath assertTrue get create SERVLET_CLASSES close runTest app MockCoordinatorEngineService coordinator.xml RestConstants getContextURL assertEquals getFileSystem -rerun args call 1 -oozie mkdirs job getFsTestCaseDir ,oozie,1
setPushMissingDependencies CoordELFunctions getUser getId poll addRecordToCoordActionTable coord CoordinatorXCommand myCmd assertNotNull  CASE 3: Both types get CoordinatorAction action event testCoordinatorActionEventDependencies getAppName generateEvent assertEquals execute setMissingDependencies  CASE 2: Only hcat (push) missing deps addRecordToCoordJobTable push call CoordinatorJob Services pull coord-action-get.xml  CASE 1: Only pull missing deps jpaService queue getMissingDeps ,oozie,1
" TODO: Create the directories CoordELFunctions 2009-09-10T23:59Z testLatest conf coord-action-start  TODO:Set hadoop properties ds 2009-09-09T23:59Z evalAndWrap /2009/09/10 getTestCaseDir file:// setUriTemplate createDir expr 2009-09-08T23:59Z ${coord:latest(0)} /${YEAR}/${MONTH}/${DAY} ${coord:latest(1)} init  ds.setUriTemplate(""file:///tmp/coord/${YEAR}/${MONTH}/${DAY}""); ${coord:latest(-100)} setVariable assertEquals testDir /2009/09/08 /2009/09/09 fail eval Should throw exception, because latest for +ve instance is not valid ${coord:latest(-2)} ${coord:latest(-1)} ",oozie,1
getTime checkCoordJobs assertFalse testCoordChangeEndTime getId DateUtils getStatus parseDateOozieTZ coordGetCmd coordJob pauseTime get startTime Job ;pausetime= printStackTrace endtime= assertEquals convertDateToString execute addRecordToCoordJobTable newEndTime Invalid date call CoordinatorJob fail Services ex isDoneMaterialization endTime job jpaService ,oozie,1
getJobTrackerUri </name-node> <configuration>  CASE: launcher specific ACLs not configured - set defaults <java> </configuration> getAppPath getActions conf setupActionConf createBaseHadoopConf actionXml wfBean addRecordToWfJobTable get context action JavaActionExecutor test1-acl <job-tracker> getNameNodeUri eActionXml testACLDefaults_launcherACLsSetToDefault MODIFIER actionConf </java> ae XmlUtils parseXml </job-tracker> createLauncherConf assertEquals <main-class>MAIN-CLASS</main-class> getFileSystem setType <name-node> VIEWER getType <property><name>mapreduce.job.acl-view-job</name><value>VIEWER</value></property> <property><name>mapreduce.job.acl-modify-job</name><value>MODIFIER</value></property> ,oozie,1
Create file jarsdir testConstructUrlsFromClasspath constructUrlsFromClasspath Create non-jar file dir  don't create nofile urls file assertTrue Make dir /* mkdir nonJarFile toURL jarsDir a.jar getAbsolutePath Make jarsDir toURI nonjar assertEquals Create jar file testDir cp jarFile toString createNewFile nofile File append ,hadoop,0
"buildTestModel testTableCreateAndDeletePB assertFalse admin tableExists delete TABLE2 put  make sure HBase concurs get client model checkModel  retrieve the schema and validate it getCode  delete the table getBody schemaPath Constants assertEquals TestTableSchemaModel getObjectFromMessage /  make sure HBase concurs, and wait for the table to come online /schema response createProtobufOutput enableTable  create the table ",hadoop,1
ConfigUtil /user file://foo getFileContext conf addLink testURIEmptyPath FileContext FsConstants ,hadoop,0
wfActionGetCmd getWorkflowInstance addRecordToWfActionTable testWfKillSuccess2 getId assertEquals WorkflowInstance getStatus execute call 1 Services addRecordToWfJobTable WorkflowAction assertNotNull get action WorkflowJob job wfInstance jpaService wfJobGetCmd ,oozie,1
getContextURL oozieUrl admin run assertEquals args call -auth -oozie testClientAuthMethod  bad method -status SIMPLE fake runTest ,oozie,1
NameValuePair Assert testNullValueNotEqual NameValuePair2 name value assertNotEquals ,httpcore,0
"setfacl should fail without options -b, -k, -m, -x or --set -m setfacl should fail with extra arguments  default:user::rwx -R setfacl should fail without path testSetfaclValidations assertFalse -x setfacl should fail with permissions for -x path --set setfacl should fail ACL spec missing setfacl should fail without options -setfacl user:user1:rwx extra runCommand setfacl should fail without aclSpec setfacl should fail with conflicting options ",hadoop,0
handler request getTime jwt publicKey setPublicKey JWTRedirectAuthenticationHandler when put bar SERVICE_URL Assert getCookies getJWT getUserName alternateAuthentication should NOT have thrown an AuthenticationException getRequestURL init cookie alternateAuthentication should NOT have thrown a ServletException thenReturn getProperties hadoop-jwt encodeRedirectURL alternateAuthenticate assertEquals props token fail privateKey serialize testValidAudienceJWT bob Mockito response mock ,hadoop,0
cluster NUM_OF_DATANODES getMetrics conf testDatanodeReport  wait until the cluster is up remove waitActive sleep client addr localhost DFSConfigKeys getDataNodes  0.5s datanodeReport  bring down one datanode assertEquals assertCounter setInt datanodes Thread setLong size build numDataNodes ExpiredHeartbeats getNameNodePort nodeInfo shutdown FSNamesystem DatanodeReportType ,hadoop,1
" advance clock tester 17177038848,8589467648,15232745472,6400417792,1,2805000,6261812, assertEquals 1234567,2345678,3456789,4567890  CpuTimeTracker advance SysInfoWindows refreshAndCpuUsage  verify information has not been refreshed getAvailablePhysicalMemorySize setSysinfoString getNumVCoresUsed 17177038848,8589467648,15232745472,5400417792,1,2805000,6263012,  info str derived from windows shell command has \r\n termination  verify information has been refreshed getCpuUsagePercentage ",hadoop,0
Optional thenReturn invoke when param1 getHeader empty optionalHeaderEmpty context create verify optionalHeader mockController ,ninja,0
@ :: closeTrx coordClient getStore getTime LocalOozie 2009-12-15T01:00Z 2009-12-16T01:00Z Could not update db. getStatus -testCoordRerun-C getCoordClient rerunScope get beginTrx CoordinatorAction reRunCoord actionNum2 commitTrx actionNum1 coord-rerun-action2.xml RestConstants printStackTrace store1 e testCoordRerunDate2 store actionId2 addRecordToJobTable jobId actionId1 Services fail CoordinatorJob addRecordToActionTable assertNotSame 0000000- action1 action2 coord-rerun-action1.xml getCoordinatorAction ,oozie,1
" Client of this LDAP server is expected to get a read timeout. finLatch getLocalPort testLdapReadTimeout run conf doGetGroups serverSock ldap://localhost: AUTHENTICATE_SUCCESS_MSG await ldapUrl clientSock countDown hadoop join write  4s LDAP response read timed out, timeout used: ldapServer mapping debug printStackTrace e LOG ms start Got the exception while LDAP querying:  getInputStream setConf accept setInt READ_TIMEOUT fail IOUtils skipFully ne assertExceptionContains getOutputStream readTimeoutMs The LDAP query should have timed out! getBaseConf remaining name ",hadoop,0
request conn resolve getRequest responseCaptor sendResponseHeader error when receiveRequestHeader requestHandler Assert httpservice assertNotNull context create forClass verify getCode close process ArgumentCaptor HttpStatus thenReturn testUnsupportedHttpVersionException capture handle assertEquals sendResponseEntity assertSame getEntity whatever / getValue doThrow responseFactory Mockito response HttpCoreContext newHttpResponse httprocessor handleRequest handlerResolver ,httpcore,0
"encode   a "" data assertFalse specifically_exclude_special_cookie_chars assertEquals , decode inMap put contains size get  "",;\ ; \ outMap ",ninja,0
server  Check for timeout status and unregistered missing dependencies timeOutCreationTime checkCoordAction CoordELFunctions  timeout. assertFalse testTimeOut addInitRecords getWaitingActions System sleep default /dt=20120430;country=usa assertTrue get CoordinatorAction tablename newHCatDependency table setCoordActionCreationTime newHCatDependency2 newHCatDependency1 hcatService populateTable hcat:// pdms isRegisteredForNotification / Thread call Services contains assertNull currentTimeMillis /dt=20120430;country=brazil actionId db ,oozie,1
http://host request getScheme testRequestWithNoPath assertEquals Method getMethod getAuthority / Assert name getPath host http http://host/ getUri ,httpcore,0
  ofSeconds ofNanoseconds hours1 ofDays assertEquals nanos1 seconds1 millis1 min Assert ofHours days1 testMin ofMilliseconds ofMicroseconds minutes1 ofMinutes TimeValue micros1 ,httpcore,0
msg conn HttpExceptionUtils getResponseMessage when put getBytes getErrorStream HttpURLConnection Assert assertTrue json FooException testValidateResponseJsonErrorUnknownException validateResponse thenReturn getMessage is jsonMapper fail contains EX ex Mockito response getResponseCode mock foo.FooException writeValueAsString ,hadoop,0
 Bring down tm2 getCurrentUser verifyToken Expected InvalidToken boo foo conf  Start second node after some time.. sleep  Create a new token thru the new ZKDTSM bar Assert bla assertNotNull token1 tm2 xyz tm1 token2 token3 token4 tm3 getSecretConf UserGroupInformation init  Cancel one token getConnectString zkServer unchecked createToken cancelToken Thread fail verifyDestroy verifyTokenFail  Start third node after some time.. TEST_RETRIES connectString testNodeUpAferAWhile ,hadoop,0
 test that the getHelp method is called test thenReturn Help 3 Help 1 Help 2 when assertArrayEquals help verifyNoMoreInteractions getHelp verify expr ,hadoop,0
PATH response should not be null returnedBody server request assertFalse body put STATUS requestHandler Assert HEADERS assertNotNull get body should be in the response defaultURI status unexpected mybody localhost headers Body should be echoed adapter withLiveServerEcho start unchecked isEmpty assertEquals Method /echo/* responseExpectations execute target ECHO_PATH headers should be in the response registerHandler getPort Mockito  Initialize the server-side request handler response name METHOD mock toString BODY ,httpcore,0
X %a %-12.550(hello %class{.4?}) add   testSimpleP2 a X  Token assertEquals tokenize witness hello  tl .4? -12.550 class ol ,logback,0
bundleJobGetExecutor Bundle Job should have been purged Bundle Action should have been purged addRecordToBundleActionTable getId DateUtils getStatus parseDateOozieTZ getErrorCode assertNotNull get Job testFailBundlePurgeXCommand 2011-01-01T01:00Z addRecordToBundleJobTable assertEquals execute call Services fail bundleActionGetExecutor1 bundleActionGetExecutor2 action1 ErrorCode je job action2 jpaService ,oozie,1
cluster getName conf waitActive  Validate we get all the corrupt files storageDir info DFSConfigKeys getBlockPoolId LOG listCorruptFileBlocks Deliberately removing file  count getFileSystem Cannot remove file. setInt dfs blk_ setLong testGetCorruptFiles util  For loop through number of datadirectories per datanode (2) cleanup getInstanceStorageDir idx  datanode scans shutdown /goodData getFinalizedDir bpid /corruptData fs delete testlistCorruptFileBlocksDFS sleep assertTrue  delete the blocks listFiles data_dir MiniDFSCluster blocks Namenode has bad files.  corruptFileBlocks  directories countPaths Thread createFiles build  (blocks.length > 0)); numCorrupt getNamesystem startsWith ,hadoop,1
request normal I2 assertEquals getID testConsiderKnownItems withConsider I7 target accept getValue considerKnownItems LIST_ID_VALUE_TYPE /recommendToMany/U4 Assert size FLOAT_EPSILON get true MediaType queryParam ,oryx,1
"hdfs,foo hae  allow all schemes  giving no scheme should skip the check getErrorCode file://localhost:1234/blah get has hdfs://localhost:1234/blah init set getConf /blah  Only allow hdfs and foo schemes assertEquals * testCheckSupportedFilesystem Should have thrown an exception because 'file' scheme isn't allowed Services fail checkSupportedFilesystem hConf foo://localhost:1234/blah oozie.service.HadoopAccessorService.supported.filesystems ErrorCode ",oozie,1
untarFile  Files to tar  Create Symbolic Link testCreateSymbolicLinkUsingJava FileUtils /sl createSymbolicLink del tmpDir isSymbolicLink assertTrue tmp getPath getParentFile tos dir1/ FILE Files close FileSystems tmpDir2  Delete the directories if they already exist os tmpDir1 toAbsolutePath getDefault symLink  Untar using java  put entries in tar file tmp/test 2 simpleTar toPath mkdirs  Check symbolic link and other directories are there in untar file dir2/ putEntriesInTar unTarUsingJava exists setupDirs toString deleteDirectory FileUtil ,hadoop,0
data Received create error from Zookeeper. code:CONNECTIONLOSS  mockNoPriorActive when ZK_LOCK_NAME notifyFatalError times Assert verify Ids create verifyExistCall mockApp stat for path   4 errors results in fatalError intValue Not retrying further znode create connection errors. thenReturn  recreate connection via getNewZooKeeper count processResult assertEquals elector Code mockZK .  setEphemeralOwner CreateMode Mockito becomeActive joinElection testCreateNodeResultRetryBecomeActive getSessionId ,hadoop,0
assertFalse run dir createFile Assert helper assertTrue get  paths are cleaned up  Ensure shutdown hook is added getTestRootPath deleteOnExit checkDeleteOnExitData blockSize dir1/file2 dir3/dir4/dir5/dir6 testDeleteOnExit numBlocks hasShutdownHook file2 exists  Create deleteOnExit entries file1 ShutdownHookManager fc FileContext ,hadoop,0
"coordinator.xml set Coord job submission should fail with reserved variable definitions. <coordinator-app name=""NAME"" frequency=""10"" start=""2009-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""  conf appPath </configuration> </workflow> </action> </coordinator-app> sc call writeToFile OozieClient 1 fail appXml getTestUser file:// getTestCaseDir UNIT_TESTING testSubmitReservedVars <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>  MINUTES File xmlns=""uri:oozie:coordinator:0.2"">  <configuration> <property> <name>inputA</name> <value>blah</value> </property>  ",oozie,1
 conn /v1/jobs 00002-12345-B put testMultipleBundleIdsForName setId setStartTime bundle  records found for this bundle runTest bundleInsert setAppName RestConstants openConnection HttpServletResponse assertEquals  Adding another bundle having same name params execute setStatus url call 1 5 getResponseCode bundleName createURL BundleJob bulkRequest jpaService bundle= ,oozie,1
 A a B b A[a] B[b] XLog createPrefix A[-] B[-] assertEquals logInfo A[a] B[-] testInfoParameters A[-] defineParameter setParameter ,oozie,1
verifyNoMoreInteractions test  test that setOptions method is called options mock setOptions verify expr ,hadoop,0
testClientWithAnonymous getContextURL oozieUrl admin run assertEquals oozie.authentication.simple.anonymous.allowed args call -oozie setSystemProperty true -status runTest ,oozie,1
headers getServerAddress  from the index screen: upload ninjaTestBrowser newHashMap Please specify file to upload: testHtmlEscapingInTeamplateWorks makeRequest  Some empty headers for now... result contains Maps  /redirect will send a location: redirect in the headers assertTrue ,ninja,1
2009-02-01T01:00Z getId DateUtils parseDateOozieTZ addRecordToCoordJobTable call getMatThrottling CoordinatorJob testMatThrottle 2009-02-03T23:59Z startTime endTime job checkCoordWaiting ,oozie,1
addRecordToBundleActionTable getCurrentDateafterIncrementingInMonths getId run DateUtils getStatus addRecordToCoordActionTable parseDateOozieTZ assertNotNull get CoordinatorAction end currentDatePlusMonth Job bundle waitFor addRecordToBundleJobTable bundleId start assertEquals XDataTestCase execute addRecordToCoordJobTableWithBundle Services CoordinatorJob runnable coord-action-get.xml testBundleStatusTransitServiceSucceeded2 equals action1 job action2 jpaService evaluate ,oozie,1
conn setRequestMethod IS_SECURITY_ENABLED /v0/admin/* assertTrue json content-type Collections runTest RestConstants testConfiguration openConnection containsKey HttpServletResponse assertEquals parse getInputStream url JSONValue call Services getHeaderField GET getResponseCode createURL startsWith ,oozie,1
1.1.1.1 verifyResolve host verifyInetAddress testResolverQualifed host.a.b. addr ,hadoop,0
"${coord:futureRange(0,3,'5')}  Action ID  CoordELFunctions TZ DateUtils /2009/02/26 parseDateOozieTZ /2009/03/26/ getTestCaseDir file:// action indexOf  providing some of the dataset dirs required as per coordinator specification with holes /2009/02/26/  limit is 5. So this should be ignored resolvedList execute /2009/03/05 jobId fail CoordCommandUtils job /2009/03/12 getMissingDependencies getTime getId 2009-02-16T23:59 </uris> /2009/03/12/ substring actionXML /2009/02/12/ <uris> get createDir startTime 2009-02-15T23:59 /2009/03/05/ /2009/02/12 testActionInputCheckFuture assertEquals -TestCoordActionInputCheckXCommand-C addRecordToCoordJobTable call @1 Services  was not stored properly in db getActionXml future 0000000- endTime jpaService ",oozie,1
getName assertFalse getOurClassPath timeout rcsjm  override output so we can capture it waitOrTimeout fakeDaemonCondition assertTrue startedProcess1 Collections startedProcess2 setOutput FakeDaemon getProcess restart Timeout Duration . isAlive getActiveProcess equals baos1 millis baos2 ,ninja,0
data becomeStandby mockNoPriorActive  should not call neutral mode/standby/active when ZK_LOCK_NAME  no new monitor called times verify Ids create verifyExistCall testCreateNodeResultBecomeActive mockApp stat intValue thenReturn  another joinElection not called. enterNeutralMode processResult elector Code  not call becomeActive since its already active mockZK setEphemeralOwner CreateMode Mockito becomeActive joinElection getSessionId ,hadoop,0
release times Assert assertNotNull get verify close entry2 entry3 getLeased conn3 conn2 entry1 conn1 assignConnection ArgumentMatchers somehost pool assertEquals totals future3 any never future1 future2 Mockito otherhost CloseMode mock lease getPending testLeaseRelease getTotalStats getAvailable ,httpcore,0
 restore events count to 10 run testQueueOperations repetition myapp 1234-C getCurrentSize get queueEvent  n(events) - n(batch)*n(threads)  n(events) - n(batch) i.e. WorkflowJob wfEvent  test two threads polling concurrently from queue  test single threads polling from queue isEmpty getEventQueue assertEquals thread numThreads  create some events to enqueue eventQ getBatchSize Services ehs r getTestUser  enqueue events again 1234-W  from queue ,oozie,1
${B} A ${A} B ${C} C OptionHelper putProperty expectedException expectMessage expect detectCircularReferences3 context Circular variable reference detected while parsing input [${B} --> ${C} --> ${A} --> ${B}] ${B}  substVars ,logback,0
bundleJobGetExecutor addRecordToBundleJobTable testBundleStartDryrun getId assertEquals getStatus execute call sleep Services size assertNotNull get bundleActionsGetExecutor isCritical Job job getBundleId jpaService actions ,oozie,1
key1 -description listKeys  HADOOP-10586 KeyShell didn't allow -description.  created ks listOut key1 has been successfully  description run assertEquals setConf testKeySuccessfulCreationWithDescription rc someDescription contains -provider assertTrue args1 reset create jceksProvider toString outContent ,hadoop,0
renderable containsString  make sure we get the correct result... assetsController when resultCaptor content Result result  check etag has been called mimeTypes getRenderable User-agent: * addEtag responseStreams verify ok render result2 serveStatic Disallow: / finalizeHeadersWithoutFlashAndSessionCookie byteArrayOutputStream thenReturn anyString capture  we mocked this one: assertEquals testServeStaticRobotsTxt contextRenderable eq assertThat httpCacheToolkit getValue getStatusCode Results Mockito anyLong getContentType mimetype getOutputStream toString /robots.txt getRequestPath ,ninja,0
"def addNode Expected to catch an exception but did not encounter any three two getCause asList we invokeForkJoin getErrorCode assertTrue four dummyConf end f one getMessage j assertEquals k kill  Make sure the message contains the node involved in the invalid transition fail contains ex parser name       *f->(2,3)      *2->decision node->{3,4}      *3->ok->j      *3->fail->k      *4->ok->j      *4->fail->k      *j->end       testDecisionForkJoinFailure ErrorCode Arrays ",oozie,1
"SlowRPC server  create a client Down slow rpc testing ping  second fast ping slowrpc conf Slow RPC should not have finished1. Waiting for slow RPC to get done. System sleep  Now the slow ping should be able to be executed assertTrue testSlowRpc addr Testing Slow RPC  first fast ping start Slow RPC should not have finished2. getClient thread isDone Thread proxy  send a slow RPC, which won't return until two fast pings stop  verify that the first RPC is still stuck setupTestServer  create a server with two handlers ",hadoop,0
getId run WorkflowInstance getStatus addRecordToCoordActionTable testCoordActionRecoveryServiceForResume coordJob sleep wfJob addRecordToWfJobTable assertNotNull get CoordinatorAction WorkflowJob recoveryRunnable waitFor ret wfGetCmd assertEquals execute addRecordToCoordJobTable CoordinatorJob Services wfJobId coord-action-get.xml SUSPENDED jpaService evaluate ,oozie,1
cluster DFS_NAMENODE_REPLICATION_MIN_KEY  create cluster testFsCloseAfterClusterShutdown hasException testFsCloseAfterClusterShutdown successful conf System createFile getBytes testFsCloseAfterClusterShutdown: Error here waitActive out ipc.ping.interval hflush  hdfs timeout is default 60 seconds assertTrue something_test fpath  create a new file. write close stopDataNode  encountered.  ensure that block is allocated f  hdfs timeout is now 10 second getFileSystem TestFileCreation ipc.client.ping DIR setInt dfs Failed to close file after cluster shutdown  test closing file after cluster is shutdown build numDataNodes DATANODE_NUM test testFsCloseAfterClusterShutdown start  shutdown last datanode in pipeline. shutdown setBoolean ,hadoop,1
toString run FROM TO testCpWithoutP assertAttributesChanged ,hadoop,0
"compare Result should be 1, should not match the writables Result should be -1, should not match the writables WritableComparator writable3 writable2 writable1 compareTo SHOULD_NOT_MATCH_WITH_RESULT_ONE testShortWritableComparator assertTrue get Result should be 0, should match the writables SHOULD_NOT_MATCH_WITH_RESULT_MINUS_ONE SHOULD_MATCH ",hadoop,0
poll DateUtils getStatus asList parseDateOozieTZ assertNotNull CoordinatorAction coordinator_action action  coord action getStartTime waitFor 2013-01-01T10:00Z getJobId modifyCoordForRunning execute ehs CoordinatorJob  Action Success size Arrays AppType getCreatedTime evaluate getParentId  Make Action ready testCoordinatorActionEvent getAppType getEventStatus getUser EventStatus getId getExternalId coordGetCmd setAppTypes  Action Failure coord wfJob get startTime  Action WAITING on materialization event WorkflowJob getAppName 2013-01-01T10:14Z assertEquals getNominalTime addRecordToCoordJobTable setStatus call Services @1 endTime jpaService queue _pollQueue ,oozie,1
MockCoordinatorEngineService -log END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL -action oozieUrl testJobLog MockDagEngineService 2009-12-16T01:00Z run assertEquals 0 args call -date -oozie reset job SERVLET_CLASSES runTest ,oozie,1
conn setRequestMethod IS_SECURITY_ENABLED assertTrue json content-type /v1/admin/* Collections runTest RestConstants testConfiguration openConnection containsKey HttpServletResponse assertEquals parse getInputStream url JSONValue call Services getHeaderField GET getResponseCode createURL startsWith ,oozie,1
here got exception : %s conf run String error out file openerDone hflush StringUtils unable to close file get interrupt create requiredSuccessfulOpens join close write generateSequentialBytes init fileSystem DFSTestUtil currentThread DFSConfigKeys set /file1 e LOG errorMessage format start stringifyException error in writer writeSize testImmediateReadOfNewFile blockSize Thread warn fail setLong assertNull opener  case of client getting a DN that hasn't yet created the blocks writer open ,hadoop,1
"r2 getName output test.*.source.filter.exclude getTestFilename Test putMetrics  When we call stop, at most two sources will be consumed by each sink thread. s0 s1 add checkMetricsRecords ms getAllValues capture test.sink.test.class mr2 mr1 s1 desc stop size *.period TestMetricsConfig test.sink.sink1.metric.filter.exclude mock shutdown s0rec  publish the metrics test.sink.sink2.metric.filter.exclude save test.source.s1.metric.filter.exclude X* verify atMost sink2 desc hadoop-metrics2-test s1rec set registerSink DefaultMetricsSystem incr start sink1 desc assertEquals Y* s0 desc testInitFirstVerifyStopInvokedImmediately sink2 sink1 publishMetricsNow register r1 ",hadoop,0
expectedContents buildTestBase resolve getResultMetadata testImage reader You get to CREATE OUR JOURNAL PROMPT FOR THE DAY!  Yay!  Way to go!   source  Very basic test for now barcodeContents ImageIO result You earned the class a 5 MINUTE DANCE PARTY!!  Awesome!  Way to go!  Let's boogie! assertNotNull bitmap You earned the class 5 EXTRA MINUTES OF RECESS!!  Fabulous!!  Way to go!! results testBase add image read 1.png getText BarcodeFormat assertEquals decodeMultiple src/test/resources/blackbox/multi-qrcode-1 You get to SIT AT MRS. SIGMON'S DESK FOR A DAY!!  Awesome!!  Way to go!! Guess I better clean up! :) AbstractBlackBoxTestCase getBarcodeFormat toFile testMultiQRCodes ,zxing,0
"def addNode Expected to catch an exception but did not encounter any three two getCause asList we invokeForkJoin getErrorCode assertTrue dummyConf end f one getMessage j assertEquals k kill  Make sure the message contains the node involved in the invalid transition fail contains ex parser testTransitionFailure1 name       f->(2,3)      2->ok->3      2->fail->j      3->ok->j      3->fail->k      j->k      ErrorCode Arrays ",oozie,1
 X . X X X . . X . X . X . . . X . X . X X X . . . X X   X X . X X . . X . . . X X . . . X X . X X X . X . X X   X . X X . . X . . . X X . X X . X . X X . . . . . X .   . . X X X X X . X . . . . X X X X . . X X X . X . X .   X . . X . X X X X . X . X . . . . X . X X . X . . X .   X . . X . . . . . . X . . . X . X X X X X X X . . . X   X  testDecodeTooManyErrors2 . . . . . . . X . X . . . . . . . X X X X . . . X X X   BitMatrix matrix decode X . . X X X . X X X X X X X X X X X X X . . . X . X X   X . . . X X . X . X X X X X X X X . X X X X . . X X .   . X X X X . . X . . X X X . X X . . X . . . . X X X .   X . . X X . . X . . X X . . . . . X . . . . . X X X .   X . . . X . X . X X X X X X . . X . X X X X X . X . .   X X . X . . X . X X . . . . . X X . . . . . X . . . X   . X . . . X X X . . . . . X . . . . . X X X X X . X .   X X . . X . . X . X X X X X X X X X X X X X . . X . X   NO_POINTS . . . . X X . . . X . . . . . . . X X . . . X X . X .   X . . . . X . X . X . X . . . X . X . X X . X X . X X   X . . . X . X X X X X X . . X X X . X . X X X X X X .   . . . X X X . . X X . X X X X X . X . . X . . . . . .   X X X X X X X X . X . X X X X X . X . X . X . X X X .   . . X X . X . X . . . X . X X . X X . . . . X X . . .   parse X . X . . X . X . X . X . X . X . X . . . . . X . X X   X X X . X X X X . . X X X X . . X . . . . X . . X X X   .  r . . X X X X . X . . . . . X X X X X X . . . . . . X X   X X . . . X X . . X . X . . . . X X . X . . X . X . X   . X X . . X . X X . . . X . . X X X . . . X X . X X .   . . . . X . . . X X X . X X . X X X X . X X . . X . .   ,zxing,0
getSubject  ///////////////////////////////////////////////////////////////////// setSubject  make sure that mocked mailer did not send email previously getLastSentMail first mail secondMail from@localhost  send simple mail via mocked postoffice assertTrue  //////////////////////////////////////////////////////////////////// getFrom postoffice simple body text  and test that mail has been sent. setFrom assertEquals getTos firstMail contains getBodyText second mail testSending equals to@localhost addTo send setBodyText ,ninja,0
testAsyncClose_read writeLock gotAsyncCloseException channel Executors handlerLatch getCause sleepUninterruptibly WRITE  cause another thread trying to read to block exc assertTrue executor get await lock countDown close MILLISECONDS read set newFixedThreadPool expected store completed failed  give enough time to ensure both reads start blocking byteStore ByteBuffer READ fail allocate future Uninterruptibles shutdown ,jimfs,1
testFile01 getPathData testfile01 testDir06 testDir05 ls formatLineMtime  check listing of multiple files out testfile03 options computeLineFormat inOrder testfile02 processOptions verify testfile05 testFile06 testfile04 processPathFiles testFile04 testFile05 testfile06 testFile02 testFile03 add pathData lineFormat processArguments verifyNoMoreInteractions TestFile testDir04 testDir03 mock testDir02 testDir01 ,hadoop,0
 Test existing files case assertFalse partitioned delete Assert assertTrue tmp getPath testListAPI mkdir Failed to create test dir Failed to delete test dir IOException expected on list() for non-existent dir  test  Test existing directory with no files case assertEquals list Unexpected number of pre-existing files fail newDir files exists setupDirs New directory unexpectedly contains files toString FileUtil  IOException ,hadoop,0
DelegationTokenAuthenticationHandler request foo assertFalse conf getMethod when put testWriterNotClosed noAuthCloseHandler Assert KerberosDelegationTokenAuthenticationHandler getUserName close write initJsonFactory printWriterCloseCount GETDELEGATIONTOKEN op thenReturn AUTO_CLOSE_TARGET false DelegationTokenAuthenticator getQueryString destroy token str already closed! managementOperation Mockito response getWriter setValue mock closed toString getHttpMethod booleanValue = user initTokenManager ,hadoop,0
 testFile01 getPathData testfile01 getTime addContents ls formatLineMtime out Found 3 items  check multiple directories are order independently testfile03 options computeLineFormat inOrder testfile02 processOptions verify testfile05 testFile06 setMtime testfile04 testFile04 testFile05 testfile06 testFile02 testFile03  set file mtime in different order to file names add pathData lineFormat -t setIsDir processArguments verifyNoMoreInteractions NOW TestFile mock testDir02 testDir01 processPathDirsOrderMtime testDirectory02 testDirectory01 ,hadoop,0
ARG_NOFAIL kdiag testKDiagStandaloneNofail KEYLEN ARG_KEYLEN ,hadoop,0
getLocation testSimpleScannerPB setBatch countCellSet delete put  confirm batch size conformance TABLE  new scanner Bytes /scanner assertNotNull get client model getCode addColumn scannerURI  get a cell set getBody cellSet toBytes assertEquals  delete the scanner getObjectFromMessage / MIMETYPE_PROTOBUF BATCH_SIZE COLUMN_1 response createProtobufOutput ,hadoop,1
data ActiveNotFoundException expected thenReturn  error getting active data rethrows keeperexception assertEquals getActiveData eq elector KeeperException.AuthFailedException expected any when ZK_LOCK_NAME mockZK fail times Assert Mockito  get valid active data testGetActiveData  active does not exist verify getData thenThrow ,hadoop,0
uploadFile getServerAddress uploadFinish ninjaTestBrowser  Let's upload a simple txt file... result testThatUploadWorks contains file assertTrue  Let's see if that has worked... test_for_upload.txt src/test/resources/test_for_upload.txt ,ninja,1
testProdAndTestMode012  Server runs in Test mode. This route is Prod & Test. Request CoreMatchers equalTo prod and test works. assertThat makeRequest url path Assert response GET /0/1/2/mode/prod/and/test testServerUrl ,ninja,0
headers getServerAddress ninjaTestBrowser newHashMap assertEquals assets/js/google-code-prettify/prettify.css  Some empty headers for now... makeRequestAndGetResponse Maps  /redirect will send a location: redirect in the headers getStatusCode getStatusLine httpResponse testThatAssetsWork ,ninja,1
"testActivationStrategySavingAndLoading TestFeature reflectionEquals setStrategyId user1, user2, user3 is assertThat getFeatureState loadedFeatureState savedFeatureState setParameter setFeatureState UsernameActivationStrategy stateRepository ",togglz,1
init CoordELFunctions ${coord:days(256)} assertEquals timeunit getVariable 1 eval evalAndWrap 256 ${coord:days(1)} TimeUnit expr coord-job-submit-freq testDay ,oozie,1
chunkSize update dataSize type crcBytesByChunk cellSize assertArrayEquals CrcComposer digest newStripedCrcComposer crcBytesByCell digester testStripedByteArray ,hadoop,0
mask5 assertTrue mask4 testGetDataMaskBitInternal mask7 mask6  See mask patterns on the page 43 of JISX0510:2004. mask1 mask0 mask3 testGetDataMaskBit mask2 ,zxing,0
setHandler DelegationTokenAuthenticationFilter getKind authURL /bar setAttribute Assert FOO_USER assertNotNull of context startThreads jetty /* /foo/bar?authenticated=foo DispatcherType getJettyURL fooKind /foo secretMgr aUrl addServlet EnumSet start setContextPath assertEquals createJettyServer stopThreads testExternalDelegationTokenSecretManager token stop addFilter getDelegationToken ,hadoop,0
END_POINTS IS_SECURITY_ENABLED oozieUrl getUser getId wc getStatus getBundleJobInfo bundleJob getCoordJobInfo getAcl SERVLET_CLASSES wfAction runTest testJobInformation group RestConstants getContextURL MockDagEngineService assertEquals call 1 jobId SUCCEEDED toString job user getJobLog getWorkflowActionInfo ,oozie,1
processWatchEvent data mockNoPriorActive  first SyncConnected should not do anything when ZK_LOCK_NAME notifyFatalError Assert Ids create  create znode success. become master and monitor verifyExistCall anyBoolean mockApp thenReturn anyString Unexpected Zookeeper watch event state: AuthFailed enterNeutralMode count processResult Code testProcessCallbackEventNone CreateMode getType becomeActive  error event results in fatal error mock  already in safe mode above. should not enter safe mode again  disconnection should enter safe mode assertFalse times  only 1 state change callback is called at a time assertTrue mockEvent verify  constructor intValue assertEquals elector any isMonitorLockNodePending mockZK getState  once in initial joinElection and one now Mockito joinElection  call to create lock znode Event exists  re-connection should monitor master status ,hadoop,0
request Options value incorrect should be SAMEORIGIN but is:  when filterConfig LJM setHeader testCustomOptionsValueAndNoOverrides doAnswer Assert X_FRAME_OPTIONS assertTrue doFilter  sure that it doesn't overwrite the configured value toArray SAMEORIGIN add headers init isOne chain resp thenReturn Header should be visible inside chain and filters. assertEquals assertThat any args filter X-Frame-Options count not equal to 1. invocation withFailMessage getInitParameter answer size Mockito response mock getArguments XFrameOptionsFilter containsHeader isEqualTo ,hadoop,0
process defaultProcessor interpretationContext assertEquals checkError tagName assertTrue setValue context end noName v1 propertyAction getStatusManager value begin getCount atts topModel ,logback,0
testRequestIsBoundToHolder number=42 getPage getContent assertThat url  send a request to the servlet with a query string part baseUrl contains getStatusCode  verify the servlet sends back the query string ?number=42 HttpServletRequestHolderServlet page getWebResponse isEqualTo ,togglz,1
testWritable testSimpleVersionedWritable TestWritable ,hadoop,0
dirY dirX foo chrootedTo listStatus fs createFile /bar bar Assert assertTrue  note 2 crc files assertNotNull /dirX/dirXX getFileStatus getPath fileSystemTestHelper getTestRootPath  Note the the file status paths are the full paths on target /dirY /dirX dirPaths /foo  list on Slash isFile fSys assertEquals  should return the full path not the chrooted path / FileSystemTestHelper testList mkdirs containsPath isDirectory ,hadoop,0
cluster Namenode has   corrupt files. Expecting none. getName maxCorruptFileBlocks conf  verify that there are no bad blocks. # of corrupt files is:  Removing files from  storageDir info DFSConfigKeys getBlockPoolId LOG listCorruptFileBlocks iter getFileSystem Cannot remove file. . setInt getNameNode blk_ Expected more than  util size  bad files. Expecting  Iterator should have made more than 1 call but made  cleanup getInstanceStorageDir idx shutdown  create 110 files with one block each /srcdat2  datanode sends block reports getFinalizedDir bpid fs waitReplication namenode delete  corrupt file blocks but got  getCallsMade sleep badFiles corruptPaths assertTrue listFiles data_dir MiniDFSCluster blocks testMaxCorruptFiles Namenode has bad files.  j countPaths Thread createFiles  Now deliberately blocks from all files build FSNamesystem  datanode scans directories getNamesystem startsWith ,hadoop,1
request Default status expected. Default request query parameters expected. Default headers expected. Default request body expected. Default protocol version expected. Default response content type expected. STATUS Assert HEADERS PROTOCOL_VERSION assertNotNull CONTENT_TYPE get Default request content type expected. Default request headers expected. initResponseExpectations initRequest test Default method should be GET Default body expected. assertEquals responseExpectations TestingFramework responseExpectations should not be null request should not be null defaults QUERY GET METHOD BODY ,httpcore,0
subwfJobGetCmd addRecordToWfActionTable coordActionGetCmd getId getNumDaysToNotBePurged WorkflowInstance getStatus addRecordToCoordActionTable SubWorkflow Job should not have been purged coordJob SubWorkflow Action should not have been purged wfJob addRecordToWfJobTable assertNotNull get Workflow Job should not have been purged CoordinatorAction WorkflowJob wfAction subwfAction wfJobGetCmd wfActionGetCmd Coordinator Action should not have been purged assertEquals getLastModifiedTime execute addRecordToCoordJobTable subwfActionGetCmd Coordinator Job should not have been purged call Services CoordinatorJob 1 coordJobGetCmd fail coord-action-get.xml testPurgeCoordWithWFChildWithSubWF1 WorkflowAction coordAction SUCCEEDED subwfJob jpaService Workflow Action should not have been purged ,oozie,1
" Check for resolved conf /2009/22/ eAction getTestCaseDir property action createActionElement elementList dryRunCoord testDryRunPullDeps printStackTrace workflow getChild parseXml /2009/15/ getPullMissingDependencies testDir fail CoordinatorJob getChildren getNamespace file://,testDir/2009/29 CoordCommandUtils job addRecordToCoordJobTableForWaiting  Make sure conf is not resolved as dependencies are not met configuration ${coord:dataIn('A')} appPath createCoordinatorActionBean actionXml sleep coord coord-action-for-action-input-check.xml /2009/08/ get createDir coord-job-for-matd-hcat.xml value actionBean missDeps XmlUtils e newactionXml getMessage assertEquals e1 setMissingDependencies e2 ${coord:dataOut('LOCAL_A')} getValue  Make the dependencies available /2009/29/ configElem file://,testDir/2009/29,file://,testDir/2009/22,file://,testDir/2009/15,file://,testDir/2009/08 getCoordActionXml  actionXml only to check whether coord conf got resolved or not getFsTestCaseDir ",oozie,1
aimaimaimaim12345678 visualized 239 91 11 91 11 91 11 91 11 254 142 164 186 208 129 237 testUnlatchingFromText assertEquals encodeHighLevel ,zxing,0
getConnectionContext session conf createSession getTopic wf-app-name1 caId1 selector wfId1 WorkflowJob jmsContext ='Non_matching_user' consumer user1 init receive printStackTrace e  Pass a selector which wont match and assert for null message testWorkflowJobSelectorsNegative getMessage destroy message wfEventListener fail assertNull onWorkflowJobEvent JMSHeaderConstants wfe createConsumer Session ,oozie,1
getName getProcess restart assertFalse getOurClassPath multipleRestartsReallyQuickly . rcsjm  override output so we can capture it isAlive getActiveProcess assertTrue equals startedProcess1 Collections baos1 startedProcess2 startedProcess3 setOutput startedProcess4 FakeDaemon ,ninja,0
"<controls> <timeout>10</timeout> <concurrency>2</concurrency> <execution>LIFO</execution>  <throttle>3</throttle></controls> <datasets> <dataset name='a' frequency='${coord:days(7)}' initial-instance='2009-02-01T01:00Z' timezone='UTC'> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset> <dataset name='local_a' frequency='${coord:days(7)}' initial-instance='2009-02-01T01:00Z' timezone='UTC'> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset> </datasets> <input-events> <data-in name='A' dataset='a'> <instance>${coord:latest(0)}</instance> </data-in>  </input-events> <output-events> <data-out name='LOCAL_A' dataset='local_a'> <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path> <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property> <property> <name>inputB</name> <value>${coord:dataOut('LOCAL_A')}</value> </property></configuration> </workflow>   <coordinator-app name='NAME' frequency='${coord:days(1)}' start='2009-02-01T01:00Z' end='2009-02-03T23:59Z' timezone='UTC' xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance' xmlns='uri:oozie:coordinator:0.2' xmlns:sla='uri:oozie:sla:0.1'>  XmlUtils e validator parseXml </action> </coordinator-app> newValidator getSchema COORD_APP1 Services wss get testCoordSchema2 SchemaName validate  System.out.println(""XML :""+ XmlUtils.prettyPrint(e)); ",oozie,1
"Content transferred:	50000000 bytes  Failed requests:		0  Document Path:			/index.html  replace CoreMatchers equalTo ResultFormatter   Server Software:		TestServer/1.1  Protocol version:		HTTP/1.1  Total transferred:		62640000 bytes  Transfer rate:			17,997.02 [Kbytes/sec] received  Assert Requests per second:	5,884.08 [#/sec] (mean)  testBasics Server Port:			8080  HttpVersion results   localhost Time per request:		0.170 [ms] (mean, across all concurrent requests)  Server Hostname:		localhost  StandardCharsets TestServer/1.1 Time taken for tests:	3.399000 seconds  assertThat buf print Concurrency Level:		5  Complete requests:		20000  toByteArray Kept alive:				20000  name Document Length:		2924 bytes  /index.html Time per request:		0.850 [ms] (mean)  ",httpcore,0
server Server conf run getClassLoader setCallIdAndRetryCount TestInvocationHandler  10000 times runs about 6s on a core i7 machine Proxy Assert testRetryProxy RetryPolicies client getCallRetryCount create Client dummyRun retryCount newProxyInstance start assertEquals RetryProxy proxy totalRetry stop retryProxy ,hadoop,0
"<execution>LIFO</execution> </controls> <datasets>  <coordinator-app name=""NAME"" frequency=""${coord:days(1)}"" start=""2010-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""  conf </input-events>  getStatus appPath xmlns=""uri:oozie:coordinator:0.2""> <controls>  getJob sc </property></configuration> </workflow> </action> </coordinator-app> writeToFile appXml getErrorCode assertTrue <property> <name>inputB</name> <value>${coord:dataOut('LOCAL_A')}</value>  file:// getTestCaseDir UNIT_TESTING testBasicSubmitWithStartTimeAfterEndTime <output-events> <data-out name=""LOCAL_A"" dataset=""local_a"">  Job timezone=""UTC""> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset>  coordinator.xml Expected to catch errors due to incorrectly specified Start and End Time set Coordinator Start Time cannot be greater than End Time. <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  e getMessage <dataset name=""local_a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  assertEquals call OozieClient fail contains getTestUser </datasets> <input-events>  <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>  <data-in name=""A"" dataset=""a""> <instance>${coord:latest(0)}</instance> </data-in>   <dataset name=""a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  ErrorCode File ",oozie,1
endtime=2011-12-01T05:00 conn setRequestMethod IS_SECURITY_ENABLED testCoordChange put setRequestProperty endtime=2011-12-01T05:00Z concurrency=200 /v1/job/* content-type runTest MockCoordinatorEngineService endtime=2011-12-01T05:00Z;concurrency=200 RestConstants openConnection HttpServletResponse assertEquals params url PUT call size getResponseCode reset createURL changeValue setDoOutput ,oozie,1
bais </configuration> conf ConfTest assertEquals getBytes Line 2: <property> has no <name> size checkConf get </property>  <property>  <configuration>  <value>foo</value>  errors testPropertyHasNoName ,hadoop,0
HttpHeaders process HttpStatus getFirstHeader h1 interceptor h2 getEntity setEntity testResponseContentEntityNoContentTypeAndEncoding Assert assertNull EmptyInputStream response context OK ,httpcore,0
"checkFatalsAndReset testHandleSessionExpiration serverFactory ========================== Expiring session appData timeout sleep ensureParentZNode verify  Should re-join the election and regain active closeSession waitForActiveLockData ========================== Quitting election cb info getServer  due to receiving the ""expired"" event.  Let the first elector become active  Should enter neutral mode when disconnected zks LOG getZKSessionIdForTests enterNeutralMode elector ActiveStandbyElectorTestUtil quitElection Thread never cbs Mockito becomeActive joinElection electors appDatas PARENT_DIR ",hadoop,0
key1 key2 value2 value1 keys value3 values compareTo bValue inMap getBytes put assertTrue get keySet key  This will work because we know what we put into each set getKey a b maps e entrySet map2 containsKey map1 copyOfMapOfMaps unchecked assertEquals getValue size mapOfMaps testMapWritable Key3  Now for something a little harder... outMap aValue ,hadoop,0
cancel conf Time FileSystem not removed from DelegationTokenRenewer when fs getRenewQueueLength sleep doAnswer getRenewToken FileSystem not added to DelegationTokenRenewer now verify atMost myservice getConf doReturn renewer removeRenewAction assertEquals eq any addRenewAction getService token Thread never setDelegationToken answer testAddRemoveRenewAction service mock atLeast renew getDelegationToken RENEW_CYCLE ,hadoop,0
test0132021 data compressed15bitWeight1750 expected compressedGtin900123456798908 header (01)90012345678908(3202)001750 assertCorrectBinaryString ,zxing,0
testTailMatch ruleElementSelector * assertEquals p  test tail matching /a /A /a/b getTailMatchLength /a/B */b/c /a/b/c */a */A */b ,logback,0
mockTask getJobUpdatedNodeEvents conf when allocator Assert nodeHeartbeat newJobId getAttempt amNodeManager  get the assignment dispatcher attemptId app getNodeId getContainer getAppAttemptId thenReturn createReq mockTaskAttempt getTaskAttemptID submitApp MRBuilderUtils jobId size getTaskAttemptKillEvents getAttemptID mock assigned  mark nodes bad rm testUpdatedNodes h1:1234  add resources to scheduler  create the map container request  updated nodes are reported getApplicationId mockJob  Submit the application h1 getCurrentAppAttempt getRMContext amNM:1234 h2:1234 nm2 nm1 sendAMLaunched assertTrue get await event getTaskId getDispatcher start isEmpty clear  schedule response returns updated nodes assertEquals  this tells the scheduler about the requests appAttemptId  no updated nodes reported schedule registerNode sendRequest getUpdatedNodes getTask ,hadoop,1
cluster Recent opcode offsets: (\d+\s*){4}$ conf getFile waitActive error message contains opcodes message getFSImage NUM_DATA_NODES write expectedErrorMessage FSEditLogOpCodes format getFileSystem matches getOpCode fail namesystem Should exist:  numDataNodes  start a cluster mkdirs fileSys getStorage shutdown next rwf NameNodeDirType rw seek findLatestEditsLog editFile sd should not be able to start assertTrue fsimage close dirIterator e testDisplayRecentEditLogOpCodes length getMessage ^Error replaying edit log at offset \d+  fileLen build exists /tmp/tmp  Corrupt the edits file. FSImageTestUtil getNamesystem ,hadoop,1
 bad conf file:  bais conf ConfTest assertEquals getBytes size assertTrue checkConf get testEmptyInput errors startsWith ,hadoop,0
 kills addNode def enters WorkflowInstance getStatus asList wf exits end signal fails a b testWFKillWithRunningNodes f start j assertEquals kill killed 1 size <worklfow-app/> Arrays job /b/ ,oozie,1
" 1 = 01 = 0001 in 4 bits.   A a abc Mode bits  .XX.XX.. XXXXX assertEquals appendBytes  0x93, 0x5f 1 testAppendBytes  ...X Encoder bytes  Anything can be encoded in QRCode.MODE_8BIT_BYTE. toString  ..X.X.  A = 10 = 0xa = 001010 in 6 bits  Lower letters such as 'a' cannot be encoded in MODE_ALPHANUMERIC.  0x61, 0x62, 0x63  .XX....X .XX...X. .XX...XX shiftJISString ",zxing,0
ce createCoordinatorEngine getFilterParams assertEquals streamLog services runJobsImpl filter jobId DagXLogInfoService service testStreamLog2 get ,oozie,1
host4 Assert testToHostString host1 toHostString host3 somehost host2 somehost:8888 assertEquals ,httpcore,0
"bin:x:2:2:bin:/bin:/bin/sh  GET_ALL_GROUPS_CMD bin assumeNotWindows hdfs:x:11502:10788:Grid Distributed File System:/home/hdfs:/bin/bash  daemon:x:2:2:daemon:/sbin:/sbin/nologin"" hdfs2:x:11502:10787:Grid Distributed File System:/home/hdfs:/bin/bash  HashBiMap uMap  | cut -d: -f1,3 echo ""hdfs:*:11501:hrt_hdfs  daemon:x:1:1:daemon:/usr/sbin:/bin/sh  mapred:x:497  assertTrue root get create gMap echo ""root:x:0:0:root:/root:/bin/bash  group mapred3:x:498"" testDuplicates hdfs2 hdfs1:x:11501:10787:Grid Distributed File System:/home/hdfs:/bin/bash  GET_ALL_USERS_CMD assertEquals daemon bin:x:1:1:bin:/bin:/sbin/nologin  mapred3 mapred:x:498  size hdfs:x:11501:10787:Grid Distributed File System:/home/hdfs:/bin/bash  ShellBasedIdMapping hdfs : mapred2:x:497   Maps for id to name map user EMPTY_PASS_THROUGH_MAP mapred updateMapInternal ",hadoop,0
request HttpHeaders HeaderElements conn testExecutionEntityEnclosingRequestWithExpectContinueSuccess Continue when setEntity times isDataAvailable flush executor context create verify OK Boolean postProcess addHeader process thenReturn ArgumentMatchers Method getEntity execute / anyInt Mockito response HttpCoreContext httprocessor mock preProcess entity receiveResponseHeader sendRequestEntity sendRequestHeader receiveResponseEntity ,httpcore,0
read doReturn inputStream testCopyBytesShouldCloseStreamsWhenCloseIsTrue when atLeastOnce IOUtils Mockito mock verify outputStream close copyBytes ,hadoop,0
addRecordToWfActionTable getId WorkflowInstance getStatus  update the list for doing bulk writes coordJob wfJob addRecordToWfJobTable assertNotNull get action WorkflowJob updateList add getStatusStr  update the status  check for expected status after running bulkUpdateJPA RUNNING assertEquals execute addRecordToCoordJobTable setStatus CoordinatorJob 1 Services setUpdateList WorkflowAction bulkUpdateCmd SUCCEEDED testUpdates action2 jpaService ,oozie,1
encode Executors decode markEndStream Assert 1234567890 getDuration tmp Boolean capacityChannel read StandardCharsets ArgumentMatchers rnd fill anyInt mock reset TIMEOUT 12345678901234567890123456789012345678901234567890 testMultithreadingReadStream charset submit executorService update System sleep get verify task1 task2 inputBuffer newFixedThreadPool assertEquals nextInt l ByteBuffer Thread getTimeUnit call updateCapacity buf Mockito currentTimeMillis toString atLeast wrap append ,httpcore,0
http://somehost/./mypath setHost Assert build somehost http ./mypath setScheme assertEquals uri testRelativePathWithAuthority ,httpcore,0
app END_POINTS IS_SECURITY_ENABLED getContextURL oozieUrl sla run assertEquals getFileSystem appPath args call 1 -oozie mkdirs SERVLET_CLASSES -len runTest getFsTestCaseDir testSlaEvents ,oozie,1
cluster  create cluster GOOD! conf System createFile waitActive /foo.txt addBlock closeStream FileSystem client  create a new file. info f testFileCreationError3 successful getFileSystem getNameNodeRpc testFileCreationError3 start dfs fail testFileCreationError3 IOUtils build numDataNodes toString shutdown ioe ,hadoop,1
"parent init Incorrect number of services AddSiblingService start assertEquals Expected an exception, got  addChildToService fail stop size getServices child testAddStartedChildBeforeInit ",hadoop,0
cluster getBlockLocations /tmp/testBadBlockReportOnTransfer/file1 Waiting until block is marked as corrupt... conf dfsClient fs waitReplication createFile Corrupted too few blocks replFactor waitActive sleep testBadBlockReportOnTransfer replicaCount assertTrue corruptBlockOnDataNodes  Receiving datanode fails on checksum and reports it to namenode get getNamenode block info localhost DFSTestUtil  Now get block details and check if the block is corrupt isCorrupt LOG blocks assertEquals getFileSystem setReplication  Corrupt the block belonging to the created file Thread  Create file with replication factor of 1 blockFilesCorrupted build      * Test if Datanode reports bad blocks during replication request     numDataNodes Long getNameNodePort getLocations toString file1 getFirstBlock shutdown ,hadoop,1
storePassword getResource toCharArray serverSocket newSingleThreadExecutor Executors serverSslContext getServerSocketFactory Assert bind assertNotNull nopassword create Boolean SSLContextBuilder /test-client.p12 localhost startHandshake read localPort loadKeyMaterial loadTrustMaterial resource2 thrown inputStream setSoTimeout getInputStream /test-server.p12 resource1 accept createSocket testSSLHandshakeClientUnauthenticatedError clientSslContext TIMEOUT setNeedClientAuth getLocalPort submit clientSocket keyPassword close connect assertEquals call getSocketFactory expect build toMillisecondsIntBound socket getSession createServerSocket ,httpcore,0
 Get the first 3 job2 job1 job4 checkWorkflows job3 job5 assertEquals getId WorkflowInstance list execute Services testWfJobsGetForPurgeTooMany size addRecordToWfJobTable addAll assertNotNull get  Get the next 3 (though there's only 2 more) WorkflowJob jpaService ,oozie,1
_testWfInfoWithActionSubsetGet addRecordToWfActionTable getId WorkflowInstance System 1 2 addRecordToWfJobTable WorkflowAction WorkflowJob job testWfInfoWithActionSubsetGet Successful testWfInfoWithActionSubsetGet ,oozie,1
filter testNoRemoteHost 1.1.1.1 testRequest destroy HttpServletResponse initFilter ,zxing,0
unreliable failsOnceThenSucceeds failsTenTimesThenSucceeds create unreliableImpl RETRY_FOREVER RetryProxy alwaysSucceeds testRetryForever ,hadoop,0
" 	   @ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_ doTest testDecodeExtendedMode 000001001011011010101001001001011001010101101001001001010110101001011010010010010101011010010110100100100101011011010010101001001001010101011001011010010010010101101011001010100100100101010110110010101001001001010101010011011010010010010101101010011010100100100101010110100110101001001001010101011001101010010010010101101010100110100100100101010110101001101001001001010110110101001010010010010101010110100110100100100101011010110100101001001001010101101101001010010010010101010101100110100100100101011010101100101001001001010101101011001010010010010101010110110010100100100101011001010101101001001001010100110101011010010010010101100110101010100100100101010010110101101001001001010110010110101010010010010101001101101010101001001001011010100101101010010010010101101001011010100100100101101101001010101001001001010101100101101010010010010110101100101010010110110100000 00000100101101101010011010110101001001010010110101001011010010010100101011010010110100100101001011011010010101001001010010101011001011010010010100101101011001010100100101001010110110010101001001010010101010011011010010010100101101010011010100100101001010110100110101001001010010101011001101010010010100101101010100110100100101001010110101001101001010110110110010101101010010010100101101011010010101001101101011010010101101011001010110110110010101010100110101101101001101010101100110101010100101101101101001011010101100101101010010010100101001101101010101001001001010110110010101010010010010101010011011010100100100101101010011010101001001001010110100110101010010010010101011001101010010110110100000  !""#$%&'()*+,-./0123456789:;<=>? `abcdefghijklmnopqrstuvwxyz{|}~ 000010010110110101010010010010100110101011011010100101101011010010110110110100101010101100101101101011001010101101100101010101001101101101010011010101101001101010101100110101101010100110101101010011011011010100101010110100110110101101001010110110100101010101100110110101011001010110101100101010110110010110010101011010011010101101100110101010100101101011011001011010101001101101010101001001001011010101001101010010010010101101010011010100100100101101101010010101001001001010101101001101010010010010110101101001010010110110100000 000001001011011010101001001001011001101010101001010010010110101001011010010100100101011010010110100101001001011011010010101001010010010101011001011010010100100101101011001010100101001001010110110010101001010010010101010011011010010100100101101010011010100101001001010110100110101001010010010101011001101010010100100101101010100110100101001001010110101001101001010010010110110101001010010100100101010110100110100101001001011010110100101001010010010101101101001010010100100101010101100110100101001001011010101100101001010010010101101011001010010100100101010110110010100101001001011001010101101001010010010100110101011010010100100101100110101010100101001001010010110101101001010010010110010110101010010100100101001101101010101001001001010110110100101010010010010101010110011010100100100101101010110010101001001001010110101100101010010010010101011011001010010110110100000 ",zxing,0
key1 metadata value2 value1 appendIfExists reader testAppend ROOT_PATH keyClass Reader Value1 conf fs delete two three  Verify the Meta data is not changed verifyAll4Values wrongCompressOption file SequenceFile four get metadataOption close deleteOnExit getMetadata set Updated one assertEquals Key1 fail createWriter Expected IllegalArgumentException for compression options  Verify the Meta data readable after append  Verify failure if the compression details are different valueClass writer testseqappend.seq compression verify2Values CompressionType Writer append ,hadoop,0
"next KeyValue  starting from each row, validate results should contain the starting row nr Count of columns Row name System FAMILY sleep Bytes startRowId addRows getNextRow assertTrue get scanner row results isExpectedRowWithoutTimestamps add toBytes clear assertEquals  Add more versions to make it a little more interesting. kv memstore  Clear out set.  Otherwise row results accumulate. Thread rowId Integer ROW_COUNT size compareRows testGetNextRow currentTimeMillis getScanners QUALIFIER_COUNT closestToEmpty ",hadoop,1
server getCurrentUser RPC SomeSuperUser GROUP_NAMES getUser newEmptyRequest run masterConf AuthenticationMethod  (auth:TOKEN) via SomeSuperUser (auth:SIMPLE)     * The user gets the token via a superuser. Server should authenticate    * this user.       Set RPC engine to protobuf RPC engine retVal setAuthenticationMethod current Assert newConf refreshConf testTokenBySuperUser getUserName client sm setProtocolEngine addr setConfiguration UserGroupInformation createUserForTesting addToken tokenId printStackTrace e expected assertEquals getClient setTokenService REAL_USER_NAME token doAs stop SecurityUtil setupTestServer != ,hadoop,0
"key1 testEqualsAndHashCode key2 value2  Sanity checks value1 keys assertFalse values Two SortedMapWritables with different data are now equal Two SortedMapWritables with same entry sets formed in different order are now different  entrySets are now same getBytes put mapB assertTrue mapA assertNotNull hashCode  When entry set is empty, they should be equal SortedMapWritable couldn't be initialized. Got null reference  Setup equals method returns true when passed null assertEquals  entrySets are different failureReason equals  Basic null check Two SortedMapWritables with different content are now equal  Let's check if entry sets of same keys but different values Two empty SortedMapWritables are no longer equal ",hadoop,0
testCoordActionsNotCompletetedForColumnValues actionNum getId getStatus addRecordToCoordActionTable addRecordToCoordJobTable _testCoordActionForCorrectColumnValues CoordinatorJob jobId coord-action-get.xml       * Add a Coordinator action with status WAITING and check for expected column values       CoordinatorAction action job getPending ,oozie,1
wait awaitRunState assertFalse listener getWaiter execute retries SHORT_DELAY testStartStop stop isClosed isRunning assertTrue executor assertNotNull runner DELAY ,logback,0
"Transfer-Encoding addHeader keepAlive assertFalse Connection chunked  Connection takes precedence over Proxy-Connection keep-alive Assert yadda, close, dumdy response context testConnectionTokens4  Use HTTP 1.1 reuseStrategy OK Proxy-Connection ",httpcore,0
"INodesInPath resolve inodes  Call getExistingPathINodes and request 2 INodes.  SnapshotRootIndex should be 3: {root, Testsnapshot, sub1, s1, file1} testSnapshotPathINodes invalidPath bar Assert createSnapshot getFileStatus /.snapshot/s1/file1 nodesInPath s1 getPathNames assertINodeFile allowSnapshot last  pointing to a snapshot file fail .snapshot The exception is expected:  invalidPathComponent fnfe snapshotFileNode  Check the INode for file1 (snapshot file) snapshot  The last INode should be the INode for sub1 INode getPathComponents components sub1 assertFalse foo System assertSnapshot  "".snapshot"" assertTrue invalidDir  No SnapshotRoot dir is included in the resolved inodes /.snapshot getParent assertEquals getSnapshot  SnapshotRootIndex should be 0. dotSnapshotPath getFullPathName snapshotPath  Call getExistingPathINodes and request only one INode. names fsdir hdfs getLastINode toString  Resolve the path ""/TestSnapshot/sub1/.snapshot"" file1  will ignore "".snapshot"" getINodes  snapshotRootIndex should be -1.  /TestSnapshot/sub1/.snapshot/s1/file1 ",hadoop,1
getJobTrackerUri map-reduce testMapReduceWithCredentials _testSubmitWithCredentials fs output actionXml <map-reduce> create write close <job-tracker> getNameNodeUri outputDir </job-tracker> dummy  getFileSystem inputDir <name-node> </name-node> </map-reduce> input getMapReduceCredentialsConfig w toXmlString toString data.txt getFsTestCaseDir ,oozie,1
result  Assert readLink testReadSymlinkWithNullInput assertEquals FileUtil ,hadoop,0
/foo     * Test resolvePath(p)      foo chrootedTo assertEquals testResolvePath createFile / resolvePath Assert getDefaultFileSystem fileContextTestHelper fc ,hadoop,0
"{hello:{world:yay}} OptionHelper curlyBraces_LOGBACK_1101 {world:{yay}} {foo{""bar""}} assertEquals {""hello"":{""world"":""yay""}} input r a:{y} foo{bar} context substVars ",logback,0
directoryCount expected length assertEquals spaceConsumed testToStringNoShowQuota fileCount  check the toString method with quotas build        33333        22222              11111  quota toString spaceQuota contentSummary ,hadoop,0
" init application/json thenReturn servletContext text/*;q=0.3, text/html;q=0.7, text/html;level=1, text/html;level=2;q=0.4, */*;q=0.5 assertEquals getAcceptContentType testGetAcceptContentType httpServletRequest text/html;q=1, application/json;q=0.9 when application/json;q=0.9, text/plain;q=0.5 accept getHeader Result application/protobuf;q=1, application/json;q=0.7 application/protobuf totally_unknown context application/xhtml;q=1, application/json;q=0.9 httpServletResponse text/plain ",ninja,0
FILE_FOOTER FILE_HEADER PRESENTATION_FOOTER headerFooterCheck PRESENTATION_HEADER PRESENTATION_FOOTER  nullPresentationHeader FILE_HEADER  ,logback,0
IOUtils original os testCopyStream copyStream toByteArray is assertEquals copy ,oozie,1
END_POINTS IS_SECURITY_ENABLED submit oozieUrl run appPath assertTrue get -config create workflow.xml SERVLET_CLASSES close runTest app createConfigFile getContextURL -run MockDagEngineService assertEquals getFileSystem testRunWithDebug args call -oozie mkdirs wfCount toString job -debug getFsTestCaseDir ,oozie,1
play A server readAscii addHeader B openConnection Foo varyMatchesRemovedRequestHeaderField assertEquals setBody addRequestProperty / enqueue getUrl bar Cache-Control: max-age=60 Vary: Foo fooConnection ,okhttp,1
constructResult TestCaseUtil getRowNumber secondRow getName rssExpandedReader decodeRow2pairs getBlackRow RSSExpandedReader getRows firstExpandedRow result getHeight getPairs get getStartEnd binaryMap src/test/resources/blackbox/rssexpandedstacked-2/1000.png testDecodingRowByRow secondRowNumber getText getFinderPattern assertEquals reverse totalPairs fail firstRow size getBinaryBitmap  expected (01)98898765432106(3202)012345(15)991231 firstRowNumber ,zxing,0
"cluster writeTimeout conf  set a very short write timeout for datanode, so that tests runs fast. writeData fs waitActive out sleep readFully  milliseconds. create testWriteTimeoutAtDataNode  set a smaller block size close  enough to empty TCP buffers.  first read a few bytes DFSConfigKeys  write a 2 block file. in filePath /testWriteTimeoutAtDataNode getFileSystem io.file.buffer.size blockSize setInt Thread  set a small buffer size buf IOUtils build  force write timeout at the datanode. numDataNodes  successfully read with write timeout on datanodes.  read enough to empty out socket buffers.  now read few more chunks of data by sleeping in between : shutdown open bufferSize ",hadoop,1
server NANOSECONDS Request + Response: %sms String System ABCDEF setBodyDelay elapsedNanos assertTrue nanoTime delayResponse connection toMillis read in openConnection SECONDS format assertEquals setBody getInputStream elapsedMillis / enqueue getUrl startNanos ,okhttp,1
date scriptExecutor session  Given simple simplemap 0 AM Eq delete SELECT * FROM simple WHERE id =  consistencylist simpleset  When of where id row value table executeScriptTemplate isNotNull RandomUtils manager getSet one should_dsl_delete simpleMap getString nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap isTrue  Then isNull containsOnly Long buildDateKey consistencyList fromBaseTable dsl isEqualTo ,achilles,1
assertServiceCreationFails SELF testNotAService ,hadoop,0
testWritable testShortWritable ,hadoop,0
checkCoordAction getTime DateUtils parseDateOozieTZ addRecordToJobTable call jobId @1 testActionMater 2009-03-06T010:00Z 2009-03-11T10:00Z -testActionMater-C action 0000000- startTime endTime ,oozie,1
receiveMessage getObserverReference observerGarbageCollection createStage ref1  this fails because the garbage collector will have disposed of the observer System observer1 join gc expectException stage1 ,orbit,1
pushPromise play data streamId headerEntries onReset asList observer TYPE_HEADERS connection https events add banana read last onHeaders /cached onData 200  SYN_STREAM requestHeaders responseHeaders Header size getSource GET pushObserver Arrays newStream onRequest android  play it back squareup.com HTTP_20_DRAFT_09  verify the peer received what was expected connectionBuilder acceptFrame assertTrue peer get client takeFrame expectedResponseHeaders a b synReply expectedRequestHeaders setVariantAndClient assertEquals pushPromiseStream sendFrame build ,okhttp,1
" cluster setSecurityManager moveFromLocalFile conf run f1 f2 asList checkPermission getStackTrace  copy multiple files to destination directory DataNode  should not be here, must got IOException getPath join copy2ndFileThread mkdir currentThread createLocalFile destmultiple2 copy local  destmultiple stringifyException .f1.crc getFileSystem testPut done getSecurityManager dfs contains numDataNodes  use SecurityManager to pause the copying of f1 and begin copying f2 srcs Arrays begin getUri shutdown copyFromLocalFile /test/putmultiple dst assertFalse show  move multiple files to destination directory fs delete System sleep  remove left over crc files: assertTrue TEST_ROOT_DIR StringUtils  to remote  root sm FileUtil.copyContent good  close .f2.crc /test/put /test/movemultiple start  pause at FileUtil.copyContent Not a HDFS:  Thread firstTime t build SecurityManager =  exists toString ioe ",hadoop,1
workflow authToken getLogToken assertEquals setLogToken  workflow.setWorkflowInstance(new MyWorkflowInstance()); getProtoActionConf proto  assertNotNull(workflow.getWorkflowInstance()); setAuthToken getAuthToken logToken setProtoActionConf testWorkflow ,oozie,1
ninjaMode  isAvailable getSslKeystoreUri conf/jetty.minimal.conf getContextPath nullValue ssl NinjaMode not getServerUrls assertNotNull getSslTruststoreUri get Standalone getHost RANDOM_PORT isStopped externalConfigurationPath https://localhost: standalone start is getSslTruststorePassword isStarted sslPort assertThat getNinjaMode getPort port getSslPort getSslKeystorePassword shutdown ,ninja,0
currentThread set unlock getMethodName LOG assertFalse start lockThread assertEquals run acl testname testTryWithResourceSyntax acquire competingThread tryLock Thread localLock assertNull get name lock join assertNotEquals ,hadoop,0
cluster FILE_SIZE getBlockLocations getLocatedBlocks dnSockets  Insert a socket to the NN conf dn dnAddr getSelfAddr nnSock put assertTrue CACHE_SIZE get getNamenode client block getAddress close Evicted socket closed localhost  Make a client cache testSocketCache  Lookup the DN socks assertEquals assertSame Cache is empty testFile  Insert DN socks nnAddr getPort createSocket util dnSock isClosed size  Find out the DN addr getDataNode getNameNodePort Read the write toString  Make some sockets to the DN NN socket evicted Retrieve cached sockets ,hadoop,1
server getCurrentUser RPC getProxySuperuserGroupConfKey GROUP_NAMES DefaultImpersonationProvider getUser newEmptyRequest conf run retVal Assert setStrings testRealUserIPNotSpecified REAL_USER_SHORT_NAME refreshConf client setProtocolEngine addr setConfiguration UserGroupInformation proxyUserUgi printStackTrace e getClient createRemoteUser group1 REAL_USER_NAME fail doAs getTestProvider stop setupTestServer PROXY_USER_NAME The RPC must have failed  realUserUgi createProxyUserForTesting ,hadoop,0
fail testParallelRead runParallelRead Check log for errors ,hadoop,1
  AIUE in Hiragana in Shift_JIS testChooseMode chooseMode A a  Sou-Utsu-Byou in Kanji in Shift_JIS. #  Numeric mode. Mode  8-bit byte mode. assertSame  Nihon in Kanji in Shift_JIS. 0 0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ $%*+-./: 0123456789 Encoder bytes  Alphanumeric mode. shiftJISString ,zxing,0
 myFile incorrect Filesystem is passed testlfs:/ listStatus run recentCheckpoint incorrectfs:/ FileSystem -expunge trashRoot addFileSystemForTesting mkdir TEST_DIR Expunge immediate should return exit code 1 when  assertNotEquals testlfsshell Old checkpoint should be removed val FS_TRASH_INTERVAL_KEY setUri format  Incorrect FileSystem scheme FS_TRASH_INTERVAL_DEFAULT yyMMddHHmm setLong isEnabled test/mkdirs/testFile -fs Current getUri myPath fs.defaultFS Expunge immediate with filesystem should return zero assertFalse removeFileSystemForTesting -immediate Time fs.testlfs.impl testlfs assertTrue getCurrentTrashDir  10 minute now checkpointFormat testlfsURI trashInterval writeFile testExpungeWithFileSystem getParent set setClass assertEquals Ensure trash folder is empty Expunge immediate should fail when filesystem is NULL setConf Recent checkpoint should be removed getLong args incorrectFS Current folder should be removed currentFolder test/mkdirs exists toString initialize  Empty FileSystem scheme config oldCheckpoint ,hadoop,0
User With Spaces:group assertIllegalArguments User With Spaces:Group With Spaces conf run us^er  The following are invalid (exception expected). user:gr#oup user:group us!er user:Group With Spaces /path :group HADOOP_SHELL_MISSING_DEFAULT_FS_WARNING_KEY chown enableWarning :gr#oup  The following are valid only on Windows. setConf  The following are valid (no exception expected). :gr%oup :Group With Spaces User With Spaces user:gr%oup testChownUserAndGroupValidity user assertValidArgumentsOnWindows setBoolean ,hadoop,0
isStatic getName LOG getDeclaredMethod getParameterTypes isPrivate getMethod error m exc2 FilterFileSystem doesn't implement  getDeclaredMethods Testing  Skipping  getModifiers isFinal Modifier info testFilterFileSystem ,hadoop,0
getPayloadContent read payload1 payload2 frame1 valueOf frame2 getStreamId assertEquals inBuffer readableChannel ByteBuffer testReadFrameMultiple remaining FrameFlag Assert allocate getType assertNotNull FrameType get of getFlags ,httpcore,0
"testExec_60  killed:   Multiplier:  System  MaxRetries:  seconds addArgument avg  need to add ""1"" to wait the requested number of seconds assertTrue startTime  However if the increase is too gradual, we never wait long enough for any test to exit normally setWatchdog cmdLine killedProcess offsetMultiplier processTerminatedCounter  System.out.println(offset + "": process was killed: "" + watchdog.killedProcess()); offset start  Elapsed (avg ms):  Processes terminated:  execute Integer Not a single process terminated on its own maxRetries watchdog watchdogKilledProcessCounter  System.out.println(offset + "": process has terminated: "" + watchdog.killedProcess()); currentTimeMillis toString Not a single process was killed by the watch dog pingScript exec Watchdog killed the process ",commons-exec,1
 Before we destroy stuff the injector is there  After destroying the context the injector is null. contextInitialized getInjector notNullValue servletContextEvent testThatContextDestroyedWorks ninjaServletListener assertThat contextDestroyed nullValue ,ninja,0
ROW_1 ROW_2 checkValuePB addRow put TABLE path Bytes yield get client VALUE_1 VALUE_3 VALUE_2 getCode  make sure the fake row was not actually created VALUE_4 addCell toBytes assertEquals cellSetModel  check that all of the values were created / Thread deleteRow MIMETYPE_PROTOBUF rowModel COLUMN_2 COLUMN_1 response createProtobufOutput /fakerow  deliberate nonexistent row testMultiCellGetPutPB ,hadoop,1
play server request C getSequenceNumber  Connection reused. redirectedBy Location: /b assertCode Location: /c assertBody /a /c Test Redirect from /b to /c assertContainsHeaders /a has moved! await client Test: Redirect from /b to /c  Connection reused again! redirect addHeader receiver takeRequest assertEquals setResponseCode setBody /b has moved! url  New connection. enqueue getUrl Test: Redirect from /a to /b build Redirect from /a to /b ,okhttp,1
END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL oozieUrl testJobInfo MockDagEngineService run assertEquals -offset -info 0 args call 1 2 -oozie 3 reset job SERVLET_CLASSES -len runTest ,oozie,1
src CodecTestUtils StandardCharsets channel assertEquals testChunkExceed encoder remaining 4 0123 4 4567 4 89AB 4 CDEF  Assert flush outbuf metrics dump wrap write 0123456789ABCDEF ,httpcore,0
EXEC_ORDER callable2 callable3 callable1 testQueueSerial assertEquals queueSerial queueservice asList Services get Arrays evaluate waitFor ,oozie,1
next getBlockLocations stat isFile assertFalse FILE1 getDefault hasNext assertEquals FILE_LEN testFile util assertTrue getLen makeQualified getPath FsPermission fc mkdir writeFile listFiles TEST_DIR itor ,hadoop,1
fail process Assert interceptor testRequestContentInvalidInput IllegalArgumentException should have been thrown ,httpcore,0
testBundleSuspendWithError bundleJobGetCmd addRecordToBundleJobTable getId assertEquals getStatus execute call Services assertNotNull get Job job jpaService ,oozie,1
cluster conf createFile simulatedStorage waitActive leasePeriod The file now has   blocks. locations =  getNamenode setLeasePeriod testFileCreationError2:    count getFileSystem setInt dfs Long DFS_HEARTBEAT_INTERVAL_KEY SimulatedFSDataset  verify that the last block was synchronized. shutdown /filestatus.dat getBlockLocations The file has   create cluster testFileCreationError2 start Added block  System sleep testFileCreationError2 successful addBlock closeStream client DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY getBlock  wait for the lease to expire assertEquals Thread IOUtils  add one block to the file build Created file filestatus.dat with one replicas. toString locations location file1  namenode triggers lease recovery testFileCreationError2 setBoolean locatedBlockCount ,hadoop,1
lastException unwrapExeption unwrapRemoteException getInternalState conf Executors getCause setupDecayRpcSchedulerandTestServer addInternal  wait for the 1st response time update numClients add res setLogLevel LOG DecayRpcScheduler unchecked GenericTestUtils eq . setInt newSleepRequest proxy callQueue re stop Level spy shutdown succeeded server .0 RPC submit executorService ns error  avg response time(3s) exceeds threshold (2s). timeout Last received non-RetriableException: sleep times RetriableException not received assertTrue verify addr newFixedThreadPool CommonConfigurationKeys e testClientBackOffByResponseTime getClient any Whitebox Thread call  start a sleep RPC call that sleeps 3s. setInternalState ,hadoop,0
compressedDateMarch12th2010 (01)90012345678908(3200)001750(17)100312 data test01320X171 expected compressedGtin900123456798908 compressed20bitWeight1750 header320x17 assertCorrectBinaryString ,zxing,0
cluster  Failover by session expiration ====== Restarting server ====== Failing over by session expiration HAServiceState waitForServerDown hostPort waitForServerUp  Graceful failovers info LOG  Failover by bad health stopServer CONNECTION_TIMEOUT start waitForHealthState gracefulFailoverToYou getZkfc testOneOfEverything setHealthy waitForHAState startServer State  Restart ZK expireAndVerifyFailover ,hadoop,0
add findDefaultComponentType result a registry other assertNull absent ,logback,0
 1010 assertEquals testAppendBit  1 appendBit getSize getSizeInBytes v  10101  10101010  10101010 10  10101010 1 getUnsignedInt  1010101  101  101010  10 ,zxing,0
/a1/a2 cluster /b1/b2/b3.txt conf error fs waitActive out checkPermission dirPerm StringUtils getDefaultReplication FileSystem get create FsPermission close write /c1 /a1 DFSConfigKeys set e LOG testCreate stringifyException filePerm permission io.file.buffer.size getDefaultBlockSize /b1/b2 / 000 inheritPerm 022 getInt build /a1/a2/a3 numDataNodes mkdirs /c1/c2.txt createImmutable shutdown rootPerm toShort /b1 setBoolean ,hadoop,1
"testRollback deactivate bean4 wfId2 bean1 assertNotNull bean2 bean3 newDate wfId1 isStartProcessed workflow-2 add RUNNING Expected exception but didnt get any workflow-1 writeCmd list  update existing record and insert another readCmd2 execute FaultInjection readCmd1 fail jpaee true  initial insert setJobId  Check whether transactions are rolled back or not getActualEnd Expected exception due to commit failure but didn't get any assertFalse EventStatus  isStartProcessed should NOT be toggled to true getErrorCode get _createSLASummaryBean updateList insertList _createSLACalcBean assertEquals SkipCommitFaultInjection  actualEnd should be null as before setActualEnd scBean Services assertNull org.apache.oozie.command.SkipCommitFaultInjection setSystemProperty  set fault injection to true, so transaction is roll backed ErrorCode jpaService sdBean ",oozie,1
exception getLocalizedMessage NinjaConstant equalTo when Result result getRenderable assertTrue verify getNotFoundResult not important getTemplate ArgumentMatchers thenReturn getWithDefault getMessage testGetOnNotFoundExceptionResultWorks eq  real test: assertThat any ninjaDefault getStatusCode contextImpl messages ninjaProperties ,ninja,0
" Now delete all... then test I can add stuff back getName serverinfo reference_A reference_B  assert some things: table_name delete put tableName result sleep Bytes fam deleteColumns  ok now delete a split: get row info add addColumn testDelete_mixed  Assert that after a delete, I can put. method printStackTrace e toBytes  add some data: assertEquals ip_address families initHRegion Thread splitB testtable size  column names region splitA ",hadoop,1
value5 fileResource1 value2 value1 value4 value3 conf CONFIG2 appendProperty out CONFIG addResource get  change values in the test file... test.key3 set test.key4 endConfig  add a few values via set. startConfig assertEquals reloadConfiguration final-value3  overlayed property overrides. final-value1 testReload test.key1 fileResource test.key2 ,hadoop,0
bundleJobGetCmd addRecordToBundleJobTable getId assertEquals getStatus execute testBundlePauseUnpauseNeg1 call Services fail assertNotNull get Job job jpaService should not reach here. ,oozie,1
primShortValidationShouldWork hasFieldViolation thenReturn invoke when param1 assertTrue context create verify primShortParam mockController validation blah getParameter ,ninja,0
addRecordToWfActionTable getId WorkflowInstance addRecordToCoordActionTable coordJob wfJob1 wfJob3 coordAction3 addRecordToWfJobTable wfJob2 coordAction4 children assertNotNull wfJob5 coordAction5 get wfJob4 CoordinatorAction  Get the next 3 (though there's only 2 more) coordAction1 coordAction2 WorkflowJob  Get the first 3 assertEquals wfAction1 wfAction2 execute addRecordToCoordJobTable wfAction3 wfAction4 wfAction5 checkChildren Services CoordinatorJob 1 2 coord-action-get.xml size WorkflowAction addAll SUCCEEDED testGetWorkflowParentTooMany jpaService ,oozie,1
localhost request init chain set getRemoteAddr thenReturn destroy when filter testHostname contains Assert assertNull Mockito HostnameFilter assertTrue doFilter response get mock invoked ,oozie,1
fail Assert testShutdown release CloseMode somehost pool IllegalStateException should have been thrown  Ignored if shut down lease close ,httpcore,0
fsn cluster Starting test testClusterStats NameNodeAdapter writeConfigFile conf  Check namenode stats for multiple datanode heartbeats namenode startCluster verifyStats file testClusterStats numDatanodes refreshNodes writeFile excludeFile info ret waitNodeState LOG testClusterStats.dat getDatanode numNameNodes getFileSystem getNameNode AdminStates fileSys decommissionNode  Stop decommissioning and verify stats getNamesystem downnode ,hadoop,1
"RecoveryService getName CoordELFunctions /nodb/notable/dt=20120430;country=usa callableQueueService CoordinatorAction action coord-job-for-action-input-check.xml addRecordToCoordActionTableForWaiting newHCatDependency  Test timeout when table containing missing dependencies is dropped in between info  Delay should be something like delay=599999. Ignore last three digits  Should be requeued at the recovery service interval delay=599[0-9]{3}, .* matches setInt CoordinatorJob fail contains size actionId job /nodb/notable/dt=20120430;country=brazil server addRecordToCoordJobTableForWaiting Queue dump is  checkCoordAction  but only push missing deps are there log getId coord-action-for-action-input-check.xml assertTrue get getQueueDump Z testRequeueOnException getConf newHCatDependency2 newHCatDependency1 e  Nothing should be queued as there are no pull dependencies hcat:// getMessage assertEquals setMissingDependencies queueDump call Services NoSuchObjectException toString ",oozie,1
getPayloadContent read payload1 payload2 frame1 valueOf frame2 getStreamId assertEquals inBuffer readableChannel ByteBuffer testReadFrameMultiple remaining FrameFlag Assert allocate getType assertNotNull FrameType get of getFlags ,httpcore,0
prepare testCodingDirectBuffer_10x4_erasure_of_d2_d4_p0 testCoding ,hadoop,0
"testSomeMethods END_POINTS archive2 IS_SECURITY_ENABLED oozieUrl configuration addArchive wc file1,file2 get archive1 SERVLET_CLASSES runTest getContextURL e XOozieClient archive1,archive2 getMessage assertEquals call file cannot be null or empty file2 createConfiguration file1  test archive addFile ",oozie,1
date withSerialConsistencyLevel  Given simple 0 AM  When id logAsserter isNotNull should_dsl_update_value_if_equal RandomUtils withResultSetAsyncListener assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap if_Value success  Then Long buildDateKey fromBaseTable dsl rs Set scriptExecutor session update SELECT value FROM simple WHERE id =  withLwtResultListener Eq of get where getAndSet row value table executeScriptTemplate prepareLogLevelForDriverConnection SERIAL onError manager one getString nextLong assertSerialConsistencyLevels isTrue new value wasApplied isEqualTo onSuccess ,achilles,1
"getConfString <frequency=120 CoordELFunctions createELEvaluatorForGroup replace conf  CoordELFunctions.evaluateFunction(eval, expr)); evalAndWrap ${coord:hours(12)} get expr end coord-job-submit-freq reply frequency=${coord:hoursInDay(2)} CoordELEvaluator ${start} ${coord:months(1)} frequency=${coord:days(2)} start frequency=${coord:tzOffset()} assertEquals  frequency=""${coord:months(1)}""><data-in name=""A"" dataset=""a""></data-in> ${coord:days(7)} 1 fail testCreateFreqELValuator eval 720 frequency=60 7  frequency=""${coord:hours(12)}""><data-in name=""A"" dataset=""a""></data-in> ${end}  -1)); frequency=${coord:daysInMonth(2)} <coordinator-app name=""mycoordinator-app"" start=""${start}"" end=""${end}""  frequency=""${coord:days(7)}""><data-in name=""A"" dataset=""a""></data-in> ",oozie,1
getAlertPercentage WORKFLOW_ACTION getNotificationMsg getSlaId ua DateUtils getParentSlaId getUpstreamApps qc bean ee ac af getParentClientId an es ap et getExpectedEnd getAlertContact getAlertFrequency jd getEvent_id getAppType nm getJobData getAppTypeStr psi getUser getSeContact getExpectedStart getJobStatusStr sc assertTrue si STARTED pci convertDateToTimestamp getStatusTimestamp getExpectedEndTS getQaContact getAppName st set gn assertEquals getDevContact testSetGet getExpectedStartTS getGroupName getEventType u getStatusTimestampTS dc ,oozie,1
next  instances from the CodePool as reader1 reader  Create a reader which uses 4 BuiltInZLibInflater instances getTempPath assertFalse conf fs  read second value from reader2 (this throws an exception) test1.seq file1-1 file2-2  Returns the 4 BuiltInZLibInflater instances to the CodecPool file1-2 file2-1 SequenceFile  read first value from reader2 FileSystem get  read first value from reader1  create a sequence file 1 text testClose close test2.seq  read second value from reader1 GenericTestUtils assertEquals reader2 reader1 deprecation NullWritable createWriter path1 path2 getLocal  4 BuiltInZLibInflater instances to the CodecPool again toString writer CompressionType append  The first reader gets 4 BuiltInZLibInflater instances from the CodecPool ,hadoop,0
"addRecordToCoordJobTableForWaiting configuration /2009/01/29/ caBean getId /2009/01/15/ coordGetCmd sleep eAction coord-action-for-action-input-check.xml getTestCaseDir get CoordinatorAction createDir property action coord-job-for-action-input-check.xml testResolveCoordConfiguration addRecordToCoordActionTableForWaiting elementList value /2009/01/22/ printStackTrace XmlUtils workflow e getChild parseXml /2009/01/08/ assertEquals e1 execute e2 Unexpected exception call fail CoordinatorJob Services getChildren getValue getActionXml getNamespace file://,testDir/2009/29 configElem file://,testDir/2009/29,file://,testDir/2009/22,file://,testDir/2009/15,file://,testDir/2009/08 job jpaService ",oozie,1
getValue fromUnixMilliseconds Assert currentTimeMillis Deadline nowPlusOneMin assertEquals deadline System testValue ,httpcore,0
test simple edit exit code run -alias dt assertTrue test simple edit output service old:  outContent test simple edit print old exit code testEdit test simple edit output kind old:  edit SERVICE2 oldService test simple edit print new exit code assertEquals test simple edit output kind new:  args -service rc tokenFilename2 print contains KIND toString newName:12345 newAlias test simple edit output service new:  ,hadoop,0
cluster newArrayList HATestUtil assertParallelFilesAreIdentical ImmutableList getMostRecentCheckpointTxId dirs doEdits assertEquals nn1 nn0 getNameNodeCurrentDirs ImmutableSet Lists addAll testBothNodesInStandbyState transitionToStandby of waitForCheckpoint getFSImage  will each try to take a checkpoint and upload to each other. FSImageTestUtil getNamesystem ,hadoop,1
"getName conf cred1 getKind cred2 getBytes clearProperty password testExternalTokenFiles token1 token2  create path for token files UserGroupInformation tokenId writeTokenStorageFile , testDir  create new token and store it / contains hadoop.token.files tokenFullPathnames setProperty credsugiTokens testDirPath getTokens System setLoginUser assertTrue StringUtils getTrimmedStrings tokenFiles  set property for token external token files getAbsoluteFile addToken token1,token2 token-service2 getAbsolutePath token-service1 length tokenUgi getLoginUser getService target tokenFilenames toString -tmpDir tokenFile append ",hadoop,0
 assertFalse channel outStream  getBytes Assert flush inbuf buffer write   chbuffer s1 s2 s3 a StandardCharsets clear assertEquals fill readLine ByteBuffer setLength outbuf toByteArray toString testComplexReadWriteLine wrap newChannel append outChannel ,httpcore,0
 a l1 l2 start assertEquals sb Thread sleep a:1-L a:1-U a:2-L a:2-U trim finish toString testWaitWriteLock ,oozie,1
server ProxyUsers TestProtocol RPC getProxySuperuserGroupConfKey getProxy aMethod GROUP_NAMES conf run retVal Assert setStrings testRealUserIPNotSpecified REAL_USER_SHORT_NAME stopProxy addr UserGroupInformation getServer ret proxyUserUgi printStackTrace e start createRemoteUser group1 getConnectAddress REAL_USER_NAME proxy fail doAs NetUtils stop ADDRESS PROXY_USER_NAME The RPC must have failed  realUserUgi createProxyUserForTesting ,hadoop,1
createInjector serviceShouldNotBeStartedBeforeLifecycleServiceIsStarted equalTo MockService getInstance assertThat ,ninja,0
HttpHeaders conn argThat inStream ack responseCaptor sendResponseHeader when setEntity receiveRequestHeader Assert assertNotNull context create Boolean getCode HttpStatus thenReturn ArgumentMatchers getAllValues capture Method eq matches / never responseFactory size newHttpResponse mock connReuseStrategy request HeaderElements getRequest testExecutionEntityEnclosingRequestWithExpectContinue times httpservice flush get forClass verify close addHeader process keepAlive ArgumentCaptor assertEquals sendResponseEntity assertSame getEntity errorResponse Mockito response HttpCoreContext httprocessor responses handleRequest entity ,httpcore,0
conf seek System HADOOP-1489  Now read the file for ioBufSize bytes assertTrue TEST_ROOT_DIR FileSystem getLen getFileStatus Read  close writeFile  read 4 more bytes before marking  bytes. read in  First create a test input file. io.file.buffer.size setInt filePos testFile  seek beyond data buffered by open MARKED ioBufSize fileSize getLocal fileSys  file size= exists  hence won't trigger this bug.  Try to read the rest testTruncatedInputBug open mark ,hadoop,0
fifoLinkedList testAddRemoveCycle h h1 h2 assertEquals h3 h4 assertSame getLast removeLast 1 2 3 Assert 4 size getFirst addFirst ,httpcore,0
thenReturn enumCsvParamSingleShouldBeParsed invoke when param1 Red enumCsvParam Rainbow context create verify mockController getParameter ,ninja,0
set Expected exception:  LOG testDefaultURIWithoutScheme getFileContext conf / fail  not thrown! ufse FileSystem FileContext info ,hadoop,0
scheduler A testUsingWeightedTimeCostProviderNoRequests getSchedulerWithWeightedTimeCostProvider assertEquals getPriorityLevel mockCall ,hadoop,0
call process task e shouldBeThreadSafe WroTestUtils runConcurrently processor $side: top;$radius: 10px;.rounded-#{$side} {border-#{$side}-radius: $radius;} ,wroj4,1
wfJobCGetCmd addRecordToBundleActionTable coordActionC coordActionD wfActionFGetCmd subwfActionAGetCmd addRecordToWfActionTable coordActionA coordActionB 2011-02-01T01:00Z getStatus coordJobCGetCmd wfJobFGetCmd wfActionCGetCmd getEndTime bundleActionA BundleJobBean assertNotNull bundleActionB CoordinatorAction Workflow Job C should not have been purged 2011-03-01T01:00Z SubWorkflow Job C should not have been purged bundleJobAGetCmd  Job relationships:         bundleJobA              yes     yes             coordJobA           yes     ^                 wfJobA          yes     ^                     subwfJobA   yes     ^         bundleJobB              no      no             coordJobB           yes     ^                 wfJobB          no      ^         coordJobC               no      no             wfJobC              no      ^                 subwfJobC       yes     ^         coordJobD               yes     no             wfJobD              no      ^         wfJobE                  yes     yes         wfJobF                  yes     no             subwfJobF           no      ^          Workflow Action C should not have been purged subwfJobCGetCmd execute Workflow Job D should not have been purged SubWorkflow Job A should have been purged CoordinatorJob 1 subwfActionF fail SubWorkflow Action F should not have been purged SUCCEEDED subwfJobFGetCmd Bundle Action B should not have been purged bundleActionAGetCmd je Coordinator Job D should not have been purged subwfActionFGetCmd wfJobA subwfJobF wfJobC 2011-04-01T01:00Z wfJobB wfJobE wfJobD subwfJobA wfJobF subwfActionA Workflow Job B should not have been purged subwfJobC subwfActionC Bundle Action A should have been purged Coordinator Action D should not have been purged 2011-07-01T01:00Z Coordinator Job C should not have been purged getErrorCode get wfJobAGetCmd wfActionEGetCmd getAppName Bundle Job B should not have been purged Coordinator Job B should not have been purged 2011-01-01T01:00Z addRecordToBundleJobTable setLastModifiedTime assertEquals getLastModifiedTime testPurgeLotsOfJobs addRecordToCoordJobTable call Services wfActionDGetCmd Workflow Action D should not have been purged wfActionA jpaService wfActionB wfActionC wfActionD wfActionE wfActionF bundleJobBGetCmd SubWorkflow Action C should not have been purged Workflow Action E should have been purged SubWorkflow Job F should not have been purged coordActionAGetCmd getNumDaysToNotBePurged DateUtils WorkflowInstance addRecordToCoordActionTable parseDateOozieTZ Workflow Job F should not have been purged coordJobDGetCmd 2011-05-01T01:00Z Coordinator Job A should have been purged Job coordActionDGetCmd Coordinator Action A should have been purged Workflow Action F should not have been purged coordJobB coordJobC Coordinator Action C should not have been purged coordJobA coordJobD wfActionBGetCmd wfJobBGetCmd wfJobEGetCmd WorkflowAction 2011-06-01T01:00Z coordActionCGetCmd Workflow Action A should have been purged wfActionAGetCmd Bundle Job A should have been purged getId Workflow Job A should have been purged subwfActionCGetCmd bundleActionBGetCmd bundleJobA bundleJobB addRecordToWfJobTable wfJobDGetCmd Workflow Action B should not have been purged WorkflowJob coordJobAGetCmd SubWorkflow Action A should have been purged coordActionBGetCmd subwfJobAGetCmd coord-action-get.xml coordJobBGetCmd setEndTime Workflow Job E should have been purged ErrorCode Coordinator Action B should not have been purged ,oozie,1
" and the approximation is not used /file-1 nodetype remove JcrConstants folder-2 folder-1 root merge builder /folder-1 /folder-2 CommitInfo getRoot oak:index  remove ""rep:security"" as it interferes with tests Mounts rootState query file-1 index createFilter assertEquals store nodeType checkCursor filter entryCount defaultMountInfoProvider rep:security getChildNode setProperty addFolder getCost addFile ",jackrabbit,1
conn HTTP/1.1 200 OK Server: test Transfer-Encoding: identity  123 Server inStream testReadResponseEntityIdentity getEndpointDetails when getBytes bind Assert assertTrue assertNotNull getResponseCount getCode StandardCharsets thenReturn assertEquals getInputStream Mockito response socket containsHeader receiveResponseHeader receiveResponseEntity ,httpcore,0
server connectors getDefaultSocketFactory conf run sleep  server should drop the other 4 connections join addr close connect testMaxConnections start assertEquals  server should only accept up to 6 connections setInt getConnectAddress Thread sock NetUtils createSocket stop getNumOpenConnections getNumDroppedConnections ipc.server.max.connections ,hadoop,0
" 3s finLatch getLocalPort assertFalse run conf doGetGroups serverSock ldap://localhost: await ldapUrl countDown hadoop join LDAP response read timed out, timeout used: ldapServer ignored mapping debug printStackTrace e LOG ms CONNECTION_TIMEOUT start getMessage Got the exception while LDAP querying:  testLdapConnectionTimeout setConf accept setInt fail contains connectionTimeoutMs ne assertExceptionContains  Client of this LDAP server is expected to get a connection timeout. The LDAP query should have timed out! getBaseConf remaining name ",hadoop,0
play windowUpdateStreamIds data readSendsWindowUpdate headerEntries Math  Send frames summing to windowUpdateThreshold. TYPE_HEADERS connection buffer  connection WINDOW UPDATE banana add read  connection in count maxFrameSize sent  stream WINDOW UPDATE contains  SYN_STREAM size getSource synStream  stream newStream android TYPE_WINDOW_UPDATE acceptFrame min stream assertTrue peer DEFAULT_INITIAL_WINDOW_SIZE getResponseHeaders takeFrame windowUpdateThreshold a windowUpdate b synReply setVariantAndClient assertEquals j sendFrame SPDY3  Play it back. ,okhttp,1
charset submit executorService channel Executors getBytes writeCompleted Assert 1234567890 flush getDuration tmp isEndStream get Boolean task1 write task2 outputBuffer awaitOutputRequest newFixedThreadPool StandardCharsets hasData testMultithreadingWriteStream assertEquals dataStreamChannel getTimeUnit call toByteArray TIMEOUT 1234567890123456789012123456789012345678901234567890 ,httpcore,0
"next rs conn Schema testGenerateCreateScript pkeyTest  VALUES(1, 'abcd') TestTable prepareStatement DBType DROP TABLE  INSERT INTO   Will throw an exception if  index cant be created TestColumns close TestIndex indexStmt ( ) SELECT COUNT(*) FROM  assertEquals getDirectConnection execute executeQuery getInt prepareDB ,  generateCreateIndexScript dropSchema executeUpdate ",oozie,1
reader authToken conf an exception should be thrown as the definition exceeds the given maximum getErrorCode getTestCaseDir /workflow.xml get file:// workflow.xml init testMaxWfDefinition WorkflowAppService wf-schema-valid.xml destroy assertEquals services 100 fail IOUtils getTestUser copyCharStream setSystemProperty wfe getResourceAsReader ErrorCode writer wps readDefinition File ,oozie,1
"getAllSecrets testOne seed  simplest case System timeout assertArrayEquals atLeastOnce rand Assert  Use the same seed and a ""plain"" Random so we can predict the RNG currentSecret secretProvider verify getDummyServletContext /secret init ZKSignerSecretProvider getConnectString zkServer rolloverFrequency getCurrentSecret destroy assertEquals secret2 secret3 rollSecret secret1 assertNull currentTimeMillis setProperty realRollSecret allSecrets atLeast generateNewSecret spy config ",hadoop,0
date scriptExecutor postUpdate_preUpdate_value session  Given update simple SELECT * FROM simple WHERE id =  crud  When of get id row value table executeScriptTemplate all RandomUtils manager should_trigger_for_update getString nextLong assertThat rows execute SimpleEntity/insert_single_row.cql ImmutableMap getValue hasSize  Then Long buildDateKey preUpdate_value isEqualTo entity ,achilles,1
primFloatParamShouldBeParsedToFloat thenReturn context 3.14 create verify invoke when param1 mockController getParameter primFloatParam ,ninja,0
getClass testAuthLocalJceks zkAuths CredentialProviderFactory zkAuthInfo conf delete getBytes assertArrayEquals localJceksFile getZKAuthInfos assertTrue get a_scheme set getScheme getAuth CommonConfigurationKeys getAbsolutePath localJceksUri createTempFile assertEquals deleted size populateLocalJceksTestFile .testAuthLocalJceks- .localjceks getSimpleName SecurityUtil localjceks://file/ a_password File ,hadoop,0
testBundleJobsGet _testGetJobInfoForUser addRecordToBundleJobTable _testGetJobsForAppName _testGetJobsForStatus Job _testGetJobsForGroup _testGetJobsForUserAndStatus ,oozie,1
setDesiredStackVersion fsm addMapreduceService Configuration hbase_master_hosts assertFalse h1 h2 h3 h4 getCluster addHdfsService mapHostToCluster centos5 mapred_tt_hosts testGetClusterHostInfo assertTrue get persist injector getHost info addCluster addHbaseService getClusterHostInfo address getCanonicalHostName getHostsForCluster assertEquals addHost c1 getLocalHost StageUtils setOsType contains slave_hosts hostList size all_hosts hbase_rs_hosts getInstance HDP-0.1 ambari_db_rca_url InetAddress ,ambari,1
"%d percentile latency with 5 second interval for stat foo Foo%dthPercentileLatency  Insert the values testMutableQuantilesRollover String System Number of ops for stat with 5s interval sleep times Ops mb  Verify that the window reset, check it has the values we pushed in  Verify the metrics were added the right number of times nanoTime verify  roll over newQuantiles info add registry stat quants test d addGauge  Use a 5s rollover period start format j eq n Latency Thread quantiles q percentile MutableQuantiles anyLong mockMetricsRecordBuilder name FooNumOps  Push values for three intervals snapshot desc ",hadoop,0
VV getKey dKFound set Configuration regular Key not found conf assertEquals deprecated Key not found k addDeprecation entry getValue kFound nKFound assertTrue v V get equals testIteratorWithDeprecatedKeys nK_iterator dK_iterator new Key not found ,hadoop,0
toRegexForFixedDate set getTime Calendar fnp assertEquals /toto/foo-2003/05/20-(\d+).txt foo-%d{yyyy.MM.dd}-%i.txt cal regex foo-2003.05.20-(\d+).txt context asRegexByDate getInstance \toto\foo-%d{yyyy\MM\dd}-%i.txt ,logback,0
testDoFilterAuthenticationWithInvalidToken _testDoFilterAuthentication ,hadoop,0
date %msg - [%thread]%n  Given simple crud ConsistencyLevel prepareLogLevel  When executionInfo id getAsyncWithStats info logAsserter isNotNull actual RandomUtils withResultSetAsyncListener should_find_by_id_async assertThat SimpleEntity/insert_single_row.cql ImmutableMap assertContains _1 _2  Then Long buildDateKey LOGGER rs scriptExecutor ASYNC_LOGGER_STRING containsExactly isUp of findById get await latch countDown table executeScriptTemplate getQueriedHost manager nextLong getConsistencyList CALLED isTrue tuple2 Called - [achilles-default-executor ,achilles,1
encode verifyGS1EncodedData testEncodeGS1WithStringTypeHint 100001%11171218 EncodeHintType qrCode hints Encoder true ErrorCorrectionLevel put ,zxing,0
server  make a really slow call. Sleep sleeps for 1000ms before getClient2 newEmptyRequest SLEEP_DURATION  make sure we never called into Log slow RPC routine.  Ensure RPC metrics are updated sleep getRpcSlowCalls client ping2  make 10 K fast calls after setLogSlowRPC isGreaterThan assertThat  disable slow RPC  logging newSleepRequest getProcessingSampleCount rpcMetrics testEnsureNoLogIfDisabled isEqualTo getRpcMetrics ,hadoop,0
http://localhost/foo bar localhost /foo bar toURL toUri assertEquals /foo+bar  URI encodes the path  URI#getPath decodes the path  URI#toString returns an encoded path testReservedCharacters /foo%20bar getPath  URI#getPath decodes the path part (and URL#getPath does not decode) http toString /foo;bar getRawPath /foo%3Fbar /foo?bar  Reserved chars are not encoded ,hadoop,0
conn setRequestMethod IS_SECURITY_ENABLED assertFalse put /v0/admin/* assertTrue get json content-type Collections runTest JsonTags RestConstants openConnection containsKey false MockDagEngineService HttpServletResponse assertEquals parse params getInputStream url PUT JSONValue call /v0/job/* getHeaderField getResponseCode GET true reset createURL testSafeMode startsWith ,oozie,1
"<execution>LIFO</execution> </controls> <datasets>  checkCoordJobs <coordinator-app name=""NAME"" frequency=""10"" start=""2009-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""  xmlns=""uri:oozie:coordinator:0.2""> <controls> <timeout>10</timeout> <concurrency>2</concurrency>  conf </input-events>  appPath testSubmitFixedValues substring sc </property></configuration> </workflow> </action> </coordinator-app> writeToFile appXml <property> <name>inputB</name> <value>${coord:dataOut('LOCAL_A')}</value>  file:// getTestCaseDir UNIT_TESTING <dataset name=""local_a"" frequency=""120"" initial-instance=""2009-02-01T01:00Z""  <output-events> <data-out name=""LOCAL_A"" dataset=""local_a"">  timezone=""UTC""> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset>  coordinator.xml set <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  length assertEquals <dataset name=""a"" frequency=""60"" initial-instance=""2009-02-01T01:00Z""  call OozieClient jobId getTestUser </datasets> <input-events>  <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>  -C <data-in name=""A"" dataset=""a""> <instance>${coord:latest(0)}</instance> </data-in>   File ",oozie,1
cluster initBuffer  write to file  verify that full blocks are sane mid conf fs System /simpleFlush.dat createFile simulatedStorage Exception : Created file simpleFlush.dat Wrote and Flushed first part of file. hflush Written second part of file  create a new file. close write checkFile Closed file. Read 2 printStackTrace e Throwable : Wrote and Flushed second part of file.  write the remainder of the file getFileSystem fileContents stm AppendTestUtil checkFullFile  verify that entire file is good Throwable :  build SimulatedFSDataset file1 testSimpleFlush shutdown setBoolean ,hadoop,1
mainThread currentThread  how could it not call getBlockCommits()?) blockCommits start AFTER run interrupted  will reach t.join(). Thread  but I don't see a good alternative here) processCommit t assertTrue limiter interrupt await latch countDown join EMPTY_NODE  using a latch to avoid having to rely on timing getBlockCommits ,jackrabbit,1
 create the framework without deleting the default tests. adapter framework runTests setAdapter defaultTests ,httpcore,0
"src  src exists, and target is a non-empty directory: srcFile  src exists, and target does not exist: replaceFile delete target testReplaceFile  check up the post-condition: nothing is deleted: assertTrue tmp targetFile mkdirs exists setupDirs  src exists and target is a regular file: createNewFile FileUtil obstacle isDirectory ",hadoop,0
lookup Assert assertTrue assertNotNull exact h h1 h2 * matcher testMatchExact register ,httpcore,0
" rather than do this by doing unregister checks, a new service is created assertListenerState l0  not the final one l3 listener  stop the service  listeners are all updated  create and register the listeners setFailingState  listeners  has incremented by one testListenerChain init assertListenerEventCount start unregister Service logListener assertServiceStateInited  can all be unregistered in any order  this service is initialized  this is the listener that is not expected to have been invoked stop service  create and init a service. assertServiceStateStarted register ",hadoop,0
"getName oozie.service.ProxyUserService.proxyuser.foo.groups foo user.name conf testValidateGroup asList System Assert StringUtils assertNotNull get join validate localhost init set oozie.service.ProxyUserService.proxyuser.foo.hosts getProperty getConf destroy * services , Services getGroup proxyUser Arrays ",oozie,1
AA BB a A b setVariables c resolveVariable setVariable assertEquals getVariable put fail testVars vars support getContext evaluator ,oozie,1
bulkInsertCmd createWorkflow addNode auth getAppPath PREP conf getId testToken WorkflowInstance actionGetCmd setInsertList assertNotNull get testApp <workflow-app/> end workflow.xml WorkflowJob app add getStatusStr set  check for expected status after running bulkUpdateJPA insertList wfGetCmd testInserts assertEquals execute appUri OozieClient 1 Services 2 getTestUser WorkflowAction toString createWorkflowAction action1  insert one workflow job and two actions job action2 jpaService ,oozie,1
Integer fail Assert testInvalidAppendCharArrayAsAscii tmp buffer IndexOutOfBoundsException should have been thrown append ,httpcore,0
" tt  Wait for consumers to wake up, then consume pt  Create putters and takers conf put swapQueue sleep schedulerClass totalCallsCreated get interrupt totalCallsConsumed queueClass consumers join  Stop the producers add manager start threads assertEquals producers Thread p t stop size  Ensure no calls were dropped testSwapUnderContention ",hadoop,0
fullyDeleteContents ret validateAndSetWritablePermissions testFailFullyDeleteContentsGrantPermissions setupDirsAndNonWritablePermissions del FileUtil  this time the directories with revoked permissions *should* be deleted: ,hadoop,0
a b testForkedContext addNode def f start j assertEquals WorkflowInstance getStatus asList wf 1 <worklfow-app/> end Arrays job ,oozie,1
addHeader keepAlive assertFalse Connection setProtocolVersion Assert response keep--alive context  Use HTTP 1.0 reuseStrategy testBrokenConnectionDirective1 OK Content-Length HttpVersion 10 ,httpcore,0
kills addNode def enters WorkflowInstance getStatus three two asList wf testSimpleFork exits assertTrue four get end fails f one start j assertEquals 1 size <worklfow-app/> Arrays job ,oozie,1
server hcatalog.mydb.mytable getJMSConnectionInfo printStackTrace e hcatService hcat.server.com:5080 jmsService assertEquals services hcat://hcat.server.com:8020 fail getMessageReceiver receiver1 connInfo assertNotNull get topic registerForNotification testUnRegisterTopic Exception encountered :  unregisterFromNotification ,oozie,1
testPermissionMask createShortPermission -rwxrwxrwx r-------- ae 400 777 toString assertEquals rwxrwxrwx -r-------- ,oozie,1
intMethod  but different method names have different hash code hash2 ProtocolSignature hash1 strMethod assertFalse  larger number of parameter types have different hash code echo intEchoHash1 assertEquals getMethod intEchoHash testHashCode  make sure that overriding methods have different hashcodes  from different declaring classes have the same hash code echo_alias stringEchoHash intEchoHashAlias intEchoHash2  types have different hash codes  make sure that methods order does not matter for method array hash code getFingerprint stringEchoHash1 ,hadoop,0
b toBytes StorageUnit is getDefault assertThat testByteConversions getLongName bytes getShortName fromBytes toString getSuffixChar ,hadoop,0
getCurrentDateafterIncrementingInMonths getId run DateUtils getStatus addRecordToCoordActionTable testCoordStatusTransitServiceForTimeout parseDateOozieTZ coordGetCmd coordJob sleep get CoordinatorAction end currentDatePlusMonth start assertEquals XDataTestCase execute addRecordToCoordJobTable CoordinatorJob Services runnable coord-action-get.xml job jpaService ,oozie,1
Assert assertTrue exists jar  picking a class that is for sure in a JAR in the classpath getJar JarFinder testJar ,hadoop,0
"fs.defaultFS myFile getLocalizedMessage val2 assertFalse val1 conf run fs  Second, create a file in that directory. System assertTrue FileSystem  10 minute testExistingFileTrash mkdir writeFile TEST_DIR set FS_TRASH_INTERVAL_KEY e test/mkdirs/myExistingFile setClass  disabled -rm setConf  Second  rm a file which parent path is the same as above  First rm a file setLong Exception raised from Trash.run  mySubFile shell getLocal  First create a new directory with mkdirs isEnabled args1 test/mkdirs args2 toString fs.file.impl getUri myPath ",hadoop,0
"cursor copyQuotedContent strbuf2 assertFalse TokenParser createBuffer Assert copyContent assertTrue getPos  some stuff  updatePos skipWhiteSpace strbuf1 atEnd length raw assertEquals    raw: "" some stuff "" parser toString INIT_BITSET charAt testBasicTokenParsing ",httpcore,0
actionNum 2009-12-15T01:00Z getId CoordUtils assertEquals getCoordActionsFromDates addRecordToCoordActionTable addRecordToCoordJobTable CoordinatorJob jobId coordActions size get  test retrieval of action corresponding to single date (date1) CoordinatorAction action1 testGetCoordActionsFromDate job coord-rerun-action1.xml ,oozie,1
assertCorrectImage2string testDecodeRow2string13 (01)90012345678908(3922)795 13.png ,zxing,0
cluster NUM_OF_DATANODES DEFAULT_BANDWIDTH conf newBandwidth fs  datanodes should remain as it was. waitActive sleep getBalancerBandwidth get  Ensure value from the configuration is reflected in the datanodes. setBalancerBandwidth  Give it a few seconds to propogate new the value to the datanodes. DFSConfigKeys getDataNodes testBalancerBandwidth  12M bps assertEquals getFileSystem datanodes Thread setLong  Create and start cluster   Set bandwidthPerSec to a low value of 1M bps.  build numDataNodes shutdown ,hadoop,1
"JMSTopicService bab addRecordToBundleActionTable =bundle cab =coord, addRecordToWfActionTable getId WorkflowInstance getTopic addRecordToCoordActionTable setupServicesForTopic coord coord-action-for-action-input-check.xml addRecordToWfJobTable get testTopicAsFixedString CoordinatorAction wab cjb bjb WorkflowJob Job bundle init set getBundleActionId printStackTrace getConf workflow e  =workflow, addRecordToBundleJobTable getMessage destroy jmsTopicService assertEquals services addRecordToCoordJobTable fail getValue Services 1 CoordinatorJob WorkflowAction wfj ",oozie,1
deleteList Workflow Action A2 should have been deleted addRecordToWfActionTable getId WorkflowInstance actionC1 testDeleteWorkflows actionC2 actionA1 Workflow Action A1 should have been deleted actionA2 jobB addRecordToWfJobTable jobA getErrorCode assertNotNull jobC get WorkflowJob add Workflow Action C1 should have been deleted Workflow Job A should have been deleted assertEquals actionB1 execute Workflow Action C2 should have been deleted actionB2 1 Services fail 2 Workflow Action B1 should have been deleted Workflow Action B2 should have been deleted WorkflowAction Workflow Job C should have been deleted ErrorCode je jpaService Workflow Job B should have been deleted ,oozie,1
numComponentsCreated  the other appenders should be in the tracker assertFalse timeout  the first appender should have been removed assertTrue find assertNotNull now get appenderTracker removeStaleComponents key add a allKeys  cleaning only happens in removeStaleComponents. The first appender should timeout assertEquals isStarted - setTimeout assertNull size appenderList getOrCreate trackerShouldHonorTimeoutParameter ,logback,0
isStatic getName LOG getDeclaredMethod getParameterTypes isPrivate getMethod error assertThat m HarFileSystem MUST not implement  HarFileSystem MUST implement  getDeclaredMethods  methods were not overridden correctly - see log withFailMessage isLessThanOrEqualTo getModifiers isFinal testInheritedMethodsImplemented Modifier errors ,hadoop,0
 cluster locs racks conf waitForReplication getBlockManager dir createFile FileSystem getPath getFileStatus exclude getFileBlockLocations getWorkingDirectory workingDir dfs.hosts.exclude testNodeDecomissionRespectsRackPolicy getFileSystem getNameNode numDataNodes mkdirs Long name  Configure an excludes file  Create a file with one block getFirstBlock waitForDecommission shutdown  otherwise the rack policy is violated. ns     * Test that rack policy is still respected when blocks are replicated    * due to node decommissioning.     /rack2 getNames /rack1 fs getDatanodeManager assertTrue refreshNodes excludeFile writeFile build/test/data/temp/decommission DFSTestUtil b set getConf filePath toUri REPLICATION_FACTOR /testFile build getLocal localFileSys  Two blocks and four racks  Check the block still has sufficient # replicas across racks getNamesystem ,hadoop,1
add addColumn createTable toBytes  Test that table is enabled HConstants assertEquals TEST_UTIL ht put Bytes  Test that table is disabled qualifier get testDisableAndEnableTable enableTable row ok value table disableTable ,hadoop,1
addRecordToWfActionTable coordActionGetCmd getId getNumDaysToNotBePurged WorkflowInstance getStatus addRecordToCoordActionTable coordJob wfJob addRecordToWfJobTable assertNotNull get Workflow Job should not have been purged CoordinatorAction WorkflowJob wfAction wfJobGetCmd wfActionGetCmd Coordinator Action should not have been purged assertEquals getLastModifiedTime execute addRecordToCoordJobTable Coordinator Job should not have been purged call Services CoordinatorJob 1 coordJobGetCmd fail coord-action-get.xml WorkflowAction coordAction SUCCEEDED jpaService testPurgeCoordWithWFChild1 Workflow Action should not have been purged ,oozie,1
fillInJarFile assertFalse rulesMap delete url tc asURL makeRandomJarFile buzz.xml jarFile assertTrue jarEntry doConfigure context setContext  deleting an open file fails lbcore105 exists ,logback,0
date Set scriptExecutor tableNameFor session  Given update_dsl_with_schema_name update Eq tableName should_dsl_update_with_schema_name  When of from where id row value table SELECT value FROM  SimpleEntity/create_simple_mirror_table.cql executeScriptTemplate RandomUtils manager one  WHERE id =  getString nextLong assertThat execute ImmutableMap SimpleEntity/insert_single_row.cql keyspaceFor  Then Long buildDateKey new value dsl isEqualTo DEFAULT_CASSANDRA_EMBEDDED_KEYSPACE_NAME ,achilles,1
args dependencyResolutionWithCustomClassLoader classLoader org.springframework spring-jdbc createDependency 3.2.4.RELEASE assertEquals customClassLoader grab put getURLs ,spring-boot,1
ROW_1 ROW_2 testMultiCellGetPutXML addRow put TABLE path Bytes checkValueXML marshal yield get client VALUE_1 VALUE_3 marshaller VALUE_2 getCode  make sure the fake row was not actually created VALUE_4 addCell toBytes assertEquals cellSetModel  check that all of the values were created / Thread deleteRow rowModel COLUMN_2 COLUMN_1 response /fakerow  deliberate nonexistent row toString writer MIMETYPE_XML ,hadoop,1
...X. ...XX ..X.. XXXXX ....X .XX..X.. ..XX. ..XXX .X... Lo. Test 123. testHighLevelEncodeString .XX.X XXX.. X.... XXXX. XX.X XX.X XX.X XXX. XXX.. XX..X Lo...x testHighLevelEncode A. b. ABCdEFG ..... ...XX XXX.. XX..X ..... X.X.X ..... X.X.. ..... X.X.. ...X. ...XX ..X.. ..... X.X.. XXXX. XX.X 09  UAG    ^160MEUCIQC0sYS/HpKxnBELR1uB85R20OoqqwFGa0q2uEi Lorem ipsum.  'L'  L/L   'o'   P/S   '. '  U/S   'T'   'e'   's'   't'    D/L   ' '  '1'  '2'  '3'  '.'  'A'  P/S   '. ' L/L    b    D/L    '.'  Uses Binary/Shift rather than Lower/Shift to save two bits. Ygh6utAIgLl1aBVM4EOTQtMQQYH9M2Z3Dp4qnA/fwWuQ+M8L3V8U=  necessary to keep the bitcount so low. ...X. ..... ...XX XXX.. ...XX XXXX. XX.X  'L'  L/L   'o'   'r'   'e'   'm'   ' '   'i'   'p'   's'   'u'   'm'   D/L   '.'  'A'   'B'   'C'   B/S    =1    'd'     'E'   'F'   'G' .XX.X XXX.. X.... ..... ...XX XXX.. X.X.X ..XX. X.X.. X.X.X  XXXX. ...X ..XX .X.. .X.X XX.X  P/S   '. '  L/L   'x'   P/S   ':'   P/S   '/'   P/S   '/'   'a'   'b'   'c'   P/S   '/'   D/L   '.'  'L'  L/L   'o'   D/L   '.'  '.'  '.'  U/L  L/L   'x' .XX.X XXX.. X.... X..XX ..XX. .XXX. ....X .X.X. X...X X.X.. X.XX. .XXX. XXXX. XX.X . x://abc/.  Found on an airline boarding pass.  Several stretches of Binary shift are ,zxing,0
jobConf getName reader authToken getErrorCode getTestCaseDir /workflow.xml get file:// workflow.xml oozie.service.ActionService.executor.ext.classes parseDef app init set destroy wf-schema-action-name-too-long.xml assertEquals services testActionNameLength OozieClient fail IOUtils getTestUser ex copyCharStream setSystemProperty getResourceAsReader writer wps ErrorCode File ,oozie,1
 initial insert getExpectedDuration  check updated + original fields getActualEnd getTime testInsertUpdate getEventStatus EventStatus getExpectedStart setInsertList cal bean1 assertTrue assertNotNull expEnd bean2 get _createSLASummaryBean newDate getActualDuration isStartProcessed getActualStart setTime add actStart RUNNING getJobId _createSLACalcBean isEndProcessed workflow-1 Calendar assertEquals writeCmd expStart list readCmd2 execute readCmd1 scBean  update existing record getExpectedEnd Services setUpdateList jpaService wfId sdBean ,oozie,1
request getName Authentication required sendError when asList getInitParameterNames doAnswer Assert doFilter verify management.operation.return http://foo:8080/bar getRequestURL init chain AuthenticationFilter thenReturn WWW-Authenticate destroy HttpServletResponse any testDoFilterNotAuthenticated filter fail getMockedServletContextWithStringSigner getInitParameter answer Mockito response elements true mock containsHeader Arrays config ,hadoop,0
_test isMainSuccessful actionDir hasOutputData assertFalse runningJob isMainDone getFileSystem testEmpty fs hasIdSwap getIdSwapPath isSuccessful assertTrue LauncherMapper getErrorPath exists getOutputDataPath evaluate waitFor getFsTestCaseDir isComplete ,oozie,1
EXEC_ORDER callable2 callable3 callable1 QueueUniquenessWithSameKeyInOneComposite queueSerial queueservice asList Services assertTrue get testQueueUniquenessWithSameKeyInOneComposite Arrays evaluate waitFor ,oozie,1
"date CoordELFunctions coord-action-create coord-action-start utcDate 2009 evalAndWrap expr3_eval coord-action-create-inst expr3 expr2 expr1 2009-09-08T23:59Z ' ,  init ${coord:formatTime(""2009-09-08T23:59Z"", ""yyyy"")} ${coord:formatTime(""2009-09-08T23:59Z"", ""yyyyMMdd_HHmmss"")} 20090908_235900 ${coord:formatTime(' yyyy)} coord-job-submit-instances setVariable assertEquals testFormatTime ${coord:formatTime(date, ""yyyy"")} coord-job-submit-data eval ",oozie,1
"cluster log conf checkResult current nameNodeDirs createEmptyDirs numDirs StartupOption  This test requires that ""current"" directory not change after        * the upgrade. Actually it is ok for those contents to change.        * For now disabling block verification so that the contents are         * not changed.         startupOption manageDataDfsDirs DFSConfigKeys Finalize with existing previous dir previous format testFinalize initializeStorageStateConf setInt getStrings UpgradeUtilities build createNameNodeStorageDirs dataNodeDirs manageNameDfsDirs createDataNodeStorageDirs initialize Finalize without existing previous dir finalizeCluster shutdown ",hadoop,1
 2009-05-31T00:00Z CoordELFunctions 2009-09-10T23:59Z 2009-05-30T00:00Z 2009-10-30T08:00Z 2009-03-06T10:00Z 2009-01-01T08:01Z 2009-01-01T7:00Z 2009-04-01T07:00Z 2009-03-07T09:00Z TimeUnit setEndOfDuration  Changed  Case 8 init  Test with EOM 2009-03-08T07:00Z setInitInstance ${coord:current(1)}  Case 1  Case 2  Case 3  Case 4  EndofDay testing  Case 5  Case 6  Case 7 2009-01-01T08:00Z 2009-03-11T07:00Z ${coord:current(-3)} evaluate 2009-10-30T08:00Z 2009-10-31T08:00Z 2009-11-01T08:00Z 2009-11-02T09:00Z 2009-11-03T09:00Z setName testCurrent coord-action-create test1 evalAndWrap  Winter DST Transition 2009-02-01T00:00Z setTimeZone 2009-05-27T00:00Z 2009-09-08T23:59Z 2009-02-02T08:00Z 2009-01-02T09:00Z setNominalTime 2009-03-06T10:00Z 2009-03-07T10:00Z 2009-03-08T09:00Z 2009-03-09T09:00Z 2009-03-10T09:00Z assertEquals ${coord:current(0)} 2009-01-01T18:00Z ${coord:current(-2)} ${coord:current(-1)} ${coord:current(0)} ${coord:current(1)} ${coord:current(2)} 2009-03-07T07:00Z 2009-03-01T08:00Z 2009-01-02T00:00Z 2009-03-10T07:00Z 2009-05-29T23:00Z 2009-05-30T23:00Z 2009-05-28T23:00Z 2009-05-26T23:00Z getTimeZone UTC 2009-03-10T08:01Z DateUtils parseDateOozieTZ setFrequency  Spring DST transition ds ${coord:current(0)} ${coord:current(1)} ${coord:current(-1)} ${coord:current(-3)} 2009-05-30T12:00Z  2009-11-01T08:00Z 2009-01-01T07:01Z 2009-03-02T08:00Z 2009-03-08T08:00Z appInst setTimeUnit eval 2009-01-01T00:00Z SYNC 2009-05-30T00:30Z 2009-05-30T01:00Z 2009-05-30T00:00Z 2009-05-29T23:00Z 2009-03-08T10:45Z ${coord:current(-1)} 2009-06-04T00:00Z 2009-05-30T00:00Z  2009-05-21T00:00Z 2009-05-07T00:00Z 2009-05-29T00:00Z 2009-05-28T00:00Z configureEvaluator 2009-06-01T07:00Z expr 2009-02-01T08:00Z 2009-03-09T07:00Z 2009-05-30T00:45Z 2009-03-07T08:00Z 2009-01-31T08:00Z setType setActualTime America/Los_Angeles 2009-03-12T07:00Z 2009-03-01T00:00Z 2009-01-02T08:00Z  expr)); 2009-01-08T00:00Z ,oozie,1
request conn inStream getEndpointDetails getContent User-Agent getMethod when getBytes content receiveRequestHeader receiveRequestEntity bind Assert assertTrue assertNotNull getPath getRequestCount StandardCharsets thenReturn assertEquals Method getEntity getContentLength getInputStream / assertNull Mockito name socket containsHeader testReadRequestEntityWithContentLength entity POST / HTTP/1.1 User-Agent: test Content-Length: 3  123 ,httpcore,0
e succeedsOnceThenFailsReturningString should not have succeeded twice succeedsOnceThenFailsReturningStringIdempotent impl2 getMessage  IOException and this method is not idempotent assertEquals impl1 RetryProxy fail  IOException and this method is idempotent. testFailoverOnNetworkExceptionIdempotentOperation TypeOfExceptionToFailWith RetryPolicies unreliable create failoverOnNetworkException newFlipFlopProxyProvider ,hadoop,0
"drwho testDefaultBlockedMachineList conf  test without setting a default blocked MachineList drwho@EXAMPLE.COM  set a  default blocked MachineList and a blocked MachineList for TestProtocol  TestProtocol1 can be accessed from ""1.2.3.4"" because it uses default block list getByName  because ""10.222.0.0"" is in default block list authorize 10.222.0.0 UserGroupInformation createUserForTesting IP_RANGE set  TestProtocol can be accessed from ""10.222.0.0"" because it blocks only ""1.2.3.4"" 1.2.3.4 security.service.authorization.default.hosts.blocked refresh BLOCKED_HOST_CONFIG group2 group1 serviceAuthorizationManager fail  TestProtocol cannot be accessed from  ""1.2.3.4"" InetAddress ",hadoop,0
" CASE 4: Success case, where only one instance is configured, but expression has a "","" testBasicSubmitWithMultipleInstancesOutputEvent reader conf getStatus appPath No child element is expected at this point getJob sc per data-out instance Not expected to fail here getErrorCode assertTrue file:// getTestCaseDir  CASE 1: Failure case i.e. multiple data-out instances UNIT_TESTING getPath Job coordinator.xml set e coord-multiple-output-instance2.xml coord-multiple-output-instance3.xml getMessage assertEquals call OozieClient fail IOUtils contains is empty getTestUser coord-multiple-output-instance1.xml copyCharStream coord-multiple-output-instance4.xml getResourceAsReader  CASE 3: Multiple <instance> tags within data-out should fail coordinator schema validation - different error than above is expected Expected to catch errors due to incorrectly specified output data set instances  CASE 2: Data-out instance tag is empty. Check works for whitespace in the tag too writer ErrorCode File ",oozie,1
BB kills A B addNode def getTransientVar enters WorkflowInstance getStatus asList wf exits testNodeContext end fails AA a b one setVar start assertEquals ta tb 1 size <worklfow-app/> getVar Arrays job setTransientVar ,oozie,1
expectedNumSectorsRead getStorageBytesWritten getStorageBytesRead String fWriter parsingProcDisksFile diskSectorSize tempFile write close deleteOnExit numSectorsReadsdf format numSectorsReadsda assertEquals expectedNumSectorsWritten numSectorsReadsdc numSectorsReadsde  use non-default sector size DISKSINFO_FORMAT FakeLinuxResourceCalculatorPlugin plugin FAKE_DISKSFILE numSectorsWrittensda numSectorsWrittensdc numSectorsWrittensdf numSectorsWrittensde ,hadoop,0
ret  delete tmpDir properly. assertFalse  dangling symlink to file link del assertEquals list tmpDir Assert assertTrue tmp  should delete 'y' properly.  dangling symlink to directory exists LINK setupDirs testFullyDeleteDanglingSymlinks FileUtil fullyDelete  to make y as a dangling link to file tmp/x linkDir ,hadoop,0
cluster NameNode  to include a port number. fs2 HATestUtil conf testDfsClientFailover withPort fs createFile hdfs:// transitionToActive assertTrue getLen getFileStatus getPath close DFSTestUtil getConf toUri assertEquals getFileSystem configureFailoverFs shutdownNameNode / FILE_LENGTH_TO_VERIFY TEST_FILE getLogicalHostname exists : ,hadoop,1
actionNum CoordinatorJob testCoordActionGet coord-action-get.xml _testGetReadyActions CoordinatorAction getId job cleanUpDBTables addRecordToCoordActionTable addRecordToCoordJobTable ,oozie,1
No nested cause in assertion Expected contains e testAssertExceptionContainsWrongText (actual) assertExceptionContains toString E_UNEXPECTED_EXCEPTION getCause ,hadoop,0
"getChecksumFile checksum deleted delete getBytes testing you  copying the wrong checksum file assertTrue TEST_ROOT_DIR fout checksum exists create  now setting verify false, the read should succeed copy write close errorRead  the chunk size, 2x chunk size, and +/-1 around these. read getConf testPath11 testing setVerifyChecksum str testVerifyChecksum localFs testPath error reading readFile equals exists toString FileUtil ",hadoop,0
"getName be the same encryptionKey KeyProviderCryptoExtension assertArrayEquals ekv decryptEncryptedKey assertNotNull getEncryptedKeyIv  Generate 1 new EEK @v2 add to the list. add generateEncryptedKey getEncryptionKeyName ekvsOrig  Roll the EK again Re-encrypted EEK should have same material kv1 getVersionName Expected encrypted key material  Generate 1 new EEK @v1 add to the list. ENCRYPTION_KEY_NAME  Verify each ekv getMaterial testReencryptEncryptedKeys size  Roll the EK getEncryptionKeyVersionName Arrays  Reencrypt ekvs getEncryptedKeyVersion assertFalse reencryptEncryptedKeys ekvs rollNewVersion assertTrue get Version name should be EEK  Decrypt the new EEK into an EK and check it  leave a deep copy of the original, for verification purpose. assertEquals same kv. kpExt kv  Decrypt it again and it should be the same origKv  Generate 2 new EEKs @v0 and add to the list Encrypted key material should not equal encryption key material Re-encrypted EEK should have different material  Verify decrypting the new EEK and orig EEK gives the same material. orig equals Returned EEK and original EEK should both decrypt to the  Encryption key name should be  Length of encryption key material and EEK material should  ",hadoop,0
Args Number notNegative testNotNegativeIntFail1 ,httpcore,0
"getJobTrackerUri rootArchive rootSo soFile.so.1  with leading and trailing spaces createContext setupActionConf filesInCache context getPath create jar rootJar getCacheFiles       <main-class>CLASS</main-class>       <job-tracker> eActionXml       <file> ae </file>  parseXml </job-tracker> archive getFileSystem ,   , archive  </name-node> setLibFilesArchives  found in classpath soFile.so rootSoFile.so  not found in cache jobConf archive.tar       <archive> <java> assertFalse getAppPath appPath createBaseHadoopConf actionXml rootSo1 rootJar.jar file found so1 DistributedCache assertTrue root so filesInClasspath close getNameNodeUri getFileClassPaths rootArchive.tar c </java> XmlUtils rootSoFile.so.1  </archive>  toUri testCommaSeparatedFilesAndArchives archivesInCache file  getSymlink  not found in classpath p getCacheArchives ,  equals rootFile toString       <name-node> getFsTestCaseDir jar.jar ",oozie,1
testReadCorrectlyRestrictedWithSecurity openForRead testFilePathFadis r realGroup testFilePathRaf openForRandomRead testFilePathIs SecureIOUtils openFSDataInputStream realOwner close ,hadoop,0
 verifyFsckHealth fileName filePath dfsClientReadFileFromPosition dfsClientReadFile  corrupted replicas to the name node. testCorruptAllOfThreeReplicas  LocatedBlock should not have the block marked as corrupted. expectedReplicasReturned  ask dfs client to read the file verifyFirstBlockCorrupted createAFileWithCorruptedBlockReplicas /tmp/testClientReportBadBlock/testCorruptAllReplicas  create a file verifyCorruptedBlockCount repl testFsckListCorruptFilesBlocks corruptBlockNumber ,hadoop,1
ACTION[action] asList JOB[-] DagXLogInfoService assertTrue testDagCommand get setParameter action waitFor ACTION[-] a resetLogInfoAction b c EXECUTED d XLog resetLogInfoWorkflow e f createPrefix clear JOB[job] assertEquals command call fail contains ex size job Arrays evaluate ,oozie,1
addTestService assertInState STATE services testServiceStopFromNotInited stop ServiceManager service NUM_OF_SERVICES toArray  Add services getServices serviceManager ,hadoop,0
"mockds30 checkMetrics mockds31 gsink31  publish the metrics .sink.gsink30.context save  Setup test for GangliaSink31  We manually publish metrics by MeticsSystem#publishMetricsNow here. gsink30 GangliaMetricsTestHelper  filter out only ""test""  check GanfliaSink30 data getTestFilename  check GanfliaSink31 data testGangliaMetrics2 .sink.gsink31.context s1 s1rec gsink31 desc getCapturedSend cb setDatagramSocket add init set expectedMetrics incr ms start gsink30 desc s1 desc  register the sinks testNamePrefix stop *.period  Setup test for GangliaSink30 hadoop-metrics2- TestMetricsConfig expectedCountFromGanglia30 expectedCountFromGanglia31 publishMetricsNow subset register ",hadoop,0
"A a set XmlUtils conf cannot be null parseXml getMessage assertEquals conf <root xmlns=""uri:oozie:workflow:0.4""></root> testVerifyParametersNull fail ex size get ParameterVerifier verifyParameters ",oozie,1
ftp://google.com/fake google.com http://google.com/foobar google.com:443/ ParsedResultType doTestResult gopher://google.com/obsolete testURI http://google.com:443/ http://google.com:443/foobar google.com:443/foobar google.com:443 http://google.com:443 HTTP://google.com https://google.com http://google.com https://google.com:443/foobar ,zxing,0
"init res .dataout.ABC.unresolved 'region=us,datastamp=20120230' hcat://hcat.server.com:5080/mydb/clicks/datastamp=20120230;region=us CoordELFunctions ${coord:dataOutPartitions('ABC')} setVariable 'datastamp=20120230,region=us' coord-action-start eval evalAndWrap assertTrue .dataout.ABC equals testDataOutPartitions expr Boolean ",oozie,1
coordJob10 testCount addRecordToBundleActionTable getNumDaysToNotBePurged 2009-07-01T01:00Z coordJob14 coordJob13 coordJob12 coordJob11 coord10 coord11 coord12 coord13 bundleJob assertNotNull 2009-11-01T01:00Z Job coord1 2009-03-01T01:00Z coord14 coord2 coord3 coord4 coord5 2009-04-01T01:00Z coord6 coord7 coord8 coord9 coordJob8 coordJob9 execute coordJob2 CoordinatorJob coordJob3 coordJob1 coordJob6 coordJob7 coordJob4 coordJob5 2009-10-01T01:00Z 2009-05-01T01:00Z TestPurgeXCommand getId 2009-01-01T01:00Z 2009-08-01T01:00Z get 2008-11-01T01:00Z getAppName setAppName addRecordToBundleJobTable 2009-02-01T01:00Z 2009-06-01T01:00Z assertEquals setLastModifiedTime getLastModifiedTime bundleJobId addRecordToCoordJobTable Services 2008-12-01T01:00Z 2009-12-01T01:00Z days jpaService 2009-09-01T01:00Z ,oozie,1
"testWithRetriableAndRetryDisabled getDefaultRetryPolicy  defaultRetryPolicyEnabled = false conf is assertThat Test.No.Such.Key 10000,6 shouldRetry action RetryUtils RetryPolicy policy Dummy exception ",hadoop,0
"init res hcat://hcat.server.com:5080/mydb/clicks/datastamp=10;region=us hcat://hcat.server.com:5080/mydb/clicks/datastamp=20;region=us, CoordELFunctions hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us, hcat://hcat.server.com:5080/mydb/clicks/datastamp=13;region=us, .datain.ABC.unresolved setVariable coord-action-start ${coord:dataInPartitionMax('ABC','datastamp')} testDataInPartitionMax eval evalAndWrap assertTrue equals .datain.ABC expr Boolean 20 ",oozie,1
doTestTableCreateDrop doTestTableMutations doTestTableTimestampsAndColumns doTestTableScanners testAll  Run all tests ,hadoop,1
os Read timed out expected timeout e LOG getMessage TEST_TIMEOUT assertEquals /file fs fail IOUtils cleanup testTwoStepWriteReadTimeout startSingleTemporaryRedirectResponseThread create  must close stream to force reading the HTTP response close ,hadoop,1
"100110110110101001010101101001101101011010010101101101001010101011001101101010110010 010011010010101101101100101011010100100101001011010110100101010011011010110100101011 011011001010010110110100000 010110101011001011010100100101001010011011010101010010010010101101100101010100100100 101001010010110110100000 101010100110110101001001001011010100110101010010010010101101001101010100100100101010 001001010110010110101010010010010101001101101010101001001001011010100101101010010010 001010100101001001010110110010101001010010010101010011011010010100100101101010011010 100101010110101001101001001001010110110101001010010010010101010110100110100100100101 011011001010101010011011011010100110101011010011010101011001101011010101001101011010 011010010110100101001001011011010010101001010010010101011001011010010100100101101011 010110010101101101100101010101001101011011010011010101011001101010101001011011011010 101010100101101011011001011010101001101101010101001001001011010101001101010010010010 01101001101010101100110101010100101101101101001011010101100101101010010110110100000 000001001011011010110101001011010110100101101101101001010101011001011011010110010101 110101010011011010101010011011010110100101011010110010101101101100101010101001101011 101101011001010101101100101100101010110100110101011011001101010101001011010110110010 11001101010010110110100000 001001010010110110100101010010010100101010110010110100100101001011010110010101001001 100101001001010110100110101001010010010101011001101010010100100101101010100110100101 011010110100101001001001010101101101001010010010010101010101100110100100100101011010 001010100100100101010110110010101001001001010101010011011010010010010101101010011010 010101010110011010100100100101101010110010101001001001010110101100101010010010010101 ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 000001001011011010101001001001011001101010101001010010010110101001011010010100100101 101001001001010100110101011010010010010101100110101010100100100101010010110101101001 010101101001011010100100100101101101001010101001001001010101100101101010010010010110  	    !""#$%&'()*+,-./0123456789:;<=>? 0000010010110110101010010010010100110101011011010100101101011010010110110110100101010 101101010011010100100100101101101010010101001001001010101101001101010010010010110101 100100100101010110100110101001001001010101011001101010010010010101101010100110100100 000001001011011010101001001001011001010101101001001001010110101001011010010010010101 101101001101010010010100101010110011010100100101001011010101001101001001010010101101 110101101010100110101101010011011011010100101010110100110110101101001010110110100101 doTest 101100101001001001010101101011001010010010010101010110110010100100100101011001010101 101100101001010010010101101011001010010100100101010110110010100101001001011001010101 010010010110010110101010010100100101001101101010101001001001010110110100101010010010 101100101010010110110100000 000001001011011010100110101101010010010100101101010010110100100101001010110100101101 101100101101101011001010101101100101010101001101101101010011010101101001101010101100 010010101101100101010010010100101010100110110100100101001011010100110101001001010010 001001010110101001101001010010010110110101001010010100100101010110100110100101001001 101001010010010100110101011010010100100101100110101010100101001001010010110101101001  extended mode blocks @ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_ 010101100110110101011001010110101100101010110110010110010101011010011010101101100110 011010010110100100100101011011010010101001001001010101011001011010010010010101101011 testEncode `abcdefghijklmnopqrstuvwxyz{|}~ 011010110100101001010010010101101101001010010100100101010101100110100101001001011010 ",zxing,0
cluster HATestUtil getCanonicalServiceName spyNS listStatus conf logicalHost lookupAllHostAddr fs root verify getHost getConf getFileContext testFileContextDoesntDnsResolveLogicalURI eq  Ensure that the logical hostname was never resolved. configureFailoverFs / never getDefaultFileSystem Mockito makeQualified spyOnNameService haClientConf fc getUri FileContext ,hadoop,1
doMultithreadedWrites cluster WRITE_SIZE testMultipleHflushers conf getFileSystem NUM_WRITES_PER_THREAD fs p NUM_THREADS build close /multiple-hflushers.dat shutdown ,hadoop,1
"testDataInPartitionMin init res hcat://hcat.server.com:5080/mydb/clicks/datastamp=10;region=us CoordELFunctions hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us, hcat://hcat.server.com:5080/mydb/clicks/datastamp=13;region=us, .datain.ABC.unresolved setVariable coord-action-start eval evalAndWrap assertTrue equals .datain.ABC expr Boolean ${coord:dataInPartitionMin('ABC','datastamp')} 10 ",oozie,1
 byteChannel StandardCharsets testStreamThatEndsWithError Expected published exception to be rethrown assertEquals error ByteBuffer produce getCause fail Assert ex assertTrue Expected ProtocolException concatArray publisher producer 12345 dump wrap just streamChannel Flowable ,httpcore,0
 123456789  teststrs assertFalse channel outStream which is only 16 bytes for this test Assert Hello flush inbuf This string should be much longer than the size of the line buffer  writeLine buffer chbuffer clear teststr  this write operation should have no effect assertEquals fill readLine outbuf toByteArray and stuff like that toString newChannel append outChannel And goodbye testBasicReadWriteLine ,httpcore,0
"init getName set oozie.service.ProxyUserService.proxyuser.foo.hosts getConf destroy conf * services , asList testWrongConfigGroups Services fail StringUtils join Arrays ",oozie,1
test SimpleDate getYesterdaysMillis testThatJavaUtilDateWorks ,ninja,0
date scriptExecutor session  Given update simple simplemap Eq simpleMap_PutTo  When of where id row ten table twenty executeScriptTemplate containsEntry should_dsl_update_map_put RandomUtils manager one simpleMap nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap getMap  Then Long buildDateKey fromBaseTable dsl SELECT simplemap FROM simple WHERE id =  thirty ,achilles,1
getConnectionContext getEventMessage conf parseDateUTC DateUtils getStatus testOnWorkflowJobStartedEvent wf-app-name1 caId1 2012-07-22T00:00Z wfId1 getStartTime MessageType init printStackTrace getText destroy wfEventListener fail contains onWorkflowJobEvent wfStartMessage createConsumer AppType startDate getParentId getAppType session assertFalse JMSMessagingUtils getEventStatus getUser EventStatus getId createSession getTopic WorkflowJob jmsContext consumer user1 getMessageType receive getAppName e getMessage assertEquals message wfe endTime Session ,oozie,1
coordId1 appName1 assertEquals createFilterList list coordActionId1 execute asList put jobid Services slaEventsGetCmd appname lastSeqId size assertNotNull get filterList Arrays jpaService testGetSLAEventsForCombined ,oozie,1
cluster  (i.e. the RPC itself should not take 3 seconds!)  ms waitForElectorState conf Time cedeActive testCedeActive getLocalTarget  since the other node in the cluster would have taken ACTIVE. assertTrue zkfc now ActiveStandbyElector RPC to cedeActive took  st getZKFCProxy et2 start assertEquals getZkfc getElectorForTests et Should take ~3 seconds to rejoin. Only took  proxy getStateForTests  It should be in active to start.  at this point. ms before rejoining. ,hadoop,0
" init text/html, application/json application/json thenReturn servletContext assertEquals getAcceptContentType httpServletRequest when accept getHeader Result testGetAcceptContentTypeLegacy application/json, text/plain totally_unknown context application/xhtml, application/json httpServletResponse text/plain ",ninja,0
 Setting total failover attempts to . p1 p2 p3 getKMSUrl testClientRetriesNonIdempotentOpWithSocketTimeoutExceptionFails conf when times assertTrue Should fail since all providers threw a SocketTimeoutException verify thenThrow test kp e anyString thenReturn getProviders keyName createKey eq any setInt CommonConfigurationKeysPublic fail Mockito mock ,hadoop,0
verifyPaths testFullAuthorityWithOtherPort myfs://host.a.b:456 fs ips authorities getVerifiedFS ,hadoop,0
bundleJobGetExecutor Bundle Job should have been purged Bundle Action should have been purged addRecordToBundleActionTable getId DateUtils getStatus parseDateOozieTZ getErrorCode assertNotNull get Job 2011-01-01T01:00Z addRecordToBundleJobTable assertEquals execute call testSucBundlePurgeXCommand Services fail bundleActionGetExecutor1 bundleActionGetExecutor2 action1 ErrorCode je job action2 jpaService ,oozie,1
toCharArray hr conf Allowed flush interval with bad units:   property every time. testGetRollInterval min doTestGetRollInterval hour builder abcefgijklnopqrtuvwxyz day add init hours c d minutes sink h 90  assertEquals m minute 1 fail getRollInterval sink.roll-interval days subset ,hadoop,0
next  Now delete everything. assertEquals COMPACTION_THRESHOLD counter getRow  Flush delete flushcache result  Major compact. r get compactStores testMajorCompactingToNoOutput getScanner results createStoreFile ,hadoop,1
unknown:/// set e getProviders CredentialProviderFactory getMessage conf assertEquals testFactoryErrors assertTrue should throw! No CredentialProviderFactory for unknown:/// in  providers ,hadoop,0
prepare testCodingDirectBuffer_10x4_erasing_d0_d1_p0_p1 testCoding ,hadoop,0
play bogus data ping  play it back  verify the peer received what was expected assertEquals INVALID_STREAM  RST_STREAM TYPE_RST_STREAM bogusDataFrameDoesNotDisruptConnection acceptFrame sendFrame peer SPDY3  write the mocking script  PING connection writeUtf8 takeFrame rstStream ,okhttp,1
testLocalFSsetOwner assumeNotWindows conf {}: {} setOwner bar localfs FileSystem get writeFile getGroups info  create files and manipulate them. set getPermission belongs to only one group. CommonConfigurationKeys f groups g0 assertEquals g1 044 filename Not testing changing the group since user  size cleanup getLocal getGroup LOGGER ,hadoop,0
cluster HATestUtil getCanonicalServiceName spyNS listStatus conf logicalHost eq lookupAllHostAddr fs  Ensure that the logical hostname was never resolved. configureFailoverFs  Make a few calls against the filesystem. / never testDoesntDnsResolveLogicalURI Mockito makeQualified spyOnNameService verify qualifiedRoot getUri getHost ,hadoop,1
  should work when metrics system is not started ms ts2 ts1 assertNull getSource assertNotNull unregisterSource testUnregisterSource s1 shutdown register s2 ,hadoop,0
getBytesTransferred read more stuff; and a lot more stuff dst StandardCharsets CodecTestUtils assertFalse channel clear bytesRead assertEquals decoder convert ByteBuffer stuff; Assert allocate inbuf assertTrue metrics more stuff testCodingBeyondContentLimit isCompleted ,httpcore,0
fail testRedirectReadTimeout Read timed out expected timeout e startSingleTemporaryRedirectResponseThread getMessage TEST_TIMEOUT assertEquals getFileChecksum /file fs ,hadoop,1
A contains stringToList StringCollectionUtil assertTrue testRemoveMatchingWithNoPatterns values removeMatching ,logback,0
renderable  But it should finalizeHeadersWithoutFlashAndSessionCookie thenReturn capture assertEquals assetsController contextRenderable when resultCaptor result getValue getRenderable getStatusCode Results /assets/../../conf/heroku.conf testServeStaticSecurityNoRelativPathWorks verify notFound ok render result2 getRequestPath serveStatic ,ninja,0
snippet resolve readFromRelativeFilePath toUri getSourceLocation getLineNumberTo getLines assertEquals first line baseDir Assert size  graceful w/ bad from/to requested? get second line toFile SourceSnippetHelper toString expectedSourceLocation getLineNumberFrom third line relativeSourcePath ,ninja,0
"getName getLog put createTableDescriptor T40 Bytes T20 assertTrue htd COLUMNS close add printStackTrace e testGetClosestRowBefore2 getRow c0 closeAndDelete flushcache createNewHRegion p T30 T10 getClosestRowBefore r  try finding ""035"" T35 equals region ",hadoop,1
call fail addRecordToBundleJobTable bundle-id testBundleSuspendFailed Job Job doesn't exist. Should fail. ,oozie,1
launcherId addRecordToWfActionTable actionExecutor user.name getId run conf WorkflowInstance getExternalId getStatus createBaseHadoopConf hasIdSwap getJob sleep isSuccessful addRecordToWfJobTable assertTrue LauncherMapper assertNotNull get context action testWorkflowActionRecoveryUserRetry WorkflowJob recoveryRunnable waitFor group a group.name launcherJob getConf XmlUtils forName wfActionGetCmd parseXml assertEquals execute Services 1 createJobClient WorkflowAction jobClient job jpaService evaluate user JobID isComplete ,oozie,1
dst CodecTestUtils 10 1234567890123456  convert setMaxLineLength metrics2 metrics1 Assert MessageConstraintException expected assertNotNull http1Config read 1234567890123456 StandardCharsets custom decoder1 clear bytesRead channel1 inbuf1 assertEquals channel2 decoder2 ByteBuffer inbuf2 trailers fail testTooLongFoldedFooter allocate size build 0 Footer1: blah   blah   blah   blah   blah   blah   blah   blah   Http1Config getTrailers ,httpcore,0
cursor ParseException should have been thrown testInvalidHttpVersionParsing clear length HTT HTTP/1      crap fail Assert HTTP/crap parseProtocolVersion HTTP/1234 HTTP/whatever.whatever whatever HTTP/1. HTTP/1.whatever whatever buffer append ,httpcore,0
"Server cleanupInterval callBarrier conf run firstCallBarrier callReturned maxIdle  start client interrupt join clientConf currentThread  wake up call and ensure connection times out setLogLevel LOG GenericTestUtils  close max connections on every cleanupInterval killMax allCallLatch setInt getConnectAddress CommonConfigurationKeysPublic stop compareAndSet Level server clients assertFalse getId error  connection for the first blocked call should still be open sleep  all calls blocked in handler so all connections made get await client  connections should have closed countDown  block first call addr  1 to block, 2 batches to kill set CommonConfigurationKeys e start threads assertEquals Thread call NetUtils t testConnectionIdleTimeouts getNumOpenConnections toString  stagger cleanups first ",hadoop,0
path methodDir assertMetricsContents toURI toString testSilentExistingWrite doAppendTest ,hadoop,0
"/foo?bar/foo?bar cluster /foo,bar/foo,bar /foo=bar/foo=bar /foo"">bar/foo"">bar waitActive /foo;bar/foo;bar p /foo bar/foo bar testViewingFile /foo+bar/foo+bar build /test-file /tmp/test-file paths CONF /tmp/test-file%with goofy&characters testViewFileJsp shutdown ",hadoop,1
jobConf </configuration> assertArrayEquals getDefaultShareLibName oozie.action.sharelib.for.java wfBean Assert get context action actionConf set ae getConf java-action-executor java-oozie-conf <property> <configuration> setConf Services java-action-conf getShareLibNames <configuration/> </property> java-job-conf testActionSharelibResolution <name>oozie.action.sharelib.for.java</name> <value>java-job-conf</value> ,oozie,1
testSubPackageControllerGet Request CoreMatchers equalTo assertThat makeRequest url sub get works. path Assert response GET testServerUrl /sub/get ,ninja,0
"cursor stuff""\""more\"";""stuff; length raw TokenParser assertEquals createBuffer result testTokenParsingEscapedDelimiter Assert parser stuff""more"";stuff parseValue INIT_BITSET ",httpcore,0
byteBufferNotification testStreamThatEndsNormally fromPublisher materialize isOnComplete consume output Assert streamEnd assertTrue get await TimeUnit synchronizedList countDown Collections consumer add forEach assertEquals ByteBuffer Observable accept getValue size isOnNext Stream did not finish before timeout complete wrap ,httpcore,0
 log files startAndWriteData server getName regions e LOG log getOnlineRegions  Now roll the log getNumLogFiles count actual count:  unexpected exception testLogRolling flushcache after flushing all regions and rolling logs there are  fatal r  flush all regions assertTrue rollWriter after writing there are  info ,hadoop,1
server getLocalPort ContentType createClientSSLContext setSslContext consume testSSLDisabledByDefault bootstrap setConnPoolListener request1 some stuff setEntity SSLv3 setProtocols createServerSSLContext setSocketConfig sslParameters context create https /stuff requester localhost SSLTestContexts SocketConfig setStreamListener custom start LoggingHttp1StreamListener setSoTimeout Method getEntity execute setSslSetupHandler ServerBootstrap target EntityUtils LoggingConnPoolListener build RequesterBootstrap TIMEOUT response1 ,httpcore,0
cluster /testfile  -cat returned 1  rmr prints reasonable error   -mkdir returned File exists  -mkdir returned 1 conf run bak  -mkdir returned 1  getBytes ToolRunner  -ls does not return Found 0 items Renamed getHomeDirectory tmp -mv No such file or getPath outtmp testErrOutPut  -ls does not print out anything  create no output from rename  unix like output -cat /nonexistentfile write ret -dus mv failed to rename setErr /testdir No such file or directory -rm  -mkdir returned this is a file  getFileSystem File exists  -rm returned 1  testFile /testfiletest /testfiletmp rm prints reasonable error  shell numDataNodes mkdirs  -dus prints reasonable error reset shutdown /user/nonxistant/*  -du prints reasonable error  argv System out cat does not print exceptions  file assertTrue root  -lsr should fail  srcFs /nonexistenfile not a directory  -ls on nonexistent glob returns 1 -rmr close  -rmr returned 1 -mkdir empty string  no error  toUri assertEquals setConf Found 0 lastIndexOf -ls build empty path specified toString returned -du ,hadoop,1
FILE_SIZE cluster  after sequence of calls append()/write()/hflush()  shouldn't be null Some more stuff to write dn createFile rand HdfsServerConstants Should be RBW replica on  getBlockPoolId getDataNodes getMethodName LOG GenericTestUtils Running  / getWrappedStream writeBytes Replica on DN  isDebugEnabled pipeline_01 .dat REPL_FACTOR getBlockLocations getLocatedBlocks bpid Invoking append but doing nothing otherwise... fs hflush getBlockId assertTrue get close DFSTestUtil getBlock debug filePath assertEquals getNameNodeRpc fetchReplicaInfo nextLong r getState lb METHOD_NAME toString ofs DataNodeAdapter append getNamesystem ,hadoop,1
"getName conf oozie.service.ProxyUserService.proxyuser.#USER#.hosts asList bar Assert assertTrue StringUtils assertNotNull get join testNullProxyUser validate localhost init oozie.service.ProxyUserService.proxyuser.#USER#.groups set getConf getMessage destroy services , Services fail contains ex proxyUser toString Arrays ",oozie,1
play setVariantAndClient clientPingsServerHttp2 ping  play it back assertFalse HTTP_20_DRAFT_09  verify the peer received what was expected assertEquals toNanos acceptFrame sendFrame assertTrue peer roundTripTime pingFrame TimeUnit  PING connection takeFrame  connection.ping() sets this. ,okhttp,1
localFs assertTrue TEST_ROOT_DIR srcPath mkdirs testRenameSrc testRenameDir/testRenameDst verifyRename testRenameFileIntoDirFile dstPath ,hadoop,0
"play server ABC clearHeaders timeout readTimeouts  to keep the server alive client connection Content-Length: 4 addHeader read  try to read more bytes than are sent, which results in a timeout. in  if Content-Length was accurate, this would return -1 immediately assertEquals setBody getInputStream / enqueue getUrl setReadTimeout fail unused open ",okhttp,1
dst compact CodecTestUtils channel convert put Assert inbuf assertTrue tmp flip s1 s2 isCompleted read testDecodingWithSmallBuffer StandardCharsets hasRemaining clear bytesRead assertEquals decoder 0123456789abcdef ByteBuffer 9 6 abcdef 0   allocate 5 01234 5 5678 metrics ,httpcore,0
args isFollowLink isFollowArgLink assertTrue find -H path processOptionsFollowArgLink assertFalse processOptions getOptions getArgs  check follow arg link option is recognized ,hadoop,0
path random testGetFileBlockLocations2 getLen offBegin oneTest getFileStatus offEnd nextInt fs status ,hadoop,0
" Now use start row with inclusive stop filter expectedRows toBytes testRowOne-0 testRowOne-3 setFilter Bytes testRowTwo-0 testInclusiveStopFilter verifyScan  If we just use start/stop row, we get total/2 - 1 rows expectedKeys testRowTwo-3 ",hadoop,1
"Transfer-Encoding request testRequestExplicitCloseMultipleTokens addHeader keepAlive assertFalse Connection chunked Method / keep-alive Assert response context reuseStrategy blah, blah, blah OK close ",httpcore,0
set runMiniBenchmark hadoop.security.authentication mb conf simple Level testSimple ,hadoop,0
 a a:1-L a:2-N a:1-U l1 l2 start assertEquals sb Thread sleep trim finish toString testTimeoutTimingOutWriteLock ,oozie,1
fail Assert testInvalidConstruction IllegalArgumentException should have been thrown ,httpcore,0
files option does not match #link file:///xyz.txt conf assertTrue assertNotNull get files is null create  GenericOptionParser should throw exception testFilesOption e toURI conf2 assertEquals conf1 testDir tmpFile FileNotFoundException is not thrown  pass a files option args -files localFs tmpURI assertNull th makeQualified files toString files is not null  pass file as uri  all platforms and GenericOptionsParser accepts only valid URIs tmpfiles tmpfile tmpPath throwable is null ,hadoop,0
inheritWF false parentLibs2 parentLibs3 checkSubworkflowLibHelper parentLibs1 parentLibs4 parentLibs5 childLibs1 expectedLibs1 expectedLibs2 expectedLibs3 expectedLibs4 inherit child2.so expectedLibs5 same.jar testCreateProtoConfWithSubWorkflowLib2 childLibs3 childLibs2 childLibs5 child1.jar childLibs4 ,oozie,1
createUserForTesting testProxyUsersWithProviderOverride set ProxyUsers proxyUserUgi refreshSuperUserGroupsConfiguration assertAuthorized GROUP_NAMES 1.2.3.4 1.2.3.5 conf  Now try proxying a group that's not allowed SUDO_GROUP_NAMES REAL_USER_NAME CommonConfigurationKeysPublic assertNotAuthorized  From good IP org.apache.hadoop.security.authorize.TestProxyUsers$TestDummyImpersonationProvider PROXY_USER_NAME  From bad IP UserGroupInformation realUserUgi  First try proxying a group that's allowed createProxyUserForTesting ,hadoop,0
"getName scan testGetScanner_WithNoFamilies  with known number, 2 - current = 1 fam4 fam3 put tableName fam2 Bytes add row1 getHeap method initHeap toBytes is assertEquals families  Setting up region initHRegion fam1 testtable size addFamily  Putting data in Region  i dont like this test region getScanner ",hadoop,1
"getAllSecrets seed System timeout assertArrayEquals atLeastOnce rand Assert  Use the same seed and a ""plain"" Random so we can predict the RNG currentSecret secretProvider verify init rolloverFrequency getCurrentSecret destroy assertEquals secret2 secret3 rollSecret secret1 testGetAndRollSecrets assertNull currentTimeMillis realRollSecret allSecrets atLeast generateNewSecret spy ",hadoop,0
encode  0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 1 0 0  testEncodeShiftjisNumeric  0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0   1 0 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0   mode: NUMERIC   maskPattern: 2   0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1  <<  >>   0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0  put  1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1   1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1   1 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0   1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0  EncodeHintType 0123 qrCode  1 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 1  Encoder  1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0   1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0   1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0  Shift_JIS  1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1   matrix:  hints expected  ecLevel: M  assertEquals  1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0   version: 1   1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1   1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0   1 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0  toString  1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1  ErrorCorrectionLevel  1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1   1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0  ,zxing,0
server getCurrentUser RPC configureSuperUserIPAddresses GROUP_NAMES getUser newEmptyRequest conf run retVal Assert REAL_USER_SHORT_NAME client setProtocolEngine addr setConfiguration UserGroupInformation proxyUserUgi printStackTrace e getClient createRemoteUser testRealUserGroupNotSpecified REAL_USER_NAME fail doAs stop setupTestServer PROXY_USER_NAME The RPC must have failed  realUserUgi createProxyUserForTesting ,hadoop,0
play server abc getSequenceNumber def receiver takeRequest ghi connectionPooling assertEquals setBody url enqueue getUrl assertBody /a /b /c build await client ,okhttp,1
de en-US en-CA NinjaConstant this is the placeholder: test_parameter when getCookie result of get context builder TorÃ¶Ã¶Ã¶Ã¶ - das ist der platzhalter: test_parameter lang ok Cookie test_parameter de-DE Optional message_with_placeholder  that will refer to messages_de.properties: thenReturn anyString en assertEquals c'est le placeholder: test_parameter  and the result overwrites it again...  that will refer to messages_en.properties: Results build Mockito  test with context Accept Header name messages testGetWithDefaultAndContextAndResult getStringArray en-UK fr-FR ninjaProperties getAcceptLanguage  that forced language from context works with empty result setLanguage ,ninja,0
prepare scriptExecutor session preparedStatement  Given simple 0 AM should_perform_prepared_typed_query  When of id table executeScriptTemplate isNotNull actual RandomUtils manager query nextLong assertThat SimpleEntity/insert_single_row.cql ImmutableMap getValue contains typedQueryForSelect  Then Long getOne SELECT * FROM simple WHERE id = :id ,achilles,1
"init ${coord:tzOffset()} testTZOffset  eval.setVariable(""resolve_tzOffset"", ""true""); CoordELFunctions getTimeZone America/New_York -180 assertEquals coord-action-create DateUtils appInst ds 0 eval evalAndWrap configureEvaluator setTimeZone expr ",oozie,1
Args Assert Number notNegative testNotNegativeIntPass1 assertEquals ,httpcore,0
kills addNode workflowJob enters one abcde start assertEquals WorkflowInstance getStatus three two asList testImmediateError exits size four testWf <worklfow-app/> end Arrays workflowDef fails ,oozie,1
headersCopy put STATUS Assert HEADERS runTests  return different headers than expected. get toArray addTest deepcopy keySet changedHeaderCheck WebServerTestingFrameworkException should have been thrown headerName adapter unchecked  change a header to force an error assertEquals responseExpectations execute fail TestingFramework framework response newFrameworkAndSetAdapter junk BODY ,httpcore,0
server ProxyUsers TestProtocol RPC testRealUserSetup getProxySuperuserGroupConfKey configureSuperUserIPAddresses getProxy aMethod GROUP_NAMES  via  conf run retVal Assert setStrings REAL_USER_SHORT_NAME refreshConf stopProxy addr UserGroupInformation getServer ret proxyUserUgi printStackTrace e start assertEquals createRemoteUser group1 getConnectAddress REAL_USER_NAME fail proxy doAs NetUtils stop ADDRESS PROXY_USER_NAME realUserUgi createProxyUserForTesting ,hadoop,1
"10000,2 getName getDefaultRetryPolicy path IO exception  test the disabled and different specifications   test the same setting  retriable exception should have the same hash code hashCode  test enabled and different specifications  40000,5 assertNotEquals no such method exception verifyRetryPolicyEquivalence 20000,3 should be equal assertEquals  test different remoteExceptionToRetry  rp1 50000,6 testDefaultRetryPolicyEquivalence rp3 rp2 60000,7 should not have the same hash code 30000,4  test disabled and the same specifications  getClassName should not be equal ",hadoop,0
play A server clearHeaders assertCode request2 request1 conditionalCacheHit setOkResponseCache getHeader assertBody HttpURLConnection await client addHeader cache receiver takeRequest assertEquals setBody setResponseCode url / If-None-Match enqueue getUrl assertNull build v1 ETag: v1 ,okhttp,1
" Check for resolved conf testDryRunPushDependencies eAction property action coord-job-for-action-input-check.xml createActionElement elementList dryRunCoord printStackTrace workflow populateTable getChild parseXml hcatDependency fail CoordinatorJob getChildren getNamespace file://,testDir/2009/29 CoordCommandUtils job addRecordToCoordJobTableForWaiting  Make sure conf is not resolved as dependencies are not met setPushMissingDependencies configuration ${coord:dataIn('A')} appPath createCoordinatorActionBean actionXml coord default coord-action-for-action-input-check.xml get tablename value actionBean table XmlUtils e newactionXml getMessage assertEquals e1 e2 ${coord:dataOut('LOCAL_A')} getValue  Make the dependencies available configElem file://,testDir/2009/29,file://,testDir/2009/22,file://,testDir/2009/15,file://,testDir/2009/08 getPushMissingDependencies getCoordActionXml  actionXml only to check whether coord conf got resolved or not db getFsTestCaseDir ",oozie,1
"test_app_name <execution>LIFO</execution> </controls> <datasets>  checkCoordJobs testSubmitWithVarAppName conf </input-events>  appPath substring sc </property></configuration> </workflow> </action> </coordinator-app> writeToFile appXml timezone=""UTC""> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template>  <property> <name>inputB</name> <value>${coord:dataOut('LOCAL_A')}</value>  file:// getTestCaseDir UNIT_TESTING <done-flag>consume_me</done-flag> </dataset> <output-events> <data-out name=""LOCAL_A"" dataset=""local_a"">  timezone=""UTC""> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset>  timezone=""UTC""> <uri-template>file:///tmp/coord/workflowsb/${YEAR}/${DAY}</uri-template>  coordinator.xml getAppName set <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  length <dataset name=""local_a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  MY_DONE_FLAG assertEquals <done-flag>${MY_DONE_FLAG}</done-flag> </dataset> <data-in name=""B"" dataset=""local_b""> <instance>${coord:latest(0)}</instance> </data-in>   NAME call OozieClient jobId getTestUser <dataset name=""local_b"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  </datasets> <input-events>  <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>  xmlns=""uri:oozie:coordinator:0.3""> <controls> <timeout>10</timeout> <concurrency>2</concurrency>  -C <data-in name=""A"" dataset=""a""> <instance>${coord:latest(0)}</instance> </data-in>   <coordinator-app name=""${NAME}"" frequency=""${coord:days(1)}"" start=""2009-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""  <dataset name=""a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  complete job File ",oozie,1
timer shouldLog testBasicLogging helper assertTrue record assertFalse LOG_PERIOD advance ,hadoop,0
TestFeature loadedFeatureState enable disable isEnabled savedFeatureState setFeatureState testEnabledStateSavingAndLoading is stateRepository assertThat getFeatureState ,togglz,1
play def Okio goAway Util headerEntries stream was reset: REFUSED_STREAM getSink getBytes TYPE_HEADERS TYPE_PING connection buffer PROTOCOL_ERROR banana expected UTF-8 fail isOpen Arrays newStream shutdown ping  play it back android assertFalse TYPE_DATA  verify the peer received what was expected  SYN_STREAM 3  SYN_STREAM 1 cola acceptFrame flush assertTrue openStreamCount peer receiveGoAway roundTripTime writeUtf8 close takeFrame a  DATA STREAM 1 b abc c setVariantAndClient stream1 stream2 data1 getMessage assertEquals synStream1 synStream2  Ensure the GO_AWAY that resets stream2 has been received. sendFrame SPDY3 equals  PING sink2 abcdef sink1 ,okhttp,1
applyGlobMixedCase item getConf apply n*e name setup /directory/path/NaMe assertEquals mockFs Result  test a glob pattern with different case ,hadoop,0
 server checkCoordAction CoordELFunctions addPartition addInitRecords default  be READY /dt=20120430;country=usa  Make first dependency available CoordinatorAction testUpdateCoordTableMultipleDepsV2 tablename newHCatDependency table newHCatDependency2 newHCatDependency1 populateTable dt=20120430;country=brazil hcat://  Checks dependencies in order. So list does not change if first one is not available dt=20120430;country=usa / call /dt=20120430;country=brazil actionId dropPartition db  Checks only for first missing dependency ,oozie,1
"b fromRow string UTF-8 getId assertEquals _foo {""s"":""string"", ""b"":true, ""i"":1} getBytes longValue testSimpleBlob2 getModCount get Collection doc row Boolean hasBinary ""blob"" ",jackrabbit,1
conn read inStream thenReturn ArgumentMatchers setSoTimeout getInputStream when any anyInt never times bind Assert Mockito assertTrue ensureOpen testAwaitInputInBuffer verify awaitInput socket spy ,httpcore,0
testCoordActionGet getCoordConf getId conf DateUtils replaceAll appPath parseDateOozieTZ resourceXmlName actionXml coord actionNominalTime  Pass the expected values getTestCaseDir CoordinatorAction action setCreatedTime missDeps actionNum prettyPrint XmlUtils #testDir getActionNominalTime testDir setMissingDependencies addRecordToCoordJobTable  Add missDeps attribute to action CoordinatorJob createCoordAction coord-action-get.xml file://#testDir/2009/29/_SUCCESS#file://#testDir/2009/22/_SUCCESS#file://#testDir/2009/15/_SUCCESS#file://#testDir/2009/08/_SUCCESS _testGetForInputCheckX dummyCreationTime  Insert the action insertRecordCoordAction toString job getCoordActionXml getFsTestCaseDir ,oozie,1
_test isMainSuccessful testOutput actionDir hasOutputData assertFalse runningJob isMainDone getFileSystem fs hasIdSwap out getIdSwapPath isSuccessful assertTrue LauncherMapper getErrorPath exists getOutputDataPath evaluate waitFor getFsTestCaseDir isComplete ,oozie,1
fail 10.119.103.112 createFileWithEntries ips.txt 10.221.204.1/23 10.221.102/23 ips testWithAWrongEntry ,hadoop,0
 Test recovery of 1 corrupt replica LOG testBlockCorruptionRecoveryPolicy1 blockCorruptionRecoveryPolicy Testing corrupt replica recovery for one corrupt replica info ,hadoop,1
END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL oozieUrl start MockDagEngineService conf assertEquals wc testStart call OozieClient 1 setProperty createConfiguration SERVLET_CLASSES runTest ,oozie,1
request conn testExecutionHead when flush executor context create verify OK postProcess process thenReturn Method getEntity execute / never Mockito response HttpCoreContext httprocessor mock preProcess receiveResponseHeader sendRequestHeader receiveResponseEntity ,httpcore,0
 check nothing changed in the directory tree emptyList createHardLinkMult tgt_mult testCreateHardLinkMultEmptyList src  test the case of empty file list validateSetup ,hadoop,0
date Set scriptExecutor DowngradingConsistencyRetryPolicy session withConsistencyLevel ONE  Given update simple SELECT value FROM simple WHERE id =  should_dsl_update_with_options Eq  When of withTracing where id row value table executeScriptTemplate logAsserter prepareLogLevelForDriverConnection isNotNull RandomUtils manager one getString nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap assertConsistencyLevels withRetryPolicy  Then Long buildDateKey new value fromBaseTable dsl isEqualTo THREE ,achilles,1
 thenReturn /testroute contextPath index is getReverseRouteWithNoContextPathWorks getContextPath assertThat when router route getReverseRoute ninjaProperties ,ninja,0
init CoordELFunctions assertEquals timeunit getVariable 1 eval evalAndWrap ${coord:minutes(1)} TimeUnit expr coord-job-submit-freq ${coord:minutes(coord:minutes(1))} testMinutes ,oozie,1
"cluster shutdownDfs  Verify we can get the data back now that it is on disk. getLog  flush cache scan  it back both with scanning and get HConstants  put.add(HConstants.COL_STARTCODE, Bytes.toBytes(START_CODE)); testScanner System put Bytes  Store some new information  clean up  Write information to the meta table REGION_INFO TESTTABLEDESC  Now update the information again write close  an older row on disk and there is a newer row in the memstore add address byteStream openClosedRegion toBytes  Validate again bar.foo.com:4321 flushcache closeAndDelete createNewHRegion getRegionInfo foo.bar.com:1234 r currentTimeMillis toByteArray  Close and re-open toString region ROW_KEY  Close and reopen ",hadoop,1
"RestConstants 2009-12-15T01:00Z getId assertEquals coordJobGetExecutor getStatus execute addRecordToCoordJobTable call Services fail testCoordRerunInFailed assertNotNull get Coordinator job is FAILED, rerun should throw exception Job job jpaService ",oozie,1
 should_dsl_update_codec_counter codec_count session  Given update Eq UUIDs uuid  When SELECT codec_count FROM entity_complex_counters WHERE id =  where id isNotNull actual counterWithCodec_Incr RandomUtils manager one timeBased codecCount nextLong assertThat execute  AND uuid =  getLong  Then Long fromBaseTable counterWithCodec dsl isEqualTo ,achilles,1
numInsertions Digits Hash hashId filter hashFunctionNumber RemoveScheme ImmutableSet and of bitSize hashes checkOnAbsentFalsePositive testRetouchedBloomFilterSpecific ,hadoop,0
cluster testServerDefaults DFS_BLOCK_SIZE_DEFAULT DFS_REPLICATION_KEY DFS_BLOCK_SIZE_KEY getBytesPerChecksum conf IO_FILE_BUFFER_SIZE_KEY fs getServerDefaults waitActive IO_FILE_BUFFER_SIZE_DEFAULT getReplication getBlockSize close getWritePacketSize DFS_REPLICATION_DEFAULT DFSConfigKeys getFileBufferSize assertEquals getFileSystem DFS_CLIENT_WRITE_PACKET_SIZE_KEY DFS_CLIENT_WRITE_PACKET_SIZE_DEFAULT setInt DFS_BYTES_PER_CHECKSUM_KEY setLong build numDataNodes serverDefaults DFS_BYTES_PER_CHECKSUM_DEFAULT shutdown ,hadoop,1
getBytesTransferred testCodingFragmentBufferingTinyFragments2 CodecTestUtils channel times Assert flush verify more stuff dump stuff---more stuff write ArgumentMatchers StandardCharsets assertEquals encoder - any Mockito outbuf metrics spy wrap stuff ,httpcore,0
checkSubworkflowLibHelper childLibs1 expectedLibs1 expectedLibs2 expectedLibs3 expectedLibs4 expectedLibs5 testCreateProtoConfWithSubWorkflowLib4 same.jar childLibs3 parent2.jar childLibs2 childLibs5 child1.jar childLibs4 inheritWF false parentLibs2 parentLibs3 parentLibs1 parent1.jar parentLibs4 parentLibs5 inherit child2.so true ,oozie,1
directoryCount expected length            11110        33333        22222              11111  assertEquals spaceConsumed fileCount  check the toString method (defaults to with quotas) testToString build quota        44444          -11111           66665 toString spaceQuota contentSummary ,hadoop,0
"10,11 conf mockfs://mock/tmp/something.zip#something localResources URI when getRawFileSystem setupDistributedCache true,true resolvePath fs.mockfs.impl file mockUri DistributedCache FileSystem get mockfs://mock/ create set thenReturn setClass filePath deprecation MRApps mockfs://mock/tmp/something.txt#something file2 file2Path MRJobConfig mockFs testSetupDistributedCacheConflictsFiles addCacheFile ",hadoop,1
FILE_SIZE cluster filepath1 recoverLeaseUsingCreate /immediateRecoverLease-sameclient  namenode triggers lease recovery on next attempt to write-for-open. BLOCK_SIZE  create another file using the same client /immediateRecoverLease-longlease REPLICATION_NUM createFile  recover the first file filepath  write bytes into the file.  test recoverLese from a different client create setLeasePeriod buffer testImmediateRecoveryOfLease write close actual /immediateRecoverLease-shortlease nextInt  test recoverlease from the same client  continue to write to the second file stm AppendTestUtil dfs verifyFile size LONG_LEASE_PERIOD  close the file immediately recoverLease BUF_SIZE toString SHORT_LEASE_PERIOD ,hadoop,1
bundleJobGetCmd addRecordToBundleJobTable getId assertEquals getStatus execute call Services assertNotNull get testBundlePauseUnpause1 Job job jpaService ,oozie,1
jobConf bundleJobGetCmd log submitCmd getId getStatus appPath Configuration parse error. read from DB : getJob testBundleSuspend3 assertNotNull get getAuthToken Job set getConf addRecordToBundleJobTable assertEquals execute bundle.xml call Services warn OozieClient toString ErrorCode job jpaService ioe ,oozie,1
"getName oozie.service.ProxyUserService.proxyuser.foo.groups foo conf asList bar Assert StringUtils assertNotNull testUnknownHost get join validate localhost init set oozie.service.ProxyUserService.proxyuser.foo.hosts getConf destroy * services , Services fail ex proxyUser toString unknownhost.bar.foo Arrays ",oozie,1
testBooleanParamParser getParsedType parseParameter asdfasdf false TRUE is + Matchers assertThat nullValue - param1 123123 true FALSE Boolean booleanParamParser validation ,ninja,0
add assertGrabAnnotation fullyCustomized my-type assertEquals annotationNode getAnnotations my-classifier org.springframework.boot grabAnnotations 1.2.3 size get spring-boot-starter-logging ,spring-boot,1
injectEdge nullResult EnvironmentEdgeManager assertFalse newEdge assertEquals  injecting null will result in default being assigned. getDelegate edge2 edge assertTrue assertNotNull reset testManageSingleton ,hadoop,1
wfGetCmd getId WorkflowInstance  first update; testWorkflowJobDelete execute setStatus JPAExecutorException should be thrown because job has been deleted. Services fail wfBean addRecordToWfJobTable assertNotNull get wfDeleteCmd1 WorkflowJob job jpaService ,oozie,1
contains goTo $ assertTrue /notauthenticate pageSource #login only visible with valid authenticationToken Login click testAuthenticityFails ,ninja,0
setClassesToBeExcluded getCurrentDateafterIncrementingInMonths getId run DateUtils getStatus addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob sleep assertNotNull get CoordinatorAction end currentDatePlusMonth init getConf testCoordStatusTransitServiceNoDoneWithErrorForBackwardSupport start destroy assertEquals services XDataTestCase setAppNamespace execute addRecordToCoordJobTable Services CoordinatorJob runnable coord-action-get.xml excludedServices SchemaService setSystemProperty true StatusTransitService jpaService ,oozie,1
myFile fileName getName  Create a file with a new name listStatus conf run emptierThread FileSystem  should've been deleted and Current might not have been recreated yet getPath interrupt join emptier mkdir TEST_DIR val add init FS_TRASH_INTERVAL_KEY -rm  Delete the file to trash trashDir trash test/mkdirs/myFile FS_TRASH_CHECKPOINT_INTERVAL_KEY size  12 seconds shell  First create a new directory with mkdirs  Start Emptier in background fs.default.name files  Scan files in .Trash and add them to set of checkpoints getUri myPath testTrashEmptier  6 seconds getLocalizedMessage fs System sleep file assertTrue getCurrentTrashDir  If checkpoints has 4 objects it is Current + 3 checkpoint directories writeFile getParent set fileIndex e setClass start checkpoints setConf Thread args 0.1 0.2 Exception raised from Trash.run  getLocal getEmptier test/mkdirs toString fs.file.impl ,hadoop,1
generateCertificate truststoreLocation BASEDIR assertFalse cert waitForFailedReloadAtLeastOnce sleep  Wait so that the file modification time is different password stopCapturing jks SHA1withRSA testReloadCorruptTrustStore write close getOutput RSA init os kp createTrustStore getReloadInterval ReloadingX509TrustManager reloaderLog destroy assertEquals cert2 generateKeyPair cert1 Thread CN=Cert2 contains CN=Cert1 /testcorrupt.jks tm getAcceptedIssuers ,hadoop,0
play server request ABCABCABC client connection readAscii getContentEncoding addHeader Accept-Encoding: gzip getHeaders takeRequest gzip assertEquals setBody getContentLength getInputStream assertContains Content-Encoding: gzip / Integer enqueue getUrl assertNull gzipEncodingEnabledByDefault open ,okhttp,1
END_POINTS IS_SECURITY_ENABLED getContextURL testAdminQueueDump oozieUrl HeaderTestingVersionServlet clear admin run assertEquals args call -oozie -queuedump SERVLET_CLASSES runTest ,oozie,1
"dateFormat getTimeZone bodyParserEngineJson equalTo CoreMatchers invoke String compareTo jsonObjMapper when getBytes testValidJsonBody cal assertTrue context setTimeZone close setTime jsonDocument thenReturn Calendar format testForm is parse assertThat getInputStream TimeZone Mockito {""firstName"":""%s"", ""lastName"":""%s"", ""birthYear"":%d, ""lastSeen"":""%s""} BodyParserEngineJsonTest getInstance ",ninja,0
add a ( h ) Token assertEquals tokenize (x witness x) testEscapedParanteheses %a(x\) tl %a\(x) (%h\) \(%h\) ,logback,0
line One assertFalse inChannel outStream Assert flush inbuf assertTrue writeLine Four clear assertEquals fill readLine Two Three US-ASCII outbuf One Two Three Four  toByteArray testWriteLineChunks toString One Two Three newChannel  Four outChannel ,httpcore,0
assertFalse getCurrentDateafterIncrementingInMonths getId run DateUtils getExternalId WorkflowInstance getStatus isPending addRecordToCoordActionTable parseDateOozieTZ coordJob sleep addRecordToWfJobTable assertNotNull get CoordinatorAction end currentDatePlusMonth WorkflowJob Job waitFor coordAction1_1 coordAction1_2 coordJobId start assertEquals XDataTestCase execute addRecordToCoordJobTable call Services CoordinatorJob coordJobGetCmd runnable coord-action-get.xml coordJob1 equals testCoordStatusTransitServiceSuspendAndResume job jpaService evaluate ,oozie,1
addToken thenReturn service2  add token unchecked  from Mockito mocks service1 getCredentials createRemoteUser assertSame when getService someone ugi  add token with another name getToken mock t1 t2 UserGroupInformation testAddNamedToken ,hadoop,0
"conf testExceptionOnBackgroundRefreshHandled asList waitForGroupCounters advance timer cacheGroupsAdd  Pause the getGroups operation and this will delay the cache refresh  add another group me getGroups grp3  Resume the getGroups operation and the cache can get refreshed resume  a onFailure callback gets called and the counter for failure is 1  exception, we now expect the counter for success is 1. getRequestCount CommonConfigurationKeys clearBlackList groups refresh FakeGroupMapping assertEquals  Then expire that entry assertThat  a request to getGroups yet.  second call pause setLong myGroups size  We make an initial request to populate the cache setThrowException startingRequestCount Arrays isEqualTo setBoolean ",hadoop,0
"cluster sleepAtLeastIgnoreInterrupts getModificationTime conf fs /test out  Open a file, and get its initial modification time. assertTrue  10 milliseconds modTimeAfterClose getFileStatus create close restartNameNode  Restart the NN, and make sure that the later mod time is still used. initialModTime assertEquals getFileSystem  Wait and then close the file. Ensure that the mod time goes up. modTimeAfterRestart testPath build sleepTime ThreadUtil shutdown testModTimePersistsAfterRestart ",hadoop,1
setQueueSize addAppender stop noEventLoss doAppend start verify loopLen delayingListAppender bufferSize asyncAppenderBase ,logback,0
" CoordELFunctions eAction /dt=20120430;country=usa CoordinatorAction property action coord-job-for-action-input-check.xml testResolveCoordConfiguration addRecordToCoordActionTableForWaiting newHCatDependency coord-action-for-action-push-check.xml elementList workflow populateTable getChild parseXml / hcat://dummyhcat:1000/db1/table1/ds=/2009-29 CoordinatorJob getChildren /dt=20120412;country=brazil getNamespace actionId job server addRecordToCoordJobTableForWaiting checkCoordAction configuration caBean getId hcat://dummyhcat:1000/db1/table1/ds=/2009-29,hcat://dummyhcat:1000/db1/table1/ds=/2009-29, default get Z tablename value table newHCatDependency2 XmlUtils newHCatDependency1 hcat:// assertEquals e1 e2 call getValue getActionXml configElem db ",oozie,1
testKerberosDelegationTokenAuthenticator testKerberosDelegationTokenAuthenticatorWithDoAs ,hadoop,0
guiceArgumentExtractorWithOptional Optional of context create verify invoke customArgumentExtractorWithOptionalAndGuiceShouldBeInstantiated dep:bar:java.lang.String mockController dep ,ninja,0
 call optional=true required=true&optional=true MyJsonRestServlet GET HttpServletResponse required=true invoke assertEquals runTest testParamsRequired ,oozie,1
read skip assertEquals in2 inBuffer3 in1 inBuffer4 inBuffer1 in4 inBuffer2 in3 Assert testSkip assertTrue inputStream4 inputStream3 inputStream2 inputStream1 close ,httpcore,0
handler request getTime jwt foo publicKey setPublicKey JWTRedirectAuthenticationHandler when put REDIRECT_LOCATION alternateAuthentication should NOT have thrown a AuthenticationException SERVICE_URL getCookies getJWT verify getRequestURL init cookie alternateAuthentication should NOT have thrown a ServletException thenReturn getProperties hadoop-jwt encodeRedirectURL alternateAuthenticate sendRedirect props token fail privateKey serialize bob Mockito response testInvalidAudienceJWT mock ,hadoop,0
numInputs CoderUtil inputs findFirstValidInput testNoValidInput ,hadoop,0
"userCredsRunnable subject  Set the runnable to not to run in a loop run when atLeastOnce ugi setRunRenewalLoop  Create and destroy the KerberosTicket, so endTime will be null verify  Create UserGroupInformation Boolean  throw IOException in the middle of the autoRenewalForUserCreds UserGroupInformation add tgt testKerberosTicketIsDestroyedChecked reloginFromTicketCache d setLogLevel kp Foo isDestroyed GenericTestUtils destroy  there should be no exception when calling this users doThrow Mockito  run AutoRenewalForUserCredsRunnable with this  isDestroyed should be called at least once Level toString spy ",hadoop,0
adapter test alreadyCheckedResponse assertEquals  This put should be ignored by the framework. responseExpectations execute put STATUS Assert framework runTests response get newFrameworkAndSetAdapter addTest RESPONSE deepcopyOfTest ,httpcore,0
ffs checkFsConf lfs create assertEquals conf initialize URI getRawFileSystem filter:/ testInitFilterFsSetsEmbedConf ,hadoop,0
init CoordinatorJob as getTestUser testAuthorizationServiceForCoord assertNotNull get getId services job addRecordToCoordJobTable authorizeForJob ,oozie,1
parent init testAddStartedSiblingInStart Incorrect number of services start assertInState STATE assertEquals sibling stop size addService getServices ,hadoop,0
createMultiPartEmailWithContent  ///////////////////////////////////////////////////////////////////// mail simple body text  set only text: assertTrue setBodyHtml testCreateMultiPartEmailWithContent commonsmailHelper <br>simple body text<br> setBodyText multiPartEmail ,ninja,0
@ closeTrx coordClient getStore getTime LocalOozie Could not update db. getStatus -testCoordRerun-C getCoordClient rerunScope get beginTrx CoordinatorAction reRunCoord actionNum2 commitTrx actionNum1 coord-rerun-action2.xml RestConstants printStackTrace store1 e store - testCoordRerunActions2 actionId2 addRecordToJobTable Integer jobId actionId1 Services fail CoordinatorJob addRecordToActionTable assertNotSame 0000000- toString action1 action2 coord-rerun-action1.xml getCoordinatorAction ,oozie,1
getTime conf DateUtils appPath cal writeToFile nominal  for start_miss assertNotNull get workflow.xml setTime nominal_time add nominalTime set SLA_XML_1 Calendar services _testWorkflowJobCommands ehs OozieClient getTestUser formatDateOozieTZ toString testSLASchema1BackwardCompatibility slas getFsTestCaseDir ,oozie,1
 isOriginalTGTReturnsCorrectValues /@ isTGSPrincipal assertTrue krbtgt/foo@foo krbtgt/foo.bar.bat@foo.bar.bat assertFalse krbtgt/foo@FOO krbtgt/hello SecurityUtil blah ,hadoop,1
authenticate isAuthenticated testAuthenticate User was not created result authenticationProvider password findLdapUserByName assertNull User alread exists in DB assertTrue assertNotNull userDAO allowedUser authentication ,ambari,1
SomeNonExistentFile testTokenFile CAT_TOKEN set kdiagFailure KEYLEN HADOOP_TOKEN_FILES ARG_KEYLEN conf unset ,hadoop,0
testIOEOnClientWriteParam doErrorTest ,hadoop,0
conn setRequestMethod IS_SECURITY_ENABLED assertTrue get testStatus json content-type /v1/admin/* Collections runTest SYSTEM_MODE JsonTags RestConstants openConnection HttpServletResponse assertEquals parse getInputStream url JSONValue call getHeaderField GET getResponseCode createURL toString startsWith ,oozie,1
testData assertFalse parseACLs commit delete ZKUtil getBytes fencingNodePath /node2 /node1 assertTrue create getData CommonConfigurationKeys setData UTF-8 txn node1 zkAcl node2 curator CreateMode /fencing equals exists Arrays createTransaction testTransaction ,hadoop,0
bundleJobGetExecutor addRecordToBundleActionTable getId getStatus assertNotNull get 2009-02-01T00:00Z Job init testBundleRerunWithError false addRecordToBundleJobTable destroy assertEquals services execute addRecordToCoordJobTable call Services CoordinatorJob setSystemProperty StatusTransitService action1 job action2 jpaService ,oozie,1
"TestFeature reflectionEquals setStrategyId user1, user2, user3 is assertThat getFeatureState featureStateWithoutStrategy loadedFeatureState savedFeatureState setParameter setFeatureState  save same feature, but without activation strategy. should remove an existing one UsernameActivationStrategy stateRepository testRemovingOfActivationStrategy ",togglz,1
testSplitableCodec testSplitableCodecs ,hadoop,0
"00 01 02 03 04 05 06 07 08 09 hit Assert  maroon 1, 6, 7, 8, 10 hasNext OranGe 0 0a 1 0b 2 0c 3 0d 4 0e 5 Yellow 6 7 8 9 next assertFalse yellow  without filter assertTrue headers a b c d e assertEquals testInterspersed  yellow 0, 5, 9, 11, 13 orange  orange 2, 3, 4, 12, 14 maroon marOOn ",httpcore,0
play server request def assertCode getHeader assertBody recordedRequest post text/plain; charset=utf-8 await MediaType create client Content-Length text/plain Content-Type abc receiver takeRequest Request assertEquals parse setBody url / getUtf8Body enqueue getUrl 3 build ,okhttp,1
"value2 value1 val3 </prepare> </configuration> credProperties <workflow-app xmlns='uri:oozie:workflow:0.2.5' name='pig-wf'> conf launcherConf <name>mapred.compress.map.output</name> <param>OUTPUT=${outputDir}/pig-output</param> property2 <message>Pig failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message> property1 </workflow-app> <value>value2</value> <prepare> assertNotNull credentialsConf setCred context action actionConf ae abc=org.apache.oozie.action.hadoop.InsertTestToken setCredentialPropertyToActionConf <error to='fail' /> <value>${queueName}</value> getProperties <name>property2</name> parseXml  Setting the credential properties in launcher conf <end name='end' /> testCredentialsModule <pig> <script>org/apache/oozie/examples/pig/id.pig</script> <start to='pig1' /> </kill> <ok to='end' /> getType  Adding if action need to set more credential tokens <value>true</value> <param>INPUT=${inputDir}</param> setCredentialTokens </credentials> <job-tracker>${jobTracker}</job-tracker> <action name='pig1' cred='abcname'> getCredentials getActions  action job configuration test1 </pig> createBaseHadoopConf oozie.credentials.credentialclasses actionXml <delete path='outputdir' /> <value>value1</value> <name>${property3}</name> wfBean <credential name='abcname' type='abc'> </action> addRecordToWfJobTable <name>mapred.job.queue.name</name> get prop copy <credentials> <name-node>${nameNode}</name-node> set getConf XmlUtils ABC Token <property> <name>property1</name> <kill name='fail'> assertEquals setType <configuration> setConf actionXmlconf prop3 abcname Services XConfiguration actionxml </property> getToken tk </credential> <value>${value3}</value> ",oozie,1
"DagELFunctions ${wf:callback('XX')} def b=B ${wf:id()} conf ${wf:run()} getStatus createEvaluator WorkflowInstance  ${toPropertiesStr(wf:actionData('actionName'))} setId action setUser ${wf:lastErrorNode()} ec ${wf:conf('a')} group ext testFunctions ${wf:errorCode('actionName')} workflow expected em OozieClient setGroup contains eval ${wf:appPath()} WorkflowAction ${wf:actionExternalId('actionName')} name actionId ${wf:actionExternalStatus('actionName')} job evaluate actionName setName A ${a} B addNode getWorkflowInstance setActionInfo getId setRun appPath setAppPath setTrackerUri System wf ${wf:actionTrackerUri('actionName')} status=XX assertTrue configureEvaluator get tracker <workflow-app/> ${wf:group()} end setExternalId wfInstance setProtoActionConf ${wf:user()} setWorkflowInstance a ${toJsonStr(wf:actionData('actionName'))} setAppName b set ${wf:errorMessage('actionName')} prettyPrint XmlUtils setData id=actionId ${wf:actionData('actionName')['b']} escapeCharsForXML setExternalStatus assertEquals setStatus Services setErrorInfo ${wf:name()} toXmlString toString externalStatus {""b"":""B""} user wfId ${toConfigurationStr(wf:actionData('actionName'))} ",oozie,1
"testFindByte data Hello, world! UTF8ByteArrayUtils assertEquals Did not find first occurrence of character 'o' Character 'a' does not exist in string findByte getBytes ",hadoop,0
getJobTrackerUri launcherId getName getJobID <java> conf getExternalId getStatus createContext createBaseHadoopConf actionXml isSuccessful LauncherMapper assertTrue context end waitFor <job-tracker> getData getNameNodeUri </java> ae XmlUtils </main-class> parseXml </job-tracker> runningJob getAction assertEquals check getExternalStatus <name-node> <main-class> </name-node> assertNull WorkflowAction testRecovery runningJob2 SUCCEEDED submitAction toString getRecoveryId evaluate getActionDir isComplete ,oozie,1
"expectedA        <value>A</value>  AAA        <name>a</name>    <job-tracker>foo</job-tracker>  validateAndParse   </prepare>      </property>        <value>C</value>    <script>script.q</script>  replaceAll System   <configuration>    </configuration>  <hive xmlns=""uri:oozie:hive-action:0.2"">  app   a     <mkdir path=""/tmp"" />  getConf testParserGlobalExtensionActions   <prepare>        <name>b</name>  assertEquals wf-schema-valid-global-ext.xml       <value>B</value>  </hive>   <param>INPUT=/tmp/table</param>  IOUtils       <name>c</name>  parser   <param>OUTPUT=/tmp/hive</param>  getResourceAsReader     <property>  getNode     <delete path=""/tmp"" />    <name-node>bar</name-node>  ",oozie,1
Keep-Alive expect addHeader response converter Header 'Connection: Keep-Alive' is illegal for HTTP/2 messages Connection thrown testConvertFromMessageConnectionHeader convert expectMessage ,httpcore,0
getName tokenSigned TOKEN_VALIDITY_SEC sign when asList getInitParameterNames invalidtype Assert secretProvider management.operation.return signer init cookie thenReturn StringSignerSecretProviderCreator destroy failed ex getInitParameter newStringSignerSecretProvider setProperty true mock Arrays request Invalid AuthenticationToken type setExpires secret System secretProviderProps assertTrue getCookies AuthenticatedURL AuthenticationFilter getMessage assertEquals token token not invalid type filter p getMockedServletContextWithStringSigner Mockito u elements currentTimeMillis getToken toString config testGetTokenInvalidType ,hadoop,0
"<sla:should-start>5</sla:should-start> <sla:should-end>50</sla:should-end>  <coordinator-app name='NAME' frequency='${coord:days(1)}' start='2009-02-01T01:00Z' end='2009-02-03T23:59Z' timezone='UTC' xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance' xmlns='uri:oozie:coordinator:0.2' xmlns:sla='uri:oozie:sla:0.1'>  XmlUtils e testCoordSLASchema validator </sla:info> parseXml </action> </coordinator-app> newValidator getSchema COORD_APP1 Services <sla:info> <sla:app-name>5</sla:app-name> <sla:nominal-time>2009-03-06T010:00Z</sla:nominal-time>  <controls> <timeout>10</timeout> <concurrency>2</concurrency> <execution>LIFO</execution> </controls> <datasets> <dataset name='a' frequency='${coord:days(7)}' initial-instance='2009-02-01T01:00Z' timezone='UTC'> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset> <dataset name='local_a' frequency='${coord:days(7)}' initial-instance='2009-02-01T01:00Z' timezone='UTC'> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset> </datasets> <input-events> <data-in name='A' dataset='a'> <instance>${coord:latest(0)}</instance> </data-in>  </input-events> <output-events> <data-out name='LOCAL_A' dataset='local_a'> <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path> <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property> <property> <name>inputB</name> <value>${coord:dataOut('LOCAL_A')}</value> </property></configuration> </workflow>   wss <sla:alert-contact>abc@example.com</sla:alert-contact> <sla:dev-contact>abc@example.com</sla:dev-contact> get  <sla:qa-contact>abc@example.com</sla:qa-contact> <sla:se-contact>abc@example.com</sla:se-contact> SchemaName validate  System.out.println(""XML :""+ XmlUtils.prettyPrint(e)); ",oozie,1
App.callback App.callback([123]) jsonp testCorrectFlow thenReturn finalizeHeaders UTF-8 invoke assertEquals when result objectMapper toByteArray context callback verify outputStream TemplateEngineJsonP properties jsonpEngine getParameter ,ninja,0
"gidNameMap  getUserName() getGid conf  <username> is numerical, remove them from the map for testing purpose. getGidNameMap tid getUid uidNameMap refIdMapping me getUserName id clearNameMaps getKey getUidNameMap entrySet  getGid() incrIdMapping tname assertEquals getValue getGroupName testUpdateMapIncr IdMappingConstant setLong size  getUid() name  getGroupName() ",hadoop,0
 kills addNode def enters WorkflowInstance getStatus asList wf exits end signal fails testDoneWithRunningNodes a b f start j assertEquals 1 size <worklfow-app/> Arrays job /b/ ,oozie,1
next badRequest thenReturn getFilterChain filterChain when getBadRequestResult ninjaDefault route Mockito That's a BadRequest that should be handled by onBadRequest contextImpl mock verify testOnRouteRequestWhenOnBadRequest onRouteRequest thenThrow ,ninja,0
"date https://www.example.com private getDynamicEntry foo=ASDJKHQKBZXOQWEOPIUAXQWEOIU; max-age=3600; version=1 content-encoding assertHeaderEquals dynamicTable setMaxSize asList assertArrayEquals getCurrentSize encodeHeaders set-cookie Assert createByteArray :status cache-control StandardCharsets Mon, 21 Oct 2013 20:13:22 GMT clear Mon, 21 Oct 2013 20:13:21 GMT assertEquals headers2 gzip headers3 encoder headers1 expected1 buf 200 expected3 expected2 302 toByteArray location 307 Arrays dynamicLength testResponseEncodingWithoutHuffmanRFC7541Examples ",httpcore,0
"JsonTags ;coordinators=Coord1,Coord2;actionstatus=KILLED /v1/jobs testMultipleCoordinators  giving range as 2 of the total 3 coordinators assertEquals jaction1 jaction2 Coord1@2 Coord2@1 call size array assertNotNull get bundleName _requestToServer bulkRequest bundle= runTest jbundle ",oozie,1
workerShouldStopEvenIfInterruptExceptionConsumedWithinSubappender addAppender stop assertTrue doAppend start verify delayingListAppender interrupted asyncAppenderBase Thread ,logback,0
RestConstants getTime 2009-12-15T01:00Z getId assertEquals coordJobGetExecutor getStatus addRecordToCoordActionTable execute testCoordRerunInPausedWithError call getPauseTime Services pauseTime assertNotNull get CoordinatorAction curr Job job jpaService coord-rerun-action1.xml addRecordToCoordJobTableWithPausedTime ,oozie,1
getName fileF fileD src/test/resources/resource-matcher/three bravo/fileE bravo/fileC three asList System assertTrue src/test/resources/resource-matcher/one find resourceMatching bravo/* matchedResources add resource containsAll alpha/** * assertEquals alpha/nested/fileA resourceMatcher size paths alpha/**/excluded Arrays .* src/test/resources/resource-matcher/two ,spring-boot,1
g2 desc c1 found newGauge run num metrics in registry Metric name c1 already exists assertTrue get c1 desc g1 found s1 g3 desc test s1 found c2 found testNewMetrics g1 assertEquals g2 g3 g3 found c1 c2 c2 desc s1 desc newStat g2 found expectMetricsException r ops size newCounter g1 desc time metrics test dup ,hadoop,0
play  server readAscii ABC  The request should work once and then fail assertEquals getKeepAlive setBody getInputStream Integer enqueue getUrl setReadTimeout input fail connection1 client open shutdown connection2 ,okhttp,1
checkCoordAction getId DateUtils parseDateOozieTZ addRecordToCoordJobTable call CoordinatorJob @1 testActionMater 2009-03-06T010:00Z 2009-03-11T10:00Z startTime endTime job ,oozie,1
Oopsie testExpressionCheckFail Asserts check ,httpcore,0
cluster /foo  write 2 files at the same time read in conf assertEquals getFileSystem fs out p /bar build DFS_DATANODE_SYNCONCLOSE_KEY create testFileCreationSyncOnClose write close shutdown open  verify setBoolean ,hadoop,1
5.png assertCorrectImage2binary  (01)90614141000015(3202)000150 testDecodeRow2binary5  ..X.X... .XXXX.X. XX..XXXX ....XX.. X....... ....X... ....X..X .XX. ,zxing,0
getLong setLong configuration assertEquals value testLong ,hadoop,0
subwfJobGetCmd addRecordToWfActionTable coordActionGetCmd getId WorkflowInstance getStatus addRecordToCoordActionTable SubWorkflow Action should have been purged coordJob wfJob Workflow Job should have been purged addRecordToWfJobTable getErrorCode assertNotNull Coordinator Action should have been purged get CoordinatorAction WorkflowJob wfAction subwfAction wfJobGetCmd Coordinator Job should have been purged Workflow Action should have been purged SubWorkflow Job should have been purged wfActionGetCmd assertEquals execute addRecordToCoordJobTable subwfActionGetCmd call Services CoordinatorJob 1 coordJobGetCmd fail coord-action-get.xml WorkflowAction coordAction testPurgeCoordWithWFChildWithSubWF3 SUCCEEDED subwfJob ErrorCode je jpaService ,oozie,1
getWorkflowInstance addRecordToWfActionTable getId testWfKillSuccessAfterNodeDefUpgrade WorkflowInstance getStatus sleep addRecordToWfJobTable assertNotNull LiteWorkflowStoreService get action WorkflowJob wfInstance wfJobGetCmd init wfActionGetCmd destroy assertEquals services execute call 1 Services WorkflowAction setSystemProperty job jpaService ,oozie,1
ff getBytesTransferred dst stuf  stu CodecTestUtils assertFalse channel convert stuff; Assert inbuf f; assertTrue testBasicDecodingSmallBuffer more stuff isCompleted read StandardCharsets more clear bytesRead assertEquals decoder ByteBuffer allocate metrics ,httpcore,0
reverseRouter www.greenback.com pathParam is assertThat with route build absolute https://www.greenback.com/user/test%40example.com/1000000 id test@example.com https email ,ninja,0
"cursor     getName   test assertFalse test=stuff test  = ""  stuff\"""" Assert param assertTrue getPos buffer    test  =   stuff ;1234  = stuff  test atEnd testNVParse length assertEquals    test  =   stuff    stuff"" getValue test  = ""stuff"" test  ,12 parseNameValuePair test; append stuff ",httpcore,0
addressFactory addressHost4 HOST_LIST addressMockHost4 addressMockHost5 assertFalse  test for exclusion with an unknown IP  test for inclusion with an known IP when addressHost1 assertTrue StringUtils getByName getTrimmedStringCollection 1.2.3.1 ml host5 differentName host4 host1 1.2.3.4 getCanonicalHostName thenReturn 1.2.3.5 includes  create MachineList with a list of of Hostnames Mockito mock testHostNames InetAddress ,hadoop,0
assertEquals parse p head result xyz Helloworld xyz %hello\_world t compile converterMap context setContext write testWithNopEscape ,logback,0
cluster Failed to throw IOE when seeking after close conf Failed to throw IOE when seeking past end  create file seek testDFSSeekExceptions output path getTestConfiguration file assertTrue create close threw getFileSystem Some test data to write longer than 10 bytes input writeBytes build numDataNodes /test/fileclosethenseek/file-0 fileSys  success shutdown open ,hadoop,1
 .0 getQueueClass CommonConfigurationKeys Server manager assertCanPut ns org.apache.hadoop.ipc.DecayRpcScheduler  Default FCQ has 4 levels and the max capacity is 8 getCanonicalName conf queueClassName org.apache.hadoop.ipc.FairCallQueue . scheduler getSchedulerClass testFcqBackwardCompatibility setStrings assertTrue equals  Ensure the DecayScheduler will be added to avoid breaking.  work without explicitly specifying DecayRpcScheduler queue ,hadoop,0
getBytesTransferred CodecTestUtils channel times Assert flush verify dump write ArgumentMatchers StandardCharsets length assertEquals encoder - any stuff--m Mockito outbuf much more stuff testCodingFragmentBufferingChannelSaturated2 metrics spy wrap stuff ,httpcore,0
setClassesToBeExcluded addRecordToBundleActionTable createBundleJob getId run DateUtils getStatus parseDateOozieTZ setPauseTime bundleJob get testBundleStatusTransitServicePausedWithError Job bundle waitFor init getConf false 2009-02-01T01:00Z bundleId destroy bundleInsertjpa assertEquals services execute Services runnable excludedServices setSystemProperty StatusTransitService action1 action2 jpaService action3 evaluate ,oozie,1
prepareAppendKey outKey fail key0 Key is shorter than expected. skip writer testFailureValueTooShort write close getBytes ,hadoop,0
actionDir testDoOperationsWithValidXML </prepare>  Delete the file if it is already there doOperations conf getFileSystem fs delete createJobConf LauncherMapper assertTrue newDir <prepare> <mkdir path=' '/> prepareXML exists  Test to check if prepare action is performed as expected when the prepare XML block is a valid one setupLauncherURIHandlerConf PrepareActionsDriver getFsTestCaseDir ,oozie,1
AAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP/ /SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQ KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAA  This specially-formatted frame has trailing deflated bytes after the name value block. AAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD A//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9 //0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0o headerBlockHasTrailingCompressedBytes2048 EAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAA gAMAAgAAB/sAAAABeLvjxqfCAqYjRhAGJmxGxUQAAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAA headerBlockHasTrailingCompressedBytes AAAD//0oEAAAA//8= frame ,okhttp,1
setClassesToBeExcluded addRecordToBundleActionTable createBundleJob getId run DateUtils getStatus parseDateOozieTZ setPauseTime bundleJob get Job bundle waitFor init getConf false 2009-02-01T01:00Z bundleId destroy bundleInsertjpa assertEquals services execute Services runnable testBundleStatusTransitServicePaused excludedServices setSystemProperty StatusTransitService action1 action2 jpaService action3 evaluate ,oozie,1
FileUtils isProd NinjaConstant uuid defaultConfiguration setFileName assertTrue src/main/java/conf/application.conf randomUUID UUID baseDirWithoutTrailingSlash Files /tmp/ninja-test- testMissingSecretCreatesNewOneInDevMode length getString checkThatApplicationSecretIsSet compositeConfiguration contains NinjaPropertiesImplTool toString File deleteDirectory devConf Charsets  tear down ,ninja,0
 check the header        QUOTA       REM_QUOTA     SPACE_QUOTA  testGetHeader header assertEquals REM_SPACE_QUOTA  QuotaUsage getHeader ,hadoop,0
=38=38=20=4C=79=6E=62=72=6F=6F=6B=0D=0A=43=  =4F=20=36=39=39=  testQuotedPrintable doTest 88 Lynbrook CO 69999 =39=39;;; END:VCARD BEGIN:VCARD ADR;HOME;CHARSET=UTF-8;ENCODING=QUOTED-PRINTABLE:;; ,zxing,0
" The server shall authorize the access, but should not drop a new cookie expires TOKEN_MAX_INACTIVE_INTERVAL  newCookie _testDoFilterAuthenticationMaxInactiveInterval TOKEN_VALIDITY_SEC currentTimeMillis  authorized maxInactives  with renewed activity interval System testTokenWithValidActivityInterval ",hadoop,0
bundleJobGetExecutor testBundleRerun1 addRecordToBundleActionTable addRecordToBundleJobTable getId assertEquals getStatus execute addRecordToCoordJobTable call CoordinatorJob Services assertNotNull get 2009-02-01T00:00Z action1 Job job action2 jpaService ,oozie,1
"INodesInPath  ignore "".snapshot"" getName resolve inodes getModificationTime  The modification time of the INode for file3 should have been changed createFile ssNodesInPath ssInodes Assert createSnapshot nodesInPath getPathNames s3 s4  Modify file1 allowSnapshot last  The last INode should be associated with file1  pointing to a snapshot file snapshotFileNode testSnapshotPathINodesAfterModification  First check the INode for /TestSnapshot/sub1/file1 newInodes INode getPathComponents components appendFile getPathSnapshot seed sub1 /.snapshot/s3/file1 assertFalse  file1 was deleted, create it again.  Check the INodes for snapshot of file1 the content for appending  original INode before modification REPLICATION assertSnapshot assertTrue DFSTestUtil  Check the INode for /TestSnapshot/sub1/file1 again newNodesInPath assertEquals  The number of inodes should be equal to components.length getSnapshot getFullPathName snapshotPath names fsdir getLocalName hdfs toString  Check the INode for snapshot of file1 file1 getINodes ",hadoop,1
val set a+rw valueOf conf SYMBOLIC assertEquals  Test some symbolic to octal settings getUMask FsPermission testSymbolicUmasks Short toShort ,hadoop,0
coordActionGetCmd getId assertEquals getStatus addRecordToCoordActionTable execute addRecordToCoordJobTable call CoordinatorJob Services coordJobGetCmd coord-action-get.xml assertNotNull get testCoordKillFailedOnAction CoordinatorAction action job jpaService ,oozie,1
"init getName set getConf testInvalidGroupsMapping destroy conf services , asList oozie.service.GroupsService.hadoop.security.group.mapping Services fail ex StringUtils toString join Arrays ",oozie,1
testPutMetrics2 setReceiveBufferSize getLocalPort MetricType MsInfo getLocalAddress Received data did not match data sent result putMetrics assertTrue record process.jvm.Context.foo2:2|g foo1 foo2 mockStatsD close getData add jvm process.jvm.Context.foo1:1|c receive process getHostName forName sink UTF-8 statsd Charset tags makeMetric Whitebox p sock equals getLength metrics setInternalState ,hadoop,0
server ContentType javaVersion listener CoreMatchers notNullValue equalTo connectFuture some stuff listen endpoint Assert getDuration HttpVersionPolicy getHead get testNegotiateProtocol getAddress https /stuff getCode HttpVersion connect requester localhost getVersion address HttpStatus start resultFuture1 Method assertThat execute target getTimeUnit getPort future TIMEOUT response1 message1 ,httpcore,0
coordActionGetCmd getCurrentDateafterIncrementingInMonths getId DateUtils getStatus addRecordToCoordActionTable parseDateOozieTZ assertNotNull get CoordinatorAction action end currentDatePlusMonth testCoordKillSuccess2 start assertEquals XDataTestCase execute addRecordToCoordJobTable call CoordinatorJob Services coordJobGetCmd coord-action-get.xml job jpaService ,oozie,1
init CoordELFunctions ${coord:months(1) + 7} ${coord:months(1)} testMonth assertEquals timeunit getVariable 1 eval evalAndWrap 256 7 8 TimeUnit ${coord:months(256)} expr coord-job-submit-freq ${coord:months(coord:months(7))} ,oozie,1
" cluster locs racks conf waitForReplication getBlockManager dir createFile FileSystem getPath getFileStatus exclude getFileBlockLocations getWorkingDirectory workingDir dfs.hosts.exclude getFileSystem  ie we didn't remove the replica on the host on /rack1. getNameNode  be impossible to respect the rack policy). numDataNodes mkdirs Long name  Configure an excludes file testNodeDecomissionWithOverreplicationRespectsRackPolicy getFirstBlock waitForDecommission shutdown ns  Lower the replication factor so the blocks are over replicated /rack2 /rack1 fs substring top getDatanodeManager assertTrue getTopologyPaths     * Test that rack policy is still respected when blocks are replicated    * due to node decommissioning, when the blocks are over-replicated.     refreshNodes excludeFile writeFile build/test/data/temp/decommission DFSTestUtil b set  All hosts are on two racks, only one host on /rack2 getConf filePath toUri length setReplication REPLICATION_FACTOR /testFile build getLocal localFileSys getNamesystem startsWith ",hadoop,1
END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL oozieUrl MockDagEngineService run assertEquals 0 args call -oozie reset job -definition SERVLET_CLASSES testJobDefinition runTest ,oozie,1
cluster getBlockLocations NameNodeAdapter getMetrics findAndMarkBlockAsCorrupt bm NS_METRICS fs delete createFile file CorruptBlocks get block assertGauge testCorruptBlock getBlock PendingReplicationBlocks ScheduledReplicationBlocks  Create a file with single block with two replicas getNameNode getTestPath rb updateMetrics getLocations toString  Corrupt first replica of the block ,hadoop,1
" Object under test conf Allowed methods do not match  destroy filter values compareTo put filterConfig Assert assertTrue  initialize filter Allowed headers do not match getAllowedMethodsHeader example.com init  destroy filter values and clear conf Content-Type,Origin  verify filter values X-Requested-With,Accept getAllowedHeadersHeader clear destroy  Setup the configuration settings of the server CrossOriginFilter areOriginsAllowed newexample.com filter GET,HEAD testCrossOriginFilterAfterRestart GET,POST ",hadoop,0
testProdMode /base/middle/app/mode/prod Request CoreMatchers equalTo  Server runs in Test mode. This route is Prod. assertThat makeRequest url Result path Assert response GET testServerUrl ,ninja,0
TEST_JAR_NAME  make a simple zip jstream Manifest-Version: 1.0 Created-By: 1.8.0_1 (Manual) data getBytes unjarDir setSize TEST_ROOT_DIR unjar-path testUnJar2 write close META-INF/MANIFEST.MF getUnjarDir RunJar unJar putNextEntry unJar should throw IOException. e StandardCharsets any data here GenericTestUtils would create file outside of fail closeEntry jarFile MATCH_ANY assertExceptionContains ../outside.path je  Unjar everything ,hadoop,0
add testDelegationTokenSelector SomeUser1 SomeUser2 selectToken JobTracker unchecked MY-SERVICE1 MY-SERVICE2 assertEquals stopThreads ds generateDelegationToken setService  Creates a collection of tokens Assert t KIND dtSecretManager token1 token2 startThreads tokens  try to select a token with a given service name (created earlier) ,hadoop,0
date scriptExecutor session  Given update simple simplemap Eq should_dsl_update_map_addAll  When of where id row ten table executeScriptTemplate containsEntry RandomUtils manager simpleMap_AddAllTo one new_twenty simpleMap nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap getMap hasSize  Then Long buildDateKey fromBaseTable dsl SELECT simplemap FROM simple WHERE id =  thirty ,achilles,1
"getName user.name conf asList System Assert StringUtils assertNotNull get join getGroups testService init set getProperty getConf g destroy groups services , Services size assertNotSame Arrays ",oozie,1
 getParsedType parseParameter asdfasdf is Matchers assertThat nullValue param1 0 000 -123 testIntegerParamParser 123 integerParamParser validation ,ninja,0
in e Premature EOF from inputStream  getMessage assertEquals fail IOUtils skipFully after skipping 0 byte(s). inArray after skipping 1 byte(s). reset close testSkipFully mark expected to get a PrematureEOFException after skipping 5 byte(s). ,hadoop,0
ninjaCache parseDuration cache 10s TimeUtil verify expiration safeAdd testSafeAdd value key ,ninja,0
text/html assertTrue isTextual contextType smoke getSubType html assertEquals ContentTypeUtil ,logback,0
"mapreduce.job.cache.files  lm jobConf assertFalse user.name  when there is prepare block in workflow XML fs createJobConf testSetupLauncherInfoHadoop2_0_2_alphaWorkaround 1@a aa.jar#aa.jar assertTrue get getBoolean getNameNodeUri set actionConf 1@a-0 getConf actionDir a.jar,aa.jar#aa.jar assertEquals getFileSystem getAuthority Services 1 getTestUser newDir fs.default.name setupLauncherInfo  Setting up the job configuration oozie.hadoop-2.0.2-alpha.workaround.for.distributed.cache getFsTestCaseDir setBoolean ",oozie,1
"setName other parsedList default:user:user1::,default:mask:: Parsed Acl not correct parseAclSpec user::,user:user1:,group::,group:group1:,mask::,other::, defaultUser group mask owner user1 add testMultipleAclSpecParsingWithoutPermissions AclEntryScope AclEntryType namedUser expectedList AclEntry assertEquals setType group1 namedGroup build setScope defaultMask ",hadoop,0
HttpHeaders process testResponseContentEntityUnknownContentLength HttpStatus getFirstHeader h1 chunked interceptor assertEquals h2 getEntity setEntity getValue Assert assertNull EmptyInputStream response assertNotNull context OK ,httpcore,0
cluster conf testFileCreationDeleteParent:   create file2. createFile waitActive  This ensures that leases are persisted in fsimage. ipc.client.connection.maxidletime  move dir1 while file1 is open newfile testWhileOpenRenameParentToNonexistentDir  2s DFSConfigKeys format  create file1. getFileSystem Test 2************************************ setInt  persistent leases from fsimage. stm2 MAX_IDLE_TIME stm1 /user/dir1 nnport /user/dir2 /user/dir3 getNameNodePort shutdown nameNodePort  create cluster fs System sleep hflush assertTrue close writeFile dir3 Created file  dir2 dir1 TestFileCreation Thread checkFullFile dfs.support.append build rename file2 exists file1 setBoolean ,hadoop,1
getJobTrackerUri getName isMainSuccessful <java> assertFalse getStatus createContext actionXml FAILED/KILLED isSuccessful assertTrue LauncherMapper <arg>ex</arg> context end waitFor <job-tracker> getData isCompleted getNameNodeUri </java> ae </main-class> </job-tracker> runningJob getAction assertEquals testExceptionSubmitError check getExternalStatus <name-node> <main-class> </name-node> assertNull WorkflowAction submitAction evaluate isComplete ,oozie,1
door getClassNameViaImplicitRules defaultComponentRegistry assertEquals compClass setter AggregationType testgetClassNameViaImplicitRules ,logback,0
actionNum nominalTime testCoordActionGet getTime getActionNominalTime actionNomialTime getId DateUtils cleanUpDBTables addRecordToCoordActionTable appPath d1 addRecordToCoordJobTable parseDateOozieTZ d2 actionXml CoordinatorJob coord coord-action-get.xml _testGetActionForDates CoordinatorAction job getCoordActionXml getFsTestCaseDir ,oozie,1
setName renaming is not allowed fail context renameTest ,logback,0
 bindpass CredentialProviderFactory getCredential conf ourUrl delete createCredentialEntry assertArrayEquals file  make sure we get back the right key Assert storepass flush provider get  create new aliases JavaKeyStoreProvider getCredentialEntry  ensure that we get nulls when the key isn't there test.jks mapping set  extract password printStackTrace e getTestDir getProviders toUri GenericTestUtils assertEquals testDir LdapGroupsMapping jksPath getPassword assertNull invalid-alias ://file testConfGetPassword toString getBaseConf ,hadoop,0
"JMSTopicService  = workflow, ${username} setupServicesForTopic coord get init getTopicPatternProperties set printStackTrace getConf workflow e =coord getMessage destroy jmsTopicService assertEquals services props fail getValue Services testTopicProperties2 AppType ",oozie,1
"getName ContentType listener CoreMatchers equalTo setExceptionCallback AsyncServerBootstrap listen IOReactorConfig Assert getDuration create https /stuff setLookupRegistry getCode CN=localhost,OU=Apache HttpComponents,O=Apache Software Foundation getPeerPrincipal requester localhost setStreamListener HttpStatus LoggingExceptionCallback tlsVersion LoggingHttp1StreamListener setIOSessionListener resultFuture1 sslSession * setSoTimeout Method assertThat execute LoggingConnPoolListener SecureAllPortsStrategy greaterEquals TIMEOUT response1 server testTLSSuccess setIOReactorConfig createClientSSLContext notNullValue bootstrap H2RequesterBootstrap setConnPoolListener setTlsStrategy sslSessionRef some stuff setIOSessionDecorator createServerSSLContext getHead get body1 verify getAddress TLS getAndSet SSLTestContexts set address getBody custom start getProtocol parse sslEngine target getTimeUnit LoggingIOSessionDecorator getPort build future LoggingIOSessionListener getSession register message1 ",httpcore,0
date scriptExecutor DowngradingConsistencyRetryPolicy session withConsistencyLevel  Given simple SELECT value FROM simple WHERE id =  Eq delete QUORUM  When of where id row value table executeScriptTemplate logAsserter prepareLogLevelForDriverConnection isNotNull should_dsl_delete_with_options RandomUtils manager one nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap assertConsistencyLevels isTrue withRetryPolicy  Then isNull Long buildDateKey fromBaseTable dsl ,achilles,1
"addToken getCachedFS foo unchecked ugiA2 conf createRemoteUser assertSame fsA1 bar  and so are different.  file system. fsB fsA newConf assertNotSame mock  Since the UGIs are the same, we should have the same filesystem for both  corresponding to the two UGIs ugiA ugiB t1 UserGroupInformation testCacheForUgi ",hadoop,0
applyMixedCase item getConf  test a matching name (different case) apply name setup /directory/path/NaMe assertEquals mockFs Result ,hadoop,0
 ReflectionTestUtils -static/** assertFalse includedDeltas getField unchecked includes static/** asList contains resourceMatcher assertTrue templates/** Arrays ,spring-boot,1
" Try to add the same token through configuration and file expectedToken1 tokenPath1 testTokenKind1 cred0 testTokenKind0 cred1 getBytes found1 found0 assertArrayEquals password ugi encodeToUrlString expectedToken0 UserGroupInformation copyToken passwordImportConfig service1 GenericTestUtils writeTokenStorageFile tokenBase64 , service0 ,badtoken CommonConfigurationKeysPublic Expected token testTokenService0 not found:  testTokenImportService0 size identityImportConfig reset  Check if the tokens were loaded testTokenImportService1 getRandomizedTestDir outCred dt.token getAllTokens outCred1 getCredentials ugi1 Expected token testTokenService1 not found:  assertTrue identity getIdentifier badfile setKind testImportTokensFromConfig workDir setConfiguration addToken set getAbsolutePath assertEquals getLoginUser getService Tokens:  token  Add a token from a file setService equals  Add a base64 token toString config ",hadoop,0
@ closeTrx coordClient getStore getTime LocalOozie 2009-12-15T01:00Z Could not update db. getStatus -testCoordRerun-C getCoordClient get beginTrx CoordinatorAction reRunCoord commitTrx actionNum RestConstants printStackTrace store1 e store2 testCoordRerunDate1 assertEquals store addRecordToJobTable jobId Services fail CoordinatorJob addRecordToActionTable assertNotSame actionId 0000000- action1 action2 coord-rerun-action1.xml getCoordinatorAction ,oozie,1
appendIfExists noneWithCodec  Verify failure if the compression details are different or not Provided ROOT_PATH keyClass compressOption conf fs delete two three verifyAll4Values wrongCompressOption file  Codec should be ignored SequenceFile four testseqappendnonecompr.seq close deleteOnExit testAppendNoneCompression one fail createWriter Expected IllegalArgumentException for compression options  Verify failure if the compression details are different valueClass writer compression CompressionType verify2Values Writer append ,hadoop,0
"testToString DataChecksum(type=CRC32, chunkSize=512) toString assertEquals DataChecksum newDataChecksum ",hadoop,0
cluster testReplDueToNodeFailRespectsRackPolicy ns  only 1 rack for all the replicas racks dm conf /rack2 getBlockManager waitForReplication /rack1 fs createFile  short one rack and therefore need one replica     * Test that when a block is replicated because a replica is lost due    * to host failure the the rack policy is preserved.     getDatanodeManager  Create a file with one block with a replication factor of 2 get  it should have been replicated within the same rack. stopDataNode DFSTestUtil b getDataNodes getConf filePath dnId getFileSystem dataNode REPLICATION_FACTOR getNameNode datanodes /testFile  Last datanode is on a different rack size build removeDatanode numDataNodes  calling removeDatanode and stopping it. idx getFirstBlock shutdown getDatanodeId getNamesystem ,hadoop,1
closeTrx coordClient getStore LocalOozie Could not update db. getStatus testCoordRerunCleanup getCoordClient beginTrx CoordinatorAction create commitTrx waitFor bean actionNum printStackTrace store2 getFileSystem jobId fail CoordinatorJob  after cleanup _SUCCESS addRecordToActionTable success mkdirs actionId /coord-input/2009/12/14/11/00 evaluate getCoordinatorAction @  before cleanup getTime assertFalse appPath fs -testCoordRerun-C coord assertTrue get reRunCoord outputDir RestConstants e store addRecordToJobTable Integer Services getCoordActionInfo assertNotSame exists 0000000- toString action2 coord-rerun-action1.xml getFsTestCaseDir ,oozie,1
unsupportedFSLayoutVersion outputOfFileDistributionVisitor  the fsimage file once and use it for multiple tests. delete truncatedFSImage originalFsimage originalFsImage shouldn't be null outputOfLSVisitor assertNotNull exists  Tests: testOIV initFsimage ,hadoop,1
conn setRequestMethod IS_SECURITY_ENABLED getId put bundleJobBean endtime=2011-12-01T05:00Z /v1/job/* id Job runTest MockCoordinatorEngineService RestConstants openConnection addRecordToBundleJobTable HttpServletResponse assertEquals params url PUT call testBundleEngineChange xDataTestCase getResponseCode reset createURL changeValue ,oozie,1
conn setRequestMethod IS_SECURITY_ENABLED testJobInfo put assertTrue get content-type runTest JsonTags RestConstants openConnection MockDagEngineService HttpServletResponse assertEquals parse params getInputStream url JSONValue call /v0/job/* getHeaderField size obj GET getResponseCode reset createURL startsWith ,oozie,1
"next assertFalse value2=whatever hit  without filter Assert  with filter, first & last assertTrue way-off  with filter, no match headers match testFirstLastOneNone hasNext assertEquals  with filter, one match value3;tag=nil single 0 1 2 3 mismatch value1, value1.1 value0 ",httpcore,0
fail Assert buffer IndexOutOfBoundsException should have been thrown append substring stuff substringTrimmed testSubstringIndexOfOutBound ,httpcore,0
"cursor    getName assertFalse test; test1 =  stuff   ; test2 =  ""stuff; stuff""; test3=""stuff testNVParseAll test1 Assert assertTrue getPos buffer test; test1 =  stuff   ; test2 =  ""stuff; stuff""; test3=""stuff"",123 test atEnd length assertEquals stuff; stuff params parseParameters getValue test2 test3 append stuff ",httpcore,0
bundleJobGetExecutor testBundleRerun2 addRecordToBundleActionTable addRecordToBundleJobTable getId assertEquals getStatus execute addRecordToCoordJobTable call CoordinatorJob Services assertNotNull get action1 Job job action2 jpaService ,oozie,1
 thenReturn contextPath is getContextPath assertThat when getReverseRouteWithMethodReference ref router route2 route /ref getReverseRoute ninjaProperties ,ninja,0
processWatchEvent data becomeStandby assertFalse testSuccessiveStandbyCalls when ZK_LOCK_NAME times Assert  is standby. no need to notify anything now assertTrue  monitoring should be setup again after event is received mockEvent getPath verify Ids create  another joinElection called. verifyExistCall  monitor is set again mockApp stat intValue thenReturn  lost election enterNeutralMode processResult  make the object go into the monitoring standby state elector Code  still standby. so no need to notify again isMonitorLockNodePending mockZK setEphemeralOwner CreateMode Mockito getType joinElection mock Event getSessionId ,hadoop,0
@ timeOutCreationTime checkCoordAction  timeout. TZ testTimeout addInitRecords substring System Thread call sleep currentTimeMillis CoordinatorAction missingDeps actionId hdfs:///dirx/filex indexOf setCoordActionCreationTime ,oozie,1
server getDefaultSocketFactory testRTEDuringConnectionSetup conf when doAnswer assertTrue StringUtils client info address e LOG RANDOM Expected an exception to have been thrown start  Call should fail due to injected exception. stringifyException caught expected exception  (i.e. it should not have cached a half-constructed connection) nextLong spyFactory getConnectAddress call fail contains NetUtils createSocket answer stop Mockito reset Injected fault spy  throw an RTE when setSoTimeout is called. ,hadoop,0
StandardCharsets assertEquals getBytes EntityUtils Assert bytes assertNotNull toByteArray Message content testUnknownLengthContentToByteArray bytes2 entity ,httpcore,0
"startServerProduceConsumeTopics inputToUpdate getName log ConfigUtils shouldBeModel update updates put startMessaging getFirst UP key  Else should be just an int info models oryx.speed.streaming.block-interval-sec assertEquals MODEL message , getConfig Integer parseInt testSpeedLayer contains oryx.speed.streaming.generation-interval-sec getSecond  it's an input converted to update overlayConfig receivedUpdates overlayOn oryx.speed.model-manager-class config Received {} models, {} inputs converted to updates, and {} other updates ",oryx,1
DiskValidatorFactory testGetInstanceOfNonExistClass getInstance non-exist ,hadoop,0
request p1 adapter containsKey query  change the request from what is expected. unchecked responseExpectations execute remove fail Assert requestHandler framework QUERY assertTrue runTests get newFrameworkAndSetAdapter defaultURI addTest removeParameter WebServerTestingFrameworkException should have been thrown ,httpcore,0
result handleResult context equalTo fallbackContentType getContentType testThatFallbackContentTypeWorks resultHandler assertThat contentType Result ,ninja,0
testGetSLAEventsForCoordActionId filterListAction1 assertEquals createFilterList list coordActionId1 execute jobid Services slaEventsGetCmd size assertNotNull get jpaService ,oozie,1
value5 fileResource1 getResource Configuration value2 value1 value4 value3 conf jconf put CONFIG getKey getProperties endConfig testDumpConfiguration dumpConfiguration newValue1 newValue2 getIsFinal  efficient retrieval outWriter fileResource  check for consistency in the number of properties parsed in Json format. defaultLength jsonStr mapper CONFIG2 appendProperty  check if the value and resource of test.key1 is changed out  add 3 keys to the existing configuration properties addResource prop get close  check for other keys which are not modified later test.key5 readValue test.key6 test.key3 confDump test.key4 set length programmatically startConfig assertEquals  change few keys in another resource file getValue ${test.key5} toString  loaded as final parameter test.key1  and expansion of properties test.key2 ,hadoop,0
addNode def start assertEquals WorkflowInstance getStatus wf 1 <worklfow-app/> testEmptyWorkflow end job evaluate waitFor ,oozie,1
 Resuming job getEventStatus getUser getWorkflowInstance EventStatus getId poll  Suspending job WorkflowInstance getStatus  Starting job getEndTime addRecordToWfJobTable assertNotNull get getStartTime WorkflowJob event wfInstance wfJobGetCmd wfAction getAppName start assertEquals execute call  Killing job Services testWorkflowJobEvent size  Successful job (testing SignalX) @one _createWorkflowJob setWfInstance job jpaService AppType queue getAppType ,oozie,1
SecureFilter testThatUSERNAMEIsCorrect equalTo assertThat username ,ninja,0
touched getCanonicalPath methodDir assertHomeResolveFailed E_NOT_DIRECTORY FileUtils touch deleteQuietly testHadoopHomeNotADir ,hadoop,0
date session  Given insert SELECT * FROM simple WHERE id =  crud sleep should_insert_with_ttl  When id row value RandomUtils manager one nextLong assertThat execute usingTimeToLive Thread  Then isNull Long buildDateKey entity ,achilles,1
init destroy getId assertEquals services setAppNamespace getStatus execute addRecordToCoordJobTable call Services CoordinatorJob coordJobGetCmd SchemaService assertNotNull get setSystemProperty true StatusTransitService testCoordSuspendAndResumeForPrepWithBackwardCompatibility job jpaService ,oozie,1
verifyInterruptionDoesNotPreventLogging listAppender currentThread  and https://jira.qos.ch/browse/LOGBACK-1247 isInterrupted valueOf start interrupted  the interruption needs to be consumed Thread Integer addAppender stop assertTrue doAppend interrupt verify asyncAppenderBase ,logback,0
 position read fname stat positionReadOption assertEquals numTimes testWriteAndRead rdBeginPos blockSize wrChunkSize Assert filenameOption testReadPosCurrentBlock ,hadoop,1
"<execution>LIFO</execution> </controls> <datasets>  submitJob getMissingDependencies /workflows/${YEAR}/${MONTH}/${DAY}</uri-template>  <done-flag></done-flag> </dataset> testEmptyDoneFlag conf <data-in name=""A"" dataset=""local_a""> <instance>${coord:current(0)}</instance> </data-in>   getActions </input-events>  getStatus appPath System writeToFile appXml actionStatus <dataset name=""local_a"" frequency=""${coord:days(1)}"" initial-instance=""2009-02-01T01:00Z""  assertTrue file:// getTestCaseDir UNIT_TESTING get CoordinatorAction ..Missing deps= action missingDeps xmlns=""uri:oozie:coordinator:0.1""> <controls> <timeout>10</timeout> <concurrency>2</concurrency>  waitFor timezone=""UTC""> <uri-template>file:// getCoordJob coordinator.xml ce set <coordinator-app name=""NAME"" frequency=""${coord:days(1)}"" start=""2009-02-01T01:00Z"" end=""2009-02-01T02:00Z"" timezone=""UTC""  <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  assertEquals <action> <workflow> <app-path>hdfs:///tmp/workflows2/</app-path>  </configuration> </workflow> </action> </coordinator-app> OozieClient jobId getTestUser size </datasets> <input-events>  /workflows/2009/02/01 File actions evaluate ",oozie,1
getSubject setCharset  ///////////////////////////////////////////////////////////////////// replyTo2@domain mail value2 getReplyTo value1 subject MailImplTestHelper replyTo1@domain getCharset bodyText assertTrue getCcs get getBccs bodyHtml getMailImplWithDemoContent getFrom to1@domain header2 header1 getHeaders mailImpl cc2@domain from1@domain getTos cc1@domain testThatMailImplWorksAsExpected contains getBodyHtml bcc1@domain bcc2@domain getBodyText utf-8 equals to2@domain ,ninja,0
play server request User-Agent assertCode assertBody Content-Type: text/plain assertTrue assertContainsHeaders get await client AsyncApiTest addHeader abc receiver getHeaders takeRequest User-Agent: AsyncApiTest setBody url / enqueue getUrl contains build header ,okhttp,1
de franÃ§ais en-US en-CA NinjaConstant language testGetWithContextAndResult when getCookie result of get deutsch context english  test that result overwrites context AcceptHeader builder lang ok Cookie de-DE Optional thenReturn anyString en assertEquals  and the result overwrites it again... Results build Mockito  test with context Accept Header name messages getStringArray en-UK fr-FR ninjaProperties getAcceptLanguage  that forced language from context works with empty result setLanguage ,ninja,0
addRecordToWfActionTable coordActionGetCmd getId getNumDaysToNotBePurged WorkflowInstance getStatus addRecordToCoordActionTable coordJob wfJob getEndTime addRecordToWfJobTable assertNotNull get Workflow Job should not have been purged CoordinatorAction WorkflowJob wfAction wfJobGetCmd wfActionGetCmd Coordinator Action should not have been purged assertEquals execute addRecordToCoordJobTable Coordinator Job should not have been purged call Services CoordinatorJob 1 coordJobGetCmd fail coord-action-get.xml WorkflowAction coordAction SUCCEEDED jpaService Workflow Action should not have been purged testPurgeCoordWithWFChild2 ,oozie,1
headerIterator Assert headergroup assertNotNull assertFalse hasNext testIterator ,httpcore,0
play server addHeader getSequenceNumber takeRequest sameConnectionRedirectAndReuse setSocketPolicy assertContent assertEquals setResponseCode setBody Location: /foo / enqueue getUrl SHUTDOWN_INPUT_AT_END This is the new page! HttpURLConnection client open ,okhttp,1
ContentTypes testGetJsonP createTemplateEngineManager getTemplateEngineForContentType assertThat instanceOf ,ninja,0
 and more stuff Assert buffer2 testAppendCharArrayBuffer buffer1 toString assertEquals append stuff stuff and more stuff ,httpcore,0
cluster excluded nodes with ~ scope should be considered excluded nodes without ~ scope should be considered getNewNode  create exclude list  add one existing node to exclude list 4 nodes should be available with extra excluded Node remove NodeBase  remove a node from the cluster 1 node should be available No nodes should be considered for non-exist scope  getting count with non-exist scope. testCountNumNodes 4 nodes should be available excludedNodes add  create the topology assertEquals /non-exist node1 node4 excluded nodes with ROOT scope should be considered node5 deadNode node2 getNetworkLocation node3 NetworkTopology /d1/r2 excluded nodes with rack scope should be considered /d1/r1 getInstance countNumOfAvailableNodes /d1/r4 ~ /d1/r3  adding the node in excluded scope to excluded list ,hadoop,0
HttpHeaders process HttpStatus getFirstHeader h1 interceptor assertEquals h2 getEntity testResponseContentEntityContentLenghtDelimited setEntity getValue Assert assertNull EmptyInputStream response assertNotNull context OK 10 ,httpcore,0
assumeFalse testEnvHelper WINDOWS Assume testEnvVarsWithInheritance ,hadoop,0
innerFilter Context shouldNotLeakContextForNestedRequest init res chain mockFilterConfig assertEquals countActive mockFilterChain mockRequest mockResponse doFilter victim req ,wroj4,1
subwfJob3GetCmd addRecordToWfActionTable Workflow Action 2 should have been purged WorkflowInstance getStatus wfAction5GetCmd SubWorkflow Action 5 should have been purged wfAction1GetCmd assertNotNull Workflow Action 5 should have been purged SubWorkflow Job 3 should have been purged subwfAction3GetCmd wfJobGetCmd subwfJob2GetCmd SubWorkflow Action 2 should have been purged SubWorkflow Job 1 should have been purged subwfAction4GetCmd SubWorkflow Job 4 should have been purged execute 1 fail 2 3 4 WorkflowAction 5 wfAction2GetCmd Workflow Action 3 should have been purged je subwfAction5 subwfJob1GetCmd getId SubWorkflow Job 2 should have been purged subwfAction5GetCmd subwfJob5GetCmd wfJob subwfAction1GetCmd Workflow Job should have been purged addRecordToWfJobTable getErrorCode get subwfJob1 Workflow Action 1 should have been purged WorkflowJob subwfJob5 subwfAction1 subwfJob4 subwfAction2 SubWorkflow Action 4 should have been purged subwfJob3 subwfAction3 subwfJob2 subwfAction4 wfAction3GetCmd wfAction4GetCmd Workflow Action 4 should have been purged assertEquals wfAction1 SubWorkflow Action 3 should have been purged wfAction2 wfAction3 wfAction4 wfAction5 call Services testPurgeWFWithSubWF3MoreThanLimit SubWorkflow Action 1 should have been purged SubWorkflow Job 5 should have been purged subwfAction2GetCmd ErrorCode jpaService subwfJob4GetCmd ,oozie,1
cluster blockfile datanode findBlockFile conf createFile getBytes waitActive testLeaseExpireHardLimit start leasePeriod  should be replicated to  getNamenode setLeasePeriod write  datanodes. getBlockPoolId in getFileSystem something setInt dfs getWrappedStream successcount testLeaseExpireHardLimit successful numDataNodes actualRepl DATANODE_NUM Long getDataNode DFS_HEARTBEAT_INTERVAL_KEY getLocations shutdown getBlockLocations getLocatedBlocks  create cluster foo System out sleep hflush getBlockId assertTrue closeStream get blockfile= fpath  create a new file. close DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY blk datanodeinfo getBlock b f  wait for the lease to expire assertEquals TestFileCreation successcount= DIR readLine getStoredBlock getNumCurrentReplicas Thread testLeaseExpireHardLimit locatedblock IOUtils build locations  namenode triggers lease recovery dataset locatedBlockCount ,hadoop,1
server ContentType testForceHttp2 listener CoreMatchers notNullValue equalTo connectFuture some stuff listen endpoint Assert getDuration HttpVersionPolicy getHead get getAddress https /stuff getCode HttpVersion connect requester localhost getVersion address HttpStatus start resultFuture1 Method assertThat execute target getTimeUnit getPort future TIMEOUT response1 message1 ,httpcore,0
rc isTooSoon assertTrue recoveryNotNeededAfterInit ,logback,0
executeScriptTemplate all scriptExecutor manager deleteByPartitionKeys session  Given isEmpty should_delete_by_partition rows assertThat execute SELECT * FROM simple WHERE id =  ImmutableMap crud SimpleEntity/insert_2_rows_same_partition.cql  When of  Then id ,achilles,1
server requestBytes start serverAddress awaitResponseTimeout generateRandomBytes clientCallable conf sendResponse assertEquals getConnectAddress clientThread NetUtils Assert stop awaitInvocation future response get testDeferredResponse ,hadoop,0
INTERVAL getOwnAvg getOwnMin getTotalMax start assertEquals cron1 cron2 addCron Thread sleep timer getTicks getValue getTotalSquareSum stop getTotalAvg getOwnMax getTotalMin getOwn getTotal testTimer getOwnSquareSum ,oozie,1
wfUpdateCmd2 getId WorkflowInstance  first update; wfBean addRecordToWfJobTable  second update; assertNotNull wfUpdateCmd1 wfBean2 get wfBean1 WorkflowJob testWorkflowJobUpdate getStatusStr setAppName test RUNNING wfGetCmd assertEquals execute setStatus Services SUCCEEDED job jpaService ,oozie,1
next cluster metaIndex listener TEST_UTIL assertRegionIsBackOnline  Figure the index of the server that is not server the .META. getRegionServer sleep iterator otherServerIndex metaHRS getHServerInfo assertTrue unregisterRegionServerOperationListener abortRegionServer testRegionCloseWhenNoMetaHBase2428 hri  Add our RegionServerOperationsListener info getServerAddress LOG getOnlineRegions getRegionServerThreads  Now close the server carrying meta. getRegionServerOperationQueue getServerWithMeta isDone registerRegionServerOperationListener master getRegionInfo Threads otherServer  Get a region out on the otherServer. HBase2428Listener Running testRegionCloseWhenNoMetaHBase2428 size  First wait on receipt of meta server shutdown message. getHBaseCluster  (Multiple by two to add in some slop in case of GC or something). getMaster  Assert the closed region came back online getCloseCount ,hadoop,1
" array contains both local node, local node group & local rack node cluster dataNodes  array contains local node & rack node assertTrue computeNode testSortByDistance  array contains local node & local node group  array contains local-nodegroup node (not a data node also) & rack node testNodes sortByDistance ",hadoop,0
cluster conf testFileCreationDeleteParent:   create file2. createFile waitActive  This ensures that leases are persisted in fsimage.  rename file3 to some bad name testWhileOpenRenameParent ipc.client.connection.maxidletime  move dir1 while file1 is open newfile  2s DFSConfigKeys printStackTrace format  create file3  create file1. getFileSystem setInt  persistent leases from fsimage. stm2 stm3 MAX_IDLE_TIME stm1 nnport /user/dir2 /user/dir3 mkdirs getNameNodePort shutdown nameNodePort  create cluster /user/dir3/dir1 fs System sleep /user/a+b/dir1 hflush assertTrue Test 1***************************** close writeFile e dir3 Created file  dir2 dir1 TestFileCreation Thread checkFullFile dfs.support.append build rename file2 file3 exists file1 $  setBoolean ,hadoop,1
" CoordELFunctions TZ action-actual-time="" DateUtils  Sleep for sometime as it gets requeued with 10ms delay on failure to acquire write lock ${coord:latestRange(-3,0)}  before and after action creation time parseDateOozieTZ  Datasets should be picked up based on current time and not action creation/actual time. getTestCaseDir file:// action setCreatedTime indexOf /2009/01/08/ resolvedList execute setActionXml /2009/03/05 jobId contains CoordCommandUtils /2009/02/19/ job getMissingDependencies getTime getId 2009-02-16T23:59 </uris> replaceAll /2009/02/05 substring testActionInputCheckLatestCurrentTime actionXML sleep /2009/02/12/ <uris> assertTrue get createDir startTime  Update action creation time ""> latest 2009-02-15T23:59 action-actual-time=""2009-02-15T01:00 /2009/03/05/ /2009/01/22/ /2009/02/12 getConf action-actual-time="".*""> /2009/02/19 assertEquals -TestCoordActionInputCheckXCommand-C addRecordToCoordJobTable Thread call Services @1 getActionXml 0000000- endTime 2009-02-15T01:00 actionCreationTime jpaService setBoolean /2009/02/05/ ",oozie,1
channel outStream Assert constructString Like hello and stuff flush RUSSIAN_HELLO inbuf tmp writeLine chbuffer s1 s2 s3 StandardCharsets newDecoder SWISS_GERMAN_HELLO clear assertEquals fill readLine outbuf toByteArray newEncoder toString newChannel testMultibyteCodedReadWriteLine append outChannel ,httpcore,0
jobConf bundleJobGetCmd log submitCmd getId getStatus appPath Configuration parse error. read from DB : getJob assertNotNull get getAuthToken Job set getConf addRecordToBundleJobTable assertEquals execute bundle.xml call Services warn OozieClient testBundleKill3 toString ErrorCode job jpaService ioe ,oozie,1
conn setRequestMethod IS_SECURITY_ENABLED assertTrue json content-type /v1/admin/* Collections runTest testV1QueueDump JsonTags RestConstants openConnection containsKey HttpServletResponse assertEquals parse getInputStream url JSONValue call getHeaderField GET getResponseCode createURL startsWith ,oozie,1
OTHER_GROUP_NAMES ProxyUsers refreshSuperUserGroupsConfiguration assertAuthorized GROUP_NAMES DefaultImpersonationProvider  from the other test case!) getProxySuperuserUserConfKey conf PROXY_IP  From bad IP UserGroupInformation set proxyUserUgi 1.2.3.4 1.2.3.5 testWildcardUser AUTHORIZED_PROXY_USER_NAME * createRemoteUser REAL_USER_NAME assertNotAuthorized getTestProvider  From good IP  First try proxying a user that's allowed getProxySuperuserIpConfKey PROXY_USER_NAME realUserUgi createProxyUserForTesting ,hadoop,0
"       <value>A</value>        <name>a</name>    <job-tracker>foo</job-tracker>  expectedD validateAndParse   </prepare>      </property>  replaceAll   <archive>/tmp</archive>    <configuration>  wf-schema-valid-global.xml   </configuration>  app     <file>/tmp</file>      <mkdir path=""/tmp"" />  d getConf     <reducer>/mywc.sh</reducer>    <prepare>  testParserGlobal     <mapper>/mycat.sh</mapper>        <name>b</name>  assertEquals       <value>B</value>  </map-reduce> IOUtils parser   </streaming>    <streaming>  getResourceAsReader     <property>  getNode     <delete path=""/tmp"" />  <map-reduce xmlns=""uri:oozie:workflow:0.4"">    <job-xml>/tmp</job-xml>    <name-node>bar</name-node>  ",oozie,1
request getName getUserPrincipal testFilter getRemoteAddr knox@EXAMPLE.COM simple type when put doas actualUser doFilter proxyuser.knox.hosts getParameter init chain thenReturn proxyuser.knox.users testuser params assertThat servletRequest getRemoteUser Mockito response mock config isEqualTo 127.0.0.1 knox ,hadoop,0
prepare item2 item5ca item1 conf setRootExpression when setOut out Result find inOrder verify setOptions expr finish item1b item1a item5e item5d item5c createDirectories item5b item5a setErr fsCheck err test inOrderFsCheck apply thenReturn check processArguments  check expressions are called in the correct order any setConf anyInt verifyNoMoreInteractions mock getOptions item1aa item4 items item3 item5 ,hadoop,0
executorService testGetFormattedTimeWithDiff getFormattedTimeWithDiff run Executors System Method returned inconsistent results indicative of assertTrue StringUtils  a race condition await TimeUnit awaitTermination end FAST_DATE_FORMAT newFixedThreadPool start cyclicBarrier  Multithreaded Test GetFormattedTimeWithDiff() execute currentTimeMillis equals formattedTime2 formattedTime1 shutdown ,hadoop,0
"CreateFlag cluster  createNonRecursive() should throw FileNotFoundException   Overwrite a file in root dir, should succeed testFileCreationNonRecursive conf /testCreateNonRecursive fs expectedException delete System simulatedStorage out  Create a new file in root dir, should succeed Create a file in a non-exist dir using overwriteFlag path /non-exist- assertTrue Create of -testFileCreationNonRecursive nonExistDir close  Create a file in a non-exist directory, should fail createFlag Create a file when parent directory exists as a file Overwrite e EnumSet  Overwrite a file in a non-exist directory, should fail getFileSystem /testOverwriteNonRecursive  Overwrite a file when parent dir exists as file, should fail / Overwrite a file when parent directory exists as a file  Create a file when parent dir exists as file, should fail build  should throw ParentNotDirectoryException  path2 createNonRecursive path3 Overwrite a file in a non-exist dir using currentTimeMillis SimulatedFSDataset shutdown setBoolean ",hadoop,1
"createUserForTesting set  set conf, should again override assertFalse rules assertEquals conf KerberosName  explicitly set a rule  implicit init should honor rules already being set HADOOP_SECURITY_AUTH_TO_LOCAL RULE:[1:TEST2] RULE:[1:TEST3] someone RULE:[1:TEST1] assertTrue testSetConfigWithRules hasRulesBeenSet reset getRules setRules setConfiguration  set conf, should override UserGroupInformation ",hadoop,0
child_value session  Given insert crud  When id row value val RandomUtils manager child_val one getString nextLong assertThat execute SELECT * FROM entity_child getLong should_insert  Then Long isEqualTo entity ,achilles,1
rw assertFalse channel getBytes head Assert getChannel writeLine dump chbuffer close write fchannel testCodingFromFileChannelSaturated isCompleted testfile StandardCharsets createTempFile assertEquals encoder transfer outbuf header metrics append stuff ,httpcore,0
aee oozie.action.mapreduce.uber.jar.enable serv getConf e ActionExecutorException getMessage assertEquals MR003 testMapReduceWithUberJarDisabled Services contains originalUberJarDisabled getErrorCode assertTrue  this test is excluded by default) get _testMapReduceWithUberJar getBoolean oozie.mapreduce.uber.jar getErrorType setBoolean ,oozie,1
"init CoordELFunctions .datain.ABC.unresolved setVariable assertEquals coord-action-start ${coord:dataIn('ABC')} file:///tmp/coord/US/2009/1/30,file:///tmp/coord/US/2009/1/31 eval evalAndWrap testDataIn .datain.ABC expr Boolean ",oozie,1
"       <name>a</name>  expectedB validateAndParse   </prepare>      </property>  replaceAll   <configuration>    <arg>/tmp2/data.txt</arg>    <job-tracker>blah</job-tracker>    </configuration>      <mkdir path=""/tmp2"" />  <distcp xmlns=""uri:oozie:distcp-action:0.1"">  app   b       <value>A2</value>  testParserGlobalExtensionActionsLocalAlreadyExists getConf   <prepare>        <name>b</name>  assertEquals wf-schema-valid-global-ext.xml       <value>B</value>    <arg>/tmp/data.txt</arg>  </distcp> IOUtils parser     <delete path=""/tmp2"" />  getResourceAsReader     <property>  getNode   <name-node>meh</name-node>  ",oozie,1
" Verify that cp from a directory to a subdirectory fails cluster /test/dir1/dir2 myFile /test/mkdirs/myFile conf run -test Exception raised from DFSShell.run   This tests some properties of ChecksumFileSystem as well.      * Make sure that we create ChecksumDFS  -cat val -rm stringifyException /test/dir1 getFileSystem /test/dir1foo shell -touchz numDataNodes  First create a new directory with mkdirs mkdirs fileSys  this should succeed getUri shutdown myPath Exception raised from DFSShell.run:   re-create the files for other tests getLocalizedMessage  Verify that we succeed in removing the file we created assertFalse fs delete  Second, create a file in that directory. System testDFSShell assertTrue StringUtils -d -e -cp  Verify touch/test close writeFile  Verify that rm with a pattern -mkdir /test/mkdirs e /test/mkdirs/myFile*  Verify that we get an error while trying to delete an nonexistent file myFile2  this should fail assertEquals  Verify that we get an error while trying to read an nonexistent file -z setConf /test/mkdirs/myFile2 Not a HDFS:  /test/mkdirs/myFile1 args build  Verify that we can read the file args1 exists /test/mkdirs/noFileHere ",hadoop,1
 getName splits log System tableName Bytes hflush testSplit  Add edits for three regions. verifySplits howmany add ii splitLog edit :  toBytes rowName column j closeAndDelete Integer qualifier currentTimeMillis Region  toString family rollWriter HLog infos append column: ,hadoop,1
testCoordReRun4 END_POINTS IS_SECURITY_ENABLED -action oozieUrl run appPath assertTrue get create SERVLET_CLASSES close runTest app MockCoordinatorEngineService coordinator.xml RestConstants getContextURL assertEquals getFileSystem -rerun 0 args call -nocleanup -oozie mkdirs job getFsTestCaseDir ,oozie,1
"as requested, one exception! justThrowAnException fut e createStage getMessage handle assertEquals getCause checkingTheException 0 ref  TODO: check this. ex assertTrue IActor join isCompletedExceptionally getReference stage1 ",orbit,1
a http:// getActionId replace createCallBackUrl assertEquals getExternalStatus id=a testCallbacks cs status=@STATUS Services contains assertTrue assertNotNull get callback OK @STATUS ,oozie,1
" sla-END stage job is removed from map  2 hours ahead _createSLARegistration run runSLAWorker output testUpdateSLA action-1  test same job multiple events (start-miss, end-miss) through regular check assertNotNull CoordinatorAction addStatusEvent  1 hour back setExpectedEnd  test start-miss getJobId job-1 job-3 getEventQueue job-2 job-4 ehs CoordinatorJob contains setLength size isEnabled name sla1 AppType setExpectedStart sla2 addRegistrationEvent  Sla END - MET!!! SLAService EventStatus System  remains same as before since assertTrue get WorkflowJob  Sla START - MISS!!! assertEquals  1 hour ahead only for testing getSLACalculator  2 hours back  test same job multiple events (start-met, end-met) through job status event Services  test different jobs and events start-met and end-miss currentTimeMillis  1 hour ahead Sla START - MISS!!! toString  Sla START - MET!!! slas  Sla END - MISS!!! ",oozie,1
add getBuffer pool returnBuffer clear assertEquals testWeakRefClearing bufs System buf  GC. Weak refs should get cleared.  references from the pool. Lists  Allocate and return 10 buffers. newLinkedList gc countBuffersOfSize ,hadoop,1
init ${coord:user()} CoordELFunctions coord-job-submit-instances assertEquals coord-sla-create coord-action-create coord-action-start coord-job-submit-data test_user eval evalAndWrap coord-action-create-inst expr testUser coord-job-submit-freq coord-sla-submit ,oozie,1
fail expected timeout testAuthUrlConnectTimeout e renewer connect timed out consumeConnectionBacklog getMessage TEST_TIMEOUT assertEquals fs getDelegationToken ,hadoop,1
keepAlive Assert HttpStatus response assertFalse context No Content  Use HTTP 1.0 reuseStrategy testNoContentResponseHttp10 setProtocolVersion HttpVersion ,httpcore,0
 server  Test for single dependency which is already in the hcat server checkCoordAction populateTable hcat:// addInitRecords / call default /dt=20120430;country=usa testUpdateCoordTableSingleDep CoordinatorAction actionId tablename newHCatDependency db table ,oozie,1
date consistencyList_PrependAllTo scriptExecutor should_dsl_update_list_prependAll session LOCAL_ONE  Given update simple Eq consistencylist asList containsExactly QUORUM  When getList of where id row table executeScriptTemplate RandomUtils manager one nextLong assertThat TWO execute SimpleEntity/insert_single_row.cql ImmutableMap SELECT consistencylist FROM simple WHERE id =   Then Long buildDateKey fromBaseTable consistencyList dsl THREE ,achilles,1
reason adapter Assert assertNull checkRequestSupport assertRequestSupported reason should be null A reason this request is not supported. ,httpcore,0
"setName failed to delete  statusChecker  StatusPrinter.print(context); delete getCopyOfStatusList fat-testPrudentModeLogicalImplications.txt file assertTrue CoreTestConstants get doAppend context setContext setPrudent Got message [ sm ] Status msg1 getAbsolutePath Expecting status list size to be 2 or larger, but was  start getMessage diff appender setEncoder assertEquals setAppend getHighestLevel filename setFile statusList size stop isAppend exists testPrudentModeLogicalImplications getStatusManager Setting ""Append"" property startsWith ",logback,0
 getParsedType parseParameter asdfasdf is Matchers assertThat nullValue param1 0 000 -123 123 0.1 floatParamParser 123.1 -123.1 testFloatParamParser validation ,ninja,0
subwfJobGetCmd addRecordToWfActionTable getId WorkflowInstance getStatus SubWorkflow Action should have been purged wfJob Workflow Job should have been purged addRecordToWfJobTable getErrorCode assertNotNull get WorkflowJob wfAction subwfAction wfJobGetCmd testPurgeWFWithSubWF3 Workflow Action should have been purged SubWorkflow Job should have been purged wfActionGetCmd assertEquals execute subwfActionGetCmd call Services 1 fail WorkflowAction subwfJob ErrorCode je jpaService ,oozie,1
add process doFilterWithProcessors shouldThrowExceptionWhenProcessorFails processors processor fails ,wroj4,1
"bigEnough encode strangeWidth BarcodeFormat assertEquals getWidth matrix testQRCodeWriter  The QR should be multiplied up to fit, with extra padding if necessary getHeight assertTrue assertNotNull  We should also be able to handle non-square requests by padding them tooSmall strangeHeight writer http://www.google.com/  The QR will not fit in this size, so the matrix should come back bigger ",zxing,0
Cookie yummy argument ArgumentCaptor doNothing cookie setDomain capture is assertThat when unsetCookie getValue abstractContext addCookie getMaxAge build domain context builder forClass unsetCookieAddsCookieWithMaxAgeZero spy ,ninja,0
lookup getSymbolWidth There's no rectangular symbol for 50 data codewords getSymbolHeight assertEquals maxSize SymbolInfo SymbolShapeHint testSymbolInfo fail assertNull getErrorCodewords assertNotNull There's no rectangular symbol for more than 1558 data codewords fixedSize minSize info ,zxing,0
addNode def one start assertEquals WorkflowInstance getStatus two asList wf 1 fail ex getErrorCode <worklfow-app/> end testLoopSimple ErrorCode Arrays job ,oozie,1
cluster nameNodePort  create cluster conf testFileCreationDeleteParent:  fs System createFile waitActive  This ensures that leases are persisted in fsimage. sleep hflush Test 3************************************ assertTrue ipc.client.connection.maxidletime close writeFile newfile  2s DFSConfigKeys format  create file1. Created file  dir2 getFileSystem dir1 TestFileCreation testWhileOpenRenameToExistentDirectory setInt Thread  persistent leases from fsimage. checkFullFile MAX_IDLE_TIME dfs.support.append stm1 build /user/dir1 rename nnport /user/dir2 mkdirs getNameNodePort exists file1 shutdown setBoolean ,hadoop,1
input node loneColonShouldReadLikeAnyOtherCharacter transform nodeToStringTransformer propertyContainer0 makeNode assertEquals java:comp/env/jdbc/datasource ,logback,0
getParameterValues Violet enumArrayParamMultipleShouldBeParsed Blue thenReturn invoke when asList param1 Rainbow context create verify enumArrayParam Indigo Arrays mockController ,ninja,0
prepare scriptExecutor should_perform_bound_statement_typed_query session  Given simple 0 AM bind boundStatement  When of id table executeScriptTemplate isNotNull actual RandomUtils manager query nextLong assertThat SimpleEntity/insert_single_row.cql ImmutableMap getValue contains typedQueryForSelect  Then Long getOne SELECT * FROM simple WHERE id = :id ,achilles,1
fail Assert IllegalArgumentException must have been thrown (600) IllegalArgumentException must have been thrown (-1) EnglishReasonPhraseCatalog getReason testStatusInvalid IllegalArgumentException must have been thrown (99) ,httpcore,0
request getName converter convert Assert :scheme assertNotNull get host :authority header4 headers header3 addHeader header2 header1 assertEquals custom123 / header5 getValue testConvertFromMessageBasic size :method GET Value http :path ,httpcore,0
sys_prop_does_not_exist standalones add default_does_not_exist StandaloneHelper e thenReturn containsString resolveStandaloneClass getMessage newInstance  try to resolve using default assertThat when instanceOf resolvedStandaloneClass fail serviceLoader iterator mock  try to resolve system property  mock the service loader ,ninja,0
conn argThat inStream responseCaptor sendResponseHeader when setEntity receiveRequestHeader Assert assertNotNull context create Boolean getCode testExecutionEntityEnclosingRequest HttpStatus thenReturn ArgumentMatchers capture Method eq matches / never responseFactory newHttpResponse mock connReuseStrategy request getRequest httpservice flush forClass verify close process keepAlive ArgumentCaptor assertEquals sendResponseEntity assertSame getEntity errorResponse getValue Mockito response HttpCoreContext httprocessor handleRequest entity ,httpcore,0
cron  INTERVAL getStart TOLERANCE start assertEquals getEnd System Thread sleep stop realOwnDelay currentTimeMillis now getOwn getTotal testCron realTotalDelay ,oozie,1
init getAllSecrets AuthenticationFilter getCurrentSecret secretStr assertEquals secret secretProviderProps getBytes secretBytes assertArrayEquals Assert testGetSecrets setProperty secretProvider allSecrets ,hadoop,0
play ping android  play it back headerEntries  verify the peer received what was expected source System acceptFrame elapsedNanos stream openStreamCount TYPE_HEADERS peer nanoTime roundTripTime TimeUnit connection toMillis  Prevent the peer from exiting prematurely. takeFrame banana a b synReply read readTimeoutExpires assertEquals setReadTimeout fail  SYN_STREAM sendFrame SPDY3 getSource  PING synStream newStream startNanos ,okhttp,1
"ROWS_ONE  Expect all keys in all but two rows testRowOne-2  testRowOne-3 Bytes QUALIFIERS_ONE FAMILIES  Should see all keys in all rows but testRowTwo-2 VALUES expectedKeys verifyScanNoEarlyOut  Expect all keys in two rows  Match a two rows, one from each group, using regex expectedRows f testRow.+-2 ROWS_TWO toBytes kvs  Expect all keys in all but one row setFilter  testRowTwo-0 QUALIFIERS_TWO verifyScanFull .+-2  Match a single row, all keys testRowFilter CompareOp  Expect all keys in one row  testRowTwo-3  testRowTwo-2 ",hadoop,1
"#DFS-Hosts-excluded  getExcludesFile excludesFile excludesLen newExcludesFile assertFalse getExcludedHosts  test for refreshing hostreader wit new include/exclude host files HOSTS_TEST_DIR #This-is-comment  assertTrue #Hosts-in-DFS  node2  somehost3 # host3  somehost4  /dfs1.exclude getIncludesFile     * 1.Create dfs.exclude,dfs.include file    * 2.Write host names per line    * 3.Write comments starting with #    * 4.Close file    * 5.Compare if number of hosts reported by HostsFileReader    *   are equal to the number of hosts written     write somehost2  close getHosts testHostsFileReader host4 /dfs1.include hostDetails somehost4 # host4  host3 includesFile somehost4 somehost5  refresh assertEquals getHostDetails newIncludesFile node1 contains node2 hfp size efw somehost5 getIncludedHosts somehost3  ifw node1  somehost1  includesLen ",hadoop,0
"next isOne joe testAccessControlList drwho groups iter acl drwho tardis assertThat  tardis users iterator drwho  size drwho,joe tardis, users getUsers tardis isZero isEqualTo getGroups ",hadoop,0
SYSTEM_MODE END_POINTS IS_SECURITY_ENABLED getContextURL oozieUrl getSystemMode setSystemMode assertEquals wc call testSafeMode systemMode SERVLET_CLASSES runTest ,oozie,1
"testRLParse clear assertEquals Method getMethod parseRequestLine  Lots of blanks  GET /stuff HTTP/1.1 getProtocolVersion buf Assert GET /stuff HTTP/1.1 requestline name   GET    /stuff   HTTP/1.1    toString /stuff HttpVersion  typical request line append getUri  this is not strictly valid, but is lenient ",httpcore,0
 checkCoordAction addInitRecords getAvailableDependencyURIs partitionAvailable availableURIs assertTrue get CoordinatorAction mydb hcatUri newHCatDependency addMissingDependency hcat.server.com:5080 assertEquals pdms call Services contains src=search;datastamp=12;region=us assertNull size testUpdateCoordTableBasic actionId clicks getPartitionMap hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us ,oozie,1
NULL_STR ESCAPED_STR_WITH_COMMA escapeString assertEquals testEscapeString STR_WITH_ESCAPE STR_WITH_BOTH2 STR_WO_SPECIAL_CHARS STR_WITH_COMMA ESCAPED_STR_WITH_BOTH2 StringUtils EMPTY_STR ESCAPED_STR_WITH_ESCAPE ,hadoop,0
getPayloadContent read valueOf getStreamId assertEquals testReadEmptyFrame inBuffer readableChannel Assert assertNull getType payload FrameType getFlags frame ,httpcore,0
sub not created in src dir ContractTestUtils testRenameWithNonEmptySubDirPOSIX renameTestDir dest handleEmptyDstDirectoryOnWindows fs assertPathDoesNotExist path writeTextFile finalDir not created in src/sub dir  Accept only POSIX rename behavior in this test not deleted assertPathExists sub/subfile.txt pathToFile subfile.txt getFileSystem this is the file in src dir source.txt rlfs not renamed into dest/sub dir mkdirs src1 srcDir this is the file in src/sub dir rm srcSubDir not renamed into dest dir testRenameWithNonEmptySubDir ,hadoop,0
_testDoFilterAuthentication testDoFilterAuthenticationWithDomainPath ,hadoop,0
 getName when asList getInitParameterNames parseCookieMap setHeader Assert assertNotNull AUTH FAILED Set-Cookie management.operation.return cookie missing http://foo:8080/bar getRequestURL init cookieMap thenReturn anyString destroy eq fail never invocation testDoFilterAuthenticationFailure getInitParameter shouldn't get here true mock getArguments Arrays request sendError getHeader doAnswer dummyauth doFilter getCookies get verify value AuthenticatedURL chain addHeader AuthenticationFilter WWW-Authenticate HttpServletResponse assertEquals any filter args getMockedServletContextWithStringSigner answer Mockito response elements config ,hadoop,0
excludesFile lazyRefresh LazyDetails: no. of excluded hosts lazyDetails Details: no. of included hosts host2  getExcludedHosts finishRefresh host3  details getLazyLoadedHostDetails write close Details: no. of excluded hosts testLazyRefresh includesFile getHostDetails assertEquals host1  LayDetails: no. of included hosts hfp assertNull host4  size efw getIncludedHosts ifw Lazy host details should be null ,hadoop,0
"JMSTopicService bab addRecordToBundleActionTable cab getUser addRecordToWfActionTable  = workflow, getId WorkflowInstance getTopic addRecordToCoordActionTable setupServicesForTopic coord coord-action-for-action-input-check.xml addRecordToWfJobTable  As no default is specified, user will be considered as topic get CoordinatorAction wab cjb bjb WorkflowJob Job init set getBundleActionId printStackTrace getConf workflow e =coord addRecordToBundleJobTable getMessage destroy jmsTopicService assertEquals services addRecordToCoordJobTable fail getValue Services 1 CoordinatorJob WorkflowAction wfj testMixedTopic2 ",oozie,1
addRecordToBundleActionTable bundleActionJPA addRecordToBundleJobTable bundleId getId assertEquals execute addRecordToCoordJobTableWithBundle call sleep CoordinatorJob Services testBundleRerunKilledCoordinator assertNotNull get action1 Job job getPending jpaService ba ,oozie,1
Integer testComputeCapacity r testCapacity  Compute capacity for some 100 random max memory and percentage nextInt  Tests for boundary conditions where percent or memory are zero maxMemory percent ,hadoop,0
Integer fail Assert tmp testInvalidCharArrayAppend buffer IndexOutOfBoundsException should have been thrown append ,httpcore,0
"next getSubject getCurrentUser setLastLogin assertFalse invoke conf hasSufficientTimeElapsed  30 seconds before ""now"" System  2 minutes before ""now"" iterator assertTrue ugi now testHasSufficientTimeElapsed setConfiguration UserGroupInformation method setAccessible getDeclaredMethod conf2 getPrincipals  Restore original conf to UGI CommonConfigurationKeysPublic  15 minutes before ""now""  Make hasSufficientTimeElapsed public setLong  Restore hasSufficientTimElapsed back to private currentTimeMillis  Using relogin time of 10 minutes  6 minutes before ""now"" user ",hadoop,0
init getClass testServicesExtLoading SERVICES assertFalse destroy assertEquals S1Ext services Services SERVICES_EXT assertTrue setSystemProperty get S1 ,oozie,1
"OTHER_GROUP_NAMES ProxyUsers  Now set up an unallowed group refreshSuperUserGroupsConfiguration getProxySuperuserGroupConfKey assertAuthorized GROUP_NAMES DefaultImpersonationProvider conf asList StringUtils join UserGroupInformation  First try proxying a group that's allowed set proxyUserUgi  Neither IP should be OK testWildcardIP 1.2.3.4 1.2.3.5 * , createRemoteUser REAL_USER_NAME assertNotAuthorized getTestProvider  From either IP should be fine Arrays getProxySuperuserIpConfKey PROXY_USER_NAME realUserUgi createProxyUserForTesting ",hadoop,0
source getBytes  make sure the channels are still open addThread  InterruptedIOException.  first open pipe: interrupt pipe write TEST_STRING info read in ste LOG sink ctx GenericTestUtils fail writeBytes isOpen stop assertExceptionContains TIMEOUT Arrays  larger buffers in doIO.  Nothing helped the situation though. assertFalse out sleep Got expection while reading as expected :  Shell assertTrue doWork startThreads testSocketIOWithTimeout byteWithHighBit close doIO stream is closed         * Verify that it handles interrupted threads properly.        * Use a large timeout and expect the thread to return quickly        * upon interruption.         Did not throw  Change timeout on the read side. getMessage assertEquals Pipe thread Thread setTimeout  make sure close() closes the underlying channel. equals  close sink and expect -1 from source.read() Did not fail with interrupt readBytes open ioe ,hadoop,0
 call /resource testFixedResource POST MyJsonRestServlet GET HttpServletResponse invoke assertEquals runTest ,oozie,1
onWorkflowActionEvent listener 2012-07-22T01:00Z parseDateUTC DateUtils wf-app-name1 ca1 caId1 CoordinatorAction 2012-07-22T00:00Z wfId1 isStartProcessed _createSLARegBean init setExpectedEnd wa1  Since serviceObj is removed from memory after END stage isEndProcessed  check that end sla has been calculated cj1 execute CoordinatorJob serviceObj size onWorkflowJobEvent WorkflowAction job 2012-07-22T02:00Z AppType actualStart setExpectedStart  add dummy registration events to the SLAService map addRegistrationEvent wf1 cae getEventStatus EventStatus  check that start sla has been calculated onCoordinatorActionEvent assertTrue get testOnJobEvent wae WorkflowJob cje user1 summary coord-app-name1 getConf actualEnd bj1 assertEquals services getSLACalculator Services wfe onCoordinatorJobEvent calc slas ,oozie,1
 future oops testInterceptFutureNotAnException2 interceptFuture completeExceptionally verifyCause ,hadoop,0
prepare item5ca conf setRootExpression when setOut out Result setMinDepth find inOrder verify setOptions expr finish item1b item1a item5e processArgumentsMinDepth item5d item5c createDirectories item5b item5a setErr fsCheck err test inOrderFsCheck apply thenReturn check processArguments any setConf anyInt verifyNoMoreInteractions mock getOptions item1aa items  check minimum depth is handledfollowLink ,hadoop,0
END_POINTS IS_SECURITY_ENABLED oozieUrl conf wc testReRun appPath assertTrue get create workflow.xml SERVLET_CLASSES close runTest app RestConstants getContextURL MockDagEngineService assertEquals getFileSystem reRun call OozieClient 1 getTestUser setProperty mkdirs createConfiguration toString getFsTestCaseDir ,oozie,1
END_POINTS IS_SECURITY_ENABLED getContextURL oozieUrl e getJobInfo testWSErrors getMessage MockDagEngineService wc dummy call fail getErrorCode assertNotNull SERVLET_CLASSES runTest ,oozie,1
KeyProvider  Corrupt file and Check if JKS can reload from _OLD file  Check that an uppercase keyname results in an error testRootDir  inject failure during keystore write oldFile renameTo key5 setBitLength key6 replace conf ourUrl path Assert assertNotNull  SHould be reset to pre-flush state options getFileStatus getPath  get a new instance of the provider to ensure it was saved correctly JKS should load from _OLD file !! rw------- _NEW and current file should not exist together !! testJksProvider Expected failure on creating key name with uppercase  getPermission getProviders  Load from _NEW file GenericTestUtils getFileSystem setBackupFail fail ://file fProvider should be deleted assertExceptionContains KeyProviderFactory setWriteFail  _NEW exists but corrupt.. must load from _OLD  START : Test flush error by failure injection  inject failure during keystore backup FailureInjectingJavaKeyStoreProvider getCurrentKey assertFalse verifyAfterReload newFile JKS should load from _NEW file !! delete fs characters file flush provider assertTrue get 777 UPPERCASE  _NEW and current file should not exist together setPermission JavaKeyStoreProvider  check permission retention after explicit change test.jks unnestUri set  END : Test flush error by failure injection checkSpecificProvider isFile _OLD e toUri createKey assertEquals Should not succeed Uppercase key names  should exist _NEW jksPath assertNull checkPermissionRetention exists toString ProviderUtils createNewFile ,hadoop,0
getStats release sleep Assert updateExpiry assertTrue stats assertNotNull get of TimeUnit verify Collections close TimeValue getLeased singleton testCreateNewIfExpired entry1 conn1 assignConnection somehost pool assertEquals totals isDone Thread future1 getRoutes future2 Mockito CloseMode mock lease getTotalStats getAvailable ,httpcore,0
server Server setCallIdAndRetryCount checkResponse conf run put Assert get  Set different call id and retry count for the next call client getCallRetryCount Client  Attach a listener that tracks every call received by the server. addr info getCallId getRetryCount nextCallId rpcKind TestIPC assertReturnValues start rpcRequest assertEquals nextInt createCall getConnectAddress call caller testCallIdAndRetry NetUtils  Override client to store the call info and check response stop header infoMap ,hadoop,0
cluster FILE_SIZE testMultipleFilesSmallerThanOneBlock conf dir /test createFile waitActive webhdfsuri= checkContentSummary getNSQuota exceededQuota :// WebHdfsFileSystem /test/test DFSConfigKeys Invalid space consumed  192kb quota  Now check that trying to create another file violates the quota getFileSystem getDefaultBlockSize setInt getNameNode nnAddr Default namespace quota expected as long max. But the value is : numDataNodes mkdirs -setSpaceQuota Long  Should account for all 59 files (almost QUOTA_SIZE) shutdown /test/test59 QUOTA_SIZE  Test for deafult NameSpace Quota BLOCK_SIZE admin fs waitReplication System file assertTrue get runCommand getSpaceConsumed DFSTestUtil  the last block: (58 * 3 * 1024) (3 * 6 * 1024) = 192kb c nsQuota getContentSummary webhdfs assertEquals Quota not exceeded Integer build webhdfsuri  amount used as calculated by INode#spaceConsumedInTree. toString FSImageTestUtil setBoolean getNamesystem ,hadoop,1
template execution <ul>{{#list}}<li>{{name}}</li>{{/list}}</ul> start length js assertEquals run assertConcurrent toJavaScript System printf compile toSharedJavaScript currentTimeMillis Shared execution: %s took: %sms  end ,handlebars,1
testVerifyChecksumPassthru mock verify reset setVerifyChecksum mockFs eq fs ,hadoop,0
"app2Dir before2000Secs listStatus  Now,lets change the confs conf suffix when mockfs://foo/ getRawFileSystem  Set time last modified of app1Dir directory and its files to before2000Secs fs.mockfs.impl Assert rootFs me application_1_1 application_1_2 50 logs app1Dir init  We have not called refreshLogSettings,hence don't expect to see the changed conf values thenReturn app2DirStatus rootPath getFileSystem  time before 2000 sec remoteRootLogDir 1 app2Log1 2 app1DirStatus userDirStatus stop true mockFs app1Log1 refreshLogRetentionSettings before50Secs remoteRootLogPath app1Log1Status app2Log1Status delete System timeout  app1Dir would be deleted since its done above log retention period tmp/logs times  app2Dir is not expected to be deleted since its below the threshold createConf YarnConfiguration assertTrue getCheckIntervalMsecs now root  Set time last modified of app1Dir directory and its files to before50Secs verify testRefreshLogRetentionSettings set host1 deletionSvc setClass start 1800  time before 50 sec currentTimeMillis userDir  refresh the log settings  Check interval time should reflect the new value  app2Dir should be deleted since it falls above the threshold userLogDir ",hadoop,1
r2 getName output test.*.source.filter.exclude getTestFilename Test putMetrics s0 s1 add checkMetricsRecords onTimerEvent testInitFirst ms getAllValues capture test.sink.test.class mr2 mr1 s1 desc stop *.period TestMetricsConfig test.sink.sink1.metric.filter.exclude mock  trigger something interesting s0rec test.sink.sink2.metric.filter.exclude save test.source.s1.metric.filter.exclude X* times verify sink2 desc hadoop-metrics2-test s1rec cb set registerSink incr start sink1 desc assertEquals Y* s0 desc sink2 sink1 register r1 ,hadoop,1
conn setRequestMethod IS_SECURITY_ENABLED testJobInfo put assertTrue get /v1/job/* content-type 50 runTest MockCoordinatorEngineService JsonTags RestConstants openConnection HttpServletResponse assertEquals parse params getInputStream url JSONValue call 1 getHeaderField size obj GET getResponseCode reset createURL startsWith ,oozie,1
getJobTrackerUri getWorkflow </name-node> <configuration> <java>  'MODIFIER' assertFalse </configuration> createContext fs actionXml getAppFileSystem assertTrue get context JavaActionExecutor  then it equals group name getAcl userGroup <job-tracker> getNameNodeUri jobXmlConf userModifyAcl </java> </job-tracker> <main-class>MAIN-CLASS</main-class> <name-node>  then it should NOT be overridden by group name  'USERS' getJobFile <property><name>mapreduce.job.acl-modify-job</name><value>MODIFIER</value></property> equals submitAction USERS job testACLModifyJob open ,oozie,1
cancel isCancelled assertFalse CoreMatchers is assertThat dependency2 testCancelled dependency1 isDone Assert future setDependency ,httpcore,0
EXEC_ORDER callable2 init callable3 callable1 callableLow CallableQueueService destroy queueservice Services 1 assertTrue get setSystemProperty testPriorityExecution callableHigh evaluate waitFor queue ,oozie,1
getTime checkCoordinators DateUtils parseDateOozieTZ jobId3 insertJob jobId2 jobId1 assertNotNull jobId5 get jobId4 00002-  Get the next 3 (though there's only 2 more) 00004-  Get the first 3 2011-01-01T01:00Z assertEquals list execute Services CoordinatorJob -TestCoordJobsGetForPurgeJPAExecutor-C size addAll 00003- 00005- jpaService 00001- testCoordJobsGetForPurgeJPAExecutorTooMany ,oozie,1
CodecTestUtils channel empty Assert flush assertTrue 678 90 testCodingEmptyBuffer dump write flip isCompleted StandardCharsets assertEquals encoder ByteBuffer 5 12345 3 678 2 90 0   allocate outbuf 12345 metrics complete wrap ,httpcore,0
mockRes init mockReq  Object under test thenReturn  CSRF has not been sent  Objects to verify interactions based on request testNoHeaderDefaultConfigNonBrowserGoodRequest  Setup the configuration settings of the server when filterConfig getHeader filter mockChain getInitParameter Mockito doFilter mock verify NON_BROWSER RestCsrfPreventionFilter ,hadoop,0
cancelTokenUrl conf checkQueryParams  wipe out internal token to simulate auth always required  send user test-user setAuthenticationMethod  fake turning on security so api thinks it should use tokens fileStatusUrl setLoginUser ugi encodeToUrlString fsPath toQueryString setConfiguration UserGroupInformation getShortUserName toUrl getTokenUrl webhdfs createRemoteUser KERBEROS / renewTokenUrl GetOpParam setDelegationToken getWebHdfsFileSystem  send token testSecureAuthParamsInUrl SecurityUtil toString tokenString getDelegationToken PutOpParam ,hadoop,1
yyyy.MMM.dd doTest dot CAL_2009_08_3_NIGHT ,logback,0
getValueClass reader conf fs testDeprecatedConstructors cleanupWithLogger path SequenceFile assertNotNull FileSystem get writes.mapfile close TEST_DIR defaultCodec e LOG getKeyClass WritableComparator getMessage deprecation reader key is null !!! reader value in null fail IOUtils getLocal defaultProgressable toString writer CompressionType ,hadoop,0
"getClass  First, transparently via ObjectWritable ObjectWritable resultSet out assertTrue get  Write a big set of data, one of each primitive type array expectedResultSet write getData in deepEquals writeObject  validate data structures and values In and Out arrays didn't match values apw assertEquals readObject  Second, explicitly bigSet readFields  First, transparently ComponentType of array  testMany  Now read the data back in getComponentType getLength reset  Second, explicitly via ArrayPrimitiveWritable Arrays ",hadoop,0
SSLTestConstants setLocation assertNotNull createKeyStore factoryBean testDefaults ,logback,0
"Property had invalid int value, but was read successfully. conf appendProperty test.int2 out test.int1 CONFIG addResource testIntegerValues getLongBytes endConfig startConfig assertEquals -20  -20  020 test.int4 getLong test.int3 getInt fail test.int5 fileResource 20  -20xyz  ",hadoop,0
bundleJobGetCmd addRecordToBundleJobTable getId assertEquals getStatus execute call Services testBundleSuspend1 assertNotNull get Job job jpaService ,oozie,1
handler request getTime jwt Public key for signature validation must be provisioned when alternateAuthentication should NOT have thrown a AuthenticationException se SERVICE_URL assertTrue getCookies getJWT getRequestURL init cookie testNoPublicKeyJWT thenReturn getProperties hadoop-jwt encodeRedirectURL getMessage alternateAuthenticate alternateAuthentication should have thrown a ServletException props token fail privateKey serialize contains bob Mockito response mock ,hadoop,0
internalTestSerial testSerial ,hadoop,0
tfs kills /0 clients CommonUtils mTfs ls assertEquals mLocalTachyonClusterMultiMaster getClient k sleepMs createFile / faultTest Assert size assertTrue get killLeader files ,alluxio,1
testResolverUnqualified .a.b. 1.1.1.1 verifyResolve host verifyInetAddress host.a.b addr ,hadoop,0
start.non-transient _testNonTransient assertTrue testStartNonTransient start WorkflowActionBean ,oozie,1
getSecretKey getCurrentUser set checkSpecificProvider credentials CredentialProviderFactory getCredentials conf ourUrl :/// assertArrayEquals UserProvider pass2  see if the credentials are actually in the UGI testUserProvider UserGroupInformation ,hadoop,0
"doNothing getName getProxy Could not connect to host HAServiceState errorThrowingProxy when testFailoverFromNonExistantServiceWithFencer  not on creation of the proxy. verify withSettings close defaultAnswer doFailover svc2 CommonConfigurationKeys svc1Addr svc1 doReturn  Don't check svc1 because we can't reach it, but that's OK, it's been fenced. assertEquals eq any Non-existant active prevented failover  gracefully used the right rpc timeout anyInt setupFencer fail Mockito svc2Addr extraInterfaces mock spy ",hadoop,0
incrementAndGet ContentType testConsumeData getContent count consume assertEquals completed failed ByteBuffer longValue assertArrayEquals Assert streamEnd cancelled streamStart wrap consumer ,httpcore,0
testRequestExpectContinueInvalidInput fail process Assert interceptor IllegalArgumentException should have been thrown ,httpcore,0
checkBundles  Get the first 3 testBundleJobsGetForPurgeJPAExecutorTooMany job2 job1 job4 2011-01-01T01:00Z job3 addRecordToBundleJobTable job5 assertEquals getId DateUtils list execute parseDateOozieTZ Services size addAll assertNotNull get  Get the next 3 (though there's only 2 more) Job jpaService ,oozie,1
a${k67:-x${k0}}c input node transform nodeToStringTransformer propertyContainer0 defaultValueNestedAsVar makeNode assertEquals axv0c ,logback,0
"getBooleanWithDefault  not in prod => no-cache isProd DateUtil  if cache time = 0 => set to no-cache:  IMPORTANT: etag added NinjaConstant no-cache getMethod when getHeader Result result addEtag 1234 max-age=1234 context formatForHttpHeader testAddETag verify  if not in production => no cache:  in production => make sure cache header is set accordingly:  IMPORTANT: etag not added addHeader thenReturn anyString getWithDefault  add etag when configured: eq  set regular header with request to http cache control constant: ""12___34"" 0 ""1234"" httpCacheToolkit never  test lastmodified is added when etags match:  => but Last-Modified header is added GET reset  do not add etag when not configured: ninjaProperties HttpHeaderConstants status ",ninja,0
"filePermissionGenerator next ANCESTOR_NAME testPermissionCheckingPerUser dirPermissionGenerator ancestorPermissions  create ancestor directory parentPaths testPermissionChecking ancestorPaths  has a different permission conf  create a directory hierarchy and sets random permission for each inode  file owner   change parent directory's ownership to be user1 fs FILE_NAME setOwner USER1 USER2 permissions PARENT_NAME FileSystem get create setPermission USER1_NAME USER3 close  Check if namenode performs permission checking correctly for    * superuser, file owner, group owner, and other users  DIR_NAME dirPaths ancestorPermissionGenerator  group owner   other owner  parentPermissions GROUP2_NAME / r  set the permission of the root to be world-wide rwx NUM_TEST_PERMISSIONS SUPERUSER OpType filePaths  super owner   create parent directory ",hadoop,1
 next @ getSubject getClass getPrivateCredentials getName createServerConfig subject foo keytab createClientConfig KerberosConfiguration principals getRealm login principal logout iterator Assert workDir add testKerberosLogin isEmpty assertEquals  server login kdc getPrincipals loginContext foo.keytab getWorkDir size  client login createPrincipal getKdc ,hadoop,0
END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL oozieUrl -kill MockDagEngineService run assertEquals args call 1 testKill -oozie size job SERVLET_CLASSES runTest ,oozie,1
result testResultsRedirectTemporary http://example.com getStatusCode getHeaders getRenderable Results assertTrue get assertEquals redirectTemporary Result ,ninja,0
pt quadrilateralToQuadrilateral assertPointEquals PerspectiveTransform testQuadrilateralToQuadrilateral ,zxing,0
createMapping mapping set isSingleSwitch ScriptBasedMapping Expected to be multi switch testFilenameMeansMultiSwitch assertFalse conf any-filename setConf Expected to be single switch assertTrue ,hadoop,0
"Unexpected Exception addNode def j2 seven f2 three two asList invokeForkJoin four dummyConf end five six printStackTrace e f one j k kill fail       f->(2,3)      2->f2      3->j      f2->(4,5,6)      (4,5,6)->j2      j2->7      7->j      parser testWf <worklfow-app/> testNestedForkJoin Arrays ",oozie,1
"/a/b/,/c/b/,/c/d/  ADD ab ELConstantsFunctions  /a/b/  ,/c/b/ , /c/d/  appendAll /a/b/ADD,/c/b/ADD,/c/d/ADD /a/b/  /a/b/  ADD,/c/b/ ADD, /c/d/ ADD assertEquals , /a/b/ADD testAppendAll ADDaADDbADD ",oozie,1
file setURLStreamHandlerFactory assertFalse FileSystem conf getFileSystemClass  we might get an exception but this not related to infinite loop problem URL testInitializationWithRegisteredStreamFactory ,hadoop,0
testBloomMapFileConstructors error !!! testFileName defaultProgress defaultCodec LOG WritableComparator conf deprecation cleanupWithLogger testBloomMapFileConstructors fail IOUtils TEST_FILE assertNotNull FileSystem get toString writer CompressionType close ts ,hadoop,0
setName getProperty getName XTestCase getProperties System testcase tearDown testBaseDir TESTING assertTrue setProperty getTestCaseDir setUp TestXTestCase startsWith ,oozie,1
Set scriptExecutor updated_static EntityWithStaticColumn/insert_single_row.cql session  Given SELECT static_col FROM entitywithstaticcolumn WHERE id =  Eq UUIDs uuid  When of staticCol should_dsl_update_static where id static_col executeScriptTemplate isNotNull static_val actual RandomUtils manager one timeBased if_StaticCol getString nextLong assertThat execute ImmutableMap  Then Long updateStatic fromBaseTable dsl isEqualTo ,achilles,1
init .dataout.ABC.unresolved CoordELFunctions .datain.ABC.unresolved ${coord:databaseIn('ABC')} setVariable ${coord:databaseOut('ABC')} assertEquals coord-action-start testDatabase eval evalAndWrap .dataout.ABC mydb .datain.ABC expr Boolean hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us ,oozie,1
"curl verifyZeroInteractions  Object under test EXPECTED_MESSAGE sendError when filterConfig getHeader atLeastOnce mockChain doFilter verify mockRes init mockReq thenReturn  CSRF has not been sent  Objects to verify interactions based on request HttpServletResponse ^Mozilla.*,^Opera.*,curl  Setup the configuration settings of the server filter getInitParameter Mockito mock testNoHeaderCustomAgentConfigBadRequest RestCsrfPreventionFilter ",hadoop,0
Args Number testIntRangeFailHigh checkRange ,httpcore,0
calendar Last flush time should have been null prior to calling init() rfsSink set  Now try pathological settings getTime Calendar getTimeInMillis diff assertEquals testSetInitialFlushTime assertNull  Try again with a random offset assertTrue The initial flush time was calculated incorrectly getInstance setInitialFlushTime The initial flush time was calculated incorrectly:  ,hadoop,0
testedValue getTime TZ getId caicc DateUtils parseDateOozieTZ effectiveValue 2009-02-01T23:59 get startTime  Verify if two values are same. getConf assertEquals  Override the property value for testing purpose only.  -TestCoordActionInputCheckXCommand-C           * Create a dummy Coordinator Job to pass to          * CoordActionInputCheckXCommand constructor.           2009-02-02T23:59 addRecordToCoordJobTable testRequeueInterval jobId Services @1 setLong getCoordInputCheckRequeueInterval 0000000- endTime CoordActionInputCheckXCommand job ,oozie,1
conn setRequestMethod IS_SECURITY_ENABLED testGraph put assertTrue /v1/job/* content-type runTest MockCoordinatorEngineService RestConstants openConnection clear MockDagEngineService HttpServletResponse assertEquals params url call getHeaderField GET getResponseCode name reset createURL ErrorCode startsWith  Negative test..  should fail ,oozie,1
init ${coord:dataOutPartitions('ABCD')}  -ve test CoordELFunctions ${coord:dataOutPartitions('ABC')} setVariable  +ve test assertEquals coord-job-submit-data fail testDataOutPartitionsPh1 eval evalAndWrap should throw exception because Data-in is not defiend expr oozie.dataname.ABC data-out ,oozie,1
stuff; fail Assert inbuf StandardCharsets channel testInvalidConstructor more stuff metrics IllegalArgumentException should have been thrown ,httpcore,0
addRecordToBundleActionTable getCurrentDateafterIncrementingInMonths run DateUtils WorkflowInstance getStatus addRecordToCoordActionTable parseDateOozieTZ bundleJob assertNotNull CoordinatorAction currentDatePlusMonth Job waitFor bundleAction1 bundleAction2 XDataTestCase execute addRecordToCoordJobTableWithBundle coordJob2 CoordinatorJob coordJob1 testBundleStatusTransitServiceSuspended evaluate assertFalse getId getExternalId isPending wfJob addRecordToWfJobTable get end coordAction1_3 WorkflowJob coordAction1_4 bundle coordAction1_1 coordAction1_2 addRecordToBundleJobTable bundleId start assertEquals call Services runnable coord-action-get.xml equals action1 action2 jpaService ,oozie,1
getName contextCookie1 contextCookie2  test  against cookie that is really there httpServletRequest cookie1 when getCookie cookie2 doesNotExist getCookies context getCookieTest servletCookies servletCookie1  test 2 against cookie that is really there servletCookie2 init thenReturn servletContext assertEquals theValue1 theValue2  negative test: getValue assertNull httpServletResponse ,ninja,0
"init getName set getConf oozie.service.ProxyUserService.proxyuser.foo.groups destroy conf * services , asList Services fail StringUtils testWrongConfigHosts join Arrays ",oozie,1
testPauseUnpause1 job1 getTime pauseStartRunnable addRecordToBundleJobTable run getId assertEquals getStatus execute setPauseTime Services jobId assertNotNull get setKickoffTime Job job jpaService evaluate waitFor ,oozie,1
colin newToken getSequenceNumber getUser alice  clone origToken into newToken testSerialization origToken outBuf  now test the fields setIssueDate getIssueDate getUserName getMasterKeyId write getData getMaxDate assertEquals getRealUser getRenewer readFields setMasterKeyId bob inBuf setSequenceNumber setMaxDate getLength reset ,hadoop,0
regex validationWithOptionalPassed validateJSR303WithOptional length buildDto context doCheckValidationPassed ,ninja,0
" 2009-06-24 02:43:19,344 DEBUG _L6_:323 - USER[oozie] GROUP[oozie] TOKEN[MYtoken] APP[-]  APP lr JOB[-] ACTION[-] Number of pending signals to check [0]   split getTestCaseDir 14-200904160239--example-C JOB TOKEN write See JobConf(Class) or JobConf#setJar(String). test JOB[14-200904160239--example-C] ACTION[14-200904160239--example-C@2] Use GenericOptionsParser for   2009-06-24 02:43:14,505  INFO _L5_:317 - USER[oozie] GROUP[oozie] TOKEN[-] APP[-]   2009-06-24 02:43:29,151 DEBUG _L7_:323 - USER[-] GROUP[-] TOKEN[-] APP[-] JOB[-]  matches testProcessCoordinatorLogForActions parsing the arguments.  _L3A_Applications should implement Tool for the same.  _L3B_Multi line  contains /test.log JOB[14-200904160239--example-C] ACTION[14-200904160239--example-C@2]  reset JOB[14-200904160239--example-C] ACTION[14-200904160239--example-C@1] End workflow state change sb 2009-06-24 02:43:13,958 DEBUG _L1_:323 - USER[oozie] GROUP[-] TOKEN[-] APP[example-forkjoinwf]  GROUP fw  2009-06-24 02:43:13,961  INFO _L2_:317 - USER[-] GROUP[-] TOKEN[-] APP[example-forkjoinwf]  14-200904160239--example-C@1 [org.apache.oozie.core.command.WorkflowRunnerCallable] released lock ACTION[-] Number of pending actions [0]  defineParameter setParameter close  2009-06-24 02:43:14,431  WARN _L4_:661 - No job jar file set.  User classes may not be found.  sw JOB[14-200904160239--example-C] ACTION[14-200904160239--example-C@1] Released Lock XLogStreamer assertEquals USER xf  2009-06-24 02:43:13,986  WARN _L3_:539 - USER[-] GROUP[-] TOKEN[-] APP[example-forkjoinwf]  ACTION _L1_ toString _L5_ processLog append ",oozie,1
addChildToService parent init AddSiblingService stop start assertInState STATE testAddStartedChildInInit child ,hadoop,0
 testFile01 getPathData testfile01 addContents -S ls formatLineMtime out  check reverse length order (-S -r options) testfile03  set file length in different order to file names options computeLineFormat inOrder testfile02 processOptions verify testfile05 testFile06 testfile04 testFile04 testFile05 testfile06 testFile02 testFile03 add Found 6 items pathData lineFormat -r length setIsDir processArguments testDir testDirectory setLength verifyNoMoreInteractions processPathDirOrderLengthReverse TestFile mock ,hadoop,0
cluster ns racks conf dnToCorrupt /rack2 waitForReplication /rack1     * Test that a block that is re-replicated because one of its replicas    * is found to be corrupt and is re-replicated across racks.     fs createFile readBlockOnDataNode restartDataNode Corrupt replica  Create a file with one block with a replication factor of 2 assertTrue  have been cleaned up yet). waitCorruptReplicas  Wait for the namenode to notice the corrupt replica  Datanodes are spread across two racks DFSTestUtil b MiniDFSCluster  block is detected. getConf filePath assertEquals testCorruptBlockRereplicatedAcrossRacks getFileSystem firstDnWithBlock  The rack policy is still respected corruptReplica REPLICATION_FACTOR getNameNode fileLen /testFile  Corrupt a replica of the block build blockContent numDataNodes readFile getFirstBlock shutdown fileContent getNamesystem ,hadoop,1
"keys put remove numElements expected all entries to be removed capacity testAdditionsAndRemovals key  Assert assertTrue get add  keys empty, but found  debug LOG visitAll valueOf isEmpty assertEquals store k expected the store to be  accept Integer fail generating  contains  elements. NUM_KEYS ",hadoop,0
alwaysFailsWithFatalException getClass retryUpToMaximumTimeWithFixedSleep submit newSingleThreadExecutor Executors  time to fail and sleep getCause sleep futureThread assertTrue assertNotNull get await interrupt TimeUnit create latch countDown Retry interrupted unreliableImpl currentThread set sleep interrupted e ute getMessage assertEquals RetryProxy testRetryInterruptible Thread call isAlive future unreliable  should return immediately exec ,hadoop,0
storePassword getResource toCharArray serverSocket newSingleThreadExecutor Executors serverSslContext getServerSocketFactory Assert bind assertNotNull nopassword clientPrincipal create TimeUnit SSLContextBuilder /test-client.p12 write getPeerPrincipal localhost startHandshake read localPort loadTrustMaterial loadKeyMaterial resource2 inputStream setSoTimeout getInputStream /test-server.p12 resource1 accept createSocket clientSslContext TIMEOUT setNeedClientAuth getLocalPort submit session clientSocket flush keyPassword testSSLHandshakeClientAuthenticated get outputStream close connect assertEquals call getSocketFactory build future toMillisecondsIntBound getOutputStream socket getSession createServerSocket ,httpcore,0
prepare testCodingBothBuffers_erasing_d5 testCoding ,hadoop,0
   verifyRead toRead Sequence of actions:  conf  Write random bytes to file   Math fs seek @  System nextBytes sb seekOff min stream FileSystem create close write afe setClass reads newInstance j nextInt stm setInt CommonConfigurationKeysPublic buf r TEST_PATH  Record the sequence of seeks and reads which trigger a failure. toString fs.file.impl testBufferedFSInputStream open append seeks read  ,hadoop,0
assertHomeResolveFailed E_IS_RELATIVE ./target testHadoopHomeRelative ,hadoop,0
 assertFalse channel outStream  getBytes Assert flush inbuf buffer write   chbuffer s1 s2 s3 a StandardCharsets clear assertEquals fill readLine ByteBuffer setLength outbuf toByteArray toString testComplexReadWriteLine wrap newChannel append outChannel ,httpcore,0
 ///////////////////////////////////////////////////////////////////// /{name}/dashboard /dashboard buildRoute assertFalse John assertTrue get /{name}/{id}/dashboard id map /John/20/dashboard entrySet getPathParametersEncoded assertEquals matches ninjaBaseDirectoryResolver route /John/dashboard size GET name routeBuilder ninjaProperties 20 basicPlaceholersAndParameters ,ninja,0
"def addNode j1 j2 Expected to catch an exception but did not encounter any f2 two getCause asList we been [j2] invokeForkJoin getErrorCode assertTrue testForkJoinMismatch dummyConf end f one getMessage assertEquals Join [j1] k kill fail contains ex parser Fork [f] name ErrorCode Arrays       * f->(1,2)      * 1->ok->j1      * 1->fail->k      * 2->ok->j2      * 2->fail->k      * j1->end      * j2->f2      * f2->k,k       ",oozie,1
A ${A} expect Circular variable reference detected while parsing input [${A} --> ${A}] OptionHelper context detectCircularReferences0 putProperty expectedException expectMessage substVars ,logback,0
"formatNameValuePair param=""this,that"" this\that param=""regular_stuff"" quote marks ("") must be escaped Assert param param7 param5 param=regular_stuff param6 param=""back slash (\\) must be escaped too"" clear testNVPFormatting param=""quote marks (\"") must be escaped"" assertEquals param3 param4 param1 param=""this\\that"" param2 buf regular_stuff toString param=""values with	blanks must always be quoted"" this,that back slash (\) must be escaped too values with	blanks must always be quoted ",httpcore,0
"java.naming.provider.url#tcp://broker.${2}:61616 http://unknown:9999/fs conf server2 hcat://server1.colo1.server.com:8020/db/table/pk1=val1;pk2=val2  No default JMS mapping server3 HCatAccessorService testGetJMSConnectionInfoNoDefault get getJNDIPropertiesString java.naming.factory.initial#Dummy.Factory;java.naming.provider.url#tcp://broker.colo1:61616 hcat://xyz.corp.dummy.com/db/table hcat://xyz.corp.dummy.com=java.naming.factory.initial#Dummy.Factory; init set getJMSConnectionInfo getConf hcatService destroy assertEquals services hcat://${1}.${2}.server.com:8020=java.naming.factory.initial#Dummy.Factory; , java.naming.provider.url#tcp:localhost:61616 assertNull connInfo java.naming.factory.initial#Dummy.Factory;java.naming.provider.url#tcp:localhost:61616 setupServicesForHCatalog jmsConnectionURL ",oozie,1
22 cluster 23 myFile getLocalizedMessage conf run fs System setOut out psOut Exception raised from DFSShell.run  assertTrue /test/dir close writeFile val /test/dir/file2 e myFile2 getFileSystem setConf Not a HDFS:  dfs psBackup args returnString  Check if size matchs as expected contains testDu build shell numDataNodes mkdirs exists reset toString getUri shutdown myPath -du /test/dir/file ,hadoop,1
aA Cc eE Gg iI mM qQ uU yY Kk Oo Ss Ww JobSetup bB Dd fF Hh jJ nN rR vV zZ Ll Pp Tt Xx testCamelize SomeStuff Map MAP Mm Aa cC Yy Ee gG kK oO sS wW Ii Qq Uu camelize JOB_SETUP StringUtils Nn Bb dD Zz Ff hH lL pP tT xX Jj Rr Vv assertEquals  common use cases  sanity checks for ascii alphabet against unexpected locale issues. some_stuff ,hadoop,0
equals assertFalse notEquals  test all combinations of not equals Result ,hadoop,0
getConnectionContext getEventMessage errorCode conf parseDateUTC DateUtils getStatus wf-app-name1 caJobId1 caId1 CoordinatorAction 2012-07-22T00:00Z getStartTime MessageType 2011-07-11T00:00Z init printStackTrace getText fail contains createConsumer AppType startDate getParentId testOnCoordinatorActionStartEvent getAppType cae session coordEventListener assertFalse JMSMessagingUtils getEventStatus getUser EventStatus getId createSession getTopic onCoordinatorActionEvent jmsContext consumer user1 missingDependency getMessageType nominalTime receive getAppName e errorMessage coordActionStartMessage getMessage assertEquals message endTime Session ,oozie,1
lib LocalOozie     <end name='end'/> conf compareTo getStatus testWorkflowRun lastModTime input-data getEndTime </workflow-app> getTestGroup assertNotNull create workflow.xml write waitFor app suspend getFileSystem inputWriter OozieClient jobId stop Hello. This is my input data set. mkdirs setProperty createConfiguration     <start to='end'/> dateTest File getCreatedTime evaluate <workflow-app xmlns='uri:oozie:workflow:0.1' name='test-wf'> submit getJobInfo wc fs appPath wf sleep input-data/data1.txt WorkflowJob close resume start assertEquals getLastModifiedTime getClient wfApp getTestUser toString writer getFsTestCaseDir ,oozie,1
getConnectionContext getEventMessage endDate conf parseDateUTC DateUtils getStatus setErrorCode wf-app-name1 setErrorMessage getEndTime caJobId1 caId1 CoordinatorAction 2012-07-22T00:00Z dummyError getStartTime MessageType 2011-07-11T00:00Z init printStackTrace getText fail contains createConsumer AppType startDate getParentId getAppType cae session coordEventListener assertFalse JMSMessagingUtils getEventStatus getUser EventStatus getId coordActionFailMessage createSession getTopic onCoordinatorActionEvent getErrorCode jmsContext testOnCoordinatorJobFailureEvent consumer user1 missingDependency getMessageType nominalTime receive getAppName E0101 e getMessage assertEquals message setEndTime Session getErrorMessage ,oozie,1
testClientWithoutAnonymous getContextURL oozieUrl false admin run assertEquals oozie.authentication.simple.anonymous.allowed args call -oozie setSystemProperty -status runTest ,oozie,1
" getCpuFrequency  Write fake /proc/stat file.  Write fake /proc/cpuinfo file. CPUINFO_FORMAT    In this case, CPU usage should not be updated. String CpuTimeTracker fWriter cpuFrequencyKHz FAKE_JIFFY_LENGTH tempFile sTime write close numProcessors deleteOnExit parsingProcStatAndCpuFile FAKE_STATFILE FAKE_CPUFILE  Advance the time and sample again. This time, we call getCpuUsagePercentage() only. getCumulativeCpuTime advanceTime format getNumProcessors assertEquals nTime  Advance the time and sample again to test the CPU usage calculation plugin updateStatFile uTime getNumVCoresUsed fileContent getCpuUsagePercentage  CPU usage is not updated. ",hadoop,0
getContentEncoding abc ContentType byteChannel StandardCharsets assertFalse assertEquals getContentLength produce testTextContent Assert isOpen producer getContentType toString dump streamChannel ,httpcore,0
setClassesToBeExcluded  set the pause time explicity to make sure the job is not unpaused assertFalse getCurrentDateafterIncrementingInMonths getId run DateUtils isPending getStatus addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob setPauseTime testCoordStatusTransitServicePausedWithError assertNotNull get CoordinatorAction end currentDatePlusMonth waitFor createCoordJob init getConf coordInsertCmd false start 2009-02-01T01:00Z destroy assertEquals services XDataTestCase execute Services CoordinatorJob jobId runnable coord-action-get.xml excludedServices setSystemProperty StatusTransitService job jpaService evaluate ,oozie,1
"next headers assertFalse hasNext assertEquals Name value2=whatever value3;tag=nil testAllSame 0 1 hit  without filter 2 Assert 3 assertTrue nAme naMe namE name value1, value1.1 value0  with filter ",httpcore,0
Path /foo testMergePaths file://fileauthority/bar /C:/foo/bar assertEquals viewfs:///foo /C:/bar mergePaths /bar/baz /C:/C:/bar / /bar Shell /foo/bar viewfs://vfsauthority/foo/bar /foo/bar/baz /baz viewfs:///foo/bar /C:/foo file:///bar viewfs://vfsauthority/foo /C:/foo/C:/bar /C:/ ,hadoop,0
dummyErrorCode getConnectionContext getEventMessage endDate conf parseDateUTC DateUtils getStatus setErrorCode wf-app-name1 setErrorMessage getEndTime caId1 testOnWorkflowJobFailureEvent 2012-07-22T00:00Z wfId1 getStartTime MessageType init printStackTrace destroy wfEventListener fail onWorkflowJobEvent createConsumer AppType startDate getParentId getAppType session JMSMessagingUtils getEventStatus getUser EventStatus getId createSession getTopic getErrorCode WorkflowJob jmsContext consumer user1 getMessageType receive getAppName e getMessage assertEquals message dummyErrorMessage wfe wfFailMessage Session getErrorMessage ,oozie,1
"getSubject  verify login user got a new ticket. getName checkTicketAndKeytab user1.keytab user2.keytab  verify subject ugi relogin did not affect the login user. run principal2 principal1 loginUser Assert removeUser extSubjectUser reloginFromKeytab getPath testReloginForUGIFromSubject workDir assertNotEquals UserGroupInformation user1 user2 getUGIFromSubject ticket loginTicket keytab1 kdc loginUserFromKeytab assertSame getLoginUser keytab2 loginUserFromKeytabAndReturnUGI  verify an ""external"" subject ticket does not change. doAs extSubject  ""external"" subject. getAuthTime  get the ugi for the previously logged in subject. createPrincipal  Login another user. newLoginTicket ",hadoop,0
date %msg - [%thread]%n  Given simple SELECT * FROM simple WHERE id =  crud executeAsyncWithStats prepareLogLevel  When executionInfo id should_delete_instance_async info logAsserter all RandomUtils withResultSetAsyncListener assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap assertContains  Then Long buildDateKey LOGGER rs Called scriptExecutor ASYNC_LOGGER_STRING session delete isUp of get await latch countDown value table executeScriptTemplate getQueriedHost manager isEmpty nextLong rows CALLED isTrue future entity ,achilles,1
setLong DFSConfigKeys fName  Modify defaul filesystem settings hFlush_02 conf customPerChecksumSize customBlockSize setInt doTheJob ,hadoop,1
"checkOwnership  case 6: user2 (non-owner) changes FILE_DIR_PATH's group to be group3  case 3: user1 changes FILE_DIR_PATH's owner to be user2  case 2: superuser changes FILE_DIR_PATH's owner to be <user1, group3> conf DEFAULT_UMASK login fs delete DEFAULT_PERMISSION setOwner FILE_DIR_PATH USER1 USER2 FileSystem get  which it does not belong to GROUP3_NAME create  delete the file/directory  test directory creation  to  case 7: user2 (non-owner) changes FILE_DIR_PATH's user to be user2  case 1: superuser create a file/directory getShortUserName op getParent  check if the ownership of a file/directory is set correctly  SUPERUSER getGroup  test file creation OpType  check ownership is set correctly for a file or directory  testOwnership GROUP1_NAME ",hadoop,1
getBytesTransferred testfile more stuff; and a lot more stuff rw StandardCharsets assertFalse channel bytesRead createTempFile assertEquals decoder testCodingBeyondContentLimitFile stuff; transfer Assert inbuf getChannel assertTrue metrics close fchannel isCompleted ,httpcore,0
coordClient 2009-02-02T23:59Z LocalOozie coordActionGetCmd getId DateUtils getStatus addRecordToCoordActionTable parseDateOozieTZ coordJob testCoordRerunForBackwardSupport1 getCoordClient rerunScope assertNotNull get CoordinatorAction end reRunCoord init RestConstants 2009-02-01T01:00Z start destroy assertEquals services setAppNamespace execute - addRecordToCoordJobTable Integer Services CoordinatorJob coordJobGetCmd SchemaService setSystemProperty assertNotSame true StatusTransitService toString action1 action2 jpaService action3 coord-rerun-action1.xml ,oozie,1
result testAndAddHeaders addHeader header2 header1 value2 getHeaders size value1 get assertEquals ,ninja,0
testCoordActionGet lastModifiedTime _E errorCode getId _testGetForInfo DateUtils setTrackerUri appPath setErrorCode parseDateOozieTZ resourceXmlName actionXml setErrorMessage coord actionNominalTime consoleUrl slaXml  Pass the expected values CoordinatorAction missingDeps createdTime action  Add extra attributes for action setCreatedTime actionNum trackerUri errorMessage getActionNominalTime setConsoleUrl setExternalStatus setLastModifiedTime setMissingDependencies addRecordToCoordJobTable 000 CoordinatorJob createCoordAction coord-action-get.xml  Insert the action setSlaXml insertRecordCoordAction externalStatus job getCoordActionXml Dummy getFsTestCaseDir ,oozie,1
"JOB[14-200904160239--example-forkjoinwf] ACTION[-] Use GenericOptionsParser for parsing   2009-06-24 02:43:19,344 DEBUG _L6_:323 - USER[oozie] GROUP[oozie] TOKEN[MYtoken] APP[-]  APP the arguments.  lr [org.apache.oozie.core.command.WorkflowRunnerCallable]  JOB[-] ACTION[-] Number of pending signals to check [0]    2009-06-24 02:43:14,505  INFO _L5_:317 - USER[oozie] GROUP[oozie] TOKEN[-] APP[-] JOB[-]  split getTestCaseDir ACTION[-]  _L3A_ JOB TOKEN  2009-06-24 02:43:29,151 DEBUG _L7_:323 - USER[-] GROUP[-] TOKEN[-] APP[-] JOB[-] ACTION[-]  write testProcessLog See JobConf(Class) or JobConf#setJar(String). setLogLevel JOB[14-200904160239--example-forkjoinwf] ACTION[-] End workflow state change contains /test.log _L3_ DEBUG|WARN reset _L3B_ released lock JOB[14-200904160239--example-forkjoinwf] ACTION[-]  sb out 2009-06-24 02:43:13,958 DEBUG _L1_:323 - USER[oozie] GROUP[-] TOKEN[-] APP[example-forkjoinwf]  GROUP fw  2009-06-24 02:43:13,961  INFO _L2_:317 - USER[-] GROUP[-] TOKEN[-] APP[example-forkjoinwf]  14-200904160239--example-forkjoinwf Released Lock defineParameter setParameter  _L3A_Applications should implement Tool for the same.  _L3B_Multi line test close  2009-06-24 02:43:14,431  WARN _L4_:661 - No job jar file set.  User classes may not be found.  sw XLogStreamer Number of pending actions [0]  assertEquals USER xf  2009-06-24 02:43:13,986  WARN _L3_:539 - USER[-] GROUP[-] TOKEN[-] APP[example-forkjoinwf]  ACTION _L1_ toString processLog append ",oozie,1
date scriptExecutor session  Given update simple Eq SELECT simpleset FROM simple WHERE id =  simpleset containsExactly Sets  When of where id row should_dsl_update_set_setValue table executeScriptTemplate RandomUtils manager getSet one nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap simpleSet_Set simpleSet newHashSet  Then Long buildDateKey fromBaseTable dsl ,achilles,1
assertFalse getCurrentDateafterIncrementingInMonths getId run DateUtils isPending getStatus addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob testCoordStatusTransitServiceRunning1 assertNotNull get CoordinatorAction end currentDatePlusMonth Job waitFor start assertEquals XDataTestCase execute addRecordToCoordJobTable CoordinatorJob jobId Services runnable coord-action-get.xml job jpaService evaluate ,oozie,1
getBooleanWithDefault thenReturn NinjaConstant invoke when param1 longParam context create ninjaProperties mockController getParameter longParamEmptyStrictModeWorks ,ninja,0
"@ closeTrx coordClient getStore getTime LocalOozie 2009-12-15T01:00Z 2009-12-16T01:00Z Could not update db. getStatus -testCoordRerun-C getCoordClient rerunScope get beginTrx CoordinatorAction reRunCoord actionNum2 commitTrx actionNum1 coord-rerun-action2.xml RestConstants printStackTrace store1 e store , actionId2 addRecordToJobTable jobId actionId1 Services fail CoordinatorJob addRecordToActionTable assertNotSame testCoordRerunDate3 0000000- action1 action2 coord-rerun-action1.xml getCoordinatorAction ",oozie,1
" check that / exists  create a new file in the root, write data, do no close conf System createFile path io.bytes.per.checksum  Make sure a client can read it before it is closed close fileSystem "" partialBlockSize /unfinished-block TestFileCreation stm / getInt Path : "" writeFileAndSync  write partial block and sync checkCanRead toString file1 testUnfinishedBlockPacketBufferOverrun bytesPerChecksum ",hadoop,1
b_out cluster a b conf getFileSystem dir fs delete something hasLease Assert a_out writeBytes build assertTrue numDataNodes mkdirs create close shutdown testLease ,hadoop,1
server RPC getDefaultSocketFactory conf blockKeyUpdateInterval allOf generateToken getBlockId getReplicaVisibleLength stopProxy sm addr UserGroupInformation createMockDatanode addToken ticket block3 EnumSet DFSUtil start assertEquals createRemoteUser token getConnectAddress testBlockTokenRpc proxy blockTokenLifetime createClientDatanodeProtocolProxy NetUtils stop toString ,hadoop,1
cluster parent  should never reach here. conf getFileSystem fs delete Not a HDFS:  build assertTrue testRecrusiveRm numDataNodes mkdirs close getUri shutdown child ,hadoop,1
files option does not match fileName getCurrentUser -tokenCacheFile getCredentials conf  create file delete creds getBytes password ugiCreds mapreduce.job.credentials.binary assertTrue numberOfTokens assertNotNull FileSystem token-service token-alias get files is null UserGroupInformation tokenCacheFile identifier addToken e getAbsolutePath toURI ugiToken assertEquals writeTokenStorageFile testDir tmpFile FileNotFoundException is not thrown  pass a files option token-kind token args localFs th getLocal makeQualified getToken exists  test non existing file toString testTokenCacheOption tmpPath ,hadoop,0
checkCoordJobs toDate getId DateUtils System parseDateOozieTZ addRecordToCoordJobTable call CoordinatorJob 2099-02-03T23:59Z currentTimeMillis startTime endTime job testMatLookupCommand3 ,oozie,1
 getInstances set getName testGetInstances empty.property no.such.Class does not exist classes isEmpty conf assertEquals no.such.Class fail size assertTrue setStrings java.lang.String does not implement SampleInterface no.such.property some.classes ,hadoop,0
date simpleMap_Set scriptExecutor session  Given update simple simplemap Eq doesNotContainEntry  When of where id row ten table executeScriptTemplate containsEntry RandomUtils manager one new_twenty simpleMap nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap getMap hasSize should_dsl_update_map_set  Then Long buildDateKey fromBaseTable dsl SELECT simplemap FROM simple WHERE id =  thirty ,achilles,1
addRecordToBundleActionTable testPurgeBundleWithCoordChildWithWFChildWithSubWF2 addRecordToWfActionTable coordActionGetCmd getNumDaysToNotBePurged DateUtils WorkflowInstance getStatus addRecordToCoordActionTable parseDateOozieTZ SubWorkflow Job should not have been purged getEndTime bundleJob BundleJobBean assertNotNull CoordinatorAction Job wfAction wfJobGetCmd Bundle Action should not have been purged execute subwfActionGetCmd Bundle Job should not have been purged CoordinatorJob 1 coordJobGetCmd fail WorkflowAction coordAction SUCCEEDED Workflow Action should not have been purged subwfJobGetCmd bundleJobGetCmd getId coordJob SubWorkflow Action should not have been purged wfJob addRecordToWfJobTable get Workflow Job should not have been purged WorkflowJob subwfAction getAppName bundleAction wfActionGetCmd Coordinator Action should not have been purged 2011-01-01T01:00Z addRecordToBundleJobTable assertEquals getLastModifiedTime addRecordToCoordJobTable Coordinator Job should not have been purged call Services coord-action-get.xml subwfJob jpaService bundleActionGetCmd ,oozie,1
server Server assertFalse start conf assertEquals run  Override client to store the call id  side we should see retry count as 0 testInitialCallRetryCount getConnectAddress  Attach a listener that tracks every call ID received by the server. caller Assert NetUtils stop client getCallRetryCount addr ,hadoop,0
getCurrentBlockPoolID cluster dfs.datanode.scan.period.hours testCases log bpid assertFalse CURRENT_SHOULD_EXIST_AFTER_RECOVER prevAfterRecover checkResultBlockPool conf createNameNodeStorageState PREVIOUS_SHOULD_EXIST_AFTER_RECOVER get numDirs SHOULD_RECOVER StartupOption PREVIOUS_TMP_EXISTS curAfterRecover startDataNodes getDataNodes shouldRecover CURRENT_EXISTS  First setup the datanode storage directory testBlockPoolStorageStates initializeStorageStateConf  DataNode will create and format current if no directories exist baseDirs isBPServiceAlive REMOVED_TMP_EXISTS setInt createBlockPoolStorageState UpgradeUtilities PREVIOUS_EXISTS BLOCK_POOL recovery createCluster shutdown NUM_DN_TEST_CASES testCase ,hadoop,1
"expires TOKEN_MAX_INACTIVE_INTERVAL _testDoFilterAuthenticationMaxInactiveInterval testDoFilterAuthenticationUnauthorizedExpired TOKEN_VALIDITY_SEC currentTimeMillis authorized maxInactives  Expired period is reached, MaxInActiveInterval is not reached. System ",hadoop,0
testAddRemoveCycle h h1 h2 assertEquals h3 fifoBuffer h4 assertSame getLast removeLast 1 2 3 Assert 4 size getFirst get addFirst ,httpcore,0
add stat max SampleStat num samples assertEquals EPSILON min variance numSamples mean reset testSimple stddev ,hadoop,0
date ALL scriptExecutor session LOCAL_ONE  Given update simple Eq consistencylist containsExactly QUORUM  When getList of where id row table executeScriptTemplate RandomUtils manager one nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap SELECT consistencylist FROM simple WHERE id =   Then Long buildDateKey fromBaseTable consistencyList dsl should_dsl_update_list_append consistencyList_AppendTo ,achilles,1
verifyPaths fs ips authorities testFullAuthorityWithDefaultPort myfs://host.a.b:123 getVerifiedFS ,hadoop,0
"getCpuFrequency getNetworkBytesRead  undef on first call parseSystemInfoString getCumulativeCpuTime tester 17177038848,8589467648,15232745472,6400417792,1,2805000,6261812, getNumProcessors getStorageBytesWritten assertEquals getPhysicalMemorySize getStorageBytesRead 1234567,2345678,3456789,4567890  getVirtualMemorySize CpuTimeTracker getAvailablePhysicalMemorySize setSysinfoString getNetworkBytesWritten getNumVCoresUsed  info str derived from windows shell command has \r\n termination getAvailableVirtualMemorySize getNumCores getCpuUsagePercentage ",hadoop,0
p1 p2 getKMSUrl conf when getCause times assertTrue Should fail since provider p1 threw AuthenticationException verify thenThrow testClientRetriesWithAuthenticationExceptionWrappedinIOException kp e anyString thenReturn createKey eq any setInt CommonConfigurationKeysPublic fail test3 Mockito mock ,hadoop,0
date scriptExecutor session LOCAL_ONE  Given update simple Eq consistencylist asList QUORUM  When of where id row table executeScriptTemplate should_dsl_update_list_removeAll RandomUtils manager one nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap isTrue SELECT consistencylist FROM simple WHERE id =  consistencyList_RemoveAllFrom  Then isNull Long buildDateKey fromBaseTable consistencyList dsl ,achilles,1
getId assertEquals getStatus execute addRecordToCoordJobTable call CoordinatorJob Services coordJobGetCmd assertNotNull get testCoordSuspendWithErrorPostive job jpaService ,oozie,1
factory testExplicitProvider getName setProvider assertNotNull TrustManagerFactory getDefaultAlgorithm getProvider getInstance factoryBean createTrustManagerFactory ,logback,0
 application/xml application/xml; param=x application/json testContentTypeJsonCron MyJsonRestServlet HttpServletResponse invoke assertEquals json=object call contains assertTrue array response GET invokeAndGetResponse json=array runTest object ,oozie,1
ErasureCodeConstants coder XORRawErasureCoderFactory NativeXORRawErasureCoderFactory RSLegacyRawErasureCoderFactory getCoderByName assertTrue RSRawErasureCoderFactory getInstance NativeRSRawErasureCoderFactory CodecRegistry testGetCoderByName ,hadoop,0
"${PB} ${firstNotNull(null, 'b')} workflow ${trim(' ')} ${MB} ${concat('a', 'b')} ${TB} createEvaluator Services eval ${timestamp()} assertNotNull ${urlEncode('abc')} get ${KB} testELForWorkflow evaluate ${GB} ",oozie,1
SASL_PRIVACY_PROPS conf 10.221.103.121 10.222.103.121 variablewhitelist.txt removeFile getByName wqr testFixedVariableAndLocalWhiteList 10.222.0.0/16 WhitelistBasedResolver 10.119.103.112 set 10.119.103.113 10.113.221.222 10.113.221.221 10.221.102.0/23 getServerProperties assertEquals 10.221.104.0 setConf fixedIps createFileWithEntries setLong TestFileBasedIPList variableIps getDefaultProperties InetAddress fixedwhitelist.txt 127.0.0.1 setBoolean 10.223.104.0 ,hadoop,0
"deleteList addRecordToWfActionTable getId WorkflowInstance actionC1 actionC2 actionA1 Workflow Action A1 should not have been deleted actionA2 deactivate jobB addRecordToWfJobTable jobA assertNotNull  Remove fault injection jobC get Workflow Action A2 should not have been deleted Workflow Action C1 should not have been deleted WorkflowJob testDeleteWorkflowsRollback add Should have skipped commit for failover testing Skipping Commit for Failover Testing Workflow Job A should not have been deleted Workflow Action B1 should not have been deleted getMessage Workflow Action C2 should not have been deleted assertEquals Workflow Job B should not have been deleted SkipCommitFaultInjection actionB1 execute actionB2 FaultInjection 1 Services fail 2 re Workflow Action B2 should not have been deleted WorkflowAction org.apache.oozie.command.SkipCommitFaultInjection setSystemProperty true  set fault injection to true, so transaction is roll backed jpaService Workflow Job C should not have been deleted ",oozie,1
set getProperty CommonConfigurationKeys LOG testNetgroupShell GenericTestUtils groups user.name conf groupList setRootLogLevel System  has GROUPS:  size assertTrue Level toString org.apache.hadoop.security.ShellBasedUnixGroupsNetgroupMapping getGroups username info ,hadoop,0
"reader LocalOozie checkSuspendActions conf getStatus assertNotNull decision1 create workflow.xml app :start: getFileSystem action4a action4b action4c OozieClient jobId copyCharStream mkdirs setProperty getResourceAsReader createConfiguration File action1,nonexistant_action_name,decision1, action3,join1 ,fork1,action4b oozie.suspend.on.nodes submit getJobInfo fs appPath join1 wf oc end WorkflowJob close resume start assertEquals getClient testSuspendPoints wf-suspendpoints.xml IOUtils getTestUser toString writer action1 action2 action3 fork1 getFsTestCaseDir ",oozie,1
INPUT_BUFFER_LEN read rw f HALFWAY assertEquals delete ByteBuffer seek output input buf IOUtils rewind getChannel raf exists testWriteFully fc wrap close writeFully TEST_FILE_NAME ,hadoop,0
factory Guice  this will not work => we expect a runtime exception with the impl missing does_not_exist i.am.a.test.implementation logger thrown expect NinjaMode createInjector setProperty  this should be okay since we want to defer the resolution until a 'get' create ninjaProperties injector missingImplementationDeferredUntilGet ,ninja,0
getBytesTransferred a lot more stuff! beginning rw stuff;  CodecTestUtils more stuff;  channel testDecodingFileWithOffsetAndBufferedSessionData getBytes Assert inbuf getChannel pos beginning; stuff; more stuff; a lot more stuff! close write fchannel isCompleted testfile beginning;  StandardCharsets length bytesRead assertEquals createTempFile decoder fill setLength transfer  count everything except the initial 7 bytes that went to the session buffer readFromFile metrics ,httpcore,0
checkCoordActions getId DateUtils parseDateOozieTZ addRecordToCoordJobTable 2009-03-06T10:00Z call CoordinatorJob pauseTime 2009-03-06T10:08Z startTime endTime job testActionMaterWithPauseTime2 2009-03-06T10:14Z ,oozie,1
readFields set _testGet bean2 toByteArray dos testSerialization baos write close bean ,oozie,1
END_POINTS -file IS_SECURITY_ENABLED oozieUrl run appPath pig submitPig assertTrue testSubmitPig get -config SERVLET_CLASSES runTest app getContextURL MockDagEngineService assertEquals getFileSystem args call createPigPropertiesFile -oozie mkdirs wfCount createPigScript toString getFsTestCaseDir ,oozie,1
getStatus SubWorkflowActionExecutor protoConf createBaseWorkflow getWorkflowClient newConf xyz create action </app-path> workflow.xml write getBaseProtoConf waitFor workflow testConfigNotPropagation getFileSystem check childConf       </configuration> WorkflowAction File evaluate <sub-workflow xmlns='uri:oozie:workflow:0.1' name='subwf'>       <app-path>       <configuration> getJobInfo           <name>a</name>         </property> getActions getExternalId fs APP1           <value>A</value> wf W get end WorkflowJob close abc set getConf oozieClient         <property> start defaultConf subWorkflowAppPath subWorkflow assertEquals JOB_TIMEOUT setConf assertNull toXmlString </sub-workflow> writer getFsTestCaseDir ,oozie,1
getConnectionContext getEventMessage session JMSMessagingUtils getUser conf getStatus createSession getTopic wf-app-name1 Assert ='JOB' testWorkflowJobSelectorsAnd caId1 ='FAILURE' AND  selector wfId1 WorkflowJob jmsContext consumer MessageType user1 getMessageType init receive ='WORKFLOW_JOB' AND  printStackTrace e getMessage destroy  Pass a selector using AND condition assertEquals message wfEventListener fail onWorkflowJobEvent JMSHeaderConstants wfe createConsumer wfFailMessage Session ,oozie,1
"testReadWithKnownLength  Read shorter length, make sure it shortens in line assertEquals hello world readWithKnownLength getBytes hello w inputBytes  Read longer length, make sure it lengthens reset toString text he Charsets ",hadoop,0
getCurrentDateafterIncrementingInMonths run getId DateUtils getStatus addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob testCoordStatusTransitServiceStaleCoordActions  add a record with stale reference to coord job id sleep get CoordinatorAction end  this block will initialize the lastinstancetime for status transit service currentDatePlusMonth ABCD start assertEquals XDataTestCase execute addRecordToCoordJobTable  add records with reference to correct job ids CoordinatorJob Services runnable coord-action-get.xml job jpaService ,oozie,1
primLongParam assertFalse context create verify hasViolations primLongParamShouldHandleNull invoke mockController validation ,ninja,0
pp testSmoke foo 3 foo foo3.xixo foo%i.xixo assertEquals foo.%3i.log foo.43.log foo.%1i.log %i foo foo.%i.log foo.003.log t convertInt context foo3.log foo%i.log foo.3.log ,logback,0
prefix declareProperty conf run String out CONFIG some.config some.config.value- addResource xyz join value add set valueOf testConcurrentAccesses start endConfig threads startConfig t fileResource config ,hadoop,0
${coord:tableIn('ABCD')} init  -ve test CoordELFunctions setVariable testTablePh1  +ve test assertEquals ${coord:tableOut('ABCD')} data-in coord-job-submit-data           * tableOut           fail should throw exception because Data-in ABCD is not defiend ${coord:tableIn('ABC')}           * tableIn           eval evalAndWrap should throw exception because Data-out ABCD is not defiend expr oozie.dataname.ABC ${coord:tableOut('ABC')} data-out ,oozie,1
@ closeTrx coordClient getStore getTime LocalOozie Could not update db. Exception expected because action is not in terminal state. getStatus -testCoordRerun-C getCoordClient getErrorCode get beginTrx CoordinatorAction reRunCoord commitTrx actionNum RestConstants printStackTrace e store2 Error code should be E1018 when action is not in terminal state. testCoordRerunActionsNeg2 assertEquals store addRecordToJobTable Integer jobId Services fail CoordinatorJob ex addRecordToActionTable equals actionId 0000000- toString ErrorCode action2 coord-rerun-action1.xml getCoordinatorAction ,oozie,1
subwfJobGetCmd addRecordToWfActionTable getId WorkflowInstance getStatus addRecordToWfJobTableForNegCase SubWorkflow Job should not have been purged SubWorkflow Action should not have been purged wfJob addRecordToWfJobTable assertNotNull get Workflow Job should not have been purged WorkflowJob wfAction subwfAction wfJobGetCmd testPurgeWFWithSubWF2 wfActionGetCmd assertEquals execute subwfActionGetCmd call Services 1 fail WorkflowAction subwfJob jpaService Workflow Action should not have been purged ,oozie,1
 thread addAppender checkThatStartMethodIsIdempotent start lossyAsyncAppender asyncAppenderBase ,logback,0
actionNum testCoordActionGet job2 job1 getId addRecordToCoordActionTable _testCoordActionGetByLastModifiedTime addRecordToCoordJobTable CoordinatorJob jobId2 jobId1 coord-action-get.xml dateBeforeAction  Get date before action is created CoordinatorAction  Add two jobs with lastmodifiedtime > dateBeforeAction ,oozie,1
AAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP/ /SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQ KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAA  This specially-formatted frame has trailing deflated bytes after the name value block. AAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD A//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9 //0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0o headerBlockHasTrailingCompressedBytes2048 EAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAAAAP//SgQAAAD//0oEAAA gAMAAgAAB/sAAAABeLvjxqfCAqYjRhAGJmxGxUQAAAAA//9KBAAAAP//SgQAAAD//0oEAAAA//9KBAA headerBlockHasTrailingCompressedBytes AAAD//0oEAAAA//8= frame ,okhttp,1
cluster getZKFCProxy start conf assertEquals waitForActiveLockHolder getService Thread sleep  allow to quiesce stop gracefulFailover testGracefulFailover ,hadoop,1
"getConnectionContext getName randomPort conf wf-app-name1 tcp://localhost: assertNotNull caId1 testConnectionDrop wfId1 init printStackTrace destroy , wfEventListener ActiveMQConnFactory fail java.naming.provider.url# stop onWorkflowJobEvent createConsumer ;  Exception Listener should have removed the old conn context JMSJobEventListener ;connectionFactoryNames# session createSession getTopic random brokerURl ConnectionFactory jmsContext WorkflowJob java.naming.factory.initial# consumer user1 receive set getConf e start getMessage services nextInt broker message addConnector Services assertNull wfe Session ",oozie,1
assertCorrectImage2string (11)100224(17)110224(3102)000100 testDecodeRow2string1 1.png ,zxing,0
newSimpleStatement exception SELECT * FROM entity_with_clusterings WHERE id = :id manager session query  Given expectMessage expect The typed query [select * from entity_with_clusterings where id = :id] should contain the table name 'simple' if the entity type is 'info.archinnov.achilles.internals.entities.SimpleEntity'  When typedQueryForSelect getList statement should_fail_regular_typed_query_if_table_not_correspond ,achilles,1
AA BB a A b setVariables c resolveVariable setVariable assertEquals getVariable put fail assertNull testContextVars vars support ,oozie,1
conn Assert bind Mockito Timeout assertEquals getSoTimeout socket testGetSocketTimeoutException getSocketTimeout when thenThrow ,httpcore,0
exception getLocalizedMessage NinjaConstant equalTo when getBadRequestResult Result result getRenderable assertTrue verify not important getTemplate ArgumentMatchers thenReturn getWithDefault getMessage eq  real test: assertThat any ninjaDefault testGetBadRequest getStatusCode contextImpl messages ninjaProperties ,ninja,0
cluster fileName bpid getRbwDir conf dn Windows fs waitReplication delete System createFile waitActive assertTrue get os.name storageDir DFSTestUtil getProperty startDataNodes getBlockPoolId MiniDFSCluster setWritable getDataNodes  restore its old permission  create files and make sure that first datanode will be down /test.txt dir2 dir1 Couldn't chmod local vol testShutdown dnIndex  Bring up two more datanodes getInstanceStorageDir setReadOnly  make the data directory of the first datanode to be readonly startsWith getNamesystem isDatanodeUp ,hadoop,1
" backoff is enabled, add + scheduler backoff = overflow exception. CallQueueOverflowException  backoff is enabled, put + scheduler backoff = overflow exception. when getCause shouldBackOff put scheduler times assertTrue  call queue exceptions passed threw as-is testCallQueueOverflowExceptions cqmTriggerFailover verify didn't throw  backoff enabled, put is add to queue. Boolean  exception. add setClientBackoffEnabled doReturn unchecked  call queue exceptions that trigger failover getMessage assertEquals didn't fail assertSame call fail doThrow ex Mockito  backoff disabled, put is put to queue. cqe mock reset toString spy queue cqm ",hadoop,0
testC40EncodationSpecExample  Example in Figure 1 in the spec visualized assertEquals A1B2C3D4E5F6G7H8I9J0K1L2 230 88 88 40 8 107 147 59 67 126 206 78 126 144 121 35 47 254 encodeHighLevel ,zxing,0
release times Assert assertNotNull get verify close entry2 entry3 getLeased conn3 conn2 entry1 conn1 assignConnection ArgumentMatchers somehost pool assertEquals totals future3 any never future1 future2 Mockito otherhost CloseMode mock lease getPending testLeaseRelease getTotalStats getAvailable ,httpcore,0
SELECT child_value FROM entity_child WHERE id =  child_value Set scriptExecutor session  Given update simple Eq should_dsl_update_child_value  When of where id EntityAsChild/insert_single_row.cql row table anotherValue executeScriptTemplate isNotNull RandomUtils manager one getString nextLong assertThat another_child_val execute ImmutableMap  Then Long fromBaseTable dsl isEqualTo ,achilles,1
CodecTestUtils StandardCharsets channel assertEquals encoder ByteBuffer empty testCodingEmptySrcBuffer Assert allocate flush outbuf assertTrue metrics dump complete wrap write flip stuff isCompleted ,httpcore,0
"cluster Checking for file   Choose 3 copies of block file - delete 1 and corrupt the remaining 2 conf dfsClient fileCount waitActive  first time format waitForBlockReplication  only 3 copies exist getBlockFile len getNamenode create block buffer write info localhost Deleting file  DFSConfigKeys dfs.datanode.block.write.timeout.sec LOG format getFileSystem 0.75f testFile dnIndex numDataNodes  get first block of the file.  corrupt it. Long getNameNodePort shutdown getBlockLocations Restarting minicluster after deleting a replica and corrupting 2 crcs rw Corrupting file  seek delete out blockFile testPendingReplicationRetry assertTrue get close /replication-test-file getBlock blockOut set MiniDFSCluster length  This test makes sure that NameNode retries all the available blocks     * for under replicated blocks.     *     * It creates a file with one block and replication of 4. It corrupts     * two of the blocks and removes one of the replicas. Expected behavior is    * that missing replica will be copied from one valid source.     assertEquals  Start the MiniDFSCluster with more datanodes since once a writeBlock        * to a datanode node fails, same block can not be written to it        * immediately. In our case some replication attempts will fail.         Integer testPath build exists toString ",hadoop,1
"coord-multiple-input-end-instance1.xml Expected to catch errors due to incorrectly specified input data set end-instances reader conf getStatus appPath getJob sc coord-multiple-input-end-instance2.xml testBasicSubmitWithMultipleEndInstancesInputEvent getErrorCode assertTrue file:// getTestCaseDir UNIT_TESTING  CASE 1: Failure case i.e. multiple data-in start-instances getPath Coordinator app definition should not have multiple end-instances Job coordinator.xml set e getMessage assertEquals call OozieClient fail IOUtils contains getTestUser copyCharStream Unexpected failure:  getResourceAsReader writer ErrorCode File  CASE 2: Success case i.e. Single end instances for input and single end instance for output, but both with "","" ",oozie,1
"charset ContentType text/blah; p=blah getCharset that this and that Assert testWithParams create text/blah; charset=ISO-8859-1; p=blah contentType ascii text/plain blah getMimeType text/plain; charset=UTF-8; p=this; p=that StandardCharsets UTF-8 this text/blah assertEquals p text/plain; charset=ascii; p=""this and that"" withParameters toString ",httpcore,0
 Servlets should have text/plain with proper encoding by default /echo?a=b.css conn testContentTypes openConnection JettyUtils assertEquals /static/test.css baseUrl  Static CSS files should have text/css  Servlets that specify text/html should get that content type cssUrl getResponseCode  ending in .css should not change mime type getContentType /echo?a=b servletUrl MediaType /htmlcontent ; text/css connect ,hadoop,0
cluster fs2 fs1 Waiting for close to get to latch... Opening file for append from new fs conf run when waitActive waitForCall assertNotNull appenderStream delayer create join write  write 1/2 block info Lease mismatch proceed LOG anyString /testCompleteOtherLease interruptAndJoin Waiting for close to finish. getFileSystem anyObject stm Killing lease checker preSpyNN contains numDataNodes testCompleteOtherLeaseHoldersFile spy shutdown recoverFile doAnswer assertTrue get client  error. close  Lose the leases set err getConf start Recovering file getMessage getNameNodeRpc Telling old close to proceed.  Delay completeFile AppendTestUtil t build spyNN createHdfsWithDifferentUsername Close finished. Writing some data from new appender thrownByClose file1 complete append  The appender should be able to close properly ,hadoop,1
"scheme specials setScheme /abcd!$&*()_-+.,=:;'~@[]?<>|#^%""{}\Â£`Â¬Â¦xyz Assert setCustomQuery host getPath getLoopbackAddress https getHostAddress bld getHost getQuery loopbackAddress  N.B. excludes space setFragment setPath assertEquals  Check that the URI generated by URI builder agrees with that generated by using URI directly uri URIBuilder setUserInfo testLoopbackAddress build getFragment getUserInfo InetAddress ",httpcore,0
byteParamShouldHandleNull byteParam assertFalse context create verify hasViolations invoke mockController validation ,ninja,0
" Test case where dir-files=false, recursive=false chgrp <fs/> dir fs createContext setOwner path getTestGroup testGroup getFileStatus context testUser grandchild getTestGroup2  revert to testgroup ae testGroup2 assertEquals getFileSystem getTestUser testChgrp mkdirs getGroup toString getFsTestCaseDir child ",oozie,1
cluster /ForceTestDir  Tests for copyFromLocal  Tests for put conf testFileForPut run testdir fs delete argv ToolRunner -put TEST_ROOT_DIR -f ERROR -cp cp -f is not working close writeFile testCopyCommandsWithForceOption hdfsTestDir res SUCCESS localFile cp command itself is able to overwrite the file getAbsolutePath copyFromLocal command itself is able to overwrite the file format localfilepath assertEquals getFileSystem put -f is not working  Tests for cp build shell numDataNodes mkdirs exists -copyFromLocal copyFromLocal -f is not working  force Copy Option is -f createNewFile shutdown put command itself is able to overwrite the file ,hadoop,1
session thenReturn invoke sessionParam when param1 get context create verify sessionParamAnnotatedArgumentShouldBePassed value mockController ,ninja,0
key1 t.abc.ey3 key2 res set value2 value1 key3 containsKey key4 value3 conf t.abc.key1 t.abc.key2 Conf didn't get key  getValByRegex assertTrue testGetValByRegex Picked out wrong key  ^t\..*\.key\d tt.abc.key3 ,hadoop,0
"0 Footer1: looooooooooooooooooooooooooooooooooooooooooooooooooooooog   dst CodecTestUtils 10 1234567890123456  convert metrics2 metrics1 Assert MessageConstraintException expected assertNotNull testTooLongFooter read 1234567890123456 StandardCharsets  ""0\r\nFooter1: looooooooooooooooooooooooooooooooooooooooog\r\n   \r\n  fghij\r\n\r\n""; decoder1 clear bytesRead channel1 inbuf1 assertEquals channel2 decoder2 ByteBuffer inbuf2 trailers fail allocate size getTrailers ",httpcore,0
hasFieldViolation thenReturn shortParam invoke when param1 shortValidationShouldWork assertTrue context create verify mockController validation blah getParameter ,ninja,0
log4jFile test-log4j.properties init currentThread getTestCaseConfDir XLogService getResourceAsStream ls assertFalse testCustomLog4jFromConfigDir cl destroy is assertEquals getLog4jProperties Thread IOUtils Assert test-oozie-log4j.properties getFromClasspath getContextClassLoader copyStream setSystemProperty ,oozie,1
getBytesTransferred CodecTestUtils channel times Assert flush verify more stuff dump stuff---more stuff write testCodingFragmentBufferingTinyFragments ArgumentMatchers StandardCharsets assertEquals encoder - any Mockito outbuf metrics spy wrap stuff ,httpcore,0
log4jFile getTestCaseConfDir getLog ls assertFalse testLog4jReload sleep assertTrue isTraceEnabled waitFor test-custom-log4j.properties init a currentThread XTestCase XLogService getResourceAsStream cl destroy is originalRatio Thread LogFactory 1 IOUtils test-oozie-log4j.properties getContextClassLoader copyStream setSystemProperty evaluate ,oozie,1
getLocation setBatch unmarshaller body countCellSet delete put  confirm batch size conformance TABLE  new scanner Bytes /scanner assertNotNull marshal get client model marshaller getCode addColumn scannerURI  get a cell set getBody cellSet toBytes assertEquals  delete the scanner / BATCH_SIZE unmarshal COLUMN_1 response testSimpleScannerXML toString writer MIMETYPE_XML ,hadoop,1
key1  configProperty > defaultValue key2 conf/overlayed.conf key3 getInteger conf/overlayed.empty.conf nullValue test1 System precedence clearProperty NinjaMode default current  no value anywhere get getBoolean Boolean  defaultValue > nothing  currentValue > systemProperty is assertThat 2 system setProperty true ninjaProperties  systemProperty > configProperty ,ninja,0
rw channel header stuff;more stuff testCodingFromFileFlushBuffer getBytes stuff; Assert getChannel assertTrue writeLine more stuff dump chbuffer close write fchannel isCompleted testfile StandardCharsets createTempFile assertEquals encoder transfer outbuf header metrics append ,httpcore,0
testAsyncClose_read writeLock gotAsyncCloseException channel Executors handlerLatch getCause sleepUninterruptibly WRITE  cause another thread trying to read to block exc assertTrue executor get await lock countDown close MILLISECONDS read set newFixedThreadPool expected store completed failed  give enough time to ensure both reads start blocking byteStore ByteBuffer READ fail allocate future Uninterruptibles shutdown ,jimfs,1
application/xml testThatContentNegotiationWithFallbackWorks headers getServerAddress Accept ninjaTestBrowser newHashMap equalTo Person is: zeeess name - and some utf8 =&gt; Ã¶Ã¤Ã¼ assertThat makeRequest put Maps text/html response application/unknown_content_type api/person_with_content_negotiation_fallback ,ninja,0
(15)991231(15)991231(3103)001750(10)12A checkFields testParseField2 ,zxing,0
next metricsRecord incrementCnt getMetrics  create test source with a single metric counter of value 0 source metricsRecords sa longValue C1 sb sleep iterator getAttribute assertTrue builder injectedTags newSourceBuilder value  all metrics are initially assumed to have changed  skip JMX cache TTL test assertEquals hasNext Thread  change metric value  Validate getMetrics and JMX initial values build test desc MetricsAnnotations metrics  validate getMetrics and JMX testGetMetricsAndJmx ,hadoop,0
addToken new token should be selected when both exist kp oldToken conf assertEquals creds uri getService token providerUriString testSelectTokenWhenBothExist t selectDelegationToken close ,hadoop,0
"DagELFunctions def conf dir createEvaluator ${fs:fileSize(wf:conf('file2'))} protoConf getTestCaseDir create setId action setUser write group testFunctions workflow test.dir ${fs:fileSize(wf:conf('file1'))} getFileSystem , ${fs:blockSize(wf:conf('file2'))} OozieClient setGroup eval ${fs:exists(wf:conf('file1'))} mkdirs ${fs:exists(wf:conf('dir'))} name actionId ${fs:exists(wf:conf('file2'))} job evaluate actionName setName addNode writeXml getId fs appPath setAppPath baos ${file2} wf assertTrue configureEvaluator get <workflow-app/> end hadoop.job.ugi close setProtoActionConf setWorkflowInstance ${fs:blockSize(wf:conf('file1'))} arr a b setAppName set os assertEquals ${fs:isDir(wf:conf('file1'))} Services getTestUser ${fs:dirSize(wf:conf('dir'))} file2 file3 toString file1 wfId getFsTestCaseDir ",oozie,1
end.non-transient assertTrue _testNonTransientWithCoordActionUpdate testEndNonTransientWithCoordActionUpdate end WorkflowActionBean ,oozie,1
Services callable assertTrue scheduled testDelayedQueuing get currentTimeMillis evaluate waitFor queueservice System queue ,oozie,1
validationWithOptionalFailedWithTwoAnnotations validateJSR303WithOptional length buildDto context regex!!! which is also too long doValidationFailedWithTwoAnnotations ,ninja,0
 p1 testChown/nonExistingfiles* p4 p5 p6  Test 5: test for setOwner invocation on FS from command handler. admin f1 f2 f3 testChown/fileExists f7 assertTrue Test TEST_ROOT_DIR  create and write test file  Test 2: exit code for chown on non-existing path is 1 testChown getPath writeFile  Test 3: exit code for chown on non-existing path with globbed input is 1  Test 4: exit code for chown on existing path with globbed input is 0 toUri change testChown/file* testChown/fileDoesNotExist  create required files testChown/file1 testChown/file2 testChown/file3 fileSys exists  Test 1: exit code for chown on existing file is 0 ,hadoop,0
coordClient 2009-02-02T23:59Z LocalOozie coordActionGetCmd getId DateUtils getStatus addRecordToCoordActionTable parseDateOozieTZ coordJob getCoordClient testCoordRerunForBackwardSupport3 rerunScope assertNotNull get CoordinatorAction end reRunCoord init RestConstants 2009-02-01T01:00Z start destroy assertEquals services setAppNamespace execute - addRecordToCoordJobTable Integer Services CoordinatorJob coordJobGetCmd SchemaService setSystemProperty assertNotSame true StatusTransitService toString action1 action2 jpaService action3 coord-rerun-action1.xml ,oozie,1
formatDate play A Last-Modified:  server readAscii addHeader Warning openConnection assertEquals setBody setResponseCode getHeadersDeletesCached100LevelWarnings / Cache-Control: max-age=0 enqueue getUrl getHeaderField Warning: 199 test danger HttpURLConnection connection1 TimeUnit 199 test danger connection2 ,okhttp,1
" some nada foo MsInfo .NumActiveSources=foo.NumActiveSinks=bar.NumAllSinks=haa haa none testTagsForPrefix .sink.ganglia sb bar record host NumActiveSinks,  cb add all init set appendPrefix sink .sink.ganglia.tagsForPrefix.none * assertEquals .sink.ganglia.tagsForPrefix.some tags testNamePrefix .sink.ganglia.tagsForPrefix.all toString NumActiveSources metrics .NumActiveSources=foo.NumActiveSinks=bar subset ",hadoop,0
"init  -ve test CoordELFunctions testDataInPartitionMinPh1 setVariable  +ve test assertEquals oozie.dataname.ABCD data-in coord-job-submit-data fail ${coord:dataInPartitionMin('ABCD')} eval evalAndWrap should throw exception because EL function requires 2 parameters expr oozie.dataname.ABC ${coord:dataInPartitionMin('ABC', 'mypartition')} ",oozie,1
cluster conf run exitcode args= FSInputChecker asList getPath options runner mkdir -get fname createLocalFile count stringifyException getFileSystem /test/get files= / dfs shell numDataNodes files setLogLevel2All Arrays shutdown copyFromLocalFile dst show localf delete substring testGet assertTrue TEST_ROOT_DIR StringUtils corruptedcontent root close localfcontent DFSTestUtil corrupt  find and modify the block files e testGet.txt assertEquals getBlockFiles setConf args remotef build -ignoreCrc readFile toString charAt ,hadoop,1
Services testGetSLAEventsWithRange slaEventsGetCmd lastSeqId size assertNotNull get assertEquals filterList list jpaService execute ,oozie,1
getName getUserPrincipal tokenSigned TOKEN_VALIDITY_SEC sign when asList getInitParameterNames Assert secretProvider management.operation.return signer http://foo:8080/bar getRequestURL init cookie thenReturn StringSignerSecretProviderCreator destroy invocation getInitParameter newStringSignerSecretProvider setProperty true mock getArguments Arrays request setExpires secret System secretProviderProps doAnswer doFilter getCookies AuthenticatedURL chain AuthenticationFilter testDoFilterAuthenticated assertEquals any token filter p args getMockedServletContextWithStringSigner t answer Mockito u getRemoteUser response elements currentTimeMillis toString config ,hadoop,0
mExecutorService  openCloseTest user_createFile assertFalse isConnected Constants masterClient /file getMasterAddress Assert assertTrue getFileStatus mMasterInfo close connect ,alluxio,1
play bogus data ping  play it back  verify the peer received what was expected assertEquals INVALID_STREAM  RST_STREAM TYPE_RST_STREAM bogusDataFrameDoesNotDisruptConnection acceptFrame sendFrame peer SPDY3  write the mocking script  PING connection writeUtf8 takeFrame rstStream ,okhttp,1
getBytesTransferred rw stuff;  CodecTestUtils more stuff;  channel Assert inbuf getChannel pos testBasicDecodingFile stuff; more stuff; a lot more stuff! a lot more stuff!!! close fchannel isCompleted testfile StandardCharsets length bytesRead createTempFile assertEquals decoder transfer readFromFile  ----------------- FileChannel Part testing ---------------------------  metrics ,httpcore,0
"00 reader  Make an index entry for every third insertion. FIRST_KEY conf  less than first key in the mapfile, that the first key is returned. FileSystem 90  Get closest that falls before the passed key: 50  the first key in the file, we should get null 50 TEST_DIR testGetClosest.mapfile 55  Assert that closest after 55 is 60 99 LOG  Assert that null is returned if key is > last entry in mapfile. deprecation TWENTY getIndexInterval testGetClosest qualifiedDirName  Test get closest when we pass explicit key iStr 60  Now do getClosest on created mapfile. 20 dirName  Write a mapfile of simple data: keys are  Add entries up to 100 in intervals of ten. MapFile fs cleanupWithLogger substring getClosest  If we were looking for the key before, we should get the last key close value key  Assert that the index interval is 1 length assertEquals Integer parseInt IOUtils setIndexInterval assertNull t getLocal makeQualified toString writer append closest ",hadoop,0
TaskEventType values 1000 conf stagingDir timeout getAttempts  Job has only 1 mapper task. No reducers times createRunningStubbedJob committer  FAIL_ABORT state await verify dispatcher testFailAbortDoesntHang init set commitHandler JobStateInternal start getID handle assertJobState ta any setInt task t stop Mockito abortJob mock MRJobConfig createCommitterEventHandler job  Verify abortJob is called once and the job failed ,hadoop,1
getDistance cluster dataNodes testGetDistance assertEquals ,hadoop,0
/foo isFile /newDir/newDir2/foo foo assertFalse fSys chrootedTo newDir/foo fSysTarget testCreateDelete delete createFile  Create file with a 2 component dirs recursively Assert  Create file assertTrue  Create file with recursive dir exists /newDir/foo fileSystemTestHelper  Delete the created file newDir/newDir2/foo ,hadoop,0
"Unexpected Exception def addNode printStackTrace f one testTransition2 j k kill three two asList fail ex invokeForkJoin parser      f->(2,3)     2->fail->3     2->ok->j     3->ok->j     3->fail->k     j->end     name dummyConf end Arrays ",oozie,1
"getName ContentType CoreMatchers equalTo setSslContext request1 setEntity Assert setSocketConfig context create https /stuff getCode CN=localhost,OU=Apache HttpComponents,O=Apache Software Foundation setExceptionListener getPeerPrincipal requester localhost SocketConfig setStreamListener HttpStatus tlsVersion LoggingHttp1StreamListener sslSession * setSoTimeout Method assertThat execute ServerBootstrap EntityUtils LoggingConnPoolListener LoggingExceptionListener greaterEquals RequesterBootstrap TIMEOUT response1 server testTLSSuccess getLocalPort createClientSSLContext bootstrap setConnPoolListener sslSessionRef some stuff createServerSSLContext body1 verify TLS getAndSet setSslSessionVerifier SSLTestContexts set custom start getProtocol parse getEntity target build toString register ",httpcore,0
cache mockKey  asserting no caching when key is not known getCurrentKey getConf k1 thenReturn k2 assertEquals eq when Thread sleep testCurrentKey times Assert Mockito mock verify  asserting caching mockProv ,hadoop,0
getBytesTransferred testCodingFragmentBufferingTinyFragments3 CodecTestUtils channel times Assert flush verify more stuff dump write -- ArgumentMatchers StandardCharsets assertEquals encoder - any stuff------more stuff Mockito outbuf metrics spy wrap stuff ,httpcore,0
getClass bad contents resolve conf testBadFile result .testBadFile .txt get Files write deleteOnExit add mapFile mapping getCanonicalPath set asCharSink createTempFile assertEquals setConf NET_TOPOLOGY_TABLE_MAPPING_FILE_KEY names size NetworkTopology hostName2 hostName1 getSimpleName File Charsets ,hadoop,0
play  server getSequenceNumber clearHeaders assertContent HttpURLConnection connection1 client requestB requestA connection2 addHeader b noTransparentGzipFor304NotModified takeRequest assertEquals setResponseCode setBody Content-Encoding: gzip / enqueue getUrl getResponseCode open ,okhttp,1
setDepthFirst prepare item2 item1 processArgumentsDepthFirstMaxDepth conf setRootExpression when setOut out Result  check max depth is handled when -depth is specified find inOrder verify setOptions expr finish item1b item1a item5e item5d item5c createDirectories item5b item5a setErr fsCheck setMaxDepth err test inOrderFsCheck apply thenReturn check processArguments any setConf anyInt verifyNoMoreInteractions mock getOptions item4 items item3 item5 ,hadoop,0
cluster getProxy racks numOfDatanodes conf sum TestBalancer runBalancerCanFinish createFile waitActive  run balancer which can finish in 5 iterations with no block movement. createProxy createConf NameNodeProxies MiniDFSClusterWithNodeGroup totalCapacity RACK1 NODEGROUP2 builder NODEGROUP1 client capacities RACK0 NODEGROUP0 nodeGroups testBalancerEndInNoMoveProgress CAPACITY  fill up the cluster to be 60% full filePath assertEquals getFileSystem simulatedCapacities totalUsedSpace setNodeGroups numDataNodes shutdown getUri ,hadoop,1
release setMaxTotal getConnection Assert assertTrue assertNotNull get setMaxPerRoute verify entry4 close entry2 getLeased entry3 updateState conn2 entry1 testStatefulConnectionRedistributionOnPerRouteMaxLimit conn1 assignConnection ArgumentMatchers somehost pool assertEquals some-other-stuff totals future3 assertSame isDone future4 any future5 some-stuff never future1 future2 Mockito CloseMode mock lease getPending getTotalStats getAvailable ,httpcore,0
Integer fail Assert tmp testInvalidAppendAsciiByteArray buffer IndexOutOfBoundsException should have been thrown append ,httpcore,0
request testMostPopular assertEquals target accept LIST_ID_COUNT_TYPE getValue Assert top size assertTrue get MediaType /mostPopularItems thisCount ,oryx,1
"ProxyUsers refreshSuperUserGroupsConfiguration getProxySuperuserGroupConfKey assertAuthorized testNetgroups DefaultImpersonationProvider TestProxyUsersGroupMapping conf System asList PROXY_IP NETGROUP_NAMES StringUtils Groups getUserToGroupsMappingService toArray Not testing netgroups,  join  try proxying a group that's allowed getGroups info UserGroupInformation getProperty set proxyUserUgi group mapping class (must implement GroupMappingServiceProvider  LOG interface and support netgroups) groups Not testing netgroups, no group mapping class specified,  , createRemoteUser NativeCodeLoader isNativeCodeLoaded this test only runs when native code is compiled REAL_USER_NAME CommonConfigurationKeysPublic use -DTestProxyUsersGroupMapping=$className to specify  getTestProvider size groupMappingClassName Arrays getProxySuperuserIpConfKey PROXY_USER_NAME Testing netgroups using:  realUserUgi createProxyUserForTesting ",hadoop,0
reader LocalOozie checkSuspendActions conf getStatus assertNotNull decision1 create workflow.xml app :start: * getFileSystem action4a action4b action4c OozieClient jobId copyCharStream mkdirs setProperty getResourceAsReader createConfiguration File oozie.suspend.on.nodes submit getJobInfo fs appPath join1 wf oc end WorkflowJob close resume start assertEquals getClient wf-suspendpoints.xml IOUtils getTestUser testSuspendPointsAll toString writer action1 action2 action3 fork1 getFsTestCaseDir ,oozie,1
next reader assertFalse conf testArrayFileIteration fs seek testArrayFileWriterConstruction error !!! assertTrue assertNotNull FileSystem get close key testArrayFileIteration seek error !!! SIZE testArrayFileIteration error !!! assertThat fail withFailMessage TEST_FILE defaultProgressable writer nextWritable CompressionType isEqualTo append ,hadoop,0
request process setVersion context interceptor Method getEntity testRequestHttp10HostHeaderAbsent HttpVersion / ,httpcore,0
cluster build changeBlockLen numDataNodes  test truncated block  test extended block shutdown testReplicateLenMismatchedBlock waitActive ,hadoop,1
END:VEVENT BEGIN:VEVENT  20080504T123456Z doTest testNoVCalendar DTEND:20080505T234555Z  20080505T234555Z DTSTART:20080504T123456Z  ,zxing,0
"endDate getTime HADOOP_KERBEROS_MIN_SECONDS_BEFORE_RELOGIN conf Time AuthenticationMethod  Suppose tgt start time is now, end time is 20 seconds from now. , retry: setAuthenticationMethod reloginInterval exponentialBackoffRetry  make sure no more retries after (tgt endTime - login interval). now RetryPolicies TimeUnit 5th retry, now: setConfiguration value UserGroupInformation info testGetNextRetryTime setLogLevel incr LOG  Relogin happens every 1 second. GenericTestUtils assertEquals assertWithinBounds getRenewalFailures reloginIntervalMs currentTime lastRetry str  last try should be right before expiry. setLong overflow retry, now: Long Level SecurityUtil getNextTgtRenewalTime endTime  Verify exponential backoff and max=(login interval before endTime). rp ",hadoop,0
getClass fs.trash.classname assertTrue setClass equals conf  Test plugged TrashPolicy testPluggableTrash trash getTrashPolicy ,hadoop,0
" c"" d ""e  PMMLUtils foo AppPMMLUtils assertEquals getExtensionContent asList bar emptyList buildDummyModel assertNull addExtensionContent testExtensionContent reserializedModel model baz toString foo1 fromString Arrays foo2 Collections foo3 ",oryx,1
"Action ID            * create coordinator job           </output-events> UTC TZ <instance>${coord:current(0)}</instance> ' timezone='UTC' freq_timeunit='DAY' end_of_duration='NONE'> </coordinator-app> <action> DateUtils getStatus parseDateOozieTZ setFrequency <start-instance>${coord:current(-3)}</start-instance>           * check coord action READY           getResourceAsString 2009-02-01T23:59 <output-events> CoordinatorAction setId testApp action workflow.xml setCreatedTime setUser Unable to insert the test job record to table printStackTrace <uri-template>file:// execute 2009-02-02T23:59 testNoDatasetDependency testAppPath CoordinatorJob setGroup fail OozieClient setTimeUnit notoken <workflow> <dataset name='local_a' frequency='7' initial-instance='2009-01-01T01:00 </workflow> jobConf ' end='2009-02-03T23:59 getTime <coordinator-app xmlns='uri:oozie:coordinator:0.2' name='NAME' frequency=""1"" start='2009-02-01T01:00 </data-out> getId setAppPath </dataset> coordJob wf-no-op.xml writeToFile setMatThrottling appXml </action> <app-path> get testGroup setAuthToken setTimeZone testUser setStartTime confStr /${YEAR}/${MONTH}/${DAY}</uri-template> setAppName set setLastActionNumber setJobXml e Timeunit setConcurrency setLastModifiedTime assertEquals -TestCoordActionInputCheckXCommand-C setStatus setConf Could not set Date/time call Services @1  was not stored properly in db IOUtils getTestUser <data-out name='LOCAL_A' dataset='local_a'> wfXml setEndTime toXmlString /workflow.xml</app-path> jpaService 0000000 getFsTestCaseDir ",oozie,1
jobConf getName reader authToken wf-ext-schema.xsd assertNotNull getTestCaseDir /workflow.xml get file:// workflow.xml test-wf wf-ext-schema-invalid.xml oozie.service.ActionService.executor.ext.classes parseDef app testExtSchema init set destroy wf-ext-schema-valid.xml assertEquals services OozieClient fail IOUtils getTestUser SchemaService copyCharStream setSystemProperty getResourceAsReader writer wps File ,oozie,1
authorizeForApp fsPermission conf WorkflowInstance FsAction fsConf getTestGroup getTestUser2 create workflow.xml has createFileSystem authorizeForJob app init getTestUser3 getFileSystem fail 1 as ex mkdirs job getUri getId -invalid createJobConf wf getErrorCode addRecordToWfJobTable get setPermission WorkflowJob close ww fileSystem testErrors assertEquals services getAuthority uri authorizeForGroup setService Services getTestUser w authorizeForAdmin toString ErrorCode getFsTestCaseDir ,oozie,1
getShortUserName somerandomuser thenReturn getRealUser when dummyUser fakeuser test.user 2.2.2.2 provider proxyUser userGroupInformation user authorize realUserUGI testAuthorizationSuccess ,hadoop,0
test no alias print output kind:  test alias print exit code test legacy print exit code assertFalse run tokenFilename dt -alias assertTrue not-a-serivce SERVICE test simple print output kind:  outContent test no alias print output service:  test simple print output service:  assertEquals tokenLegacyFile testPrint args rc print contains test no alias print exit code KIND test simple print exit code reset toString ,hadoop,0
fail Should fail exponentialBackoffRetry unreliable failsOnceThenSucceeds failsTenTimesThenSucceeds TimeUnit create unreliableImpl RetryProxy alwaysSucceeds testExponentialRetry ,hadoop,0
renderable assetsControllerHelper  make sure we get the correct result... assetsController when resultCaptor Result result mimeTypes getRenderable responseStreams verify /webjar_asset.txt ok render result2 serveWebJars finalizeHeadersWithoutFlashAndSessionCookie byteArrayOutputStream thenReturn capture assertEquals normalizePathWithoutLeadingSlash contextRenderable eq httpCacheToolkit getValue getStatusCode Mockito Results mock getOutputStream toString webjar_asset ninjaProperties testServeWebJars getRequestPath ,ninja,0
encode charset submit executorService update Executors testMultithreadingSingleRead Assert getDuration get verify Boolean task1 task2 a capacityChannel inputBuffer read newFixedThreadPool StandardCharsets valueOf assertEquals fill getTimeUnit call Integer updateCapacity Mockito mock reset TIMEOUT ,httpcore,0
name: value getName writeObject inStream raw outbuffer assertEquals testSerialization outStream inBuffer readObject getValue buf Assert orig toByteArray clone close append ,httpcore,0
"      * Add 2 Coordinator actions with status as SUSPENDED, 1 Coordinator action with status FAILED and 1      * with KILLED. Then check for expected number of actions retrieved       actionNum CoordinatorJob jobId coord-action-get.xml testCoordActionsSuspendedForSize CoordinatorAction getId _testCoordActionsSuspendedSize job addRecordToCoordActionTable addRecordToCoordJobTable ",oozie,1
"addRecordToBundleActionTable getCurrentDateafterIncrementingInMonths getId run DateUtils getStatus addRecordToCoordActionTable parseDateOozieTZ sleep bundleJob assertNotNull get CoordinatorAction end currentDatePlusMonth Job  first time, service will call bundle kill bundle waitFor testBundleStatusTransitServiceKilled2  Add a bundle action with no coordinator to make it fail addRecordToBundleJobTable bundleId start assertEquals XDataTestCase execute addRecordToCoordJobTableWithBundle Services CoordinatorJob runnable coord-action-get.xml action2 jpaService evaluate ",oozie,1
add withFilterInstance test numInsertions assertFalse withTestCases Hash BloomFilterTestStrategy hashId delete filter hashFunctionNumber CountingBloomFilter.approximateCount error ImmutableSet assertTrue bitSize of membershipTest testCountingBloomFilter BloomFilterCommonTester key CountingBloomFilter.membership error  approximateCount ,hadoop,0
 testFile01 getPathData testfile01 getTime  set file mtime in different order to atime addContents ls out setAtime  check reverse access time order (-u -t -r options) testfile03 options computeLineFormat inOrder testfile02 processOptions verify testfile05 testFile06 setMtime testfile04 testFile04 formatLineAtime testFile05 testfile06 testFile02 testFile03 add processPathDirOrderAtimeReverse Found 6 items pathData lineFormat -r -t -u setIsDir processArguments testDir testDirectory  set file atime in different order to file names verifyNoMoreInteractions NOW TestFile mock ,hadoop,0
data assertFalse link del testSymLink getBytes Assert file  write some data to the file len FILE write close  ensure that symlink length is correctly reported by Java read os getAbsolutePath in  create the symlink length symLink assertEquals _link mkdirs exists  ensure that we can read from link. testSymlink FileUtil ,hadoop,0
%(%a%(%b)) add witness a b tl testNested Token assertEquals tokenize ,logback,0
isRoot getMatched hasItem * src/test/resources/foo.jar matcher assertThat asList resourceMatcher found assertTrue find **/*.jar src/test/resources/templates  A jar file is always treated as a dependency (stick it in /lib) Arrays jarFileAlwaysMatches ,spring-boot,1
EXEC_ORDER callable2 callable3 callables testQueueUniquenessWithSameKeyInComposite callable1 c type queueSerial asList queueservice Services assertTrue get QueueUniquenessWithSameKeyInComposite Arrays evaluate waitFor ,oozie,1
encode  0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0  <<   maskPattern: 4   1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1  >>   0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1   ecLevel: H   1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1  ABCDEF  1 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0   0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0  qrCode Encoder  matrix:   1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1   1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 1 0 0  expected assertEquals  0 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1   version: 1   0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0   1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 1   1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 1   1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1   1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 1 1   1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1   1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0   1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 1  testEncode  1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1   mode: ALPHANUMERIC   1 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 1 1 1 0 1  toString  1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1  ErrorCorrectionLevel  1 0 1 1 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1  ,zxing,0
bb next KeyValue midRow reader familyname isSeeked conf  timestamp. dir getLastKey fs  keys from top half of the file. Bytes split  Make a reference 1234567890 storedir assertTrue regionname StoreFile getPath testReference finalRow midkey getKey getReader createKeyValueFromKey kv getRow Range refHsf seekTo writeStoreFile getWriter equals hsf writer  Make a store file and write data to it. refPath getScanner first ,hadoop,1
conn RestConstants setRequestMethod IS_SECURITY_ENABLED openConnection MockDagEngineService HttpServletResponse testGraph assertEquals params put url call /v0/job/* getHeaderField GET getResponseCode name reset createURL ErrorCode runTest ,oozie,1
actual RandomUtils manager incr session one  Given nextLong SELECT * FROM entity_counter WHERE id =  assertThat delete execute should_delete_instance crud  When  Then isNull Long id entity ,achilles,1
getOutgoingFlashCookieData  make sure the old cookue gets parsed: getCookie when  setup this testmethod get builder context flashScope Cookie  => now both queues must be 1 init  make sure outgoing is 0 NINJA_FLASH cookie thenReturn  now call keep. hello=flashScope flashCookie assertEquals size build testThatFlashCookieKeepWorks getCurrentFlashCookieData keep ninjaProperties ,ninja,0
getBytesTransferred read [identity; completed: true] dst StandardCharsets CodecTestUtils assertFalse channel clear bytesRead assertEquals decoder convert ByteBuffer stuff; Assert allocate inbuf assertTrue testBasicDecoding toString more stuff metrics isCompleted ,httpcore,0
cluster  create cluster assertFalse t= conf error System createFile waitActive sleep leasePeriod /foo3 setLeasePeriod  create a new file. /foo2 testLeaseExpireEmptyFiles /foo DFSConfigKeys e setDefaultUncaughtExceptionHandler  wait for the lease to expire getFileSystem TestFileCreation Thread setInt dfs getDefaultUncaughtExceptionHandler LeaseManager t isConcurrentModificationException build numDataNodes DATANODE_NUM testLeaseExpireEmptyFiles start uncaughtException oldUEH  namenode triggers lease recovery shutdown ,hadoop,1
handler assertNothingThrown handle ,httpcore,0
cluster testFailoverOnConnectTimeout InjectingSocketFactory HATestUtil  successfully. setClass conf  when connecting to the first NN. fs configureFailoverFs  Make the second NN the active one. shutdownNameNode CommonConfigurationKeysPublic IOUtils transitionToActive TEST_FILE closeStream getNameNodePort create ,hadoop,1
key1 listKeys rolled. assertFalse listOut roll description key1 has been successfully  run invalidated. testKeySuccessfulKeyLifecycle assertTrue create jceksProvider outContent  jceks provider's invalidate is a no-op. created  has been  keyName ks assertEquals deleteKey setConf rc contains -provider invalidateCache args1 reset args2 toString ProviderUtils args3 successfully created ,hadoop,0
"cluster parent  but found to be of size  getName  write to file getRemaining conf dn createFile simulatedStorage path len getFileStatus but found to take  create ie getDfsUsed   ""  should take  getDataNodes getFSDataset  verify that file exists in FS namespace getFileSystem setQuota stm blockSize / dfs contains Path : "" /test_dir fileSize  can't check capacities for real storage since the OS file system may be changing under us. diskSpace mkdirs  bytes disk space  SimulatedFSDataset shutdown isDirectory  should be of size  / should be a directory createFile: Creating   verify the disk space the file occupied testFileCreation fs System  Create path, overwrite=true assertTrue getLen get  verify that file size has changed to the full size close writeFile getParent isFile filestatus.dat getContentSummary getMessage Did not prevent directory from being overwritten. assertEquals dir1  bytes build getLength toString  should be a file  for overwrite of existing directory. file1 setBoolean already exists as a directory. ",hadoop,1
"play A request Cookie: $Version=""1"";  Location:  setDomain ACCEPT_ORIGINAL_SERVER HttpURLConnection testRedirectsDoNotIncludeTooManyCookies get portList cookieManager getCookieStore redirectSource add "";$Port="" Cookie addHeader "" c cookie getHeaders takeRequest setPortlist toURI setPath redirectTarget setBody setResponseCode setDefault assertContains / Integer enqueue getUrl fail getPort getCookieDomain header toString CookieHandler c=""cookie"";$Path=""/"";$Domain="" startsWith ",okhttp,1
 getWaitingActions System dep sleep get testEvictionOnTimeToLive setupServices startTime info  timeToLiveSeconds is 1 addMissingDependency LOG pdms hcat://hcat.server.com:5080/mydb/mytbl/id= Time taken to insert and retrive  numItems verifyWaitingAction Thread Services assertNull  items is  currentTimeMillis testevictionontimetolive ,oozie,1
null service from  stop service assertNotNull launchService testLaunchService getService launcher ,hadoop,0
 POST MyJsonRestServlet HttpServletResponse invoke assertEquals /any call GET testMultipleResourcesWildCard /resource1 /resource2 runTest ,oozie,1
/ should be a directory dfsClient fs getFileInfo for a non-absolute path did not throw IOException /noSuchFile path  Check that / exists assertTrue Non-existant file should result in null getFileStatus  Test getFileInfo throws the right exception given a non-absolute path. testGetFileInfo non-absolute Invalid file name fileInfo  Make sure getFileInfo returns null for files which do not exist assertEquals / fail contains re toString getFileInfo Wrong exception for invalid file name isDirectory ,hadoop,1
getBlockLocations b getBlock  Start writing a file but do not close it src blocks foo testAbandonBlock DFSClientAdapter fs dfsclient abandonBlock  And close the file  Now abandon the last block hflush FILE_NAME_PREFIX fout getNamenode create write close getDFSClient getLastLocatedBlock ,hadoop,1
getBytesTransferred testCodingFragmentBufferingTinyFragments2 CodecTestUtils channel times Assert flush verify more stuff dump stuff---more stuff write ArgumentMatchers StandardCharsets assertEquals encoder - any Mockito outbuf metrics spy wrap stuff ,httpcore,0
conn read inStream thenReturn ArgumentMatchers setSoTimeout getInputStream when any anyInt times bind Assert Mockito assertTrue ensureOpen verify getSoTimeout awaitInput socket spy testAwaitInputInSocket ,httpcore,0
assertDOptionParsing key1 hdfs://somefs/ key2 expectedMap value2 value1 newHashMap -Dkey1=value1 testDOptionParsing put key1=value1 someother args -Dkey2 arg2 Shell Maps -Dkey1 expectedRemainingArgs arg1 -D -fs  we expect key2 not set ,hadoop,0
release assertFalse getConnection Assert assertTrue assertNotNull get entry8 setMaxPerRoute entry9 entry6 entry7 entry4 entry5 testMaxLimits entry2 entry3 getLeased conn3 conn2 entry1 conn1 assignConnection somehost pool future7 future8 assertEquals future9 totals future3 assertSame future4 isDone future5 future6 future1 future2 Mockito otherhost mock lease getPending getTotalStats getAvailable ,httpcore,0
enumParam thenReturn invoke when param1 red Rainbow context create verify mockController enumParamShouldBeParsedToEnumCaseInsensitive getParameter ,ninja,0
getConnectionContext testCoordinatorActionSelectorsNegative cae session coordEventListener conf parseDateUTC DateUtils createSession getTopic wf-app-name1 onCoordinatorActionEvent caJobId1 caId1 CoordinatorAction 2012-07-22T00:00Z selector jmsContext ='Non_matching_user' consumer 2011-07-11T00:00Z user1 init nominalTime receive printStackTrace e  Pass a selector which wont match and assert for null message getMessage message fail assertNull JMSHeaderConstants createConsumer startDate Session ,oozie,1
bulkInsertCmd createWorkflow addNode auth getAppPath PREP conf getId testToken WorkflowInstance actionGetCmd setInsertList assertNotNull get testApp <workflow-app/> end workflow.xml WorkflowJob app add getStatusStr set  check for expected status after running bulkUpdateJPA insertList wfGetCmd testInserts assertEquals execute appUri OozieClient 1 Services 2 getTestUser WorkflowAction toString createWorkflowAction action1  insert one workflow job and two actions job action2 jpaService ,oozie,1
TestMetricsSystem init TestSource sa2 ms testRegisterSourceWithoutName sa getSourceAdapter ts2 assertNotNull TestSource2  the class name will be used as the name shutdown ts register ,hadoop,0
" Wait for the async task to finish test SyncGenerationPolicy k1 assertEquals getNext testDrain drain  Drain completely, no further refills triggered  the prefill to the low watermark, 1 consumed by getNext()) waitForRefill Assert assertNull  Trigger a prefill (1) and an async refill (10)  Wait a while to make sure that no async refills are triggered getTop filler vq shutdown ",hadoop,0
"testCount putThread tableName Bytes testWritesWhileScanning scanner join prevTimestamp  new BinaryComparator(Bytes.toBytes(""row0"")))); res row1 row0 method checkNoError toBytes qualifiers done initHRegion size flushInterval previousEmpty region next numRows scan flush assertTrue getTimestamp get Timestamps were broke:  timestamp numQualifiers  System.out.println(""flush scan iteration = "" + i);  prev:  start isEmpty clear numFamilies assertEquals expectedCount families flushcache i= compactStores flushThread compactInterval qual family getScanner ",hadoop,1
END_POINTS IS_SECURITY_ENABLED oozieUrl run createMRProperties appPath assertTrue get -config SERVLET_CLASSES runTest app testSubmitMapReduce getContextURL MockDagEngineService assertEquals getFileSystem args call submitMR -oozie mapreduce mkdirs wfCount toString getFsTestCaseDir ,oozie,1
 testFile01 getPathData  check reverse default ordering testfile01 addContents ls formatLineMtime out processPathDirOrderDefaultReverse testfile03 options computeLineFormat inOrder testfile02 processOptions verify testfile05 testFile06 testfile04 testFile04 testFile05 testfile06 testFile02 testFile03 add Found 6 items pathData lineFormat -r setIsDir processArguments testDir testDirectory verifyNoMoreInteractions TestFile mock  add contents in non-lexigraphic order to show they get sorted ,hadoop,0
a writeStr b WritableUtils dos assertEquals baos dis assertNull toByteArray testWriteReadStr close readStr ,oozie,1
"timestamp2 Test 3 failed, but relax. Time spent:  Something wrong! Test 4 got Exception with maxmum retries! Something wrong! Test 2 got Exception with maxmum retries! Test 4 succeeded! Time spent:  System busyTest assertTrue Testing DFSClient random waiting on busy blocks. timestamp info Test 3 succeeded! Time spent:    timeWin pass  sec. LOG threads Test 2 succeeded! Time spent:  fileLen testDFSClientRetriesOnBusyBlocks retries warn currentTimeMillis Test 1 failed, but relax. Time spent:  Test 1 succeeded! Time spent:  xcievers ",hadoop,1
 when addError  then  given start appender eq any when some event deque offer doThrow interruptedException anyLong addsErrorMessageWhenAppendingIsInterruptedWhileWaitingForTheQueueToAcceptTheEvent verify append Interrupted while appending event to SocketAppender ,logback,1
release setMaxTotal when times Assert assertTrue assertNotNull create setMaxPerRoute verify join getEntry close entry2 getLeased entry3 conn3 conn2 entry1 testStatefulConnectionRedistributionOnPerRouteMaxLimit conn1 GRACE_PERIOD thenReturn somehost pool start assertEquals some-other-stuff connFactory totals eq future3 isDone some-stuff never future1 future2 Mockito mock setState lease getPending t1 getTotalStats getAvailable t2 t3 ,httpcore,1
"mockRes init mockReq verifyZeroInteractions  Object under test thenReturn BROWSER_AGENT  CSRF has not been sent  Objects to verify interactions based on request  Setup the configuration settings of the server getMethod when testMissingHeaderMultipleIgnoreMethodsConfigBadRequest filterConfig PUT getHeader filter mockChain getInitParameter Mockito doFilter mock GET,OPTIONS RestCsrfPreventionFilter ",hadoop,0
date scriptExecutor session  Given update simple Eq SELECT simpleset FROM simple WHERE id =  simpleset containsExactly  When of where id row table executeScriptTemplate should_dsl_update_set_remove simpleSet_RemoveFrom RandomUtils manager getSet one nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap simpleSet  Then Long buildDateKey fromBaseTable dsl ,achilles,1
"Unexpected Exception def addNode j1 j2 f1 f2 three two asList invokeForkJoin four dummyConf end five       * 1->decision node->{f1, f2}      * f1->(2,3)      * f2->(4,5)      * (2,3)->j1      * (4,5)->j2      * j1->end      * j2->end       printStackTrace e one k kill fail testDecisionMultipleForks parser name Arrays ",oozie,1
date scriptExecutor session  Given update simple Eq consistencylist asList consistencyList_Set containsExactly should_dsl_update_list_set  When getList of where id row table executeScriptTemplate RandomUtils manager one nextLong assertThat TWO execute SimpleEntity/insert_single_row.cql ImmutableMap SELECT consistencylist FROM simple WHERE id =   Then Long buildDateKey fromBaseTable consistencyList dsl THREE ,achilles,1
prepare testCodingDirectBuffer_6x3_erasing_d0_p0 testCoding  } ,hadoop,0
ninjaMode isAvailable conf/jetty.minimal.conf getContextPath nullValue NinjaMode not minimalWithContext host getHost RANDOM_PORT localhost isStopped externalConfigurationPath contextPath standalone start is assertEquals isStarted assertThat getNinjaMode /mycontext getPort port shutdown ,ninja,0
nn cluster NameNodeAdapter assertFalse /test-  Set the cluster to leave safemode quickly on its own. fs createFile Secret manager should start when safe mode is exited enterSafeMode getConfiguration assertTrue Secret manager should not run in safe mode isRunning is manually entered StartupOption sm info getDtSecretManager DFSTestUtil startDataNodes DFSConfigKeys LOG restartNameNode getFileSystem isInSafeMode setInt getNameNode ========= entering safemode again testDTManagerInSafeMode leaveSafeMode config setWaitSafeMode Secret manager should stop again when safe mode  getNamesystem ,hadoop,1
cluster testFileCreationDeleteParent nameNodePort  create cluster conf testFileCreationDeleteParent:   create file2. dir fs delete createFile System waitActive  This ensures that leases are persisted in fsimage. sleep hflush assertTrue  rm dir ipc.client.connection.maxidletime close writeFile  2s /foo DFSConfigKeys /file2 format  create file1. Created file  getFileSystem TestFileCreation setInt Thread  persistent leases from fsimage. stm2 MAX_IDLE_TIME dfs.support.append stm1 build nnport file2 getNameNodePort exists file1 shutdown setBoolean ,hadoop,1
trashShell getHomeDirectory .Trash/Current TestTrash fsView fsTarget conf testTrash fileSystemTestHelper getTestRootPath ,hadoop,0
schema  a race conditon in the validator.  This test is to make sure we don't accidently remove the dependency. assertFalse start threads error numThreads getSchema Services parser SchemaService get testRaceConditionWithOldXerces allDone evaluate waitFor ,oozie,1
formatDate A Last-Modified:  server Date:  addHeader B string noDefaultExpirationForUrlsWithQueryString assertEquals setBody body url enqueue getUrl /?foo=bar get TimeUnit ,okhttp,1
cursor HTTP/1.123 assertFalse getMajor HTTP minor version number HTTP major version number Assert HTTP version number assertTrue parseProtocolVersion getPos HTTP/1.1 buffer HTTP protocol name atEnd length clear HTTP getProtocol assertEquals version HTTP/1.123 123 testHttpVersionParsing getMinor parser toString append charAt ,httpcore,0
setClassesToBeExcluded assertFalse getCurrentDateafterIncrementingInMonths getId run DateUtils isPending getStatus addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob testCoordStatusTransitServiceRunning3 assertNotNull get CoordinatorAction end currentDatePlusMonth Job waitFor init getConf false start destroy assertEquals services XDataTestCase execute addRecordToCoordJobTable Services CoordinatorJob jobId runnable coord-action-get.xml excludedServices setSystemProperty StatusTransitService job jpaService evaluate ,oozie,1
checkCoordAction testActionInputCheck getTime TZ /2009/01/29/ getId -TestCoordActionInputCheckXCommand-C DateUtils /2009/01/15/ parseDateOozieTZ 2009-02-02T23:59 addRecordToCoordJobTable call jobId @1 2009-02-01T23:59 getTestCaseDir createDir 0000000- startTime endTime job ,oozie,1
getDynamicEntry testRequestDecodingWithHuffmanRFC7541Examples assertHeaderEquals no-cache dynamicTable custom-value getCurrentSize Assert :scheme get https cache-control :authority custom-key StandardCharsets createByteBuffer assertEquals headers2 decoder headers3 headers1 www.example.com / size :method GET src1 decodeHeaders http :path src3 src2 /index.html dynamicLength ,httpcore,0
+rwrt testFsSymbolicConstructorWithNormalInput +r  Added both Octal and short representation to show with sticky bit assertEquals +w +wx +x -rt +rw -rwx +rx  Repeated value in input will be ignored as duplicate. toOctal -rwr +rwr -rwrt +rwx toShort +rwxt ,hadoop,0
another message getName getOutgoingFlashCookieData yet another message save  make sure the old cookue gets parsed: getCookie when put  setup this testmethod  but the old has disappeared (flashScope): addCookie another+message=is+there...&yet+another+message=is+there... cookieCaptor get builder context verify  verify some stuff on the set cookie flashScope Cookie init testThatFlashCookieWorksAndIsActiveOnlyOneTime NINJA_FLASH cookie thenReturn hello=flashScope flashCookie capture assertEquals getValue size build is there... getCurrentFlashCookieData  a cookie will be set => hello:flashScope ninjaProperties ,ninja,0
date A getCipher addVersion description getDescription put second myCipher assertTrue getVersions getBitLength  Metadata with description 2013/12/25 testMetadata a getAttributes format isEmpty  Metadata without description getCreated assertEquals parse y/m/d serialize assertNull meta attributes newVersion ,hadoop,0
EXEC_ORDER callable2 callable3 callable1 queueSerial QueueUniquenessWithDiffKeyInOneComposite queueservice asList Services testQueueUniquenessWithDiffKeyInOneComposite assertTrue get QueueUniquenessWithDiffKeyInOneComposite2 QueueUniquenessWithDiffKeyInOneComposite1 QueueUniquenessWithDiffKeyInOneComposite3 Arrays evaluate waitFor ,oozie,1
cluster TABLE_NAME createTable assertFalse  reach in and set minimum server count admin conf  create and disable table  now try to enable the table Thread  now start another region server sleep createTableDescriptor assertTrue setMinimumServerCount enableTable  sleep a bit for assignment startRegionServer getMaster testMinimumServerCount isTableEnabled disableTable getServerManager isTableAvailable ,hadoop,1
"play A server B Accept-Encoding Cache-Control: max-age=60 identity connection1 Vary: Accept-Language, Accept-Charset connection2 Accept-Charset readAscii addHeader varyMultipleFieldsWithMatch openConnection UTF-8 assertEquals setBody url fr-CA addRequestProperty / enqueue getUrl Vary: Accept-Encoding Accept-Language ",okhttp,1
test.sink.test2.period test.sink.test1.class test.sink.test1.period getName save test1 getTestFilename get getSinkAdapter waitFor hadoop-metrics2-test add init  Give some time for the publish event to go through onTimerEvent test ms sink getMetricValues GenericTestUtils assertEquals test2 size TestMetricsConfig testRegisterSinksMultiplePeriods test.sink.test2.class sink2 sink1 shutdown ,hadoop,0
" symbol 10.00% 1230K -8 E 0.5430% 100m 891g n= 0.54% 1% 0.5% invalidPrefix 3 G Invalid size prefix ' 1.50 M 1 K 1.50 K .0  byteDesc  does not fit in a Long   -1E 10kb Test passed for a number  10e 0.543% 456t  test long2string(..) .00  expected 1.5 K 1.50 MB zeros  too large -8.00 E decimalPlace 0 -891G 1 KB 10p fail tooSmallNumStr  test string2long(..) 8.00 E -100M Long  n = 2^e + 1  n = 2^e - 1 TraditionalBinaryPrefix testTraditionalBinaryPrefix string2long formatPercent ' in ' tooLargeNumStr -1k values -10e -10P  too small 0 B  test byteDesc(..) -1230K 1e -100 B StringUtils 1k -1 K  test formatPercent(..)  n = 2^e -456T trailingZeros 2 M long2String e 10% g '. Allowed prefixes are k, m, g, t, p, e(case insensitive) getMessage invalidFormatNumStr assertEquals k m 10.0% n 1.50 KB p t  has invalid format 3 GB ",hadoop,0
coordId1 filterListJob1 assertEquals createFilterList list execute jobid Services slaEventsGetCmd testGetSLAEventsForCoordJobId size assertNotNull get jpaService ,oozie,1
conn setRequestMethod IS_SECURITY_ENABLED put testStart  testing for the start action setRequestProperty  check if the state remains uninitialized /v1/job/* content-type runTest MockCoordinatorEngineService RestConstants openConnection HttpServletResponse assertEquals params url PUT call getResponseCode  check if the response is 400 reset createURL setDoOutput ,oozie,1
" captured ""this"" getImplClass getImplMethodName replace specificInstanceMethodReference getCanonicalName invoke getKind serializedLambda getFunctionalInterfaceMethodName lambda reflect Kind getSerializedLambda getFunctionalMethod value lambdaInfo Lambdas apply  verify it can be dynamically invoked is assertThat l2s  String value = (String)lambda.getClass().getMethod(""apply"", Long.class).invoke(calc, 1L); getCapturedArgCount getCapturedArg 2 (Ljava/lang/Long;)Ljava/lang/String; calc getImplMethodSignature ",ninja,0
Bundle Job should have been purged addRecordToBundleActionTable Workflow Job 5 should have been purged addRecordToWfActionTable Workflow Action 2 should have been purged Coordinator Action 3 should have been purged coordJob2GetCmd getStatus wfAction5GetCmd wfJob5GetCmd coordAction4GetCmd bundleJob coordAction3 coordAction4 BundleJobBean Coordinator Job 4 should have been purged assertNotNull coordAction5 CoordinatorAction wfJob2GetCmd coordAction1 coordAction2 Bundle Action 5 should have been purged bundleAction4 bundleAction5 Coordinator Job 3 should have been purged bundleAction1 bundleAction2 bundleAction3 execute testPurgeBundleWithCoordChildWithWFChild3MoreThanLimit bundleAction1GetCmd Bundle Action 4 should have been purged CoordinatorJob 1 fail SUCCEEDED wfAction2GetCmd Coordinator Action 2 should have been purged Workflow Action 3 should have been purged je bundleJobGetCmd Workflow Job 4 should have been purged wfJob1 coordJob1GetCmd wfJob3 wfJob4GetCmd Bundle Action 1 should have been purged wfJob2 getErrorCode wfJob5 get wfJob4 coordAction2GetCmd bundleAction3GetCmd getAppName setAppName coordAction1GetCmd 2011-01-01T01:00Z addRecordToBundleJobTable Workflow Action 4 should have been purged assertEquals Coordinator Action 1 should have been purged wfAction1 wfAction2 addRecordToCoordJobTable wfAction3 wfAction4 wfAction5 call Services wfJob3GetCmd Coordinator Job 2 should have been purged jpaService Workflow Job 3 should have been purged Coordinator Job 1 should have been purged bundleAction2GetCmd DateUtils WorkflowInstance Bundle Action 2 should have been purged addRecordToCoordActionTable parseDateOozieTZ wfAction1GetCmd Workflow Action 5 should have been purged Job coord2 coord3 coord4 coord5 coordJob3GetCmd wfJob1GetCmd Coordinator Action 5 should have been purged Workflow Job 2 should have been purged coordJob2 coordJob3 coordJob1 WorkflowAction coordAction3GetCmd coordJob4 coordJob5 coordJob4GetCmd Workflow Job 1 should have been purged Coordinator Job 5 should have been purged bundleAction4GetCmd getId coordAction5GetCmd addRecordToWfJobTable Workflow Action 1 should have been purged WorkflowJob wfAction3GetCmd Coordinator Action 4 should have been purged wfAction4GetCmd coordJob5GetCmd bundleAction5GetCmd coord-action-get.xml ErrorCode Bundle Action 3 should have been purged ,oozie,1
request MyName POST Message should contain httpClientName of  put getClientPOJOAdapter  make sure the HTTP Client name is in the message. Assert requestHandler httpClientName assertTrue runTests get defaultURI addTest getClientName WebServerTestingFrameworkException should have been thrown TestingFrameworkException adapter test e  change the request from what is expected. pojoAdapter getMessage message responseExpectations execute NAME fail contains framework ; message= REQUEST GET equals newFrameworkAndSetAdapter METHOD Message should contain the test. message= requestMethodUnexpected ,httpcore,0
date scriptExecutor session  Given insert simple SELECT value FROM simple WHERE id =  0 AM crud  When of should_insert_with_insert_strategy_non_null_fields withInsertStrategy id row value table InsertStrategy executeScriptTemplate isNotNull RandomUtils manager one getString nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap  Then Long buildDateKey isEqualTo entity ,achilles,1
init CoordELFunctions ${coord:dataOut('EFG')} setVariable assertEquals ${coord:dataIn('ABC')} data-in ${coord:dataIn('ABCD')} coord-job-submit-data fail should throw exception beacuse Data in is not defiend eval evalAndWrap ${coord:dataOut('EFGH')} testDataNamesPh1 expr oozie.dataname.ABC data-out oozie.dataname.EFG ,oozie,1
"JMSTopicService bab addRecordToBundleActionTable cab addRecordToWfActionTable  = workflow, getId WorkflowInstance getTopic addRecordToCoordActionTable setupServicesForTopic coord coord-action-for-action-input-check.xml addRecordToWfJobTable =coord, default =  get CoordinatorAction wab cjb bjb WorkflowJob Job init set getBundleActionId printStackTrace getConf workflow e addRecordToBundleJobTable getMessage destroy jmsTopicService assertEquals services addRecordToCoordJobTable fail getValue Services 1 CoordinatorJob WorkflowAction testMixedTopic1 wfj ",oozie,1
"values insert String error System asList estimator get estimate Collections testQuantileError actual  Do 10 shuffle/insert/check cycles count clear format Starting run  j assertThat quantiles q isTrue r Expected %d with error %d, estimated %d Arrays shuffle snapshot ",hadoop,0
conn setRequestMethod IS_SECURITY_ENABLED getReaderAsString getId put bundleJobBean assertTrue /v1/job/* content-type id Job runTest MockCoordinatorEngineService RestConstants openConnection addRecordToBundleJobTable length HttpServletResponse assertEquals params getInputStream url call ct getHeaderField IOUtils testBundleEngineGetDefinition xDataTestCase response GET getResponseCode reset createURL startsWith ,oozie,1
getKeyVersion getMetadata cache mockKey c getCurrentKey getConf k1 thenReturn k1@0 assertEquals deleteKey  asserting the cache is purged testDeleteKey eq l when times Assert Mockito mock verify mockProv ,hadoop,0
Coordinator Action should not have been purged getId assertEquals coordJobGetExecutor getStatus addRecordToCoordActionTable execute addRecordToCoordJobTable Coordinator Job should not have been purged coordActionGetExecutor call CoordinatorJob Services fail coord-action-get.xml assertNotNull get testCoordPurgeXCommandFailed CoordinatorAction action job jpaService ,oozie,1
newModTime testSetTimes  support millisecond timestamps getModificationTime getAccessTime checkTimesStatus check we're actually changing something path assertTrue TEST_ROOT_DIR newAccTime fileSys getFileStatus setTimes writeFile set-times status ,hadoop,0
getJobTrackerUri  getName <argument>A</argument> <exec>sh</exec> getAppPath  Create the script file with canned shell command _testSubmit fs SHELL_SCRIPT_CONTENT_ERROR actionXml <shell> </file> create testShellScriptError <argument>script.sh</argument> write close <job-tracker> getNameNodeUri  Submit and verify the job's status # <argument>-c</argument> </job-tracker> getFileSystem script <name-node> </name-node> </shell> w <file> <argument>B</argument>  Create sample shell action xml toString script.sh ,oozie,1
renewToken FakeCanceller testCancelDelegationToken JobTracker run cancelToken stopThreads shouldThrow token generateDelegationToken SomeUser Assert assertTrue dtSecretManager startThreads  Fake renewer should not be able to renew ,hadoop,0
"getName outPath mm1 $[\n\r]*^\d+\s+test1.testRecord2:\s+Context=test1, outFile test.sink.mysink0.class compile getTestFilename add test ms UTF-8 getTestTempFile is  Note that in the below expression we allow tags and metrics to go in arbitrary order. matcher matches stop cleanup *.period TestMetricsConfig registerWith shutdown (testTag1=testTagValue1,\s+testTag2=testTagValue2|testTag2=testTagValue2,\s+testTag1=testTagValue1), expectedContentPattern  publish the metrics \s+Hostname=.*,\s+(testMetric1=1,\s+testMetric2=2|testMetric2=2,\s+testMetric1=1) save test.sink.mysink0.filename test1 baos  line #1:  line #2: assertTrue test.sink.mysink0.context \s+testTag22=testTagValue22,\s+Hostname=.*$[\n\r]* testFileSink hadoop-metrics2-test copyBytes ^\d+\s+test1.testRecord1:\s+Context=test1,\s+ Pattern getAbsolutePath incr start length IOUtils .out  NB: specify large period to avoid multiple metrics snapshotting: test-file-sink- outFileContent toByteArray publishMetricsNow ",hadoop,0
viewfs:/// vfs getChildFileSystem testListLocatedFileStatus conf URI mockfs://foo/ getRawFileSystem fs.mockfs.impl mockfs://foo/user FileSystem get getPath create verify listLocatedStatus mockPath ConfigUtil setClass toUri mockMount toString mockFs /usermock addLink ,hadoop,0
"INPUT caughtException getBuffer  Try writing one more byte, should fail getLimit  Try writing beyond end of buffer. Should throw an exception SIZE newBuf  Reset the stream and try, should succeed Limit did not get reset correctly stream assertTrue Array Contents Mismatch resetBuffer equals testResetBuffer Writing beyond limit did not throw an exception  Write to the stream, get the data back and check for contents Arrays write ",hadoop,0
request handler addHeader authenticate WWW_AUTHENTICATE_HEADER NEGOTIATE HttpServletResponse BASIC setStatus Assert assertNull Mockito response mock verify testRequestWithoutAuthorization ,hadoop,0
tel:212 555 1212 +15551212 ParsedResultType doTestResult telephone 212 555 1212 2125551212 TEL:+15551212 212-555-1212 tel tel:+15551212 tel:2125551212 tel:212-555-1212 testTel ,zxing,0
"getClass getName secretValue simple when getCookiePath asList getInitParameterNames /bar Assert context  custom secret by file management.operation.return test.build.data write init .foo.com thenReturn isCustomSignerSecretProvider destroy  custom cookie domain and cookie path isRandomSecret testDir  custom secret as inline getAuthenticationHandler getInitParameter mkdirs true mock secretFile reset Arrays  authentication handler lifecycle, and custom impl getAllSecrets getServletContext assertFalse kerberos System http-secret.txt sc getAttribute assertTrue DummyAuthenticationHandler hadoop close testInit getProperty AuthenticationFilter getAbsolutePath  kerberos auth handler getCurrentSecret assertEquals filter getMockedServletContextWithStringSigner Mockito getCookieDomain elements writer config target/test-dir ",hadoop,0
getOutgoingFlashCookieData  make sure the old cookue gets parsed: getCookie when put  now test clearCurrentFlashCookieData  setup this testmethod funny new flash message get builder context testThatFlashCookieClearWorks flashScope Cookie init NINJA_FLASH cookie thenReturn hello=flashScope flashCookie assertEquals size build is there... getCurrentFlashCookieData clearCurrentFlashCookieData ninjaProperties ,ninja,0
"bc cluster startUpCluster shutDownCluster resetConfiguration getPendingReplicationBlocks dnR conf bl dn waitForTempReplica findBlock DN_N0 blockReport get bytesChkSum DN_N1 join blockReport_08 writeFile DFSConfigKeys  return the initial state of the configuration getDataNodes getBlockPoolId getMethodName  all blocks belong to the same file, hence same BP blocks getBlockListAsLongs filePath start GenericTestUtils assertEquals getNameNodeRpc Wrong number of PendingReplication blocks / setInt printStats setLong size poolId METHOD_NAME .dat getNamesystem getDNRegistrationForBP ",hadoop,1
Status _testGetSLAEventsForSeqId testSLAEventsGetForSeqId current addRecordToSLAEventTable -TestSLAEventsGetJPAExecutor-W getTime 0000000- wfId ,oozie,1
cluster DFSTestUtil DFSConfigKeys /testfile  the edit log is replayed.  Shut down and restart cluster with new minimum replication of 2 format conf getFileSystem fs waitReplication createFile setInt waitActive p testReplicationAdjusted build numDataNodes  start a cluster repl shutdown  Create a file with replication count 1  Replicate and heartbeat fast to shave a few seconds off test ,hadoop,1
"postponeResponse getAndIncrement  increasing Server conf sendResponse Executors  trigger last waiting call  was consumed Assert  make sure it blocked assertNotNull TimeUnit val  make sure it's still blocked count  trigger responses getConnectAddress fail future1 ex future2 stop ADDRESS exec server wait submit assertFalse waitingCalls  the background calls should still be blocked get client  use only 1 handler to prove it's freed after every call unexpected exception: wait0 set address  do a call in the background that will have a deferred response  call 4: sendResponse, expect it to return wait1 wait2 start assertEquals getCurCall newCachedThreadPool isDone call NetUtils deferredCall waitCount TestIPCServerResponder ipc shouldn't have responded  another call with wait count of 2 testDeferResponse  call should return immediately ",hadoop,0
addToken testFsWithChildTokensOneExists fs2 addDelegationTokens credentials createFileSystemForServiceName fs1 fs3 renewer service2 service1 assertEquals assertSame token singleTokenFs1 multiFs numberOfTokens assertNotNull singleTokenFs2 getToken mock  we had added its token to credentials verifyTokenFetch ,hadoop,0
getDefinition submitJob def reader end.error conf error jobId1 engine assertNotNull getTestCaseDir /workflow.xml file:// workflow.xml OK ok testJobDefinition a external-status set wf-ext-schema-valid.xml OozieClient IOUtils getTestUser t signal-value copyCharStream getResourceAsReader writer File ,oozie,1
getClass getDeclaredMethodsIncludingInherited containsParentMethod getName Missing child method methods getParentField containsChildField Missing child field testGetDeclaredFieldsIncludingInherited getChildField assertTrue getDeclaredFieldsIncludingInherited childField method containsParentField parentField Missing parent field field containsChildMethod equals unused ReflectionUtils fields Missing parent method child ,hadoop,0
 processPathDirOrderMtimeReverse testFile01 getPathData testfile01 getTime addContents ls formatLineMtime out testfile03 options computeLineFormat inOrder testfile02 processOptions verify testfile05 testFile06 setMtime testfile04 testFile04 testFile05 testfile06 testFile02 testFile03  set file mtime in different order to file names add Found 6 items pathData lineFormat -r -t setIsDir processArguments testDir testDirectory verifyNoMoreInteractions NOW TestFile mock  check reverse mtime ordering (-t -r options) ,hadoop,0
callable2 callable3 callables callable1 getCurrentDateafterIncrementingInMonths getId DateUtils parseDateOozieTZ asList queueservice assertTrue get end currentDatePlusMonth waitFor c start XDataTestCase services testCoordKillXCommandUniqueness addRecordToCoordJobTable CoordinatorJob job Arrays evaluate queue ,oozie,1
new.conf.to.replace.deprecated.conf Configuration testReadWriteWithDeprecatedKeys writeXml conf old.config.yet.to.be.deprecated fileContents addDeprecation out contains assertTrue  Tests reading / writing a conf file with deprecation after setting toString close setBoolean ,hadoop,0
getTransitions jobConf getName reader authToken <fs StartNodeDef <pig assertTrue assertNotNull get getTestCaseDir /workflow.xml file:// workflow.xml test-wf parseDef app init a b set c <map-reduce getConf d wf-schema-valid.xml e f g destroy assertEquals services testParsing kill OozieClient IOUtils contains getTestUser size copyCharStream getResourceAsReader z wps writer getNode File startsWith ,oozie,1
"./test-workflow-app.xml END_POINTS invalidContent IS_SECURITY_ENABLED validFileName run invalidfile testValidateWorkFlowCommand delete  <start to=""end""/> <end name=""end""/> </workflow-app> <workflow-app xmlns=""uri:oozie:workflow:0.2"" name=""f"">  SERVLET_CLASSES runTest validate validContent validfile invalidFileName assertEquals args call IOUtils copyCharStream <workflow-app xmlns=""uri:oozie:workflow:0.2"" name=""no-op-wf"">  ./test-invalid-workflow-app.xml  <tag=""end""/> <tag=""end""/> </workflow-app> ",oozie,1
Integer fail Assert tmp testInvalidAppend buffer IndexOutOfBoundsException should have been thrown append ,httpcore,0
-start END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL oozieUrl MockDagEngineService run assertEquals testStart args call 1 -oozie size assertTrue get job SERVLET_CLASSES runTest ,oozie,1
END_POINTS IS_SECURITY_ENABLED oozieUrl conf run wc appPath assertTrue get create workflow.xml SERVLET_CLASSES close runTest app getContextURL MockDagEngineService assertEquals getFileSystem testRun call OozieClient mkdirs setProperty wfCount createConfiguration toString getFsTestCaseDir ,oozie,1
checkFsConf testGetLocalFsSetsConfs getLocal FileSystem lfs conf ,hadoop,0
createSymlink link Opened a link using AFS testAccessLinkFromAbstractFileSystem wrapper linkToFile afs fail file getDefaultFileSystem testBaseDir1 createAndWriteFile fc open ,hadoop,1
suspend END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL oozieUrl MockDagEngineService conf assertEquals wc call OozieClient 1 setProperty createConfiguration testSuspend SERVLET_CLASSES runTest ,oozie,1
bytes getText  ASCII double digit (00 - 99) Numeric Value + 130 DecodedBitStreamParser 00019899 assertEquals decode decodedString testAsciiDoubleDigitDecode ,zxing,0
"fromRow m1 m2 UTF-8 foo testBlobAndDiff assertEquals _foo {""m1"":2, ""m2"":2} getBytes bar get Collection doc ""blob"", [[""="", ""foo"", ""bar""],[""M"", ""m1"", 1],[""M"", ""m2"", 3]] row ",jackrabbit,1
 ///////////////////////////////////////////////////////////////////// POST Retrieving articles for a user (Json) replace CoreMatchers contentcontent GET_ARTICLES_URL POST_ARTICLE_URL testGetAndPostArticleViaJson path We are now getting 4 articles.  one new result: bob@gmail.com sayAndMakeRequest payload new title new title {username} testServerUrl articleDto Now we are authenticated and expect the post to succeed... We get back all 3 articles of that user Posting a new article is a post request to  doLogin If we now fetch the articles again we are getting a new article (the one we have posted successfully contentTypeApplicationJson Retrieving all articles of a user is a GET request to  Request say is USER sayNextSection url getGsonWithLongToDateParsing articlesDto Posting new article (Json) Please note that you have to be authenticated in order to be allowed to post. size response GET fromJson sayAndAssertThat You have to be authenticated in order to post articles After successful login we are able to post articles ,ninja,1
Auth exception Error while  testWrapExceptionWithMessage getMessage assertEquals getCause  redirect the LOG to and check log message ex Assert Error while authenticating with endpoint: localhost KerberosAuthenticator assertTrue equals authenticating with endpoint: localhost wrapExceptionWithMessage Induced exception ex2 ,hadoop,0
assertCorrectImage2binary testDecodeRow2binary19 19.png  ..XXXX.. ........ .X..XXX. X.X.X... XX.XXXXX .XXXX.X. ..XX...X .X.....X .XX..... XXXX.X.. XX..  (01)90012345678908(3102)001750(15)100312 ,zxing,0
argThat CoreMatchers notNullValue equalTo hasItem connectFuture when impl times Assert Boom verify testGetSessionFailure ofSeconds ArgumentMatchers anyString thenReturn Timeout somehost failed assertThat eq any isDone matches future1 getRoutes future2 Mockito callback connectSession getSession ,httpcore,0
 fileResource1  keys (both deprecated and new) j1 conf f1 b1 CONFIG  add the corresponding old/new keys of those added to CONFIG1 addDeprecationToConfiguration endConfig g1 c1 fileResource A B C D E F G H I h1 J CONFIG2 CONFIG3 d1 appendProperty out addResource get  5.new key which is final and has null value. a b c d e f g h i1 startConfig assertEquals e1 a1 assertNull testDeprecationForFinalParameters ,hadoop,0
SubWorkflow Job 4 should not have been purged subwfJob3GetCmd addRecordToWfActionTable WorkflowInstance getStatus wfAction5GetCmd Workflow Action 4 should not have been purged wfAction1GetCmd assertNotNull SubWorkflow Action 1 should not have been purged subwfAction3GetCmd wfJobGetCmd subwfJob2GetCmd subwfAction4GetCmd SubWorkflow Job 2 should not have been purged execute Workflow Action 2 should not have been purged 1 fail 2 3 4 WorkflowAction 5 SubWorkflow Action 3 should not have been purged wfAction2GetCmd Workflow Action 5 should not have been purged subwfAction5 subwfJob1GetCmd SubWorkflow Action 2 should not have been purged getId SubWorkflow Job 5 should not have been purged addRecordToWfJobTableForNegCase subwfAction5GetCmd subwfJob5GetCmd wfJob subwfAction1GetCmd SubWorkflow Action 5 should not have been purged addRecordToWfJobTable SubWorkflow Job 3 should not have been purged get Workflow Job should not have been purged subwfJob1 WorkflowJob subwfJob5 subwfAction1 Workflow Action 3 should not have been purged subwfJob4 subwfAction2 subwfJob3 subwfAction3 subwfJob2 subwfAction4 wfAction3GetCmd wfAction4GetCmd SubWorkflow Action 4 should not have been purged assertEquals wfAction1 wfAction2 wfAction3 wfAction4 wfAction5 call Services Workflow Action 1 should not have been purged testPurgeWFWithSubWF2MoreThanLimit SubWorkflow Job 1 should not have been purged subwfAction2GetCmd jpaService subwfJob4GetCmd ,oozie,1
IOException expected. getTempPath  create an empty file (which is not a valid sequence file) expected GenericTestUtils conf fs path fail file SequenceFile assertTrue getLocal zerolength.seq FileSystem create testInitZeroLengthSequenceFile close ,hadoop,0
unknown:/// set e getProviders getMessage conf assertEquals testFactoryErrors No KeyProviderFactory for unknown:/// in  assertTrue should throw! KeyProviderFactory providers ,hadoop,0
actionNum CoordinatorJob coord-action-get.xml _testPendingFalseStatusCount CoordinatorAction getId job addRecordToCoordActionTable testCoordActionPendingFalseStatusCountGet addRecordToCoordJobTable ,oozie,1
10.119.103.112 10.113.221.222 10.222.103.121 is  in the list 10.113.221.221 assertFalse testAddWithSleepForCacheTimeout 10.222.103.121 is not in the list 10.221.102.0/23 cipl ips 10.222.103.121 Thread sleep createFileWithEntries removeFile assertTrue ips.txt TestFileBasedIPList ips2 10.113.221.222 is in the list 10.222.0.0/16 isIn 10.113.221.222 is not in the list ,hadoop,0
conf run bak fs System out tmpname ToolRunner returned should be 1 assertTrue tmp fshell setPermission indexOf permission denied printed UserGroupInformation createUserForTesting ret setErr /foo Permission denied tmpUGI testRemoteException assertEquals getFileSystem dfs p args str mygroup doAs -ls build numDataNodes mkdirs reset toString shutdown ,hadoop,1
KeyProvider a A getCipher set getAttributes setBitLength description conf assertEquals setDescription setAttributes getDescription put setInt testOptions myCipher setCipher options attributes getBitLength yourCipher ,hadoop,0
add  create the framework without deleting the default tests. request adapter method setAdapter alreadyCheckedResponse calledMethodSet execute Method not in default tests.  method= contains TestingFramework framework Assert defaultTestsWithMockedAdapter runTests assertTrue get METHOD ,httpcore,0
" jobConf conn setRequestMethod IS_SECURITY_ENABLED /app POST writeXml appPath fs setRequestProperty getTestUser2 create workflow.xml content-type /v0/jobs jobXmlPath  runTest(""/jobs"", BaseJobsServlet.class, IS_SECURITY_ENABLED, new Callable<Void>() { runTest set RestConstants openConnection MockDagEngineService HttpServletResponse testDiffUser assertEquals getFileSystem params url call OozieClient getTestUser getResponseCode reset createURL toString getOutputStream getFsTestCaseDir setDoOutput ",oozie,1
" getWaitingActions dep evicted toURIString assertTrue  First 500 should have been evicted. But it is LRU and the last 200 removed is between 300 and 700. assertNotNull get setupServices actionID  maxElementsInMemory=""500"" overflowToDisk=""false"" testmaxelementsinmemory addMissingDependency waitingActions assertEquals testMaxElementsInMemory pdms hcat://hcat.server.com:5080/mydb/mytbl/id=  is missing in cache numItems Services contains assertNull ",oozie,1
actual Count.getUsage -count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ... expected count assertEquals getUsage ,hadoop,0
yyyy-MM yyyy-ww yyyy-WW yyyy-MM-dd_HH_mm assertEquals yyyy-MM-dd_HH_mm_ss yyyy-MM-dd_HH yyyy-MM-dd_hh getPeriodicityType rc PeriodicityType yyyy-MM-dd testPeriodicity ,logback,0
assumeFalse ex assertExContains getWinUtilsFile E_NOT_A_WINDOWS_SYSTEM getWinUtilsPath WINDOWS Assume testNoWinutilsOnUnix getCause ,hadoop,0
java.version EnvUtil setProperty assertFalse 1.4.xx isJDK6OrHigher isJDK5 testJava1_4 System isJDK7OrHigher ,logback,0
"<execution>LIFO</execution> </controls> <datasets>  addRecordToBundleActionTable checkCoordJobs conf getId </input-events>  appPath substring coordJob sc </property></configuration> </workflow> </action> </coordinator-app> writeToFile appXml <property> <name>inputB</name> <value>${coord:dataOut('LOCAL_A')}</value>  file:// getTestCaseDir UNIT_TESTING <output-events> <data-out name=""LOCAL_A"" dataset=""local_a"">  Job getBundleId timezone=""UTC""> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset>  coordinator.xml getAppName set <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  uri:oozie:coordinator:0.2 addRecordToBundleJobTable length <dataset name=""local_a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  assertEquals xmlns=""uri:oozie:coordinator:0.2""> <controls> <concurrency>2</concurrency>  call <coordinator-app name=""NAME"" frequency=""${coord:days(1)}"" start=""2009-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""  OozieClient jobId fail getTestUser </datasets> <input-events>  <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>  -C getAppNamespace <data-in name=""A"" dataset=""a""> <instance>${coord:latest(0)}</instance> </data-in>   COORD-NAME <dataset name=""a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  job File testBasicSubmitWithBundleId ",oozie,1
testSetClosed isOpen assertTrue Reference count should be open assertFalse clr setClosed Reference count should be closed ,hadoop,0
viewFs getChildFileSystem viewFsPath1 mockfs2:/ viewFsPath2 removeDefaultAcl /d/e/f removeAcl conf setAcl ViewFileSystemTestSetup getRawFileSystem mockFs2 mockFs1 emptyList setupMockFileSystem FileSystem get mockfs1:/ /a/b/c verify /mounts/mockfs2/d/e/f Collections removeAclEntries testAclMethods mockFsPath2 getAclStatus mockFsPath1 createConfig FsConstants entries modifyAclEntries /mounts/mockfs1/a/b/c ,hadoop,0
" Refill task should add 10 values to get to a full queue Failed to get all 19. Sync call filler got wrong number. drain Assert  Trigger a prefill (1) and an async refill (10)  Wait a while to make sure that no async refills are triggered  Synchronous call getTop  2. Start another async task to fill the queue in the cache  Wait for the async task to finish  Drain completely after filled by the async thread test SyncGenerationPolicy k1 getAtMost Failed in async call. assertEquals getNext Failed in sync call.  Drain completely, no further refills triggered  the prefill to the low watermark, 1 consumed by getNext()) waitForRefill getSize assertNull size filler vq testgetAtMostPolicyALL shutdown Failed to drain completely after async. ",hadoop,0
"101001010010001010001001010000101001010001001001001001000101010100001000100101000010 111010010  bK bO 111010110 101011000 100000 00000  bU aA 101101100  % + cA 100001010 110001010 101100101101011001101001101100101101100110101011011001011001101001101101001110101000  bT 100110010 doTest 110101110  cZ bF 100010100 100011010 110011010  bW dA  checksum: 12 28  bV A Z 000001010111101101010001101001001101000101100101001100100101100010101011010001011001 100100110 100101100 111011010 101011110 111001010  cL 0 9 001011000101001101001000110101010110001010011001010001101001011001000101101101101001 100111010 ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 testEncode  bE space $ 10100111010101000010101011110100000 110101000 110100010   $%+!,09:;@AZ[_`az{ 110100110 110101100 101110110 100010110  aZ bA  dZ bP 110010110 110010010 ",zxing,0
init thenReturn servletContext ContentTypes httpServletRequest testIsJsonWorks when isRequestJson assertTrue context getContentType httpServletResponse  init the context from a (mocked) servlet ,ninja,0
formatDate Expires:  Last-Modified:  headers addHeader getHeaders lastModifiedDate If-Modified-Since:  contains assertTrue TimeUnit cacheControlNoCacheAndExpirationDateInTheFuture assertConditionallyCached conditionalRequest Cache-Control: no-cache ,okhttp,1
"coordinator.xml testSubmitNoUsername set <coordinator-app name=""NAME"" frequency=""10"" start=""2009-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""  conf Exception expected if user.name is not set! appPath </configuration> </workflow> </action> </coordinator-app> sc call writeToFile OozieClient fail appXml file:// getTestCaseDir UNIT_TESTING <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>  <controls> <timeout>10</timeout> <concurrency>2</concurrency>   conf.set(OozieClient.USER_NAME, getTestUser()); File xmlns=""uri:oozie:coordinator:0.2"">  <execution>LIFO</execution> </controls>  <configuration> <property> <name>inputA</name> <value>blah</value> </property>  ",oozie,1
 init set SLAService getConf assertFalse testBasicService destroy conf services Services assertTrue assertNotNull get isEnabled slas ,oozie,1
fail ex ae getErrorCode testvalidateSameNN FS007 assertEquals validateSameNN hdfs://x/foo viefs://x/bla hdfs://y/bla hdfs://x/bla ,oozie,1
result testResultsJsonWithObjectToRender getStatusCode getRenderable Results testObject json getContentType assertEquals render Result ,ninja,0
init wf-schema-valid.xml reader authToken destroy conf wfDef services IOUtils getTestUser testReadDefinition copyCharStream assertNotNull getTestCaseDir /workflow.xml get file:// getResourceAsReader workflow.xml toString writer wps readDefinition File ,oozie,1
formatDate Expires:  Last-Modified:  headers addHeader getHeaders lastModifiedDate If-Modified-Since:  contains assertTrue TimeUnit cacheControlNoCacheAndExpirationDateInTheFuture assertConditionallyCached conditionalRequest Cache-Control: no-cache ,okhttp,1
testDefaultURIwithOutPort testDefaultUriInternal hdfs://dummyhost ,hadoop,0
"${coord:dataInPartitionFilter('ABC', 'java')} CoordELFunctions           * type=java           (datastamp=='12' AND region=='us') coord-action-start evalAndWrap assertTrue (region=='us' AND datastamp=='12') OR (region=='us' AND datastamp=='13') .datain.ABC expr hcat://hcat.server.com:5080/mydb/clicks/datastamp=13;region=us Boolean (datastamp='12' AND region='us') (region='us' AND datastamp='12') testdataInPartitionFilter init res (region=='us' AND datastamp=='12') OR (datastamp=='13' AND region=='us') hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us, .datain.ABC.unresolved setVariable ${coord:dataInPartitionFilter('ABC', 'pig')}           * type=pig           (datastamp=='12' AND region=='us') OR (region=='us' AND datastamp=='13') (region=='us' AND datastamp=='12') (datastamp=='12' AND region=='us') OR (datastamp=='13' AND region=='us') eval equals hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us ",oozie,1
cluster /foo  write 2 files at the same time read in conf assertEquals getFileSystem testConcurrentFileCreation fs out p /bar build create write close shutdown open  verify ,hadoop,1
assertNull testGetNonExistingProducesNoNPE manager createTemplateEngineManager non/existing getTemplateEngineForContentType ,ninja,0
 A B addNode def getTransientVar getId WorkflowInstance getStatus asList wf array testJobPersistance end signal fromByteArray a b WritableUtils one setVar start assertEquals / 1 <worklfow-app/> toByteArray getVar Arrays job setTransientVar ,oozie,1
"TestFeature reflectionEquals /FEATURE  Modify data in ZK setupTestWithEmptyDatastore run getBytes sleep externallySetStateWrapper setParameter setFeatureState await json TimeUnit latch countDown serverClientPair externallySetState forPath TEST_ZNODE printStackTrace e setData testZkNodeChangesUpdateFeatureState UTF-8 start setStrategyId user1, user2, user3 is assertThat getFeatureState Thread loadedFeatureState objectMapper savedFeatureState UsernameActivationStrategy stateRepository writeValueAsString ",togglz,1
 init set getConf _testEventHandlerService assertFalse destroy getEventQueue conf services ehs Services contains EventHandlerService getAppTypes assertTrue  check default initializations workflow_job get isEnabled coordinator_action jobtypes testService ,oozie,1
http://myserver.com:80  and application.conf: (fullServerName=${serverName}:${serverPort}) NinjaMode testReferenciningOfPropertiesWorks  instantiate the properties: get fullServerName assertEquals ninjaProperties ,ninja,0
request newToken getName tokenSigned TOKEN_VALIDITY_SEC setExpires sign secret when asList getInitParameterNames System Assert getCookies DummyAuthenticationHandler secretProvider management.operation.return signer AuthenticatedURL init cookie AuthenticationFilter thenReturn destroy assertEquals token filter p getMockedServletContextWithStringSigner getInitParameter Mockito u elements currentTimeMillis getToken true mock toString Arrays config testGetToken ,hadoop,0
bundleJobGetCmd testBundleKill1 addRecordToBundleJobTable getId assertEquals getStatus execute call Services assertNotNull get Job job jpaService ,oozie,1
storePassword /test.p12 getResource toCharArray getLocalPort submit serverSocket newSingleThreadExecutor Executors serverSslContext getServerSocketFactory clientSocket Assert bind keyPassword assertNotNull nopassword create Boolean SSLContextBuilder close connect localhost startHandshake localPort loadKeyMaterial loadTrustMaterial resource2 thrown setSoTimeout testSSLHandshakeServerNotTrusted /test-server.p12 resource1 accept call getSocketFactory expect createSocket build toMillisecondsIntBound clientSslContext socket TIMEOUT getSession createServerSocket ,httpcore,0
bad:-port set    	    host4:5     	      host2 myAddress getMessage conf assertEquals threwException iae getSocketAddr Does not contain a valid host:port authority:  defaultPort getHostPortString NetUtils host:1 assertTrue bad:-port (configuration property 'myAddress') defaultAddr host2: host4:5 addr testSocketAddress host2:3 ,hadoop,0
bundleJobGetExecutor testBundlePurgeXCommandFailed addRecordToBundleActionTable getId DateUtils getStatus parseDateOozieTZ assertNotNull get Job 2011-01-01T01:00Z addRecordToBundleJobTable assertEquals Bundle Action should not have been purged execute call Bundle Job should not have been purged Services fail bundleActionGetExecutor1 bundleActionGetExecutor2 action1 job action2 jpaService ,oozie,1
session  Given insert getTupleValue asList crud tuple  When of id map 10 isNotNull actual containsEntry RandomUtils manager one nextLong assertThat execute ImmutableMap getMap getInt should_insert Tuple2  Then Long SELECT * FROM complex_tuple WHERE id =  tupleValue isEqualTo 20 entity ,achilles,1
"testSkipFilter testQualifierOne-2 f ROWS_TWO toBytes kvs setFilter Bytes QUALIFIERS_TWO verifyScanFull FAMILIES  Should only get rows from second group, and all keys VALUES CompareOp  testRowTwo-3  testRowTwo-2 ",hadoop,1
"listKeys  glarch =baz    Clean up to be a good citizen  listOut run abc=def attributes: [foo=bar] foo = bar testAttributes  Simple creation test  keyattr2 create keyattr3 keyattr1 keyattr4 foo=bar deleteKey =bar [abc=def] [glarch=baz]  Legal: attribute is a, value is b=c   Negative test - repeated attributes should fail  rc contains -provider -attr reset  Not in attribute = value form  =  Test several attrs together...  foo attributes: [a=b=c]  ...and list to see that we have the attr  keyattr1 has been  assertTrue a=b=c jceksProvider  ...and list to ensure they're there.   Negative tests: no attribute  outContent foo=glarch ks assertEquals  No attribute or value  setConf [foo=bar] args1 args2 toString args3 successfully created args4 ",hadoop,0
init QUEUE_TIME costProvider lockfreeWeight foo foo.weighted-cost.lockfree expectedCost conf DEFAULT_LOCKEXCLUSIVE_WEIGHT assertEquals bar.weighted-cost.lockexclusive LOCKFREE_TIME LOCKSHARED_TIME setInt queueWeight foo.weighted-cost.queue processingDetails foo.weighted-cost.lockshared testGetCostConfiguredWeights locksharedWeight LOCKEXCLUSIVE_TIME getCost  should not apply actualCost ,hadoop,0
request  The request should be equal to the default request. assertNothingThrown setRequestHandler defaultRequest put STATUS Assert requestHandler HEADERS runTests assertNotNull CONTENT_TYPE get defaultURI verify addTest The responseExpectations do not match the defaults initResponseExpectations matchesDefaultURI initRequest adapter The request handler should have been passed to the adapter defaultResponseExpectations assertEquals assertThat assertSame responseExpectations execute  The responseExpectations should be equal to the default. The request does not match the default request should not be null framework Mockito response mockRequestHandler newFrameworkAndSetAdapter mock  assertNothingThrown() should have been called. BODY ,httpcore,0
"XmlUtils <property><name></name></property> parseXml conf assertEquals <root xmlns=""uri:oozie:workflow:0.4""><parameters> str fail ex getErrorCode <property><name>hello</name></property> ParameterVerifier testVerifyParametersEmptyName ErrorCode verifyParameters </parameters></root> ",oozie,1
testNoArgs checkArgLimits ,hadoop,0
getSubject getName checkTicketAndKeytab originalLoginUser subject getUser user1.keytab loginUserFromSubject user2.keytab run principal2 principal1  not affected.  login principal1 with a keytab. Assert removeUser assertNotNull reloginFromKeytab getPath workDir  no login context should be attached to the user. UserGroupInformation user1 user2 extLoginUserTicket keytab1 testReloginForLoginFromSubject kdc loginUserFromKeytab  verify the new login user is external. assertSame getLoginUser keytab2 getLogin loginUserFromKeytabAndReturnUGI doAs assertNull assertNotSame createPrincipal extLoginUser originalLoginUserTicket  original login user not affected. ,hadoop,0
 X . X X X . . X . X . X . . . X . X . X X X . . . X X   X . . X X . . X X . X . X . . . . X . X . . X . . X .   X X . . X X . . . . . X X . . . X X . . . X . X . . X   X X . X . X . . . X . X . . . . X X . X . . X X . . .   . . . . X . X X X . . . . X X X X . . X X X X . . . .   X  . . . . . . . X . X . . . . . . . X X X X . . . X X X   BitMatrix matrix decode X X X . . X X X X X . . . . . X X . . . X . X . X . X   X . . X X X . X X X X X X X X X X X X X . . . X . X X   X . X . X . . X . X X X X X X X X . X X X X . . X X .   X X . X . . . X X . . . X . . X X X . X . X X X X X .   . . X . . X . X . . . X . X X . X X . X . . . X . X .   X X . . . . . . . . X . . . X . X X X . X . . X . . .   X . X X . . X X . . . . . X . . . . . . X X . X X X .   testDecodeTooManyErrors . . . X . X . X . . . . . X X X X X X . . . . . . X X   X X . . X . . X . X X X X X X X X X X X X X . . X . X   NO_POINTS . . . . X X . . . X . . . . . . . X X . . . X X . X .   X . . . . X . X . X . X . . . X . X . X X . X X . X X   X . . . X . X X X X X X . . X X X . X . X X X X X X .   . . . X X X . . X X . X X X X X . X . . X . . . . . .   X . . . X X . . X X X . X X . X X X X . X X . . X . .   X X X X X X X X . X . X X X X X . X . X . X . X X X .   parse . . . . X . X X . . X X . X X . X . X X X X . X . . X   X X . . X . . X X X X X X X . . X . X X X X X X X . .   X . X . . X . X . X . X . X . X . X . . . . . X . X X   X X X . X X X X . . X X X X . . X . . . . X . . X X X   .  r X X . . X . . . . . X X . . . . . X . . . . X . . X X   X X X X . . . X . . X X X . X X . . X . . . . X X X .   ,zxing,0
date session  Given insert SELECT * FROM simple WHERE id =  crud  When get id row value all postInsert_preInsert_value RandomUtils manager should_trigger_for_insert getString nextLong assertThat rows execute preInsert_value getValue hasSize  Then Long isEqualTo entity ,achilles,1
 Decrypt it manually getEncryptedKeyVersion manualMaterial getName decryptedKey AES/CTR/NoPadding deriveIV eek encryptionKey KeyProviderCryptoExtension doFinal assertArrayEquals createForDecryption testEncryptDecrypt EncryptedKeyVersion decryptEncryptedKey getEncryptedKeyIv encryptedKeyIv cipher generateEncryptedKey init getEncryptionKeyName encryptedKeyMaterial eek2  Test the createForDecryption factory method apiMaterial Wrong key material from decryptEncryptedKey  Get an EEK kpExt AES getMaterial Cipher getInstance getEncryptionKeyVersionName  Decrypt it with the API ,hadoop,0
addNode def start assertEquals kill WorkflowInstance getStatus killed wf 1 <worklfow-app/> end job testKillWorkflow ,oozie,1
hello_depArray2 hello_depArray1  and test: bodyParserEnginePost hello_dep1 getValidation assertFalse equalTo hasViolations invoke when dep put depList1 depList2 hello_depList1 hello_depList2 depArray1 assertNotNull testObject get context depArray2 depList map validation thenReturn  some setup for this method: testBodyParserWithCustomNeedingInjectionParamParser  do dep1 assertThat size Mockito getParameters depArray ,ninja,0
formatNameValuePair value1 formatParameters formatHeaderElement params testInvalidArguments fail buf regular_stuff Assert param formatElements elements name1 element IllegalArgumentException should habe been thrown ,httpcore,0
 call a=A testNoResourceNoParams MyJsonRestServlet GET HttpServletResponse invoke assertEquals runTest / /hello ,oozie,1
 getWaitingActions System dep sleep testevictionontimetoidle get setupServices startTime info  timeToIdleSeconds is 1 addMissingDependency LOG pdms hcat://hcat.server.com:5080/mydb/mytbl/id= Time taken to insert and retrive  numItems verifyWaitingAction Thread Services assertNull  items is  currentTimeMillis testEvictionOnTimeToIdle ,oozie,1
assertFalse getCurrentDateafterIncrementingInMonths getId run DateUtils isPending getStatus addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob assertNotNull get CoordinatorAction end Job waitFor start assertEquals XDataTestCase currentDateplusMonth execute addRecordToCoordJobTable CoordinatorJob jobId Services runnable coord-action-get.xml testCoordStatusTransitServiceSuspendedByUser job jpaService evaluate ,oozie,1
"getStats getConsoleUrl setJobId setExecutionData getLogToken setEndData setExternalChildIDs setPendingAge isPending getStatus getExternalId System consoleUrl assertTrue assertNotNull action setPending jsonStats id signal getSignalValue getData trackerUri getPendingAge getJobId setStartData getProperties externalId assertEquals setLogToken setStats getExternalStatus executionPath setExecutionPath getExecutionPath setSignalValue WorkflowAction externalStatus job1,job2 getExternalChildIDs logToken getTrackerUri testAction ",oozie,1
srcConf set testInjectDefaults assertEquals targetConf XConfiguration testParameter1 testParameter2 assertNull testParameter3 injectDefaults originalValueFromTarget get valueFromSource ,oozie,1
"setJobStatus     <app-type>WORKFLOW_ACTION</app-type>      <alert-percentage>ap</alert-percentage>  </event>     <parent-sla-id>psi</parent-sla-id>   Set ""CREATED"" status to get the event of registration kind: toXml System   <sequence-id>1</sequence-id>      <sla-id>si</sla-id>      <notification-msg>nm</notification-msg>      <alert-frequency>af</alert-frequency>  testToXmlRegistrationEvent     <dev-contact>dc</dev-contact>    <registration>      <status-timestamp>1970-01-01T00:00Z</status-timestamp>  bean <event>      <expected-end>1970-01-01T00:00Z</expected-end>  set prettyPrint     <job-data>jd</job-data>  XmlUtils el   </registration>      <user>u</user>  assertEquals actualXml     <alert-contact>ac</alert-contact>      <expected-start>1970-01-01T00:00Z</expected-start>      <qa-contact>qc</qa-contact>      <upstream-apps>ua</upstream-apps>      <job-status>CREATED</job-status>      <app-name>an</app-name>      <group>gn</group>  toString     <se-contact>sc</se-contact>  ",oozie,1
"request ;coordinators=Coord1,Coord2;actionstatus=KILLED _execQuery testMultipleCoordinators assertEquals getAction getId  there are 3 coordinators but giving range as only two of them brList Coord1@2 Coord2@1 size get bundleName  2 actions satisfy the conditions bundle= ",oozie,1
expiringKeys conf rmDTMasterKeyState when getRMDelegationToken Assert delegationToken getClientRMService getRMDTSecretManagerState token1  record the current key init  tokenRemoverThread.rollMasterKey() thenReturn containsKey getTokenState oldCurrentKey decodeIdentifier getRenewer convertFromYarn  rollMasterKey is called every 1 second. contains stop mock  request to generate a RMDelegationToken testRMDTMasterKeyStateOnRollingMasterKey request getCurrentKey assertFalse ConverterUtils sleep assertTrue rm1 get rmState dtSecretManager  wait for the first rollMasterKey renewer1 rmDTState start assertEquals Thread memStore dtId1 getState  assert all master keys are saved getRMDTSecretManager getAllMasterKeys addAll response getMasterKeyState getDelegationToken  assert old-current-key and new-current-key exist newCurrentKey ,hadoop,1
"@ closeTrx coordClient getStore getTime LocalOozie Could not update db. getStatus -testCoordRerun-C getCoordClient rerunScope get beginTrx CoordinatorAction reRunCoord actionNum2 commitTrx actionNum1 coord-rerun-action2.xml RestConstants printStackTrace store1 e store , testCoordRerunActions3 actionId2 addRecordToJobTable Integer jobId actionId1 Services fail CoordinatorJob addRecordToActionTable assertNotSame 0000000- toString action1 action2 coord-rerun-action1.xml getCoordinatorAction ",oozie,1
handler getURIHandler testExists toUri assertFalse uriService conf getFileSystem getTestUser path1 path2 assertTrue mkdirs  Try without the scheme. getPath exists /2012/12/02/ /2012/12/12/ getFsTestCaseDir ,oozie,1
Bundle Job should have been purged Bundle Action should have been purged addRecordToBundleActionTable testPurgeBundleWithCoordChildWithWFChildWithSubWF3 addRecordToWfActionTable coordActionGetCmd DateUtils WorkflowInstance getStatus addRecordToCoordActionTable parseDateOozieTZ bundleJob BundleJobBean assertNotNull Coordinator Action should have been purged CoordinatorAction Job wfAction wfJobGetCmd SubWorkflow Job should have been purged execute subwfActionGetCmd CoordinatorJob 1 coordJobGetCmd fail WorkflowAction coordAction SUCCEEDED je subwfJobGetCmd bundleJobGetCmd getId SubWorkflow Action should have been purged coordJob wfJob Workflow Job should have been purged addRecordToWfJobTable getErrorCode get WorkflowJob subwfAction getAppName bundleAction Coordinator Job should have been purged Workflow Action should have been purged wfActionGetCmd 2011-01-01T01:00Z addRecordToBundleJobTable assertEquals addRecordToCoordJobTable call Services coord-action-get.xml subwfJob ErrorCode jpaService bundleActionGetCmd ,oozie,1
add org.springframework.boot grabAnnotations basicAdd 1.2.3 assertGrabAnnotation size get assertEquals annotationNode getAnnotations spring-boot-starter-logging ,spring-boot,1
garbageStrings maxGcTimePercentage alerter gcTimePercentage getLatestGcData System  Alerter should be called if GC takes >= 10% Assert alert  alerter is invoked at least once. assertTrue Long string prefix just to fill memory with garbage  numAlerts  Run this for at least 1 sec for our monitor to collect enough data startTime gc getGcTimePercentage add alertGcPerc gcTimeMonitor gcCount start clear j gcData testGcTimeMonitor currentTimeMillis getAccumulatedGcCount ,hadoop,0
getCoordAction recoveredAction getCurrentDateafterIncrementingInMonths getId run DateUtils WorkflowInstance getStatus addRecordToCoordActionTable parseDateOozieTZ sleep wfJob addRecordToWfJobTable UNIT_TESTING get CoordinatorAction action end currentDatePlusMonth WorkflowJob waitFor actionCheckRunnable actionNum ce testActionCheckerServiceCoord RUNNING start assertEquals XDataTestCase execute addRecordToCoordJobTable CoordinatorJob Services getTestUser coord-action-get.xml job evaluate jpaService ,oozie,1
p test4 size get cvvsdf b1234 assertEquals a123 /a123/b1234/cvvsdf ,logback,0
set testToString TimeUnit processingTime=0 lockfreeTime=0 lockwaitTime=0 locksharedTime=0  details lockexclusiveTime=0 responseTime=0 toString assertEquals Timing enqueueTime=10 queueTime=20000 handlerTime=0  ,hadoop,0
 we still can scan records in an unsorted TFile reader conf vbuf testScan getKeyLength  now try get value first fs advance path getLen getFileStatus scanner valueM kbuf getKey getValueLength vlen keyZ isFalse assertThat createScanner valueZ entry getValue klen BUF_SIZE isSorted getEntryCount keyM isEqualTo open  read key and value ,hadoop,0
testInterruptsWithCompositeCallable initialCallable callables key5 type queueSerial       * assuring an interrupt command will be executed before a composite      * callable with the same lock key       queueservice initialKey assertTrue get initialType lockKey waitFor key EXEC_ORDER add init c initialLockKey retValue CallableQueueService destroy Services 1 testKill intCallable setSystemProperty evaluate queue ,oozie,1
      <app-path>       <configuration> getJobInfo           <name>a</name>         </property> getActions getId getExternalId getStatus fs APP1           <value>A</value> SubWorkflowActionExecutor protoConf createBaseWorkflow getWorkflowClient W get create action </app-path> workflow.xml end WorkflowJob write close getBaseProtoConf waitFor workflow <sub-workflow xmlns='uri:oozie:workflow:0.1'> oozieClient         <property> start subWorkflowAppPath subWorkflow assertEquals getFileSystem JOB_TIMEOUT check setConf       </configuration> WorkflowAction </sub-workflow> testSubWorkflowStart writer evaluate getParentId getFsTestCaseDir ,oozie,1
valueX  write a key/value first Compression getName keyY skip keyX valueY getBytes Cannot add key/value after start adding meta blocks.  add more key/value dummy fail outMeta closeOutput Assert testX prepareMetaBlock  create a new metablock writer testFailureWriteRecordAfterMetaBlock write close append ,hadoop,0
server hcat.mydb.mytable getJMSConnectionInfo printStackTrace e hcatService hcat.server.com:5080 jmsService assertEquals services hcat://hcat.server.com:8020 fail getMessageReceiver receiver2 receiver1 connInfo get topic registerForNotification Exception encountered :  testRegisterSingleConsumerPerTopic ,oozie,1
PATH request  Add request. queryMap text/html; charset=us-ascii  ) put STATUS HEADERS param runTests CONTENT_TYPE <HTML>42</HTML> addTest /stuff RESPONSE more-stuff  Response header3 header2 requestHeadersMap header1 test method What is the meaning of life? responseHeadersMap something TestingFramework framework REQUEST QUERY response METHOD text/plain; charset=us-ascii header_stuff BODY addTestNoMocks stuff ,httpcore,0
ex reps count await assertEquals TIMEOUT testAwaitLambdaRepetitions  lambda expression which will succeed after exactly 4 probes timeout ,hadoop,0
"r2 getName output test.*.source.filter.exclude getTestFilename Test putMetrics  When we call stop, at most two sources will be consumed by each sink thread. s0 s1 testInitFirstVerifyCallBacks add checkMetricsRecords ms getAllValues capture test.sink.test.class mr2 mr1 s1 desc stop *.period TestMetricsConfig test.sink.sink1.metric.filter.exclude mock shutdown s0rec  publish the metrics test.sink.sink2.metric.filter.exclude save test.source.s1.metric.filter.exclude timeout X* times verify sink2 desc hadoop-metrics2-test s1rec set registerSink DefaultMetricsSystem incr start sink1 desc assertEquals Y* s0 desc sink2 sink1 publishMetricsNow register r1 ",hadoop,0
 test retrieval of range of actions (action 1-2) getId CoordUtils assertEquals addRecordToCoordActionTable - addRecordToCoordJobTable Integer getCoordActionsFromIds testGetCoordActionsFromIdsRange CoordinatorJob jobId coord-action-get.xml rerunScope coordActions size CoordinatorAction toString actionNum2 job actionNum1 ,oozie,1
putValuePB ROW_1 assertEquals checkValuePB TABLE deleteRow testSingleCellGetPutPB COLUMN_1 getValuePB response VALUE_1 putValueXML getCode VALUE_2 ,hadoop,1
"add a b setFormatInfo assertEquals parse p Integer witness t setOptions %45x{a, b} testOptions1 ol ",logback,0
allow assertFalse generateId save principals getUserManager remove createGlobRestriction group2_ path getPrincipal acMgr getTestGroup assertTrue /* add hasPrivileges createGroup deny readPrivs group3 group2 privilegesFromName modify testGlobRestriction3 childNPath group3_ Privilege superuser ,jackrabbit,1
"cluster conf fileSpace  Now, appending more than 1 fileLen should result in an error createFile  make sure no intermediate directories left by failed rename  verify space quota  directory should exist 512 write  verify space for its parent quotaDir2053  verify increase in space getFileSystem  now increase the quota for quotaDir1 dfs quotaDir2053_A  Move /nqdir0/qdir1/qdir21/nqdir32 /nqdir0/qdir1/qdir20/nqdir30  appending 1 fileLen should succeed quotaDir2053_B mkdirs tempPath quotaDir2053_C /nqdir0/qdir1/qdir20 /nqdir0/qdir1/qdir21  Check space consumed for /hdfs-2053 dstPath /nqdir0/qdir1  identifiable file sizes per subdir, which helps during debugging. A B C  diskspace quotas hasException out  Verify space before the move: assertTrue /hdfs-2053 getSpaceConsumed close replication DFSTestUtil set  create directory /nqdir0/qdir1/qdir20/nqdir30 c assertEquals  Create directory /hdfs-2053 IOUtils rename  now increase the quota for quotaDir1 and quotaDir20 exists  5: Create directory /nqdir0/qdir1/qdir21/nqdir32 setBoolean  Create /nqdir0/qdir1/qdir21 and set its space quota to 2 * fileSpace fileDir/file2  verify space before append;  verify space after append; quotaDir1 getSpaceQuota fileB fileC  create a file under nqdir32/fileDir  after partial append fileA fileDir/file1 DFSConfigKeys  now try to increase the replication and and expect an error.  Create a file under subdirectory C (which has a space quota) srcPath  verify space after the move setQuota  set the quota of /nqdir0/qdir1 to 4 * fileSpace  set the quota of /nqdir0/qdir1/qdir20 to 6 * fileSpace nqdir30 numDataNodes /nqdir0/qdir1/qdir20/nqdir30 nqdir33 nqdir32  delete nqdir33 getUri shutdown HdfsConstants  Create a file under subdirectory A  Create a larger file /nqdir0/qdir1/qdir21/nqdir33/ assertFalse  Create a file under subdirectory B fs delete nqdir33/file2  Set space quota for subdirectory C  create a larger file under /nqdir0/qdir1/qdir20/nqdir30 flush  first reduce the replication closeStream  Create subdirectories /hdfs-2053/{A,B,C}  Reverse: Move /nqdir0/qdir1/qdir20/nqdir30 to /nqdir0/qdir1/qdir21/ sizeFactorC sizeFactorB sizeFactorA  verify space after the failed move  then increasing replication should be ok. file2Len getContentSummary quotaDir21  verify space after partial append setReplication  verify that space is reduced by file2Len Not a HDFS:  quotaDir20 fileLen  verify space consumed remains unchanged. dfs.support.append build  after append file2 testSpaceCommands append  verify space for source for the move ",hadoop,1
assertFalse getCurrentDateafterIncrementingInMonths getId run DateUtils getStatus isPending addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob testCoordStatusTransitServiceRunning2 assertNotNull get CoordinatorAction end currentDatePlusMonth Job waitFor start assertEquals XDataTestCase execute addRecordToCoordJobTable CoordinatorJob jobId Services runnable coord-action-get.xml job jpaService evaluate ,oozie,1
cluster  write into hosts file writeConfigFile conf dir HEARTBEAT_INTERVAL waitActive  Setup conf Assert assertNotNull FileSystem getPath exclude info add hostsFile getWorkingDirectory DFSConfigKeys getHostName hosts workingDir restartNameNode stringifyException numNameNodes list fail numDataNodes getByAddress Number of live nodes should be  InetAddress shutdown nn setupHostsFile getDatanodeReport testNNRestart  Set up the hosts/exclude files. sleep build/test/data/work-dir/restartnn assertTrue StringUtils numDatanodes excludeFile cleanupFile b getParent isDataNodeUp set e toUri  heartbeat interval in seconds assertEquals getNameNodeRpc Thread inetAddress build getLocal localFileSys DatanodeReportType ,hadoop,1
"<execution>LIFO</execution> </controls> <datasets>  submitJob getMissingDependencies /workflows/${YEAR}/${MONTH}/${DAY}</uri-template>  conf <data-in name=""A"" dataset=""local_a""> <instance>${coord:current(0)}</instance> </data-in>   getActions </input-events>  getStatus appPath System writeToFile appXml actionStatus <dataset name=""local_a"" frequency=""${coord:days(1)}"" initial-instance=""2009-02-01T01:00Z""  assertTrue file:// getTestCaseDir UNIT_TESTING get CoordinatorAction ..Missing deps= action missingDeps <done-flag>consume_me</done-flag> </dataset> xmlns=""uri:oozie:coordinator:0.1""> <controls> <timeout>10</timeout> <concurrency>2</concurrency>  waitFor timezone=""UTC""> <uri-template>file:// getCoordJob coordinator.xml ce set testCustomDoneFlag <coordinator-app name=""NAME"" frequency=""${coord:days(1)}"" start=""2009-02-01T01:00Z"" end=""2009-02-01T02:00Z"" timezone=""UTC""  <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  assertEquals <action> <workflow> <app-path>hdfs:///tmp/workflows2/</app-path>  </configuration> </workflow> </action> </coordinator-app> OozieClient jobId getTestUser size </datasets> <input-events>  File actions evaluate /workflows/2009/02/01/consume_me ",oozie,1
test.txt viewfs:/// Wrong file content Starting testNflyWriteSimple listStatus conf testConf  should exist! /nfwd2 testUri URI /nfwd1 readUTF assertTrue FileSystem get create close info testUris nflyRoot testFileName /nflyroot testNflyWriteSimple LOG ConfigUtil fsDos assertEquals testFile fsdis nfly getLocal testString addLinkNfly writeUTF lfs statuses exists targetTestRoot toString Hello Nfly! open ,hadoop,0
"A B C D setIncludedProtocols getEnabledProtocols A,B ,C, D configuration setSupportedProtocols testSetIncludedProtocols configure assertTrue equals Arrays configurable ",logback,0
Assert host1 testToString host3 somehost host2 somehost:8888 toString assertEquals ,httpcore,0
"getConfString <uri-template>file:/// conf DateUtils parseDateOozieTZ 2009-09-05T00:00Z 2009-09-01T00:00Z ${coord:latest(0)} ${coord:latest(-1)} ${coord:future(1, 30)} actualTime  TODO: Create the directory <dataset name=""a"" frequency=""1440"" initial-instance=""2009-01-01T00:00Z""  freq_timeunit=""MINUTE"" timezone=""UTC"" end_of_duration=""NONE""> testCreateLazyEvaluator getTestCaseDir createDir expr CoordELEvaluator  future testCaseDir nominalTime createLazyEvaluator /US/2009/1/30|file:///tmp/coord/US/2009/1/31</uris> /2009/01/02 XmlUtils 2009-01-02T00:00Z ${coord:latest(-1)} parseXml /${YEAR}/${MONTH}/${DAY}</uri-template></dataset></data-in> /2009/09/04 assertEquals /2009/09/05 eval <data-in name=""A"" dataset=""a""><uris>file:///  -1)); dataEvntXML evaluate 2009-09-01T01:00Z dEvent ",oozie,1
" <execution>LIFO</execution> </controls> <datasets>  pr /workflows/${YEAR}/${MONTH}/${DAY}</uri-template>  testDoneFlagCreation conf <data-in name=""A"" dataset=""local_a""> <instance>${coord:current(0)}</instance> </data-in>   </input-events>  getStatus Runtime actionStatus file:// getTestCaseDir UNIT_TESTING CoordinatorAction action missingDeps getRuntime waitFor mkdir -p  printStackTrace <coordinator-app name=""NAME"" frequency=""${coord:days(1)}"" start=""2009-02-01T01:00Z"" end=""2009-02-01T02:00Z"" timezone=""UTC""  <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  <action> <workflow> <app-path>hdfs:///tmp/workflows2/</app-path>  OozieClient jobId fail size </datasets> <input-events>   create done flag /consume_me /workflows/2009/02/01 File doneDir actions evaluate exec submitJob getMissingDependencies getActions appPath System writeToFile appXml <dataset name=""local_a"" frequency=""${coord:days(1)}"" initial-instance=""2009-02-01T01:00Z""  assertTrue get ..Missing deps= <done-flag>consume_me</done-flag> </dataset> xmlns=""uri:oozie:coordinator:0.1""> <controls> <timeout>10</timeout> <concurrency>2</concurrency>  timezone=""UTC""> <uri-template>file:// getCoordJob coordinator.xml ce set e status= </configuration> </workflow> </action> </coordinator-app> getTestUser equals ",oozie,1
actionNum testCoordActionGet _E _testGetActionByExternalId getId XDataTestCase addRecordToCoordJobTable CoordinatorJob createCoordAction coord-action-get.xml  Insert the action CoordinatorAction setSlaXml action insertRecordCoordAction job ,oozie,1
Args Assert testArgNotEmptyPass Stuff notEmpty assertSame stuff ,httpcore,0
checkCoordActions getId DateUtils getStatus parseDateOozieTZ addRecordToCoordJobTable 2009-03-06T10:00Z call CoordinatorJob 2009-03-06T09:58Z pauseTime startTime endTime job evaluate waitFor 2009-03-06T10:14Z testActionMaterWithPauseTime3 ,oozie,1
      <configuration>           <name>a</name>         </property> getActions           <value>A</value> SubWorkflowActionExecutor http://localhost:8080/oozie protoConf createBaseWorkflow getWorkflowClient assertNotNull W get action getBaseProtoConf testSubWorkflowConfCreation workflow <sub-workflow xmlns='uri:oozie:workflow:0.1'> oozieClient         <property> subWorkflow setConf       </configuration>       <app-path>hdfs://foo:9000/user/bar/workflow.xml</app-path> </sub-workflow> ,oozie,1
p2 testRerunFromFailNodes submit reader getJobInfo LocalOozie conf getStatus delete path jobId1 getTestCaseDir /workflow.xml file:// getPath create workflow.xml WorkflowJob waitFor  Skip succeeded nodes nnbase rerun-wf.xml wfClient toUri start assertEquals getFileSystem getClient reRun OozieClient IOUtils getTestUser copyCharStream setProperty getResourceAsReader true createConfiguration toString writer File evaluate getFsTestCaseDir base ,oozie,1
r2 getLastTaskTimeMillis setParallelPreprocessing  should be about 100%).  parallel delta  test it only if number there are more than 1 CPU cores are available availableProcessors: {} sequential preProcessing String Processing details:    sequential Runtime Assert assertTrue processAndMerge get create victim getRuntime info  warm up Context initExecutor availableProcessors prettyPrint debug LOG Resource start format resources ResourceType message getConfig %s  > %s + %s createResources stop watch preProcessingInParallelIsFaster parallel preProcessing createSlowPreProcessor sequentialExecution config r1 parallelExecution ,wroj4,1
testSocketIOWithTimeoutInterrupted source timeout sleep addThread assertTrue doWork  InterruptedIOException. interrupt pipe startThreads totalString read in ste ctx getMessage millis timeout left Pipe Total timeout mills is  thread Thread fail contains stop leftString Did not fail with interrupt TIMEOUT detail open ,hadoop,0
" 2015-01-02T00:45Z 2016-01-02T00:45Z 2014-01-02T00:45Z 2012-01-02T00:45Z ${coord:offset(7, ""HOUR"")} CoordELFunctions getTimeZone  ${coord:offset(-3, ""HOUR"")} DateUtils parseDateOozieTZ setFrequency ds 2015-01-02T00:45Z 2015-02-02T00:45Z 2014-12-02T00:45Z 2014-10-01T23:45Z  4.5 is not a valid integer 2010-01-02T00:01Z  Year  ${coord:offset(-26304, ""HOUR"")} ${coord:offset(1, ""MONTH"")}  ${coord:offset(-1096, ""DAY"")} testOffset TimeUnit ${coord:offset(-24, ""HOUR"")} ${coord:offset(-1, ""DAY"")} init 2015-01-02T00:01Z 2016-01-02T00:01Z 2014-01-02T00:01Z 2012-01-02T00:01Z  ${coord:offset(-3, ""MINUTE"")}  should have thrown an exception ${coord:offset(5, ""MINUTE"")} setInitInstance 2015-01-02T00:45Z  ${coord:offset(-36, ""MONTH"")}  its -1096 instead of -1095 because of DST (extra 1 day) 2015-01-02T00:01Z  ${coord:offset(-3, ""YEAR"")}  ${coord:offset(-3, ""DAY"")} 2015-01-01T20:01Z appInst ${coord:offset(0, ""MINUTE"")} ${coord:offset(1, ""MINUTE"")} ${coord:offset(-1, ""MINUTE"")} ${coord:offset(0, ""DAY"")} ${coord:offset(365, ""DAY"")} ${coord:offset(-365, ""DAY"")} fail setTimeUnit ${coord:offset(-43825, ""HOUR"")} contains eval ${coord:offset(0, ""MINUTE"")} ${coord:offset(525600, ""MINUTE"")} ${coord:offset(-525600, ""MINUTE"")} ${coord:offset(1, ""blah"")} evaluate  its -1578240 instead of -1576800 because of DST (extra 1440 minutes)  frequency ${coord:offset(-1440, ""MINUTE"")}  Hour Unable to evaluate ${coord:offset(1, ""YEAR"")} ${coord:offset(0, ""HOUR"")} ${coord:offset(1, ""HOUR"")} ${coord:offset(-1, ""HOUR"")}  ${coord:offset(-1578240, ""MINUTE"")} coord-action-create  Month ${coord:offset(0, ""MONTH"")} ${coord:offset(1, ""MONTH"")} ${coord:offset(-1, ""MONTH"")} evalAndWrap 2010-09-09T23:59Z  Day assertTrue ${coord:offset(1, ""HOUR"")} 2015-01-02T00:45Z 2015-01-02T00:46Z 2015-01-02T00:44Z 2015-01-02T00:42Z setTimeZone ${coord:offset(-10, ""DAY"")} expr  its -26304 instead of -26280 because of DST (extra 24 hours) eval of  ${coord:offset(0, ""DAY"")} ${coord:offset(1, ""DAY"")} ${coord:offset(-1, ""DAY"")} 2015-01-02T00:45Z 2015-01-03T00:45Z 2015-01-01T00:45Z 2014-12-30T00:45Z 2009-09-08T23:59Z 2009-10-09T23:59Z ${coord:offset(0, ""YEAR"")} ${coord:offset(1, ""YEAR"")} ${coord:offset(-1, ""YEAR"")} ${coord:offset(0, ""HOUR"")} ${coord:offset(8760, ""HOUR"")} ${coord:offset(-8760, ""HOUR"")} setNominalTime ${coord:offset(-2, ""HOUR"")} e 2015-01-02T04:01Z getMessage assertEquals  ""blah"" is not a valid TimeUnit America/Los_Angeles ${coord:offset(0, ""MONTH"")} ${coord:offset(12, ""MONTH"")} ${coord:offset(-12, ""MONTH"")}  Minute 2015-01-02T00:45Z 2015-01-02T01:45Z 2015-01-01T23:45Z 2015-01-01T21:45Z  ${coord:offset(-3, ""MONTH"")} ${coord:offset(4.5, ""blah"")} ",oozie,1
callable2 addRecordToCoordJobTableForWaiting callable3 callables callable1 TZ /2009/01/29/ getId DateUtils /2009/01/15/ parseDateOozieTZ asList queueservice coord-action-for-action-input-check.xml assertTrue 2009-02-01T23:59 getTestCaseDir get CoordinatorAction createDir startTime coord-job-for-action-input-check.xml addRecordToCoordActionTableForWaiting waitFor /2009/01/22/ c /2009/01/08/ services 2009-02-02T23:59 CoordinatorJob 1 2 testCoordActionInputCheckXCommandUniqueness 3 endTime action1 job Arrays evaluate queue ,oozie,1
"appendBit getSizeInBytes appendBits v assertEquals  1 bit was added in the vector, so 1 byte should be consumed.  We now have 17 bits, so 3 bytes should be consumed. testNumBytes ",zxing,0
<fs/> dir fs createContext -rwxr----- path rwx---r-- rwx-----x getFileStatus context rwx------ chmod FsPermission setPermission grandchild -rwxr----x -rwx-----x getPermission ae testChmodRecursive valueOf rwxr----- assertEquals getFileSystem rwxr----x -rwx------ mkdirs toString getFsTestCaseDir child -rwx---r-- ,oozie,1
de renderer getInternalServerErrorResult containsString isDiagnosticsEnabled getMethod getContextPath when instanceOf DiagnosticErrorRenderer out Assert  renderable in testResult is the DiagnosticError getRenderable  build context that will have HTML entites in key spots assertNotNull of context Boolean render Attribute with < > & entities getAttributes thenReturn doReturn buildAndRenderDiagnosticErrorWithHTMLEntities assertThat ImmutableMap / Attribute with &lt; &gt; &amp; entities Exception message with &lt; &gt; &amp; entities Mockito ninja build TEST-ATTR GET testResult spy Exception message with < > & entities ,ninja,0
"addTestService  Verify that stop() call sequence numbers for every service don't change. testCallSequence  Verify the start() call sequence numbers for every service assertInState STATE conf getCallSequenceNumber  Try to stop again. This should be a no-op. ServiceManager NUM_OF_SERVICES  verify they were all started  service, start() call sequence number should have been  toArray getServices  Reset the call sequence numbers  Verify the stop() call sequence numbers for every service init  Verify the init() call sequence numbers for every service  service, stop() call sequence number should have been   verify they were all stopped Number of registered services  start assertEquals services  service, init() call sequence number should have been   Initialise the composite service stop service For   Add services resetServices serviceManager  verify they were all inited ",hadoop,0
Cookie  de getName cookie thenReturn NinjaConstant returnCookie getOrDie assertEquals when getCookie result getValue getMaxAge build Results testClearLanguage clearLanguage builder ninjaProperties lang ok NINJA_TEST ,ninja,0
request getName tokenSigned TOKEN_VALIDITY_SEC setExpires sign secret when asList getInitParameterNames System secretProviderProps getCookies DummyAuthenticationHandler secretProvider management.operation.return verifyUnauthorized signer AuthenticatedURL http://foo:8080/bar getRequestURL init chain cookie AuthenticationFilter thenReturn testDoFilterAuthenticatedExpired StringSignerSecretProviderCreator WWW-Authenticate destroy token filter p getMockedServletContextWithStringSigner getInitParameter newStringSignerSecretProvider Mockito u response elements currentTimeMillis setProperty true mock toString containsHeader Arrays config ,hadoop,0
5 days 12 8 milliseconds 10.7 millisecond 1 hour d test 159 milli valueOf Duration assertEquals HOURS_CO 2.2 minutes getMilliseconds 12seconde DAYS_CO 12second 4.2 hours 15 millis 10 SECOnds 10.7 seconds 14 SECONDES 1 minute ,logback,0
X-Timestamp getName ROW_3 body put TABLE path Bytes MIMETYPE_BINARY assertTrue yield get client VALUE_3 testSingleCellGetPutBinary getCode foundTimestampHeader getHeaders getBody toBytes assertEquals / Thread deleteRow COLUMN_1 response equals header ,hadoop,1
 server checkCoordAction newHCatDependency2 newHCatDependency1 CoordELFunctions populateTable hcat:// addInitRecords  Test for two dependencies which are already in the hcat server / call default /dt=20120430;country=usa /dt=20120412;country=brazil CoordinatorAction actionId tablename newHCatDependency testUpdateCoordTableMultipleDepsV1 db table ,oozie,1
-version END_POINTS IS_SECURITY_ENABLED getContextURL oozieUrl HeaderTestingVersionServlet clear admin run assertEquals args call testServerBuildVersion -oozie SERVLET_CLASSES runTest ,oozie,1
 localhost Localhost verifyResolve  no lookup should occur host verifyInetAddress testResolverLoopback addr 127.0.0.1 ,hadoop,0
setUserInfo result http://stuff@localhost:80/stuff?param=stuff#fragment http://localhost:80/stuff?param=stuff#fragment Assert build testMutationRemoveUserInfo assertEquals uri ,httpcore,0
setClassesToBeExcluded cJob1 getTime pauseStartRunnable getCurrentDateafterIncrementingInMonths run getId DateUtils getStatus parseDateOozieTZ testPauseCoordinatorForBackwardSupport setPauseTime pauseTime assertNotNull get end currentDatePlusMonth Job waitFor init getConf start destroy assertEquals services XDataTestCase setAppNamespace execute addRecordToCoordJobTable coordJob2 Services CoordinatorJob coordJob1 excludedServices coordJobId1 SchemaService coordJobId2 setSystemProperty true StatusTransitService action1 action2 jpaService evaluate ,oozie,1
getStatus SubWorkflowActionExecutor protoConf createBaseWorkflow getWorkflowClient newConf xyz create action </app-path> workflow.xml write getBaseProtoConf waitFor workflow getFileSystem check childConf       </configuration> WorkflowAction       <propagate-configuration /> File evaluate <sub-workflow xmlns='uri:oozie:workflow:0.1' name='subwf'>       <app-path>       <configuration> getJobInfo           <name>a</name>         </property> getActions getExternalId fs APP1           <value>A</value> wf W get end WorkflowJob close abc set getConf oozieClient         <property> start defaultConf subWorkflowAppPath subWorkflow assertEquals JOB_TIMEOUT setConf toXmlString </sub-workflow> writer getFsTestCaseDir testConfigPropagation ,oozie,1
2009-02-02T23:59Z getTime 2009-02-01T23:59Z getId replaceFirst Should throw exception due to non-existent NN path. Therefore fail parseDateUTC caicc pathExists DateUtils localhost:5330 appPath testNonExistingNameNode coord assertTrue startTime nonExistDir localhost getCoordActionErrorCode loadState init /coord-input/2010/07/09/01/00 nonExist destroy assertEquals services -TestCoordActionInputCheckXCommand-C E0901 HadoopAccessorService inputDir addRecordToCoordJobTable call jobId @1 getCoordActionErrorMsg fail contains getTestUser not in Oozies whitelist setSystemProperty 0000000- whiteList toString endTime job  setting the test path with nonExistDir  Override the name node while list for testing purpose only. getFsTestCaseDir ,oozie,1
getJobTrackerUri getName <argument>A</argument> getAppPath testPerlScript _testSubmit PERL_SCRIPT_CONTENT  Create a sample perl script fs actionXml <shell> </file> create script.pl  Create a Sample Shell action using the perl script write close <job-tracker> getNameNodeUri <exec>perl</exec> # <capture-output/> </job-tracker> <argument>script.pl</argument> getFileSystem script <name-node> <env-var>my_var1=my_val1</env-var> </name-node> </shell> TESTING w <file> <argument>B</argument> toString ,oozie,1
"de accept-language doReturn language assertEquals when getHeader abstractContext assertNull context da, en-gb;q=0.8, en;q=0.7 getAcceptLanguage spy ",ninja,0
"getName  the candidate be in memory. getLog  Put into a different column family.  Should make it so I still get t10 delete put createTableDescriptor Bytes T20 T00 assertTrue htd COLUMNS  Ask for a value off the end of the file.  Should return t10. close add  in memory; make sure we get back t10 again. printStackTrace d e testGetClosestRowBefore3 getRow c0 c1 closeAndDelete flushcache createNewHRegion p T30  try finding ""010"" after flush T10 getClosestRowBefore r T31 T12 T11 equals region deleteColumn ",hadoop,1
fname stat  need to run long enough to fail: takes 25 to 35 seec on Mac LOG positionReadOption assertEquals testWriteAndRead testWriteReadSeq Summary status from test1: status=  rdBeginPos WR_NTIMES Assert filenameOption WR_CHUNK_SIZE useFCOption info ,hadoop,1
"getClass getName Time Not an array:  INFO new line  and {} rootNode assertTrue now outcome Datacenter problems dateText l4j quoted"" textValue e isTextual Log4Json testNestedException parse assertEntryEquals that box caught fire 3 years ago - timeStamp node toJson contains Not a string:  ti assertNodeContains No '-' in  toString isArray : ioe  and colon characters are in the string. ",hadoop,0
20080504T123456Z testLocation doTest LOCATION:Miami  BEGIN:VCALENDAR BEGIN:VEVENT  DTSTART:20080504T123456Z  END:VEVENT END:VCALENDAR Miami ,zxing,0
getJobTrackerUri getName <java> assertFalse </prepare> <delete path=' testPrepare getStatus fs delete createContext actionXml isSuccessful assertTrue <prepare> <mkdir path=' '/> context end mkdir waitFor <job-tracker> getData getNameNodeUri </java> ae </main-class> </job-tracker> runningJob getAction assertEquals getFileSystem check getExternalStatus <name-node> <main-class> </name-node> assertNull WorkflowAction mkdirs SUCCEEDED submitAction exists evaluate getFsTestCaseDir isComplete ,oozie,1
set writeLock getMethodName LOG release readLock assertFalse start run testname testWriteLock acquire tryLock remove readWriteLock get name competingWriteThread lock competingReadThread join locked Boolean ,hadoop,0
getClass getControllerClass NinjaConstant bootstrap when instanceOf NinjaMode router ninjaPropertiesImpl get getRouteFor boot conf.Routes initialized properly. We get back the class we defined by the route. Ninja Boostrap process picks up user supplied conf.Ninja definition thenReturn getInjector is assertThat / route Mockito GET com.example getInstance testInitializeWithAllUserSpecifiedThingsInShiftedConfDirectory spy Ninja Boostrap process picks up user supplied Guice module in conf.Module ,ninja,0
getName tokenSigned TOKEN_VALIDITY_SEC sign testGetTokenExpired when asList getInitParameterNames Assert secretProvider token not expired management.operation.return signer init cookie thenReturn StringSignerSecretProviderCreator destroy failed ex getInitParameter newStringSignerSecretProvider setProperty true mock Arrays request setExpires secret System secretProviderProps assertTrue getCookies DummyAuthenticationHandler AuthenticatedURL AuthenticationToken expired AuthenticationFilter getMessage assertEquals token filter p getMockedServletContextWithStringSigner Mockito u elements currentTimeMillis getToken toString config ,hadoop,0
testPutWithoutP toString run FROM TO assertAttributesChanged ,hadoop,0
fail Assert ae Java assert does not work. LOG Good! Java assert is on. testJavaAssert The AssertionError is expected. info ,hadoop,0
cluster testChangeIpcPort gotHeartbeat conf  Wait until we get a heartbeat from the new datanode  Restart datanodes firstUpdateAfterRestart sleep restartDataNodes get client addr localhost realIpcPort getDataNodes datanodeReport Never got a heartbeat from restarted datanode. assertEquals Thread fail getIpcPort build  Now make sure the reported IPC port is the correct one. report getNameNodePort getLastUpdate shutdown DatanodeReportType ,hadoop,1
leftPad rightPad buf abc longString toString assertEquals SpacePadder ,logback,0
EXEC_ORDER callable2 testQueueUniquenessWithDiffKeyInComposite callable3 callables callable1 c type queueSerial asList queueservice QueueUniquenessWithDiffKeyInComposite3 Services QueueUniquenessWithDiffKeyInComposite assertTrue QueueUniquenessWithDiffKeyInComposite2 QueueUniquenessWithDiffKeyInComposite1 get Arrays evaluate waitFor ,oozie,1
add QUALIFIER_1 value2 QUALIFIER_2 value1 ROW_3 delete put result getValue Bytes testDelete assertNull COLUMN_2 COLUMN_1 addFamily assertTrue assertNotNull get equals remoteTable VALUE_1 VALUE_2 deleteColumn ,hadoop,1
CONFIG_FOR_ENUM conf CONFIG2 bis appendProperty out CONFIG  prperties that were included from the first resource. SecondLevelInclude file CONFIG_MULTI_BYTE endInclude addResource get a b startInclude c d e  Add CONFIG as an InputStream resource. f g h endConfig startConfig assertEquals testIncludesFromInputStreamWhenResourceAdded tearDown  Add another resource to the conf. 1  second time the conf is parsed. 2 3 4 FirstLevelInclude fileResource  CONFIG includes CONFIG2. CONFIG2 includes CONFIG_FOR_ENUM  from all levels of includes. ,hadoop,0
getEncryptedKeyVersion getName be the same  Re-encrypting the same EEK with the same EK should be deterministic ek1 encryptionKey KeyProviderCryptoExtension Name of EEK should be encryption key name  Reencrypt ek1 ek3  Generate a new EEK ek2 rollNewVersion assertArrayEquals reencryptEncryptedKey decryptEncryptedKey assertNotNull  Decrypt the new EEK into an EK and check it generateEncryptedKey getEncryptionKeyName k1 k2 assertEquals kpExt getVersionName Expected encrypted key material ENCRYPTION_KEY_NAME getMaterial  Re-encrypting an EEK with the same version EK should be no-op fail  Decrypt EEK into an EK and check it Re-encrypted EEK should have different material  Roll the EK equals ek2a testReencryptEncryptedKey Arrays Version name of EEK should be EEK Length of encryption key material and EEK material should  ,hadoop,0
checkBadTranslation checkTranslation testAntiPatterns setRuleMechanism owen/owen/owen@FOO.COM checkBadName root/joe@FOO.COM owen@foo/bar.com KerberosName foo@ACME.COM ,hadoop,0
END_POINTS IS_SECURITY_ENABLED oozieUrl assertFalse run appPath testCoordReRunNeg3 get -config create SERVLET_CLASSES close runTest app MockCoordinatorEngineService coordinator.xml createConfigFile getContextURL assertEquals getFileSystem -rerun 0 args call -oozie assertNull mkdirs toString job getFsTestCaseDir ,oozie,1
_test isMainSuccessful actionDir hasOutputData assertFalse runningJob isMainDone getFileSystem fs hasIdSwap getIdSwapPath exit1 isSuccessful assertTrue LauncherMapper getErrorPath exists getOutputDataPath evaluate waitFor testExit1 getFsTestCaseDir isComplete ,oozie,1
"Cookie headers getServerAddress NINJA_FLASH=""success=This+is+a+flashed+success+-+with+placeholder%3A+PLACEHOLDER"";Path=/ getFirstHeader testThatStaticAssetsDoNotSetNinjaCookies  ... and static assets should not set any flash information ninjaTestBrowser newHashMap assertEquals  Some empty headers for now... put makeRequestAndGetResponse Maps  /redirect will send a location: redirect in the headers assets/files/test_for_mimetypes.dxf Set-Cookie httpResponse ",ninja,1
"thenReturn invoke when param1 enumCsvParamValidationShouldWork enumCsvParam assertTrue context create verify White,Black mockController validation hasViolation getParameter ",ninja,0
reader conf coord-dataset-initial-instance.xml getStatus appPath getJob earlier than the default initial instance sc getErrorCode file:// getTestCaseDir UNIT_TESTING getPath Job coordinator.xml set Unexpected failure -  getMessage assertEquals call OozieClient fail testSubmitDatasetInitialInstance IOUtils contains Expected to catch errors due to invalid dataset initial instance getTestUser cx copyCharStream getResourceAsReader writer ErrorCode File ,oozie,1
addRecordToWfActionTable getId WorkflowInstance getStatus  update the list for doing bulk writes coordJob wfJob addRecordToWfJobTable assertNotNull get action WorkflowJob updateList add getStatusStr  update the status  check for expected status after running bulkUpdateJPA RUNNING assertEquals execute addRecordToCoordJobTable setStatus CoordinatorJob 1 Services setUpdateList WorkflowAction bulkUpdateCmd SUCCEEDED testUpdates action2 jpaService ,oozie,1
A  check consistency in get of old and new keys B fileResource1 C D conf testDeprecation  the corresponding new keys. CONFIG2 M appendProperty N out CONFIG P Q  set new keys to different values addDeprecationToConfiguration R  load an old key and a new key. addResource get  load an old key with multiple new-key mappings X Y Z  set old key and then get new key(s). a b c set d endConfig startConfig assertEquals  load the old/new keys corresponding to the keys loaded before. m n p  get old key  set new key y z fileResource ,hadoop,0
stringWriter session equalTo testThatItWorks assertThat execute getAuthenticityToken environment Mockito templateEngineFreemarkerAuthenticityTokenDirective 12345 verify toString parameters loopVars ,ninja,0
"cluster  stop a datanode, it should have least recover. testClientTriggeredLeaseRecovery conf dir fs System sleep  let the slow writer writes a few more seconds /wrwelkj Wait a few seconds REPLICATION file getLen closeStream interrupt getFileStatus join  let writers get started Verify the file stopDataNode DFSConfigKeys read slowwriters in start j assertEquals getFileSystem nextInt AppendTestUtil : length= setInt Thread IOUtils build numDataNodes  Verify the file shutdown open ",hadoop,1
"AvroTestUtil {""type"":""string"",""java-class"":""org.apache.hadoop.io.Text""} testReflect foo testAvroReflect ",hadoop,0
"bee =aaa, ,bbb BundleEngine  incorrect status: assertEquals  no eq sign in token:  unparseable time value: xx=yy=zz fail BundleEngineException expected. winniethepooh =foo getErrorCode BulkResponseImpl parseBulkFilter  incorrect key=value pair syntax: toString  one of the values is a whitespace: ErrorCode  filter does not contain ""BulkResponseImpl.BULK_FILTER_BUNDLE_NAME"" field: testParseBulkFilterNegative =blah-blah ",oozie,1
"testFixBlockCompress compressBlocksize reader MapFile keyClass conf dir suffix fs delete cleanupWithLogger .orig fix With MapFile.fix-ed index, could not get entries #  FileSystem get value close TEST_DIR key io.seqfile.compress.blocksize val indexLessMapFile indexInterval length index assertEquals setInt No of valid MapFile entries wrong IOUtils setIndexInterval size rename getLocal value- exists testFixBlockCompress.mapfile notFound writer valueClass compression noBlocks CompressionType append ",hadoop,0
path NetUtils create testCanonicalUriWithPath toString assertEquals uri URI getCanonicalUri /path ,hadoop,0
"filepaths cluster  write something to file3  write something to file2  write something to file1 conf dir out2  Check to see if opening a non-existent file triggers a FNF out3 path /wrwelkj readFully out1 FileSystem  close create Did not get a FileNotFoundException for non-existing write  passed previous grace period, should still running setGraceSleepPeriod in  create file2  create file3  passed grace period getFileSystem  create file1  write something dfs numDataNodes getNameNodePort millis shutdown testDFSClient  is listening on. In this case, it is localhost. assertFalse hdfs://127.0.0.1: fs File should not exist for test. System filepathstring out sleep getTestConfiguration writeLong isRunning assertTrue  within grace period get grace /test/ipAddress/file  close file3 close  close file2  close file1 toUri assertEquals uri Thread buf readLong build  open and check the file currentTimeMillis  create a file exists /test/LeaseChecker/foo  file. open ",hadoop,1
pushPromise play PushObserver  play it back squareup.com HTTP_20_DRAFT_09  verify the peer received what was expected TYPE_RST_STREAM asList connectionBuilder acceptFrame peer https takeFrame rstStream synReply setVariantAndClient assertEquals /cached  RST_STREAM pushPromiseStreamsAutomaticallyCancel 200 sendFrame Header build GET  write the mocking script CANCEL pushObserver Arrays ,okhttp,1
"set range conf assertEquals first =  34- second =  third =  System second -100 third getRange 4-6,9-10,27 testIntegerRanges first isIncluded ",hadoop,0
getRecoveryPath chmod1 chmod2 source getStatus createContext getPath context getFileStatus action mkdir getPermission ae format <chmod path=''{4}'' permissions=''-rwxrwxrwx''/> getFileSystem check rwxrwx--- WorkflowAction mkdirs <fs><mkdir path=''{0}''/> <chmod path=''{5}'' permissions=''-rwxrwx---'' dir-files=''false''/> newFile2 newFile1 assertFalse testSubmit <touchz path=''{7}''/> child2 fs delete child1 actionXml assertTrue <move source=''{2}'' target=''{3}''/> </fs> end OK getData MessageFormat <delete path=''{1}''/> toUri start getAction assertEquals getExternalStatus rwxrwxrwx target assertNull <touchz path=''{6}''/> assertNotSame exists toString createNewFile getFsTestCaseDir ,oozie,1
hasFieldViolation thenReturn invoke doubleParam doubleValidationShouldWork when param1 assertTrue context create verify mockController validation blah getParameter ,ninja,0
"test8 .zip NO_RESTART defaultTest %d{yyyy-MM-dd, aux}/test8 FILE_OPTION_SET withMissingTargetDirWithZipCompression ",logback,0
 p fail parse empty ,logback,0
bundleJobGetExecutor addRecordToBundleActionTable getTime addRecordToBundleJobTableWithPausedTime assertFalse testBundleRerunInPausedWithError getId getStatus isPending pauseTime assertNotNull get curr Job init false destroy assertEquals services execute addRecordToCoordJobTable call getPauseTime Services CoordinatorJob setSystemProperty StatusTransitService action1 job action2 jpaService ,oozie,1
scriptExecutor session  Given Eq SELECT * FROM entity_counter WHERE id =  delete  When of where id executeScriptTemplate actual RandomUtils manager incr allColumns_FromBaseTable one should_dsl_delete nextLong assertThat execute ImmutableMap EntityWithCounterColumn/insert_single_row.cql  Then isNull Long dsl ,achilles,1
testSingleCellGetPutXML ROW_1 assertEquals TABLE getValueXML checkValueXML deleteRow COLUMN_1 response VALUE_1 putValueXML getCode VALUE_2 ,hadoop,1
"2009-09-11T23:59Z CoordELFunctions ${coord:future(4, 20)} conf coord-action-start  TODO:Set hadoop properties ds Should fail for negative instance value evalAndWrap /2009/09/10 /2009/09/11 getTestCaseDir file:// setUriTemplate createDir expr /${YEAR}/${MONTH}/${DAY} init res coord-job-submit-instances setVariable assertEquals ${coord:future(1, 20)} testDir testFuture fail eval ${coord:future(-1, 3)} ",oozie,1
/newfile1 getName <fs/> FS006 FS007 source dest fs createContext delete assertTrue getErrorCode /newfile context getPath complexTarget ://foo/ testMove move getScheme ae toUri assertEquals getFileSystem target / fail ex /a/b mkdirs destPath exists createNewFile getFsTestCaseDir ,oozie,1
getContentEncoding abc ContentType byteChannel StandardCharsets assertFalse assertEquals getContentLength produce testBinaryContent Assert isOpen producer getContentType toString dump streamChannel ,httpcore,0
setFloat configuration DOUBLE_DELTA assertEquals getFloat value testFloat ,hadoop,0
"The -x option excludes snapshots from being calculated.   storage types.  getDescription Count.getDescription The -u option shows the quota and   otherwise it will be ignored.   check the correct description is returned it displays the quota and usage for the specified types.   types that support quota. The list of possible storage  The -h option shows file sizes in human readable format.  DIR_COUNT FILE_COUNT CONTENT_SIZE PATHNAME  It can also pass the value '', 'all' or 'ALL' to specify all the  the usage against the quota without the detailed content summary. The -t option displays quota by storage types.  Count the number of directories, files and bytes under the paths  types(case insensitive):  actual The -v option displays a header line.  that match the specified file pattern.  The output columns are:  expected count assertEquals QUOTA REM_QUOTA SPACE_QUOTA REM_SPACE_QUOTA  It should be used with -q or -u option,  Otherwise, it displays the quota and usage for all the storage   The -e option shows the erasure coding policy. If a comma-separated list of storage types is given after the -t option,   or, with the -q option:  ram_disk, ssd, disk and archive.        DIR_COUNT FILE_COUNT CONTENT_SIZE PATHNAME  ",hadoop,0
getDynamicEntry assertHeaderEquals no-cache dynamicTable custom-value asList assertArrayEquals getCurrentSize encodeHeaders Assert :scheme createByteArray https cache-control :authority testRequestEncodingWithoutHuffmanRFC7541Examples custom-key StandardCharsets clear assertEquals headers2 headers3 encoder www.example.com headers1 / expected1 buf expected3 expected2 :method GET toByteArray http :path /index.html Arrays dynamicLength ,httpcore,0
makeGraphite argument MsInfo isConnected testFailureAndPutMetrics graphite when result putMetrics record host verify forClass foo1 foo2 null.all.Context.Context=all.Hostname=host.foo1 1.25 10  write close  reset mock and try again mockGraphite all add  throw exception when first try null.all.Context.Context=all.Hostname=host.foo2 2.25 10  ArgumentCaptor sink anyString thenReturn capture assertEquals IO exception tags makeMetric Whitebox getValue doThrow equals reset metrics setInternalState ,hadoop,0
10.119.103.112 is not in the list 10.221.104.1 is in the list assertFalse assertTrue ips.txt 10.221.104.0 is in the list 10.221.102.1 is not in the list 10.119.103.113 is in the list 10.221.102.0 is not in the list ipList isIn 10.221.103.255 is not in the list testSubnetsAndIPs 10.119.103.112 10.119.103.113 10.221.102.0/23 10.221.104.1 10.221.102.1 ips 10.221.103.1 10.221.103.255 10.221.104.0 10.221.102.0 createFileWithEntries 10.221.103.1 is not in the list ,hadoop,0
" failed ProxyUsers rsrc gr3,gr4,gr5 run when first auth for   superuser can proxy for this group super_user getUserName authorize gr2 thenReturn  so the server side will pick it up gr1 gr4 addNewConfigResource testRefreshSuperUserGroupsConfiguration gr3  should've succeeded:  fail  keys in conf mock getProxySuperuserIpConfKey 127.0.0.1 refreshSuperUserGroupsConfiguration getProxySuperuserGroupConfKey userKeyHosts getLocalizedMessage  super user getGroupNames admin ugi1 L ugi2  should've failed   succeeded System second auth for  userL2 userL1 suUgi getShortUserName user1 GROUP_NAMES1 user2 GROUP_NAMES2 set e  set groups for users getRealUser SUPER_USER args  expected testGroupMappingRefresh_rsrc.xml auth for  -refreshSuperUserGroupsConfiguration  check before config userKeyGroups ",hadoop,1
testRootDir set getConf run DUMMYAUTH  Passing Dummy such that it should through IAE    UGI params should take effect when we pass.   CommonConfigurationKeysPublic testListWithUGI -ls fsShell lsArgv toString ,hadoop,0
Optional assertFalse context dateParamWithOptional create verify hasViolations invoke customDateFormatParamWithOptionalShouldHandleEmpty mockController validation empty ,ninja,0
conn setRequestMethod IS_SECURITY_ENABLED assertTrue get json content-type /v1/admin/* Collections runTest getBuildInfo JsonTags RestConstants getProperty openConnection testVersion HttpServletResponse assertEquals parse getInputStream url JSONValue call getHeaderField GET getResponseCode BuildInfo createURL startsWith ,oozie,1
cluster DFSConfigKeys seed NUM_OF_DATANODES writeFile1 expected writeFile2 BLOCK_SIZE writeFile3 conf getFileSystem testFSOutputSummer setInt nextBytes rand setLong file build numDataNodes fileSys close BYTES_PER_CHECKSUM shutdown try.dat ,hadoop,1
actionNum getId CoordUtils assertEquals addRecordToCoordActionTable addRecordToCoordJobTable Integer getCoordActionsFromIds  check for the expected size of actions list CoordinatorJob jobId coord-action-get.xml  check for the expected action coordActions size  test retrieval of single action (action 1) get CoordinatorAction toString action1 job testGetCoordActionsFromIds ,oozie,1
"jcoord BUNDLE-TEST /v1/jobs parseDateUTC DateUtils actionStatus=FAILED;startcreatedtime=2012-07-21T00:00Z testSingleRecord split FAILED array assertNotNull get Coord1 CREATE_TIME runTest jbundle JsonTags jaction RUNNING ;coordinators=Coord1; assertEquals toGMTString call size ,  bundleName toString _requestToServer bulkRequest bundle= ",oozie,1
cluster Adding 3rd region server Adding 3rd region server. Test table should have 20 regions Adding 4th region server conf waitOnRegionServer assertRegionsAreBalanced Adding 2nd region server. Killing the 3rd region server. table stopRegionServer debug  add a region server - total of 3 test LOG assertEquals  add a region server - total of 2  kill a region server - total of 2  verify that the region assignments are balanced to start out  start two more region servers - total of 4 Adding  startRegionServer th region server getStartKeys testRebalancing ,hadoop,1
appendBits  010 1010  1111 1110  101 0101 xor assertEquals v1 v2 getUnsignedInt testXOR2 ,zxing,0
"getJobTrackerUri test3-acl </name-node> <configuration> <java> </configuration> getAppPath getActions conf setupActionConf createBaseHadoopConf  CASE: launcher specific ACLs configured, as well as MR job ACLs configured. Check that NO overriding with defaults actionXml wfBean <property><name>oozie.launcher.mapreduce.job.acl-modify-job</name><value>M</value></property> addRecordToWfJobTable get context action JavaActionExecutor testACLDefaults_explicitLauncherAndActionSettings <job-tracker> getNameNodeUri eActionXml <property><name>oozie.launcher.mapreduce.job.acl-view-job</name><value>V</value></property> actionConf </java> ae XmlUtils parseXml </job-tracker> createLauncherConf <main-class>MAIN-CLASS</main-class> getFileSystem setType <name-node> getType <property><name>mapreduce.job.acl-view-job</name><value>VIEWER</value></property> <property><name>mapreduce.job.acl-modify-job</name><value>MODIFIER</value></property> assertNotSame ",oozie,1
"getClass reduceTask getName conf getStatus getAttempts iterator Assert sendFetchFailure  wait for map Task state move back to RUNNING JobState  send 3 fetch failures from reduce to trigger map re execution reduceAttempt events  send done to reduce app  the map is not in a SUCCEEDED state after restart of AM getEventHandler Num completion events not correct getID handle it size stop TaskAttemptState  send the done signal to the map attempt MRJobConfig job next testFetchFailureWithRecovery getTaskAttemptCompletionEvents submit values  wait for reduce to start running TaskAttemptCompletionEventStatus  rerun  wait for map success waitForState Num tasks not correct TaskAttemptEventType  all maps would be running mapAttempt1 runCount mapTask  Crash the app again.  sequential, single-task-attempt approach in uber-AM, so disable: assertEquals Event status not correct getTasks TaskState getContext setBoolean  wait for Task state move to RUNNING ",hadoop,1
testCoordReRunNeg1 END_POINTS IS_SECURITY_ENABLED -action oozieUrl assertFalse 2009-12-15T01:00Z run appPath get create SERVLET_CLASSES close runTest app MockCoordinatorEngineService coordinator.xml getContextURL MockDagEngineService assertEquals getFileSystem -rerun args call 1 -date -oozie assertNull mkdirs job getFsTestCaseDir ,oozie,1
parseBody abstractContext assertNull doReturn context testParseBodyWithUnkownContentTypeWorks spy when getRequestContentType o ,ninja,0
valid1 valid2 assertEquals testValidTagsEqual ,hadoop,0
"init JMSTopicService set getConf =coord getMessage destroy  = workflow, services setupServicesForTopic Expected Service Exception getValue fail se contains testIncorrectConfigurationJobType assertTrue Incorrect job type InvalidJobType ",oozie,1
setClassesToBeExcluded assertFalse getCurrentDateafterIncrementingInMonths getId run DateUtils getStatus isPending addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob assertNotNull get CoordinatorAction end  Keeping wait time to 20s to ensure status is updated currentDatePlusMonth waitFor init getConf testCoordStatusTransitServiceSuspendedWithError false start destroy assertEquals services XDataTestCase execute addRecordToCoordJobTable Services CoordinatorJob jobId runnable coord-action-get.xml excludedServices setSystemProperty StatusTransitService job jpaService evaluate ,oozie,1
verifyZeroInteractions  Object under test conf  Origin is not specified for same origin requests when put filterConfig getHeader mockChain doFilter verify example.com mockRes init mockReq thenReturn  Objects to verify interactions based on request  Setup the configuration settings of the server CrossOriginFilter filter Mockito GET mock Disallowed-Header testDisallowedHeader ,hadoop,0
END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL oozieUrl testJobStatus getJobInfo MockDagEngineService assertEquals getId wc wf call 1 SERVLET_CLASSES runTest ,oozie,1
getJobTrackerUri oozie.shell.exec <exec>SCRIPT</exec> b=B conf  Verify the class setupActionConf protoConf createBaseWorkflow context action testSetupMethods <job-tracker> add ae pig-action parseXml </job-tracker>  Verify the launcher jar filename <name-node> </name-node> 2 SCRIPT shell getType getClassesForLauncher a=A  ActionExcutor type is 'shell' classes oozie.shell.args.1 getActions oozie.shell.args.0 createBaseHadoopConf wf actionXml <shell> get getNameNodeUri set XmlUtils WorkflowAppService <argument>a=A</argument> getLauncherClasses assertEquals shell-launcher.jar setType getLauncherJarName </shell> Services oozie.shell.args.size getTestUser addAll <argument>b=B</argument> getFsTestCaseDir ,oozie,1
exception getForbiddenResult getLocalizedMessage NinjaConstant equalTo when Result result getRenderable assertTrue verify not important getTemplate ArgumentMatchers thenReturn getWithDefault getMessage eq  real test: assertThat any ninjaDefault getStatusCode contextImpl testGetForbiddenRequest messages ninjaProperties ,ninja,0
"index  router.GET().route(""/user/{id}/{email}/userDashboard"").with(ApplicationController.class, ""userDashboard""); assertEquals  this looks strange, but is expected: / testReverseRoutingWithoutMap router userDashboard startServer  TEST 1: a simple route without replacements: generatedReverseRoute getReverseRoute /user/{id}/{email}/userDashboard ",ninja,1
renderThumbnail testThumbnail YUV source COLS ROWS assertArrayEquals ,zxing,0
"cluster 0.0.0.0:0 conf dn getSelfAddr unset dfs.datanode.ipc.address System waitActive  assert that default self socket address is 127.0.0.1 DN Self Socket Addr ==  assertTrue assertNotNull get StartupOption /0.0.0.0: stopDataNode -------------------------------------------------------------------------      * By default, the DataNode socket address should be localhost (127.0.0.1).      *------------------------------------------------------------------------ getDataNodes /127.0.0.1: startDataNodes set -------------------------------------------------------------------------      * Shut down the datanodes, reconfigure, and bring them back up.      * Even if told to use the configuration properties for dfs.datanode,      * MiniDFSCluster.startDataNodes() should use localhost as the default if      * the dfs.datanode properties are not set.      *------------------------------------------------------------------------  assert that default self socket address is 0.0.0.0 dnp dfs.datanode.address dns -------------------------------------------------------------------------      * Shut down the datanodes, reconfigure, and bring them back up.      * This time, modify the dfs.datanode properties and make sure that they      * are used to configure sockets by MiniDFSCluster.startDataNodes().      *------------------------------------------------------------------------ Should have been able to stop simulated datanode size build testDFSAddressConfig toString selfSocketAddr dfs.datanode.http.address shutdown startsWith ",hadoop,1
cluster mockResourceChecker hasAvailableDiskSpace getName getAllStackTraces testCheckThatNameNodeResourceMonitorIsRunning  Make sure the NNRM thread has a chance to run. assertFalse Thread[ conf NN should not presently be in safe mode when System waitActive sleep assertTrue keySet nameDir startMillis DFSConfigKeys set getAbsolutePath thenReturn isInSafeMode getNameNode Thread NN resource monitor should be running setLong isNameNodeMonitorRunning runningThreads NN should be in safe mode after resources crossed threshold build Mockito numDataNodes currentTimeMillis name mock toString shutdown runningThread getNamesystem startsWith ,hadoop,1
regex toRegex context fnp foo-\d{4}\.\d{2}\.\d{2}-\d+.txt asRegex assertEquals foo-\d{4}\.\d{2}\.\d{2}T-\d+.txt foo-%d{yyyy.MM.dd}-%i.txt foo-%d{yyyy.MM.dd'T'}-%i.txt ,logback,0
host5     host4 host1 getHostName host3 somehost host2 assertEquals testConstructor fail Assert getPort http https getSchemeName IllegalArgumentException should have been thrown ,httpcore,0
user11 createResource conf isContinuousSchedulingEnabled nodeEvent1  check consumption Assert getContinuousSchedulingSleepMs resourceManager add  send application request handle testContinuousScheduling  available resource node1 getMemory  Add one node allocate createConfiguration Resources ResourceRequest 127.0.0.1 getClusterCapacity request reinitialize newNodeInfo addApplication Continuous scheduling should be enabled. createAppAttemptId fs getRMContext sleep assertTrue get FairSchedulerConfiguration getCurrentConsumption getConf assertEquals consumption  at least one pass appAttemptId Thread  set continuous scheduling enabled MockNodes getVirtualCores createResourceRequest ask queue11 setBoolean ,hadoop,1
bind createInjector start equalTo MockService configure injector assertThat serviceShouldNotBeStartedIfExplicitlyBoundAndNotSingleton ,ninja,0
"testRootDir http:// conn ProxyUsers  userA cannot impersonate userC, it fails. servlet testAuthenticationWithProxyUser conf hadoop.proxyuser.userA.groups  Create http server to test.  setup logs dir Assert jmx serverURL groupC getSpengoConf logs groupB groupA UserGroupInformation signer createUserForTesting openConnection stacks *  setup auth token for userA / stop setProperty getEncryptedAuthToken userA groupA spengoConf  userA impersonates userB, it's allowed. hadoop.log.dir  Setup user group getSignerToEncrypt refreshSuperUserGroupsConfiguration  only userA has the access. setACL  userB cannot access these servlets. System  Make userA impersonate users in groupB authUrl getHostPortString getConnectorAddress HttpURLConnection logLevel  Get signer to encrypt token getCommonBuilder  Setup token for userB hadoop.proxyuser.userA.hosts set getAbsolutePath  The default authenticator is kerberos. start httpServer assertEquals ?doAs=userC ?doAs=userB setConf token userA userB NetUtils build getResponseCode userC ",hadoop,0
skip getBytes testFailureOutOfOrderKeys keyA fail closeOutput Assert Error on handling out of order keys. valueA valueM writer keyM append ,hadoop,0
getJobTrackerUri getName <java> testSimpestSleSubmitOK getStatus createContext actionXml isSuccessful assertTrue context end waitFor <job-tracker> getData getNameNodeUri </java> ae </main-class> </job-tracker> runningJob getAction assertEquals check getExternalStatus <name-node> <main-class> </name-node> assertNull WorkflowAction SUCCEEDED submitAction evaluate isComplete ,oozie,1
next getEndpoints awaitShutdown getStatus ioReactor listen iterator endpoint Assert IOReactorStatus assertNotNull get getAddress close TimeValue endpoint1 endpoint2 ofSeconds endpoints start assertEquals future1 future2 getPort size port testEndpointUpAndDown CloseMode ,httpcore,0
generated  force checks -1 timeout probes intercept testInterceptAwaitLambdaDiagnostics await ,hadoop,0
addressFactory addressHost4 HOST_LIST addressMockHost4 addressMockHost5 assertFalse  test for exclusion with an unknown IP  test for inclusion with an known IP when addressHost1 assertTrue StringUtils getByName getTrimmedStringCollection 1.2.3.1 ml host5 testHostNamesReverserIpMatch host4 host1 1.2.3.4 getCanonicalHostName thenReturn 1.2.3.5 includes  create MachineList with a list of of Hostnames Mockito mock InetAddress ,hadoop,0
_testAuthentication auth AuthenticationFilter AuthenticatorTestCase setProperty true simple PseudoAuthenticationHandler setAuthenticationHandlerConfig testFallbacktoPseudoAuthenticatorAnonymous props ,hadoop,0
Unexpected Exception def addNode printStackTrace testWfNoForkJoin e one three two fail invokeForkJoin parser name dummyConf end       * 1->ok->2      * 2->ok->end       ,oozie,1
testDecision ActionExecutorException <case to='a'>true</case> <case to='b'>true</case> getStatus <case to='a'>false</case> getErrorCode <case to='c'>false</case> get action end init <default to='d'/></switch> a b decision d <switch xmlns='uri:oozie:workflow:0.1'> start destroy assertEquals <case to='b'>false</case> <wrong> getExternalStatus setConf Services fail ex getType WorkflowAction DecisionActionExecutor getErrorType ,oozie,1
Context setResourceWatcherUpdatePeriod tryAsyncCheck thenReturn assertFalse ResourceType shouldNotWatchForChangeUnlessCheckCompleted eq when getConfig GROUP_NAME wasCheckedForChange Mockito assertTrue get mockResourceWatcher victim key ,wroj4,1
"next shutdownDfs getLog scan We don't want anything more, we should be failing testRaceBetweenClientAndTimeout HConstants addContent closeAndDelete createNewHRegion fail r  ok! getTableDesc REGION_INFO getScanner close results ",hadoop,1
pausetime=null ;concurrency=200 getTime checkCoordJobs ;pausetime=;concurrency=200 Running Test endtime=2012-12-20T05:00;concurrency=-200 endtime=2012-12-20T05:00Z;concurrency=2ac DateUtils System parseDateOozieTZ concurrency=-1 a=1;b=-200 pauseTime getErrorCode endtime=2012-12-20T05:00Z;concurrency=-200 pausetime=2009-02-01T01:03Z Error code should be E1015. endtime=2012-12-20T05:00Z printStackTrace pausetime=2009-02-01T01:08Z Should not reach here. endtime= endtime=1900-12-20T05:00Z Exception thrown  convertDateToString Invalid date addRecordToJobTable call jobId fail ex ;concurrency=200;pausetime= testCoordChangeXCommand 2012-12-20T05:00Z 0000000- changeValue endTime ErrorCode -testCoordChangeXCommand-C pausetime=1900-12-20T05:00Z ,oozie,1
" /2009/01/01/ CoordELFunctions TZ action-actual-time="" DateUtils  Sleep for sometime as it gets requeued with 10ms delay on failure to acquire write lock ${coord:latestRange(-3,0)}  before and after action creation time parseDateOozieTZ  Datasets should be picked up based on current time and not action creation/actual time. Actual:  file:// getTestCaseDir CoordinatorAction action setCreatedTime indexOf /2009/01/08/ resolvedList execute setActionXml /2009/03/05 jobId contains CoordCommandUtils /2009/02/19/ job getMissingDependencies checkCoordAction Expected:  setPushMissingDependencies getTime getId 2009-02-16T23:59 </uris> /2009/02/05 replaceAll System substring actionXML sleep /2009/02/12/ <uris> testActionInputCheckLatestCurrentTimeWithPushDependency assertTrue get createDir startTime  Update action creation time ""> latest 2009-02-15T23:59 action-actual-time=""2009-02-15T01:00 /2009/03/05/ /2009/01/22/  Run input check after making push dependencies available /2009/02/12 getConf action-actual-time="".*""> /2009/02/19 assertEquals -TestCoordActionInputCheckXCommand-C addRecordToCoordJobTable Thread call Services @1 pushMissingDependency getActionXml  Run input check after making latest available getPushMissingDependencies 0000000- endTime 2009-02-15T01:00 actionCreationTime jpaService setBoolean  Set push missing dependency ",oozie,1
handler Assert getType testType assertEquals getExpectedType ,hadoop,0
setCharacterEncoding testGetInputStreamEnforcingOfCorrectEncoding init  this proofs that the encoding has been set: servletContext anyString context verify httpServletRequest httpServletResponse getInputStream ,ninja,0
"server serverThreads run Executors  Start the client threads when they are all ready System a:b c:d  /echo?a=b&c=d  which is less or equal than the max =  clientThreads assertTrue executor ready await countDown readOutput MAX_THREADS getThreadPool newFixedThreadPool  Run many clients to make server reach its maximum number of threads start assertEquals Number of threads =  execute baseUrl More threads are started than expected, Server Threads count:  testMaxThreads getThreads ",hadoop,0
PATH request server /custom/* getMethod put CUSTOM_PATH Assert requestHandler defaultURI localhost adapter method start thrown method not expected assertEquals handle responseExpectations execute target registerHandler TestingFramework withLiveServerCustomRequestHandler getPort t junk METHOD toString ,httpcore,0
e assertFalse getProperties getMessage conf isReloaded testReloadNotQuiet Should not have got here fail contains assertTrue addResource toString setQuietMode not found properties not-a-valid-resource ,hadoop,0
x(123)y testEscapeBothParentheses plb context setContext start setPattern assertEquals getPatternLayoutBase doLayout x\(%OTT\)y ,logback,0
credential1 has been successfully deleted. credential1 run delete testPromptForCredential Password match failed for credential1. password passwords passwordError create jceksProvider -f p@ssw0rd add assertOutputContains assertEquals check setConf rc setPasswordReader -provider shell args1 args2 p@ssw0rderr credential1 has been successfully created. args3 Password match success for credential1. ,hadoop,0
date dsl_delete_with_schema scriptExecutor tableNameFor session  Given Eq delete SELECT * FROM simple WHERE id =  tableName provider  When of where id row table SimpleEntity/create_simple_mirror_table.cql executeScriptTemplate allColumns_From RandomUtils manager one should_dsl_delete_with_schema_name nextLong assertThat execute ImmutableMap SimpleEntity/insert_single_row.cql keyspaceFor  Then isNull Long buildDateKey dsl DEFAULT_CASSANDRA_EMBEDDED_KEYSPACE_NAME ,achilles,1
listAppender addAppender stop doAppend start smoke verify asyncAppenderBase ,logback,0
init actionNum _testGetForInfoAllActions testGetActionAllColumns destroy getId services CoordActionGetForInfoJPAExecutor addRecordToCoordJobTable resourceXmlName CoordinatorJob createCoordAction slaXml coord-action-get.xml setSystemProperty true CoordinatorAction setSlaXml action insertRecordCoordAction job ,oozie,1
request conn resolve getRequest responseCaptor sendResponseHeader error when receiveRequestHeader requestHandler Assert httpservice assertNotNull context create forClass verify getCode close process ArgumentCaptor HttpStatus thenReturn testMethodNotSupported capture handle assertEquals sendResponseEntity assertSame getEntity whatever / getValue doThrow responseFactory Mockito response HttpCoreContext newHttpResponse httprocessor handleRequest handlerResolver ,httpcore,0
getTime pausetime= getId Error code should be E1022 DateUtils addRecordToCoordActionTable pauseTime getErrorCode CoordinatorAction end  4 hrs e Should not reach here. start  2 hrs call pauseTimeChangeStr CoordinatorJob fail coord-action-get.xml testCoordActionDelete formatDateOozieTZ addRecordToCoordJobTableForPauseTimeTest ErrorCode job  Checks that RUNNING coord action is not deleted ,oozie,1
"play http://google.com/ server Path=""/path"";  getName getDiscard Domain="" android 80,443, Set-Cookie2: a=""android"";  ACCEPT_ORIGINAL_SERVER cookies getMaxAge get getCookies /path/foo getPath getComment getPortlist cookieManager getCookieStore getCommentURL /path getVersion a addHeader cookie testQuotedAttributeValues "";  Comment=""this cookie is delicious"";  assertEquals setDefault Secure;  getDomain enqueue getValue Discard;  getPort size getCookieDomain this cookie is delicious Max-Age=""60"";  CommentURL=""http://google.com/"";  Version=""1"" CookieHandler Port=""80,443, getSecure ",okhttp,1
"A a set XmlUtils parseXml <parameters></parameters></root> conf assertEquals <root xmlns=""uri:oozie:workflow:0.4""></root> testVerifyParametersEmpty size get ParameterVerifier verifyParameters <root xmlns=""uri:oozie:workflow:0.4""> ",oozie,1
getBytesTransferred read dst StandardCharsets CodecTestUtils assertFalse channel clear bytesRead assertEquals decoder convert ByteBuffer [content length: 16; pos: 16; completed: true] stuff; Assert allocate inbuf assertTrue testBasicDecoding toString more stuff metrics isCompleted ,httpcore,0
log4jFile init currentThread getTestCaseConfDir XLogService getResourceAsStream ls assertFalse cl destroy is assertEquals testDefaultLog4jFromConfigDir getLog4jProperties Thread IOUtils Assert test-oozie-log4j.properties getFromClasspath getContextClassLoader copyStream ,oozie,1
"http:// getName RECORDS =  prefix /listPaths conf /logs/a.log stacksURL HttpServer2 /data logURL info allURL LOG fsckURL /  verify records contains /streamFile stop size http access  Accesing ""/"" will redirect to /index.html  start a http server with CountingFilter /stacks /a.jsp remove outURL urls getHostPortString getConnectorAddress assertTrue /static/a.out /* streamFile  access the urls dataURL /fsck set listPathsURL testServletFilter createTestServer start ajspURL rootURL RECORDS NetUtils /index.html ",hadoop,0
testKillCoordPurgeXCommand getId coordJobGetExecutor getStatus addRecordToCoordActionTable coordActionGetExecutor getErrorCode assertNotNull Coordinator Action should have been purged get CoordinatorAction action Coordinator Job should have been purged assertEquals execute addRecordToCoordJobTable call CoordinatorJob Services fail coord-action-get.xml ErrorCode je job jpaService ,oozie,1
actionDir  Delete the file if it is already there </prepare> doOperations conf getFileSystem fs delete  Prepare block that contains mkdir action createJobConf  Test for mkdir as prepare action LauncherMapper assertTrue newDir <prepare> <mkdir path=' '/> prepareXML exists testMkdir setupLauncherURIHandlerConf PrepareActionsDriver getFsTestCaseDir ,oozie,1
exception getLocalizedMessage getInternalServerErrorResult NinjaConstant equalTo when Result result getRenderable assertTrue verify not important getTemplate ArgumentMatchers thenReturn getWithDefault getMessage eq  real test: assertThat any ninjaDefault getStatusCode contextImpl messages ninjaProperties ,ninja,0
shouldLog bar testNamedLoggersWithoutSpecifiedPrimary helper assertTrue foo record assertFalse LOG_PERIOD ,hadoop,0
server getCurrentUser RPC getProxySuperuserGroupConfKey GROUP_NAMES DefaultImpersonationProvider getUser newEmptyRequest conf run retVal Assert setStrings REAL_USER_SHORT_NAME testRealUserIPAuthorizationFailure refreshConf 20.20.20.20 client     * Tests authorization of superuser's ip.     setProtocolEngine addr setConfiguration UserGroupInformation proxyUserUgi printStackTrace e  Authorized IP address getClient createRemoteUser group1 REAL_USER_NAME fail doAs getTestProvider stop setupTestServer getProxySuperuserIpConfKey PROXY_USER_NAME The RPC must have failed  realUserUgi createProxyUserForTesting ,hadoop,0
container conf getId getStatus when System coord Assert getServletURL runConf assertTrue CoordinatorAction end set thenReturn start command testCoordNotificationTimeout call OozieClient 1 getRunConf Mockito toXmlString currentTimeMillis mock /hang/* ,oozie,1
"cluster  Block Size is 1MB. writeByte getDataNodes HdfsConstants src setQuota fs / test_quota1 dfs  Setting diskspace quota to 3MB  Shutdown one datanode, causing the block abandonment. fail testQuotaUpdatedWhenBlockAbandoned get FILE_NAME_PREFIX fout create Unexpected quota exception when closing fout close  Close the file, new block will be allocated with 2MB pending size. shutdown ",hadoop,1
"server getName getHdfsConf conf dir fs asList TestDirHelper Assert createHadoopConf /tmp/foo server.services StringUtils get server.hadoop.filesystem.cache.purge.timeout join hadoop getFileSystemConfiguration init set getAbsolutePath TestHdfsHelper getTestDir hadoopConf destroy fileSystemExecutorException assertEquals services , execute CommonConfigurationKeysPublic 0 getError fail ex fsa u mkdirs FileSystemAccessException Arrays ",hadoop,1
bundleJobGetExecutor Bundle Job should have been purged Bundle Action should have been purged addRecordToBundleActionTable getId DateUtils getStatus parseDateOozieTZ testKillBundlePurgeXCommand getErrorCode assertNotNull get Job 2011-01-01T01:00Z addRecordToBundleJobTable assertEquals execute call Services fail bundleActionGetExecutor1 bundleActionGetExecutor2 action1 ErrorCode je job action2 jpaService ,oozie,1
"default factory foo codec full factory bar codec /tmp/foo.bz2 getCanonicalName empty factory lz4 codec conf getCodecClasses bzip2 BZIP2CODEC /tmp/foo.gz bar /tmp/foo.lz4 klass full codec bzip2 codec  org.apache.hadoop.io.compress.BZip2Codec    /tmp/.foo.bar.gz empty factory snappy codec getCodec empty factory for .bz2 FOO testFinding default factory for .gz getCodecByName getCodecClassByName bzip2codec full factory foo bar codec full factory for .bz2 deflatecodec codec fail deflate /tmp/foo.foo overridden factory for gzip codec default factory for .bz2 default factory for deflate codec /tmp/foo/baz.foo.bar empty factory gz codec full factory foo codec /tmp/foo.bar foo     org.apache.hadoop.io.compress.DefaultCodec  ,  overridden factory for .gz empty factory for bzip2 codec DEFLATECODEC full codec gz codec /tmp/foo.snappy default factory for bzip2 codec foobar CompressionCodecFactory full factory gz codec default factory for gzip codec BZIP2 checkCodec factory set CommonConfigurationKeys    org.apache.hadoop.io.compress.GzipCodec   ,   gz, bz2, snappy, lz4 are picked up by service loader, but bar isn't assertEquals gzip IllegalArgumentException is unexpected GZIPCodec DEFLATE gzipcodec empty factory bar codec BAR GZIP setClasses FOOBAR getCodecByClassName ",hadoop,0
dst CodecTestUtils channel convert Assert inbuf assertTrue testBasicDecoding isCompleted read StandardCharsets 5 01234 5 56789 6 abcdef 0   clear bytesRead assertEquals [chunk-coded; completed: true] decoder 0123456789abcdef ByteBuffer trailers allocate toString metrics getTrailers ,httpcore,0
"1.0, 2.0, 3.0m geo 1.0, 2.0 geo:80.33,-32.3344,3.35 GEO:1,2 geo:1,2,3 geography ParsedResultType doTestResult testGeo geo:1,2 80.33, -32.3344, 3.35m ",zxing,0
methodDir setWritable  publish the metrics ms toURI No exception was generated while writing metrics  even though the target directory was not writable path MockSink stop assertTrue  Make sure the dir is writable again so we can delete it at the end toString publishMetricsNow initMetricsSystem FileUtil registerWith shutdown testFailedWrite ,hadoop,0
getResource hdfs7067.keystore other non-Hadoop method getCurrentKey should have thrown an exception getting testkey5@0 should have thrown an exception getting testkey2 conf keystoreDirAbsolutePath keyVersionWrongKeyNameFormat ourUrl should have thrown an exception No version in key path  No version in key path testkey2/ provider get  Sanity check that we are using the right keystore getPath  org.apache.hadoop.crypto.key.JavaKeyStoreProvider$KeyMetadata JavaKeyStoreProvider testJksProviderWithKeytoolKeys ://file@/ getKeyVersion keyVersionCurrentKeyNotReally set e keyVersionCurrentKeyNotWrongKeyNameFormat getProviders testkey5@0 GenericTestUtils testkey2 fail keyVersion assertExceptionContains unused KeyProviderFactory ,hadoop,0
oozieUrl getReaderAsString assertFalse newCache admin run secret oozie.authentication.simple.anonymous.allowed  not using cache delete testClientAuthTokenCache assertTrue -status runTest getContextURL oozie.authentication.signature.secret false assertEquals  using cache args call oozie.auth.token.cache IOUtils -oozie currentCache setSystemProperty AuthOozieClient true exists  re-using cache ,oozie,1
storePassword getResource toCharArray setWantClientAuth serverSocket newSingleThreadExecutor Executors serverSslContext getServerSocketFactory Assert bind assertNotNull nopassword clientPrincipal create TimeUnit SSLContextBuilder /test-client.p12 write getPeerPrincipal localhost startHandshake read localPort loadKeyMaterial loadTrustMaterial resource2 inputStream setSoTimeout testSSLHandshakeClientUnauthenticated getInputStream /test-server.p12 resource1 accept createSocket clientSslContext TIMEOUT getLocalPort submit session clientSocket flush keyPassword get outputStream close connect assertEquals call getSocketFactory assertNull build future toMillisecondsIntBound getOutputStream socket getSession createServerSocket ,httpcore,0
testMatLookupCommand2 2099-02-01T01:00Z checkCoordJobs getId DateUtils parseDateOozieTZ addRecordToCoordJobTable call CoordinatorJob 2099-02-03T23:59Z startTime endTime job ,oozie,1
Status TOP_OPTIONAL_RESOURCE StatusPrinter assertEquals verifyConfig statusChecker getHighestLevel tc optionalResource print doConfigure IA context IB ,logback,0
setClassesToBeExcluded assertFalse getCurrentDateafterIncrementingInMonths getId run DateUtils isPending getStatus addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob setPauseTime get CoordinatorAction end currentDatePlusMonth waitFor  set some pause time explicity to make sure the job is not unpaused createCoordJob init testCoordStatusTransitServicePaused getConf coordInsertCmd false start 2009-02-01T01:00Z destroy assertEquals services XDataTestCase execute Services CoordinatorJob jobId runnable coord-action-get.xml excludedServices setSystemProperty StatusTransitService jpaService evaluate ,oozie,1
 a b addSampler testSamplers assertEquals counter 1 getValue 2 size setScheduler inst get shutdownNow getSamplers scheduledExecutorService evaluate waitFor ,oozie,1
 Issue the kill command getCurrentDateafterIncrementingInMonths  Create a coordinator job with RUNNING status getId testCoordKillWaiting DateUtils WorkflowInstance getStatus addRecordToCoordActionTable parseDateOozieTZ coordJob  action kill should be false wfJob1  Create a coordinator job with WAITING status addRecordToWfJobTable assertNotNull get CoordinatorAction end currentDatePlusMonth WorkflowJob  kill should be true RUNNING coordActionGetCmd2  Check the status and pending flag after kill command is issued coordActionGetCmd1 start  Make sure the status is updated assertEquals XDataTestCase execute addRecordToCoordJobTable call CoordinatorJob Services coordJobGetCmd coord-action-get.xml  Create a workflow job with RUNNING status action1 action2 getPending jpaService ,oozie,1
checkCoordActions getTime DateUtils parseDateOozieTZ 2009-03-06T10:00Z addRecordToJobTable call jobId pauseTime 2009-03-06T10:08Z -testActionMater-C 0000000- startTime endTime testActionMaterWithPauseTime2 2009-03-06T10:14Z ,oozie,1
testCoordReRun3 END_POINTS IS_SECURITY_ENABLED -action oozieUrl -refresh run appPath assertTrue get create SERVLET_CLASSES close runTest app MockCoordinatorEngineService coordinator.xml RestConstants getContextURL assertEquals getFileSystem -rerun 0 args call -oozie mkdirs job getFsTestCaseDir ,oozie,1
" write file and start second node to be ""older"" than the original bc cluster startUpCluster shutDownCluster resetConfiguration getPendingReplicationBlocks dnR conf bl dn waitForTempReplica findBlock DN_N0 blockReport get bytesChkSum DN_N1 join writeFile blockReport_09  block DFSConfigKeys  return the initial state of the configuration getDataNodes getBlockPoolId getMethodName  all blocks belong to the same file, hence same BP blocks getBlockListAsLongs filePath start GenericTestUtils corruptBlockLen assertEquals getNameNodeRpc Wrong number of PendingReplication blocks / setInt corruptBlockGS printStats setLong poolId METHOD_NAME .dat getNamesystem getDNRegistrationForBP ",hadoop,1
@ No FileSystem for scheme timeOutCreationTime checkCoordAction  timeout. TZ addInitRecords substring System sleep testTimeoutWithException assertTrue CoordinatorAction missingDeps indexOf setCoordActionCreationTime e getMessage Thread call fail contains currentTimeMillis nofs:///dirx/filex actionId ,oozie,1
writeLock  ensure time for operations to start blocking channel run Executors interruptException getCause sleepUninterruptibly WRITE assertTrue executor get interrupt await lock  ensure all operations on the channel will block latch countDown write MILLISECONDS  ensure time for thread to start blocking on the write lock set e testCloseByInterrupt expected start store thread byteStore futures newCachedThreadPool ByteBuffer  ClosedByInterruptException READ fail allocate queueAllBlockingOperations future Uninterruptibles  interrupt this thread. ,jimfs,1
"Unexpected Exception      f->(2,3)     (2,3)->j      addNode def printStackTrace e f one j testSimpleForkJoin k kill three two asList wf fail invokeForkJoin parser four <worklfow-app/> dummyConf end Arrays ",oozie,1
 conn /v1/jobs id-valid put assertNotNull name=x openConnection testJobs params getInputStream JSONValue PST getHeaderField 2 size GET endsWith reset setRequestMethod IS_SECURITY_ENABLED wf external-valid assertTrue array get json content-type startTime runTest PDT JsonTags RestConstants MockDagEngineService HttpServletResponse assertEquals parse url call 100  PDT if on daylight saving time assertNull obj getResponseCode wfCount createURL toString external-invalid startsWith ,oozie,1
thenReturn invoke doubleParam doubleValidationShouldWork when param1 assertTrue context create verify mockController validation hasViolation blah getParameter ,ninja,0
shexec assertEquals countTimerThreads timersAfter before:  execute System timersBefore Thread sleep 100 fail /bin/sleep Bad command should throw exception testShellCommandTimerLeak quickCommand after:  ,hadoop,1
cluster quotaDir3 quotaDir2 quotaDir1 conf  15: Delete /nqdir0/qdir1/qdir20/qdir21 /nqdir0  11: Move /nqdir0/qdir1/qdir20/nqdir30 to /nqdir0 getDirectoryCount getFileSystem setQuota  6: Create directory /nqdir0/qdir1/qdir21/nqdir33 dfs  3: set the quota of /nqdir0/qdir1/qdir20 to be 7 nqdir30  14: Move /nqdir0/qdir1/qdir21 /nqdir0/qdir1/qdir20 numDataNodes /nqdir0/qdir1/qdir20/nqdir30 mkdirs tempPath /nqdir0/qdir1/qdir20 /nqdir0/qdir1/qdir21 nqdir33 nqdir32  16: Move /nqdir0/qdir30 /nqdir0/qdir1/qdir20 nqdir31  8: Create directory /nqdir0/qdir1/qdir20/nqdir33 qdir21 getUri shutdown /nqdir0/qdir1  10.a: Rename /nqdir0/qdir1/qdir20/nqdir30 to /nqdir0/qdir1/qdir21/nqdir32  1: create directory /nqdir0/qdir1/qdir20/nqdir30 testNamespaceCommands HdfsConstants hasException assertFalse fs delete getQuota  7: Create directory /nqdir0/qdir1/qdir20/nqdir31  4: Create directory /nqdir0/qdir1/qdir21 and set its quota to 2 assertTrue  2: set the quota of /nqdir0/qdir1 to be 6 /nqdir0/nqdir30 c  9: Move /nqdir0/qdir1/qdir21/nqdir32 /nqdir0/qdir1/qdir20/nqdir30 getContentSummary assertEquals Not a HDFS:   13: Move /nqdir0/nqdir30 /nqdir0/qdir1/qdir20/qdir30 /nqdir0/nqdir30/nqdir33  12: Create directory /nqdir0/nqdir30/nqdir33 build rename exists  5: Create directory /nqdir0/qdir1/qdir21/nqdir32  10: Move /nqdir0/qdir1/qdir20/nqdir30 to /nqdir0/qdir1/qdir21 ,hadoop,1
request Test client status ContentType POST pattern setMaxTotal getStatus remove setEntity NStringEntity IOReactorStatus Assert assertNotNull expectedPattern get create buffer HttpVersion localhost add address setDefaultMaxPerRoute start count isEmpty assertEquals generateText getEntity execute target EntityUtils RndTestPatternGenerator generateCount getPort future response toString testHttpPostsHTTP10 append queue entity ,httpcore,1
 msg hcat.topic1 dt=20120101;country=us;state=CA createTextMessage createProducer getWaitingActions testCacheUpdateByMessage HCatConstants getAvailableDependencyURIs  construct message Exception:  dt=20120101;country=us;state=NY 1234465454 jsonMsg 1234465452 1234465453 registerForNotification add getServer  test message processing through JMS notification listener printStackTrace hcatService hcat.server.com:5080 dep3 dep4 dep1 dep2 pdms getDb HCatEventMessage actionId2 fail actionId1 actionId4 contains actionId3 hcat://hcat.server.com:5080/mydb/mytbl/dt=20120102;country=us;state=CA getTable hcatHandler topic producer getPartitionMap  add partition as missing send getURI setStringProperty thrift:// session System sleep assertTrue get hcat://hcat.server.com:5080/mydb/mytbl/country=us;dt=20120101 addMissingDependency process hcat://hcat.server.com:5080/mydb/mytbl/dt=20120101;country=us createTopic e 1234465451 clear getMessage  test message processing partitionsList dt=20120102;country=us;state=NY Thread Services assertNull currentTimeMillis toString dt=20120102;country=us;state=CA hcat://hcat.server.com:5080/mydb/mytbl/dt=20120102;country=us ,oozie,1
testConstructorWithQuota  check the full constructor with quota information getFileAndDirectoryCount getSpaceQuota fileAndDirectoryCount assertEquals spaceConsumed getQuota build quota quotaUsage fileAndDirCount spaceQuota getSpaceConsumed ,hadoop,0
actionNum CoordinatorJob testCoordActionGet coord-action-get.xml CoordinatorAction getId job cleanUpDBTables addRecordToCoordActionTable addRecordToCoordJobTable _testGetRunningActionsCount ,oozie,1
ReadWriteDiskValidator source LastFailureTime test.build.data FailureCount test MetricsRecords getMetricValueByName ms testDir 000 The first failure time should be less than the second one fail testCheckFailures getSource toFile Disk check should fail. getMetrics delete  verify the first metrics record System collector lastFailureTime2 lastFailureTime1 Shell checkStatus assertTrue get  create a temporary test directory under the system test directory ReadWriteDiskValidatorMetrics getRecords Paths assertMetric Files Disk Check failed! execCommand getProperty createTempDirectory e getAbsolutePath  verify the second metrics record readWriteDiskValidator getMessage assertEquals DiskValidatorFactory getSetPermissionCommand toString getInstance sourceName ,hadoop,0
reader skip conf keyX createScanner Error on handling negative length. fs getBytes testFailureNegativeLength_2 path fail closeOutput Assert getLen getFileStatus scanner lowerBound close open ,hadoop,0
"DagELFunctions ""FEATURES"":""UNKNOWN"", ActionType ""RETURN_CODE"":""0"", ""ERROR_MESSAGE"":null, put ${hadoop:counters('H')['JOB_GRAPH']} createEvaluator ${hadoop:counters('H')['ACTION_TYPE']} split ""0"" {""ACTION_TYPE"":""PIG"", ""ERROR_CODE"":""-1"", tmp context setId action indexOf ""job_201111300933_0004"" item workflow ""HADOOP_VERSION"":""0.20.2"", ${hadoop:counters('H')['job_201111300933_0004']} , version ""RECORD_WRITTEN"":""33"", 1 ApplicationType eval null job1StatusResArray ${hadoop:counters('H')['job_201111300933_0004']['MAP_INPUT_RECORDS']} ""NUMBER_JOBS"":""2"", job1StatusMap : evaluate ""JOB_GRAPH"":""job_201111300933_0004,job_201111300933_0005"", ""MIN_REDUCE_TIME"" ""job_201111300933_0005"" status setName addNode ""job_201111300933_0005"":{""MAP_INPUT_RECORDS"":""37"",""MIN_REDUCE_TIME"":""0"",""MULTI_STORE_COUNTERS"":{},""ERROR_MESSAGE"":null,""JOB_ID"":""job_201111300933_0005""}, 0.9.0 generateId H jobStatusItems job2StatusMap ""37"" pigStats ${hadoop:counters('H')['job_201111300933_0005']} ""job_201111300933_0004"":{""MAP_INPUT_RECORDS"":""33"",""MIN_REDUCE_TIME"":""0"",""MULTI_STORE_COUNTERS"":{},""ERROR_MESSAGE"":null,""JOB_ID"":""job_201111300933_0004""}, substring ""ERROR_MESSAGE"" wi ""BYTES_WRITTEN"":""1410"", configureEvaluator ""PIG_VERSION"":""0.9.0"", get <workflow-app/> MapReduceActionExecutor ""MULTI_STORE_COUNTERS"" setProtoActionConf setWorkflowInstance a {} job2StatusResArray testELFunctionsReturningPigStats setVar assertEquals wfApp ""33"" Services ""JOB_ID"" lastIndexOf <configuration/> job_201111300933_0004,job_201111300933_0005 ${hadoop:counters('H')['PIG_VERSION']} jobGraph ""MAP_INPUT_RECORDS"" toString job2StatusResult job2StatusResMap } job1StatusResMap job1StatusResult ",oozie,1
getCurrentUser newRecordInstance conf run stagingDir fs delete when  Staging Dir exists System jobid hook assertTrue appId verify  no retry testDeletionofStagingOnKillLastTry UserGroupInformation attemptId getShortUserName mockAlloc MRAppMaster isn't stopped anyBoolean init set thenReturn Service newInstance ApplicationAttemptId isLastAMRetry any setAppId appMaster.isLastAMRetry() is false MRApps stagingJobPath recordFactory  simulate the process being killed currentTimeMillis mock exists MRJobConfig ApplicationId user getStagingAreaDir appMaster isInState stagingJobDir ,hadoop,1
coordId1 testGetSLAEventsForOR assertEquals createFilterList list coordActionId1 execute jobid Services slaEventsGetCmd size assertNotNull get filterList jpaService ,oozie,1
END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL oozieUrl MockDagEngineService run assertEquals testResume args call 1 -oozie size job -resume SERVLET_CLASSES runTest ,oozie,1
setDepthFirst prepare item2 item5ca item1 conf setRootExpression when setOut out Result find inOrder verify setOptions expr finish item1b item1a item5e item5d item5c createDirectories item5b processArgumentsDepthFirst item5a setErr fsCheck err test inOrderFsCheck apply thenReturn check processArguments any setConf anyInt verifyNoMoreInteractions mock getOptions  check that directories are descended correctly when -depth is specified item1aa item4 items item3 item5 ,hadoop,0
cancel connectors validator Jackson Executors requestReceived /test http://localhost: executor TimeUnit connection Validation test openConnection newScheduledThreadPool assertThat getInputStream objectMapper isOpen stop connector cleanup port isInstanceOf testGracefulShutdown http getConnectors isNotEmpty server getLocalPort submit buildDefaultValidatorFactory setPort metricRegistry sleep result  wait for server to close the connectors  cancel the cleanup future since everything succeeded jersey get await ClassLoader shutdownNow getValidator serverStopped countDown connect isStopped start futureResult getSystemClassLoader url newObjectMapper shutdownInvoked CharStreams Thread call schedule environment build toString isEqualTo register ,dropwizard,1
conn xFrameEnabled createServer getHttpURLConnection conf httpServer X-FRAME-OPTIONS Unexpected X-FRAME-OPTIONS in header getHeaderField stop assertTrue xfoHeader toString HttpServer2 testHttpResonseDoesNotContainXFrameOptions ,hadoop,0
de en-US NinjaConstant language when getCookie testGetAllWithContextAndResult result assertTrue of get deutsch context english builder lang ok map keySet a_property_only_in_the_defaultLanguage Cookie TorÃ¶Ã¶Ã¶Ã¶ - das ist der platzhalter: {0} getAll Optional message_with_placeholder thenReturn containsKey anyString en a_propert_with_commas assertEquals  reset result and set context cookie: size Results build Mockito name messages getStringArray fr-FR ninjaProperties getAcceptLanguage  GERMAN locale testing:  US locale testing: setLanguage ,ninja,0
hdfsfoocs cluster qualified getCurrentUser data qfoocs= conf run dir setLevel webhdfsuri= bar ugi  test permission error on webhdfs FileSystem create :// HftpFileSystem WebHdfsFileSystem write UserGroupInformation hftpuri info localhost createUserForTesting DFSConfigKeys data.length= webhdfs_qfoocs  write another file  generate random data  write data to a file getLogger getFileSystem getFileChecksum setInt getInt fail doAs nnAddr hftpfoocs  test permission error on hftp numDataNodes Level webhdfsfoocs= barhashcode setSeed shutdown webhdfsqualified qfoocs webhdfsfoocs hftpuri= seed hdfsfoocs= buffer_size foo hftp hftp:// System nextBytes out  compute checksum barcs getTestConfiguration current /filechecksum hashCode get setPermission block_size close getShortUserName webhdfs_qfoocs= set  webhdfs  hftp webhdfs assertEquals testFileChecksum nextInt nextLong io.file.buffer.size  try different number of blocks n seed= GOOD: getting an exception build hdfs webhdfsuri  verify checksum hftpfoocs= user RAN ioe setBoolean ,hadoop,1
getTime getExpectedStart testSLARegistrationGet current assertNotNull get -TestSLARegGetJPAExecutor-W bean getAlertEvents readCmd getJobId getSlaConfigMap _addRecordToSLARegistrationTable assertEquals execute jobId Services getAlertContact size 0000000- AppType alert@example.com jpaService END_MISS getAppType ,oozie,1
testUnknownClass assertServiceCreationFails no.such.classname ,hadoop,0
deleteList addRecordToBundleActionTable Bundle Action B2 should have been deleted Bundle Job B should have been deleted getId actionC1 actionC2 Bundle Action B1 should have been deleted actionA1 actionA2 Bundle Action A2 should have been deleted testDeleteBundles Bundle Action A1 should have been deleted jobB jobA getErrorCode assertNotNull jobC get Job getBundleId Bundle Job A should have been deleted add getCoordName addRecordToBundleJobTable assertEquals actionB1 execute actionB2 Services fail Bundle Job C should have been deleted Bundle Action C2 should have been deleted ErrorCode je Bundle Action C1 should have been deleted jpaService ,oozie,1
maxTime Should fail retryUpToMaximumTimeWithFixedSleep realPolicy RetryDecision constructReasonString times shouldRetry Other exception other than UnreliableException should also get  TimeUnit create verify RetryUpToMaximumTimeWithFixedSleep unreliableImpl policy anyBoolean failsOnceThenSucceeds failsTenTimesThenSucceeds setupMockPolicy assertEquals failed. testRetryUpToMaximumTimeWithFixedSleep RetryProxy alwaysSucceeds any anyInt fail  expected unreliable mock caughtRetryAction ,hadoop,0
cluster fsHome conf somewhat/random.txt delete assertTrue getHomeDirectory else getUserName close writeFile /somewhere cleanupFile subdir2 testWorkingDirectory getWorkingDirectory subdir1 assertEquals getFileSystem /user/ home setWorkingDirectory orig_path build readFile makeQualified fileSys isAbsolute exists toString file1  test home directory shutdown ,hadoop,1
simulator buildScenario longTest verify parameters simulate ,logback,0
NULL_STR testUnescapeString ESCAPED_STR_WITH_COMMA unEscapeString assertEquals STR_WITH_ESCAPE STR_WITH_BOTH2 Should throw IllegalArgumentException fail STR_WO_SPECIAL_CHARS STR_WITH_COMMA ESCAPED_STR_WITH_BOTH2 StringUtils EMPTY_STR ESCAPED_STR_WITH_ESCAPE ,hadoop,0
"checksumFile checksumStream getChecksumFile  Now reading the file should fail with a ChecksumException getBytes getRawFileSystem testtruncatedcrc  telling it not to verify checksums, should avoid issue. assertTrue TEST_ROOT_DIR fout create Did not throw a ChecksumException when reading truncated  write close replaceStream rawFs  Read in the checksum testing truncation read setVerifyChecksum str  Now rewrite the checksum file with the last byte missing fail buf localFs testPath crc file readFile testTruncatedChecksum equals toString open ",hadoop,0
mapred.child.java.opts conf getLauncherMain setupActionConf asList A1 A2 protoConf action.bar getMainArguments context getPath action JavaActionExecutor <job-tracker> f.jar AA actionConf ae lib/a.so.1#a.so.1 getFileSystem java-launcher.jar checkForDisallowedProps appSoPath <name-node> setLibFilesArchives AQ fail contains MAIN-CLASS getType lib/a.so endsWith <property><name>a</name><value>AA</value></property> Arrays JAVA-OPTS mapred.job.classpath.files BB action.foo getClassesForLauncher C D E F writeXml user.name getActions appPath createBaseHadoopConf oozie.action.sharelib.for.java assertTrue LauncherMapper get job.xml close a mapred.job.tracker b set c XmlUtils d e toUri mapred.cache.archives assertEquals getLauncherJarName <property><name>mapred.job.queue.name</name><value>AQ</value></property> Services getTestUser assertNull action.barbar addAll LA exists toString getOozieLauncherJar getJobTrackerUri LQ mapred.job.queue.name </configuration> prepareActionDir <property><name>oozie.launcher.mapred.job.queue.name</name><value>LQ</value></property> createBaseWorkflow appSo1Path <arg>A2</arg> create job2.xml testSetupMethods lib/a.so.1 add mapred.cache.files parseXml </job-tracker> createLauncherConf </name-node> setupLauncherConf addToCache <file>f.jar</file> fs.default.name appJarPath action.foofoo <property><name>oozie.action.sharelib.for.java</name><value>sharelib-java</value></property> <java-opts>JAVA-OPTS</java-opts> </name-node> <configuration> <java> classes expectedSo1Path assertFalse oozie.launcher.f archivePath wf actionXml oozie.launcher.a oozie.launcher.d <job-xml>job.xml</job-xml> setStrings <job-xml>job2.xml</job-xml> cleanUpActionDir <archive>a.tar</archive> <property><name>oozie.launcher.a</name><value>LA</value></property> getNameNodeUri </java> os WorkflowAppService filePath getLauncherClasses <property><name>b</name><value>BB</value></property> <main-class>MAIN-CLASS</main-class> <configuration> setType <arg>A1</arg> a.tar lib/a.jar getFsTestCaseDir getActionDir startsWith sharelib-java ,oozie,1
MatrixUtil getVersionForNumber  1 1 1 1 1 1 1 0           0 1 1 1 1 1 1 1  expected              1                              assertEquals testEmbedBasicPatterns1 matrix  1 0 0 0 0 0 1 0           0 1 0 0 0 0 0 1   0 0 0 0 0 0 0 0 1                          embedBasicPatterns  1 0 1 1 1 0 1 0                             0 0 0 0 0 0 0 0           0 0 0 0 0 0 0 0   1 0 0 0 0 0 1 0                             Version 1. Version clearMatrix toString  1 0 1 1 1 0 1 0           0 1 0 1 1 1 0 1   1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1   1 1 1 1 1 1 1 0                                         0                              ,zxing,0
date scriptExecutor session  Given simpleMap_RemoveByKey update simple simplemap Eq doesNotContainEntry  When of where id row ten table twenty executeScriptTemplate containsEntry RandomUtils manager one simpleMap nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap getMap hasSize  Then Long buildDateKey fromBaseTable dsl SELECT simplemap FROM simple WHERE id =  should_dsl_update_map_removeByKey ,achilles,1
c:/log/debug-old-2010-08-10.2.log c:/log/debug-old-%d{yyyy-MM-dd}.%i.log matchingFileArray c:/log/debug-old-2010-08-10.12.log  see also http://jira.qos.ch/browse/LBCORE-164 sa c:/log/debug-old-2010-08-10.7.log result c:/log/debug-old-2010-08-10.1.log findHighestCounterTest rexexp context FileFilterUtil c:/log/debug-old-2010-08-10.6.log toRegexForFixedDate c:/log/debug-old-2010-08-10.5.log fnp assertEquals c:/log/debug-old-2010-08-10.10.log parse c:/log/debug-old-2010-08-10.9.log 2010-08-10 findHighestCounter stemRegex c:/log/debug-old-2010-08-10.3.log sdf c:/log/debug-old-2010-08-10.0.log c:/log/debug-old-2010-08-10.11.log yyyy-MM-dd afterLastSlash c:/log/debug-old-2010-08-10.4.log c:/log/debug-old-2010-08-10.8.log ,logback,0
session  Given insert uuid crud getUUID  When get id row value val all SELECT * FROM entity_composite_pk WHERE id =  RandomUtils manager getString nextLong rows assertThat execute  AND uuid =  getLong hasSize should_insert  Then Long isEqualTo entity ,achilles,1
 Test 4: exit code for chgrp on existing path with globbed input is 0 p1 p4 p5 p6  Test 1: exit code for chgrp on existing file is 0 admin f1 f2 f3 testChgrp/file*  Test 2: exit code for chgrp on non existing path is 1 f7 testChgrp/file3 assertTrue TEST_ROOT_DIR testChgrp/file2  create and write test file testChgrp/file1 getPath testChgrp/nonExistingfiles*  exit code used to be for last item writeFile testChgrp/fileExists toUri change  Test 3: exit code for chgrp on non-existing path with globbed input is 1 testChgrp/fileDoesNotExist  create required files testChgrp fileSys exists ,hadoop,0
"getCurrentUser zksmNew dtinfo conf good  Cancel one token, verify it's gone Assert assertNotNull  Fake a restart which launches a new tm canceled dt should be gone! id waitFor UserGroupInformation info init idCancelled zkServer LOG  The cancelled token should be gone, and not loaded. unchecked GenericTestUtils destroy createToken cancelToken zksm1 setLong Waiting for the cancelled token to be removed cancelled connectString good dt should be in memory! DelegationTokenManager  Set the remove scan interval to remove expired tokens verifyToken getTokenInfo Waiting for the expired token to be removed...  Wait for the good token to expire. sleep bla get getDelegationTokenSecretManager sm removeScan getSecretConf  is hard-coded to sleep at least 5 seconds. smNew getConnectString  The good token should be loaded on startup, and removed after expiry. getTokenInfoFromMemory token Thread testNodesLoadedAfterRestart zksm assertNull id1 tm  Set token expire time to 5 seconds. decodeTokenIdentifier ",hadoop,0
server ContentType testForceHttp1 listener CoreMatchers notNullValue equalTo connectFuture some stuff listen endpoint Assert getDuration HttpVersionPolicy getHead get getAddress https /stuff getCode HttpVersion connect requester localhost getVersion address HttpStatus start resultFuture1 Method assertThat execute target getTimeUnit getPort future TIMEOUT response1 message1 ,httpcore,0
"  testDivide toMilliseconds assertEquals toMicroseconds toSeconds toNanoseconds  nominator is 0, result should be 0. toMinutes Assert toHours ofMilliseconds toMillisecondsIntBound TimeUnit divide toDays ofMinutes TimeValue toSecondsIntBound ",httpcore,0
"serviceInitTimeResult /serviceInitTime getServerAddress  The response information must match the internal application state  We know that this service is a singleton and it provides the application initialization time. ninjaTestBrowser makeJsonRequest getInjector assertEquals serviceInitializationTime testThatInjectorAccessibleFromNinjaTestIsTheApplicationInjector  this is the application guice injector  provide a json with information about the application initialization time. getInstance injector {""initTime"": } getServiceInitializationTime ",ninja,1
"  Now delete 'C' and make sure I don't get entries from 'B'. HConstants conf getRegionName put getBytes Bytes getTableDesc FileSystem createRegionName hri info add last mr LOG firstRowInC toBytes rootdir  Write rows for three tables 'A', 'B', and 'C'. getRow HRegion mkdirs interval  Up flush size else we bind up when we use default catalog flush of 16k. next  Assert we get null back (pass -1). findRow keys scan CATALOG_FAMILY delete testUsingMetaAndBinary HRegionInfo get htd close Writables c REGIONINFO_QUALIFIER clear filesystem flushcache setMemStoreFlushSize makeQualified createHRegion getScanner ",hadoop,1
firstValidInput numInputs allocate putInt array CoderUtil inputs findFirstValidInput assertEquals ByteBuffer testFindFirstValidInput ,hadoop,0
"init getName set getConf destroy conf services , asList Services Assert StringUtils assertNotNull get proxyUser join Arrays testService ",oozie,1
cluster chiSquareTestRejectedCounter getName randomNode Random is not selecting all nodes  Pick random nodes excluding the 2 nodes in /d1/r3  Check that they have the proper distribution values assertFalse getNewNode occurrence Random is not selecting the nodes it should put Random not choosing nodes with proper distribution observed NodeBase numIterations  Pick random nodes numTestRuns get  Check with 99% confidence alpha=0.01 as confidence = 100 * (1 - alpha) chiSquareTest chiSquareTestRejected add testChooseRandom containsKey  create the topology expected assertEquals j node1 chooseRandom testRun ~/d1/r3 node4 histogram  Number of test runs node2 node3 size  Number of iterations to do the test NetworkTopology /d1/r2 /d1/r1 getInstance /d1/r3 ,hadoop,0
 be equal assertFalse  equal assertTrue get join jmsContext jmsProps session4 session3 session2 getConf printStackTrace session1 e createConnectionContext createThreadLocalSession start assertEquals services Services connInfo th equals testThreadLocalSession JMSJobEventListener Session ,oozie,1
callable2 callable3 callables TestSerialConcurrencyLimit callable1 callable4 callable5 type queueSerial Math asList queueservice min assertTrue get secondBatch testSerialConcurrencyLimit SerialConcurrencyLimit waitFor EXEC_ORDER c Services Long Arrays evaluate first ,oozie,1
setName testDetachAppenderByName addAppender tab test assertTrue assertFalse start aai detachAppender ta test1 ,logback,0
getJobTrackerUri getName <java> getStatus createContext testExit0SubmitOK actionXml isSuccessful assertTrue context end waitFor <job-tracker> getData isCompleted getNameNodeUri <arg>exit0</arg> </java> ae </main-class> </job-tracker> runningJob getAction assertEquals check getExternalStatus <name-node> <main-class> </name-node> assertNull WorkflowAction SUCCEEDED submitAction evaluate isComplete ,oozie,1
play  Verify the peer received what was expected. android Okio TYPE_DATA headerEntries Util getSink out acceptFrame flush TYPE_HEADERS peer client connection buffer write close takeFrame banana a b synReply setVariantAndClient  DATA assertEquals frameCount  SYN_STREAM sendFrame clientSendsEmptyDataServerDoesntSendWindowUpdate SPDY3  Play it back. newStream ,okhttp,1
spyFs getTempPath GenericTestUtils conf testCreateUsesFSArg.seq deprecation fs p createWriter SequenceFile Mockito getLocal getDefaultReplication FileSystem testCreateUsesFsArg verify writer spy close ,hadoop,0
ABC thenReturn context characterParam create verify invoke characterParamShouldBeParsedToCharacter when param1 mockController getParameter ,ninja,0
"mytbl1 getWaitingActions server2 server1 getAvailableDependencyURIs  Should not contain duplicates removeAvailableDependencyURIs 1234465454 mydb 1234465452 1234465453 hcat://hcat-server1.domain.com:5080/mydb/mytbl1/dt=20120101;country=us removeMissingDependency  server1,db,table1 getJMSConnectionInfo hcatService dep3 jmsService dep4 dep1 dep2 isRegisteredForNotification . pdms getDb actionId2 actionId1 actionId4 contains testPartitionDependency actionId3 hcat://hcat-server1.domain.com:5080/mydb/mytbl1/country=us;dt=20120101 connInfo size getTable isListeningToTopic hcat://hcat-server2.domain.com:5080/mydb/mytbl2/dt=20120102;country=us getPartitionMap  add partition as missing getURI mytbl2  server2,db,table2 dt=20120101;country=us assertFalse partitionAvailable hcat://hcat-server2.domain.com:5080/mydb/mytbl2/dt=20120102;country=us;state=CA table2 table1 hcat-server1.domain.com:5080 assertTrue get  Test all APIs related to dependency caching  Add duplicates. RecoveryService will add duplicates 1234465451 addMissingDependencyAndRegister assertEquals dt=20120102;country=us;state=NY Services assertNull hcat-server2.domain.com:5080 toString dt=20120102;country=us;state=CA db ",oozie,1
"APP xf1 xf2  test log GROUP constructPattern 14-200904160239--example-forkjoinwf  WorkflowRunnerCallable:323 -  get defineParameter setParameter JOB TOKEN testXLogFileter add init a XLog setLogLevel oozie createPrefix destroy XLogStreamer example-forkjoinwf assertEquals services USER matches xf 2009-06-24 02:43:13,958 DEBUG ACTION MYtoken reset toString | ",oozie,1
Expected successful touch with a specified access time newFile2  Verify if both modification and access times are recorded correctly getTime testTouch getModificationTime newFile new_status  remains unchanged). Expected successful touch with a specified timestamp delete System fstatus -touch not Expected successful touch with a specified modificatiom time strTime -a -c shellRun getFileStatus parseTimestamp Expected successful touch on a non-existent file with -c option -m formatTimestamp  Ensure newFile2 does not exist -t newFileName getAccessTime is assertThat dateObj Expected failed touch with a missing timestamp currentTimeMillis lfs exists Expected successful touch on a new file with a specified timestamp ,hadoop,0
getJobTrackerUri rootArchive rootSo soFile.so.1 createContext setupActionConf filesInCache testLibFileArchives context getPath create jar rootJar getCacheFiles       <main-class>CLASS</main-class>       <job-tracker> eActionXml       <file> ae </file>  parseXml </job-tracker> archive getFileSystem archive  </name-node> setLibFilesArchives  found in classpath soFile.so rootSoFile.so  not found in cache jobConf archive.tar       <archive> <java> assertFalse getAppPath appPath createBaseHadoopConf actionXml rootSo1 rootJar.jar file found so1 DistributedCache assertTrue root so filesInClasspath close getNameNodeUri getFileClassPaths rootArchive.tar c </java> XmlUtils rootSoFile.so.1 toUri archivesInCache file  getSymlink  not found in classpath p </archive>  getCacheArchives equals rootFile toString       <name-node> getFsTestCaseDir jar.jar ,oozie,1
Should fail realPolicy RetryDecision constructReasonString  shouldRetry += 1  shouldRetry += 2 times shouldRetry Other exception other than UnreliableException should also get  retryUpToMaximumCountWithFixedSleep TimeUnit create verify unreliableImpl policy RetryUpToMaximumCountWithFixedSleep testRetryUpToMaximumCountWithFixedSleep anyBoolean failsOnceThenSucceeds failsTenTimesThenSucceeds setupMockPolicy assertEquals failed. RetryProxy alwaysSucceeds any anyInt  shouldRetry += (maxRetries -1) (just failed once above) fail maxRetries  expected unreliable mock caughtRetryAction ,hadoop,0
storePassword getResource toCharArray serverSocket newSingleThreadExecutor Executors serverSslContext getServerSocketFactory Assert bind assertNotNull nopassword create TimeUnit Boolean SSLContextBuilder write localhost read localPort loadKeyMaterial loadTrustMaterial inputStream setSoTimeout getInputStream resource1 accept createSocket clientSslContext TIMEOUT /test.p12 getLocalPort submit clientSocket result testSSLHandshakeServerTrusted flush keyPassword get outputStream close connect assertEquals call getSocketFactory build future toMillisecondsIntBound getOutputStream socket createServerSocket ,httpcore,0
"<execution>LIFO</execution> </controls> <datasets>  checkCoordJobs xmlns=""uri:oozie:coordinator:0.2""> <controls> <timeout>10</timeout> <concurrency>2</concurrency>  conf </input-events>  appPath substring sc </property></configuration> </workflow> </action> </coordinator-app> writeToFile appXml timezone=""UTC""> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template>  <property> <name>inputB</name> <value>${coord:dataOut('LOCAL_A')}</value>  file:// getTestCaseDir UNIT_TESTING <done-flag>consume_me</done-flag> </dataset> <output-events> <data-out name=""LOCAL_A"" dataset=""local_a"">  timezone=""UTC""> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset>  timezone=""UTC""> <uri-template>file:///tmp/coord/workflowsb/${YEAR}/${DAY}</uri-template>  coordinator.xml set <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  length <dataset name=""local_a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  MY_DONE_FLAG assertEquals <done-flag>${MY_DONE_FLAG}</done-flag> </dataset> <data-in name=""B"" dataset=""local_b""> <instance>${coord:latest(0)}</instance> </data-in>   call <coordinator-app name=""NAME"" frequency=""${coord:days(1)}"" start=""2009-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""  OozieClient jobId getTestUser <dataset name=""local_b"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  </datasets> <input-events>  <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>  testSubmitWithDoneFlag -C <data-in name=""A"" dataset=""a""> <instance>${coord:latest(0)}</instance> </data-in>   <dataset name=""a"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z""  complete File ",oozie,1
getCanonicalHostName replaced assertEquals shouldReplace userPrincipal testGetServerPrincipal hdfs/ NAME never hostname notUsed @REALM foo@FOOREALM Mockito service getServerPrincipal verify mock  testing reverse DNS lookup doesn't happen realm SecurityUtil foohost shouldNotReplace ,hadoop,0
applyGlobMixedCase item getConf apply n*e name setup /directory/path/NaMe assertEquals mockFs Result  test a matching glob pattern (different case) ,hadoop,0
getName expected exception did not contain helpful message Successfully got proxy provider for misconfigured FS conf logicalHost /test hdfs:// assertTrue StringUtils FileSystem get got expected exception info set LOG stringifyException Could not find any configured addresses for URI  uri . fail contains exists testFailureWithMisconfiguredHaNNs misconfigured-ha-uri DFS_CLIENT_FAILOVER_PROXY_PROVIDER_KEY_PREFIX ioe ,hadoop,1
getParameterValues mockReq b a&lt;b a<b Test that missing parameters dont cause NPE for array doReturn assertEquals when quoter assertArrayEquals Test escaping of an array testRequestQuoting Mockito mock Test simple param quoting Test that missing parameters dont cause NPE getParameter ,hadoop,0
getClass test assertTrue WritableName equals conf testAddName altName addName  check original name still works .alt testName ,hadoop,1
":: endDate getTime streamLog DateUtils DagXLogInfoService assertTrue middleDate get action cjb after getCoordJob ce middle RestConstants createCoordinatorEngine getFilterParams ( assertEquals services @1| , runJobsImpl filter jobId createdDate formatDateOozieTZ service @2) testStreamLog4JobLogDate getCreatedTime ",oozie,1
 testFile01 getPathData  check path only display (-C option) testfile01 addContents ls out processPathDirectoryPathOnly testfile03 options inOrder getPath testfile02 processOptions verify testfile05 testFile06 testfile04 testFile04 testFile05 testfile06 testFile02 testFile03 add pathData setIsDir processArguments testDir testDirectory verifyNoMoreInteractions -C mock toString ,hadoop,0
getBytesTransferred CodecTestUtils testCodingFragmentBufferingChannelSaturated channel times Assert flush verify more stuff dump write ArgumentMatchers StandardCharsets length assertEquals encoder - any stuff--- Mockito outbuf metrics spy wrap stuff ,httpcore,0
q1 qq1 expectMetricsException testAddIllegalParameters Interval should be positive.  Value passed is: -20 r IllegalParamTest run qv1 newQuantiles New Quantile 1 ,hadoop,0
init getCurrentUser verifyToken getConnectString renewToken zkServer foo unchecked conf createToken token testRenewTokenSingleManager verifyDestroy Assert assertNotNull tm1 TEST_RETRIES connectString getSecretConf UserGroupInformation ,hadoop,0
init CoordELFunctions ${coord:hours(1)} assertEquals timeunit getVariable eval evalAndWrap ${coord:hours(coord:hours(1))} 3600 TimeUnit expr 60 coord-job-submit-freq testHours ,oozie,1
hasFieldViolation assertTrue validationShouldFailWhenBadRequest context create verify invoke mockController required param1 validation ,ninja,0
T123T testEncode2 doTest 0110010101 0101011001 00000 01011001001 1011001001 0101001011 ,zxing,0
"init  -ve test CoordELFunctions setVariable  +ve test assertEquals oozie.dataname.ABCD data-in coord-job-submit-data fail eval evalAndWrap ${coord:dataInPartitionMax('ABC', 'mypartition')} testDataInPartitionMaxPh1 should throw exception because EL function requires 2 parameters expr oozie.dataname.ABC ${coord:dataInPartitionMax('ABCD')} ",oozie,1
hdfs://///tmp/file getAuthorityWithScheme /tmp/file uriService assertEquals hdfs://nn1:8020 uri / hdfs://nn1:8020/dataset/${YEAR}/${MONTH} hdfs://nn1:8020/ testGetAuthorityWithScheme hdfs:/// toString hdfs:///tmp/file ,oozie,1
de en-US NinjaConstant language when assertTrue of get deutsch english lang testGetAllWithLanguage map keySet a_property_only_in_the_defaultLanguage TorÃ¶Ã¶Ã¶Ã¶ - das ist der platzhalter: {0} getAll Optional message_with_placeholder thenReturn containsKey en a_propert_with_commas assertEquals size getStringArray fr-FR ninjaProperties  GERMAN locale testing:  US locale testing: ,ninja,0
"fileSystem partialBlockSize /unfinished-block  create a new file in the root, write data, do no close testUnfinishedBlockRead TestFileCreation stm createFile blockSize writeFileAndSync  write partial block and sync  Make sure a client can read it before it is closed checkCanRead file1 close ",hadoop,1
"/jmx?qry=java.lang:type=Memory conn ""committed""\s*: ""name""\s*:\s*""java.lang:type=Runtime""  negative test to get an attribute of a mbean  test to get an attribute of a mbean ""modelerType"" result /jmx /jmx?get=java.lang:type=Memory:: assertNotNull readOutput /jmx?qry=java.lang:type=Runtime  test to CORS headers ""ERROR"" openConnection ""name""\s*:\s*""java.lang:type=Memory"" assertEquals ACCESS_CONTROL_ALLOW_ORIGIN baseUrl assertReFind getHeaderField testQuery GET ACCESS_CONTROL_ALLOW_METHODS /jmx?get=java.lang:type=Memory::HeapMemoryUsage ",hadoop,0
init random fail testConfiguration setSystemProperty destroy UUIDService counter services ,oozie,1
"createHardLink  are all linked, so they x1_one  x1 and x1_one are linked now str3 assertTrue  confirm that x2, which we didn't change, still shows count ""1"" appendToFile  x1, x1_one, and x11_one str1 x11_one  validate by contents  hardlink a single file and confirm expected result fetchFileContents  should all have count ""3"" x3_one  create another link to a file that already has count 2 validateTgtOne testCreateHardLink assertEquals  so they both have count ""2"" getLinkCount y_one  now do a few more equals x1 exists x2  validate that change of content is reflected in the other linked files x3 ",hadoop,0
"newGauge Standard deviation of time for stat EPSILON int gauge Ops mb s1 s2 info add S1IMaxTime Interval min time for stat test addGauge g1 long gauge g2 g3 Number of ops for stat eq c1 c2 S1IMinTime newCounter long counter mockMetricsRecordBuilder  has increased to 2, but interval number is 1 for both intervals. snapshot S1StdevTime Max time for stat Time S1AvgTime S1MinTime Min time for stat Interval number of ops for stat S2AvgTime addCounter int counter times float gauge get verify newRate S1INumOps S2NumOps Interval max time for stat registry S1MaxTime stat  should get new interval values back newStat  should get the same back. testSnapshot S1NumOps Average time for stat ",hadoop,0
checkFields unqbbc stat fsp hdfs://yaks:4344/dingos/f assertEquals convert p stat2 PBHelper testUtilitySerialization FsPermission hadoop createImmutable ,hadoop,0
genKeyPair handler request getTime jwt getPublic publicKey setPublicKey when REDIRECT_LOCATION alternateAuthentication should NOT have thrown a AuthenticationException SERVICE_URL getCookies getJWT verify getRequestURL RSA init kpg cookie kp alternateAuthentication should NOT have thrown a ServletException thenReturn getProperties hadoop-jwt encodeRedirectURL alternateAuthenticate KeyPairGenerator sendRedirect ljm props token fail privateKey serialize bob Mockito response mock getInstance initialize testUnableToParseJWT ,hadoop,0
PREP getId WorkflowInstance actionGetCmd coordJob wfBean addRecordToWfJobTable assertNotNull get  Add two jobs to update list WorkflowJob Job testBulkInsertUpdates updateList add getStatusStr insertList RUNNING wfGetCmd assertEquals  Add two actions to insert list execute addRecordToCoordJobTable setStatus CoordinatorJob 1 Services 2 WorkflowAction bulkUpdateCmd SUCCEEDED createWorkflowAction action1 job action2 jpaService ,oozie,1
generateEvent  create event with error code and message getEventStatus EventStatus errorCode getId assertEquals poll WorkflowInstance testWorkflowJobEventError execute errorMsg call addRecordToWfJobTable getErrorCode myCmd assertNotNull WorkflowJob job event queue WorkflowXCommand getErrorMessage ,oozie,1
"testRootDir f* assertFalse run f1 f2 dir f3 createFile  subdir empty createEmptyFile out f1 f2 f3  -skip-empty-file root -getmerge  two files fnf  one file, kind of silly d  glob three files assertEquals  two files, preserves order -nl df1 TestMerge df3 df1 df2 df3  df2 exit f1 df1 df2 df3 f2   file, dir, file testCopyMerge shell  directory with 1 empty + 3 non empty files, should skip subdir readFile lfs f1f2 f2f1 exists f1 f2  toString  f1 f2 f3  ",hadoop,0
"Event status not correct for map attempt1 getClass Event status not correct for map attempt2 reduceTask copyOfRange getName Event status not correct for reduce attempt1 Map TaskAttempt state not correct conf getMapAttemptCompletionEvents getStatus  send the done signal to the second map attempt mapEvents getAttempts assertArrayEquals iterator Assert atIt Event reduce attempt id not correct sendFetchFailure  wait for map Task state move back to RUNNING JobState  send 3 fetch failures from reduce to trigger map re execution reduceAttempt convertedEvents events  send done to reduce app reduceTask2  map attempt must have become FAILED getEventHandler Num completion events not correct Event map attempt id not correct getID handle it reduceTask3 size TaskAttemptState  send the done signal to the map attempt Unexpected map event MRJobConfig  previous completion event now becomes obsolete Unexpected map events job Arrays next getTaskAttemptCompletionEvents Phase submit values  wait for reduce to start running TaskAttemptCompletionEventStatus  wait for map success  We should not re-launch the map task yet waitForState Num tasks not correct TaskAttemptEventType  all maps would be running getAttemptId mapAttempt1 mapAttempt2 fromYarn mapTask testFetchFailureMultipleReduces  sequential, single-task-attempt approach in uber-AM, so disable: assertEquals Event status not correct Num attempts in Map Task not correct TypeConverter reduceAttempt2 getState getTasks updateStatus reduceAttempt3 TaskState getContext setBoolean  wait for Task state move to RUNNING Incorrect number of map events ",hadoop,1
getJobTrackerUri <java-opt>JAVA-OPT2</java-opt> mapred.child.java.opts </configuration> conf <arg>A2</arg> context action JAVA-OPT2 <job-tracker> JAVA-OPT1 actionConf ae parseXml </job-tracker> createLauncherConf getFileSystem <name-node> </name-node> contains getType <file>f.jar</file> <property><name>a</name><value>AA</value></property> <java> getActions test1 createBaseHadoopConf <java-opts>JAVA-OPT1 JAVA-OPT2</java-opts> actionXml wfBean <job-xml>job.xml</job-xml> addRecordToWfJobTable assertTrue get <job-xml>job2.xml</job-xml> <archive>a.tar</archive> <property><name>oozie.launcher.a</name><value>LA</value></property> getNameNodeUri </java> getConf XmlUtils <property><name>b</name><value>BB</value></property> <main-class>MAIN-CLASS</main-class> <java-opt>JAVA-OPT1</java-opt> <configuration> setType setConf actionXmlconf <arg>A1</arg> testJavaOpts ,oozie,1
"init ${coord:dataOutPartitionValue('ABC', 'mypartition')}  -ve test CoordELFunctions testDataOutPartitionValuePh1 setVariable  +ve test assertEquals oozie.dataname.ABCD ${coord:dataOutPartitionValue('ABCD')} coord-job-submit-data fail eval evalAndWrap should throw exception because EL function requires 2 parameters expr oozie.dataname.ABC data-out ",oozie,1
request process context interceptor Method testRequestHttp11HostHeaderAbsent getEntity / ,httpcore,0
getId assertEquals testCoordSuspendPostive getStatus execute addRecordToCoordJobTable call CoordinatorJob Services coordJobGetCmd assertNotNull get job jpaService ,oozie,1
"  Users [user1, user2] are allowed testAclString members of the groups [group1, group2] are allowed user1,user2  * acl assertThat No users are allowed  group1,group2 Members of the groups [group1, group2] are allowed  with space  Also validate if getAclString() for various cases. user1,user2 user1,user2 group1,group2 Users [user1, user2] and  toString All users are allowed isEqualTo validateGetAclString ",hadoop,0
"ce RestConstants createCoordinatorEngine getFilterParams testStreamLog4JobLogAction ( assertEquals streamLog services runJobsImpl @946) filter jobId 678, 123-127, 946 DagXLogInfoService @125| @124| service @123| get @678| @127| @126| ",oozie,1
add result basicToArrayTyped asTypedArray cowaList assertArrayEquals ,logback,0
ContentType setSslContext SSL_RSA_EXPORT_WITH_RC2_CBC_40_MD5 cipherSuite request1 setEntity weakCiphersSuites setProtocols Assert SSL_DH_anon_EXPORT_WITH_RC4_40_MD5 setSocketConfig context create https /stuff TLS_DH_anon_WITH_AES_128_CBC_SHA requester localhost SocketConfig setStreamListener LoggingHttp1StreamListener setSoTimeout Method execute ServerBootstrap EntityUtils testWeakCiphersDisabledByDefault LoggingConnPoolListener TLS_ECDHE_ECDSA_WITH_RC4_128_SHA fail CloseMode RequesterBootstrap TIMEOUT response1 TLS_RSA_WITH_NULL_SHA256 server SSL_RSA_WITH_3DES_EDE_CBC_SHA getLocalPort TLS_KRB5_EXPORT_WITH_RC4_40_SHA createClientSSLContext SSL_RSA_EXPORT_WITH_DES40_CBC_SHA consume bootstrap setConnPoolListener TLS_ECDH_anon_WITH_AES_256_CBC_SHA some stuff SSL_RSA_EXPORT_WITH_RC4_40_MD5 createServerSSLContext sslParameters SSL_RSA_WITH_RC4_128_SHA TLS_ECDH_ECDSA_WITH_3DES_EDE_CBC_SHA close IOException expected SSLTestContexts SSL_RSA_WITH_NULL_SHA custom start getEntity setSslSetupHandler target build TLS_DH_anon_WITH_AES_256_GCM_SHA384 ,httpcore,0
"play server icy-description:Rock icy-metaint:16000 icy-url:http://www.A2Rradio.com mp3 data assertContent Server: Icecast 2.3.3-kh8 getResponseMessage Accept-Ranges: none Expires: Mon, 26 Jul 1997 05:00:00 GMT client Content-Type: audio/mpeg connection shoutcast OK Cache-Control: no-cache icy-br:128 addHeader icy-pub:1 icy-name:A2RRock assertEquals setBody setStatus / Pragma: no-cache enqueue getUrl ice-audio-info: bitrate=128;samplerate=44100;channels=2 getResponseCode icy-genre:riders ICY 200 OK open ",okhttp,1
"closeTrx lib reader conf run getStatus getJob updateAction assertNotNull getTestCaseDir /workflow.xml file:// beginTrx createTestCaseSubDir create action workflow.xml waitFor commitTrx bean running-mode external-status actionConf test store2 store3 testWorkflowActionRecoveryService  assertEquals(WorkflowJob.Status.SUCCEEDED, engine.getJob(jobId).getStatus()); sync OozieClient jobId  TODO CHECK, without this we get JPA concurrency exceptions, ODD getType copyCharStream getResourceAsReader actionId File evaluate actions submitJob getId replaceAll WorkflowActionBean sleep engine get setPending getWorkflowAction ok WorkflowJob recoveryRunnable a getActionsForWorkflow set getConf fixedActionConf wf-ext-schema-valid.xml assertEquals getAction store setConf setStatus async Services IOUtils getTestUser t signal-value based_on_action_status equals writer action2 action3 ",oozie,1
"testResults resultText testCount resolve ExpectedText getRotation  Print the results of all tests first testImageGroup String expectedTextFile source decode totalFound getTestBase asList .bin ImageIO Comparator .txt fine assertNotNull Starting Image Group %s bitmap warning results testBase info  %d of %d images passed (%d required) getMustPassCount getKey image resultMetadata read entrySet StandardCharsets getText tryHarderCounts rotateImage format sort numberOfTests +++ Test too lax by %d images getFileId size Decoded %d images out of %d (%d%%, %d required) toFile Rotation  FileId --- Test failed by %d images Arrays testResult fileId log rotatedImage assertFalse getImageFileLists imageFiles getSegmentIndex result expectedText Rotation %d degrees: fileBaseName assertTrue imageFile get readFileAsString  degrees: Too many images failed Files passedCounts keySet rotation Try harder,  isEmpty assertEquals label totalMustPass getTryHarderCount testBlackBox  %d of %d images passed with try harder (%d required) totalTests getValue r addAll comparingInt exists getMeta toString append  Then run through again and assert if any failed ",zxing,0
Running DS Client --shell_command --container_memory --num_containers ls run dir yarnCluster result Shell Assert assertTrue 512 client info init testDSShell LOG --jar APPMASTER_JAR getConfig args initSuccess 2 128 Initializing DS Client Client run completed. Result= --master_memory ,hadoop,1
play clientCreatesStreamAndServerRepliesWithFin ping android  play it back headerEntries  verify the peer received what was expected acceptFrame  Ensure that the SYN_REPLY has been received. openStreamCount TYPE_HEADERS peer roundTripTime TYPE_PING connection takeFrame banana a b synReply assertEquals HeadersMode  SYN_STREAM sendFrame SPDY3  PING synStream newStream ,okhttp,1
  DFSConfigKeys TestCrcCorruption with specific parameters util1 conf2 conf1 System setInt TestCrcCorruption util2 thistest testCrcCorruption TestCrcCorruption with default parameters ,hadoop,1
actionNum getId getStatus addRecordToCoordActionTable addRecordToCoordJobTable CoordinatorJob jobId coord-action-get.xml _testCoordActionsForCorrectColumnValues CoordinatorAction testCoordActionsSuspendedForColumnValues action       * Add a Coordinator action with status SUSPENDED and check for expected column values       job getPending ,oozie,1
"testDoS A B C  After one interval, should still have enough hits to be banned test D assertFalse timerTimeMS  After building up a ban again, and letting plenty of time elapse, should un-ban Thread sleep timer maxAccessPerTime  2 requests allowed per time; 3rd should be banned assertTrue  Build up a lot of hits tracker isBanned  After max 3 others are tracked, A should be reset/evicted and un-ban ",zxing,0
StandardCharsets getContent assertFalse assertEquals getContentLength ByteBuffer getBytes capacity isRepeatable httpentity Assert isStreaming bytes assertNotNull Message content testBasics wrap ,httpcore,0
handler addTerseLoggingExceptions assertTrue assertFalse isTerseLog testExceptionsHandlerTerse ,hadoop,0
play server connectViaHttpProxyToHttpsUsingBadProxyAndHttpResponseCache initResponseCache Connect line failure on proxy  For the backwards-compatible SSLv3 retry toProxyAddress  TODO: use the fake Dns implementation instead of a loop  For the first TLS tolerant connection client SocketPolicy connection bogus proxy connect response content Host: android.com connect https://android.com/foo setSslSocketFactory getHostName getAllByName getHeaders takeRequest setProxy setSocketPolicy sslContext assertEquals setBody url assertContains getSocketFactory enqueue fail getRequestLine CONNECT android.com:443 HTTP/1.1 inetAddress response getResponseCode useHttps  Key to reproducing b/6754912 InetAddress open ,okhttp,1
getConnectionContext getEventMessage testWorkflowJobSelectors session JMSMessagingUtils getUser conf getStatus createSession getTopic wf-app-name1 Assert user_1 ='user_1' caId1 selector wfId1 WorkflowJob jmsContext consumer MessageType getMessageType init receive printStackTrace e getMessage destroy assertEquals message wfEventListener fail onWorkflowJobEvent JMSHeaderConstants wfe createConsumer wfFailMessage Session ,oozie,1
encode  mode: KANJI   1 1 1 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0   1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1  testEncodeKanjiMode  1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0  <<  >>   1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1  put  maskPattern: 0   1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1   0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0   1 1 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0   Nihon in Kanji EncodeHintType qrCode Encoder  1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1   1 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0   1 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 0 1 0 1   0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0   1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1   1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1  Shift_JIS  0 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1   1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1   0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1   matrix:   1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 0  hints expected  ecLevel: M  assertEquals æ—¥æœ¬  version: 1   1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1   1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0  toString  1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1  ErrorCorrectionLevel  1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1  ,zxing,0
bool16 byte9 Decoder byte8 assertArrayEquals convertBoolArrayToByteArray byte7 bool7 byte1 testRawBytes byte0 bool9 bool8 byte16 bool1 bool0 ,zxing,0
codec never testOutputStreamNotClosing cos mock verify outputStream close ,hadoop,0
testSucceedsTenTimesThenFailOver unreliable succeedsTenTimesThenFailsReturningString impl2 create assertEquals impl1 newFlipFlopProxyProvider RetryProxy ,hadoop,0
java.version EnvUtil assertTrue setProperty assertFalse isJDK6OrHigher isJDK5 1.6.xx testJava1_6 System isJDK7OrHigher ,logback,0
setNativeZlibLoaded ZlibFactory  don't use native libs testGzipCodecWriteJava testGzipCodecWrite ,hadoop,0
init testGetUploadedFileStream servletContext is assertEquals httpServletRequest getInputStream getParameterAsFileItem IOUtils fileX Assert file1Data assertNull assertNotNull context file2 toString file1 httpServletResponse ,ninja,0
 Should work with or without sleep testEmptyBlocking e LOG dequeue start assertEquals run consume trigger  try consuming emtpy equeue and blocking Thread Interrupted sleep q warn enqueue awhile t mock verify join element ,hadoop,0
testStartWhenAlreadyStarted start appender assertEquals runner getStartCount ,logback,0
_mkdirs defaultPerm testMkdirs_noDir_badUmask invalidPerm ,hadoop,0
"authCallsForHeader size calls realm=""testrealm@host.com"", qop=""auth,auth-int"",  assertEquals nonce=""dcd98b7102dd2f0e8b11d0f600bfb0c093"",  WWW-Authenticate: Digest  digestAuthentication opaque=""5ccc069c403ebaf9f0171e9517f40e41""  http://code.google.com/p/android/issues/detail?id=11140 ",okhttp,1
set getConf value1 FOO conf asList reconfigurable assertNull reconfigureProperty testConfIsUnset newConf get property Arrays makeReconfigurable ,hadoop,0
"r2 getName output test.*.source.filter.exclude getTestFilename Test putMetrics  When we call stop, at most two sources will be consumed by each sink thread. s0 s1 add checkMetricsRecords ms getAllValues capture test.sink.test.class mr2 mr1 s1 desc stop size *.period TestMetricsConfig test.sink.sink1.metric.filter.exclude mock shutdown s0rec  publish the metrics test.sink.sink2.metric.filter.exclude save test.source.s1.metric.filter.exclude X* verify atMost sink2 desc hadoop-metrics2-test s1rec set registerSink incr start sink1 desc assertEquals Y* s0 desc testInitFirstVerifyStopInvokedImmediately sink2 sink1 publishMetricsNow register r1 ",hadoop,1
testFsFailover reader LocalOozie conf source isActive getStatus getTestGroup getPath create action workflow.xml waitFor wfClient getFileSystem actionStartCommand failover-fs-wf.xml FaultInjection OozieClient size WorkflowAction StartActionExecutor getType copyCharStream setProperty mkdirs getResourceAsReader true createConfiguration evaluate actions submit fsfailover-source fsfailover-target getJobInfo assertFalse getId wf jobId2 jobId1 get WorkflowJob getActionsForWorkflow toUri start false assertEquals getClient store SkipCommitFaultInjection target call Services IOUtils getTestUser org.apache.oozie.command.SkipCommitFaultInjection setSystemProperty exists toString writer getFsTestCaseDir ,oozie,1
"<property><name>hello</name><value>world</value></property> foo assertFalse conf hello, meh bar world getErrorCode assertTrue get verifyParameters </parameters></root> XmlUtils <property><name>foo</name><value>bar</value></property> parseXml getMessage assertEquals <root xmlns=""uri:oozie:workflow:0.4""><parameters> str 1 fail contains 2 ex size <property><name>hello</name></property> endsWith ParameterVerifier ErrorCode <property><name>meh</name></property> testVerifyParametersMissing ",oozie,1
getId assertEquals getStatus execute addRecordToCoordJobTable call CoordinatorJob Services coordJobGetCmd assertNotNull get testCoordSuspendWithErrorPostive2 job jpaService ,oozie,1
request acls assertFalse foo sendError conf when getAttribute Assert testHasAdministratorAccess assertTrue context verify HttpServer2  authorization ON & user NOT NULL & ACLs NULL CommonConfigurationKeys thenReturn  authorization OFF anyString HttpServletResponse eq any  authorization ON & user NULL  authorization ON & user NOT NULL & ACLs NOT NULL & user not in ACLs Mockito getRemoteUser response hasAdministratorAccess isUserAllowed mock  authorization ON & user NOT NULL & ACLs NOT NULL & user in in ACLs setBoolean ,hadoop,0
abc %7hello abc llo abc Hel abc %.3hello head result abc 123  abc Hell compile abc Hello   converterMap context setContext write abc   Hello abc %4.5OTT abc  123 abc %-4.5OTT abc %3.4hello assertEquals parse testFormat abc %.-3hello p t abc %-7hello abc %-3.-4hello abc ello ,logback,0
"jsonDocument thenReturn format bodyParserEngineJson equalTo testForm is invoke {""firstName"":""%s"", ""lastName"":""%s""} String jsonObjMapper assertThat getInputStream when getBytes Mockito assertTrue context BodyParserEngineJsonTest close testJsonBodyWithMissingVariables ",ninja,0
"getName dst  0 Foot chunks CodecTestUtils channel er1: abcde Footer2: f convert key=""value"" Assert ghij   inbuf 123456789012345612345abcdef assertTrue get  123456789012345 testIncompleteChunkDecoding isCompleted 345 6 read  abcdef fghij StandardCharsets Footer1 hasRemaining abcde Footer2 clear bytesRead assertEquals decoder ByteBuffer trailers 6 5 12 getValue allocate size metrics 10; getTrailers ",httpcore,0
server logger assertFalse addInitRecords Logger testLogMessagePrefix out default addAppender assertTrue tablename newHCatDependency ] table populateTable hcat:// getLogger appender ACTION[ / layout call actionId2 actionId1 contains /dt=20120430;country=brazil reset toString db ,oozie,1
Workflow Job 5 should have been purged addRecordToWfActionTable Workflow Action 2 should have been purged Coordinator Action 3 should have been purged WorkflowInstance getStatus addRecordToCoordActionTable wfAction5GetCmd wfJob5GetCmd wfAction1GetCmd coordAction4GetCmd coordAction3 coordAction4 assertNotNull coordAction5 CoordinatorAction wfJob2GetCmd coordAction1 Workflow Action 5 should have been purged testPurgeCoordWithWFChild3MoreThanLimit coordAction2 wfJob1GetCmd execute Coordinator Action 5 should have been purged Workflow Job 2 should have been purged CoordinatorJob 1 coordJobGetCmd fail WorkflowAction coordAction3GetCmd SUCCEEDED wfAction2GetCmd Coordinator Action 2 should have been purged Workflow Action 3 should have been purged je Workflow Job 1 should have been purged getId coordAction5GetCmd Workflow Job 4 should have been purged coordJob wfJob1 wfJob3 wfJob4GetCmd addRecordToWfJobTable wfJob2 getErrorCode wfJob5 get wfJob4 coordAction2GetCmd Workflow Action 1 should have been purged WorkflowJob wfAction3GetCmd Coordinator Action 4 should have been purged wfAction4GetCmd Coordinator Job should have been purged coordAction1GetCmd Workflow Action 4 should have been purged assertEquals Coordinator Action 1 should have been purged wfAction1 wfAction2 addRecordToCoordJobTable wfAction3 wfAction4 wfAction5 call Services wfJob3GetCmd coord-action-get.xml ErrorCode jpaService Workflow Job 3 should have been purged ,oozie,1
subwfJobGetCmd addRecordToWfActionTable coordActionGetCmd getId getNumDaysToNotBePurged WorkflowInstance getStatus addRecordToCoordActionTable SubWorkflow Job should not have been purged coordJob SubWorkflow Action should not have been purged wfJob getEndTime addRecordToWfJobTable assertNotNull get Workflow Job should not have been purged CoordinatorAction WorkflowJob wfAction subwfAction wfJobGetCmd wfActionGetCmd Coordinator Action should not have been purged assertEquals execute addRecordToCoordJobTable subwfActionGetCmd Coordinator Job should not have been purged call Services CoordinatorJob 1 coordJobGetCmd fail coord-action-get.xml testPurgeCoordWithWFChildWithSubWF2 WorkflowAction coordAction SUCCEEDED subwfJob jpaService Workflow Action should not have been purged ,oozie,1
"fs.defaultFS Resource string returned for an unset property must  sources conf fs.defaultFoo Resource string returned for a file-loaded property appendProperty out assertArrayEquals CONFIG bar testPropertySource addResource value set Resource string returned for a set() property must be  ""programmatically""  must be a proper absolute path programmatically endConfig startConfig assertEquals getPropertySources be null fileResource test.foo ",hadoop,0
cluster  Failover by session expiration ====== Restarting server ====== Failing over by session expiration HAServiceState waitForServerDown hostPort waitForServerUp  Graceful failovers info LOG  Failover by bad health stopServer CONNECTION_TIMEOUT start waitForHealthState gracefulFailoverToYou getZkfc testOneOfEverything setHealthy waitForHAState stop startServer State  Restart ZK expireAndVerifyFailover ,hadoop,1
new_val scriptExecutor SELECT * FROM entitywithstaticcolumn WHERE id =  EntityWithStaticColumn/insert_single_row.cql session  Given should_insert_static UUIDs uuid crud new_static  When of id value static_col executeScriptTemplate isNotNull val actual RandomUtils manager one timeBased getString nextLong assertThat execute ImmutableMap  Then Long updateStatic isEqualTo entity ,achilles,1
 Both expired period and MaxInActiveInterval are not reached. expires TOKEN_MAX_INACTIVE_INTERVAL testDoFilterAuthenticationAuthorized _testDoFilterAuthenticationMaxInactiveInterval TOKEN_VALIDITY_SEC currentTimeMillis authorized maxInactives System ,hadoop,0
play ping  play it back  This ping will not be returned.  verify the peer received what was expected assertEquals acceptFrame sendFrame peer SPDY3  write the mocking script ping4 unexpectedPingIsNotReturned  PING connection ping2 takeFrame ,okhttp,1
renderable testServeStaticNormalOperationModifiedNoCaching  make sure we get the correct result... assetsController when resultCaptor Result result  check etag has been called mimeTypes getRenderable addEtag responseStreams  make sure the content is okay... verify testasset ok render result2 serveStatic finalizeHeadersWithoutFlashAndSessionCookie byteArrayOutputStream thenReturn anyString capture  we mocked this one: assertEquals contextRenderable eq /assets/testasset.txt httpCacheToolkit getValue getStatusCode Results Mockito anyLong getContentType mimetype getOutputStream toString getRequestPath ,ninja,0
request testMostPopular assertEquals target accept LIST_ID_COUNT_TYPE getValue Assert top size assertTrue get MediaType /mostActiveUsers thisCount ,oryx,1
getJobTrackerUri map-reduce  Assert Mapred job name has been set conf getStatus createContext getJob  hadoop.counters will always be set in case of MR action. output Counter mapred.job.name getExecutionStats assertNotNull <map-reduce> context create write waitFor <job-tracker> mapredJobName MapReduceLauncherTest ae counters getJobName parseXml </job-tracker> dummy  getFileSystem check <name-node>  Assert for stats info stored in the context. </name-node> input contains WorkflowAction SUCCEEDED submitAction testSetMapredJobName getExternalChildIDs data.txt evaluate JobID launcherId Launcher job name:  Mapred job name:   External Child IDs will always be null in case of MR action. assertFalse user.name getExternalId fs mrConfig hasIdSwap System createBaseHadoopConf sb actionXml isSuccessful assertTrue LauncherMapper MapReduceTest get end  Assert launcher job name has been set close getMapReduceConfig getData getNameNodeUri outputDir launcherJob set XmlUtils forName getAction assertEquals mrJob hadoop.counters inputDir getExternalStatus </map-reduce> oozie.launcher.mapred.job.name Services createJobClient assertNull launcherJobName w toXmlString equals getVar toString jobClient user append getFsTestCaseDir isComplete ,oozie,1
computeSlashCount slashCount fileNamePattern maxHistory expectDirMax dailyRolloverWithCronologPattern simulatedNumberOfPeriods cp expectedDirMin randomOutputDir /%d{ expectedFileAndDirCount }/clean.txt.zip logOverMultiplePeriods DAILY_CRONOLOG_DATE_PATTERN ,logback,0
testCloseExpired getStats release closeExpired sleep Assert updateExpiry assertTrue stats assertNotNull get of TimeUnit verify close entry2 TimeValue getLeased conn2 entry1 conn1 assignConnection ArgumentMatchers somehost pool assertEquals totals isDone any Thread never future1 future2 Mockito CloseMode mock lease getPending getTotalStats getAvailable ,httpcore,0
p1 p2 p3 getName p4 getKMSUrl  This should be retried conf  Exceptions other than IOExceptions will not be retried when test1 assertTrue testLoadBalancingWithFailure thenThrow  This should not be retried Should fail since its not an IOException kp e anyString thenReturn createKey assertEquals any test4 fail test2 test3 Mockito  IOException will trigger retry in next provider mock v1 v3 ,hadoop,0
setHandler conn  user foo  user ok-user via proxyuser foo run /bar HttpURLConnection Assert /foo/bar FOO_USER ugi of get testHttpUGI context readLines jetty /* DispatcherType getJettyURL UserGroupInformation ret /foo aUrl OK_USER addServlet remoteuser= openConnection EnumSet start :ugi= setContextPath assertEquals createJettyServer createRemoteUser getInputStream url realugi= token IOUtils doAs stop size getResponseCode addFilter :remoteuser= ,hadoop,0
"1.1.1.1 2.2.2.2, 3.3.3.3 set ProxyUsers 3.3.3.3 refreshSuperUserGroupsConfiguration assertFalse conf isProxyServer 2.2.2.2 ProxyServers assertTrue testProxyServer ",hadoop,0
"java.naming.provider.url#tcp://broker.${2}:61616 http://unknown:9999/fs conf server2 server1 server3 HCatAccessorService get getJNDIPropertiesString java.naming.factory.initial#org.apache.activemq.jndi.ActiveMQInitialContextFactory;  rules will be applied hcat://xyz.corp.dummy.com=java.naming.factory.initial#Dummy.Factory; init set hcat://hcatserver.blue.server.com:8020 getJMSConnectionInfo getConf hcat://xyz.corp.dummy.com hcatService java.naming.provider.url#vm://localhost?broker.persistent=false destroy assertEquals testGetJMSConnectionInfo services hcat://${1}.${2}.server.com:8020=java.naming.factory.initial#Dummy.Factory; , java.naming.provider.url#tcp:localhost:61616 connInfo java.naming.factory.initial#Dummy.Factory;java.naming.provider.url#tcp:localhost:61616 setupServicesForHCatalog jmsConnectionURL  will map to default java.naming.factory.initial#Dummy.Factory;java.naming.provider.url#tcp://broker.blue:61616 default=java.naming.factory.initial#org.apache.activemq.jndi.ActiveMQInitialContextFactory; ",oozie,1
srowen@example.org doTest mailto:bob@example.org?cc=foo@example.org&bcc=srowen@example.org&subject=baz&body=buzz foo@example.org testAll baz buzz bob@example.org ,zxing,0
PREP getId WorkflowInstance actionGetCmd coordJob wfBean addRecordToWfJobTable assertNotNull get  Add two jobs to update list WorkflowJob Job testBulkInsertUpdates updateList add getStatusStr insertList RUNNING wfGetCmd assertEquals  Add two actions to insert list execute addRecordToCoordJobTable setStatus CoordinatorJob 1 Services 2 WorkflowAction bulkUpdateCmd SUCCEEDED createWorkflowAction action1 job action2 jpaService ,oozie,1
call testActionStartCommand checkCoordAction mytoken getTime addRecordToActionTable me actionId myjob -COORD-ActionStartCommand-C@1 myapp ,oozie,1
fail test5ByteUtf8Sequence UTF8 invalid GenericTestUtils assertExceptionContains fromBytes did not throw an exception Invalid UTF8 at f88880808004 utfde ,hadoop,0
40 12345678901234561234567890123456 dst compact CodecTestUtils channel 10 1234567890123456  convert put Assert inbuf assertTrue tmp flip isCompleted read testReadingWitSmallBuffer 1234567890123456 StandardCharsets hasRemaining bytesRead assertEquals decoder ByteBuffer 12345678901234561234567890123456 allocate metrics 12345678901234561234567890123456 0  ,httpcore,0
setAnInteger setAnInt innocent smoke back assertEquals writeAndRead setaString ,logback,0
setFuture  ms assertFalse source Executors srcUpdater sleep updaterFuture test JMX cache update race condition Hit error get readerExecutor TimeUnit awaitTermination injectedTags shutdownNow newSourceBuilder  JMX cache. scheduleAtFixedRate test sourceBuilder newScheduledThreadPool  called.  set JMX info cache at the beginning testMetricCacheUpdateRace getJmxCacheTTL Thread srcReader  cleanup  Create test source with a single metric counter of value 1. build  Let the threads do their work. MetricsAnnotations readerFuture sourceAdapter hasError JMX_CACHE_TTL RACE_TEST_RUNTIME updaterExecutor ,hadoop,0
 call POST MyJsonRestServlet GET HttpServletResponse invoke assertEquals testMultipleResources /resource1 /resource2 runTest ,oozie,1
"getConfString <property><name>NAME</name><value>${coord:name()}</value></property> <configuration><property><name>inputA</name><value>${coord:dataIn('A')}</value></property> CoordELFunctions </configuration></workflow></action> <property><name>ACTIONID</name><value>${coord:actionId()}</value></property> conf <coordinator-app name=""mycoordinator-app"" start=""2009-02-01T01:00GMT"" end=""2009-02-03T23:59GMT"" timezone=""UTC"" createDataEvaluator <property><name>ACTIONID</name><value>00000-oozie-C@1</value></property> evalAndWrap testCreateDataEvaluator <uri-template>file:///tmp/coord/US/${YEAR}/${MONTH}/${DAY}</uri-template></dataset></data-in></input-events> <property><name>NAME</name><value>mycoordinator-app</value></property>  frequency=""720"" freq_timeunit=""MINUTE"" action reply <dataset name=""a"" frequency=""1440"" initial-instance=""2009-01-01T00:00Z""> CoordELEvaluator prettyPrint XmlUtils getChild parseXml assertEquals <property><name>ACTUALTIME</name><value>${coord:actualTime()}</value></property> <configuration><property><name>inputA</name><value>file:///tmp/coord/US/2009/1/30|file:///tmp/coord/US/2009/1/31</value></property> str jobXml  action-nominal-time='2009-09-01T00:00Z' action-actual-time='2010-10-01T00:00Z'> </configuration></workflow></action></coordinator-app> eval <property><name>ACTUALTIME</name><value>2010-10-01T00:00Z</value></property> getNamespace <input-events><data-in name=""A"" dataset=""a""><uris>file:///tmp/coord/US/2009/1/30|file:///tmp/coord/US/2009/1/31</uris> eJob toString <property><name>NOMINALTIME</name><value>2009-09-01T00:00Z</value></property> <action><workflow><url>http://foobar.com:8080/oozie</url><app-path>hdfs://foobarfoobar.com:9000/usr/tucu/mywf</app-path> <property><name>NOMINALTIME</name><value>${coord:nominalTime()}</value></property> 00000-oozie-C@1 ",oozie,1
All is well Asserts check testExpressionCheckPass ,httpcore,0
"<property><name>hello</name><value>world</value></property> set XmlUtils planet parseXml conf assertEquals <root xmlns=""uri:oozie:workflow:0.4""><parameters> str testVerifyParametersDefined size <property><name>hello</name></property> get ParameterVerifier verifyParameters </parameters></root> ",oozie,1
"request handler assertFalse  Try get a new token using the fetched token, should get 401. getMethod when tokenStr Assert verify testCannotGetTokenUsingToken op pwriter thenReturn & DelegationTokenAuthenticator getQueryString HttpServletResponse setStatus managementOperation Mockito response getWriter getToken mock reset getHttpMethod toString writer = ",hadoop,0
getId run assertEquals getStatus addRecordToCoordActionTable execute addRecordToCoordJobTable coordGetCmd testCoordStatusTransitServiceTransitionToDoneWithError coordJob sleep CoordinatorJob Services runnable coord-action-get.xml get CoordinatorAction job jpaService ,oozie,1
cluster test2.dat test1.dat getModificationTime conf createFile waitActive Creating testdir2  getFileStatus mdir2 mdir1 info newfile localhost   Deleting testdir2/testnew.dat. mtime1 datanodeReport getFileSystem Moving  blockSize Creating testdir1 and testdir1/test1.dat. fileSize numDataNodes mkdirs fileSys getNameNodePort testnew.dat printDatanodeReport shutdown seed delete System Creating testdir1/test2.dat. testModTime testdir2/ assertTrue client numDatanodes addr close cleanupFile DFSTestUtil stat e replicas assertEquals dir2 dir1 build  to  rename makeQualified file2 testdir1 Number of Datanodes  file1 DatanodeReportType ,hadoop,1
uri:oozie:workflow:0.3 uri:oozie:coordinator:0.3 uri:oozie:bundle:0.3 uri:oozie:workflow:0.4 uri:oozie:bundle:0.2 uri:oozie:workflow:0.5 uri:oozie:coordinator:0.5 uri:oozie:bundle:0.1 assertFalse uri:oozie:coordinator:0.4 foo supportsParameters assertTrue ParameterVerifier uri:oozie:foo:0.4 testSupportsParameters ,oozie,1
next  then buildRoute equalTo getFilterChain when filterChain result get context getProvider injector  when testWithFiltersClass  given thenReturn dummyFilter filterProvider filters Matchers assertThat / with route Mockito expectedResult GET mock routeBuilder ,ninja,0
bundleJobGetExecutor addRecordToBundleActionTable getId getStatus assertNotNull get Job init false addRecordToBundleJobTable destroy assertEquals testBundleRerunInSuspendedWithError services execute addRecordToCoordJobTable call Services CoordinatorJob setSystemProperty StatusTransitService action1 job action2 jpaService ,oozie,1
cluster shutdownDfs  do a sync flush. testScanAndSyncFlush e LOG Failed getLog count HConstants assertEquals error Added:  addContent closeAndDelete createNewHRegion Bytes r getTableDesc REGION_INFO toString close hri info ,hadoop,1
init ${HOUR} ${YEAR} CoordELFunctions ${MINUTE} assertEquals should throw exception beacuse coord-job-submit-freq doesn't resolve YEAR/MONTH/DAY ${DAY} testURIVars fail eval evalAndWrap expr       * public void testSetup() throws Exception { services = new Services();      * services.init(); }       coord-job-submit-freq coord-job-submit-nofuncs ${MONTH} ,oozie,1
java.version EnvUtil assertTrue setProperty assertFalse 1.5 isJDK6OrHigher isJDK5 testJava1_5 System isJDK7OrHigher ,logback,0
"randomOutputDir: periodDurationInMillis RollingCalendar simulatedNumberOfPeriods diffInMonths System start: get MONTHS_IN_YEAR }/clean.txt.zip startTime startTimeAsCalendar expectedCountWithFolders computeSlashCount withExtraFolder checkFileCount MONTHLY_CRONOLOG_DATE_PATTERN fileNamePattern Calendar maxHistory differenceInMonths: cp currentTime extraFolder  with success. , end= indexOfStartPeriod differenceInMonths setTimeInMillis monthlyRolloverOverManyPeriods randomOutputDir /%d{ MILLIS_IN_MONTH logOverMultiplePeriods endTime getInstance ",logback,0
createMultiPartEmailWithContent getSubject replyTo2@domain mail subject MailImplTestHelper getReplyToAddresses replyTo1@domain getToAddresses assertTrue commonsmailHelper getMailImplWithDemoContent multiPartEmail to1@domain getBccAddresses assertEquals from1@domain cc1@domain getCcAddresses testDoPopulateMultipartMailWithContent contains getFromAddress bcc1@domain bcc2@domain doConvertAdressesToInternetAddressList to2@domain doPopulateMultipartMailWithContent ,ninja,0
date NotEq ALL should_delete_with_not_equal_condition scriptExecutor session  Given simple withLwtResultListener Eq delete SELECT * FROM simple WHERE id =  asList lwtResultListener  When of get where id getAndSet row table executeScriptTemplate onError RandomUtils manager allColumns_FromBaseTable one nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap if_ConsistencyList isTrue success  Then isNull Long buildDateKey Arrays dsl onSuccess ,achilles,1
handler request getTime jwt alternateAuthentication should have thrown an AuthenticationException publicKey setPublicKey JWTRedirectAuthenticationHandler when remove alternateAuthentication should NOT have thrown a AuthenticationException se SERVICE_URL assertTrue getCookies getJWT testNoProviderURLJWT Authentication provider URL must not be null getRequestURL init cookie thenReturn getProperties hadoop-jwt encodeRedirectURL getMessage alternateAuthenticate props token fail privateKey serialize contains bob Mockito response mock ,hadoop,0
"cluster getMaxBlockAcquireFailures conf when createFile waitActive  then fail some more on another read, it shouldn't fail.  Set short retry timeout so this test runs faster  If we fail exactly that many times, then it should succeed. readFully First read successful after some failures. info DFSConfigKeys anyString is getFileSystem setInt preSpyNN fail Got expected exception fileSize anyLong  the block info won't do anything. spy shutdown getBlockLocations maxBlockAcquires testFailuresArePerOperation fs seek doAnswer file assertTrue  fail. client copyBytes DFSClient DFSTestUtil Didn't get exception Starting test case for failure reset  we're starting a new operation on the user level. getNameNodeRpc /testFile IOUtils buf build spyNN toString ioe open openInfo ",hadoop,1
headerAnnotatedArgumentShouldBePassed thenReturn context header create verify invoke value when param1 mockController getHeader ,ninja,0
 uuidParamParser getParsedType parseParameter asdfasdf is Matchers assertThat nullValue param1 fe45481f-ed31-40e4-9bca-9cec383302c2 fromString UUID testUUIDParamParser validation ,ninja,0
tfs /0 clients getClientsTest mTfs ls assertEquals mLocalTachyonClusterMultiMaster getClient k createFile / Assert size get files ,alluxio,1
play A server readAscii request GET /?query HTTP/1.1 getHostName takeRequest  http://b/4361656 assertEquals setBody getInputStream url urlContainsQueryButNoPath Integer enqueue getRequestLine getPort http ?query client open ,okhttp,1
"+15551212 foo bar testSMS sms:+15551212 +15551212 sms:+15551212;via=999333 +15551212 +12124440101 ParsedResultType SMS:+15551212 doTestResult sms:+15551212,+12124440101 sms:+15551212?subject=foo&body=bar ",zxing,0
"APP getTestCaseConfDir getLog ls   doStreamDisabledCheck 2009-06-24 02:43:14,505 INFO _L4_:317 USER[blah] GROUP[oozie] TOKEN[-] APP[-] JOB[-]  split _L4_ doStreamLog  Lines 2 and 4 are filtered out because they have the wrong user JOB TOKEN info ACTION[-] Released Lock test-log4j.properties init currentThread test-no-dash-log4j.properties outArr setLogLevel destroy is contains _L3_ getContextClassLoader reset log4jFile DEBUG|INFO assertFalse out GROUP assertTrue _L2_ defineParameter setParameter 2009-06-24 02:43:14,505 INFO _L3_:317 USER[oozie] GROUP[oozie] TOKEN[-] APP[-] JOB[-]  2009-06-24 02:43:14,505 INFO _L2_:317 - USER[blah] GROUP[oozie] TOKEN[-] APP[-] JOB[-]  a 2009-06-24 02:43:14,505 INFO _L1_:317 - USER[oozie] GROUP[oozie] TOKEN[-] APP[-] JOB[-]  XLogService oozie getResourceAsStream XLogStreamer cl assertEquals USER xf Thread LogFactory IOUtils ACTION testNoDashInConversionPattern copyStream setSystemProperty _L1_  checks that this condition is no longer required for log streaming to work ",oozie,1
wf-schema-invalid-global-ext-no-global.xml validateAndParse testParserGlobalExtensionActionsNoGlobal  or the handleGlobal() method will throw an exception assertEquals fail IOUtils ex parser getErrorCode getResourceAsReader ErrorCode wf-schema-valid-global-ext-no-global.xml ,oozie,1
 A conn setRequestMethod POST error put setRequestProperty content-type id Collections ok runTest a RestConstants testCallbackPost openConnection UTF-8 unchecked MockDagEngineService HttpServletResponse assertEquals store params url props call getResponseCode setProperty /callback reset createURL getOutputStream status setDoOutput ,oozie,1
 testClear Underlying byte array length must be zero clear Actual string on an empty text object must be an empty string assertEquals  Test if clear works as intended abcdâ‚¬bdcdâ‚¬ getBytes Length of the string must be reset to 0 after clear() len assertTrue String's length must be zero getLength toString String must be empty after clear() Length of the byte array must not decrease after clear() text  Test lengths on an empty text object ,hadoop,0
"checkCoordJobs <coordinator-app name=""NAME"" frequency=""10"" start=""2009-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""  conf appPath substring sc writeToFile appXml file:// getTestCaseDir UNIT_TESTING <controls> <timeout>10</timeout> <concurrency>2</concurrency>  xmlns=""uri:oozie:coordinator:0.2"">  <configuration> <property> <name>inputA</name> <value>blah</value> </property>  coordinator.xml testSubmitNoDatasets set length assertEquals </configuration> </workflow> </action> </coordinator-app> call OozieClient jobId getTestUser -C <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>  File <execution>LIFO</execution> </controls>  ",oozie,1
next getSubject  concurrent getCurrentUser on ugi1 should not be blocked. getCurrentUser blockingLookup getName  unblock the original call. submit  wait for the thread to block on the barrier in getCurrentUser. testUgi2 testUgi1 principals run newSingleThreadExecutor Executors when remove iterator barrier ugi get await latch countDown UserGroupInformation add callRealMethod  concurrent getCurrentUser on ugi2 should not be blocked. getPrincipals testConcurrentGetCurrentUser createRemoteUser assertSame  workaround this by swapping out the spy with the original User.  concurrent.  Ie. no synchronization. call invocation doAs answer Mockito  spy is called for the user name. spyUser thenAnswer user spy ,hadoop,0
"newHashMap index  router.GET().route(""/user/{id}/{email}/userDashboard"").with(ApplicationController.class, ""userDashboard""); assertEquals put / myEmail /user/myId/myEmail/userDashboard router userDashboard Maps startServer myId testReverseRoutingWithMap  TEST 1: a simple route without replacements: generatedReverseRoute getReverseRoute id map email ",ninja,1
input node transform nodeToStringTransformer propertyContainer0 ${k0} makeNode variable v0 assertEquals ,logback,0
"date scriptExecutor AND date = '2015-10-01 00:00:00+0000' session LOCAL_ONE  Given update simple Eq consistencyList_RemoveFrom consistencylist containsExactly QUORUM should_dsl_update_list_remove_single  When getList of where id row table executeScriptTemplate RandomUtils manager one nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap UPDATE simple SET consistencylist = consistencylist + ['QUORUM', 'QUORUM'] WHERE id =  SELECT consistencylist FROM simple WHERE id =   Then Long buildDateKey fromBaseTable consistencyList dsl ",achilles,1
add org.springframework.boot grabAnnotations 1.2.3 assertGrabAnnotation size get assertEquals annotationNode nonTransitiveAdd getAnnotations spring-boot-starter-logging ,spring-boot,1
" testData line nextBufferHeadToken  char 'a' as a filler for the test string replace getBytes </entity><entity><id>Gelesh</ currentBufferTailToken Assert testCustomDelimiter1 delimiter fillBuffer </entity> lineReader id><name>Omathil</name></entity> close numberOfCharToFillTheBuffer  Supposing the start of next buffer is this  It contains '</' ie delimiter character testPartOfInput fillerString StandardCharsets expected length assertEquals fill readLine  Expected must capture from both the buffer, excluding Delimiter toString Arrays bufferSize ",hadoop,0
testSingleCellGetJSON ROW_4 toBytes MIMETYPE_JSON assertEquals put / Thread TABLE path Bytes deleteRow COLUMN_1 MIMETYPE_BINARY response yield get client getCode VALUE_4 ,hadoop,1
cluster nameNodePort  create cluster conf testFileCreationDeleteParent:  fs System createFile waitActive  This ensures that leases are persisted in fsimage. sleep hflush assertTrue ipc.client.connection.maxidletime close writeFile newfile  2s DFSConfigKeys format  create file1. Created file  dir2 getFileSystem dir1 TestFileCreation setInt Thread  persistent leases from fsimage. checkFullFile MAX_IDLE_TIME testWhileOpenRenameToNonExistentDirectory dfs.support.append stm1 build /user/dir1 rename nnport /user/dir2 /user getNameNodePort exists file1 Test 4************************************ shutdown setBoolean ,hadoop,1
a A b B set size testSize conf assertEquals ,hadoop,0
"/blah/my.id/myname entrySet buildRoute assertFalse getPathParametersEncoded assertEquals my.id  and another slightly different route routeFromServer matches route size assertTrue GET get  the ""."" in the route should not make any trouble: routeBuilder /blah/{id}/myname id /blah/my.id/myname/should_not_match pointsInRegexDontCrashRegexInTheMiddleOfTheRoute ",ninja,0
conn setRequestMethod IS_SECURITY_ENABLED getId put bundleJobBean /v1/job/* id Job runTest MockCoordinatorEngineService RestConstants openConnection addRecordToBundleJobTable HttpServletResponse assertEquals params url call xDataTestCase GET getResponseCode reset createURL testBundleEngineStreamLog ,oozie,1
testJvmMetricsSingletonWithSameProcessName Assert test jvmMetrics1 initSingleton should return the singleton instance jvmMetrics2 assertEquals initSingleton ,hadoop,0
getClass getName test12 test11 testNested s211 test0 test1 result s11 s12 assertTrue context outputStream s0 s1 s2 add + INFO in  test22 StatusPrinter test21 + WARN in      |-WARN in  test2 s22 print contains s21 test211 toString getStatusManager ,logback,0
args  getProperty testArgsParsing foo user.name 12345 assertEquals :12345 foo:2222 System ,hadoop,0
 Setting total failover attempts to . p1 p2 testClientRetriesNonIdempotentOpWithIOExceptionFailsImmediately p3 getKMSUrl conf when times assertTrue verify thenThrow test kp e anyString thenReturn getProviders keyName createKey eq any setInt CommonConfigurationKeysPublic fail Mockito mock Should fail since all providers threw an IOException ,hadoop,0
 the match calls a player event on it's deactivation getMatchEventCount 1000 createStage machEventCount  touching the player to prevent it's deactivation; addPlayer get client TimeUnit toMillis getReference assertNotEquals player incrementTimeMillis createClient deactivationTest intValue match assertEquals clock 101 stage cleanup IActor  moving the time ahead ,orbit,1
handler init kn destroy getRealm assertEquals KerberosTestUtils KerberosName remove props KerberosAuthenticationHandler getRuleMechanism Assert getNewAuthenticationHandler setRuleMechanism getServerPrincipal MIT getDefaultProperties getRules setRules DEFAULT  destroy handler created in setUp() testNullProperties ,hadoop,0
testCopyOnWrite cluster getLocalBlock conf dn getFile createFile simulatedStorage .link getNamenode HardLink unlinkBlock localhost   testCopyOnWrite detaching block  getBlockPoolId getFileSystem stm size Long getNameNodePort SimulatedFSDataset shutdown createHardLink /filestatus.dat getBlockLocations getLocatedBlocks link fs System  should have returned true assertTrue listDataNodes get  should have returned false client addr close writeFile getBlock b blocks f AppendTestUtil  Get a handle to the datanode build  to  Creating hardlink for File  toString locations file1 There should be only one datanode but found  Detaching block  dataset setBoolean ,hadoop,1
hostname getDefaultHost assertNotNull DNS testGetLocalHost DEFAULT ,hadoop,0
cache No implementation for ninja.cache.Cache was bound e thenReturn NinjaConstant containsString getInjector getMessage bootstrap assertThat cache should not have been found when fail NinjaMode com.example.frameworkmodule frameworkModuleSkipsNinjaClassicModule ninjaPropertiesImpl Mockito get getInstance boot spy ,ninja,0
date testBodyParser integerPrimitive CoreMatchers equalTo 3000 invoke when put 4.567 dateTimeString context 1.234 validation characterPrimitive aString somethingElseWhatShouldBeSkipped thenReturn  some setup for this method: 2000 longObject  do assertThat 2014-10-10T20:09:10 2014-10-10 characterObject floatPrimitive string  and test: bodyParserEnginePost getValidation assertFalse 1000 hasViolations testObject doublePrimitive map timestamp a b 4000 integerObject toDate dateString floatObject 2.345 Mockito longPrimitive getParameters doubleObject 3.456 ,ninja,0
session  Given update Eq Incr  When where id isNotNull should_dsl_update actual RandomUtils manager incr one count nextLong assertThat execute getLong  Then Long SELECT count FROM entity_counter WHERE id =  fromBaseTable dsl isEqualTo ,achilles,1
 Type info bits = 100000011001110. MatrixUtil expected  1 0 0 0 0 0   0 1         1 1 0 0 1 1 1 0  assertEquals                  0                          matrix                  1                                                                      clearMatrix toString ErrorCorrectionLevel embedTypeInfo testEmbedTypeInfo ,zxing,0
request HttpHeaders process getFirstHeader StandardCharsets interceptor Method setProtocolVersion getEntity whatever / setEntity testRequestExpectContinueHTTP10 Assert assertNull HttpCoreContext context create header HttpVersion ,httpcore,0
server  Check for timeout status and unregistered missing dependencies timeOutCreationTime checkCoordAction CoordELFunctions  timeout. assertFalse addInitRecords getWaitingActions System sleep default /dt=20120430;country=usa assertTrue testTimeOutWithException2 get CoordinatorAction tablename newHCatDependency  Test timeout when table containing missing dependencies is dropped in between table dropTable setCoordActionCreationTime newHCatDependency2 newHCatDependency1 hcatService e populateTable hcat:// getMessage pdms isRegisteredForNotification / Thread call Services fail contains assertNull currentTimeMillis /dt=20120430;country=brazil actionId NoSuchObjectException db ,oozie,1
shouldLog helper testLoggingWithInconsistentValues assertTrue record ,hadoop,0
coordJobBean coordActionGetCmd getCurrentDateafterIncrementingInMonths getId run DateUtils WorkflowInstance getStatus isPending addRecordToCoordActionTable parseDateOozieTZ coordJob wfJob wfBean addRecordToWfJobTable assertNotNull get CoordinatorAction end currentDatePlusMonth WorkflowJob waitFor KILLED getStatusStr RUNNING wfGetCmd start assertEquals XDataTestCase execute addRecordToCoordJobTable call Services CoordinatorJob coordJobGetCmd runnable wfJobId coord-action-get.xml coordAction equals  in following assertion not failing. testCoordStatusTransitServiceKilledByUser1 jpaService evaluate ,oozie,1
-start END_POINTS IS_SECURITY_ENABLED oozieUrl run containsValue testHeaderPropagation assertTrue OozieCLI SERVLET_CLASSES runTest RestConstants test getContextURL HeaderTestingVersionServlet containsKey clear MockDagEngineService assertEquals args call 1 -oozie setSystemProperty header job ,oozie,1
"dfs.random.key appendPropertyByTag dfs.replication getAllPropertiesByTag dfs.namenode.logging.level conf INFO getAllPropertiesByTags hadoop.tags.system add isPropertyTag containsKey endConfig getPropertySources 1 contains size CMYCUSTOMTAG2 fileResource Arrays YARN,HDFS,NAMENODE sources MYCUSTOMTAG getProps readAllLines appendProperty System out assertEq testGetAllPropertiesByTags assertTrue addResource get Paths hadoop.tags.custom Files close CONFIG_CORE core-site.xml false HDFS startConfig NAMENODE namenode.host YARN DEBUG tagList dfs.cblock.trace.io XYZ toString properties ",hadoop,0
" still works, but leaves the breadcrumb in place. cluster getZKFCProxy start setFailToFence GenericTestUtils conf waitForActiveLockHolder setFailToBecomeStandby getService testGracefulFailoverFailBecomingStandbyAndFailFence fail sfe Failover should have failed when old node wont fence gracefulFailover Unable to fence  assertExceptionContains ",hadoop,0
getJobTrackerUri getName <exec>sh</exec> createContext  Submit the action <capture-output /> context create action <argument>script.sh</argument> write waitFor <job-tracker> # ae ls -ltr echo var1=$var1 echo var2=$var2 </job-tracker> getFileSystem check script <name-node> </name-node> stringToProperties <file> submitAction  Checking action data from shell script output script.sh evaluate PropertiesUtils <argument>A</argument>  Wait for the external job to getAppPath  Create the script file with canned shell command fs <env-var>var2= <env-var>var1=val1</env-var> actionXml </env-var> <shell> </file> end var2 close getData a=b;c=d getNameNodeUri launcherJob  finish getProperty shellScript <argument>-c</argument> testEnvVar getAction assertEquals </shell> w <argument>B</argument> envValueHavingEqualSign  Create sample shell action xml toString isComplete ,oozie,1
"svc LOG hm HealthMonitor assertFalse waitForState isAlive Mocking RTE in health monitor, waiting for FAILED testHealthMonitorDies join throwOOMEOnCreate shutdown info ",hadoop,0
 /user/me@me.com/10000?q=froglegs thenReturn contextPath equalTo getContextPath assertThat when froglegs q router route id getReverseRoute ninjaProperties user me@me.com email getReverseRouteWithRegexAndQueryParametersWorks ,ninja,0
request conn getEndpointDetails User-Agent outStream when bind Assert flush testWriteRequestHead GET /stuff HTTP/1.1 User-Agent: test   /stuff getRequestCount addHeader test thenReturn StandardCharsets assertEquals Method Mockito toByteArray getOutputStream socket sendRequestHeader ,httpcore,0
"getName oozie.service.ProxyUserService.proxyuser.foo.groups foo conf asList bar Assert StringUtils assertNotNull testInvalidHost get join validate localhost init set oozie.service.ProxyUserService.proxyuser.foo.hosts getConf destroy * services , www.example.com Services fail ex proxyUser toString Arrays ",oozie,1
"(FEATURE_NAME, FEATURE_ENABLED, STRATEGY_ID, STRATEGY_PARAMS)  stateNoEntry UPDATE MYTABLE  WHERE FEATURE_NAME = 'F1' getStrategyId INSERT INTO MYTABLE  inserted stateEnabled foobar param assertNotNull SomeStrategy getParameter JDBCFeatures stateDisabled assertEquals VALUES ('F1', 1, 'SomeStrategy', 'param=foobar') testGetFeatureStateFromJDBCRepository getFeatureState FeatureContext featureManager size getFeatureManager isEnabled getParameterNames SET FEATURE_ENABLED = 0, STRATEGY_ID = NULL, STRATEGY_PARAMS = NULL  dataSource executeUpdate ",togglz,1
lookup testCompleted Assert build reg create RegistryBuilder assertEquals Stuff register stuff miss ,httpcore,0
currentContext assertEquals param3 param4 param1 param2 1 setAttribute 2 3 getAttribute Assert 4 parentContext testContextOperations removeAttribute ,httpcore,0
"getCoordAction addRecordToCoordJobTableForWaiting getMissingDependencies CoordELFunctions getId DateUtils parseDateOozieTZ get 2009-03-11T10:00Z coord-job-for-matd-hcat.xml startTime actionBean init destroy assertEquals services hcat://dummyhcat:1000/db1/table1/ds=2009-12 ${coord:latestRange(-1,0)} call file://dummyhdfs/2009/05/_SUCCESS Services CoordinatorJob @1 hcat://dummyhcat:1000/db3/table3/ds=2009-05 hcat://dummyhcat:1000/db3/table3/ds=2009-26 2009-03-06T010:00Z setupServicesForHCatalog testActionMaterForHcatalog CoordCommandUtils getPushMissingDependencies endTime job ",oozie,1
.. CreateFlag foo fqWd /existingDir  cd using a absolute path fqAbsoluteDir  Go back to our test root relativeDir /testWd Assert fileContextTestHelper  Try a URI assertTrue of absolutePath create workDir mkdir close getTestRootPath getParent testWorkingDirectory getWorkingDirectory EnumSet absoluteDir cd to non existing dir should have failed assertEquals LOCAL_FS_ROOT_URI  Now open a file relative to the wd we just set above. . setWorkingDirectory existingDir1 fail /test/existingDir2 newDir makeQualified file:///tmp/test fc FileContext  First we cd to our test root open  Now mkdir relative to the dir we cd'ed to nonexistingPath isDir ,hadoop,0
HADOOP_SHELL_MISSING_DEFAULT_FS_WARNING_KEY assertIllegalArguments chgrp enableWarning :gr#oup Group With Spaces conf run  The following are valid only on Windows.  The following are invalid (exception expected). setConf  The following are valid (no exception expected). :gr%oup testChgrpGroupValidity /path assertValidArgumentsOnWindows setBoolean group ,hadoop,0
"Negative test to test an exception. Should not be succeeding! testV1JobServlet Did not expect a generic exception. Was expecting XServletException testStartForErrorCode startJob getResourceName getMessage assertEquals xse  check for the error code and the message fail Invalid parameter value, [action] = [start] contains  should not get here! serial getErrorCode assertTrue -C ErrorCode ",oozie,1
".valid {color: red}  @mixin rounded($side, $radius: 10px) { border-#{$side}-radius: $radius; -moz-border-radius-#{$side}: $radius; -webkit-border-#{$side}-radius: $radius;}#navbar li { @include rounded(top); } shouldSucceedAfterAFailure fail process $base= #f938ab; sass processor Should have failed ",wroj4,1
result sleep setDaemon t future get start TimeUnit run completed testAsyncTimeout Thread ,httpcore,0
testNegativeCacheEntriesExpire  Put user1 in negative cache. assertFalse conf asList advance  Advance fake timer timer cacheGroupsAdd assertTrue getNegativeCache Did not throw IOException : Failed to obtain groups getGroups user1  can be added to negative cache user2 No groups found for user CommonConfigurationKeys e  Check if user2 exists in negative cache  Advance timer. Only user2 should be present in negative cache. groups refresh GenericTestUtils FakeGroupMapping  Put user2 in negative cache  Check if user1 exists in negative cache fail setLong  Ensure that stale entries are removed from negative cache every 2 seconds contains  Advance timer. Even user2 should not be present in negative cache. myGroups addToBlackList assertExceptionContains Arrays  from FakeGroupMapping. ,hadoop,0
next shutdownDfs ccc compare startrow getLog scan HConstants testStopRow Bytes assertTrue getTableDesc get REGION_INFO  Do simple test of getting one row only first. close results  Now do something a bit more imvolved. abd bbb abc toBytes count assertEquals kv  We got something back. addContent getRow closeAndDelete createNewHRegion r addFamily stoprow getScanner first ,hadoop,1
testCoordActionGet _E getCoordConf errorCode getId conf appPath setErrorCode resourceXmlName actionXml setErrorMessage coord  Pass the expected values CoordinatorAction action  Add extra attributes for action actionNum prettyPrint XmlUtils errorMessage XDataTestCase addRecordToCoordJobTable 000 CoordinatorJob _testGetForStartX createCoordAction coord-action-get.xml  Insert the action setSlaXml insertRecordCoordAction toString job getCoordActionXml Dummy getFsTestCaseDir ,oozie,1
g3 description c1 description description g2 name g4 name g4 description c2 name c2 description addCounter int counter int gauge float gauge builder verify MetricsLists info gauge g3 name registry c1 name test addGauge capture long gauge g1 assertEquals g2 counter g3 eq g4 c1 c2 getValue double gauge g1 name metric long counter name testCommon mock g2 description metrics visit visitor g1 description ,hadoop,0
container CallbackServlet ${d}${d} reader conf ${e}${e} getStatus /config-default.xml ${c}${c} getJob getTestCaseDir /workflow.xml file:// create workflow.xml waitFor ?jobId=$jobId&status=$status&nodeName=$nodeName bean AA external-status isEndState OozieClient copyCharStream getResourceAsReader /callback File evaluate BB B submitJob C getWorkflow end.error getWorkflowInstance writeXml testSubmit getId error wf T:null jobId1 getServletURL CCCCCCCC engine get OK ok WorkflowJob close wfConf CCCC CC a b set c os d getConf e f wf-ext-schema-valid.xml defaultConf assertEquals kill Services IOUtils getTestUser t signal-value writer ,oozie,1
result getInvocationCount testEventuallyOnceLambda eventually assertEquals retry ,hadoop,0
 cluster fileName datanode getRbwDir conf getSelfAddr createFile waitActive  get the block belonged to the created file writeBlock block storageDir  clean up the file writeByte startDataNodes getDataNodes getBlockPoolId  the temporary block & meta files should be deleted getNameNode  close the connection before sending the content of the block getInstanceStorageDir  write the header.  bring up a second datanode  then increase the file's replication factor getBlockLocations NameNodeAdapter sndNode  replicate the block to the second datanode bpid fs waitReplication delete out sleep flush get getAddress close listFiles Should only find 1 block BlockTokenSecretManager writeInt DFSTestUtil getBlock  replication should succeed MiniDFSCluster blocks /test.txt assertEquals dir2 dir1 setReplication  write check header target Thread fileLen getPort  create a file of replication factor of 1 toString getOutputStream BlockConstructionStage locatedBlockCount getNamesystem testReplicationError ,hadoop,1
EXIT_CONNECTIVITY_PROBLEM service assertInState Service setExitCode launchService assertEquals testAccessLaunchedService execute getService launcher ,hadoop,0
TimeUnit testFactory testFactoryForMillisseconds ,httpcore,0
customGrabMetadata.groovy grape.root System javax.ejb\:ejb-api=3.0 target target/repository/test/test/1.0.0 test-1.0.0.properties testArtifact assertTrue setProperty mkdirs customMetadata writer testArtifactDir createNewFile grab close --autoconfigure=false target/repository/javax/ejb/ejb-api/3.0 isDirectory ,spring-boot,1
toCharArray assertFalse length isEmpty clear assertEquals capacity b1 b2 Assert assertTrue 1234 assertNotNull tmp toString buffer isFull testSimpleAppend append charAt ,httpcore,0
appName2 assertEquals createFilterList list execute testGetSLAEventsForAppName filterListApp2 Services slaEventsGetCmd appname size assertNotNull get jpaService ,oozie,1
src/test/resources/tmp2.png f1 f2 delete src/test/resources/graphWF.xml ImageIO Not a valid PNG:  My Test App Assert assertTrue assertNotNull src/test/resources/tmp1.png setId testWrite png1 png2 write setAppName read e io g length getMessage fail src/test/resources/invalidGraphWF.xml jsonWFJob My Test ID readFile Write PNG failed for invalidGraphWF.xml:  Write PNG failed for graphWF.xml:   Check if a valid file was written src/test/resources/invalid.png ,oozie,1
 1 x 0 E:  Y: Z   E StandardCharsets testChunkedOutputStreamWithTrailers outbuffer assertEquals asList content out Assert get toByteArray Y Z finish outputStream Arrays write close ,httpcore,0
server addSuppressedLoggingExceptions logException verifyZeroInteractions te3 logger conf  Full stack trace should be logged for other exceptions.  Nothing should be logged for a suppressed exception. eq any addTerseExceptions call 0.0.0.0 times dummyCall testLogExceptions  No stack trace should be logged for a terse exception. mock verify info ,hadoop,0
"addNode def Expected to catch an exception but did not encounter any testForkJoinFailure three two getCause  Make sure the message contains the nodes involved in the invalid transition to end node [end] asList we invokeForkJoin getErrorCode assertTrue dummyConf end f one getMessage j assertEquals k kill node [three] fail contains        f->(2,3)       2->j       3->end      ex parser testWf <worklfow-app/> ErrorCode Arrays ",oozie,1
 ///////////////////////////////////////////////////////////////////// ninjaTestBrowser assertFalse contentcontent testGetAndPostArticleViaJson System  one new result: assertTrue new title new title api/bob@gmail.com/article.json articleDto getServerAddress doLogin response:  makeJsonRequest assertEquals getGsonWithLongToDateParsing api/bob@gmail.com/articles.json articlesDto Error. Forbidden. postJson contains size response fromJson ,ninja,1
"isMetaRegion getFilenum reader conf compareTo dir getRegionName tableName Bytes info add val   logSeqId getKey toBytes getRow 1 entry filename  Assert only one more row... the meta flushed row. startCacheFlush computeFilename next log regionName fs System getKeyValues getTablename assertTrue testEditAdd get row tablename close cols key timestamp  Now open a reader on the log and assert append worked. COL_COUNT  entry in the below... thats why we have '1'. getReader column  1, 2, 3... completeCacheFlush assertEquals kv closeAndDelete Integer getValue getFamily currentTimeMillis equals toString HLog append getEdit ",hadoop,1
" Ldap server is down, no groups should be retrieved anyString any when asList  This mocks the case where Ldap server is down, and always throws CommunicationException search doTestGetGroups Connection is closed Arrays getContext testGetGroupsWithLdapDown thenThrow ",hadoop,0
getName set fs2 fs1 conf getFileSystemClass fs.uncachedfile.impl file uncachedfile://a FileSystem get assertNotSame testCacheDisabled fs.uncachedfile.impl.disable.cache setBoolean ,hadoop,0
"ROWS_ONE  Expect four keys (two from each family) in half the rows testRowTwo  testRowOne-2 HConstants  Only look in first group of rows  testRowOne-3 Bytes QUALIFIERS_ONE FAMILIES VALUES  Expect only two keys (one from each family) in half the rows  Expect varied numbers of keys, 4 per row in group one, 6 per row in group two expectedKeys verifyScanNoEarlyOut expectedRows testQualifierOne-2 f ROWS_TWO toBytes test.+-2 testQualifierFilter kvs setFilter  testRowTwo-0 QUALIFIERS_TWO  Match two keys (one from each family) in half the rows verifyScanFull CompareOp  Expect 4 keys per row across both groups  testRowTwo-3  testRowTwo-2 ",hadoop,1
Request CoreMatchers equalTo test mode works. assertThat makeRequest url testTestModeIndex path Assert /base/middle/app/mode/test response GET testServerUrl ,ninja,0
cluster mtime on   close file after writing statBeforeClose getModificationTime  ( conf waitActive getFileStatus ipc.client.connection.maxidletime  create a new file and write to it info localhost  2s Closed file. DFSConfigKeys datanodeReport format ) getFileSystem stm setInt  before close is  MAX_IDLE_TIME numDataNodes  parameter initialization fileSys getNameNodePort printDatanodeReport shutdown dateForm System statAfterClose assertTrue mdateAfterClose client numDatanodes addr close /simple.dat writeFile cleanupFile e replicas testTimesAtClose mtimeBeforeClose assertEquals mtimeAfterClose  after close is  build mdateBeforeClose Number of Datanodes  file1 Created and wrote file simple.dat DatanodeReportType ,hadoop,1
"server debug Expected exception  LOG  close the server expected createServer serverDescription Expected an exception, got  fail stop testMissingServerResource NoSuchWebapp toString ",hadoop,0
"Unexpected Exception     f->(2,3)    2->ok->j    2->fail->4    3->ok->4    3->fail->k    4->ok->j    4->fail->k    j->end    def addNode printStackTrace f one j k kill three two asList testTransition3 fail ex invokeForkJoin parser four name dummyConf end Arrays ",oozie,1
actionNum CoordinatorJob coord-action-get.xml CoordinatorAction getId job addRecordToCoordActionTable addRecordToCoordJobTable _testPendingFalseCount testCoordActionsPendingFalseCountGet ,oozie,1
getTemplateForResult getWithDefault equalTo invoke assertThat eq any testBasicInvocation TemplateEngineFreemarker getSuffixOfTemplatingEngine .ftl.html route Results context verify templateEngineHelper toString writer ok ninjaProperties Just a plain template for testing... templateEngineFreemarker ,ninja,0
msg conn getName testValidateResponseJsonErrorKnownException HttpExceptionUtils getResponseMessage when put getBytes getErrorStream HttpURLConnection Assert json validateResponse thenReturn getMessage is assertEquals jsonMapper fail EX ex Mockito response getResponseCode mock getSimpleName writeValueAsString ,hadoop,0
 mockRes init mockReq verifyZeroInteractions  Object under test thenReturn BROWSER_AGENT testMissingHeaderNoMethodsToIgnoreConfigBadRequest  CSRF has not been sent  Objects to verify interactions based on request  Setup the configuration settings of the server getMethod when filterConfig getHeader filter mockChain getInitParameter Mockito doFilter GET mock RestCsrfPreventionFilter ,hadoop,0
verifyPaths testIpAuthorityWithDefaultPort myfs://127.0.0.1:123 fs ips authorities getVerifiedFS ,hadoop,0
writeStoreFile testBasicHalfMapFile getWriter regionname familyname StoreFile getPath checkHalfHFile conf writer  Make up a directory hierarchy that has a regiondir and familyname. ,hadoop,1
CoordinatorJob _testGetJobInfoForUser testCoordJobsGet _testGetJobsForAppName _testGetJobsForStatus _testGetJobsForGroup addRecordToCoordJobTable _testGetJobsForUserAndStatus ,oozie,1
"addToken  one duplicate with different value, one new getSecretKey numberOfSecretKeys  new token & secret should be added assertEquals secret creds  non-duplicate token & secret should be present getBytes token mergeAll numberOfTokens service credsToAdd getToken addSecretKey  existing token & secret should not be overwritten ",hadoop,0
watcher restart contextProperty  verify what actually got to ninja machine project run is assertThat /test execute target/classes setupMachineAndWatcherStubs getValue times jvmArgumentsCaptor dev -Dninja.mode=dev machine -Dninja.context=/test get ninjaRunMojo verify ,ninja,0
1 2 3 _testGetActions testWfActionsGet addRecordToWfJobTable WorkflowAction addRecordToWfActionTable getId WorkflowJob WorkflowInstance job ,oozie,1
"<coordinator-app name='NAME' frequency='${coord:days(1)}' start='2009-02-01T01:00Z' end='2009-02-03T23:59Z' timezone='UTC' xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance' xmlns='uri:oozie:coordinator:0.1' xmlns:sla='uri:oozie:sla:0.1'>  XmlUtils e testCoordSchema validator parseXml </action> </coordinator-app> newValidator getSchema COORD_APP1 Services <controls> <timeout>10</timeout> <concurrency>2</concurrency> <execution>LIFO</execution> </controls> <datasets> <dataset name='a' frequency='${coord:days(7)}' initial-instance='2009-02-01T01:00Z' timezone='UTC'> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset> <dataset name='local_a' frequency='${coord:days(7)}' initial-instance='2009-02-01T01:00Z' timezone='UTC'> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset> </datasets> <input-events> <data-in name='A' dataset='a'> <instance>${coord:latest(0)}</instance> </data-in>  </input-events> <output-events> <data-out name='LOCAL_A' dataset='local_a'> <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path> <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property> <property> <name>inputB</name> <value>${coord:dataOut('LOCAL_A')}</value> </property></configuration> </workflow>   wss get SchemaName validate  System.out.println(""XML :""+ XmlUtils.prettyPrint(e)); ",oozie,1
request incrementAndGet data channel increment update CapacityChannel#update should not have been invoked yet consume lastIncrement subscription Assert get consumer testCapacityIncrements set onError subscribe onComplete assertEquals received duplicate ByteBuffer onNext updateCapacity onSubscribe wrap ,httpcore,0
./tmp/test-config2.xml getName conf relConfig2  Cleanup delete appendProperty out endInclude addResource get testRelativeIncludes a getParent b startInclude  Add the relative path instead of the absolute one. c d getAbsolutePath  verify that the includes file contains all properties endConfig startConfig assertEquals tearDown relConfig mkdirs ./tmp/test-config.xml fileResource ,hadoop,0
addRecordToCoordJobTableForWaiting coord-job-for-matd-relative.xml getId DateUtils parseDateOozieTZ call testActionMaterForHcatalogRelativePath CoordinatorJob 2009-03-06T010:00Z 2009-03-11T10:00Z startTime endTime job ,oozie,1
testRootDir -moveFromLocal assertFalse run assertEquals delete target testRoot exit shell assertTrue testMoveDirFromLocal mkdirs lfs srcDir exists toString testPutDir targetDir ,hadoop,0
"testNestedForkJoinFailure addNode def       f->(2,3,4)      2->j      3->j      4->f2      f2->(5,6)      5-j2      6-j2      j-j2      j2-end      j2 Expected to catch an exception but did not encounter any f2 three two getCause asList we invokeForkJoin getErrorCode assertTrue four dummyConf end five six f one getMessage j assertEquals k kill [j2] fail contains ex parser testWf <worklfow-app/> ErrorCode Arrays ",oozie,1
bundleJobGetExecutor addRecordToBundleActionTable Action should be purged. Should fail. Job should be purged. Should fail. getId run DateUtils getStatus parseDateOozieTZ engine assertNotNull get purgeRunnable getBundleJob Job waitFor a testPurgeServiceForBundle 2011-01-01T01:00Z addRecordToBundleJobTable assertEquals execute jobId Services fail bundleActionGetExecutor1 bundleActionGetExecutor2 u action1 job action2 jpaService evaluate ,oozie,1
"request testDistribution2 getID assertEquals target accept getValue LIST_ID_VALUE_TYPE Assert OryxTest recs get X MediaType Y Z /classificationDistribution/A,-5, ",oryx,1
 we expect that no websocket class has been configured in guice forName classAvailableFromInjector assertFalse contextInitialized getInjector Exception triggered by test servletContextEvent mockStatic eq ninjaServletListener any when PowerMockito  WHEN Mockito makeSureContextInitializedWorksWhenJettyThrowsException Class javax.websocket.server.ServerContainer injector thenThrow  on the classpath. ,ninja,0
_test isMainSuccessful actionDir hasOutputData assertFalse testSecurityManager runningJob isMainDone getFileSystem fs hasIdSwap getIdSwapPath isSuccessful assertTrue LauncherMapper getErrorPath exists getOutputDataPath securityManager evaluate waitFor getFsTestCaseDir isComplete ,oozie,1
longParam assertFalse context create verify hasViolations invoke mockController validation longParamShouldHandleNull ,ninja,0
server http:// conn getLog cookies /echo getHostPortString getConnectorAddress Assert assertTrue get Set-Cookie ; Expires= info testPersistentCookie printStackTrace e Log openConnection isEmpty parse  Auto-generated catch block token getValue getHeaderField contains NetUtils startServer equals header HttpCookie base ,hadoop,0
bundleJobGetExecutor cJob1 addRecordToBundleActionTable getTime pauseStartRunnable getCurrentDateafterIncrementingInMonths getId run DateUtils getStatus parseDateOozieTZ testPauseBundleAndCoordinator setPauseTime pauseTime assertNotNull get setBundleId end currentDatePlusMonth Job waitFor bJob1 bundleAction1 bundleAction2 addRecordToBundleJobTable start assertEquals XDataTestCase execute addRecordToCoordJobTable coordJob2 Services CoordinatorJob jobId coordJob1 coordJobId1 coordJobId2 action1 job action2 jpaService evaluate ,oozie,1
request assertNothingThrown modifyRequest setRequestHandler put STATUS Assert HEADERS modifyRequest should have been called. assertTrue runTests  make sure the modifyRequest method was called by seeing if the request was modified. CONTENT_TYPE get verify addTest UNLIKELY_ITEM something_unlikely_to_be_in_a_real_request adapter containsKey responseExpectations execute  let the adapter change the request if needed. framework modifyRequestCalled Mockito response mockRequestHandler newFrameworkAndSetAdapter mock  assertNothingThrown() should have been called. BODY ,httpcore,0
 0 1 0  set testToString array  1 0 1  expected toString assertEquals         ,zxing,0
CoreMatchers equalTo parse assertThat impl testParseBasic TLSv22.356 Assert TLSv1 TLSv1.3 TLSv1.2 TLS TLSv1.1 ,httpcore,0
 testFile01 getPathData testfile01 addContents ls formatLineMtime out testfile03 options computeLineFormat inOrder testfile02 processOptions verify testfile05 testFile06 testfile04 testFile04 testFile05 testfile06 testFile02 testFile03 add Found 6 items pathData lineFormat setIsDir processArguments testDir  check listing of a single directory testDirectory processPathDirectory verifyNoMoreInteractions TestFile mock ,hadoop,0
testConfBasedAndAPIBasedSetUMask  explicit setUMask is done. file://mydfs:50070/ conf Umask for fc2 is incorrect Umask for fc1 is incorrect 011 077 fc2 Default UMask changed! fc1 get defaultlUMask FsPermission set CommonConfigurationKeys getFileContext assertEquals 022 uri2 066 uri1 file://tmp getUMask  configuration should be reflected.. createImmutable FileContext toShort setUMask ,hadoop,0
 EXIT_INTERRUPTED getName escalator  call the interrupt operation directly e isForcedShutdownTimedOut() == true in  assertFalse testInterruptEscalationShutdown interrupted isSignalAlreadyReceived() == false in  assertExceptionDetails INT isForcedShutdownTimedOut setService fail Expected an exception to be raised in  isSignalAlreadyReceived  now interrupt it a second time and expect it to escalate to a halt assertStopped assertTrue service  the service is now stopped launcher ,hadoop,0
"ROWS_ONE  Expected KVs, the first KV from each of the remaining 6 rows QUALIFIERS_TWO QUALIFIERS_ONE verifyScanFull FAMILIES ROWS_TWO kvs VALUES testFirstKeyOnlyFilter setFilter ",hadoop,1
handler getURIHandler dt=05 testExists assertFalse uriService addPartition conf year=2012;month=12;dt=02;country=us assertTrue dt=02 hcatURI table country=us;month=12 country=us dropTestTable year=2012;month=12 createTestTable country=us;year=2012;month=12;dt=02 getTestUser exists db getHCatURI year=2012;month=12;dt=03;country=us month=02;dt=02 ,oozie,1
" g-h ${env.NULL_VALUE} ${env.NULL_VALUE:} declareProperty empty3 conf empty1 empty2 when CONFIG ${env.NULL_VALUE-} ${env.EMPTY_VALUE-c} ${env.SOME_VALUE} ${env.NULL_VALUE:-i:-j} thenReturn edge5 edge3 edge4 endConfig edge1 edge2 props testEnvDefault some1 some2 some3 mock fileResource spy EMPTY_VALUE ${env.SOME_VALUE:-f} i:-j  if var is unbound, literal ${var} is returned null3 p= null1 System out null2 assertEq ${env.EMPTY_VALUE} addResource get NULL_VALUE ${env.NULL_VALUE-g-h} ${env.NULL_VALUE:-b} getenv  some edge cases gotVal a some value b d startConfig SOME_VALUE ${env.NULL_VALUE-a} ${env.NULL_VALUE:-} ${env.EMPTY_VALUE:-d} p Mockito getRaw ${env.SOME_VALUE-e} gotRawVal ",hadoop,0
"Unexpected Exception def addNode printStackTrace testDecisionsToJoinForkJoin e f one j k kill three two asList      f->(2,3)     2->decision node->{4,j,4}     3->decision node->{j,5,j}     4->j     5->j      fail invokeForkJoin parser four name dummyConf end Arrays five ",oozie,1
"gidNameMap getGid  Clear map and update staticMap file assumeNotWindows nid conf getGidNameMap rid delete sleep getUid uidNameMap refIdMapping getPath me id clearNameMaps smapStr   nfs- getKey set getUidNameMap entrySet  getGid() uid  incrIdMapping  the staticMap createTempFile assertEquals tempStaticMapFile  the same as ""id"" gid  testStaticMapUpdate Thread getValue IdMappingConstant setLong  getUid()  Test staticMap refreshing .map name  Sleep a bit to avoid that two changes have the same modification time File createStaticMapFile ",hadoop,0
 Check initial position  Check a seek + read ostream foo tell conf dir fs delete seek  Check a read from that position. FileSystem create testAFSInput write close  Create the stream read filePath getFileContext length assertEquals getInputPath 0123456789 buf avroFSIn getLocal mkdirs w exists fc FileContext ,hadoop,0
fencer TEST_TARGET ShellCommandFencer echo hello tryFence assertTrue Mockito endsWith echo hello: hello verify testStdoutLogging info ,hadoop,0
"set trim TEST_LDAP_URL testGetGroupsWithDefaultBaseDN doTestGetGroupsWithBaseDN conf  dc=xxx,dc=com  baseDN getBaseConf LdapGroupsMapping ",hadoop,0
 fail empty string not allowed testEmpty tokenize ,logback,0
init generateId destroy counter services 0001000- uuid ApplicationType assertTrue testPadding setSystemProperty get 0000000- UUIDService id startsWith ,oozie,1
formatDate Expires:  Last-Modified:  headers addHeader getHeaders lastModifiedDate If-Modified-Since:  contains assertTrue TimeUnit cacheControlNoCacheAndExpirationDateInTheFuture assertConditionallyCached conditionalRequest Cache-Control: no-cache ,okhttp,1
addRecordToBundleActionTable getId addRecordToCoordActionTable bundleJob coordAction3 coordAction4 children assertNotNull coordAction5 get CoordinatorAction  Get the next 3 (though there's only 2 more) coordAction1 coordAction2 Job bundleAction4 getAppName bundleAction5  Get the first 3 setAppName bundleAction1 bundleAction2 bundleAction3 addRecordToBundleJobTable assertEquals execute addRecordToCoordJobTable coordJob2 checkChildren Services CoordinatorJob coordJob3 coordJob1 coord-action-get.xml size addAll coordJob4 testGetBundleParentTooMany coordJob5 jpaService ,oozie,1
"  humanoids drwho getGroupNames barbara@EXAMPLE.COM acl drwho humanoids drwho@EXAMPLE.COM humanoids assertUserAllowed drwho  ian@EXAMPLE.COM assertUserNotAllowed teachers ian verify barbara UserGroupInformation createUserForTesting aliens drwho,ian aliens,teachers never susan susan@EXAMPLE.COM isUserAllowed testIsUserAllowed timelord spyUser humans spy ",hadoop,0
cluster shutdownDfs e LOG Failed getLog  do a true concurrent background thread flush count HConstants assertEquals error Added:  addContent testScanAndRealConcurrentFlush closeAndDelete createNewHRegion Bytes r getTableDesc REGION_INFO toString close hri info ,hadoop,1
server newServerBuilder rpcThread newSlowPingRequest num rpc got exception  conf run setSecretManager error sleep testRPCInterrupted barrier leaderRunning assertTrue thread  get builder await interrupt numConcurrentRPC latch countDown addr setNumHandlers set e LOG start getClient setVerbose leaderThread Thread proxy stop slowPing setupTestServer  stop a single thread  let threads get past the barrier  should not cause any other thread to get an error ,hadoop,0
 conn openConnection unchecked HttpServletResponse assertEquals params error url put call getResponseCode /callback createURL id Collections ok runTest testCallbackGet status ,oozie,1
" aaa ccc Value1 xx,  yy  ,zz Name8=xx%2C%20%20yy%20%20%2Czz result Name3 Value 4! Name4 Name5 Assert Name4=Value%204%21 Name6 Name7=aaa&Name7=b%2Cb&Name7=ccc Name7 testParseURLCodedContent assertTrue Name2= Name8 price get b,b Name1=Value1 Name4=Value%204%21%20%214 Name0 Name1 Name2 bbb Name5=aaa&Name6=bbb isEmpty assertEquals parse Name4=Value%2B4%21 Value+4! price=10%20%E2%82%AC assertNameValuePair size Value 4! !4 10 â‚¬ ",httpcore,0
"       <value>A</value>        <name>a</name>    <job-tracker>foo</job-tracker>  expectedD validateAndParse   </prepare>      </property>  replaceAll   <archive>/tmp</archive>    <configuration>    </configuration>  wf-schema-valid-global-jobXml.xml app     <file>/tmp</file>      <mkdir path=""/tmp"" />  d getConf     <reducer>/mywc.sh</reducer>    <prepare>      <mapper>/mycat.sh</mapper>        <name>b</name>  assertEquals   <job-xml>/spam2</job-xml>    <job-xml>/spam1</job-xml>        <value>B</value>  </map-reduce> IOUtils parser   </streaming>  testParserGlobalJobXML   <streaming>  getResourceAsReader     <property>  getNode     <delete path=""/tmp"" />  <map-reduce xmlns=""uri:oozie:workflow:0.4"">    <job-xml>/tmp</job-xml>    <name-node>bar</name-node>  ",oozie,1
addRecordToWfActionTable getId WorkflowInstance getStatus  update the list for doing bulk writes coordJob wfJob addRecordToWfJobTable assertNotNull get action WorkflowJob updateList add getStatusStr  update the status  check for expected status after running bulkUpdateJPA RUNNING assertEquals execute addRecordToCoordJobTable setStatus CoordinatorJob 1 Services setUpdateList WorkflowAction bulkUpdateCmd SUCCEEDED testUpdates action2 jpaService ,oozie,1
request assertNothingThrown setRequestHandler put modifyResponseExpectations STATUS Assert HEADERS assertTrue runTests  make sure the modifyRequest method was called by seeing if the request was modified. CONTENT_TYPE get verify addTest something_unlikely_to_be_in_a_real_response UNLIKELY_ITEM modifyResponseExpectations should have been called. adapter containsKey responseExpectations execute modifyResponseExpectationsCalled  let the adapter change the request if needed. framework Mockito response mockRequestHandler newFrameworkAndSetAdapter mock  assertNothingThrown() should have been called. BODY ,httpcore,0
add next val NUM_ELEMS  Remove even elements. valueOf assertFalse  Iterate through all odd list elements. isEmpty iter  Iterate through all list elements. hasNext assertEquals list remove Integer iterator Assert size assertTrue  Check that list is now empty. testRemovals ,hadoop,0
loader waitFinish newFile invalidateStaging taskLatch callbackLatch fileCacheExecutor f2  start the original uploads copyToFile randomStream file getStagingCacheStats assertTrue executor uploader Finished invalidateStaging root countDown ID_PREFIX  create executor getIfPresent info cache LOG getAbsolutePath          bytes  f threads accepted assertCacheStats scheduledExecutor invalidate closer afterExecuteLatch folder assertNull  staging %  stage statsProvider assertFile Starting invalidateStaging register ,jackrabbit,1
"getBufferSize testFSOutputStreamBuilder createFile getBytes assertArrayEquals path Assert IO_FILE_BUFFER_SIZE_DEFAULT getReplication getBlockSize readFully getDefaultReplication getFileStatus buffer write getPermission Should be default replication factor assertThat getDefaultBlockSize blockSize input getInt  Test set 0 to replication, block size and buffer size UTF8 fileSys Should be default buffer size  and permission Buffer size should be 0 Replication factor should be 0 Should be default block size IO_FILE_BUFFER_SIZE_KEY recursive content out data written. stream TEST_ROOT_DIR Block size should be 0 getLen builder isZero FsPermission close replication getConf e contentOrigin Should be default permission The data be read should equals with the  withFailMessage testBuilder build Create with a generic type of createFile! getFileDefault isEqualTo open bufferSize ",hadoop,0
request  conditions _execQuery parseDateUTC getStatus DateUtils testSingleRecord getBundle br startcreatedtime=2012-07-21T00:00Z;endcreatedtime=2012-07-22T02:00Z getCoordinator ;actionstatus=FAILED; get CoordinatorAction Coord1 CREATE_TIME getAppName assertEquals getAction brList  only 1 action satisfies the size bundleName toString bundle= getCreatedTime ,oozie,1
Context setResourceWatcherUpdatePeriod delta start updatePeriod g1 ResourceType check getConfig System shouldCheckOnlyAfterTimeout times Mockito get currentTimeMillis mockResourceWatcher verify victim key ,wroj4,1
testJobsStatusFilter END_POINTS IS_SECURITY_ENABLED getContextURL oozieUrl getJobsInfo group=x name= wc user=x call fail x=x status=X status=RUNNING name=x name=x;name=y SERVLET_CLASSES runTest ,oozie,1
"cluster DeleteOnExit successful. conf fs createFile System simulatedStorage  set delete on exit flag on files. localfs assertTrue FileSystem closeStream writeFile close deleteOnExit   filestatus2.dat  still exists inspite of deletOnExit set.  write to files and close. Purposely, do not close file2. filestatus.dat getFileSystem DeleteOnExit: Created files.  reopen file system and verify that file does not exist. stm2 stm3 testDeleteOnExit IOUtils stm1 build getLocal file2 filestatus3.dat file3 exists SimulatedFSDataset file1 shutdown setBoolean  disappear. ",hadoop,1
addRecordToBundleActionTable getCurrentDateafterIncrementingInMonths run DateUtils WorkflowInstance getStatus addRecordToCoordActionTable parseDateOozieTZ bundleJob assertNotNull CoordinatorAction currentDatePlusMonth Job waitFor bundleAction1 bundleAction2 XDataTestCase testBundleStatusTransitServiceKilled execute addRecordToCoordJobTableWithBundle coordJob2 CoordinatorJob coordJob1 evaluate assertFalse getId getExternalId isPending wfJob addRecordToWfJobTable get end coordAction1_3 WorkflowJob coordAction1_4 bundle coordAction1_1 coordAction1_2 addRecordToBundleJobTable bundleId start assertEquals call Services runnable coord-action-get.xml equals action1 action2 jpaService ,oozie,1
q1 val type c3 desc newGauge withtab5	 Metric name 'badcount 2' contains  run num metrics in registry c5 desc c4 desc Metric name 'withnewline6 ' contains  c1 desc newQuantiles  Final validation  Fill up with some basics Metric name 'withtab5	' contains  q1 test badcount 2 withnewline6   Add some illegal names badcount3   Metric name '  badcount4' contains  g1 assertEquals c1 c2 desc expectMetricsException   badcount4 r testMetricsRegistryIllegalMetricNames illegal whitespace character size newCounter g1 desc metrics q1 desc c6 desc q1 name Metric name 'badcount3  ' contains  ,hadoop,0
 ParseException should have been thrown  : blah clear header : blah parseHeader fail Assert testInvalidHeaderParsing    : : buffer : blah append blah ,httpcore,0
fail a addFunction ${a:a()} functionError testFunctionELEvaluationError support evaluate evaluator ,oozie,1
setAuthenticationMethod getCurrentUser testTestAuthMethod ugi getAuthenticationMethod values getAuthMethod assertEquals AuthenticationMethod am  verify the reverse mappings works UserGroupInformation ,hadoop,0
set testWorkflowJobSLANew conf services appPath _testWorkflowJobCommands ehs writeToFile OozieClient IOUtils getTestUser wfXml assertNotNull getResourceAsString get workflow.xml toString wf-job-sla.xml slas getFsTestCaseDir ,oozie,1
date if_SimpleSet scriptExecutor session  Given simple withLwtResultListener Eq delete SELECT * FROM simple WHERE id =  lwtResultListener Sets  When of get where id getAndSet row table executeScriptTemplate onError RandomUtils manager allColumns_FromBaseTable one nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap isTrue newHashSet success  Then isNull Long buildDateKey should_delete_with_equal_condition dsl onSuccess ,achilles,1
next thenReturn getInternalServerErrorResult getFilterChain testOnRouteRequestWhenInternalServerErrorException filterChain when ninjaDefault route Mockito contextImpl internalServerErrorException mock verify That's an InternalServerErrorException that should be handled by onError! onRouteRequest thenThrow ,ninja,0
Timed out on barrier Passed  getName test.sink.collector. threadSourceRec run   Collector of values from all threads. asList barrier getTestFilename Test threadSource TimeUnit join equalsIgnoreCase results add all currentThread ms sink input barrier2 A source of my threaded goodness. stop barrier1 *.period TestMetricsConfig safeAwait Arrays shutdown mySource sources save testMultiThreadedPublish MetricsConfig collector Iterables assertTrue StringUtils get await Metric not collected! value hadoop-metrics2-test Someone else collected my metric! registerSink set Broken Barrier apply start threads  the system at the same time  I need to wait for the threads to finish before checking. assertEquals numThreads Thread Interrupted Integer parseInt t publishMetricsNow register ,hadoop,0
 testFile01 getPathData processPathDirOrderMtimeYears testfile01 getTime addContents ls formatLineMtime out  overflow issues) testfile03 options computeLineFormat inOrder testfile02 processOptions verify testfile05 testFile06 setMtime testfile04 testFile04 testFile05 testfile06 testFile02 testFile03  set file mtime in different order to file names add Found 6 items pathData lineFormat -t setIsDir processArguments testDir Integer testDirectory verifyNoMoreInteractions NOW TestFile mock ,hadoop,0
request conn getRequestCount addHeader testWriteRequestEntityNoContentLength test ContentType thenReturn getEndpointDetails User-Agent assertEquals Method outStream when setEntity 123 bind Assert Mockito getOutputStream socket /stuff sendRequestEntity sendRequestHeader ,httpcore,0
getRequestCount CommonConfigurationKeys clearBlackList groups refresh conf FakeGroupMapping assertEquals  Disable negative cache. asList cacheGroupsAdd setLong  Second count hits cache myGroups size assertTrue  First call hits the wire testCachePreventsImplRequest me Arrays getGroups ,hadoop,0
"closeTrx coordClient getStore LocalOozie Could not update db. getStatus After refresh, action xml=  getCoordClient eAction getTestGroup beginTrx CoordinatorAction create commitTrx waitFor bean actionNum printStackTrace store2 store3 parseXml getFileSystem jobId fail CoordinatorJob _SUCCESS addRecordToActionTable mkdirs actionId testCoordRerunRefresh evaluate getCoordinatorAction @ getTime appPath fs System actionXml -testCoordRerun-C coord urls get reRunCoord /coord-input/2010/07/09/01/00 RestConstants XmlUtils e store getActionXmlUrls inputDir addRecordToJobTable Integer Services getTestUser getActionXml getCoordActionInfo assertNotSame 0000000- toString action2 action3 coord-rerun-action1.xml getFsTestCaseDir ",oozie,1
_test isMainSuccessful actionDir hasOutputData assertFalse runningJob isMainDone getFileSystem fs hasIdSwap getIdSwapPath isSuccessful exit0 assertTrue LauncherMapper getErrorPath exists getOutputDataPath testExit0 evaluate waitFor getFsTestCaseDir isComplete ,oozie,1
prepare testCodingDirectBuffer_10x4_erasing_p1 testCoding ,hadoop,0
 Have to sleep to allow time for the clients to reconnect. stopServer CONNECTION_TIMEOUT waitForElectorState checkFatalsAndReset ActiveStandbyElectorTestUtil Thread sleep never startServer cbs Mockito becomeActive State ensureParentZNode verify hostPort electors testDontJoinElectionOnDisconnectAndReconnect waitForServerUp ,hadoop,0
"OTHER_GROUP_NAMES ProxyUsers refreshSuperUserGroupsConfiguration getProxySuperuserGroupConfKey assertAuthorized GROUP_NAMES DefaultImpersonationProvider conf asList testProxyUsers PROXY_IP StringUtils join  From bad IP UserGroupInformation  First try proxying a group that's allowed set proxyUserUgi 1.2.3.4 1.2.3.5  Now try proxying a group that's not allowed , createRemoteUser REAL_USER_NAME assertNotAuthorized getTestProvider  From good IP Arrays getProxySuperuserIpConfKey PROXY_USER_NAME realUserUgi createProxyUserForTesting ",hadoop,0
addRecordToBundleActionTable bundleJobGetCmd getCurrentDateafterIncrementingInMonths getId DateUtils getStatus addRecordToCoordActionTable parseDateOozieTZ sleep assertNotNull get CoordinatorAction end currentDatePlusMonth Job addRecordToBundleJobTable bundleId start assertEquals XDataTestCase execute addRecordToCoordJobTableWithBundle call Services CoordinatorJob coord-action-get.xml testBundleStatusTransitServiceSucceeded3 action1 job action2 jpaService ,oozie,1
setNativeZlibLoaded getClass seed gzbuf dflchk conf nextBytes assertArrayEquals decom ZlibFactory assertNotNull write close getData copyBytes info gzout b LOG testGzipCompatibility gzin newInstance assertEquals nextInt nextLong seed:  copyOf createInputStream codec r IOUtils  don't use native libs createDecompressor getLength reset setSeed ReflectionUtils Arrays dflbuf ,hadoop,0
.gz test2 withCompression_FileBlank_NoRestart_2 NO_RESTART defaultTest FILE_OPTION_BLANK ,logback,0
cluster Namenode has   fetch bad file list from namenode. There should be one file. getName  length   fetch bad file list from namenode. There should be none.  check that we are still in safe mode .meta channel conf  now leave safe mode so that we can clean up getChannel  bad files. Expecting 1. storageDir buffer /srcdat10 write isPopulatingReplQueues info   Deliberately corrupting file  DFSConfigKeys getBlockPoolId  read all files to trigger detection of corrupted replica LOG listCorruptFileBlocks restartNameNode stringifyException waiting for replication queues getFileSystem Blocks do not exist in data-dir isInSafeMode setInt testListCorruptFileBlocksInSafeMode / getNameNode blk_  wait until replication queues have been initialized util size Expecting BlockMissingException  cleanup Corrupted replicas not handled properly.  Namenode is not in safe mode waitSafeMode endsWith position getInstanceStorageDir idx shutdown  datanode sends block reports getFinalizedDir HdfsConstants rw error fs System nextBytes sleep random badFiles file assertTrue StringUtils listFiles close data_dir setFloat  restart namenode  never leave safemode automatically MiniDFSCluster e  start populating repl queues immediately blocks  Now deliberately corrupt one block  at offset  length Namenode has bad files.  setSafeMode getNameNodeRpc ByteBuffer  corrupt files. Expecting None. data directory does not exist Thread createFiles build exists checkFiles  but received IOException  Received BlockMissingException as expected. wrap  create two files with one block each  datanode scans directories getNamesystem startsWith ,hadoop,1
a fail testNotNullElements name notEmptyElements Arrays ParamChecker asList ,oozie,1
_testGetRecoveryActionsGroupByJobId _testGetAction _testGetActionForJob -TestCoordinatorStore-C _testGetActionForJobInExecOrder getTime testCoordStore _testInsertAction _testUpdateCoordActionMin _testUpdateCoordAction jobId _1 _testGetJob _testUpdateCoordJob _testGetMatJobLists _testGetActionRunningCount _testGetActionForJobInLastOnly actionId 00000- _testInsertJob ,oozie,1
testAddXIncludeFromReader abc printStackTrace def e foo prepareXmlWithInclude conf assertEquals parentXml XInclude failed fail bar oozie.dummy getTestCaseDir get  verify the properties from include file DEFAULT ,oozie,1
viewFs ConfigUtil getCanonicalServiceName conf file:/// serviceName FsConstants testGetCanonicalServiceNameWithDefaultMountTable assertNull /user FileSystem get addLink ,hadoop,0
2009-02-02T23:59Z getId run DateUtils WorkflowInstance getStatus addRecordToCoordActionTable parseDateOozieTZ coordJob sleep wfJob addRecordToWfJobTable assertNotNull get CoordinatorAction end testCoordActionRecoveryServiceForSuspended WorkflowJob recoveryRunnable waitFor ret RUNNING wfGetCmd 2009-02-01T01:00Z start assertEquals execute addRecordToCoordJobTable CoordinatorJob Services wfJobId coord-action-get.xml jpaService evaluate ,oozie,1
russian=%D0%92%D1%81%D0%B5%D0%BC_%D0%BF%D1%80%D0%B8%D0%B2%D0%B5%D1%82 ContentType result ru_hello Assert constructString RUSSIAN_HELLO withCharset get ch_hello &swiss=Gr%C3%BCezi_z%C3%A4m%C3%A4 add russian URLEncodedUtils StandardCharsets SWISS_GERMAN_HELLO format swiss assertEquals parse EntityUtils assertNameValuePair size testParseUTF8Entity parameters entity ,httpcore,0
getClass unknown_junk e assertTrue .*unknown_junk.* testBadName WritableName getMessage conf matches ,hadoop,0
@ closeTrx coordClient getStore getTime LocalOozie Could not update db. Exception expected because action is not in terminal state. getStatus Error code should be E1018 when job is killed or failed. -testCoordRerun-C getCoordClient getErrorCode get beginTrx CoordinatorAction reRunCoord commitTrx actionNum RestConstants printStackTrace e store2 assertEquals store addRecordToJobTable Integer jobId Services fail CoordinatorJob ex addRecordToActionTable equals actionId testCoordRerunNeg 0000000- toString ErrorCode action2 coord-rerun-action1.xml getCoordinatorAction ,oozie,1
add  a:b:c a b subList c a:b assertEquals StringUtils : join testJoin ,hadoop,0
owner bigBuf testOverlongDtidSerialization realUser renewer assertFalse testDelegationTokenIdentiferSerializationRoundTrip Text ,hadoop,0
incrementAndGet ContentType testConsumeData getContent count consume assertEquals completed failed ByteBuffer longValue Assert streamEnd cancelled 12345 streamStart wrap consumer ,httpcore,0
kills addNode def enters one start testSynchDouble assertEquals WorkflowInstance getStatus two asList wf 1 exits size <worklfow-app/> end Arrays job fails ,oozie,1
"Unexpected Exception addNode def j1 f1 three two      * f->(2,3)     * 2->ok->j     * 3->ok->j     * j->6     * 2->error->f1     * 3->error->f1     * f1->(4,5)     * (4,5)->j1     * j1->6     * 6->k      asList wf testErrorTransitionForkJoin invokeForkJoin four dummyConf end five six printStackTrace e f one j k kill fail parser <worklfow-app/> Arrays ",oozie,1
  X   X       X X X X X X X X X X X X   X X         X   X   X X X   X   X   X X X X     X           X X X X X X   X X X X X   X X X X X X   X       X X X   X   X     X X X X         X X         X X   X   X X               X X X   X X X X     X X   X       X X X   X X X       X X         X   X     X X X               X X X X   X X             X               X                 X       X   X   X X       X   X         X X X     X   X       X   X X X X X X X X X X X     X   X X   X       X     X   X   X   X   X   X X   X       X X   X X X X X   X X X                 X             X   X X X   X       X   X     X X X       X     X X       X     X X     X     X           X         X     X X     X   X X   X X       X   X   X         X   X       X   X X X X       X           X X     X   X X   X   X   X       X X     X               X   X X     X     X X X       testEncode1   X X X   X X X X   X     X   X     X X   X     This is an example Aztec symbol for Wikipedia.         X X X X X     X X X X   X   X     X     X     X X   X X   X X X X X   X X   X   X X X     X   X X X   X X   X   X X X X   X   X X X X   X X                 X X   X       X X X X X X   testEncode  real life tests ,zxing,0
coordId2 coordId1 coordActionId2 assertEquals createFilterList list coordActionId1 execute jobid Services slaEventsGetCmd lastSeqId size assertNotNull get filterList jpaService testGetSLAEventsForCombinedWithRange ,oozie,1
SELECT * FROM entitywithstaticcolumn WHERE id =  session  Given another_static_col crud another_static_val1 another_static_val2  When withInsertStrategy id static_col InsertStrategy isNotNull actual RandomUtils manager one static_val1 getString nextLong assertThat insertStatic execute entity1 entity2 should_insert_static_with_insert_strategy  Then Long isEqualTo ,achilles,1
testExplicitPassphrase setPassword SSLTestConstants setLocation assertNotNull createKeyStore factoryBean SSL ,logback,0
test CompressDecompressTester CompressionTestStrategy SIZE withTestCases testCompressorDecompressor GenericTestUtils rawData withCompressDecompressPair  no more for this data ex ImmutableSet of assertExceptionContains testCompressorDecompressor error !!! generate ,hadoop,0
" ///////////////////////////////////////////////////////////////////// ninjaTestBrowser assertFalse api/bob@gmail.com/article.xml contentcontent System setDefaultUseWrapper  one new result: assertTrue new title new title api/bob@gmail.com/articles.xml articleDto readValue getServerAddress doLogin module response xml:  testGetAndPostArticleViaXml assertEquals  and then configure, for example: articlesDto Error. Forbidden. makeXmlRequest contains size response postXml xmlMapper ",ninja,1
retryPolicy CuratorFrameworkFactory workingPath testACLs conf getDefaultAcl getAclForPath getBytes digestAclProvider authorization bla get digest builder tm1 close getSecretConf ret add init getConnectString ZKDelegationTokenSecretManager zkServer  check ACL userPass generateDigest UTF-8 start destroy / aclProvider myuser:mypass build setCurator digestACL verifyACL connectString curatorFramework ZooDefs DigestAuthenticationProvider ,hadoop,0
"addRecordToCoordJobTableForWaiting getId run getStatus /2009/22/ coordGetCmd sleep coord-action-for-action-input-check.xml /2009/08/ assertNotNull getTestCaseDir get CoordinatorAction createDir action coord-job-for-action-input-check.xml addRecordToCoordActionTableForWaiting recoveryRunnable waitFor /2009/15/ execute newAction recovery waiting coord action failed, action is WAITING CoordinatorJob Services fail testCoordActionRecoveryServiceForWaiting /2009/29/ actionId job jpaService evaluate ",oozie,1
handler getCurrentUser getEndJobCommitFailureFile conf stagingDir toApplicationAttemptId when assertNotNull FileSystem commitJob getClock UserGroupInformation init waitForItHandler getApplicationID mockCommitter thenReturn getEventHandler getAndClearEvent handle getEndJobCommitSuccessFile MRApps jobId stop mock startCommitFile MRJobConfig testBasic getApplicationId assertFalse ConverterUtils fs mockJobContext getApplicationAttemptId assertTrue get verify appattempt_1234567890000_0001_0 fromYarn getShortUserName set getStartJobCommitFile endCommitFailureFile e toYarn start mockClock any endCommitSuccessFile TypeConverter mockContext exists toString user attemptid ,hadoop,1
 testFile01 getPathData testfile01 addContents -S ls formatLineMtime out testfile03  set file length in different order to file names options computeLineFormat inOrder testfile02 processOptions verify testfile05 testFile06 testfile04 testFile04 testFile05 testfile06 testFile02 testFile03 add Found 6 items pathData lineFormat  check length order (-S option) length setIsDir processArguments testDir testDirectory setLength verifyNoMoreInteractions TestFile mock processPathDirOrderLength ,hadoop,0
date scriptExecutor session  Given simple withLwtResultListener Eq delete SELECT * FROM simple WHERE id =  lwtResultListener  When of get where id getAndSet row table _ executeScriptTemplate onError RandomUtils manager allColumns_FromBaseTable one Lt nextLong assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap should_delete_with_inequal_condition isTrue if_Value success  Then isNull Long buildDateKey dsl onSuccess ,achilles,1
getAndAdvanceCurrentIndex  -----5-7-9  --2-456789 ns conf poll currentIndex setMultiplexer fcq get numQueues  Schedulable[] calls = new Schedulable[numCalls]; add set  0123456789 assertSame  -----5-789  ---------- mockCall call assertNull calls u testPrioritization ,hadoop,0
host5 host4 host7 host11 host6 host1 host3 somehost host2 testHashCode someotherhost host10 myhttp Assert assertTrue hashCode http getByAddress SomeHost host9 InetAddress host8 127.0.0.1 ,httpcore,0
randomPort topic.topic1 isTopicInRetryList tcp://localhost: publisherAuthority registerForNotification Exception expected init getJMSConnectionInfo hcatService hcat.server.com:5080 createConnectionContext testConnectionRetryExceptionListener destroy jmsService JMSAccessorService ActiveMQConnFactory 1 fail connCtxt 3 java.naming.provider.url# connInfo stop isListeningToTopic topic ; assertFalse createSession sleep random ConnectionFactory isConnectionInRetryList HCatAccessorService assertTrue connectionFactoryNames# get servicesConf java.naming.factory.initial# jndiPropertiesString set getConf start services nextInt hcat://hcat.server.com:8020 broker addConnector Thread brokerURL Services  Start the broker setupServicesForHCatalog default= Session ,oozie,1
" p{a\/b,c\/d}s {/ testExpansionIsIdentical {a} /}{a,b} p\{a/b,c/d\}s {a,b}/{b,c} checkExpansionIsIdentical /} ",hadoop,0
 objectWriter  then  fill up deque when timeout deque offer verify write  when addsInfoMessageWhenEventIsBeingDroppedBecauseOfConnectionProblemAndDequeCapacityLimitReached  given max start appender addInfo anyObject some event doThrow reset Dropping event due to socket connection error and maxed out deque capacity TIMEOUT awaitStartOfEventDispatching remainingCapacity append ,logback,1
 writeToHostsFile getMetrics conf hostFile testDecommissionWithExcludeHosts nm2 nm1 NodeAction Assert nodeHeartbeat getNodeAction YarnConfiguration nm3 assertTrue The decommisioned metrics are not updated metricCount refreshNodes localhost getNodesListManager checkDecommissionedNMCount set getAbsolutePath ip host2 start localhost:4433 host2:5678 host1:1234 normalizeHostName NetUtils ClusterMetrics registerNode equals getNumDecommisionedNMs rm  To test that IPs also work ,hadoop,1
date  Given simplemap SELECT * FROM simple WHERE id =  asList ConsistencyLevel crud simpleset  When getList id all containsEntry RandomUtils getSet setSimpleMap assertThat execute ImmutableMap getMap setSimpleSet setConsistencyList hasSize newHashSet should_insert  Then containsOnly Long Arrays session insert two consistencylist containsExactly Sets getTimestamp of get row value EACH_QUORUM manager one getString nextLong rows LOCAL_QUORUM getLong isEqualTo entity ,achilles,1
cluster mtime on   is  test1.dat  ( getModificationTime atimeBeforeClose conf adate waitActive getFileStatus ipc.client.connection.maxidletime mdir1 info localhost    2s  shutdown cluster and restart new mtime on  DFSConfigKeys mtime1 datanodeReport Verifying times after cluster restart  check new modification time on file format ) getFileSystem atime on  mtime2 stm mtime3 setInt  before close is  adate3 MAX_IDLE_TIME Creating testdir1 and testdir1/test1.dat. mdate numDataNodes nnport fileSys getNameNodePort setTimes printDatanodeReport shutdown nameNodePort dateForm new atime on  System sleep assertTrue  cluster restart. mdate3 client atime1 numDatanodes addr testTimes close writeFile atime2 cleanupFile atime3 stat e replicas  set the modification time to be 1 hour in the past getAccessTime assertEquals dir1  set the access time to be one day in the past Thread build testdir1 Number of Datanodes  file1  check new access time on file DatanodeReportType ,hadoop,1
testSetMaxPerRoute Assert somehost pool setMaxPerRoute assertEquals getMaxPerRoute ,httpcore,0
END:VEVENT DTSTART;VALUE=DATE:20111110  doTest 20111110T000000Z BEGIN:VEVENT  DTEND;VALUE=DATE:20111110  testAllDayValueDate ,zxing,0
"de en-US Optional thenReturn NinjaConstant en a_propert_with_commas assertEquals when testCorrectParsingOfDelimitersInPropertiesFiles prop1, prop2, prop3 of get messages getStringArray fr-FR ninjaProperties lang ",ninja,0
setSocketTimeout conn ArgumentMatchers Timeout setSoTimeout when anyInt doThrow times bind testSetSocketTimeoutException Mockito ofMilliseconds verify socket ,httpcore,0
"  encode a data size get bake_in_a_header_a_Unicode_value assertEquals decode inMap put outMap ",ninja,0
 test that sla processes the Job Event from Kill command slaEvent conf run poll DateUtils getCmd asList runSLAWorker  for start_miss assertNotNull getResourceAsString UNIT_TESTING CoordinatorAction coordinator_action action  time for event listeners to run  coord action workflow.xml getActualStart setTime add getAlertEvents setStartProcessed expectedEnd coordXml getJobId getSLAStatus  waiting for materialize command to run getEventQueue SLAStatus writeCmd execute getExpectedEnd ehs OozieClient jobId formatDateOozieTZ name actionId Arrays AppType getAppType test-coord-sla  resetting flag for testing sla event getExpectedDuration getActualEnd getTime getEventStatus EventStatus expectedStart getId getExpectedStart appPath  clear the coord-action WAITING event generated testCoordinatorActionCommands setAppTypes cal sc sleep writeToFile  test that sla processes the Job Event from Start command nominal get wf-credentials.xml jpa WorkflowJob nominal_time  command coordinator.xml nominalTime getAppName alert_events getJobStatus set appName Calendar clear authtoken assertEquals services getSLACalculator getNominalTime setStatus Thread call coord-action-sla.xml @1 IOUtils getTestUser wfXml toString  as per the sla xml wfAppPath slas getFsTestCaseDir ,oozie,1
getJobTrackerUri  getName testShellScript <argument>A</argument> <exec>sh</exec> getAppPath  Create the script file with canned shell command _testSubmit fs <env-var>var1=val1</env-var> actionXml  Create sample Shell action xml <shell> </file> create <argument>script.sh</argument> SHELL_SCRIPT_CONTENT write close <job-tracker> getNameNodeUri  Submit and verify the job's status # <argument>-c</argument> </job-tracker> getFileSystem script <name-node> </name-node> </shell> <env-var>var2=val2</env-var> w <file> <argument>B</argument> toString script.sh ,oozie,1
request conn resolve getRequest sendResponseHeader when receiveRequestHeader Assert httpservice flush context create verify Boolean close process keepAlive HttpStatus thenReturn ArgumentMatchers setCode handle sendResponseEntity testNoContentResponse Method assertSame getEntity any / never responseFactory Mockito response HttpCoreContext newHttpResponse httprocessor connReuseStrategy handleRequest handlerResolver ,httpcore,0
reinitialize newApplicationId handle assertEquals appAttemptId Assert testAppAttemptMetrics schedular appId getRootQueueMetrics getAppsSubmitted newApplicationAttemptId metrics event dispatcher rmContext user BuilderUtils queue ,hadoop,1
offer c size fcq assertTrue  It's full testOfferFailsWhenFull assertFalse assertEquals mockCall ,hadoop,0
 encode a data size get assertEquals decode inMap put outMap bake_in_a_header_an_empty_value ,ninja,0
"Max queue flush timeout \( assertContainsMatch  ms\) exceeded.  @SuppressWarnings(""deprecation"") maxFlushTime start stopExitsWhenMaxRuntimeReached loopLen statusChecker setMaxFlushTime  runtime of 0 means wait forever, so use 1 ms instead  confirms that stop exited when runtime reached addAppender stop la doAppend verify  confirms that all entries do end up being flushed if we wait long enough delayingListAppender join asyncAppenderBase ",logback,0
getInetAddress conn getLocalPort testSocketBind remoteSockAddress when localSockAddress getLocalAddress bind Assert assertTrue remoteAddress localPort getLocalSocketAddress thenReturn remotePort getRemoteAddress assertEquals getPort 127.0.0.1:8888<->10.0.0.2:80 isOpen Mockito localAddress getByAddress toString socket InetAddress getRemoteSocketAddress ,httpcore,0
 server checkCoordAction CoordELFunctions assertFalse addPartition addInitRecords getWaitingActions default  be READY /dt=20120430;country=usa  Make first dependency available assertTrue get CoordinatorAction  Checks for all missing dependencies testUpdateCoordTableMultipleDepsV3 tablename newHCatDependency table newHCatDependency2 newHCatDependency1 hcatService populateTable dt=20120430;country=brazil hcat:// pdms isRegisteredForNotification / call Services contains assertNull /dt=20120430;country=brazil actionId db ,oozie,1
bundleJobGetExecutor getTime addRecordToBundleJobTableWithPausedTime getId assertEquals getStatus execute testBundleRerunInPrep call Services pauseTime assertNotNull get curr Job job action2 jpaService ,oozie,1
getCurrentDateafterIncrementingInMonths getId run DateUtils getStatus addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob sleep get testCoordStatusTransitServiceDoneWithError CoordinatorAction end currentDatePlusMonth start assertEquals XDataTestCase execute addRecordToCoordJobTable CoordinatorJob Services runnable coord-action-get.xml job jpaService ,oozie,1
ContentType listener CoreMatchers setExceptionCallback getCause AsyncServerBootstrap listen instanceOf IOReactorConfig Assert getDuration create https /stuff setLookupRegistry requester localhost setStreamListener LoggingExceptionCallback LoggingHttp1StreamListener setIOSessionListener resultFuture1 * setSoTimeout Method assertThat execute LoggingConnPoolListener fail ex SecureAllPortsStrategy TIMEOUT server setIOReactorConfig cause bootstrap H2RequesterBootstrap setConnPoolListener setTlsStrategy some stuff setIOSessionDecorator testTLSTrustFailure createServerSSLContext get ExecutionException expected getAddress createDefault SSLContexts SSLTestContexts address custom start target getTimeUnit LoggingIOSessionDecorator getPort build future LoggingIOSessionListener register ,httpcore,0
server getCurrentUser RPC configureSuperUserIPAddresses getProxySuperuserGroupConfKey GROUP_NAMES DefaultImpersonationProvider getUser newEmptyRequest conf run retVal testRealUserGroupAuthorizationFailure Assert setStrings REAL_USER_SHORT_NAME refreshConf client setProtocolEngine addr setConfiguration UserGroupInformation proxyUserUgi printStackTrace e group3 getClient createRemoteUser REAL_USER_NAME fail doAs getTestProvider stop setupTestServer PROXY_USER_NAME The RPC must have failed  realUserUgi createProxyUserForTesting ,hadoop,0
createGSet  test put with a null element data  test remove while iterating put remove  okay because data[0] is not in gset Assert  test putting an element which is not implementing LinkedElement GOOD: getting  get  test get with a null element info  test contains LightWeightGSet resizable e  test iterator  test put new element while iterating gset  exception because data[1] is in gset testExceptionCases fail contains  test put existing element while iterating  test get  test contains with a null element v  test put ,hadoop,0
conn setRequestMethod IS_SECURITY_ENABLED testInstrumentation /v0/admin/* assertTrue json content-type Collections runTest JsonTags RestConstants openConnection containsKey HttpServletResponse assertEquals parse getInputStream url JSONValue call getHeaderField GET getResponseCode createURL startsWith ,oozie,1
testBadECLevel forBits ErrorCorrectionLevel ,zxing,0
2009-12-15T01:00Z getId coordJobGetExecutor getStatus addRecordToCoordActionTable assertNotNull get CoordinatorAction Job init RestConstants false destroy assertEquals services execute addRecordToCoordJobTable call Services setSystemProperty testCoordRerunInDoneWithError StatusTransitService job jpaService coord-rerun-action1.xml ,oozie,1
fruitContext print simpleConfigurator statusListenerWithPrefix.xml StatusPrinter IMPLCIT_DIR assertIsErrorFree doConfigure je checker statusListenerWithPrefix ,logback,0
scriptExecutor session  Given simple crud  When of id EntityAsChild/insert_single_row.cql SELECT * FROM entity_child WHERE id =  table should_delete_by_id executeScriptTemplate all RandomUtils manager isEmpty nextLong rows assertThat execute ImmutableMap  Then Long deleteById ,achilles,1
lookup matcher testLookupInvalidInput ,httpcore,0
 previous warnings. monotonicNow incrementAndGet logWarning  t = 0 get lock  t = 2800 suppressed  t = 2400 wsuppresed  t = 1100 set unlock getMethodName wlogged LOG mclock mlock assertEquals testLockLongHoldingReport testname  t = 700 name mock time  t = 200 ,hadoop,0
"abc?def î€€ testNonPrintableCharacters ?ab? xó°€€yô¿½zá ab  -ï»¿--  Formatting Unicode â£	   -?-- x?yz x?ð¤€yz abc def  Standalone surrogate character (not in a pair) abc	def Should replace private use U+E000 Should replace multiple control characters Should replace standalone surrogate mixed with valid pair ?abc?def ???? -?-?-  Control characters x?yz ??  Private use Unicode  Unassigned Unicode Should replace single control character U+10FFFD, but keep U+1050 Should replace unassigned U+30000 and U+DFFFF Should replace Invisible Separator -ð°€€-óŸ¿¿- Should replace Byte Order Mark Should replace standalone surrogate U+DB80 expect Should replace private use in Plane 15 and 16: U+F0000 and  x?y?zá î„£abcï² Should replace all control characters ?abc? Should replace mixed characters starting with a control x?ð¤€yz ? Should replace private use U+E123 and U+F432 ",hadoop,0
checkSubworkflowLibHelper childLibs1 expectedLibs1 expectedLibs2 expectedLibs3 expectedLibs4 expectedLibs5 same.jar testCreateProtoConfWithSubWorkflowLib3 childLibs3 parent2.jar childLibs2 childLibs5 child1.jar childLibs4 inheritWF parentLibs2 parentLibs3 parentLibs1 parent1.jar parentLibs4 parentLibs5 inherit child2.so true ,oozie,1
readFields workflow toByteArray dos testEmptyWriteRead baos write close dis ,oozie,1
xxxxtestxxxx testFullRegion setRegex test testxxxx assertTrue start .*test.* matcher matches xxxxtest ,logback,0
play A server /foo readAscii addHeader B openConnection assertEquals setBody enqueue getUrl /bar Cache-Control: max-age=60 Content-Location: /bar contentLocationDoesNotPopulateCache ,okhttp,1
src StandardCharsets createByteBuffer decodeIndexedHeader hasRemaining assertFalse assertHeaderEquals dynamicTable assertEquals decoder Decoding completed Assert :method testIndexedHeaderDecodingRFC7541Examples GET header dynamicLength ,httpcore,0
handler getCurrentUser getEndJobCommitFailureFile conf stagingDir toApplicationAttemptId when assertNotNull FileSystem commitJob getClock UserGroupInformation init waitForItHandler getApplicationID mockCommitter thenReturn getEventHandler Intentional Failure getAndClearEvent handle getEndJobCommitSuccessFile MRApps jobId doThrow stop mock startCommitFile MRJobConfig getApplicationId assertFalse ConverterUtils fs testFailure mockJobContext getApplicationAttemptId assertTrue get verify appattempt_1234567890000_0001_0 fromYarn getShortUserName set getStartJobCommitFile endCommitFailureFile e toYarn start mockClock any endCommitSuccessFile TypeConverter mockContext exists user attemptid ,hadoop,1
getBytesTransferred CodecTestUtils testCodingFragmentBuffering channel times Assert flush verify writeLine dump chbuffer write ArgumentMatchers StandardCharsets assertEquals encoder any never header stuff Mockito outbuf header metrics spy wrap append stuff ,httpcore,0
hasFieldViolation getFieldViolations invoke assertEquals validationShouldBeAppliedInCorrectOrderPreFail validation.required.violation param1 requiredInt size getMessageKey assertTrue get context create verify mockController validation ,ninja,0
assertFalse getCurrentDateafterIncrementingInMonths getId run DateUtils isPending addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob assertNotNull get CoordinatorAction end currentDatePlusMonth waitFor start XDataTestCase execute addRecordToCoordJobTable CoordinatorJob jobId Services runnable coord-action-get.xml testCoordStatusTransitServiceKilledByUser2 job jpaService evaluate ,oozie,1
chrootFs testAclMethodsPathTranslation mockfs://foo/a/b removeDefaultAcl removeAcl conf setAcl URI getRawFileSystem rawPath emptyList fs.mockfs.impl /c chrootUri /a/b/c create verify Collections removeAclEntries getAclStatus setClass entries chrootPath modifyAclEntries mockFs ,hadoop,0
storePassword getResource toCharArray serverSocket newSingleThreadExecutor Executors serverSslContext asList getServerSocketFactory Assert bind assertNotNull nopassword isWindows create Boolean SSLContextBuilder /test-client.p12 localhost startHandshake read localPort loadKeyMaterial loadTrustMaterial resource2 thrown inputStream setSoTimeout getInputStream /test-server.p12 resource1 accept contains createSocket testSSLHandshakeProtocolMismatch2 clientSslContext TIMEOUT Arrays supportedServerProtocols getSupportedProtocols getLocalPort submit supportedClientProtocols clientSocket SSLv3 assertTrue TLSv1 keyPassword close connect assertEquals setEnabledProtocols call getSocketFactory expect build toMillisecondsIntBound socket getSession createServerSocket ,httpcore,0
actual getReplacementCommand ls expected Ls.getReplacementCommand assertEquals  check there's no replacement command ,hadoop,0
buildMatrix getVersionForNumber MatrixUtil  Mask pattern 3  1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 0  matrix  1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 0   0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1  Version  1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1   1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 1 1 1 0  testBuildMatrix  1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1   1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0   1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1  c  From http://www.swetake.com/qr/qr7.html  0 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0   1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1   1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0  expected bits  Version 1  1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 0   1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0   0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 1  assertEquals  1 0 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 1  appendBits bytes  0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0   1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0   1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1  toString  1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1  ErrorCorrectionLevel  1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 1 1   1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0  ,zxing,0
 Check if dummyRun called only once server handler isOne dummyRun newProxyInstance start conf getClassLoader setCallIdAndRetryCount assertThat RetryProxy proxy Proxy testNoRetryOnInvalidToken stop provider RetryPolicies client create failoverOnNetworkException retryProxy Client ,hadoop,0
"newHashMap  router.GET().route(""/user/{id}/{email}/userDashboard"").with(ApplicationController.class, ""userDashboard""); assertEquals put myEmail testReverseRoutingWithArrayAndWrongAmountOfQueryParameters 100 1 userDashboard 2 router Maps paging_size 3 startServer myId generatedReverseRoute id page getReverseRoute map email ",ninja,1
getClass endDate reader Job should be purged. Should fail. conf run getStatus getJob getTestGroup dex getTestCaseDir /workflow.xml file:// workflow.xml waitFor wfJobGetCmd external-status testPurgeServiceForWorkflow execute OozieClient jobId fail ex copyCharStream getResourceAsReader File evaluate submitJob System sleep wfBean engine setStrings getErrorCode get purgeRunnable ok WorkflowJob a set wf-ext-schema-valid.xml assertEquals call Services IOUtils getTestUser t signal-value u based_on_action_status currentTimeMillis setEndTime wfUpdateCmd writer ErrorCode jpaService ,oozie,1
perm applyUMask foo assumeNotWindows conf f1 none f2 delete /foo_copy localfs FileSystem foo1 FsPermission setPermission foo2 testLocalFSsetPermission writeFile filename2 filename1 all  create files and manipulate them. set getPermission CommonConfigurationKeys initialPermission f assertEquals TEST_PATH_PREFIX copyPath 044 filename cleanup rename getLocal exists getUMask getFileDefault copyPermission ,hadoop,0
cluster conf getFileSystem testFileNotFound fs simulatedStorage /nonexistingfile.dat build SimulatedFSDataset file1 close shutdown append setBoolean ,hadoop,1
getBytesTransferred CodecTestUtils channel times Assert flush verify writeLine dump chbuffer write ArgumentMatchers StandardCharsets assertEquals encoder any never header stuff testCodingFragmentBufferingLargeFragment Mockito outbuf header metrics spy wrap append stuff ,httpcore,0
afterLogout SUCCESS beforeLogin getPage getContent ADMIN = true afterLogin url contains logout testShiroLoginAsFeatureAdmin USER = ck assertTrue USER = null login?user=ck client loginPage user ADMIN = null logoutPage ,togglz,1
encode  RS Java coder testRSCoder performBench decode RawErasureCoderBenchmark ,hadoop,0
setDouble configuration DOUBLE_DELTA getDouble assertEquals value testDouble ,hadoop,0
actual testNamingStrategyThatWorkedInOneDotOhContinuesToWork spring.jpa.hibernate.namingstrategy: getJpaPropertyMap org.hibernate.cfg.EJB3NamingStrategy equalTo refresh assertThat hibernate.ejb.naming_strategy EnvironmentTestUtils addEnvironment get setupTestConfiguration getBean bean ,spring-boot,1
nn_host/ getDefaultUri set tetGetDefaultUriNoSchemeTrailingSlash intercept FileSystem conf No scheme in default FS FS_DEFAULT_NAME_KEY ,hadoop,0
lookup h unregister h1 h2 testRegisterUnregister h3 matcher Assert assertNull assertTrue assertNotNull /h1 /h2 /h3 register ,httpcore,0
"NULL_STR ,, A B splits ESCAPED_STR_WITH_COMMA B\\ assertEquals STR_WITH_ESCAPE STR_WITH_BOTH2 A\, split STR_WO_SPECIAL_CHARS STR_WITH_COMMA ESCAPED_STR_WITH_BOTH2 testSplit StringUtils EMPTY_STR ",hadoop,0
FileSystemTestHelper file:///tmp/dirFooBar testRenameAcrossFs /newDir/dirFoo rename mkdirs /tmp/dirFooBar fSys isDir ,hadoop,0
key1 p1 p2 getKMSUrl kp e anyString thenReturn keyName conf when warmUpEncryptedKeys getCause fail doThrow times Should fail since both providers threw IOException Mockito assertTrue mock verify testWarmUpEncryptedKeysWhenAllProvidersFail ,hadoop,0
cluster handler hi setLastHeartbeatTime setHardwareProfile hm setHostname  After registration and by HeartbeatMonitor setNodeStatus getCluster mapHostsToCluster centos5 handleRegistration reg setResponseId join getHost info add addCluster LOG commandCaptor getServerVersion getAllValues capture am eq Role isAlive fail setAgentVersion size name YYY mock aqMock addServiceComponent HDP-0.1 shutdown setDesiredStackVersion setOS hostNames getServiceName System sleep hostname1 addService assertTrue Centos5 clusterName cmds HeartbeatMonitor should generate StatusCommands for host1 forClass verify HostStatus persist injector clusters setTimestamp getServiceComponent ArgumentCaptor handleHeartBeat HeartbeatMonitor should be already stopped cool ambariMetaInfo start HDFS assertEquals addServiceComponentHost serviceName addHost command testHeartbeatStateCommandsEnqueueing Thread enqueue setOsType currentTimeMillis hdfs heartbeatMonitorWakeupIntervalMS hb atLeast getInstance ,ambari,1
getNameNodeUri listStatus testFsDir getFileSystem testDir fs contains getTestUser fsTestDir assertTrue assertNotNull getTestCaseDir exists toString user getUri getFsTestCaseDir nameNode startsWith ,oozie,1
bundleJobGetCmd addRecordToBundleJobTable getId assertEquals getStatus execute call Services testBundleSuspendWithError2 assertNotNull get Job job jpaService ,oozie,1
svc init stop l2 unregisterServiceListener listener start testServiceNotificationsUnregisterDuringCallback registerServiceListener assertEventCount ,hadoop,0
testEncodeDecodeRandom testEncodeDecode testAztec GenericGF  compact mode message  real life test cases  full mode message ,zxing,0
getBuildInfo END_POINTS getProperty IS_SECURITY_ENABLED getContextURL oozieUrl assertEquals wc call testClientBuildVersion BuildInfo SERVLET_CLASSES runTest getClientBuildVersion ,oozie,1
getBytesTransferred CodecTestUtils testCodingFragmentBufferingChannelSaturated channel times Assert flush verify more stuff dump write ArgumentMatchers StandardCharsets length assertEquals encoder - any stuff--- Mockito outbuf metrics spy wrap stuff ,httpcore,0
addHeader /_non_existing_url HttpConstants Request NinjaConstant CoreMatchers equalTo assertEquals message assertThat makeRequest url path Assert response GET testThatNotFoundWorksJson payloadJsonAs testServerUrl ,ninja,0
"statelessWorkerDeactivationTest  this will force the creation of concurrent activations in each node 1000 awaitFor  touch a single activation (that will probably not be collected) createStage  this will collect all but one activation actor5  increment the clock assertTrue get client TimeUnit toMillis getReference incrementTimeMillis createClient add  now there should be a single element from the first set1 that still exists here.  and no other ids will match getUniqueActivationId  there should be multiple activations, off course statistics might let use down here. theSurviving set2 f assertEquals clock futures contains size cleanup  multiple activations, again IActor set1 isIdle unused  do the shenanigans again stage1 retainAll ",orbit,1
 create keys and put it in wrong number of keys in the Storage getSecretKeyMap tmpFileName  compare secret keys put dis  get the tokens and compare the services getTokenMap tokenMap assertNotNull token1 token2 secretKeyMap write add getKey  not found entrySet DEFAULT_HMAC_ALGORITHM getEncoded containsKey service2 unchecked service1 testReadWriteStorage readFields entry size  open and read it back getTokenMap should return collection of size 2 Arrays alias1 dos alias2 Token for service  delete tmpDir sometoken2 sometoken1 Keys don't match for alias  assertTrue Secret key for alias  get alias Token for alias  kg addSecretKey KeyGenerator close key addToken  create file to store numberOfSecretKeys  create tokenStorage Object assertEquals services m getService generateKey setService getValue  must be present equals getInstance ts tokenStorageTest ,hadoop,0
assertCorrectImage2string testDecodeRow2string28 (10)1098/1234 28.png ,zxing,0
localhost uribuilder testHierarchicalUri assertEquals uri result fragment param=stuff Assert /some stuff build http http://stuff@localhost:80/some%20stuff?param=stuff#fragment stuff ,httpcore,0
@ getCoordAction closeTrx getStore getTime run workflows getStatus no-op/lib sleep UNIT_TESTING get beginTrx getTestCaseDir createTestCaseSubDir CoordinatorAction action recoveryRunnable commitTrx waitFor bean actionNum ce in store2 store no-op testCoordActionRecoveryServiceForSubmitted addRecordToJobTable -testCoordRecoveryService-C jobId Services fail getTestUser addRecordToActionTable actionId 0000000- evaluate getCoordinatorAction ,oozie,1
ofSeconds CoreMatchers equalTo compareTo assertThat NullPointerException expected tv1 tv3 tv2 fail tv5 tv4 Assert tv6 ofMilliseconds testCompareTo ofMinutes TimeValue ,httpcore,0
hasData CoreMatchers equalTo length clear ExpandableBuffer assertThat put capacity mode Assert setInputMode testBasics buffer ensureCapacity ,httpcore,0
setJobId getTime /v1/jobs parseDateUTC DateUtils Coord3@1 cal array testDefaultStatus CoordinatorAction setId CREATE_TIME setCreatedTime Coord3  adding coordinator action #4 to Coord#3 runTest setTime add setNominalTime Calendar assertEquals execute setStatus actionInsert call size bundleName getInstance _requestToServer bulkRequest jpaService bundle= action4 ,oozie,1
hive END_POINTS IS_SECURITY_ENABLED lib oozieUrl conf wc /test System localhost:9001 libPath assertTrue getTestCaseDir get CREATE EXTERNAL TABLE ${NAME} (a INT); SERVLET_CLASSES write close runTest getContextURL hiveScriptFile XOozieClient MockDagEngineService hdfs://localhost:9000 assertEquals getFileSystem params submitScriptLanguage call OozieClient NAME=test mkdirs setProperty wfCount createConfiguration toString writer testSubmitHive getFsTestCaseDir ,oozie,1
testGetValidIndexes  Check valid indexes numInputs chunkSize CoderUtil inputs getValidIndexes assertEquals validIndexes ,hadoop,0
conn setRequestMethod IS_SECURITY_ENABLED /v0/admin/* assertTrue json content-type Collections runTest RestConstants openConnection containsKey HttpServletResponse assertEquals parse USER getInputStream url JSONValue call testOsEnv getHeaderField GET getResponseCode createURL startsWith ,oozie,1
cluster /texttest getWorkingDirectory set texttest conf getFileSystem dfs textTest build numDataNodes getLocal TEST_ROOT_DIR makeQualified FileSystem fs.default.name lfs toString testText shutdown getUri ,hadoop,1
/0/1/2/mode/test Request CoreMatchers equalTo test mode works. assertThat makeRequest url path Assert testTestModeIndex012 response GET testServerUrl ,ninja,0
 getRuntimeDir init getSystemId getProperty testDefaultServices oozie- destroy user.name shouldBe services System oozie-dummy.xml Services assertTrue assertNotNull setSystemProperty get exists ConfigurationService startsWith ,oozie,1
Assert size Incorrect encoded size Byte testVLong4Bytes assertEquals writeAndVerify Short ,hadoop,0
"deleteList  Check whether transactions are rolled back or not Expected exception due to commit failure but didn't get any addRecordToWfActionTable PREP getId WorkflowInstance  status should NOT be RUNNING deactivate wfBean addRecordToWfJobTable assertNotNull wfUpdateCmd1 get testBulkUpdatesDeletesRollback WorkflowJob updateList add getStatusStr  Add two actions to delete list wfGetCmd assertEquals SkipCommitFaultInjection execute setStatus FaultInjection 1 Services fail 2 WorkflowAction org.apache.oozie.command.SkipCommitFaultInjection setSystemProperty true action1  set fault injection to true, so transaction is roll backed job action2  Add to update list WF action should not be removed due to rollback but was not found jpaService ",oozie,1
executeScriptTemplate logAsserter prepareLogLevelForDriverConnection isNotNull actual RandomUtils scriptExecutor manager  Given nextLong assertThat ImmutableMap LOCAL_QUORUM assertConsistencyLevels crud EntityWithStaticAnnotations/insert_single_row.cql  When of findById get  Then Long id should_find_using_static_consistency ,achilles,1
CommonConfigurationKeysPublic testConnectionRetriesOnSocketTimeoutExceptions  set max retries to 3 conf  set max retries to 0 assertRetriesOnSocketTimeouts setInt ,hadoop,0
dateFormat getTimeZone equalTo CoreMatchers invoke String compareTo when getBytes cal assertTrue testValidXmlBody context setTimeZone xmlDocument close setTime bodyParserEngineXml thenReturn Calendar BodyParserEngineXmlTest format testForm is parse assertThat getInputStream TimeZone <form><firstName>%s</firstName><lastName>%s</lastName><birthYear>%d</birthYear><lastSeen>%s</lastSeen></form> Mockito xmlObjMapper getInstance ,ninja,0
"cluster lm  lease, expected 1 waitLeaseRecovery conf REPLICATION_NUM createFile waitActive oldSize lastblock Testing that lease recovery cannot happen during safemode. filepath  connect to data nodes DataNode  verify that we still cannot recover the lease currentGS getNamenode datanodeinfos create testBlockSynchronization getLastLocatedBlock info /foo DFSConfigKeys getBlockPoolId newblocks= getFileSystem dfs countLease setLong getGenerationStamp numDataNodes dfs.dfs.clientName=  expire lease to trigger block recovery. getDataNode Found  getLocations updatedmetainfo shutdown filestr ORG_FILE_SIZE NameNodeAdapter HdfsConstants BLOCK_SIZE waitReplication System TestInterDatanodeProtocol getNumBytes getBlockId assertTrue /foo.safemode  verify that lease recovery does not occur when namenode is in safemode DFSTestUtil getLeaseManager getBlock assertEquals setSafeMode  get block info for the last block getNameNodeRpc getStoredBlock datanodes locatedblock  verify Block Info dfs.support.append getIpcPort build checkMetaInfo  create a file exists append setBoolean getNamesystem ",hadoop,1
getCounters a 1 getValue 2 b size incr testInstrumentationCounter inst get assertEquals ,oozie,1
"12345678901234561234512345 getName dst CodecTestUtils channel convert Assert inbuf assertTrue get isCompleted read fghij testComplexDecoding StandardCharsets Footer1 hasRemaining abcde Footer2 clear bytesRead 5 12345 5 12345 0 Footer1: abcde Footer2: fghij   assertEquals decoder ByteBuffer 10;key=""value"" 1234567890123456  trailers getValue allocate size metrics getTrailers ",httpcore,0
ErasureCodeConstants coder testGetCoderByNameWrong WRONG_RS assertNull getCoderByName getInstance CodecRegistry ,hadoop,0
Bundle Job should have been purged Bundle Action should have been purged addRecordToBundleActionTable addRecordToWfActionTable coordActionGetCmd DateUtils WorkflowInstance getStatus testPurgeBundleWithCoordChildWithWFChild3 addRecordToCoordActionTable parseDateOozieTZ bundleJob BundleJobBean assertNotNull Coordinator Action should have been purged CoordinatorAction Job wfAction wfJobGetCmd execute CoordinatorJob 1 coordJobGetCmd fail WorkflowAction coordAction SUCCEEDED je bundleJobGetCmd getId coordJob wfJob Workflow Job should have been purged addRecordToWfJobTable getErrorCode get WorkflowJob getAppName bundleAction Coordinator Job should have been purged Workflow Action should have been purged wfActionGetCmd 2011-01-01T01:00Z addRecordToBundleJobTable assertEquals addRecordToCoordJobTable call Services coord-action-get.xml ErrorCode jpaService bundleActionGetCmd ,oozie,1
date scriptExecutor tableNameFor session  Given tableName crud SELECT * FROM  should_delete_with_schema_name_provider simple_delete_with_schema_name provider  When of id row table SimpleEntity/create_simple_mirror_table.cql executeScriptTemplate withSchemaNameProvider RandomUtils manager one  WHERE id =  nextLong assertThat execute ImmutableMap SimpleEntity/insert_single_row.cql keyspaceFor  Then isNull Long deleteById buildDateKey DEFAULT_CASSANDRA_EMBEDDED_KEYSPACE_NAME ,achilles,1
bundleJobGetExecutor addRecordToBundleActionTable getTime addRecordToBundleJobTableWithPausedTime assertFalse getId testBundleRerunInPaused getStatus isPending pauseTime assertNotNull get curr Job assertEquals execute addRecordToCoordJobTable call getPauseTime CoordinatorJob Services action1 job action2 jpaService ,oozie,1
2009-12-15T01:00Z 2009-12-16T01:00Z getId DateUtils getStatus getExternalId addRecordToCoordActionTable myapp parseDateOozieTZ testActionStartWithEscapeStrings coordJob  is : assertTrue assertNotNull get CoordinatorAction action end  expected to be NOT SUBMITTED (i.e. RUNNING) waitFor wfAction coord-action-start-escape-strings.xml start undef myjob wfActionId execute addRecordToCoordJobTable wfActions call CoordActionStartCommand didn't work because the status for action id CoordinatorJob Services fail getTestUser size actionId jpaService wfId evaluate ,oozie,1
"date https://www.example.com private getDynamicEntry foo=ASDJKHQKBZXOQWEOPIUAXQWEOIU; max-age=3600; version=1 content-encoding assertHeaderEquals dynamicTable setMaxSize getCurrentSize set-cookie Assert get :status cache-control testResponseDecodingWithoutHuffmanRFC7541Examples StandardCharsets Mon, 21 Oct 2013 20:13:22 GMT createByteBuffer Mon, 21 Oct 2013 20:13:21 GMT assertEquals headers2 gzip decoder headers3 headers1 200 size 302 src1 decodeHeaders location 307 src3 src2 dynamicLength ",httpcore,0
headers /i18n/en de-DE getServerAddress ninjaTestBrowser newHashMap /i18n/de makeRequest put  language on the root. result testThatExplicitLangSettingWorks TEXT_EN contains  2) test that fallback is accept-language header Maps /i18n/tk assertTrue  4) normal operation TEXT_DE Accept-Language  1) test that overriding of accept-language header works ,ninja,1
play ping android  play it back headerEntries  verify the peer received what was expected STREAM_IN_USE TYPE_RST_STREAM cola stream was reset: STREAM_IN_USE acceptFrame stream TYPE_HEADERS peer getResponseHeaders roundTripTime TYPE_PING connection  Ensure that the 2nd SYN REPLY has been received. takeFrame rstStream banana a b synReply c read expected getMessage assertEquals  RST_STREAM HeadersMode fail  SYN_STREAM sendFrame SPDY3 getSource  PING synStream remoteDoubleSynReply newStream ,okhttp,1
assertCorrectImage2string testDecodeRow2string26 (10)5678(11)010101 26.png ,zxing,0
date rs %msg - [%thread]%n Set scriptExecutor ASYNC_LOGGER_STRING  Given update simple 0 AM withLwtResultListener Eq prepareLogLevel  When of await should_dsl_update_value_async where id latch countDown getAndSet value executeAsync table info executeScriptTemplate logAsserter onError RandomUtils manager withResultSetAsyncListener nextLong SimpleEntity/insert_single_row.cql ImmutableMap assertContains CALLED if_Value success  Then Long buildDateKey LOGGER new value fromBaseTable dsl Called - [achilles-default-executor onSuccess ,achilles,1
" statusLine testSLParse Not Found getReasonPhrase  status line with multi word reason phrase Assert  reason phrase can be anyting HTTP/1.1 200 HTTP/1.1 404 Non Trouve OK HttpVersion HTTP/1.1 200 OK  this is not strictly valid, but is lenient HTTP/1.1 404 Not Found  Non Trouve HTTP/1.1 200  parseStatusLine  HTTP/1.1 200 OK   HTTP/1.1 200 OK clear assertEquals HTTP/1.1     200 OK getProtocolVersion buf getStatusCode  this is valid according to the Status-Line BNF  its ok to end with a \n\r toString HTTP/1.1 404 Not Found  typical status line append ",httpcore,0
request conn inStream POST /stuff HTTP/1.1 User-Agent: test Transfer-Encoding:  getEndpointDetails getContent User-Agent getMethod when testReadRequestEntityChunckCoded getBytes content receiveRequestHeader chunked  3 123 0   receiveRequestEntity bind Assert isChunked assertTrue assertNotNull getPath /stuff getRequestCount StandardCharsets thenReturn assertEquals Method getEntity getContentLength getInputStream assertNull Mockito name socket containsHeader entity ,httpcore,0
prepare set testCodingDirectBufferWithConf_10x4_erasing_d0 CodecUtil RSRawErasureCoderFactory conf testCoding ,hadoop,0
"getName oozie.service.ProxyUserService.proxyuser.foo.groups foo user.name conf asList System Assert StringUtils assertNotNull get join nobody validate localhost init set oozie.service.ProxyUserService.proxyuser.foo.hosts getProperty getConf destroy services , Services fail ex testInvalidGroup proxyUser toString Arrays ",oozie,1
cluster fs2 fs1 Waiting for close to get to latch... conf run when waitActive waitForCall assertNotNull delayer create join write  write 1/2 block /testRecoverFinalized info proceed LOG anyString interruptAndJoin Waiting for close to finish. getFileSystem anyObject stm Killing lease checker preSpyNN contains No lease on /testRecoverFinalized numDataNodes spy shutdown recoverFile Telling close to proceed. testRecoverFinalizedBlock doAnswer assertTrue get client  error. close  Lose the leases set err getConf start Recovering file getMessage getNameNodeRpc  Delay completeFile AppendTestUtil t build spyNN createHdfsWithDifferentUsername Close finished. thrownByClose file1 complete ,hadoop,1
This is a test 20080504T123456Z DESCRIPTION:This is a test  doTest BEGIN:VCALENDAR BEGIN:VEVENT  DESCRIPTION:This is a test 	 with a continuation  testDescription DTSTART:20080504T123456Z  END:VEVENT END:VCALENDAR This is a test with a continuation ,zxing,0
Guice  this will not work => we expect a runtime exception... NinjaConstant thrown not_existing_implementation expect NinjaMode migrationEngine createInjector provider setProperty missingImplementationThrowsExceptionOnUseNotCreate getProvider getInstance ninjaProperties injector ,ninja,0
"getName oozie.service.ProxyUserService.proxyuser.foo.groups foo conf asList bar Assert StringUtils assertNotNull get join validate localhost init set oozie.service.ProxyUserService.proxyuser.foo.hosts getConf destroy testValidateAnyHostAnyUser * services , Services proxyUser Arrays ",oozie,1
request conn when setEntity flush executor context create verify OK postProcess testExecutionEntityEnclosingRequest process thenReturn Method getEntity execute / Mockito response HttpCoreContext httprocessor mock preProcess entity receiveResponseHeader sendRequestEntity sendRequestHeader receiveResponseEntity ,httpcore,0
Location: / play server /0 request addHeader receiver Redirecting to / assertCode setResponseCode setBody /20 url enqueue getUrl assertBody Success! build await client follow20Redirects ,okhttp,1
multiService fs2 addDelegationTokens credentials createFileSystemForServiceName fs1 fs4 fs3 testFsWithNestedDuplicatesChildren fs1B  down: multi-filter-multi-filter-filter-fs4. numberOfTokens  fs1+fs2+fs4+multifs (fs3=0) assertNotNull token2  we had added its token to credentials addToken superMultiFs multiTokenFs renewer service2 service1  does not have its own token service4  has its own token assertEquals assertSame singleTokenFs1 multiFs  has no tokens singleTokenFs4 singleTokenFs2 getToken mock verifyTokenFetch ,hadoop,0
"?op=RENEWDELEGATIONTOKEN&token= setHandler  unauthenticated access to URL  authenticated access to URL conn urlString Token ?delegation= dt /bar Assert /foo/bar assertNotNull context DispatcherType /foo  delegation token access to URL  cancel delegation token, nonauthenticated access to URL openConnection &op=CANCELDELEGATIONTOKEN&token= setContextPath createJettyServer getInputStream &delegation= nonAuthURL toExternalForm stop ?op=CANCELDELEGATIONTOKEN&token= addFilter &op=RENEWDELEGATIONTOKEN&token=  unauthenticated access to get delegation token setRequestMethod /foo/bar?authenticated=bar&op=RENEWDELEGATIONTOKEN&token= mapper authURL  renewew delegation token, authenticated access to URL HttpURLConnection of get jetty /* /foo/bar?authenticated=foo  cancel delegation token, authenticated access to URL map getJettyURL  get new delegation token readValue  cancel canceled delegation token, nonauthenticated access to URL testRawHttpCalls addServlet ?op=GETDELEGATIONTOKEN EnumSet  renewew delegation token, authenticated access to URL, not renewer start assertEquals url  renewew delegation token, unauthenticated access to URL PUT getResponseCode &op=GETDELEGATIONTOKEN&renewer=foo  delegation token and authenticated access to URL  authenticated access to get delegation token ",hadoop,0
Location: / play server /0 request addHeader receiver Too many redirects: 21 doesNotFollow21Redirects Redirecting to / setResponseCode setBody /20 url enqueue getUrl build await client assertFailure ,okhttp,1
"getStats testMultipleLoggersWithValues shouldLog getMax foo assertFalse assertEquals  All should log once the period has elapsed getCurrentStats timer bar helper  ""bar""/""baz"" should not log yet because ""foo"" hasn't been triggered assertTrue record LOG_PERIOD getMean baz getCount ",hadoop,0
waitFinish newFile Finished add taskLatch callbackLatch Starting add copyToFile randomStream file getStagingCacheStats assertTrue assertNotNull countDown ID_PREFIX getIfPresent info add cache LOG f  start accepted assertCacheStats folder stage assertFile ,jackrabbit,1
abc printStackTrace def e foo prepareXmlWithInclude conf assertEquals parentXml XInclude failed fail bar oozie.dummy getTestCaseDir get testAddXIncludeFromStream  verify the properties from include file DEFAULT ,oozie,1
  should work when metrics system is not started ms testRegisterDups ts2 ts1 getSource assertNotNull assertNotSame s1 shutdown register s2 ,hadoop,0
/storagePolicy storagePolicyPath chrootFs setClass mockfs://foo/a/b /a/b/storagePolicy conf URI chRootedStoragePolicyPath getRawFileSystem getStoragePolicy fs.mockfs.impl testGetStoragePolicy chrootUri create verify mockFs ,hadoop,0
setName cfDef DynamicCF updateColumnFamily getCfDefs birthdate getColumnMetadata getName setValidationClass ComparatorType columnDefinition keyspaceDefinition toByteBuffer asList DynKeyspace3 testEditColumnFamily org.apache.cassandra.locator.SimpleStrategy get HFactory ColumnIndexType describeKeyspace StringSerializer cassandraCluster fromCluster createKeyspaceDefinition addColumnDefinition assertEquals columnFamilyDefinition addKeyspace fromByteBuffer setIndexType setKeyspaceName getClassName Arrays ,hector,1
testReadSymlink getAbsolutePath assertFalse link del symLink assertEquals delete result Assert file _link readLink mkdirs exists  Create a symbolic link FILE FileUtil ,hadoop,0
getBytesTransferred a lot more stuff! rw stuff;  CodecTestUtils more stuff;  channel Assert inbuf getChannel pos stuff; more stuff; a lot more stuff! close fchannel isCompleted testfile StandardCharsets length bytesRead assertEquals createTempFile decoder fill transfer  count everything except the initial 7 bytes that went to the session buffer readFromFile metrics testDecodingFileWithBufferedSessionData ,httpcore,0
lm jobConf prepareBlock </prepare> user.name  when there is prepare block in workflow XML fs createJobConf oozie.action.prepare.xml 1@a assertTrue <prepare> <mkdir path=' '/> get getNameNodeUri set actionConf 1@a-0 actionDir getFileSystem testSetupLauncherInfoWithNonEmptyPrepareXML getAuthority Services 1 getTestUser newDir equals fs.default.name setupLauncherInfo  Setting up the job configuration getFsTestCaseDir ,oozie,1
"new_val scriptExecutor session ""overRiden"" LOCAL_ONE  Given insert SELECT * FROM entity_static_annotations WHERE partition_key =  crud EntityWithStaticAnnotations/insert_single_row.cql  When of id value should_insert_using_static_strategy_an_consistency_level executeScriptTemplate logAsserter prepareLogLevelForDriverConnection isNotNull actual RandomUtils manager one getString nextLong assertThat execute ImmutableMap assertConsistencyLevels usingTimeToLive  Then Long isEqualTo overriden_val entity ",achilles,1
"oryx.input-schema.target-feature startServerProduceConsumeTopics MAX_DEPTH DATA_TO_WRITE GEN_INTERVAL_SEC put oryx.input-schema.categorical-features ""4"" oryx.input-schema.num-features oryx.batch.update-class model Boolean targetEncoding getMostProbableCategoryEncoding oryx.rdf.hyperparams.max-depth expected  Low values like 2 are deliberately bad, won't work getValueEncodingMap * MLUpdate Model instance dirs: {} size [""0""] No such model file:  [""4""] NumericFeature forest PMMLUtils log expectedPositive RDFPMMLUtils getTempDir assertTrue get Files ] modelInstanceDirs oryx.batch.streaming.block-interval-sec {} set modelFile IMPURITY pmml assertEquals getExtensions getConfig maxDepth oryx.batch.storage.data-dir IOUtils MAX_SPLIT_CANDIDATES getSecond exists toString maxSplitCandidates config No models? impurity getName data resolve oryx.rdf.hyperparams.impurity dataDir ConfigUtils oryx.input-schema.id-features f1 f2 f3 checkIntervals oryx.ml.eval.candidates getFirst oryx.batch.storage.model-dir info read oryx.ml.eval.parallelism encoding latestModelDir testRDF WRITE_INTERVAL_MSEC prediction overlayOn modelDir oryx.rdf.num-trees assertFalse startMessaging forestEncoding [2, forValue predict oryx.rdf.hyperparams.max-split-candidates checkExtensions listFiles NUM_TREES intValue isEmpty oryx.batch.streaming.generation-interval-sec tempDir overlayConfig BLOCK_INTERVAL_SEC ",oryx,1
creationExpiration testLightWeightCache checkSizeLimit  test size limit dataSize nextInt check sizeLimit  test randomized creation expiration with zero access expiration accessExpiration  test randomized creation/access expiration periods ran modulus ,hadoop,0
server TestProtocol RPC configureSuperUserIPAddresses getProxy aMethod GROUP_NAMES conf run retVal Assert REAL_USER_SHORT_NAME stopProxy addr UserGroupInformation getServer ret proxyUserUgi printStackTrace e start createRemoteUser testRealUserGroupNotSpecified getConnectAddress REAL_USER_NAME proxy fail doAs NetUtils stop ADDRESS PROXY_USER_NAME The RPC must have failed  realUserUgi createProxyUserForTesting ,hadoop,1
      a a testTextContainsBlanks containsBlanks Assert assertTrue assertFalse TextUtils 	 ,httpcore,0
Expected to fail as action 4 should have been deleted getTime pausetime= getId DateUtils getStatus addRecordToCoordActionTable coordGetCmd coordJob pauseTime getErrorCode get CoordinatorAction end  4 hrs jpae Job printStackTrace start assertEquals execute  2 hrs call getPauseTime pauseTimeChangeStr CoordinatorJob Services fail coord-action-get.xml getLastActionNumber testCoordChangePauseTime formatDateOozieTZ addRecordToCoordJobTableForPauseTimeTest ErrorCode Expected to fail as action 3 should have been deleted job jpaService ,oozie,1
SelectionKey verifyNoMoreInteractions getWindow testWindowUpdate update verify assertEquals setEvent window eq ioSession ,httpcore,0
principalNameWoRealm getHostName HTTP/abc.com@EXAMPLE.COM getServiceName HTTP assertEquals getRealm principalNameFull testParsing HTTP@EXAMPLE.COM kerbNamewoRealm kerbNameFull kerbNameWoHost Assert abc.com HTTP/abc.com principalNameWoHost EXAMPLE.COM ,hadoop,0
test/hadoop assertFalse fSys testDir createFile test/hadoop/file/subdir fail Assert test/hadoop/file assertTrue mkdirs Should throw IOException. exists testDeepSubDir test/hadoop/file/deep/sub/dir getTestRootPath testMkdirsFailsForSubdirectoryOfExistingFile testSubDir ,hadoop,1
HttpHeaders process HttpStatus getFirstHeader h1 interceptor h2 getEntity testResponseDateGenerated Assert response assertNotNull context OK ,httpcore,0
yak dingo getName dst src conf delete fail assertTrue TEST_ROOT_DIR tmp mkdirs fileSys exists testCopy copy Failed to detect existing dir writeFile FileUtil ,hadoop,0
streamAbort thenReturn inStream any when eofstream getWrappedStream times Assert assertNull Mockito abort assertTrue testAbortConnection verify eofwatcher Boolean close isSelfClosed ,httpcore,0
testPauseUnpause2 job1 getTime pauseStartRunnable addRecordToBundleJobTable run getId assertEquals getStatus execute setPauseTime Services jobId assertNotNull get setKickoffTime Job job jpaService evaluate waitFor ,oozie,1
data  Fake failure to become active from within the stat callback fail to become active mockNoPriorActive  should re-join when ZK_LOCK_NAME times Assert assertTrue Ids verify create verifyExistCall stat mockApp intValue thenReturn count processResult assertEquals elector Code mockZK doThrow setEphemeralOwner CreateMode Mockito becomeActive joinElection testFailToBecomeActiveAfterZKDisconnect getSessionId ,hadoop,0
setClassesToBeExcluded testCoordStatusTransitServiceBackwardSupport assertFalse getCurrentDateafterIncrementingInMonths getId run DateUtils isPending getStatus addRecordToCoordActionTable parseDateOozieTZ coordGetCmd coordJob assertNotNull get CoordinatorAction end currentDatePlusMonth Job waitFor init getConf start destroy assertEquals services XDataTestCase execute addRecordToCoordJobTable Services CoordinatorJob jobId runnable coord-action-get.xml excludedServices setSystemProperty true StatusTransitService job jpaService evaluate ,oozie,1
" Check whether transactions are rolled back or not Expected exception due to commit failure but didn't get any PREP getId WorkflowInstance actionGetCmd deactivate testBulkInsertUpdatesRollback wfBean addRecordToWfJobTable getErrorCode assertNotNull wfUpdateCmd1 get WorkflowJob updateList add getStatusStr insertList Expected exception but didnt get any wfGetCmd assertEquals SkipCommitFaultInjection  Add two actions to insert list execute setStatus FaultInjection 1 Services fail jpaee 2 WorkflowAction org.apache.oozie.command.SkipCommitFaultInjection setSystemProperty true createWorkflowAction action1  set fault injection to true, so transaction is roll backed ErrorCode job action2  Add to update list  status should not be RUNNING jpaService ",oozie,1
/version RESTServlet body java.vm.vendor System os.version Bytes assertTrue get client os.name getCode getPackage testGetStargateVersionText getProperty getBody java.version os.arch MIMETYPE_TEXT length contains java.vm.version response toString getImplementationVersion ,hadoop,1
 Make a configuration file with a final property A adding same resource twice should not cause logging Event =  loggingEvent getLog logger declareProperty conf  Add the resource twice from a stream - should not generate warnings Logger getRenderedMessage getBytes System out removeAppender  Make sure the appender is removed addAppender assertTrue addResource prop  The 2 input streams both have the same config file get getRootLogger testNoFinalWarnings events isEmpty endConfig  Attach our own log appender so we can verify output startConfig appender assertEquals in2 in1 bytes toString writer ,hadoop,0
" verify the peer's settings were read and applied. settings set getHeaderTableSize maxHeaderTableByteCount PERSIST_VALUE assertEquals  Peer is server, so we are client. frameReader peerHttp2ServerZerosCompressionTable client connection sendHttp2SettingsAndCheckForAck Settings ",okhttp,1
"ProxyUsers refreshSuperUserGroupsConfiguration assertAuthorized GROUP_NAMES DefaultImpersonationProvider  Now try proxying a user that's not allowed getProxySuperuserUserConfKey conf asList PROXY_IP StringUtils join  From bad IP UserGroupInformation set proxyUserUgi 1.2.3.4 1.2.3.5 testProxyUsersWithUserConf AUTHORIZED_PROXY_USER_NAME , createRemoteUser REAL_USER_NAME assertNotAuthorized getTestProvider  From good IP  First try proxying a user that's allowed Arrays getProxySuperuserIpConfKey PROXY_USER_NAME realUserUgi createProxyUserForTesting ",hadoop,0
getName setProvider setProtocol setTrustManagerFactoryAlgorithm PROVIDER_SUN_JSSE Assert assertNotNull setSecureRandom getDefaultAlgorithm create getProvider TLS SSLContextBuilder setKeyManagerFactoryAlgorithm loadTrustMaterial loadKeyMaterial setKeyStoreType sslContext getProtocol assertEquals KeyStore getDefaultType KeyManagerFactory build testBuildAllDefaults TrustManagerFactory ,httpcore,0
addRecordToWfActionTable coordActionGetCmd getId WorkflowInstance getStatus addRecordToCoordActionTable coordJob wfJob Workflow Job should have been purged addRecordToWfJobTable getErrorCode assertNotNull Coordinator Action should have been purged get CoordinatorAction WorkflowJob wfAction wfJobGetCmd Coordinator Job should have been purged Workflow Action should have been purged wfActionGetCmd assertEquals execute addRecordToCoordJobTable call testPurgeCoordWithWFChild3 Services CoordinatorJob 1 coordJobGetCmd fail coord-action-get.xml WorkflowAction coordAction SUCCEEDED ErrorCode je jpaService ,oozie,1
testExpiryDoesNotOverflow assignConnection Deadline assertEquals currentTimeSupplier entry route1 Assert Mockito of getValidityDeadline Long TimeUnit mock TimeValue ,httpcore,0
conn read inStream thenReturn ArgumentMatchers getInputStream when any anyInt testStaleWhenIOError bind Assert Mockito assertTrue ensureOpen mock socket isStale thenThrow ,httpcore,0
NinjaMode testNinjaModeHelperWorksWithProdSet determineModeFromSystemProperties setProperty get NinjaConstant NinjaModeHelper assertEquals determineModeFromSystemPropertiesOrProdIfNotSet System clearProperty ,ninja,0
/storagePolicy storagePolicyPath chrootFs unsetStoragePolicy setClass mockfs://foo/a/b /a/b/storagePolicy conf URI chRootedStoragePolicyPath getRawFileSystem testUnsetStoragePolicy fs.mockfs.impl chrootUri create verify mockFs ,hadoop,0
testExpressionNotBlankFail3 notBlank Asserts Stuff  	   ,httpcore,0
init .dataout.ABC.unresolved CoordELFunctions .datain.ABC.unresolved setVariable assertEquals coord-action-start eval ${coord:tableIn('ABC')} evalAndWrap .dataout.ABC clicks testTable .datain.ABC expr ${coord:tableOut('ABC')} Boolean hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us ,oozie,1
play handler incrementAndGet android  play it back headerEntries  verify the peer received what was expected TYPE_RST_STREAM cola acceptFrame stream getErrorCode TYPE_HEADERS peer receiveCount reply PROTOCOL_ERROR  SYN_REPLY takeFrame rstStream banana a receive b c openSocket intValue remoteDoubleSynStream assertEquals  RST_STREAM HeadersMode getRequestHeaders sendFrame build  write the mocking script synStream ,okhttp,1
"this  contains a comment testCommentsInValue my.comment endConfig startConfig conf assertEquals appendProperty out CONFIG this <!--comment here--> contains a comment addResource get  two spaces one after ""this"", one before ""contains"" fileResource ",hadoop,0
addRecordToCoordJobTableForWaiting getId DateUtils parseDateOozieTZ testActionMaterForHcatalogIncorrectURI getErrorCode get 2009-03-11T10:00Z startTime init printStackTrace e destroy getMessage assertEquals services coord-job-for-matd-neg-hcat.xml Expected Command exception but didn't catch any call Services CoordinatorJob fail 2009-03-06T010:00Z setupServicesForHCatalog endTime ErrorCode job Unexpected exception  ,oozie,1
server Server assertReturnValues start conf assertEquals run  Override client to store the call id  side we should see retry count as 0 testInitialCallRetryCount getConnectAddress  Attach a listener that tracks every call ID received by the server. caller Assert NetUtils stop client getCallRetryCount addr ,hadoop,0
next TaskEventType submit  wait and validate for Job to become SUCCEEDED values  send the kill signal to the first Task getReport No of attempts is not correct waitForState getAttempts getTaskAttemptState iterator Assert  Job is succeeded JobState getTaskState latch countDown task1 task2 tasks  wait and vailidate for Job to become RUNNING attempts app getEventHandler  this will start the job but job won't complete as Task is blocked iter assertEquals getID handle it Attempt state not correct  unblock Task testKillTask Task state not correct size TaskAttemptState getTasks job No of tasks is not correct getContext TaskState ,hadoop,1
Node is not decommisioned. writeToHostsFile getMetrics conf hostFile nm2 nm1 NodeAction Assert nodeHeartbeat getNodeAction YarnConfiguration nm3 assertTrue metricCount refreshNodes testDecommissionWithIncludeHosts localhost getNodesListManager checkDecommissionedNMCount set host1 getAbsolutePath host2 ip start localhost:4433 host2:5678 assertEquals host1:1234 normalizeHostName NetUtils ClusterMetrics registerNode equals getNumDecommisionedNMs rm metrics  To test that IPs also work ,hadoop,1
deleteList  Add action to delete bulkDelRerunCmd addRecordToWfActionTable  should not be found testBulkUpdatesDeletes  check for update after running bulkJPA. job should be updated from KILLED -> RUNING getId WorkflowInstance  check for non existence after running bulkJPA addRecordToWfJobTable getErrorCode assertNotNull get action  Add job to update WorkflowJob jex updateList add getStatusStr setDeleteList RUNNING assertEquals execute setStatus 1 Services fail setUpdateList WorkflowAction ErrorCode job jpaService ,oozie,1
verifyPaths  with non-standard ports testShortAuthorityWithOtherPort myfs://host:456 myfs://host.a.b:456 fs ips authorities getVerifiedFS ,hadoop,0
exception END_POINTS lib  set fs.defaultFS instead java.lang.RuntimeException: namenode is not specified in conf conf submit client without LIBPATH should throw exception startPosition localhost:9001 testSubmitMR libPath  set fs.default.name getPath localPath SERVLET_CLASSES indexOf lib path can not be relative getContextURL getFileSystem submitMapReduce fail OozieClient java.lang.RuntimeException: libpath should be absolute mkdirs setProperty createConfiguration submit client without JT should throw exception submit client without NN should throw exception nn IS_SECURITY_ENABLED oozieUrl wc substring remove assertTrue get runTest e toUri XOozieClient MockDagEngineService assertEquals java.lang.RuntimeException: jobtracker is not specified in conf call wfCount toString  try to submit without JT and NN getFsTestCaseDir java.lang.RuntimeException: libpath is not specified in conf ,oozie,1
<value></value>  bais </configuration> isEmpty conf ConfTest testPropertyHasEmptyValue <name>foo</name>  getBytes assertTrue checkConf </property>  <property>  <configuration>  errors ,hadoop,0
EXEC_ORDER callable2 callable3 callables callable1 c asList queueservice QueueUniquenessWithSameKey Services assertTrue get Arrays testQueueUniquenessWithSameKey evaluate waitFor queue ,oozie,1
date DowngradingConsistencyRetryPolicy session withConsistencyLevel ONE  Given insert SELECT * FROM simple WHERE id =  crud  When id row should_insert_with_downgrading_consistency value logAsserter prepareLogLevelForDriverConnection isNotNull RandomUtils manager one nextLong assertThat TWO execute assertConsistencyLevels withRetryPolicy  Then Long buildDateKey entity ,achilles,1
a variables timers getAll counters incr assertEquals counter cron1 samplers addCron addVariable 1 getValue size inst get getOwn testAll ,oozie,1
 a l1 l2 start assertEquals sb Thread sleep a:1-L a:1-U a:2-L a:2-U trim finish toString testTimeoutWaitingWriteLock ,oozie,1
fail vfs DFS_BLOCK_SIZE_DEFAULT  test should still pass getServerDefaults on viewFs did not throw excetion! testFilePath testGetDefaultBlockSize assertEquals getDefaultBlockSize ,hadoop,1
"srcFile partitioned conf del  copy a dir: dest fs delete content createFile getBytes System result  should be deleted assertTrue tmp FileSystem copy listFiles getProperty     * Test method copy(FileSystem srcFS, Path src, File dst, boolean deleteSource, Configuration conf)     src f toURI some-content srcPath length newInstance assertEquals uri  copy regular file: line.separator testCopy5 exists files setupDirs FileUtil  copy regular file, delete src: isDirectory  should not be deleted ",hadoop,0
" Simulate 4 failures to test cycling through the bind users conf LDAP_NUM_ATTEMPTS_KEY asList .bob alicePasswordFile2.txt createPasswordFile bobBindPassword .alice expectedBindUsers bob,alice bobPasswordFile1.txt set expectedBindPasswords setInt BIND_USER_SUFFIX bobUsername testBindUserSwitchPasswordFromFile BIND_PASSWORD_FILE_SUFFIX BIND_USERS_KEY aliceUsername aliceBindPassword doTestBindUserSwitch Arrays getBaseConf ",hadoop,0
ContentType listener CoreMatchers setExceptionCallback getCause AsyncServerBootstrap listen instanceOf IOReactorConfig Assert getDuration create https /stuff setLookupRegistry requester localhost setStreamListener LoggingExceptionCallback LoggingHttp1StreamListener setIOSessionListener resultFuture1 * setSoTimeout Method assertThat execute LoggingConnPoolListener fail ex SecureAllPortsStrategy TIMEOUT setNeedClientAuth server setIOReactorConfig createClientSSLContext cause bootstrap H2RequesterBootstrap setConnPoolListener setTlsStrategy some stuff setIOSessionDecorator createServerSSLContext get ExecutionException expected getAddress SSLTestContexts address custom start sslEngine testTLSClientAuthFailure target getTimeUnit LoggingIOSessionDecorator getPort build future LoggingIOSessionListener initialize register ,httpcore,0
"cluster dataDir conf dn dataDirs dir  Check permissions on directories in 'dfs.datanode.data.dir' testLocalDirs localFS get FileSystem getFileStatus actual DFSConfigKeys getPermission , while expected is  getDataNodes getConf Permission for dir:  expected assertEquals permStr getStrings getLocal , is  ",hadoop,1
testTimeout getId DateUtils parseDateOozieTZ addRecordToCoordJobTable 2009-03-06T10:00Z call CoordinatorJob @1 pauseTime startTime endTime job checkCoordActionsTimeout 2009-03-06T10:14Z ,oozie,1
fs.localfs1.impl set getName printStackTrace e InitializeForeverFileSystem start conf run getFileSystemClass acquire testCacheEnabledWithInitializeForeverFS org.apache.hadoop.fs. fs.cachedfile.impl file cachedfile://a t TestFileSystemCaching$InitializeForeverFileSystem localfs1://a  wait for InitializeForeverFileSystem to start initialization FileSystem get interrupt join ,hadoop,0
 @ fail testValidToken validateActionName azAZ09_- ParamChecker ,oozie,1
END_POINTS IS_SECURITY_ENABLED submit oozieUrl run appPath assertTrue get -config create workflow.xml SERVLET_CLASSES close runTest app createConfigFile getContextURL -run MockDagEngineService assertEquals getFileSystem testRun args call -oozie mkdirs wfCount toString job getFsTestCaseDir ,oozie,1
"getName oozie.service.ProxyUserService.proxyuser.foo.groups foo conf asList bar Assert assertTrue StringUtils assertNotNull get join validate init set oozie.service.ProxyUserService.proxyuser.foo.hosts getConf getMessage destroy services , testNullHost Services fail contains ex proxyUser toString Arrays ",oozie,1
"testCount putThread gotValue testWritesWhileGetting tableName Bytes testWritesWhileScanning join prevTimestamp row0 method checkNoError toBytes qualifiers raw done initHRegion sorted size  search looking for the qualifier in question? flushInterval previousEmpty region numRows result  System.out.println(""iteration = "" + i); flush assertTrue getTimestamp get timestamp numQualifiers thisValue start isEmpty numFamilies assertEquals expectedCount kv families flushcache getValue i= getFamily compactStores equals flushThread compactInterval qual family getQualifier ",hadoop,1
initialCallable callables type keyInt queueservice initialKey assertTrue get testInterrupt initialType lockKey waitFor key EXEC_ORDER add init c initialLockKey retValue CallableQueueService destroy Services 1 testKill intCallable setSystemProperty evaluate queue ,oozie,1
EXEC_ORDER callable2 TestConcurrency callable3 callables callable1 c callable4 callable5 Math asList queueservice testConcurrency Services min assertTrue get secondBatch Long Arrays evaluate waitFor queue first ,oozie,1
kills addNode def enters j2 seven f2 WorkflowInstance getStatus three two asList exits assertTrue four get end five fails six f one abcde start j assertEquals size testWf <worklfow-app/> Arrays job testNestedFork ,oozie,1
"END_POINTS IS_SECURITY_ENABLED submit oozieUrl assertFalse testSubmit run appPath -submit get -config create workflow.xml SERVLET_CLASSES close runTest app createConfigFile getContextURL MockDagEngineService assertEquals getFileSystem createPropertiesFile  job was not created, then how did this extra job come after reset? fail!! args call fail -oozie mkdirs wfCount reset toString job getFsTestCaseDir ",oozie,1
"testBasicSubmitWithMultipleInstancesInputEvent coord-multiple-input-instance1.xml  CASE 3: Success case i.e. Multiple data-in instances specified correctly as separate <instance> tags reader per data-in instance conf getStatus appPath getJob sc  CASE 4: Success case i.e. Single instances for input and single instance for output, but both with "","" getErrorCode assertTrue Expected to catch errors due to incorrectly specified input data set instances file:// getTestCaseDir UNIT_TESTING getPath Job coordinator.xml coord-multiple-input-instance4.xml set e  CASE 2: Multiple data-in instances specified as separate <instance> tags, but one or more tags are empty. Check works for whitespace in the tags too getMessage assertEquals coord-multiple-input-instance3.xml call  CASE 1: Failure case i.e. multiple data-in instances OozieClient fail IOUtils contains is empty getTestUser copyCharStream Unexpected failure:  getResourceAsReader coord-multiple-input-instance2.xml writer ErrorCode File ",oozie,1
 Version 40-H. (20 + 61) blocks.  Version 3-H.  2 blocks.  Version 7-H. (4 + 1) blocks.  Version 1-H. Encoder getNumDataBytesAndNumECBytesForBlockID numDataBytes testGetNumDataBytesAndNumECBytesForBlockID numEcBytes assertEquals ,zxing,0
testBasicRead input read Assert in tmp inputStream assertEquals inBuffer close ,httpcore,0
notAService init Incorrect number of services TestService testRemoveService assertFalse Added an integer as a service service2 service1 assertEquals service3 serviceInit Service3 Service2 Service1 removeService size addIfService getServices testService ,hadoop,0
getConnectionContext getEventMessage session JMSMessagingUtils getUser conf getStatus createSession getTopic wf-app-name1 Assert testWorkflowJobSelectorsOr caId1 selector wfId1 WorkflowJob jmsContext consumer MessageType user1 getMessageType init receive printStackTrace e getMessage destroy assertEquals message wfEventListener fail ='Non_matching_user' OR   Pass a selector using OR condition onWorkflowJobEvent ='wf-app-name1' JMSHeaderConstants wfe createConsumer wfFailMessage Session ,oozie,1
END_POINTS IS_SECURITY_ENABLED submit oozieUrl assertFalse testSubmit conf wc appPath get create workflow.xml SERVLET_CLASSES close runTest app getContextURL MockDagEngineService assertEquals getFileSystem call OozieClient mkdirs setProperty wfCount reset createConfiguration toString getFsTestCaseDir ,oozie,1
"jsonDocument testInvalidJsonBody thenReturn format bodyParserEngineJson is invoke String jsonObjMapper getInputStream when getBytes Mockito assertTrue {""firstName"":""%s"", ""lastName"":""%s"", ""birthYear"":%d, ""lastSeen"":""%s"" context BodyParserEngineJsonTest badRequestThrown close ",ninja,0
testFactoryForHours TimeUnit testFactory ,httpcore,0
 testData Kerala  recor StandardCharsets line assertEquals readLine getBytes Bangalore core Assert delimiter testCustomDelimiter2 record  ~EOF with 're' lineReader  North Korea toString testStringBuilder Guantanamo close append ecord ,hadoop,0
deleteList 000-123-C bulkDelRerunCmd  check for non existence after running bulkDeleteJPA addRecordToWfActionTable  should not be found getId addRecordToCoordActionTable 000-123-W getErrorCode assertNotNull get CoordinatorAction jex add setDeleteList assertEquals execute Services fail 2 coord-action-get.xml WorkflowAction testDeletes action1  insert one workflow job and two actions ErrorCode action2 jpaService ,oozie,1
 a a:1-L a:2-N a:1-U l1 l2 start assertEquals sb Thread sleep trim testNoWaitWriteLock finish toString ,oozie,1
 1644            932             1644            932 masked_permission_value permission_mask_map getStickyBit  33700    -rw-r-t fsPermission hasStickyBit assertEquals original_permission_value testIntPermission  16804    drw-r--  17316    drw-r-t permission_mask_maps toShort ,hadoop,0
init  -ve test CoordELFunctions ${coord:databaseIn('ABCD')} ${coord:databaseIn('ABC')}           * databaseOut           setVariable ${coord:databaseOut('ABC')} ${coord:databaseOut('ABCD')}  +ve test assertEquals data-in coord-job-submit-data fail should throw exception because Data-in ABCD is not defiend eval evalAndWrap should throw exception because Data-out ABCD is not defiend           * databaseIn           testDatabasePh1 expr oozie.dataname.ABC data-out ,oozie,1
"[LocalizedFileNames] org.apache.oozie.action.decision.TestDecisionActionExecutor.testDecision=@org.apache.oozie.action.decision.TestDecisionActionExecutor.testDecision,0 org.apache.oozie.action.email.TestEmailActionExecutor.testValidation=@org.apache.oozie.action.email.TestEmailActionExecutor.testValidation,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testChgrp=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testChgrp,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testChmod=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testChmod,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testChmodRecursive=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testChmodRecursive,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testDoOperations=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testDoOperations,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testDoOperationsWithNameNodeElement=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testDoOperationsWithNameNodeElement,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testFileSchemeWildcard=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testFileSchemeWildcard,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testMove=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testMove,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testPermissionMask=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testPermissionMask,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testRecovery=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testRecovery,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testResolveToFullPath=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testResolveToFullPath,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testSubmit=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testSubmit,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testSubmitWithNameNode=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testSubmitWithNameNode,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testTouchz=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testTouchz,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testValidatePath=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testValidatePath,0 org.apache.oozie.action.hadoop.TestFsActionExecutor.testvalidateSameNN=@org.apache.oozie.action.hadoop.TestFsActionExecutor.testvalidateSameNN,0 org.apache.oozie.action.hadoop.TestFsELFunctions.testFunctions=@org.apache.oozie.action.hadoop.TestFsELFunctions.testFunctions,0 org.apache.oozie.action.hadoop.TestFSPrepareActions.testDelete=@org.apache.oozie.action.hadoop.TestFSPrepareActions.testDelete,0 org.apache.oozie.action.hadoop.TestFSPrepareActions.testForInvalidScheme=@org.apache.oozie.action.hadoop.TestFSPrepareActions.testForInvalidScheme,0 org.apache.oozie.action.hadoop.TestFSPrepareActions.testForNullScheme=@org.apache.oozie.action.hadoop.TestFSPrepareActions.testForNullScheme,0 org.apache.oozie.action.hadoop.TestFSPrepareActions.testMkdir=@org.apache.oozie.action.hadoop.TestFSPrepareActions.testMkdir,0 org.apache.oozie.action.hadoop.TestHadoopELFunctions.testELFunctionsReturningMapReduceStats=@org.apache.oozie.action.hadoop.TestHadoopELFunctions.testELFunctionsReturningMapReduceStats,0 org.apache.oozie.action.hadoop.TestHadoopELFunctions.testELFunctionsReturningPigStats=@org.apache.oozie.action.hadoop.TestHadoopELFunctions.testELFunctionsReturningPigStats,0 org.apache.oozie.action.hadoop.TestHCatPrepareActions.testDelete=@org.apache.oozie.action.hadoop.TestHCatPrepareActions.testDelete,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testACLDefaults_explicitLauncherAndActionSettings=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testACLDefaults_explicitLauncherAndActionSettings,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testACLDefaults_launcherACLsSetToDefault=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testACLDefaults_launcherACLsSetToDefault,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testACLDefaults_noFalseChange=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testACLDefaults_noFalseChange,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testACLModifyJob=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testACLModifyJob,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testActionLibsPath=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testActionLibsPath,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testActionSharelibResolution=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testActionSharelibResolution,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testAddActionShareLib=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testAddActionShareLib,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testAdditionalJarSubmitOK=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testAdditionalJarSubmitOK,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testAddShareLibSchemeAndAuthority=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testAddShareLibSchemeAndAuthority,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testCommaSeparatedFilesAndArchives=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testCommaSeparatedFilesAndArchives,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testCredentialsModule=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testCredentialsModule,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testExceptionSubmitError=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testExceptionSubmitError,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testExit0SubmitOK=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testExit0SubmitOK,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testExit1SubmitError=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testExit1SubmitError,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testFilesystemScheme=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testFilesystemScheme,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testIdSwapSubmitOK=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testIdSwapSubmitOK,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testInjectLauncherUseUberMode=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testInjectLauncherUseUberMode,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testJavaOpts=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testJavaOpts,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testKill=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testKill,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testLibFileArchives=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testLibFileArchives,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testOutputSubmitOK=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testOutputSubmitOK,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testParseJobXmlAndConfiguration=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testParseJobXmlAndConfiguration,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testPrepare=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testPrepare,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testRecovery=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testRecovery,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testSetupMethods=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testSetupMethods,0 org.apache.oozie.action.hadoop.TestJavaActionExecutor.testSimpestSleSubmitOK=@org.apache.oozie.action.hadoop.TestJavaActionExecutor.testSimpestSleSubmitOK,0 org.apache.oozie.action.hadoop.TestLauncher.testEmpty=@org.apache.oozie.action.hadoop.TestLauncher.testEmpty,0 org.apache.oozie.action.hadoop.TestLauncher.testException=@org.apache.oozie.action.hadoop.TestLauncher.testException,0 org.apache.oozie.action.hadoop.TestLauncher.testExit0=@org.apache.oozie.action.hadoop.TestLauncher.testExit0,0 org.apache.oozie.action.hadoop.TestLauncher.testExit1=@org.apache.oozie.action.hadoop.TestLauncher.testExit1,0 org.apache.oozie.action.hadoop.TestLauncher.testNewId=@org.apache.oozie.action.hadoop.TestLauncher.testNewId,0 org.apache.oozie.action.hadoop.TestLauncher.testOutput=@org.apache.oozie.action.hadoop.TestLauncher.testOutput,0 org.apache.oozie.action.hadoop.TestLauncher.testSecurityManager=@org.apache.oozie.action.hadoop.TestLauncher.testSecurityManager,0 org.apache.oozie.action.hadoop.TestLauncher.testSetupLauncherInfoHadoop2_0_2_alphaWorkaround=@org.apache.oozie.action.hadoop.TestLauncher.testSetupLauncherInfoHadoop2_0_2_alphaWorkaround,0 org.apache.oozie.action.hadoop.TestLauncher.testSetupLauncherInfoWithEmptyPrepareXML=@org.apache.oozie.action.hadoop.TestLauncher.testSetupLauncherInfoWithEmptyPrepareXML,0 org.apache.oozie.action.hadoop.TestLauncher.testSetupLauncherInfoWithNonEmptyPrepareXML=@org.apache.oozie.action.hadoop.TestLauncher.testSetupLauncherInfoWithNonEmptyPrepareXML,0 org.apache.oozie.action.hadoop.TestLauncher.testSetupMainClass=@org.apache.oozie.action.hadoop.TestLauncher.testSetupMainClass,0 org.apache.oozie.action.hadoop.TestLauncherHCatURIHandler.testDelete=@org.apache.oozie.action.hadoop.TestLauncherHCatURIHandler.testDelete,0 org.apache.oozie.action.hadoop.TestMapReduceActionError.testMapReduce=@org.apache.oozie.action.hadoop.TestMapReduceActionError.testMapReduce,0 org.apache.oozie.action.hadoop.TestMapReduceActionError.testSetupMethods=@org.apache.oozie.action.hadoop.TestMapReduceActionError.testSetupMethods,0 org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testCommaSeparatedFilesAndArchives=@org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testCommaSeparatedFilesAndArchives,0 org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testMapReduce=@org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testMapReduce,0 org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testMapReduceWithCredentials=@org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testMapReduceWithCredentials,0 org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testMapReduceWithUberJarDisabled=@org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testMapReduceWithUberJarDisabled,0 org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testPipes=@org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testPipes,0 org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testSetExecutionStats_when_user_has_specified_stats_write_FALSE=@org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testSetExecutionStats_when_user_has_specified_stats_write_FALSE,0 org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testSetExecutionStats_when_user_has_specified_stats_write_TRUE=@org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testSetExecutionStats_when_user_has_specified_stats_write_TRUE,0 org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testSetMapredJobName=@org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testSetMapredJobName,0 org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testSetupMethods=@org.apache.oozie.action.hadoop.TestMapReduceActionExecutor.testSetupMethods,0 org.apache.oozie.action.hadoop.TestPrepareActionsDriver.testDoOperationsWithInvalidXML=@org.apache.oozie.action.hadoop.TestPrepareActionsDriver.testDoOperationsWithInvalidXML,0 org.apache.oozie.action.hadoop.TestPrepareActionsDriver.testDoOperationsWithValidXML=@org.apache.oozie.action.hadoop.TestPrepareActionsDriver.testDoOperationsWithValidXML,0 org.apache.oozie.action.hadoop.TestRerun.testRerun=@org.apache.oozie.action.hadoop.TestRerun.testRerun,0 org.apache.oozie.action.hadoop.TestShellActionExecutor.testEnvVar=@org.apache.oozie.action.hadoop.TestShellActionExecutor.testEnvVar,0 org.apache.oozie.action.hadoop.TestShellActionExecutor.testPerlScript=@org.apache.oozie.action.hadoop.TestShellActionExecutor.testPerlScript,0 org.apache.oozie.action.hadoop.TestShellActionExecutor.testSetupMethods=@org.apache.oozie.action.hadoop.TestShellActionExecutor.testSetupMethods,0 org.apache.oozie.action.hadoop.TestShellActionExecutor.testShellScript=@org.apache.oozie.action.hadoop.TestShellActionExecutor.testShellScript,0 org.apache.oozie.action.hadoop.TestShellActionExecutor.testShellScriptError=@org.apache.oozie.action.hadoop.TestShellActionExecutor.testShellScriptError,0 org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testConfigNotPropagation=@org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testConfigNotPropagation,0 org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testConfigPropagation=@org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testConfigPropagation,0 org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testGetGroupFromParent=@org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testGetGroupFromParent,0 org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testSubWorkflowConfCreation=@org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testSubWorkflowConfCreation,0 org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testSubworkflowLib=@org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testSubworkflowLib,0 org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testSubWorkflowRecovery=@org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testSubWorkflowRecovery,0 org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testSubWorkflowStart=@org.apache.oozie.action.oozie.TestSubWorkflowActionExecutor.testSubWorkflowStart,0 org.apache.oozie.action.TestActionExecutor.testActionExecutor=@org.apache.oozie.action.TestActionExecutor.testActionExecutor,0 org.apache.oozie.action.TestActionFailover.testFsFailover=@org.apache.oozie.action.TestActionFailover.testFsFailover,0 org.apache.oozie.client.TestLocalOozie.testLocalOozieInitDestroy=@org.apache.oozie.client.TestLocalOozie.testLocalOozieInitDestroy,0 org.apache.oozie.client.TestLocalOozie.testWorkflowRun=@org.apache.oozie.client.TestLocalOozie.testWorkflowRun,0 org.apache.oozie.client.TestOozieCLI.testAdminQueueDump=@org.apache.oozie.client.TestOozieCLI.testAdminQueueDump,0 org.apache.oozie.client.TestOozieCLI.testChangeValue=@org.apache.oozie.client.TestOozieCLI.testChangeValue,0 org.apache.oozie.client.TestOozieCLI.testCoordReRun1=@org.apache.oozie.client.TestOozieCLI.testCoordReRun1,0 org.apache.oozie.client.TestOozieCLI.testCoordReRun2=@org.apache.oozie.client.TestOozieCLI.testCoordReRun2,0 org.apache.oozie.client.TestOozieCLI.testCoordReRun3=@org.apache.oozie.client.TestOozieCLI.testCoordReRun3,0 org.apache.oozie.client.TestOozieCLI.testCoordReRun4=@org.apache.oozie.client.TestOozieCLI.testCoordReRun4,0 org.apache.oozie.client.TestOozieCLI.testCoordReRunNeg1=@org.apache.oozie.client.TestOozieCLI.testCoordReRunNeg1,0 org.apache.oozie.client.TestOozieCLI.testCoordReRunNeg2=@org.apache.oozie.client.TestOozieCLI.testCoordReRunNeg2,0 org.apache.oozie.client.TestOozieCLI.testCoordReRunNeg3=@org.apache.oozie.client.TestOozieCLI.testCoordReRunNeg3,0 org.apache.oozie.client.TestOozieCLI.testCoordReRunNeg4=@org.apache.oozie.client.TestOozieCLI.testCoordReRunNeg4,0 org.apache.oozie.client.TestOozieCLI.testHeaderPropagation=@org.apache.oozie.client.TestOozieCLI.testHeaderPropagation,0 org.apache.oozie.client.TestOozieCLI.testJobDefinition=@org.apache.oozie.client.TestOozieCLI.testJobDefinition,0 org.apache.oozie.client.TestOozieCLI.testJobInfo=@org.apache.oozie.client.TestOozieCLI.testJobInfo,0 org.apache.oozie.client.TestOozieCLI.testJobLog=@org.apache.oozie.client.TestOozieCLI.testJobLog,0 org.apache.oozie.client.TestOozieCLI.testJobsStatus=@org.apache.oozie.client.TestOozieCLI.testJobsStatus,0 org.apache.oozie.client.TestOozieCLI.testJobStatus=@org.apache.oozie.client.TestOozieCLI.testJobStatus,0 org.apache.oozie.client.TestOozieCLI.testKill=@org.apache.oozie.client.TestOozieCLI.testKill,0 org.apache.oozie.client.TestOozieCLI.testOozieStatus=@org.apache.oozie.client.TestOozieCLI.testOozieStatus,0 org.apache.oozie.client.TestOozieCLI.testPropertiesWithTrailingSpaces=@org.apache.oozie.client.TestOozieCLI.testPropertiesWithTrailingSpaces,0 org.apache.oozie.client.TestOozieCLI.testReRun=@org.apache.oozie.client.TestOozieCLI.testReRun,0 org.apache.oozie.client.TestOozieCLI.testResume=@org.apache.oozie.client.TestOozieCLI.testResume,0 org.apache.oozie.client.TestOozieCLI.testRun=@org.apache.oozie.client.TestOozieCLI.testRun,0 org.apache.oozie.client.TestOozieCLI.testRunWithDebug=@org.apache.oozie.client.TestOozieCLI.testRunWithDebug,0 org.apache.oozie.client.TestOozieCLI.testServerBuildVersion=@org.apache.oozie.client.TestOozieCLI.testServerBuildVersion,0 org.apache.oozie.client.TestOozieCLI.testSlaEvents=@org.apache.oozie.client.TestOozieCLI.testSlaEvents,0 org.apache.oozie.client.TestOozieCLI.testStart=@org.apache.oozie.client.TestOozieCLI.testStart,0 org.apache.oozie.client.TestOozieCLI.testSubmit=@org.apache.oozie.client.TestOozieCLI.testSubmit,0 org.apache.oozie.client.TestOozieCLI.testSubmitDoAs=@org.apache.oozie.client.TestOozieCLI.testSubmitDoAs,0 org.apache.oozie.client.TestOozieCLI.testSubmitMapReduce=@org.apache.oozie.client.TestOozieCLI.testSubmitMapReduce,0 org.apache.oozie.client.TestOozieCLI.testSubmitMapReduce2=@org.apache.oozie.client.TestOozieCLI.testSubmitMapReduce2,0 org.apache.oozie.client.TestOozieCLI.testSubmitPig=@org.apache.oozie.client.TestOozieCLI.testSubmitPig,0 org.apache.oozie.client.TestOozieCLI.testSubmitWithPropertyArguments=@org.apache.oozie.client.TestOozieCLI.testSubmitWithPropertyArguments,0 org.apache.oozie.client.TestOozieCLI.testSuspend=@org.apache.oozie.client.TestOozieCLI.testSuspend,0 org.apache.oozie.client.TestOozieCLI.testValidateWorkFlowCommand=@org.apache.oozie.client.TestOozieCLI.testValidateWorkFlowCommand,0 org.apache.oozie.client.TestWorkflowClient.testClientBuildVersion=@org.apache.oozie.client.TestWorkflowClient.testClientBuildVersion,0 org.apache.oozie.client.TestWorkflowClient.testExternalId=@org.apache.oozie.client.TestWorkflowClient.testExternalId,0 org.apache.oozie.client.TestWorkflowClient.testHeaders=@org.apache.oozie.client.TestWorkflowClient.testHeaders,0 org.apache.oozie.client.TestWorkflowClient.testJobInformation=@org.apache.oozie.client.TestWorkflowClient.testJobInformation,0 org.apache.oozie.client.TestWorkflowClient.testJobsStatus=@org.apache.oozie.client.TestWorkflowClient.testJobsStatus,0 org.apache.oozie.client.TestWorkflowClient.testJobsStatusFilter=@org.apache.oozie.client.TestWorkflowClient.testJobsStatusFilter,0 org.apache.oozie.client.TestWorkflowClient.testJobStatus=@org.apache.oozie.client.TestWorkflowClient.testJobStatus,0 org.apache.oozie.client.TestWorkflowClient.testKill=@org.apache.oozie.client.TestWorkflowClient.testKill,0 org.apache.oozie.client.TestWorkflowClient.testReRun=@org.apache.oozie.client.TestWorkflowClient.testReRun,0 org.apache.oozie.client.TestWorkflowClient.testResume=@org.apache.oozie.client.TestWorkflowClient.testResume,0 org.apache.oozie.client.TestWorkflowClient.testRun=@org.apache.oozie.client.TestWorkflowClient.testRun,0 org.apache.oozie.client.TestWorkflowClient.testSafeMode=@org.apache.oozie.client.TestWorkflowClient.testSafeMode,0 org.apache.oozie.client.TestWorkflowClient.testServerBuildVersion=@org.apache.oozie.client.TestWorkflowClient.testServerBuildVersion,0 org.apache.oozie.client.TestWorkflowClient.testSla=@org.apache.oozie.client.TestWorkflowClient.testSla,0 org.apache.oozie.client.TestWorkflowClient.testStart=@org.apache.oozie.client.TestWorkflowClient.testStart,0 org.apache.oozie.client.TestWorkflowClient.testSubmit=@org.apache.oozie.client.TestWorkflowClient.testSubmit,0 org.apache.oozie.client.TestWorkflowClient.testSuspend=@org.apache.oozie.client.TestWorkflowClient.testSuspend,0 org.apache.oozie.client.TestWorkflowClient.testUrls=@org.apache.oozie.client.TestWorkflowClient.testUrls,0 org.apache.oozie.client.TestWorkflowClient.testWSErrors=@org.apache.oozie.client.TestWorkflowClient.testWSErrors,0 org.apache.oozie.client.TestWorkflowXClient.testSomeMethods=@org.apache.oozie.client.TestWorkflowXClient.testSomeMethods,0 org.apache.oozie.client.TestWorkflowXClient.testSubmitHive=@org.apache.oozie.client.TestWorkflowXClient.testSubmitHive,0 org.apache.oozie.client.TestWorkflowXClient.testSubmitMR=@org.apache.oozie.client.TestWorkflowXClient.testSubmitMR,0 org.apache.oozie.client.TestWorkflowXClient.testSubmitPig=@org.apache.oozie.client.TestWorkflowXClient.testSubmitPig,0 org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspend1=@org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspend1,0 org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspend2=@org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspend2,0 org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspend3=@org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspend3,0 org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspendFailed=@org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspendFailed,0 org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspendWithError=@org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspendWithError,0 org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspendWithError2=@org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspendWithError2,0 org.apache.oozie.command.bundle.TestBundleJobsXCommand.testBundleJobsGet=@org.apache.oozie.command.bundle.TestBundleJobsXCommand.testBundleJobsGet,0 org.apache.oozie.command.bundle.TestBundleJobXCommand.testBundleJobInfo1=@org.apache.oozie.command.bundle.TestBundleJobXCommand.testBundleJobInfo1,0 org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKill1=@org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKill1,0 org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKill2=@org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKill2,0 org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKill3=@org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKill3,0 org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpause1=@org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpause1,0 org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpause2=@org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpause2,0 org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpause3=@org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpause3,0 org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpauseNeg1=@org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpauseNeg1,0 org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerun1=@org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerun1,0 org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerun2=@org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerun2,0 org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInPaused=@org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInPaused,0 org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInPausedWithError=@org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInPausedWithError,0 org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInPrep=@org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInPrep,0 org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInSuspended=@org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInSuspended,0 org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInSuspendedWithError=@org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInSuspendedWithError,0 org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunKilledCoordinator=@org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunKilledCoordinator,0 org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunWithError=@org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunWithError,0 org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStart1=@org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStart1,0 org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStart2=@org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStart2,0 org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartDryrun=@org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartDryrun,0 org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartNegative1=@org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartNegative1,0 org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartNegative2=@org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartNegative2,0 org.apache.oozie.command.bundle.TestBundleSubmitXCommand.testJobXmlCommentRemoved=@org.apache.oozie.command.bundle.TestBundleSubmitXCommand.testJobXmlCommentRemoved,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheck=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheck,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckFuture=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckFuture,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestActionCreationTime=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestActionCreationTime,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestActionCreationTimeWithPushDependency=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestActionCreationTimeWithPushDependency,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestCurrentTime=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestCurrentTime,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestCurrentTimeWithPushDependency=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestCurrentTimeWithPushDependency,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputMissingDependencies=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputMissingDependencies,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testCoordActionInputCheckXCommandUniqueness=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testCoordActionInputCheckXCommandUniqueness,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testNoDatasetDependency=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testNoDatasetDependency,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testNonExistingNameNode=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testNonExistingNameNode,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testRequeueInterval=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testRequeueInterval,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testResolveCoordConfiguration=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testResolveCoordConfiguration,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testTimeout=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testTimeout,0 org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testTimeoutWithException=@org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testTimeoutWithException,0 org.apache.oozie.command.coord.TestCoordActionMaterializeCommand.testActionMater=@org.apache.oozie.command.coord.TestCoordActionMaterializeCommand.testActionMater,0 org.apache.oozie.command.coord.TestCoordActionMaterializeCommand.testActionMaterWithPauseTime1=@org.apache.oozie.command.coord.TestCoordActionMaterializeCommand.testActionMaterWithPauseTime1,0 org.apache.oozie.command.coord.TestCoordActionMaterializeCommand.testActionMaterWithPauseTime2=@org.apache.oozie.command.coord.TestCoordActionMaterializeCommand.testActionMaterWithPauseTime2,0 org.apache.oozie.command.coord.TestCoordActionMaterializeCommand.testActionMaterWithPauseTime3=@org.apache.oozie.command.coord.TestCoordActionMaterializeCommand.testActionMaterWithPauseTime3,0 org.apache.oozie.command.coord.TestCoordActionNotificationXCommand.testCoordNotificationTimeout=@org.apache.oozie.command.coord.TestCoordActionNotificationXCommand.testCoordNotificationTimeout,0 org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartCommand=@org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartCommand,0 org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartWithErrorReported=@org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartWithErrorReported,0 org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartWithEscapeStrings=@org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartWithEscapeStrings,0 org.apache.oozie.command.coord.TestCoordActionUpdatePushMissingDependency.testUpdateCoordTableAdvanced=@org.apache.oozie.command.coord.TestCoordActionUpdatePushMissingDependency.testUpdateCoordTableAdvanced,0 org.apache.oozie.command.coord.TestCoordActionUpdatePushMissingDependency.testUpdateCoordTableBasic=@org.apache.oozie.command.coord.TestCoordActionUpdatePushMissingDependency.testUpdateCoordTableBasic,0 org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordActionDelete=@org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordActionDelete,0 org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTime=@org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTime,0 org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangePauseTime=@org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangePauseTime,0 org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeStatus=@org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeStatus,0 org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeXCommand=@org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeXCommand,0 org.apache.oozie.command.coord.TestCoordCommandUtils.testDryRunPullAndPushDeps=@org.apache.oozie.command.coord.TestCoordCommandUtils.testDryRunPullAndPushDeps,0 org.apache.oozie.command.coord.TestCoordCommandUtils.testDryRunPullDeps=@org.apache.oozie.command.coord.TestCoordCommandUtils.testDryRunPullDeps,0 org.apache.oozie.command.coord.TestCoordCommandUtils.testDryRunPushDependencies=@org.apache.oozie.command.coord.TestCoordCommandUtils.testDryRunPushDependencies,0 org.apache.oozie.command.coord.TestCoordJobsXCommand.testCoordJobsGet=@org.apache.oozie.command.coord.TestCoordJobsXCommand.testCoordJobsGet,0 org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillFailed=@org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillFailed,0 org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillFailedOnAction=@org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillFailedOnAction,0 org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillForBackwardSupport=@org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillForBackwardSupport,0 org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillRemovePushMissingDeps=@org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillRemovePushMissingDeps,0 org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillSuccess1=@org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillSuccess1,0 org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillSuccess2=@org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillSuccess2,0 org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillWaiting=@org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillWaiting,0 org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillXCommandUniqueness=@org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillXCommandUniqueness,0 org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMater=@org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMater,0 org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterForHcatalog=@org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterForHcatalog,0 org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterForHcatalogIncorrectURI=@org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterForHcatalogIncorrectURI,0 org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterForHcatalogRelativePath=@org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterForHcatalogRelativePath,0 org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithPauseTime1=@org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithPauseTime1,0 org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithPauseTime2=@org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithPauseTime2,0 org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithPauseTime3=@org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithPauseTime3,0 org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand1=@org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand1,0 org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand2=@org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand2,0 org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand3=@org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand3,0 org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand4=@org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand4,0 org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatThrottle=@org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatThrottle,0 org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testTimeout=@org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testTimeout,0 org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testLogMessagePrefix=@org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testLogMessagePrefix,0 org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testRequeueOnException=@org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testRequeueOnException,0 org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testResolveCoordConfiguration=@org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testResolveCoordConfiguration,0 org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOut=@org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOut,0 org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOutWithException1=@org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOutWithException1,0 org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOutWithException2=@org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOutWithException2,0 org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOutWithUnresolvedMissingDependencies=@org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOutWithUnresolvedMissingDependencies,0 org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableMultipleDepsV1=@org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableMultipleDepsV1,0 org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableMultipleDepsV2=@org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableMultipleDepsV2,0 org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableMultipleDepsV3=@org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableMultipleDepsV3,0 org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableSingleDep=@org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableSingleDep,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActions1=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActions1,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActions2=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActions2,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActions3=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActions3,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActionsNeg1=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActionsNeg1,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActionsNeg2=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActionsNeg2,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunCleanup=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunCleanup,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunCleanupNoOutputEvents=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunCleanupNoOutputEvents,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate1=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate1,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate2=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate2,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate3=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate3,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate4=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate4,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDateNeg=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDateNeg,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunForBackwardSupport1=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunForBackwardSupport1,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunForBackwardSupport2=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunForBackwardSupport2,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunForBackwardSupport3=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunForBackwardSupport3,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInDoneWithError=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInDoneWithError,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInFailed=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInFailed,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInPaused=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInPaused,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInPausedWithError=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInPausedWithError,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunNeg=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunNeg,0 org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunRefresh=@org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunRefresh,0 org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendAndResumeForPrep=@org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendAndResumeForPrep,0 org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendAndResumeForPrepWithBackwardCompatibility=@org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendAndResumeForPrepWithBackwardCompatibility,0 org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendAndResumeForRunning=@org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendAndResumeForRunning,0 org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendWithErrorAndResumeWithErrorForRunning=@org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendWithErrorAndResumeWithErrorForRunning,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmit=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmit,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithBundleId=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithBundleId,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithIncludeFile=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithIncludeFile,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleEndInstancesInputEvent=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleEndInstancesInputEvent,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleInstancesInputEvent=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleInstancesInputEvent,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleInstancesOutputEvent=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleInstancesOutputEvent,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleStartInstancesInputEvent=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleStartInstancesInputEvent,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithSLA=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithSLA,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithStartTimeAfterEndTime=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithStartTimeAfterEndTime,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithWrongNamespace=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithWrongNamespace,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testDuplicateDatasetNameInIncludeFile=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testDuplicateDatasetNameInIncludeFile,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSchemaError=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSchemaError,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitDatasetInitialInstance=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitDatasetInitialInstance,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitFixedValues=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitFixedValues,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitNoControls=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitNoControls,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitNoDatasets=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitNoDatasets,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitNoUsername=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitNoUsername,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitReservedVars=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitReservedVars,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitWithDoneFlag=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitWithDoneFlag,0 org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitWithVarAppName=@org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitWithVarAppName,0 org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendNegative=@org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendNegative,0 org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendPostive=@org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendPostive,0 org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendWithErrorPostive=@org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendWithErrorPostive,0 org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendWithErrorPostive2=@org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendWithErrorPostive2,0 org.apache.oozie.command.TestCommand.testDagCommand=@org.apache.oozie.command.TestCommand.testDagCommand,0 org.apache.oozie.command.TestPurgeXCommand.testBundlePurgeXCommandFailed=@org.apache.oozie.command.TestPurgeXCommand.testBundlePurgeXCommandFailed,0 org.apache.oozie.command.TestPurgeXCommand.testCoordPurgeXCommandFailed=@org.apache.oozie.command.TestPurgeXCommand.testCoordPurgeXCommandFailed,0 org.apache.oozie.command.TestPurgeXCommand.testFailBundlePurgeXCommand=@org.apache.oozie.command.TestPurgeXCommand.testFailBundlePurgeXCommand,0 org.apache.oozie.command.TestPurgeXCommand.testKillBundlePurgeXCommand=@org.apache.oozie.command.TestPurgeXCommand.testKillBundlePurgeXCommand,0 org.apache.oozie.command.TestPurgeXCommand.testKillCoordPurgeXCommand=@org.apache.oozie.command.TestPurgeXCommand.testKillCoordPurgeXCommand,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChild1=@org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChild1,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChild2=@org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChild2,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChild2MoreThanLimit=@org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChild2MoreThanLimit,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChild3=@org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChild3,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChild3MoreThanLimit=@org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChild3MoreThanLimit,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChildWithSubWF1=@org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChildWithSubWF1,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChildWithSubWF2=@org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChildWithSubWF2,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChildWithSubWF3=@org.apache.oozie.command.TestPurgeXCommand.testPurgeBundleWithCoordChildWithWFChildWithSubWF3,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChild1=@org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChild1,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChild2=@org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChild2,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChild2MoreThanLimit=@org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChild2MoreThanLimit,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChild3=@org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChild3,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChild3MoreThanLimit=@org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChild3MoreThanLimit,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChildWithSubWF1=@org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChildWithSubWF1,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChildWithSubWF2=@org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChildWithSubWF2,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChildWithSubWF3=@org.apache.oozie.command.TestPurgeXCommand.testPurgeCoordWithWFChildWithSubWF3,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeLotsOfJobs=@org.apache.oozie.command.TestPurgeXCommand.testPurgeLotsOfJobs,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeWFWithSubWF2=@org.apache.oozie.command.TestPurgeXCommand.testPurgeWFWithSubWF2,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeWFWithSubWF2MoreThanLimit=@org.apache.oozie.command.TestPurgeXCommand.testPurgeWFWithSubWF2MoreThanLimit,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeWFWithSubWF3=@org.apache.oozie.command.TestPurgeXCommand.testPurgeWFWithSubWF3,0 org.apache.oozie.command.TestPurgeXCommand.testPurgeWFWithSubWF3MoreThanLimit=@org.apache.oozie.command.TestPurgeXCommand.testPurgeWFWithSubWF3MoreThanLimit,0 org.apache.oozie.command.TestPurgeXCommand.testSucBundlePurgeXCommand=@org.apache.oozie.command.TestPurgeXCommand.testSucBundlePurgeXCommand,0 org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckTransientDuringLauncher=@org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckTransientDuringLauncher,0 org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckTransientDuringMRAction=@org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckTransientDuringMRAction,0 org.apache.oozie.command.wf.TestActionErrors.testEndNonTransient=@org.apache.oozie.command.wf.TestActionErrors.testEndNonTransient,0 org.apache.oozie.command.wf.TestActionErrors.testEndNonTransientWithCoordActionUpdate=@org.apache.oozie.command.wf.TestActionErrors.testEndNonTransientWithCoordActionUpdate,0 org.apache.oozie.command.wf.TestActionErrors.testEndTransient=@org.apache.oozie.command.wf.TestActionErrors.testEndTransient,0 org.apache.oozie.command.wf.TestActionErrors.testKillNodeErrorMessage=@org.apache.oozie.command.wf.TestActionErrors.testKillNodeErrorMessage,0 org.apache.oozie.command.wf.TestActionErrors.testStartError=@org.apache.oozie.command.wf.TestActionErrors.testStartError,0 org.apache.oozie.command.wf.TestActionErrors.testStartErrorWithUserRetry=@org.apache.oozie.command.wf.TestActionErrors.testStartErrorWithUserRetry,0 org.apache.oozie.command.wf.TestActionErrors.testStartNonTransient=@org.apache.oozie.command.wf.TestActionErrors.testStartNonTransient,0 org.apache.oozie.command.wf.TestActionErrors.testStartNonTransientWithCoordActionUpdate=@org.apache.oozie.command.wf.TestActionErrors.testStartNonTransientWithCoordActionUpdate,0 org.apache.oozie.command.wf.TestActionErrors.testStartTransient=@org.apache.oozie.command.wf.TestActionErrors.testStartTransient,0 org.apache.oozie.command.wf.TestLastModified.testWorkflowRun=@org.apache.oozie.command.wf.TestLastModified.testWorkflowRun,0 org.apache.oozie.command.wf.TestReRunXCommand.testRedeploy=@org.apache.oozie.command.wf.TestReRunXCommand.testRedeploy,0 org.apache.oozie.command.wf.TestReRunXCommand.testRerun=@org.apache.oozie.command.wf.TestReRunXCommand.testRerun,0 org.apache.oozie.command.wf.TestReRunXCommand.testRerunFromFailNodes=@org.apache.oozie.command.wf.TestReRunXCommand.testRerunFromFailNodes,0 org.apache.oozie.command.wf.TestReRunXCommand.testRerunVariableSub=@org.apache.oozie.command.wf.TestReRunXCommand.testRerunVariableSub,0 org.apache.oozie.command.wf.TestSignalXCommand.testSuspendPoints=@org.apache.oozie.command.wf.TestSignalXCommand.testSuspendPoints,0 org.apache.oozie.command.wf.TestSignalXCommand.testSuspendPointsAll=@org.apache.oozie.command.wf.TestSignalXCommand.testSuspendPointsAll,0 org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillFailed=@org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillFailed,0 org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillSuccess1=@org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillSuccess1,0 org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillSuccess2=@org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillSuccess2,0 org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillSuccessAfterNodeDefUpgrade=@org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillSuccessAfterNodeDefUpgrade,0 org.apache.oozie.coord.TestCoordELEvaluator.testCreateDataEvaluator=@org.apache.oozie.coord.TestCoordELEvaluator.testCreateDataEvaluator,0 org.apache.oozie.coord.TestCoordELEvaluator.testCreateFreqELValuator=@org.apache.oozie.coord.TestCoordELEvaluator.testCreateFreqELValuator,0 org.apache.oozie.coord.TestCoordELEvaluator.testCreateInstancesELEvaluator=@org.apache.oozie.coord.TestCoordELEvaluator.testCreateInstancesELEvaluator,0 org.apache.oozie.coord.TestCoordELEvaluator.testCreateLazyEvaluator=@org.apache.oozie.coord.TestCoordELEvaluator.testCreateLazyEvaluator,0 org.apache.oozie.coord.TestCoordELEvaluator.testCreateURIELEvaluator=@org.apache.oozie.coord.TestCoordELEvaluator.testCreateURIELEvaluator,0 org.apache.oozie.coord.TestCoordELFunctions.testCurrent=@org.apache.oozie.coord.TestCoordELFunctions.testCurrent,0 org.apache.oozie.coord.TestCoordELFunctions.testDataIn=@org.apache.oozie.coord.TestCoordELFunctions.testDataIn,0 org.apache.oozie.coord.TestCoordELFunctions.testDataNamesPh1=@org.apache.oozie.coord.TestCoordELFunctions.testDataNamesPh1,0 org.apache.oozie.coord.TestCoordELFunctions.testDateOffset=@org.apache.oozie.coord.TestCoordELFunctions.testDateOffset,0 org.apache.oozie.coord.TestCoordELFunctions.testDay=@org.apache.oozie.coord.TestCoordELFunctions.testDay,0 org.apache.oozie.coord.TestCoordELFunctions.testDaysInMonth=@org.apache.oozie.coord.TestCoordELFunctions.testDaysInMonth,0 org.apache.oozie.coord.TestCoordELFunctions.testFormatTime=@org.apache.oozie.coord.TestCoordELFunctions.testFormatTime,0 org.apache.oozie.coord.TestCoordELFunctions.testFuture=@org.apache.oozie.coord.TestCoordELFunctions.testFuture,0 org.apache.oozie.coord.TestCoordELFunctions.testHours=@org.apache.oozie.coord.TestCoordELFunctions.testHours,0 org.apache.oozie.coord.TestCoordELFunctions.testHoursInDay=@org.apache.oozie.coord.TestCoordELFunctions.testHoursInDay,0 org.apache.oozie.coord.TestCoordELFunctions.testLatest=@org.apache.oozie.coord.TestCoordELFunctions.testLatest,0 org.apache.oozie.coord.TestCoordELFunctions.testMinutes=@org.apache.oozie.coord.TestCoordELFunctions.testMinutes,0 org.apache.oozie.coord.TestCoordELFunctions.testMonth=@org.apache.oozie.coord.TestCoordELFunctions.testMonth,0 org.apache.oozie.coord.TestCoordELFunctions.testOffset=@org.apache.oozie.coord.TestCoordELFunctions.testOffset,0 org.apache.oozie.coord.TestCoordELFunctions.testTZOffset=@org.apache.oozie.coord.TestCoordELFunctions.testTZOffset,0 org.apache.oozie.coord.TestCoordELFunctions.testURIVars=@org.apache.oozie.coord.TestCoordELFunctions.testURIVars,0 org.apache.oozie.coord.TestCoordELFunctions.testUser=@org.apache.oozie.coord.TestCoordELFunctions.testUser,0 org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromDate=@org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromDate,0 org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromDateRange=@org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromDateRange,0 org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromIds=@org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromIds,0 org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromIdsRange=@org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromIdsRange,0 org.apache.oozie.coord.TestHCatELFunctions.testDatabase=@org.apache.oozie.coord.TestHCatELFunctions.testDatabase,0 org.apache.oozie.coord.TestHCatELFunctions.testDatabasePh1=@org.apache.oozie.coord.TestHCatELFunctions.testDatabasePh1,0 org.apache.oozie.coord.TestHCatELFunctions.testdataInPartitionFilter=@org.apache.oozie.coord.TestHCatELFunctions.testdataInPartitionFilter,0 org.apache.oozie.coord.TestHCatELFunctions.testdataInPartitionFilterPh1=@org.apache.oozie.coord.TestHCatELFunctions.testdataInPartitionFilterPh1,0 org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMax=@org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMax,0 org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMaxPh1=@org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMaxPh1,0 org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMin=@org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMin,0 org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMinPh1=@org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMinPh1,0 org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitions=@org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitions,0 org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitionsPh1=@org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitionsPh1,0 org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitionValue=@org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitionValue,0 org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitionValuePh1=@org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitionValuePh1,0 org.apache.oozie.coord.TestHCatELFunctions.testHCatExists=@org.apache.oozie.coord.TestHCatELFunctions.testHCatExists,0 org.apache.oozie.coord.TestHCatELFunctions.testTable=@org.apache.oozie.coord.TestHCatELFunctions.testTable,0 org.apache.oozie.coord.TestHCatELFunctions.testTablePh1=@org.apache.oozie.coord.TestHCatELFunctions.testTablePh1,0 org.apache.oozie.dependency.TestFSURIHandler.testExists=@org.apache.oozie.dependency.TestFSURIHandler.testExists,0 org.apache.oozie.dependency.TestHCatURIHandler.testExists=@org.apache.oozie.dependency.TestHCatURIHandler.testExists,0 org.apache.oozie.dependency.TestURIHandlerService.testGetAuthorityWithScheme=@org.apache.oozie.dependency.TestURIHandlerService.testGetAuthorityWithScheme,0 org.apache.oozie.event.TestEventGeneration.testCoordinatorActionEvent=@org.apache.oozie.event.TestEventGeneration.testCoordinatorActionEvent,0 org.apache.oozie.event.TestEventGeneration.testCoordinatorActionEventDependencies=@org.apache.oozie.event.TestEventGeneration.testCoordinatorActionEventDependencies,0 org.apache.oozie.event.TestEventGeneration.testWorkflowJobEvent=@org.apache.oozie.event.TestEventGeneration.testWorkflowJobEvent,0 org.apache.oozie.event.TestEventGeneration.testWorkflowJobEventError=@org.apache.oozie.event.TestEventGeneration.testWorkflowJobEventError,0 org.apache.oozie.event.TestEventQueue.testQueueOperations=@org.apache.oozie.event.TestEventQueue.testQueueOperations,0 org.apache.oozie.executor.jpa.TestBulkMonitorJPAExecutor.testDefaultStatus=@org.apache.oozie.executor.jpa.TestBulkMonitorJPAExecutor.testDefaultStatus,0 org.apache.oozie.executor.jpa.TestBulkMonitorJPAExecutor.testJavaNoRecords=@org.apache.oozie.executor.jpa.TestBulkMonitorJPAExecutor.testJavaNoRecords,0 org.apache.oozie.executor.jpa.TestBulkMonitorJPAExecutor.testMultipleBundleIdsForName=@org.apache.oozie.executor.jpa.TestBulkMonitorJPAExecutor.testMultipleBundleIdsForName,0 org.apache.oozie.executor.jpa.TestBulkMonitorJPAExecutor.testMultipleCoordinators=@org.apache.oozie.executor.jpa.TestBulkMonitorJPAExecutor.testMultipleCoordinators,0 org.apache.oozie.executor.jpa.TestBulkMonitorJPAExecutor.testMultipleRecords=@org.apache.oozie.executor.jpa.TestBulkMonitorJPAExecutor.testMultipleRecords,0 org.apache.oozie.executor.jpa.TestBulkMonitorJPAExecutor.testSingleRecord=@org.apache.oozie.executor.jpa.TestBulkMonitorJPAExecutor.testSingleRecord,0 org.apache.oozie.executor.jpa.TestBulkUpdateDeleteJPAExecutor.testBulkUpdatesDeletes=@org.apache.oozie.executor.jpa.TestBulkUpdateDeleteJPAExecutor.testBulkUpdatesDeletes,0 org.apache.oozie.executor.jpa.TestBulkUpdateDeleteJPAExecutor.testBulkUpdatesDeletesRollback=@org.apache.oozie.executor.jpa.TestBulkUpdateDeleteJPAExecutor.testBulkUpdatesDeletesRollback,0 org.apache.oozie.executor.jpa.TestBulkUpdateDeleteJPAExecutor.testDeletes=@org.apache.oozie.executor.jpa.TestBulkUpdateDeleteJPAExecutor.testDeletes,0 org.apache.oozie.executor.jpa.TestBulkUpdateDeleteJPAExecutor.testUpdates=@org.apache.oozie.executor.jpa.TestBulkUpdateDeleteJPAExecutor.testUpdates,0 org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStartJPAExecutor.testBulkInsertUpdates=@org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStartJPAExecutor.testBulkInsertUpdates,0 org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStartJPAExecutor.testBulkInsertUpdatesRollback=@org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStartJPAExecutor.testBulkInsertUpdatesRollback,0 org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStartJPAExecutor.testInserts=@org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStartJPAExecutor.testInserts,0 org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStartJPAExecutor.testUpdates=@org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStartJPAExecutor.testUpdates,0 org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStatusJPAExecutor.testBulkInsertUpdates=@org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStatusJPAExecutor.testBulkInsertUpdates,0 org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStatusJPAExecutor.testBulkInsertUpdatesRollback=@org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStatusJPAExecutor.testBulkInsertUpdatesRollback,0 org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStatusJPAExecutor.testInserts=@org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStatusJPAExecutor.testInserts,0 org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStatusJPAExecutor.testUpdates=@org.apache.oozie.executor.jpa.TestBulkUpdateInsertForCoordActionStatusJPAExecutor.testUpdates,0 org.apache.oozie.executor.jpa.TestBulkUpdateInsertJPAExecutor.testBulkInsertUpdates=@org.apache.oozie.executor.jpa.TestBulkUpdateInsertJPAExecutor.testBulkInsertUpdates,0 org.apache.oozie.executor.jpa.TestBulkUpdateInsertJPAExecutor.testBulkInsertUpdatesRollback=@org.apache.oozie.executor.jpa.TestBulkUpdateInsertJPAExecutor.testBulkInsertUpdatesRollback,0 org.apache.oozie.executor.jpa.TestBulkUpdateInsertJPAExecutor.testInserts=@org.apache.oozie.executor.jpa.TestBulkUpdateInsertJPAExecutor.testInserts,0 org.apache.oozie.executor.jpa.TestBulkUpdateInsertJPAExecutor.testUpdates=@org.apache.oozie.executor.jpa.TestBulkUpdateInsertJPAExecutor.testUpdates,0 org.apache.oozie.executor.jpa.TestBundleActionsCountForJobGetJPAExecutor.testBundleActionsForJobCountGet=@org.apache.oozie.executor.jpa.TestBundleActionsCountForJobGetJPAExecutor.testBundleActionsForJobCountGet,0 org.apache.oozie.executor.jpa.TestBundleJobInfoGetJPAExecutor.testBundleJobInfoGet=@org.apache.oozie.executor.jpa.TestBundleJobInfoGetJPAExecutor.testBundleJobInfoGet,0 org.apache.oozie.executor.jpa.TestBundleJobsDeleteJPAExecutor.testDeleteBundles=@org.apache.oozie.executor.jpa.TestBundleJobsDeleteJPAExecutor.testDeleteBundles,0 org.apache.oozie.executor.jpa.TestBundleJobsDeleteJPAExecutor.testDeleteBundlesRollback=@org.apache.oozie.executor.jpa.TestBundleJobsDeleteJPAExecutor.testDeleteBundlesRollback,0 org.apache.oozie.executor.jpa.TestBundleJobsGetForPurgeJPAExecutor.testBundleJobsGetForPurgeJPAExecutorTooMany=@org.apache.oozie.executor.jpa.TestBundleJobsGetForPurgeJPAExecutor.testBundleJobsGetForPurgeJPAExecutorTooMany,0 org.apache.oozie.executor.jpa.TestCoordActionGetByLastModifiedTimeJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordActionGetByLastModifiedTimeJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordActionGetForCheckJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordActionGetForCheckJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordActionGetForExternalIdJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordActionGetForExternalIdJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordActionGetForInfoJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordActionGetForInfoJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordActionGetForInfoJPAExecutor.testCoordActionGetAllColumns=@org.apache.oozie.executor.jpa.TestCoordActionGetForInfoJPAExecutor.testCoordActionGetAllColumns,0 org.apache.oozie.executor.jpa.TestCoordActionGetForInputCheckJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordActionGetForInputCheckJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordActionGetForStartJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordActionGetForStartJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordActionGetForTimeoutJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordActionGetForTimeoutJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordActionRemoveJPAExecutor.testRunningActionDelete=@org.apache.oozie.executor.jpa.TestCoordActionRemoveJPAExecutor.testRunningActionDelete,0 org.apache.oozie.executor.jpa.TestCoordActionsActiveCountJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordActionsActiveCountJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordActionsPendingFalseCountGetJPAExecutor.testCoordActionsPendingFalseCountGet=@org.apache.oozie.executor.jpa.TestCoordActionsPendingFalseCountGetJPAExecutor.testCoordActionsPendingFalseCountGet,0 org.apache.oozie.executor.jpa.TestCoordActionsPendingFalseStatusCountGetJPAExecutor.testCoordActionPendingFalseStatusCountGet=@org.apache.oozie.executor.jpa.TestCoordActionsPendingFalseStatusCountGetJPAExecutor.testCoordActionPendingFalseStatusCountGet,0 org.apache.oozie.executor.jpa.TestCoordJobGetActionForNominalTimeJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordJobGetActionForNominalTimeJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordJobGetActionIdsForDatesJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordJobGetActionIdsForDatesJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordJobGetActionsForDatesJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordJobGetActionsForDatesJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordJobGetActionsNotCompletedJPAExecutor.testCoordActionsNotCompletetedForColumnValues=@org.apache.oozie.executor.jpa.TestCoordJobGetActionsNotCompletedJPAExecutor.testCoordActionsNotCompletetedForColumnValues,0 org.apache.oozie.executor.jpa.TestCoordJobGetActionsNotCompletedJPAExecutor.testCoordActionsNotCompletetedForSize=@org.apache.oozie.executor.jpa.TestCoordJobGetActionsNotCompletedJPAExecutor.testCoordActionsNotCompletetedForSize,0 org.apache.oozie.executor.jpa.TestCoordJobGetActionsRunningJPAExecutor.testCoordActionsRunningForColumnValues=@org.apache.oozie.executor.jpa.TestCoordJobGetActionsRunningJPAExecutor.testCoordActionsRunningForColumnValues,0 org.apache.oozie.executor.jpa.TestCoordJobGetActionsRunningJPAExecutor.testCoordActionsRunningForSize=@org.apache.oozie.executor.jpa.TestCoordJobGetActionsRunningJPAExecutor.testCoordActionsRunningForSize,0 org.apache.oozie.executor.jpa.TestCoordJobGetActionsSubsetJPAExecutor.testCoordActionFilter=@org.apache.oozie.executor.jpa.TestCoordJobGetActionsSubsetJPAExecutor.testCoordActionFilter,0 org.apache.oozie.executor.jpa.TestCoordJobGetActionsSubsetJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordJobGetActionsSubsetJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordJobGetActionsSubsetJPAExecutor.testCoordActionOrderBy=@org.apache.oozie.executor.jpa.TestCoordJobGetActionsSubsetJPAExecutor.testCoordActionOrderBy,0 org.apache.oozie.executor.jpa.TestCoordJobGetActionsSubsetJPAExecutor.testGetActionAllColumns=@org.apache.oozie.executor.jpa.TestCoordJobGetActionsSubsetJPAExecutor.testGetActionAllColumns,0 org.apache.oozie.executor.jpa.TestCoordJobGetActionsSuspendedJPAExecutor.testCoordActionsSuspendedForColumnValues=@org.apache.oozie.executor.jpa.TestCoordJobGetActionsSuspendedJPAExecutor.testCoordActionsSuspendedForColumnValues,0 org.apache.oozie.executor.jpa.TestCoordJobGetActionsSuspendedJPAExecutor.testCoordActionsSuspendedForSize=@org.apache.oozie.executor.jpa.TestCoordJobGetActionsSuspendedJPAExecutor.testCoordActionsSuspendedForSize,0 org.apache.oozie.executor.jpa.TestCoordJobGetReadyActionsJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordJobGetReadyActionsJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordJobGetRunningActionsCountJPAExecutor.testCoordActionGet=@org.apache.oozie.executor.jpa.TestCoordJobGetRunningActionsCountJPAExecutor.testCoordActionGet,0 org.apache.oozie.executor.jpa.TestCoordJobInfoGetJPAExecutor.testCoordJobGet=@org.apache.oozie.executor.jpa.TestCoordJobInfoGetJPAExecutor.testCoordJobGet,0 org.apache.oozie.executor.jpa.TestCoordJobsCountNotForPurgeFromParentIdJPAExecutor.testCount=@org.apache.oozie.executor.jpa.TestCoordJobsCountNotForPurgeFromParentIdJPAExecutor.testCount,0 org.apache.oozie.executor.jpa.TestCoordJobsDeleteJPAExecutor.testDeleteCoords=@org.apache.oozie.executor.jpa.TestCoordJobsDeleteJPAExecutor.testDeleteCoords,0 org.apache.oozie.executor.jpa.TestCoordJobsDeleteJPAExecutor.testDeleteCoordsRollback=@org.apache.oozie.executor.jpa.TestCoordJobsDeleteJPAExecutor.testDeleteCoordsRollback,0 org.apache.oozie.executor.jpa.TestCoordJobsGetForPurgeJPAExecutor.testCoordJobsGetForPurgeJPAExecutorTooMany=@org.apache.oozie.executor.jpa.TestCoordJobsGetForPurgeJPAExecutor.testCoordJobsGetForPurgeJPAExecutorTooMany,0 org.apache.oozie.executor.jpa.TestCoordJobsGetForPurgeJPAExecutor.testCoordJobsGetForPurgeJPAExecutorWithParent=@org.apache.oozie.executor.jpa.TestCoordJobsGetForPurgeJPAExecutor.testCoordJobsGetForPurgeJPAExecutorWithParent,0 org.apache.oozie.executor.jpa.TestCoordJobsGetFromParentIdJPAExecutor.testGetBundleParent=@org.apache.oozie.executor.jpa.TestCoordJobsGetFromParentIdJPAExecutor.testGetBundleParent,0 org.apache.oozie.executor.jpa.TestCoordJobsGetFromParentIdJPAExecutor.testGetBundleParentTooMany=@org.apache.oozie.executor.jpa.TestCoordJobsGetFromParentIdJPAExecutor.testGetBundleParentTooMany,0 org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsForAppName=@org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsForAppName,0 org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsForCombined=@org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsForCombined,0 org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsForCombinedWithRange=@org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsForCombinedWithRange,0 org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsForCoordActionId=@org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsForCoordActionId,0 org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsForCoordJobId=@org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsForCoordJobId,0 org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsForOR=@org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsForOR,0 org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsWithRange=@org.apache.oozie.executor.jpa.TestSLAEventsGetForFilterJPAExecutor.testGetSLAEventsWithRange,0 org.apache.oozie.executor.jpa.TestSLAEventsGetForSeqIdJPAExecutor.testSLAEventsGetForSeqId=@org.apache.oozie.executor.jpa.TestSLAEventsGetForSeqIdJPAExecutor.testSLAEventsGetForSeqId,0 org.apache.oozie.executor.jpa.TestSLAEventsGetJPAExecutor.testSLAEventsGetForSeqId=@org.apache.oozie.executor.jpa.TestSLAEventsGetJPAExecutor.testSLAEventsGetForSeqId,0 org.apache.oozie.executor.jpa.TestWorkflowActionGetJPAExecutor.testWfActionGetWithExecPath=@org.apache.oozie.executor.jpa.TestWorkflowActionGetJPAExecutor.testWfActionGetWithExecPath,0 org.apache.oozie.executor.jpa.TestWorkflowActionsGetForJobJPAExecutor.testWfActionsGet=@org.apache.oozie.executor.jpa.TestWorkflowActionsGetForJobJPAExecutor.testWfActionsGet,0 org.apache.oozie.executor.jpa.TestWorkflowActionSubsetGetJPAExecutor.testWfActionSubsetGet=@org.apache.oozie.executor.jpa.TestWorkflowActionSubsetGetJPAExecutor.testWfActionSubsetGet,0 org.apache.oozie.executor.jpa.TestWorkflowInfoWithActionsSubsetGetJPAExecutor.testWfInfoWithActionSubsetGet=@org.apache.oozie.executor.jpa.TestWorkflowInfoWithActionsSubsetGetJPAExecutor.testWfInfoWithActionSubsetGet,0 org.apache.oozie.executor.jpa.TestWorkflowJobDeleteJPAExecutor.testWorkflowJobDelete=@org.apache.oozie.executor.jpa.TestWorkflowJobDeleteJPAExecutor.testWorkflowJobDelete,0 org.apache.oozie.executor.jpa.TestWorkflowJobGetActionsJPAExecutor.testWfActionsGet=@org.apache.oozie.executor.jpa.TestWorkflowJobGetActionsJPAExecutor.testWfActionsGet,0 org.apache.oozie.executor.jpa.TestWorkflowJobsDeleteJPAExecutor.testDeleteWorkflows=@org.apache.oozie.executor.jpa.TestWorkflowJobsDeleteJPAExecutor.testDeleteWorkflows,0 org.apache.oozie.executor.jpa.TestWorkflowJobsDeleteJPAExecutor.testDeleteWorkflowsRollback=@org.apache.oozie.executor.jpa.TestWorkflowJobsDeleteJPAExecutor.testDeleteWorkflowsRollback,0 org.apache.oozie.executor.jpa.TestWorkflowJobsGetForPurgeJPAExecutor.testWfJobsGetForPurgeTooMany=@org.apache.oozie.executor.jpa.TestWorkflowJobsGetForPurgeJPAExecutor.testWfJobsGetForPurgeTooMany,0 org.apache.oozie.executor.jpa.TestWorkflowJobsGetForPurgeJPAExecutor.testWfJobsGetForPurgeWithParent=@org.apache.oozie.executor.jpa.TestWorkflowJobsGetForPurgeJPAExecutor.testWfJobsGetForPurgeWithParent,0 org.apache.oozie.executor.jpa.TestWorkflowJobsGetFromParentIdJPAExecutor.testGetCoordinatorParent=@org.apache.oozie.executor.jpa.TestWorkflowJobsGetFromParentIdJPAExecutor.testGetCoordinatorParent,0 org.apache.oozie.executor.jpa.TestWorkflowJobsGetFromParentIdJPAExecutor.testGetCoordinatorParentTooMany=@org.apache.oozie.executor.jpa.TestWorkflowJobsGetFromParentIdJPAExecutor.testGetCoordinatorParentTooMany,0 org.apache.oozie.executor.jpa.TestWorkflowJobsGetFromParentIdJPAExecutor.testGetWorkflowParent=@org.apache.oozie.executor.jpa.TestWorkflowJobsGetFromParentIdJPAExecutor.testGetWorkflowParent,0 org.apache.oozie.executor.jpa.TestWorkflowJobsGetFromParentIdJPAExecutor.testGetWorkflowParentTooMany=@org.apache.oozie.executor.jpa.TestWorkflowJobsGetFromParentIdJPAExecutor.testGetWorkflowParentTooMany,0 org.apache.oozie.executor.jpa.TestWorkflowJobUpdateJPAExecutor.testWorkflowJobUpdate=@org.apache.oozie.executor.jpa.TestWorkflowJobUpdateJPAExecutor.testWorkflowJobUpdate,0 org.apache.oozie.jms.TestDefaultConnectionContext.testThreadLocalSession=@org.apache.oozie.jms.TestDefaultConnectionContext.testThreadLocalSession,0 org.apache.oozie.jms.TestHCatMessageHandler.testCacheUpdateByMessage=@org.apache.oozie.jms.TestHCatMessageHandler.testCacheUpdateByMessage,0 org.apache.oozie.jms.TestHCatMessageHandler.testDropEventTypeMessage=@org.apache.oozie.jms.TestHCatMessageHandler.testDropEventTypeMessage,0 org.apache.oozie.jms.TestJMSJobEventListener.testConnectionDrop=@org.apache.oozie.jms.TestJMSJobEventListener.testConnectionDrop,0 org.apache.oozie.jms.TestJMSJobEventListener.testCoordinatorActionSelectors=@org.apache.oozie.jms.TestJMSJobEventListener.testCoordinatorActionSelectors,0 org.apache.oozie.jms.TestJMSJobEventListener.testCoordinatorActionSelectorsNegative=@org.apache.oozie.jms.TestJMSJobEventListener.testCoordinatorActionSelectorsNegative,0 org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorActionStartEvent=@org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorActionStartEvent,0 org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorActionWaitingEvent=@org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorActionWaitingEvent,0 org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorJobFailureEvent=@org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorJobFailureEvent,0 org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorJobSuccessEvent=@org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorJobSuccessEvent,0 org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobFailureEvent=@org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobFailureEvent,0 org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobStartedEvent=@org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobStartedEvent,0 org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobSuccessEvent=@org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobSuccessEvent,0 org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobSuspendEvent=@org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobSuspendEvent,0 org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectors=@org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectors,0 org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsAnd=@org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsAnd,0 org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsNegative=@org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsNegative,0 org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsOr=@org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsOr,0 org.apache.oozie.service.TestActionCheckerService.testActionCheckerService=@org.apache.oozie.service.TestActionCheckerService.testActionCheckerService,0 org.apache.oozie.service.TestActionCheckerService.testActionCheckerServiceCoord=@org.apache.oozie.service.TestActionCheckerService.testActionCheckerServiceCoord,0 org.apache.oozie.service.TestActionCheckerService.testActionCheckerServiceDelay=@org.apache.oozie.service.TestActionCheckerService.testActionCheckerServiceDelay,0 org.apache.oozie.service.TestAuthorizationService.testAuthorizationServiceForBundle=@org.apache.oozie.service.TestAuthorizationService.testAuthorizationServiceForBundle,0 org.apache.oozie.service.TestAuthorizationService.testAuthorizationServiceForCoord=@org.apache.oozie.service.TestAuthorizationService.testAuthorizationServiceForCoord,0 org.apache.oozie.service.TestAuthorizationService.testErrors=@org.apache.oozie.service.TestAuthorizationService.testErrors,0 org.apache.oozie.service.TestCallableQueueService.testConcurrency=@org.apache.oozie.service.TestCallableQueueService.testConcurrency,0 org.apache.oozie.service.TestCallableQueueService.testConcurrencyLimit=@org.apache.oozie.service.TestCallableQueueService.testConcurrencyLimit,0 org.apache.oozie.service.TestCallableQueueService.testConcurrencyReachedAndChooseNextEligible=@org.apache.oozie.service.TestCallableQueueService.testConcurrencyReachedAndChooseNextEligible,0 org.apache.oozie.service.TestCallableQueueService.testDelayedQueuing=@org.apache.oozie.service.TestCallableQueueService.testDelayedQueuing,0 org.apache.oozie.service.TestCallableQueueService.testInterrupt=@org.apache.oozie.service.TestCallableQueueService.testInterrupt,0 org.apache.oozie.service.TestCallableQueueService.testInterruptsInCompositeCallable=@org.apache.oozie.service.TestCallableQueueService.testInterruptsInCompositeCallable,0 org.apache.oozie.service.TestCallableQueueService.testInterruptsWithCompositeCallable=@org.apache.oozie.service.TestCallableQueueService.testInterruptsWithCompositeCallable,0 org.apache.oozie.service.TestCallableQueueService.testInterruptsWithDistinguishedLockKeys=@org.apache.oozie.service.TestCallableQueueService.testInterruptsWithDistinguishedLockKeys,0 org.apache.oozie.service.TestCallableQueueService.testMaxInterruptMapSize=@org.apache.oozie.service.TestCallableQueueService.testMaxInterruptMapSize,0 org.apache.oozie.service.TestCallableQueueService.testPriorityExecution=@org.apache.oozie.service.TestCallableQueueService.testPriorityExecution,0 org.apache.oozie.service.TestCallableQueueService.testQueueSerial=@org.apache.oozie.service.TestCallableQueueService.testQueueSerial,0 org.apache.oozie.service.TestCallableQueueService.testQueueUniquenessWithDiffKey=@org.apache.oozie.service.TestCallableQueueService.testQueueUniquenessWithDiffKey,0 org.apache.oozie.service.TestCallableQueueService.testQueueUniquenessWithDiffKeyInComposite=@org.apache.oozie.service.TestCallableQueueService.testQueueUniquenessWithDiffKeyInComposite,0 org.apache.oozie.service.TestCallableQueueService.testQueueUniquenessWithDiffKeyInOneComposite=@org.apache.oozie.service.TestCallableQueueService.testQueueUniquenessWithDiffKeyInOneComposite,0 org.apache.oozie.service.TestCallableQueueService.testQueueUniquenessWithSameKey=@org.apache.oozie.service.TestCallableQueueService.testQueueUniquenessWithSameKey,0 org.apache.oozie.service.TestCallableQueueService.testQueueUniquenessWithSameKeyInComposite=@org.apache.oozie.service.TestCallableQueueService.testQueueUniquenessWithSameKeyInComposite,0 org.apache.oozie.service.TestCallableQueueService.testQueueUniquenessWithSameKeyInOneComposite=@org.apache.oozie.service.TestCallableQueueService.testQueueUniquenessWithSameKeyInOneComposite,0 org.apache.oozie.service.TestCallableQueueService.testQueuing=@org.apache.oozie.service.TestCallableQueueService.testQueuing,0 org.apache.oozie.service.TestCallableQueueService.testSerialConcurrencyLimit=@org.apache.oozie.service.TestCallableQueueService.testSerialConcurrencyLimit,0 org.apache.oozie.service.TestCallbackService.testCallbacks=@org.apache.oozie.service.TestCallbackService.testCallbacks,0 org.apache.oozie.service.TestConfigurationService.testAlternateConfDir=@org.apache.oozie.service.TestConfigurationService.testAlternateConfDir,0 org.apache.oozie.service.TestConfigurationService.testMissingSite=@org.apache.oozie.service.TestConfigurationService.testMissingSite,0 org.apache.oozie.service.TestCoordMaterializeTriggerService.testCoordMaterializeTriggerService1=@org.apache.oozie.service.TestCoordMaterializeTriggerService.testCoordMaterializeTriggerService1,0 org.apache.oozie.service.TestCoordMaterializeTriggerService.testCoordMaterializeTriggerService2=@org.apache.oozie.service.TestCoordMaterializeTriggerService.testCoordMaterializeTriggerService2,0 org.apache.oozie.service.TestELService.testELForWorkflow=@org.apache.oozie.service.TestELService.testELForWorkflow,0 org.apache.oozie.service.TestEventHandlerService.testEventListener=@org.apache.oozie.service.TestEventHandlerService.testEventListener,0 org.apache.oozie.service.TestEventHandlerService.testService=@org.apache.oozie.service.TestEventHandlerService.testService,0 org.apache.oozie.service.TestGroupsService.testInvalidGroupsMapping=@org.apache.oozie.service.TestGroupsService.testInvalidGroupsMapping,0 org.apache.oozie.service.TestGroupsService.testService=@org.apache.oozie.service.TestGroupsService.testService,0 org.apache.oozie.service.TestHadoopAccessorService.testAccessor=@org.apache.oozie.service.TestHadoopAccessorService.testAccessor,0 org.apache.oozie.service.TestHadoopAccessorService.testCheckSupportedFilesystem=@org.apache.oozie.service.TestHadoopAccessorService.testCheckSupportedFilesystem,0 org.apache.oozie.service.TestHadoopAccessorService.testGetMRDelegationTokenRenewer=@org.apache.oozie.service.TestHadoopAccessorService.testGetMRDelegationTokenRenewer,0 org.apache.oozie.service.TestHadoopAccessorService.testService=@org.apache.oozie.service.TestHadoopAccessorService.testService,0 org.apache.oozie.service.TestHCatAccessorService.testGetJMSConnectionInfo=@org.apache.oozie.service.TestHCatAccessorService.testGetJMSConnectionInfo,0 org.apache.oozie.service.TestHCatAccessorService.testGetJMSConnectionInfoNoDefault=@org.apache.oozie.service.TestHCatAccessorService.testGetJMSConnectionInfoNoDefault,0 org.apache.oozie.service.TestJMSAccessorService.testConnection=@org.apache.oozie.service.TestJMSAccessorService.testConnection,0 org.apache.oozie.service.TestJMSAccessorService.testConnectionContext=@org.apache.oozie.service.TestJMSAccessorService.testConnectionContext,0 org.apache.oozie.service.TestJMSAccessorService.testConnectionRetry=@org.apache.oozie.service.TestJMSAccessorService.testConnectionRetry,0 org.apache.oozie.service.TestJMSAccessorService.testConnectionRetryExceptionListener=@org.apache.oozie.service.TestJMSAccessorService.testConnectionRetryExceptionListener,0 org.apache.oozie.service.TestJMSAccessorService.testConnectionRetryMaxAttempt=@org.apache.oozie.service.TestJMSAccessorService.testConnectionRetryMaxAttempt,0 org.apache.oozie.service.TestJMSAccessorService.testRegisterSingleConsumerPerTopic=@org.apache.oozie.service.TestJMSAccessorService.testRegisterSingleConsumerPerTopic,0 org.apache.oozie.service.TestJMSAccessorService.testUnRegisterTopic=@org.apache.oozie.service.TestJMSAccessorService.testUnRegisterTopic,0 org.apache.oozie.service.TestJMSTopicService.testIncorrectConfigurationDefault=@org.apache.oozie.service.TestJMSTopicService.testIncorrectConfigurationDefault,0 org.apache.oozie.service.TestJMSTopicService.testIncorrectConfigurationJobType=@org.apache.oozie.service.TestJMSTopicService.testIncorrectConfigurationJobType,0 org.apache.oozie.service.TestJMSTopicService.testMixedTopic1=@org.apache.oozie.service.TestJMSTopicService.testMixedTopic1,0 org.apache.oozie.service.TestJMSTopicService.testMixedTopic2=@org.apache.oozie.service.TestJMSTopicService.testMixedTopic2,0 org.apache.oozie.service.TestJMSTopicService.testTopicAsFixedString=@org.apache.oozie.service.TestJMSTopicService.testTopicAsFixedString,0 org.apache.oozie.service.TestJMSTopicService.testTopicAsJobId=@org.apache.oozie.service.TestJMSTopicService.testTopicAsJobId,0 org.apache.oozie.service.TestJMSTopicService.testTopicAsUser=@org.apache.oozie.service.TestJMSTopicService.testTopicAsUser,0 org.apache.oozie.service.TestJMSTopicService.testTopicProperties1=@org.apache.oozie.service.TestJMSTopicService.testTopicProperties1,0 org.apache.oozie.service.TestJMSTopicService.testTopicProperties2=@org.apache.oozie.service.TestJMSTopicService.testTopicProperties2,0 org.apache.oozie.service.TestLiteWorkflowAppService.testActionNameLength=@org.apache.oozie.service.TestLiteWorkflowAppService.testActionNameLength,0 org.apache.oozie.service.TestLiteWorkflowAppService.testCreateprotoConf=@org.apache.oozie.service.TestLiteWorkflowAppService.testCreateprotoConf,0 org.apache.oozie.service.TestLiteWorkflowAppService.testCreateprotoConfWithLibPath=@org.apache.oozie.service.TestLiteWorkflowAppService.testCreateprotoConfWithLibPath,0 org.apache.oozie.service.TestLiteWorkflowAppService.testCreateprotoConfWithMulipleLibPath=@org.apache.oozie.service.TestLiteWorkflowAppService.testCreateprotoConfWithMulipleLibPath,0 org.apache.oozie.service.TestLiteWorkflowAppService.testCreateProtoConfWithSubWorkflowLib1=@org.apache.oozie.service.TestLiteWorkflowAppService.testCreateProtoConfWithSubWorkflowLib1,0 org.apache.oozie.service.TestLiteWorkflowAppService.testCreateProtoConfWithSubWorkflowLib2=@org.apache.oozie.service.TestLiteWorkflowAppService.testCreateProtoConfWithSubWorkflowLib2,0 org.apache.oozie.service.TestLiteWorkflowAppService.testCreateProtoConfWithSubWorkflowLib3=@org.apache.oozie.service.TestLiteWorkflowAppService.testCreateProtoConfWithSubWorkflowLib3,0 org.apache.oozie.service.TestLiteWorkflowAppService.testCreateProtoConfWithSubWorkflowLib4=@org.apache.oozie.service.TestLiteWorkflowAppService.testCreateProtoConfWithSubWorkflowLib4,0 org.apache.oozie.service.TestLiteWorkflowAppService.testCreateProtoConfWithSubWorkflowLib5=@org.apache.oozie.service.TestLiteWorkflowAppService.testCreateProtoConfWithSubWorkflowLib5,0 org.apache.oozie.service.TestLiteWorkflowAppService.testCreateProtoConfWithSubWorkflowLib6=@org.apache.oozie.service.TestLiteWorkflowAppService.testCreateProtoConfWithSubWorkflowLib6,0 org.apache.oozie.service.TestLiteWorkflowAppService.testExtSchema=@org.apache.oozie.service.TestLiteWorkflowAppService.testExtSchema,0 org.apache.oozie.service.TestLiteWorkflowAppService.testMaxWfDefinition=@org.apache.oozie.service.TestLiteWorkflowAppService.testMaxWfDefinition,0 org.apache.oozie.service.TestLiteWorkflowAppService.testParsing=@org.apache.oozie.service.TestLiteWorkflowAppService.testParsing,0 org.apache.oozie.service.TestLiteWorkflowAppService.testReadDefinition=@org.apache.oozie.service.TestLiteWorkflowAppService.testReadDefinition,0 org.apache.oozie.service.TestLiteWorkflowAppService.testSchema=@org.apache.oozie.service.TestLiteWorkflowAppService.testSchema,0 org.apache.oozie.service.TestLiteWorkflowStoreService.testRetry=@org.apache.oozie.service.TestLiteWorkflowStoreService.testRetry,0 org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testEvictionOnTimeToIdle=@org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testEvictionOnTimeToIdle,0 org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testEvictionOnTimeToLive=@org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testEvictionOnTimeToLive,0 org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testMaxElementsInMemory=@org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testMaxElementsInMemory,0 org.apache.oozie.service.TestPartitionDependencyManagerService.testPartitionDependency=@org.apache.oozie.service.TestPartitionDependencyManagerService.testPartitionDependency,0 org.apache.oozie.service.TestPauseTransitService.testPauseBundleAndCoordinator=@org.apache.oozie.service.TestPauseTransitService.testPauseBundleAndCoordinator,0 org.apache.oozie.service.TestPauseTransitService.testPauseCoordinatorForBackwardSupport=@org.apache.oozie.service.TestPauseTransitService.testPauseCoordinatorForBackwardSupport,0 org.apache.oozie.service.TestPauseTransitService.testPauseUnpause1=@org.apache.oozie.service.TestPauseTransitService.testPauseUnpause1,0 org.apache.oozie.service.TestPauseTransitService.testPauseUnpause2=@org.apache.oozie.service.TestPauseTransitService.testPauseUnpause2,0 org.apache.oozie.service.TestPauseTransitService.testStart1=@org.apache.oozie.service.TestPauseTransitService.testStart1,0 org.apache.oozie.service.TestPauseTransitService.testStart2=@org.apache.oozie.service.TestPauseTransitService.testStart2,0 org.apache.oozie.service.TestPauseTransitService.testUnpauseBundleAndCoordinator=@org.apache.oozie.service.TestPauseTransitService.testUnpauseBundleAndCoordinator,0 org.apache.oozie.service.TestProxyUserService.testInvalidGroup=@org.apache.oozie.service.TestProxyUserService.testInvalidGroup,0 org.apache.oozie.service.TestProxyUserService.testInvalidHost=@org.apache.oozie.service.TestProxyUserService.testInvalidHost,0 org.apache.oozie.service.TestProxyUserService.testInvalidProxyUser=@org.apache.oozie.service.TestProxyUserService.testInvalidProxyUser,0 org.apache.oozie.service.TestProxyUserService.testNullHost=@org.apache.oozie.service.TestProxyUserService.testNullHost,0 org.apache.oozie.service.TestProxyUserService.testNullProxyUser=@org.apache.oozie.service.TestProxyUserService.testNullProxyUser,0 org.apache.oozie.service.TestProxyUserService.testService=@org.apache.oozie.service.TestProxyUserService.testService,0 org.apache.oozie.service.TestProxyUserService.testUnknownHost=@org.apache.oozie.service.TestProxyUserService.testUnknownHost,0 org.apache.oozie.service.TestProxyUserService.testValidateAnyHostAnyUser=@org.apache.oozie.service.TestProxyUserService.testValidateAnyHostAnyUser,0 org.apache.oozie.service.TestProxyUserService.testValidateGroup=@org.apache.oozie.service.TestProxyUserService.testValidateGroup,0 org.apache.oozie.service.TestProxyUserService.testValidateHost=@org.apache.oozie.service.TestProxyUserService.testValidateHost,0 org.apache.oozie.service.TestProxyUserService.testWrongConfigGroups=@org.apache.oozie.service.TestProxyUserService.testWrongConfigGroups,0 org.apache.oozie.service.TestProxyUserService.testWrongConfigHosts=@org.apache.oozie.service.TestProxyUserService.testWrongConfigHosts,0 org.apache.oozie.service.TestProxyUserService.testWrongHost=@org.apache.oozie.service.TestProxyUserService.testWrongHost,0 org.apache.oozie.service.TestPurgeService.testPurgeServiceForBundle=@org.apache.oozie.service.TestPurgeService.testPurgeServiceForBundle,0 org.apache.oozie.service.TestPurgeService.testPurgeServiceForCoordinator=@org.apache.oozie.service.TestPurgeService.testPurgeServiceForCoordinator,0 org.apache.oozie.service.TestPurgeService.testPurgeServiceForWorkflow=@org.apache.oozie.service.TestPurgeService.testPurgeServiceForWorkflow,0 org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForKilled=@org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForKilled,0 org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForResume=@org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForResume,0 org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForSubmitted=@org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForSubmitted,0 org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForSuspended=@org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForSuspended,0 org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForWaiting=@org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForWaiting,0 org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForWaitingRegisterPartition=@org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForWaitingRegisterPartition,0 org.apache.oozie.service.TestRecoveryService.testWorkflowActionRecoveryService=@org.apache.oozie.service.TestRecoveryService.testWorkflowActionRecoveryService,0 org.apache.oozie.service.TestRecoveryService.testWorkflowActionRecoveryUserRetry=@org.apache.oozie.service.TestRecoveryService.testWorkflowActionRecoveryUserRetry,0 org.apache.oozie.service.TestSchedulerService.testInstrumentation=@org.apache.oozie.service.TestSchedulerService.testInstrumentation,0 org.apache.oozie.service.TestSchemaService.testBundleSchema=@org.apache.oozie.service.TestSchemaService.testBundleSchema,0 org.apache.oozie.service.TestSchemaService.testCoordSchema=@org.apache.oozie.service.TestSchemaService.testCoordSchema,0 org.apache.oozie.service.TestSchemaService.testCoordSchema2=@org.apache.oozie.service.TestSchemaService.testCoordSchema2,0 org.apache.oozie.service.TestSchemaService.testCoordSLASchema=@org.apache.oozie.service.TestSchemaService.testCoordSLASchema,0 org.apache.oozie.service.TestServices.testDefaultServices=@org.apache.oozie.service.TestServices.testDefaultServices,0 org.apache.oozie.service.TestServices.testServicesExtLoading=@org.apache.oozie.service.TestServices.testServicesExtLoading,0 org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceForTerminalStates=@org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceForTerminalStates,0 org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceKilled=@org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceKilled,0 org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceKilled1=@org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceKilled1,0 org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceKilled2=@org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceKilled2,0 org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServicePaused=@org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServicePaused,0 org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServicePausedWithError=@org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServicePausedWithError,0 org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceRunningWithError=@org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceRunningWithError,0 org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSucceeded1=@org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSucceeded1,0 org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSucceeded2=@org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSucceeded2,0 org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSucceeded3=@org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSucceeded3,0 org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSuspended=@org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSuspended,0 org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSuspendedWithError=@org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSuspendedWithError,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceBackwardSupport=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceBackwardSupport,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceDoneWithError=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceDoneWithError,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceForTimeout=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceForTimeout,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceKilledByUser1=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceKilledByUser1,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceKilledByUser2=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceKilledByUser2,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceNoDoneWithErrorForBackwardSupport=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceNoDoneWithErrorForBackwardSupport,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServicePaused=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServicePaused,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServicePausedWithError=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServicePausedWithError,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceRunning1=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceRunning1,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceRunning2=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceRunning2,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceRunning3=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceRunning3,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceStaleCoordActions=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceStaleCoordActions,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSucceeded=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSucceeded,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendAndResume=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendAndResume,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendedBottomUp=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendedBottomUp,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendedByUser=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendedByUser,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendedWithError=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendedWithError,0 org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceTransitionToDoneWithError=@org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceTransitionToDoneWithError,0 org.apache.oozie.service.TestUUIDService.testChildId=@org.apache.oozie.service.TestUUIDService.testChildId,0 org.apache.oozie.service.TestUUIDService.testConfiguration=@org.apache.oozie.service.TestUUIDService.testConfiguration,0 org.apache.oozie.service.TestUUIDService.testPadding=@org.apache.oozie.service.TestUUIDService.testPadding,0 org.apache.oozie.service.TestXLogService.testCustomLog4jFromConfigDir=@org.apache.oozie.service.TestXLogService.testCustomLog4jFromConfigDir,0 org.apache.oozie.service.TestXLogService.testDefaultLog4jFromConfigDir=@org.apache.oozie.service.TestXLogService.testDefaultLog4jFromConfigDir,0 org.apache.oozie.service.TestXLogService.testDisableLogOverWS=@org.apache.oozie.service.TestXLogService.testDisableLogOverWS,0 org.apache.oozie.service.TestXLogService.testLog4jReload=@org.apache.oozie.service.TestXLogService.testLog4jReload,0 org.apache.oozie.service.TestXLogService.testNoDashInConversionPattern=@org.apache.oozie.service.TestXLogService.testNoDashInConversionPattern,0 org.apache.oozie.servlet.TestAdminServlet.testConfiguration=@org.apache.oozie.servlet.TestAdminServlet.testConfiguration,0 org.apache.oozie.servlet.TestAdminServlet.testInstrumentation=@org.apache.oozie.servlet.TestAdminServlet.testInstrumentation,0 org.apache.oozie.servlet.TestAdminServlet.testJavaSysProps=@org.apache.oozie.servlet.TestAdminServlet.testJavaSysProps,0 org.apache.oozie.servlet.TestAdminServlet.testOsEnv=@org.apache.oozie.servlet.TestAdminServlet.testOsEnv,0 org.apache.oozie.servlet.TestAdminServlet.testSafeMode=@org.apache.oozie.servlet.TestAdminServlet.testSafeMode,0 org.apache.oozie.servlet.TestAdminServlet.testStatus=@org.apache.oozie.servlet.TestAdminServlet.testStatus,0 org.apache.oozie.servlet.TestAdminServlet.testVersion=@org.apache.oozie.servlet.TestAdminServlet.testVersion,0 org.apache.oozie.servlet.TestAuthFilterAuthOozieClient.testClientAuthMethod=@org.apache.oozie.servlet.TestAuthFilterAuthOozieClient.testClientAuthMethod,0 org.apache.oozie.servlet.TestAuthFilterAuthOozieClient.testClientAuthTokenCache=@org.apache.oozie.servlet.TestAuthFilterAuthOozieClient.testClientAuthTokenCache,0 org.apache.oozie.servlet.TestAuthFilterAuthOozieClient.testClientWithAnonymous=@org.apache.oozie.servlet.TestAuthFilterAuthOozieClient.testClientWithAnonymous,0 org.apache.oozie.servlet.TestAuthFilterAuthOozieClient.testClientWithCustomAuthenticator=@org.apache.oozie.servlet.TestAuthFilterAuthOozieClient.testClientWithCustomAuthenticator,0 org.apache.oozie.servlet.TestAuthFilterAuthOozieClient.testClientWithoutAnonymous=@org.apache.oozie.servlet.TestAuthFilterAuthOozieClient.testClientWithoutAnonymous,0 org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testDefaultStatus=@org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testDefaultStatus,0 org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testMultipleBundleIdsForName=@org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testMultipleBundleIdsForName,0 org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testMultipleCoordinators=@org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testMultipleCoordinators,0 org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testMultipleRecords=@org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testMultipleRecords,0 org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testNoRecords=@org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testNoRecords,0 org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testSingleRecord=@org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testSingleRecord,0 org.apache.oozie.servlet.TestCallbackServlet.testCallbackGet=@org.apache.oozie.servlet.TestCallbackServlet.testCallbackGet,0 org.apache.oozie.servlet.TestCallbackServlet.testCallbackPost=@org.apache.oozie.servlet.TestCallbackServlet.testCallbackPost,0 org.apache.oozie.servlet.TestHostnameFilter.testHostname=@org.apache.oozie.servlet.TestHostnameFilter.testHostname,0 org.apache.oozie.servlet.TestHostnameFilter.testMissingHostname=@org.apache.oozie.servlet.TestHostnameFilter.testMissingHostname,0 org.apache.oozie.servlet.TestJobsServlet.testDiffUser=@org.apache.oozie.servlet.TestJobsServlet.testDiffUser,0 org.apache.oozie.servlet.TestJobsServlet.testJobs=@org.apache.oozie.servlet.TestJobsServlet.testJobs,0 org.apache.oozie.servlet.TestJobsServlet.testSubmit=@org.apache.oozie.servlet.TestJobsServlet.testSubmit,0 org.apache.oozie.servlet.TestJsonRestServlet.testContentTypeJsonCron=@org.apache.oozie.servlet.TestJsonRestServlet.testContentTypeJsonCron,0 org.apache.oozie.servlet.TestJsonRestServlet.testFixedResource=@org.apache.oozie.servlet.TestJsonRestServlet.testFixedResource,0 org.apache.oozie.servlet.TestJsonRestServlet.testMultipleResources=@org.apache.oozie.servlet.TestJsonRestServlet.testMultipleResources,0 org.apache.oozie.servlet.TestJsonRestServlet.testMultipleResourcesNoResource=@org.apache.oozie.servlet.TestJsonRestServlet.testMultipleResourcesNoResource,0 org.apache.oozie.servlet.TestJsonRestServlet.testMultipleResourcesWildCard=@org.apache.oozie.servlet.TestJsonRestServlet.testMultipleResourcesWildCard,0 org.apache.oozie.servlet.TestJsonRestServlet.testNoResourceNoParams=@org.apache.oozie.servlet.TestJsonRestServlet.testNoResourceNoParams,0 org.apache.oozie.servlet.TestJsonRestServlet.testParamsRequired=@org.apache.oozie.servlet.TestJsonRestServlet.testParamsRequired,0 org.apache.oozie.servlet.TestJsonRestServlet.testParamTypes=@org.apache.oozie.servlet.TestJsonRestServlet.testParamTypes,0 org.apache.oozie.servlet.TestJsonRestServlet.testResourceGetPostParamGet=@org.apache.oozie.servlet.TestJsonRestServlet.testResourceGetPostParamGet,0 org.apache.oozie.servlet.TestV0JobServlet.testGraph=@org.apache.oozie.servlet.TestV0JobServlet.testGraph,0 org.apache.oozie.servlet.TestV0JobServlet.testJobInfo=@org.apache.oozie.servlet.TestV0JobServlet.testJobInfo,0 org.apache.oozie.servlet.TestV0JobServlet.testReRun=@org.apache.oozie.servlet.TestV0JobServlet.testReRun,0 org.apache.oozie.servlet.TestV1AdminServlet.testAvailableTimeZones=@org.apache.oozie.servlet.TestV1AdminServlet.testAvailableTimeZones,0 org.apache.oozie.servlet.TestV1AdminServlet.testConfiguration=@org.apache.oozie.servlet.TestV1AdminServlet.testConfiguration,0 org.apache.oozie.servlet.TestV1AdminServlet.testInstrumentation=@org.apache.oozie.servlet.TestV1AdminServlet.testInstrumentation,0 org.apache.oozie.servlet.TestV1AdminServlet.testJavaSysProps=@org.apache.oozie.servlet.TestV1AdminServlet.testJavaSysProps,0 org.apache.oozie.servlet.TestV1AdminServlet.testOsEnv=@org.apache.oozie.servlet.TestV1AdminServlet.testOsEnv,0 org.apache.oozie.servlet.TestV1AdminServlet.testSafeMode=@org.apache.oozie.servlet.TestV1AdminServlet.testSafeMode,0 org.apache.oozie.servlet.TestV1AdminServlet.testStatus=@org.apache.oozie.servlet.TestV1AdminServlet.testStatus,0 org.apache.oozie.servlet.TestV1AdminServlet.testV1QueueDump=@org.apache.oozie.servlet.TestV1AdminServlet.testV1QueueDump,0 org.apache.oozie.servlet.TestV1AdminServlet.testVersion=@org.apache.oozie.servlet.TestV1AdminServlet.testVersion,0 org.apache.oozie.servlet.TestV1JobServlet.testCoordChange=@org.apache.oozie.servlet.TestV1JobServlet.testCoordChange,0 org.apache.oozie.servlet.TestV1JobServlet.testGraph=@org.apache.oozie.servlet.TestV1JobServlet.testGraph,0 org.apache.oozie.servlet.TestV1JobServlet.testJobInfo=@org.apache.oozie.servlet.TestV1JobServlet.testJobInfo,0 org.apache.oozie.servlet.TestV1JobServlet.testStart=@org.apache.oozie.servlet.TestV1JobServlet.testStart,0 org.apache.oozie.servlet.TestV1JobServlet.testStartForErrorCode=@org.apache.oozie.servlet.TestV1JobServlet.testStartForErrorCode,0 org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineChange=@org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineChange,0 org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineGetBundleJob=@org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineGetBundleJob,0 org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineGetDefinition=@org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineGetDefinition,0 org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineStreamLog=@org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineStreamLog,0 org.apache.oozie.servlet.TestV1JobsServlet.testJobs=@org.apache.oozie.servlet.TestV1JobsServlet.testJobs,0 org.apache.oozie.servlet.TestV1JobsServlet.testSubmit=@org.apache.oozie.servlet.TestV1JobsServlet.testSubmit,0 org.apache.oozie.servlet.TestVersionServlet.testVersion=@org.apache.oozie.servlet.TestVersionServlet.testVersion,0 org.apache.oozie.sla.TestSLACalculationJPAExecutor.testInsert=@org.apache.oozie.sla.TestSLACalculationJPAExecutor.testInsert,0 org.apache.oozie.sla.TestSLACalculationJPAExecutor.testInsertUpdate=@org.apache.oozie.sla.TestSLACalculationJPAExecutor.testInsertUpdate,0 org.apache.oozie.sla.TestSLACalculationJPAExecutor.testRollback=@org.apache.oozie.sla.TestSLACalculationJPAExecutor.testRollback,0 org.apache.oozie.sla.TestSLAEventGeneration.testCoordinatorActionCommands=@org.apache.oozie.sla.TestSLAEventGeneration.testCoordinatorActionCommands,0 org.apache.oozie.sla.TestSLAEventGeneration.testSLASchema1BackwardCompatibility=@org.apache.oozie.sla.TestSLAEventGeneration.testSLASchema1BackwardCompatibility,0 org.apache.oozie.sla.TestSLAEventGeneration.testWorkflowJobSLANew=@org.apache.oozie.sla.TestSLAEventGeneration.testWorkflowJobSLANew,0 org.apache.oozie.sla.TestSLAJobEventListener.testOnJobEvent=@org.apache.oozie.sla.TestSLAJobEventListener.testOnJobEvent,0 org.apache.oozie.sla.TestSLARegistrationGetJPAExecutor.testSLARegistrationGet=@org.apache.oozie.sla.TestSLARegistrationGetJPAExecutor.testSLARegistrationGet,0 org.apache.oozie.sla.TestSLAService.testBasicService=@org.apache.oozie.sla.TestSLAService.testBasicService,0 org.apache.oozie.sla.TestSLAService.testUpdateSLA=@org.apache.oozie.sla.TestSLAService.testUpdateSLA,0 org.apache.oozie.store.TestCoordinatorStore.testCoordStore=@org.apache.oozie.store.TestCoordinatorStore.testCoordStore,0 org.apache.oozie.store.TestDBWorkflowStore.testDBWorkflowStore=@org.apache.oozie.store.TestDBWorkflowStore.testDBWorkflowStore,0 org.apache.oozie.test.TestEmbeddedServletContainer.testEmbeddedServletContainer=@org.apache.oozie.test.TestEmbeddedServletContainer.testEmbeddedServletContainer,0 org.apache.oozie.test.TestXFsTestCase.testFsDir=@org.apache.oozie.test.TestXFsTestCase.testFsDir,0 org.apache.oozie.test.TestXTestCase.testBaseDir=@org.apache.oozie.test.TestXTestCase.testBaseDir,0 org.apache.oozie.test.TestXTestCase.testSysPropSetting=@org.apache.oozie.test.TestXTestCase.testSysPropSetting,0 org.apache.oozie.test.TestXTestCase.testWaitFor=@org.apache.oozie.test.TestXTestCase.testWaitFor,0 org.apache.oozie.TestActionBean.testAction=@org.apache.oozie.TestActionBean.testAction,0 org.apache.oozie.TestActionBean.testEmptyWriteRead=@org.apache.oozie.TestActionBean.testEmptyWriteRead,0 org.apache.oozie.TestBundleEngineSimple.testParseBulkFilterNegative=@org.apache.oozie.TestBundleEngineSimple.testParseBulkFilterNegative,0 org.apache.oozie.TestBundleEngineSimple.testParseFilterNegative=@org.apache.oozie.TestBundleEngineSimple.testParseFilterNegative,0 org.apache.oozie.TestBundleJobBean.testSerialization=@org.apache.oozie.TestBundleJobBean.testSerialization,0 org.apache.oozie.TestCoordinatorEngine.testCustomDoneFlag=@org.apache.oozie.TestCoordinatorEngine.testCustomDoneFlag,0 org.apache.oozie.TestCoordinatorEngine.testDoneFlag=@org.apache.oozie.TestCoordinatorEngine.testDoneFlag,0 org.apache.oozie.TestCoordinatorEngine.testDoneFlagCreation=@org.apache.oozie.TestCoordinatorEngine.testDoneFlagCreation,0 org.apache.oozie.TestCoordinatorEngine.testEmptyDoneFlag=@org.apache.oozie.TestCoordinatorEngine.testEmptyDoneFlag,0 org.apache.oozie.TestCoordinatorEngineSimple.testParseFilterNegative=@org.apache.oozie.TestCoordinatorEngineSimple.testParseFilterNegative,0 org.apache.oozie.TestCoordinatorEngineSimple.testParseFilterPositive=@org.apache.oozie.TestCoordinatorEngineSimple.testParseFilterPositive,0 org.apache.oozie.TestCoordinatorEngineStreamLog.testStreamLog2=@org.apache.oozie.TestCoordinatorEngineStreamLog.testStreamLog2,0 org.apache.oozie.TestCoordinatorEngineStreamLog.testStreamLog4JobLogAction=@org.apache.oozie.TestCoordinatorEngineStreamLog.testStreamLog4JobLogAction,0 org.apache.oozie.TestCoordinatorEngineStreamLog.testStreamLog4JobLogDate=@org.apache.oozie.TestCoordinatorEngineStreamLog.testStreamLog4JobLogDate,0 org.apache.oozie.TestCoordinatorEngineStreamLog.testStreamLog4NullNull=@org.apache.oozie.TestCoordinatorEngineStreamLog.testStreamLog4NullNull,0 org.apache.oozie.TestCoordinatorJobBean.testSerialization=@org.apache.oozie.TestCoordinatorJobBean.testSerialization,0 org.apache.oozie.TestDagELFunctions.testFunctions=@org.apache.oozie.TestDagELFunctions.testFunctions,0 org.apache.oozie.TestDagEngine.testGetJobs=@org.apache.oozie.TestDagEngine.testGetJobs,0 org.apache.oozie.TestDagEngine.testJobDefinition=@org.apache.oozie.TestDagEngine.testJobDefinition,0 org.apache.oozie.TestDagEngine.testSubmit=@org.apache.oozie.TestDagEngine.testSubmit,0 org.apache.oozie.TestLocalOozieClientCoord.testGetJobsInfo=@org.apache.oozie.TestLocalOozieClientCoord.testGetJobsInfo,0 org.apache.oozie.TestLocalOozieClientCoord.testHeaderMethods=@org.apache.oozie.TestLocalOozieClientCoord.testHeaderMethods,0 org.apache.oozie.TestLocalOozieClientCoord.testJobMethods=@org.apache.oozie.TestLocalOozieClientCoord.testJobMethods,0 org.apache.oozie.TestSLAEventBean.testSetGet=@org.apache.oozie.TestSLAEventBean.testSetGet,0 org.apache.oozie.TestSLAEventBean.testToXmlRegistrationEvent=@org.apache.oozie.TestSLAEventBean.testToXmlRegistrationEvent,0 org.apache.oozie.TestSLAEventBean.testToXmlStatusEvent=@org.apache.oozie.TestSLAEventBean.testToXmlStatusEvent,0 org.apache.oozie.TestV1JobsServletBundleEngine.testGetBundleJobs=@org.apache.oozie.TestV1JobsServletBundleEngine.testGetBundleJobs,0 org.apache.oozie.TestWorkflowBean.testEmptyWriteRead=@org.apache.oozie.TestWorkflowBean.testEmptyWriteRead,0 org.apache.oozie.TestWorkflowBean.testWorkflow=@org.apache.oozie.TestWorkflowBean.testWorkflow,0 org.apache.oozie.util.db.TestSchema.testGenerateCreateScript=@org.apache.oozie.util.db.TestSchema.testGenerateCreateScript,0 org.apache.oozie.util.TestCoordActionsInDateRange.testCoordActionsInDateRange=@org.apache.oozie.util.TestCoordActionsInDateRange.testCoordActionsInDateRange,0 org.apache.oozie.util.TestELConstantsFunctions.testAppendAll=@org.apache.oozie.util.TestELConstantsFunctions.testAppendAll,0 org.apache.oozie.util.TestELConstantsFunctions.testReplaceAll=@org.apache.oozie.util.TestELConstantsFunctions.testReplaceAll,0 org.apache.oozie.util.TestELConstantsFunctions.testToConfigurationStr=@org.apache.oozie.util.TestELConstantsFunctions.testToConfigurationStr,0 org.apache.oozie.util.TestELConstantsFunctions.testToJsonStr=@org.apache.oozie.util.TestELConstantsFunctions.testToJsonStr,0 org.apache.oozie.util.TestELEvaluator.testCheckForExistence=@org.apache.oozie.util.TestELEvaluator.testCheckForExistence,0 org.apache.oozie.util.TestELEvaluator.testContextFunctions=@org.apache.oozie.util.TestELEvaluator.testContextFunctions,0 org.apache.oozie.util.TestELEvaluator.testContextVars=@org.apache.oozie.util.TestELEvaluator.testContextVars,0 org.apache.oozie.util.TestELEvaluator.testFunctionELEvaluationError=@org.apache.oozie.util.TestELEvaluator.testFunctionELEvaluationError,0 org.apache.oozie.util.TestELEvaluator.testVars=@org.apache.oozie.util.TestELEvaluator.testVars,0 org.apache.oozie.util.TestGraphGenerator.testConstructor=@org.apache.oozie.util.TestGraphGenerator.testConstructor,0 org.apache.oozie.util.TestGraphGenerator.testWrite=@org.apache.oozie.util.TestGraphGenerator.testWrite,0 org.apache.oozie.util.TestInstrumentation.testAll=@org.apache.oozie.util.TestInstrumentation.testAll,0 org.apache.oozie.util.TestInstrumentation.testCron=@org.apache.oozie.util.TestInstrumentation.testCron,0 org.apache.oozie.util.TestInstrumentation.testInstrumentationCounter=@org.apache.oozie.util.TestInstrumentation.testInstrumentationCounter,0 org.apache.oozie.util.TestInstrumentation.testInstrumentationTimer=@org.apache.oozie.util.TestInstrumentation.testInstrumentationTimer,0 org.apache.oozie.util.TestInstrumentation.testSamplers=@org.apache.oozie.util.TestInstrumentation.testSamplers,0 org.apache.oozie.util.TestInstrumentation.testTimer=@org.apache.oozie.util.TestInstrumentation.testTimer,0 org.apache.oozie.util.TestInstrumentation.testVariables=@org.apache.oozie.util.TestInstrumentation.testVariables,0 org.apache.oozie.util.TestIOUtils.testCopyStream=@org.apache.oozie.util.TestIOUtils.testCopyStream,0 org.apache.oozie.util.TestIOUtils.testGetResourceAsString=@org.apache.oozie.util.TestIOUtils.testGetResourceAsString,0 org.apache.oozie.util.TestLogStreamer.testStreamLog=@org.apache.oozie.util.TestLogStreamer.testStreamLog,0 org.apache.oozie.util.TestLogStreamer.testStreamLogMultipleHours=@org.apache.oozie.util.TestLogStreamer.testStreamLogMultipleHours,0 org.apache.oozie.util.TestLogStreamer.testStreamLogNoDash=@org.apache.oozie.util.TestLogStreamer.testStreamLogNoDash,0 org.apache.oozie.util.TestMemoryLocks.testNoWaitWriteLock=@org.apache.oozie.util.TestMemoryLocks.testNoWaitWriteLock,0 org.apache.oozie.util.TestMemoryLocks.testReadLock=@org.apache.oozie.util.TestMemoryLocks.testReadLock,0 org.apache.oozie.util.TestMemoryLocks.testReadWriteLock=@org.apache.oozie.util.TestMemoryLocks.testReadWriteLock,0 org.apache.oozie.util.TestMemoryLocks.testTimeoutTimingOutWriteLock=@org.apache.oozie.util.TestMemoryLocks.testTimeoutTimingOutWriteLock,0 org.apache.oozie.util.TestMemoryLocks.testTimeoutWaitingWriteLock=@org.apache.oozie.util.TestMemoryLocks.testTimeoutWaitingWriteLock,0 org.apache.oozie.util.TestMemoryLocks.testWaitWriteLock=@org.apache.oozie.util.TestMemoryLocks.testWaitWriteLock,0 org.apache.oozie.util.TestMemoryLocks.testWriteReadLock=@org.apache.oozie.util.TestMemoryLocks.testWriteReadLock,0 org.apache.oozie.util.TestOozieRollingPolicy.testDeletingOldFiles=@org.apache.oozie.util.TestOozieRollingPolicy.testDeletingOldFiles,0 org.apache.oozie.util.TestParamChecker.testNotEmptyElements=@org.apache.oozie.util.TestParamChecker.testNotEmptyElements,0 org.apache.oozie.util.TestParamChecker.testNotNullElements=@org.apache.oozie.util.TestParamChecker.testNotNullElements,0 org.apache.oozie.util.TestParamChecker.testValidToken=@org.apache.oozie.util.TestParamChecker.testValidToken,0 org.apache.oozie.util.TestParameterVerifier.testSupportsParameters=@org.apache.oozie.util.TestParameterVerifier.testSupportsParameters,0 org.apache.oozie.util.TestParameterVerifier.testVerifyParametersDefined=@org.apache.oozie.util.TestParameterVerifier.testVerifyParametersDefined,0 org.apache.oozie.util.TestParameterVerifier.testVerifyParametersEmpty=@org.apache.oozie.util.TestParameterVerifier.testVerifyParametersEmpty,0 org.apache.oozie.util.TestParameterVerifier.testVerifyParametersEmptyName=@org.apache.oozie.util.TestParameterVerifier.testVerifyParametersEmptyName,0 org.apache.oozie.util.TestParameterVerifier.testVerifyParametersMissing=@org.apache.oozie.util.TestParameterVerifier.testVerifyParametersMissing,0 org.apache.oozie.util.TestParameterVerifier.testVerifyParametersNull=@org.apache.oozie.util.TestParameterVerifier.testVerifyParametersNull,0 org.apache.oozie.util.TestWritableUtils.testWriteReadStr=@org.apache.oozie.util.TestWritableUtils.testWriteReadStr,0 org.apache.oozie.util.TestXConfiguration.testAddXIncludeFromReader=@org.apache.oozie.util.TestXConfiguration.testAddXIncludeFromReader,0 org.apache.oozie.util.TestXConfiguration.testAddXIncludeFromStream=@org.apache.oozie.util.TestXConfiguration.testAddXIncludeFromStream,0 org.apache.oozie.util.TestXConfiguration.testCopy=@org.apache.oozie.util.TestXConfiguration.testCopy,0 org.apache.oozie.util.TestXConfiguration.testInjectDefaults=@org.apache.oozie.util.TestXConfiguration.testInjectDefaults,0 org.apache.oozie.util.TestXConfiguration.testVarResolutionAndSysProps=@org.apache.oozie.util.TestXConfiguration.testVarResolutionAndSysProps,0 org.apache.oozie.util.TestXLog.testInfoParameters=@org.apache.oozie.util.TestXLog.testInfoParameters,0 org.apache.oozie.util.TestXLog.testInfoThreadLocal=@org.apache.oozie.util.TestXLog.testInfoThreadLocal,0 org.apache.oozie.util.TestXLog.testXLogFunctionality=@org.apache.oozie.util.TestXLog.testXLogFunctionality,0 org.apache.oozie.util.TestXLogFilter.testXLogFileter=@org.apache.oozie.util.TestXLogFilter.testXLogFileter,0 org.apache.oozie.util.TestXLogReader.testProcessCoordinatorLogForActions=@org.apache.oozie.util.TestXLogReader.testProcessCoordinatorLogForActions,0 org.apache.oozie.util.TestXLogReader.testProcessLog=@org.apache.oozie.util.TestXLogReader.testProcessLog,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDecisionForkJoin=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDecisionForkJoin,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDecisionForkJoinFailure=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDecisionForkJoinFailure,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDecisionMultipleForks=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDecisionMultipleForks,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDecisionsToJoinForkJoin=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDecisionsToJoinForkJoin,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDecisionsToKillForkJoin=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDecisionsToKillForkJoin,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDecisionToEndForkJoinFailure=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDecisionToEndForkJoinFailure,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDisableWFValidateForkJoin=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testDisableWFValidateForkJoin,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testErrorTransitionForkJoin=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testErrorTransitionForkJoin,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testForkJoinFailure=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testForkJoinFailure,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testForkJoinMismatch=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testForkJoinMismatch,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testNestedForkJoin=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testNestedForkJoin,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testNestedForkJoinFailure=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testNestedForkJoinFailure,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParser=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParser,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParserGlobal=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParserGlobal,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParserGlobalExtensionActions=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParserGlobalExtensionActions,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParserGlobalExtensionActionsLocalAlreadyExists=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParserGlobalExtensionActionsLocalAlreadyExists,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParserGlobalExtensionActionsNoGlobal=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParserGlobalExtensionActionsNoGlobal,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParserGlobalJobXML=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParserGlobalJobXML,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParserGlobalLocalAlreadyExists=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testParserGlobalLocalAlreadyExists,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testRaceConditionWithOldXerces=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testRaceConditionWithOldXerces,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testSimpleForkJoin=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testSimpleForkJoin,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testTransition2=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testTransition2,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testTransition3=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testTransition3,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testTransitionFailure1=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testTransitionFailure1,0 org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testWfNoForkJoin=@org.apache.oozie.workflow.lite.TestLiteWorkflowAppParser.testWfNoForkJoin,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testActionOKError=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testActionOKError,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testAsynchSimple=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testAsynchSimple,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testDecision=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testDecision,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testDoneWithRunningNodes=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testDoneWithRunningNodes,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testEmptyWorkflow=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testEmptyWorkflow,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testFailWithRunningNodes=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testFailWithRunningNodes,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testForkedContext=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testForkedContext,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testImmediateError=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testImmediateError,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testInvalidExecutionPath=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testInvalidExecutionPath,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testJobPersistance=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testJobPersistance,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testKillWithRunningNodes=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testKillWithRunningNodes,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testKillWorkflow=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testKillWorkflow,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testLoopFork=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testLoopFork,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testLoopSimple=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testLoopSimple,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testNestedFork=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testNestedFork,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testNodeContext=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testNodeContext,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testSelfTransition=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testSelfTransition,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testSimpleFork=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testSimpleFork,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testSynchDouble=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testSynchDouble,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testSynchSimple=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testSynchSimple,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testWfFailWithRunningNodes=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testWfFailWithRunningNodes,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testWFKillWithRunningNodes=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testWFKillWithRunningNodes,0 org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testWorkflowStates=@org.apache.oozie.workflow.lite.TestLiteWorkflowLib.testWorkflowStates,0 ",oozie,1
 Setting total failover attempts to . p1 testClientRetriesIdempotentOpWithIOExceptionSucceedsSecondTime p2 p3 getCurrentKey getKMSUrl conf when result times verify thenThrow test kp anyString thenReturn getProviders keyName assertEquals eq setInt CommonConfigurationKeysPublic keyVersion Mockito mock v1 ,hadoop,0
cluster Namenode has   fetch bad file list from namenode. There should be one file. getName  length  testCorruptFilesCorruptedBlock  fetch bad file list from namenode. There should be none. .meta channel conf getChannel  bad files. Expecting 1. storageDir buffer /srcdat10 write info   Deliberately corrupting file  DFSConfigKeys getBlockPoolId  read all files to trigger detection of corrupted replica LOG listCorruptFileBlocks getFileSystem Blocks do not exist in data-dir setInt getNameNode / blk_ Corrupted replicas not handled properly. Expecting BlockMissingException  util size cleanup endsWith position getInstanceStorageDir idx shutdown  datanode sends block reports getFinalizedDir rw bpid fs namenode System nextBytes random badFiles file assertTrue listFiles close testListCorruptFilesCorruptedBlock data_dir MiniDFSCluster e blocks  Now deliberately corrupt one block  at offset  length Namenode has bad files.  ByteBuffer  corrupt files. Expecting None. data directory does not exist createFiles build exists checkFiles  but received IOException  Received BlockMissingException as expected. wrap  create two files with one block each  datanode scans directories getNamesystem startsWith ,hadoop,1
.name foo  test call with no properties for a given prefix conf none bar assertTrue assertNotNull get prefix. value prefixedProps set value_bar subprefix.  Repeat test with variable substitution subname isEmpty is assertEquals value_${foo} getPropsWithPrefix assertThat different.prefix size name testGettingPropertiesWithPrefix ,hadoop,0
cluster backup getFirstTxId nnImageBefore  BN checkpoint getRpcServer conf /edit-while-bn-down nn should have received new checkpoint. before:  assertNotNull StartupOption getFSImage  NN should have received a new image doCheckpoint isInProgress nnImageAfter info rollEditLog Should not have finalized  LOG  BN should stay in sync after checkpoint getFileSystem  BN should stay in sync after roll getNameNode  do some edits stop numDataNodes mkdirs fileSys getStorage getFileInfo shutdown testBackupNodeTailsEdits nn getStorageDir nnRpc getMostRecentCheckpointTxId  start a new backup node  Force a roll -- BN should roll with NN. findLatestEditsLog sd editsLog assertTrue close getCurSegmentTxId bnImage getEditLog  after:  Shutting down...  still open on the NN  Stop BN testBNInSync assertEquals startBackupNode build assertStorageDirsMatch FSImageTestUtil getNamesystem ,hadoop,1
cleanedConts attempt setLevel unregisterAppAttempt Assert nodeHeartbeat Got  getRootLogger  cleanedApps:  info getContainersToCleanup cleanedApps app contReceived contsToClean LOG getAppAttemptId conts  containers. Waiting to get  am ContainerState submitApp allocate size getApplicationsToCleanup stop  kick the scheduler Level rm 127.0.0.1 rootLogger request getApplicationId 127.0.0.1:1234 registerAppAttempt  request for containers getCurrentAppAttempt  kick the scheduling waitForState sleep nm1 sendAMLaunched get getAllocatedContainers  AM container is cleaned via container launcher apps resp start assertEquals Thread registerNode Waiting to get cleanup events.. cleanedConts:  testAppCleanup RMAppAttemptState waitCount LogManager ,hadoop,1
bundleJobGetExecutor bundle-app-name jobConf log submitCmd getId getStatus appPath Configuration parse error. read from DB : getJob sleep assertNotNull get getAuthToken Job getBundleId waitFor getAppName set getConf addRecordToBundleJobTable testBundleStart2 assertEquals execute bundle.xml call Services warn OozieClient size bundleActionsGetExecutor equals toString isCritical ErrorCode job jpaService actions evaluate ioe ,oozie,1
testUserNameAnonymousOn _testUserName ,hadoop,0
"init res .dataout.ABC.unresolved 20120230 hcat://hcat.server.com:5080/mydb/clicks/datastamp=20120230;region=US CoordELFunctions ${coord:dataOutPartitionValue('ABC','region')} testDataOutPartitionValue setVariable coord-action-start eval evalAndWrap assertTrue .dataout.ABC ${coord:dataOutPartitionValue('ABC','datastamp')} equals expr Boolean US ",oozie,1
prepareAppendKey outKey key0 assertTrue Multiple close should have no effect. skip testFailureCloseKeyStreamManyTimesInWriter writer close write getBytes ,hadoop,0
init getProperty getConf getResourceAsStream oozie- cl user.name destroy assertEquals customConfDir System oozie-site1.xml testAlternateConfDir IOUtils assertNull xconf oozie.system.id oozie.dummy setSystemProperty copyStream get createTestCaseSubDir oozie-site.xml ConfigurationService ,oozie,1
testSla END_POINTS IS_SECURITY_ENABLED getContextURL data oozieUrl wc </sla-message> System setOut call contains oldStream assertTrue <sla-message> toString SERVLET_CLASSES getSlaInfo runTest <last-sequence-id>0</last-sequence-id> ,oozie,1
 testFile01 getPathData processPathDirOrderLengthLarge testfile01 addContents -S ls formatLineMtime out  overflow issues) testfile03  set file length in different order to file names options computeLineFormat inOrder testfile02 processOptions verify testfile05 testFile06 testfile04 testFile04 testFile05 testfile06 testFile02 testFile03 add Found 6 items pathData lineFormat length setIsDir processArguments testDir Integer testDirectory setLength verifyNoMoreInteractions TestFile mock ,hadoop,0
 Note the trailing '/' in the target path. /foo Expected failed put to a path without parent directory Expected failed copyFromLocal to a non-existent directory srcPath is assertThat noDir delete / not -put shellRun lfs exists -copyFromLocal testCopyNoParent toString noDirName ,hadoop,0
 %bar% begin %foo%_%bar%_%baz% end %foo%_%bar%_%baz% testReplaceTokensWinEnvVars foo pattern assertEquals zoo__zaz put zaz begin zoo__zaz end StringUtils replaceTokens %baz% baz replacements zoo %foo% ,hadoop,0
"def addNode Expected to catch an exception but did not encounter any three two getCause  Make sure the message contains the nodes involved in the invalid transition to end node [end] asList we invokeForkJoin getErrorCode assertTrue four node [two] dummyConf end testDecisionToEndForkJoinFailure       *f->(2,3)      *2->decision node->{4,end}      *3->ok->j      *3->fail->k      *4->ok->j      *4->fail->k      *j->end       f one getMessage j assertEquals k kill fail contains ex parser name ErrorCode Arrays ",oozie,1
conn setRequestMethod IS_SECURITY_ENABLED assertFalse assertTrue array get json content-type testAvailableTimeZones /v1/admin/* Collections runTest JsonTags RestConstants openConnection containsKey isEmpty HttpServletResponse assertEquals parse getInputStream url JSONValue call getHeaderField GET getResponseCode createURL startsWith ,oozie,1
hcat://hcatserver.blue.server.com:8020 getJMSConnectionInfo connInfo1  both servers should connect to default JMS server hcatService testConnection createConnectionContext jmsService assertEquals services ctxt2 ctxt1 connInfo assertTrue get http://unknown:80 isConnectionInitialized close ,oozie,1
cluster getBlockLocations fileName conf getKind fs waitActive out sleep Assert /testBlockTokenInLastLocatedBlock locatedBlocks create write close getLastLocatedBlock DFSConfigKeys filePath assertEquals numNameNodes getFileSystem getNameNodeRpc testBlockTokenInLastLocatedBlock setInt Thread token getBlockToken BlockTokenIdentifier build numDataNodes shutdown setBoolean ,hadoop,1
encode ISO-8859-1 data BarcodeFormat StandardCharsets expectedMatrix UTF-8 aztec assertEquals testWriter matrix ISO-8859-15 getBytes testAztecWriter  Test AztecWriter defaults getMatrix â‚¬ 1 sample data. Encoder In ut magna vel mauris malesuada writer ,zxing,1
bundleJobGetExecutor addRecordToBundleActionTable testBundleRerunInSuspended addRecordToBundleJobTable getId assertEquals getStatus execute addRecordToCoordJobTable call CoordinatorJob Services assertNotNull get action1 Job job action2 jpaService ,oozie,1
conn setRequestMethod IS_SECURITY_ENABLED put assertTrue get json /v1/job/* content-type /v1/admin/* Collections runTest SYSTEM_MODE JsonTags RestConstants openConnection containsKey MockDagEngineService HttpServletResponse assertEquals parse params getInputStream url PUT JSONValue call 1 getHeaderField getResponseCode GET reset createURL toString testSafeMode startsWith ,oozie,1
"storePassword trustStrategy getResource toCharArray getName getIssuerDN serverSocket newSingleThreadExecutor Executors serverSslContext getServerSocketFactory Assert bind assertNotNull nopassword create TimeUnit Boolean SSLContextBuilder write isTrusted localhost read localPort loadKeyMaterial loadTrustMaterial issuerDN CN=Test CA, OU=HttpComponents Project, O=Apache Software Foundation inputStream setSoTimeout cert2 getInputStream /test-server.p12 resource1 accept cert1 createSocket clientSslContext TIMEOUT getLocalPort submit certChainRef EMAILADDRESS=dev@hc.apache.org,  clientSocket result CN=Test Server, OU=HttpComponents Project, O=Apache Software Foundation flush keyPassword get getSubjectDN outputStream close connect testSSLHandshakeServerCustomTrustStrategy chain set assertEquals certs call getSocketFactory subjectDN2 build subjectDN1 future toMillisecondsIntBound getOutputStream socket createServerSocket ",httpcore,0
read dst StandardCharsets hasRemaining channel 10 1234567890123456  decoder ByteBuffer 5 12345 5 12345 testMissingLastCRLF allocate inbuf metrics isCompleted ,httpcore,0
" Object under test  No origin in list is allowed assertFalse conf regex:https?:\/\/sub1[.]example[.]com(:[0-9]+)?,  foo.nomatch.com foo.example2.com https://sub1.example.com:8080 example2.com put filterConfig foo.example2.com  match multiple sub-domains Assert assertTrue http://sub1.example.com foo.nomatch1.com foo.nomatch2.com *.example2.com testMixedRegexPatternMatchingOrigins init  Setup the configuration settings of the server http://sub1.example.com:1234  Second origin is allowed CrossOriginFilter areOriginsAllowed filter  First origin is allowed foo.example2.com foo.nomatch.com https://sub1.example.com foo.bar.example2.com foo:example2.com ",hadoop,0
 execPath testWfActionGetWithExecPath addRecordToWfActionTable getId WorkflowInstance _testGetActionWithExecPath 1 addRecordToWfJobTable WorkflowAction /fork action toString WorkflowJob job append ,oozie,1
<chmod path=''{5}'' permissions=''-rwxrwxrwx''/> chmod1 chmod2 chmod3 <chmod path=''{6}'' permissions=''-rwxrwx---'' dir-files=''false''/> source createContext grandchild1 grandchild3 newFile2X xml chmod2X getPath getFileStatus mkdirX mkdir <touchz path=''{8}''/> <move source=''{3}'' target=''{4}''/> getPermission ae format parseXml <mkdir path=''{1}''/> getFileSystem </root> chmod1X str rwxrwx--- newFile1X mkdirs <chmod path=''{9}'' permissions=''-rwxrwx---''> <recursive/> </chmod> newFile2 <fs/> newFile1 assertFalse doOperations <touchz path=''{7}''/> child2 fs delete child3 child1 <delete path=''{2}''/> assertTrue getNameNodeUri sourceX MessageFormat XmlUtils toUri deleteX <root><name-node>{0}</name-node> testDoOperationsWithNameNodeElement assertEquals rwxrwxrwx target chmod3X assertNotSame exists toString createNewFile getFsTestCaseDir ,oozie,1
addRecordToBundleJobTable getId assertEquals getStatus execute call Services bundleJob size assertNotNull get Job job testBundleJobInfo1 jpaService bundleJobGetjpa getCoordinators ,oozie,1
" Check whether transactions are rolled back or not Expected exception due to commit failure but didn't get any PREP getId WorkflowInstance actionGetCmd deactivate testBulkInsertUpdatesRollback wfBean addRecordToWfJobTable getErrorCode assertNotNull wfUpdateCmd1 get WorkflowJob updateList add getStatusStr insertList Expected exception but didnt get any wfGetCmd assertEquals SkipCommitFaultInjection  Add two actions to insert list execute setStatus FaultInjection 1 Services fail jpaee 2 WorkflowAction org.apache.oozie.command.SkipCommitFaultInjection setSystemProperty true createWorkflowAction action1  set fault injection to true, so transaction is roll backed ErrorCode job action2  Add to update list  status should not be RUNNING jpaService ",oozie,1
parseStaticMap gid 10 200  uid 10000 10001# line without whitespace before comment    # Comment at the beginning of a line  testStaticMapParsing parsedMap gid 4294967295 321 uid 10 100  gid 12 202  get  Entirely empty line. uid 13 302   Ensure pass-through of unmapped IDs works. uid 4294967294 123  nfs- uid 12 301  uid 11 201 # comment at the end of a line  createTempFile assertEquals tempStaticMapFile staticMapFileContents     # Comment that starts late in the line   Tabs instead of spaces. gid	11	201  .map ShellBasedIdMapping File createStaticMapFile ,hadoop,0
doTest testISBN 9784567890123 ,zxing,0
X-Timestamp getLocation  get a cell getName setBatch X-Column delete put testSimpleScannerBinary TABLE  new scanner Bytes /scanner MIMETYPE_BINARY assertTrue assertNotNull get client model getCode foundTimestampHeader addColumn scannerURI foundRowHeader getHeaders getBody toBytes foundColumnHeader X-Row assertEquals  delete the scanner /  verify that data was returned MIMETYPE_PROTOBUF COLUMN_1 response createProtobufOutput equals header  verify that the expected X-headers are present ,hadoop,1
testCoordReRunNeg2 END_POINTS IS_SECURITY_ENABLED oozieUrl assertFalse run appPath get create SERVLET_CLASSES close runTest app MockCoordinatorEngineService coordinator.xml getContextURL MockDagEngineService assertEquals getFileSystem -rerun args call 1 -oozie assertNull mkdirs job getFsTestCaseDir ,oozie,1
"add %x{'opt}'} %x{t,y} hello world. Token assertEquals tokenize %x{t} witness 12y   testOptions t tl y %x{""hello world."", ""12y  ""} ol opt} ",logback,0
"server getName fs2 getHdfsConf fs1 conf dir asList TestDirHelper sleep Assert createHadoopConf /tmp/foo server.services StringUtils assertNotNull /tmp/foo2 get /tmp/foo1 server.hadoop.filesystem.cache.purge.timeout join hadoop getFileSystemConfiguration createFileSystem releaseFileSystem  should be same instance because of caching init fileSystemCache set  still around because of caching getAbsolutePath TestHdfsHelper getTestDir hadoopConf destroy assertEquals services ,  should not be around as lease count is 0 Thread CommonConfigurationKeysPublic 1 fail server.hadoop.filesystem.cache.purge.frequency u mkdirs Arrays  still around because of lease count is 1 (fs2 is out) ",hadoop,1
dataBytes ecBytes generateECBytes bytes Encoder expected  High-order zero coefficient case. assertEquals  http://www.swetake.com/qr/qr9.html testGenerateECBytes ,zxing,0
cluster  Now verify that it shows up on webui http://  start a cluster with single datanode conf WARNING : There are  getBlockManager getUnderReplicatedBlocksCount createFile waitActive HDFS Front page does not contain expected warning readFully 1 missing blocks block info /dfshealth.jsp DFSConfigKeys in LOG Waiting for missing blocks count to be zero... dfsFrontPage getFileSystem Waiting for missing blocks count to increase... setInt dfs contains HDFS Front page contains unexpected warning  read the file so that the corrupt block is reported to NN TestDatanodeBlockScanner getFirstBlock shutdown getUnderReplicatedNotMissingBlocks assertFalse bm corruptFile delete /testMissingBlocksAlert/file1 warnStr testMissingBlocksAlert sleep getMissingBlocksCount assertTrue get  Corrupt the block close DFSTestUtil /testMissingBlocks/corruptFile assertEquals  minimize test delay corruptReplica url Thread fileLen build urlGet  blocks to go to zero open getNamesystem  create a normal file ,hadoop,1
a A b ELConstantsFunctions <x> XmlUtils </x> e map2 & getText parseXml assertEquals parse put toJsonStr str testToJsonStr json map ,oozie,1
prepareAppendValue ROOT reader BLOCK_SIZE dos conf fs buildValue getBytes out NENTRY advance path getLen getFileStatus scanner create cube close write value key set atEnd in jClassLongWritableComparator assertEquals getFileSystem createScanner testSortedLongWritable prepareAppendKey entry getValue gz name getLength writer open ,hadoop,0
getTimers INTERVAL a b start assertEquals testInstrumentationTimer cron1 cron2 addCron cron3 Thread sleep 1 getValue 2 size stop inst get getOwn ,oozie,1
writeObject inStream somehost raw outbuffer assertEquals testSerialization outStream inBuffer readObject Assert orig toByteArray clone close ,httpcore,0
parent foo2://bar2/baz2 testChildParentResolution assertEquals foo1://bar1/baz1 child ,hadoop,0
addRecordToBundleJobTableNegative bundleJobGetExecutor job1 testBundleStartNegative2 getId assertEquals getStatus execute call Services assertNotNull get equals Job job jpaService evaluate waitFor ,oozie,1
"openFile writeData createFile recursive CRC_SIZE file stats TEST_ROOT_DIR Bytes read in openFile() call with stats  get assertWritesCRC overwrite close write getBytesRead  now read back the data, again with the builder API createFile() createFileNonRecursive() assertEquals bytesRead0  now write with overwrite = true testReadIncludesCRCwithBuilders build DATA fileSys getFileStatistics  write the file using the builder API ",hadoop,0
server getCurrentUser RPC SomeSuperUser GROUP_NAMES getUser  The user returned by server must be the one in the token. newEmptyRequest conf run masterConf AuthenticationMethod  (auth:TOKEN) via SomeSuperUser (auth:SIMPLE) retVal setAuthenticationMethod testProxyWithToken current Assert refreshConf getUserName client sm setProtocolEngine addr setConfiguration UserGroupInformation addToken proxyUserUgi tokenId printStackTrace e assertEquals getClient     *  Tests the scenario when token authorization is used.    *  The server sees only the the owner of the token as the    *  user.     createRemoteUser setTokenService REAL_USER_NAME token doAs stop SecurityUtil setupTestServer PROXY_USER_NAME createProxyUserForTesting ,hadoop,0
item getConf /one/two/test apply assertEquals  test the full path is printed to stdout setOut out Result testPrint print filename verifyNoMoreInteractions options mock setOptions verify mockFs ,hadoop,0
"de franÃ§ais en-US en-CA NinjaConstant defaultlanguage language fr a_non_existing_key when da,fr-FR;q=0.8 empty  that will refer to messages_fr-FR.properties: testGetWithLanguage of get deutsch english lang de-DE Optional  that will refer to messages_de.properties: thenReturn de;q=0.9, fr-FR; q=0.8 en assertEquals  that will refer to messages_en.properties: messages getStringArray en-UK fr-FR ninjaProperties de,fr-FR;q=0.8 da;q=0.9, fr-FR; q=0.8 ",ninja,0
conn setRequestMethod IS_SECURITY_ENABLED /v0/admin/* assertTrue json content-type Collections runTest RestConstants java.version openConnection containsKey HttpServletResponse assertEquals parse getInputStream url JSONValue call getHeaderField testJavaSysProps GET getResponseCode createURL startsWith ,oozie,1
"var-app-name checkCoordJobs </dataset>  </configuration> includePath conf <action> file:///tmp/include_xml/workflows/${YEAR}/${DAY} end=""2009-02-03T23:59Z"" timezone=""UTC"" xmlns=""uri:oozie:coordinator:0.2""> <controls>  </input-events>  <app-path>hdfs:///tmp/workflows/</app-path>  datasetElements URI_TEMPLATE_INCLUDE_XML </datasets> <property> <name>inputB</name> <value>${coord:dataIn('inputB')}</value> </property>  assertNotNull file:// getTestCaseDir UNIT_TESTING processedJobXml </include> <dataset name=""B"" frequency=""${coord:days(7)}"" initial-instance=""2009-02-01T01:00Z"" timezone=""UTC""> </uri-template> getChild parseXml unchecked <execution>LIFO</execution> data-in URI_TEMPLATE_COORD_XML OozieClient jobId getChildren contains size getNamespace <workflow> -C  <input-events>  </workflow> <include>  </coordinator-app> </controls> job File <data-in name=""inputB"" dataset=""B""> <instance>${coord:latest(0)}</instance> </data-in>   <coordinator-app name=""${appName}-foo"" frequency=""${coord:days(1)}"" start=""2009-02-01T01:00Z""  assertFalse appPath substring include1.xml sc writeToFile appXml getJobXml uri-template <dataset> should not be duplicate </action> assertTrue get <uri-template> should not contain one from the include file includeXml coordinator.xml set XmlUtils <datasets>  appName length testDuplicateDatasetNameInIncludeFile <uri-template> assertEquals <configuration> file:///tmp/coord_xml/workflows/${YEAR}/${DAY} input-events call getChildText getTestUser namespace dataset ",oozie,1
"INodesInPath INode getPathComponents components resolve  Get the inodes by resolving the path of a normal file inodes sub1 dir , nodesInPath= assertSnapshot assertTrue nodesInPath testNonSnapshotPathINodes getPathNames file1=  The returned nodesInPath should be non-snapshot  when identifying the parent INode of a given path. assertEquals  The last INode should be associated with file1  The number of inodes should be equal to components.length  when identifying the INode for a given path. getFullPathName names fsdir toString file1 getINodes ",hadoop,1
" conn setRequestMethod IS_SECURITY_ENABLED id-valid put external-valid assertTrue array assertNotNull get name=x json content-type /v0/jobs  runTest(""/jobs"", BaseJobsServlet.class, IS_SECURITY_ENABLED, new Callable<Void>() { runTest JsonTags RestConstants openConnection testJobs MockDagEngineService HttpServletResponse assertEquals parse params getInputStream url JSONValue call 100 getHeaderField 2 assertNull size obj GET getResponseCode wfCount reset createURL external-invalid startsWith ",oozie,1
getJobTrackerUri map-reduce conf getStatus createContext getJob  hadoop.counters will always be set in case of MR action. output Counter getExecutionStats assertNotNull <map-reduce> context create write waitFor <job-tracker> group group.name ae counters parseXml </job-tracker> dummy  getFileSystem check <name-node>  Assert for stats info stored in the context. </name-node>  configuration. input contains WorkflowAction SUCCEEDED true getOozieActionExternalStatsWriteProperty submitAction getExternalChildIDs data.txt evaluate JobID launcherId  External Child IDs will always be null in case of MR action. assertFalse user.name getExternalId fs hasIdSwap createBaseHadoopConf actionXml isSuccessful assertTrue LauncherMapper  write property as true. get end testSetExecutionStats_when_user_has_specified_stats_write_TRUE close getData ACTION_TYPE getNameNodeUri outputDir launcherJob XmlUtils forName getAction assertEquals mrJob hadoop.counters inputDir getExternalStatus </map-reduce> Services createJobClient assertNull w toXmlString equals getVar toString jobClient user getFsTestCaseDir isComplete ,oozie,1
server ProxyUsers TestProtocol RPC configureSuperUserIPAddresses getProxySuperuserGroupConfKey getProxy aMethod GROUP_NAMES conf run retVal testRealUserGroupAuthorizationFailure Assert setStrings REAL_USER_SHORT_NAME stopProxy addr UserGroupInformation getServer ret proxyUserUgi printStackTrace e start group3 createRemoteUser getConnectAddress REAL_USER_NAME proxy fail doAs NetUtils stop ADDRESS PROXY_USER_NAME The RPC must have failed  realUserUgi createProxyUserForTesting ,hadoop,1
"server RPC newReflectiveBlockingService getProxy ping setProtocol conf echo  Set RPC engine to protobuf RPC engine setPort emptyRequest  client and server. Expected an exception to occur as version mismatch. testProtocolVersionMismatch EmptyRequestProto setProtocolEngine addr NewProtobufRpcProto  Get RPC server for server side implementation version mismatch setBindAddress CommonConfigurationKeys PORT e serverImpl  Verify that missing of optional field is still compatible in RPC call. start getMessage newProxy newBuilder setInt getConnectAddress proxy fail contains  Exception type is not what we expected, re-throw it. NetUtils build service ADDRESS  Create server side implementation setInstance ",hadoop,0
getConnectionContext getEventMessage errorCode conf parseDateUTC DateUtils getStatus wf-app-name1 caJobId1 caId1 CoordinatorAction 2012-07-22T00:00Z getStartTime MessageType 2011-07-11T00:00Z init printStackTrace wfEventListner getText fail contains createConsumer AppType testOnCoordinatorActionWaitingEvent startDate getParentId getAppType cae session assertFalse JMSMessagingUtils getEventStatus getUser EventStatus getId createSession getTopic onCoordinatorActionEvent missingDep1 jmsContext coordActionWaitingMessage consumer user1 getMessageType nominalTime receive getAppName e errorMessage getMessage assertEquals message getNominalTime endTime getMissingDependency Session ,oozie,1
 correctly krb5LoginModuleName foo getLoginModuleName System principal bar com.ibm.security.auth.module.Krb5LoginModule /some/location/foo.keytab Assert IBM get options foo/localhost com.sun.security.auth.module.Krb5LoginModule jConf useKeyTab refreshKrb5Config getControlFlag getProperty test storeKey keyTab false assertEquals entry contains entries AppConfigurationEntry assertNull java.vendor size true getOptions useTicketCache getAppConfigurationEntry ,hadoop,0
"play server request  fail auth three times...  ...then succeed the fourth time Successful auth! client connection assertContainsNoneMatching GET / HTTP/1.1 Authenticator readAscii addHeader getHeaders takeRequest Authorization: Basic .*  no authorization header for the first request... assertEquals Authorization: Basic  WWW-Authenticate: Basic realm=""protected area"" setResponseCode setBody setDefault getInputStream  ...but the three requests that follow requests include an authorization header assertContains / Integer authenticateWithGet enqueue getUrl getRequestLine Please authenticate. open RecordingAuthenticator pleaseAuthenticate ",okhttp,1
ROW_1 assertEquals TABLE getValueXML checkValueXML deleteRow testDelete COLUMN_2 COLUMN_1 response VALUE_1 putValueXML deleteValue getCode VALUE_2 ,hadoop,1
getKeyVersion cache mockKey  asserting no caching when key is not known getConf thenReturn k2@0 k1@0 assertEquals eq when Thread sleep times Assert testKeyVersion Mockito mock verify  asserting caching mockProv ,hadoop,0
conn setRequestMethod IS_SECURITY_ENABLED getId put bundleJobBean assertTrue get /v1/job/* content-type testBundleEngineGetBundleJob id Job runTest MockCoordinatorEngineService RestConstants openConnection addRecordToBundleJobTable HttpServletResponse assertEquals parse params getInputStream bundleJobId url JSONValue call getHeaderField xDataTestCase obj GET getResponseCode reset createURL startsWith ,oozie,1
init JMSTopicService set getConf not allowed in default getMessage destroy services setupServicesForTopic Expected Service Exception fail se contains invalidvalue assertTrue testIncorrectConfigurationDefault default= ,oozie,1
init getServletContext servletContext assertNotNull context testGetServletContext assertEquals httpServletRequest httpServletResponse  init the context from a (mocked) servlet o ,ninja,0
testMakeQualifiedPath qualifiedPath harPath harPathWithUserinfo har://file-user:passwd@localhost:80 toUri format conf getFileSystem String path The qualified path (%s) did not match the expected path (%s). assertTrue makeQualified equals getPath toString  can correctly preserve the information for the underlying file system. ,hadoop,0
 conn RestConstants bundle=BUNDLE-ABC openConnection /v1/jobs HttpServletResponse assertEquals params put url call 1 5 getResponseCode createURL testNoRecords bulkRequest  records found for this bundle runTest ,oozie,1
"request handler testCannotRenewTokenUsingToken assertFalse getMethod when tokenStr Assert verify  Try renew a token using itself, should get 401. op pwriter thenReturn & DelegationTokenAuthenticator getQueryString HttpServletResponse setStatus managementOperation Mockito response getWriter getToken mock reset getHttpMethod toString writer = ",hadoop,0
getTime coordActionGetCmd getId getStatus addRecordToCoordActionTable assertNotNull get CoordinatorAction action 0000001- -testCoordKill-C assertEquals Job doesn't exist. Should fail. execute testCoordKillFailed addRecordToCoordJobTable call CoordinatorJob Services coordJobGetCmd fail coord-action-get.xml testJobId job jpaService ,oozie,1
play handler incrementAndGet android  play it back headerEntries  verify the peer received what was expected TYPE_RST_STREAM cola acceptFrame stream getErrorCode TYPE_HEADERS peer receiveCount reply PROTOCOL_ERROR  SYN_REPLY takeFrame rstStream banana a receive b c openSocket intValue remoteDoubleSynStream assertEquals  RST_STREAM HeadersMode getRequestHeaders sendFrame build  write the mocking script synStream ,okhttp,1
encode  1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 1 1 1 0 1   1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1   1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1   1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1   1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1   0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0  <<  >>   1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0   ecLevel: H   0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0  put  1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0   1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0  EncodeHintType qrCode Encoder  0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0   1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0   1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 1 0   0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1   1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1   matrix:  hints  1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1  expected assertEquals  0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1   version: 1   maskPattern: 6  UTF8  mode: BYTE   1 1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1  testSimpleUTF8ECI toString  1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1   0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1  ErrorCorrectionLevel  1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0  ,zxing,0
theirs checkOnBytes UTF-8 update nextInt getBytes checkSame nextBytes hello world! ours testCorrectness randomBytes ,hadoop,0
encode putValuePB HConstants assertEquals checkValuePB testURLEncodedKey TABLE checkValueXML COLUMN_2 COLUMN_1 response encodedKey VALUE_1 putValueXML URLEncoder getCode VALUE_2 http://www.google.com/ ,hadoop,1
"00 reader FIRST_KEY  less than first key in the mapfile, that the first key is returned. cleanupWithLogger testGetClosestOnCurrentApi getClosest  If we were looking for the key before, we should get the last key 91 92 51 close value key TEST_PREFIX 55 LOG createReader testGetClosestOnCurrentApi.mapfile assertEquals  Assert that null is returned if key is > last entry in mapfile. Integer parseInt IOUtils createWriter assertNull t  Test keys: 11,21,31,...,91  Test get closest with step forward Not null key in testGetClosestWithNewCode  Test get closest when we pass explicit key explicitKey toString writer 61  Test get closest with step back append closest 21 ",hadoop,0
"fs1 reader fs1,fs2,dec3 LocalOozie conf getStatus getCause path getTestCaseDir /workflow.xml file:// getPath create workflow.xml waitFor rerun-wf.xml wfClient getFileSystem failed reRun OozieClient contains copyCharStream setProperty getResourceAsReader createConfiguration File evaluate p2 submit getJobInfo delete jobId1 assertTrue WorkflowJob nnbase  Skip executed nodes e toUri start getMessage assertEquals getClient testRerun IOUtils getTestUser toString  Skip a non-executed node writer ErrorCode getFsTestCaseDir base ",oozie,1
getAndAdvanceCurrentIndex isOne  1x0 1x1 IPC_CALLQUEUE_WRRMUX_WEIGHTS_KEY  1x0 3x1 2x2 conf test.custom. assertThat 1 mux 2 3 setStrings isZero test.custom testCustomPattern isEqualTo ,hadoop,0
testCachingOfFeatureState features?user=ck getPage getContent start System url duration contains assertTrue currentTimeMillis client page F1 = false  without cache: 500ms * 10 = 5000ms ,togglz,1
newGauge Unsupported add Average time for s1 run S1AvgTime addCounter get verify s1 test add info add test Number of ops for s1 addGauge g1 c1 rb expectMetricsException r newCounter mockMetricsRecordBuilder S1NumOps testAddByName snapshot ,hadoop,0
readFields set _testGet bean2 toByteArray dos testSerialization baos write close bean ,oozie,1
container /ping/* conn openConnection reader ping PingServlet start assertEquals readLine addServletEndpoint getInputStream url HttpURLConnection stop getServletURL assertTrue bla getResponseCode addFilter testEmbeddedServletContainer connect blah ,oozie,1
"hook2 hook1 timeouts  Test hook finish without timeout executeShutdown hook clearShutdownHooks assertNotNull  analyze the hooks mgr getHook TimeUnit hook4 hook3 Shutdown completed hook5 info INVOCATION_COUNT  a default timeout hook and verify it gets the default timeout LOG Was not invoked   hook4 was invoked first, but it timed out. sleeping hook4 blocked other threads for  Expected to complete  entry hook priority size  now execute the hook shutdown sequence shutdown hook list is not empty invoking executeShutdown() Expected to be invoked first  getShutdownHooksInOrder assertFalse  is the longest. addShutdownHook shutdownHookManager invocation difference too short  assertTrue get getTimeout  Test hook finish with timeout; highest priority Number of timed out hooks hooks getShutdownTimeout hook4timeout set hookEntry5 failed to remove  assertEquals SERVICE_SHUTDOWN_TIMEOUT_DEFAULT  did any hook raise an exception? No ShutdownHookManager Expected to time out   remove this to avoid a longer sleep in the test run maybeThrowAssertion hasShutdownHook invocationInterval  finally, clear the hooks getPriority removeShutdownHook  and verify that the hooks are empty default timeout not used ShutdownHookManager ",hadoop,0
getValue Assert Deadline 1969-12-31T17:00:01.000 MST assertEquals parse deadline testParse ,httpcore,0
 conn setRequestMethod /version assertTrue array get content-type runTest RestConstants openConnection testVersion HttpServletResponse assertEquals parse params getInputStream url JSONValue call OozieClient getHeaderField size GET getResponseCode createURL startsWith ,oozie,1
j testMask6 testMaskAcrossDimensions ,zxing,0
"Did not find 3rd occurrence of character 'l' Did not find 2nd occurrence of character 'l' testFindNthByte data Hello, world! UTF8ByteArrayUtils assertEquals 4th occurrence of character 'l' does not exist findNthByte getBytes ",hadoop,0
contains stdout assertTrue UTF8 Classpath toByteArray Prints the classpath testHelpShort strOut main -h stderr ,hadoop,0
add newValue testExtraConfig extraConfig set test.extra.config TraceUtils conf assertEquals wrapHadoopConf get old value new value oldValue wrapped key TEST_PREFIX ,hadoop,0
cluster createTable testTimestamps t TimestampTestBase doTestDelete  not pollute this latter?  Or put into separate tests. incommon doTestTimestampScanning flushcache ,hadoop,1
" /2009/01/01/ CoordELFunctions TZ action-actual-time="" DateUtils  Sleep for sometime as it gets requeued with 10ms delay on failure to acquire write lock ${coord:latestRange(-3,0)}  before and after action creation time parseDateOozieTZ Actual:  file:// getTestCaseDir CoordinatorAction action setCreatedTime indexOf /2009/01/22 /2009/01/08/ resolvedList execute setActionXml jobId contains testActionInputCheckLatestActionCreationTimeWithPushDependency CoordCommandUtils /2009/02/19/ job getMissingDependencies checkCoordAction Expected:  setPushMissingDependencies getTime getId 2009-02-16T23:59 </uris> /2009/02/05 replaceAll System substring actionXML sleep /2009/02/12/ <uris> assertTrue get createDir startTime  Update action creation time ""> latest 2009-02-15T23:59 action-actual-time=""2009-02-15T01:00 /2009/03/05/ /2009/01/22/  Run input check after making push dependencies available /2009/02/12 getConf action-actual-time="".*""> /2009/01/08 assertEquals -TestCoordActionInputCheckXCommand-C addRecordToCoordJobTable Thread  Datasets only before action creation/actual time should be picked up. call Services @1 pushMissingDependency getActionXml  Run input check after making latest available getPushMissingDependencies 0000000- endTime 2009-02-15T01:00 actionCreationTime jpaService setBoolean  Set push missing dependency ",oozie,1
mockRes init mockReq verifyZeroInteractions X_CUSTOM_HEADER  Object under test thenReturn BROWSER_AGENT  CSRF has not been sent  Objects to verify interactions based on request  Setup the configuration settings of the server testMissingHeaderWithCustomHeaderConfigBadRequest when filterConfig getHeader filter mockChain getInitParameter Mockito doFilter mock RestCsrfPreventionFilter ,hadoop,0
local path file accessTime2 readAttributes accessTime1 getFileStatus toMillis getConnectionPool Files lastAccessTime getMethodName  SFTPFileSystem doesn't have milliseconds. Excluding it. toLowerCase pathToFile touch getAccessTime assertEquals is assertThat sftpFs localFs toPath testGetAccessTime name getLiveConnCount ,hadoop,0
midKey  Write a mapfile of simple data: keys are reader conf assertEquals deprecation fs testMidKeyEmpty.mapfile getLocal FileSystem makeQualified qualifiedDirName testMidKeyEmpty toString writer close TEST_DIR  Now do getClosest on created mapfile. dirName ,hadoop,0
result jsonView testSetAndGetJsonView getJsonView assertEquals Result ,ninja,0
 and check if new umask is applied testSetUmaskInRealTime default permission is 777 assumeNotWindows conf dir not localfs Current umask is {} assertTrue finalPermission FileSystem get 755 getFileStatus 715 info With umask 062 we expect 715 since the default permission is 777 With umask 062 permission should not be 755 since the  set getPermission getConf CommonConfigurationKeys initialPermission dir2 assertEquals is 062 assertThat TEST_PATH_PREFIX 022 With umask 022 permission should be 755 since the default  cleanup getLocal mkdirs LOGGER permission is 777 ,hadoop,0
"be bee status=foo foo=moo assertEquals parseFilter  no eq sign in token:  incorrect ""status"" key value: fail xx=yy=zz winniethepooh BundleEngineException expected. getErrorCode  incorrect key=value pair syntax:  unknown key in key=value pair: ErrorCode testParseFilterNegative ",oozie,1
"mockRes init mockReq  Object under test thenReturn BROWSER_AGENT  CSRF has not been sent  Objects to verify interactions based on request  Setup the configuration settings of the server getMethod OPTIONS when filterConfig getHeader filter mockChain getInitParameter Mockito doFilter testMissingHeaderMultipleIgnoreMethodsConfigGoodRequest mock verify GET,OPTIONS RestCsrfPreventionFilter ",hadoop,0
"cluster parent  test chmod on DFS runCmd _Hdfs.User-10:_hadoop.users-- conf testFilePermissions :reptiles path  Test different characters in names testChmod FileSystem python: -chown /nonExistentFile /tmp hdfs/hadoop-core@apache.org:asf-projects python DFSConfigKeys /tmp/chownTest chmodTest  test chown and chgrp on DFS: /tmp/chmodTest hdfs.user getFileSystem / mammals shell herbivores numDataNodes hdfs/hadoop-core@apache.org true -chgrp shutdown -R reptiles fs _hadoop.users-- _Hdfs.User-10  For dfs, I am the super user and I can change owner of any file to      * anything. ""-R"" option is already tested by chmod test above.       file TEST_ROOT_DIR root /* hadoop writeFile set toys getAbsolutePath unknownFile setConf confirmOwner  test chmod on local fs build getLocal hadoop-core@apache.org/100 TestDFSShell unknownFile* asf-projects hadoop:toys ",hadoop,1
init _testGetForInfoAllActions destroy getId services CoordActionGetForInfoJPAExecutor addRecordToCoordJobTable resourceXmlName CoordinatorJob createCoordAction coord-action-get.xml slaXml setSystemProperty  Insert the action true CoordinatorAction setSlaXml action insertRecordCoordAction testCoordActionGetAllColumns job ,oozie,1
/a/b/*  test prefix matching ruleElementSelector assertEquals testPrefixMatch p /a /a/b /x/* /A/b /a/* /A/* /* getPrefixMatchLength ,logback,0
 current har block b getOffset  do some tests where start == 0 assertThat  case 4: range starts and ends in current har block  case 5: range starts before current har block and ends after  case 2: range starts in current har block and ends after  case 6: range starts in current har block and ends after fixBlockLocations  case 8: range starts and ends in current har block testFixBlockLocations HarFileSystem getLength isZero  test case from JIRA MAPREDUCE-1752  case 1: range starts before current har block and ends after isEqualTo  now try a range where start == 3 ,hadoop,0
setName A B getName getProperty C getProperties assertEquals System remove testcase tearDown testUnsetSysProperty assertNull setProperty setUp SYS_PROP testSysPropSetting testSetSysProperty ,oozie,1
init Assert assertTrue servletContext context testIsMultipart isMultipart httpServletRequest httpServletResponse ,ninja,0
unknown.domain. testResolverGetByNameQualifiedWithDomain verifyGetByName ,hadoop,0
host5 host4 host7 host6 host1 host3 somehost host2 assertFalse someotherhost Assert assertTrue equals SomeHost user testEquals ,httpcore,0
cluster RenewerUser GROUP_NAMES getUser run proxyUgi Assert ugi getIdentifier getUserName PROXY_USER UserGroupInformation identifier testDelegationTokenWithRealUser tokenId REAL_USER assertEquals getRealUser getFileSystem createRemoteUser token dfs readFields doAs getDelegationToken createProxyUserForTesting ,hadoop,1
getBytesTransferred payload2 getMetrics outbuffer inBuffer readableChannel testReadWriteFrame Assert assertNotNull FrameType get FrameConsts getFramesTransferred write getPayloadContent read frame2 getStreamId assertEquals ByteBuffer remaining getValue allocate getType bytes toByteArray getFlags wrap writableChannel frame ,httpcore,0
END_POINTS IS_SECURITY_ENABLED oozieUrl run testReRun appPath assertTrue get -config create workflow.xml SERVLET_CLASSES close runTest app createConfigFile RestConstants getContextURL MockDagEngineService assertEquals getFileSystem -rerun args call 1 -oozie mkdirs toString job getFsTestCaseDir ,oozie,1
cluster getFirstTxId  restart cluster conf run waitActive Assert In-progress log  Could not renew or cancel the token token1 getUserName token2 getFSImage  Saving image in safe mode should succeed token3 token4 token5 isInProgress  should only have START txn UserGroupInformation  restart cluster again  verify that the edits file is empty except for the START txn format cancelToken getFileSystem getNameNode validateLog fail namesystem testSaveNamespace numDataNodes getLastTxId  Saving image without safe mode should fail getStorage  Should be able to renew & cancel the delegation token after cluster restart shutdown nn renewToken log numTransactions admin fs findLatestEditsLog sd assertTrue getDelegationTokenSecretManager startThreads numDatanodes dirIterable close  should have 5 transactions e renewer getMessage assertEquals setSafeMode getLoginUser -saveNamespace args SafeModeAction build  verify that the edits file is NOT empty getDelegationToken FSImageTestUtil getNamesystem ,hadoop,1
allow-append was not set correctly ignore-error was not set correctly sink.source conf path The roll interval was not set correctly builder sink.roll-offset-interval-millis The source was not set correctly sink.basepath add init testInit src sink sink.ignore-error assertEquals 10m The roll offset interval was not set correctly 1 sink.roll-interval true The base path was not set correctly sink.allow-append subset ,hadoop,0
cluster dst Block size =  show conf f1 /test/zeroSizeFile f2 fs delete copyToLocalFile assertTrue getBlockSize TEST_ROOT_DIR  to remote  root getPath getFileStatus  create a zero size file close mkdir testZeroSizeFile isFile copy local  length assertEquals getFileSystem Not a HDFS:  dfs  getBlockSize() should not throw exception remotef build numDataNodes  copy to remote exists createNewFile getUri shutdown copyFromLocalFile  copy back ,hadoop,1
request http://somehost/stuff somehost assertEquals Method getMethod getAuthority Assert name getPath http /stuff testRequestWithAuthority getUri ,httpcore,0
CoordinatorJobBean jobConf bundleJobGetCmd log submitCmd getId getStatus isPending appPath Configuration parse error. read from DB : getJob sleep bundleActionsGetCmd assertNotNull get getAuthToken Job waitFor coordGetCmd1 set coordGetCmd2 getConf job2 job1 addRecordToBundleJobTable assertEquals getCoordId execute bundle.xml call Services warn OozieClient size equals testBundleKill2 toString ErrorCode job jpaService actions evaluate ioe ,oozie,1
p1 p2 Should fail testClientRetriesIfMaxAttemptsNotSet getKMSUrl kp e anyString thenReturn createKey conf eq any when fail times test3 Mockito mock verify thenThrow ,hadoop,0
 get the switch map and examine it mapping n1 addNodeToRack resolve switchMap LOG topology dumpTopology testAddResolveNodes getSwitchMap newInstance assertEquals /r1 queryList StaticMapping size get NetworkTopology createQueryList resolved info ,hadoop,0
file testCRCwithCreate7 create/7 TEST_ROOT_DIR fileSys assertWritesCRC getFileDefault create FsPermission writeData ,hadoop,0
 testExpressionNotEmptyBlank2 notBlank Asserts Stuff ,httpcore,0
cluster address testFileSystemCloseAll conf closeAll getTestConfiguration getDefaultUri build setDefaultUri numDataNodes FileSystem get shutdown ,hadoop,1
 testFile01 getPathData processPathDirOrderMtime testfile01 getTime addContents ls formatLineMtime out testfile03 options computeLineFormat inOrder testfile02 processOptions verify testfile05 testFile06 setMtime testfile04 testFile04 testFile05 testfile06 testFile02 testFile03  set file mtime in different order to file names add Found 6 items pathData lineFormat -t setIsDir processArguments testDir testDirectory verifyNoMoreInteractions  convention NOW TestFile mock ,hadoop,0
setupCompareFs testCompareFsDirectories fs2 fs1 fs4 fs3 fs6 compareFs fs5 assertEquals FileUtil ,hadoop,0
parent init Incorrect number of services testAddUninitedSiblingInStop assertInState start STATE assertEquals sibling stop size addService getServices ,hadoop,0
VV Configuration regular Key not found conf addDeprecation nK1Found assertTrue V get VVV nK2Found testIteratorWithDeprecatedKeysMappedToMultipleNewKeys getKey dKFound new Key 2 not found set dK assertEquals deprecated Key not found k entry getValue kFound nK2 nK1 v equals new Key 1 not found ,hadoop,0
testGetJobs submitJob reader end.error conf error jobId2 jobId1 engine getTestCaseDir /workflow.xml file:// workflow.xml OK ok a external-status set wf-ext-schema-valid.xml OozieClient IOUtils getTestUser t signal-value copyCharStream getResourceAsReader writer File ,oozie,1
00 reader conf  write the file fs delete cleanupWithLogger System assertTrue FileSystem value close False positives:  TEST_DIR key  check false positives rate set LOG assertEquals deprecation falseNeg setInt False negatives:  testMembershipTest io.mapfile.bloom.size IOUtils falsePos getLocal makeQualified qualifiedDirName exists toString writer probablyHasKey append ,hadoop,0
readValue getServerAddress ninjaTestBrowser assertEquals api/person.xml System testPostPersonXml result j:  person response postXml zeeess name - and some utf8 => Ã¶Ã¤Ã¼ ,ninja,1
BB A prop;  Ignoring. loggingEvent getLog logger declareProperty  Make a configuration file with 2 final properties with different values conf testFinalWarningsMultipleOverride Logger getRenderedMessage getBytes out removeAppender  Make sure the appender is removed addAppender did not see expected string inside message  assertTrue addResource prop get overriding a final parameter should cause logging getRootLogger events  Add the resource - this should produce a warning endConfig  Attach our own log appender so we can verify output startConfig appender assertEquals in1 contains should see the value size bytes an attempt to override final parameter:  toString writer renderedMessage ,hadoop,0
classArgArgumentExtractor customArgumentExtractorWithClassArgShouldBeInstantiated context create verify invoke java.lang.String mockController ,ninja,0
server callStarted conf run when mockFactory sleep doAnswer MIN_SLEEP_TIME createSocketCalled get client addr waitFor set RANDOM start GenericTestUtils  Track how many times we retried to set up the connection assertEquals nextLong getConnectAddress Thread call NetUtils createSocket  stop() should stop the client immediately without any more retries answer stop Mockito  Start server mock addAndGet fake  Call a random function asynchronously so that we can call stop() testSetupConnectionShouldNotBlockShutdown ,hadoop,0
URIAuthority Assert somehost:1234 user@somehost somehost somehost:8080 create SomeHost:8080 assertEquals testCreateFromString user ,httpcore,0
server Server conf run getClassLoader setCallIdAndRetryCount TestInvocationHandler  10000 times runs about 6s on a core i7 machine Proxy Assert testRetryProxy RetryPolicies client getCallRetryCount create Client dummyRun retryCount newProxyInstance start assertEquals RetryProxy proxy totalRetry stop retryProxy ,hadoop,1
ContentType listener CoreMatchers setExceptionCallback getCause AsyncServerBootstrap listen instanceOf IOReactorConfig Assert getDuration create https /stuff setLookupRegistry requester localhost setStreamListener LoggingExceptionCallback LoggingHttp1StreamListener setIOSessionListener resultFuture1 * setSoTimeout Method assertThat execute LoggingConnPoolListener fail ex SecureAllPortsStrategy TIMEOUT server setIOReactorConfig createClientSSLContext cause testSSLDisabledByDefault bootstrap H2RequesterBootstrap setConnPoolListener setTlsStrategy some stuff setIOSessionDecorator SSLv3 createServerSSLContext get ExecutionException expected getAddress SSLTestContexts address custom start sslEngine setEnabledProtocols target getTimeUnit LoggingIOSessionDecorator getPort build future LoggingIOSessionListener initialize register ,httpcore,0
random rand1 rand2 nextDouble testRandomDouble ,hadoop,0
verifyZeroInteractions  Object under test EXPECTED_MESSAGE BROWSER_AGENT sendError when filterConfig getHeader atLeastOnce mockChain doFilter verify mockRes init mockReq thenReturn  CSRF has not been sent  Objects to verify interactions based on request HttpServletResponse  Setup the configuration settings of the server filter testNoHeaderDefaultConfigBadRequest getInitParameter Mockito mock RestCsrfPreventionFilter ,hadoop,0
    * Java 8 Examples go below this line.     intercept assertNotNull expected assertExceptionContains testInterceptFailure ioe ,hadoop,0
 Construct prepare XML block with the path  Parse the XML to get the node </prepare> doOperations <delete path=' Expected to catch an exception but did not encounter any Expected a LauncherException but received an Exception conf substring Scheme hftp not supported in uri  getDocumentFromXML createJobConf path trim LauncherMapper <prepare> '/>  Test for invalid scheme value in the path for action getNamedItem testForInvalidScheme item getAttributes hftp:/ actionDir getDocumentElement getMessage assertEquals  Construct a path with invalid scheme n getNodeValue /delete fail newDir prepareXML doc le toString PrepareActionsDriver setupLauncherURIHandlerConf getFsTestCaseDir getChildNodes ,oozie,1
"DagELFunctions dropDatabase def year,month,dt,country conf createEvaluator ${hcat:exists(wf:conf('partition2'))} protoConf getTestCaseDir ${hcat:exists(wf:conf('partition1'))} setId action setUser group testHCatExists workflow test.dir , createDatabase OozieClient setGroup eval name actionId job evaluate getHCatURI actionName setName createTable dt=05 addNode writeXml addPartition getId appPath setAppPath baos year=2012;month=12;dt=02;country=us wf table1 configureEvaluator get dt=02 <workflow-app/> end hadoop.job.ugi dropTable setProtoActionConf setWorkflowInstance partition2 setAppName set assertEquals partition1 Services db1 getTestUser toString wfId ",oozie,1
next submit values getReport No of attempts is not correct waitForState getAttempts getTaskAttemptState  blocked iterator Assert JobState getTaskState latch countDown tasks  wait and vailidate for Job to become RUNNING attempts app JobEventType getEventHandler  send the kill signal to Job testKillJob getID handle assertEquals it Attempt state not correct  unblock Task task Task state not correct size TaskAttemptState  wait and validate for Job to be KILLED getTasks job No of tasks is not correct getContext TaskState ,hadoop,1
"getJobTrackerUri getName  sharelib path because it doesn't have a scheme or authority conf createContext  Set sharelib to a full path (i.e. include scheme and authority) context <job-tracker> eActionXml init ae [No FileSystem for scheme: foo] java-action-executor parseXml </job-tracker> destroy <name-node> <main-class> /user/ </name-node>  from the obviously invalid appPath) contains getOozieUser aee <java> getAppPath appPath createBaseHadoopConf getDefaultShareLibName actionXml getErrorCode assertTrue get  invalid, and not the sharelib path because it doesn't have a scheme or authority foo://bar:1234/blah getNameNodeUri </java> XmlUtils  Set sharelib to a relative path (i.e. no scheme nor authority) WorkflowAppService testAddShareLibSchemeAndAuthority </main-class> getMessage assertEquals Services E0902 /share/ setSystemProperty addShareLib ",oozie,1
handlerRegistry resolve /tes?test=a /test?test=a assertEquals Method /test* testByRequestUriWithQuery Assert context assertNotEquals stuff register ,httpcore,0
"cluster  normal write getClass getName getFilenum getLog Need HDFS-826 for this test HConstants conf invoke dnprop writeData oldFilenum waitActive tableName getRegionServer getDefaultReplication  When the META table can be opened, the region servers are running Need append support for this test  write some more log data (this should use a new hdfs_out) startDataNodes getDataNodes stm testLogRollOnDatanodeDeath setAutoFlush curTime size getPipeline addFamily The log shouldn't have rolled yet newFilenum  add up the datanode count, to ensure proper replication when we kill 1 endsWith desc server createTable log dfsCluster This test requires HLog file replication. admin Missing datanode should've triggered a log roll fs System getDeclaredMethods  this write should succeed, but trigger a log roll assertTrue canGetCurReplicas Log should have a timestamp older than now getLogReplication repl table stopDataNode  don't run this test without append support (HDFS-200 & HDFS-142) setAccessible The log should not roll again.  kill a datanode in the pipeline to force a log roll on the next sync() m pipeline  Create the test table and open it isAppend currentTimeMillis Need DFSOutputStream.getPipeline() for this test getOutputStream New log file should have the default replication HLog ",hadoop,1
"JsonTags actionStatus=FAILED,KILLED;startcreatedtime=2012-07-21T00:00Z /v1/jobs ;coordinators=Coord1; assertEquals jaction1 jaction2 testMultipleRecords call size FAILED array assertNotNull get bundleName _requestToServer bulkRequest bundle= KILLED runTest jbundle ",oozie,1
getBooleanWithDefault thenReturn NinjaConstant invoke when param1 integerParamStrictModeWorks context create integerParam ninjaProperties mockController getParameter ,ninja,0
testCloseExpired getStats release closeExpired sleep Assert updateExpiry assertTrue stats assertNotNull get of TimeUnit verify close entry2 TimeValue getLeased conn2 entry1 conn1 assignConnection ArgumentMatchers somehost pool assertEquals totals isDone any Thread never future1 future2 Mockito CloseMode mock lease getPending getTotalStats getAvailable ,httpcore,0
"init  -ve test CoordELFunctions testdataInPartitionFilterPh1 setVariable  +ve test assertEquals ${coord:dataInPartitionFilter('ABC', 'pig')} oozie.dataname.ABCD data-in coord-job-submit-data fail eval evalAndWrap ${coord:dataInPartitionFilter('ABCD')} should throw exception because dataInPartitionFilter() requires 2 parameters expr oozie.dataname.ABC ",oozie,1
getRestartCount Conditions timeout sleep waitOrTimeout interrupt  wait until restart count is 1 verify getAccumulatedTriggerCount restart Timeout start  thread needs to be waiting after start assertEquals setSettleDownMillis trigger restartTrigger Thread  thread needs to be waiting after restart  wait until accumulated trigger is set back to zero  should have only called this exactly once machine  long settling down period to ensure it'll happen mock isWaiting  call restart quickly in a row isSatisfied atLeast millis shutdown settleTimeMillis ,ninja,0
server  Check for timeout status and unregistered missing dependencies timeOutCreationTime checkCoordAction CoordELFunctions  timeout. /nodb/notable/dt=20120430;country=usa assertFalse addInitRecords getWaitingActions System sleep assertTrue get CoordinatorAction testTimeOutWithException1 newHCatDependency setCoordActionCreationTime newHCatDependency2 newHCatDependency1 e hcatService hcat:// getMessage pdms isRegisteredForNotification Thread call fail Services contains  Test timeout when missing dependencies are from a non existing table assertNull currentTimeMillis actionId NoSuchObjectException /nodb/notable/dt=20120430;country=brazil ,oozie,1
testJobsStatus END_POINTS IS_SECURITY_ENABLED -jobtype oozieUrl run -localtime coord name=x SERVLET_CLASSES -len runTest -timezone RestConstants getContextURL -filter jobs MockDagEngineService assertEquals -offset args PST call 2 3 -oozie status=FAILED ,oozie,1
argument makeGraphite MsInfo graphite result putMetrics record host forClass verify foo1 foo2 null.all.Context.Context=all.Hostname=host.foo1 1.25 10  write mockGraphite all add null.all.Context.Context=all.Hostname=host.foo2 2.25 10  ArgumentCaptor printStackTrace e sink capture assertEquals tags makeMetric Whitebox getValue testPutMetrics equals metrics setInternalState ,hadoop,0
EXIT_EXCEPTION_THROWN testThrowable java.lang.OutOfMemoryError ARG_THROWABLE assertLaunchOutcome NAME ,hadoop,0
"conn LOG assertFalse isEmpty getConnectionWithSSLSocketFactory excludedCipher list is empty No Ciphers in common, SSLHandshake must fail. url readFromConnection fail baseUrl ex SERVLET_PATH_ECHO testExcludedCiphers EXCLUDED_CIPHERS ?a=b&c=d No Ciphers in common, expected successful test result. info ",hadoop,0
Context getClass getResource css testFolder test expected expectedFolder getFile getConfig url testFromFolder setIgnoreMissingResources get WroTestUtils compareFromDifferentFoldersByExtension cssImport victim ,wroj4,1
cluster writeXml conf /testWriteConf.xml fs Setting conf in:  System identityHashCode foobar create close testWriteConf DFSConfigKeys set os filePath longString getFileSystem setInt  500KB IOUtils build cleanup numDataNodes toString shutdown append ,hadoop,1
request HttpHeaders addHeader process getFirstHeader testRequestUserAgentNotGenerated interceptor assertEquals Method getEntity whatever / getValue Assert assertNotNull context some agent header ,httpcore,0
bufentity StandardCharsets assertFalse getContent assertEquals getContentLength getBytes testWrappingEntity isRepeatable httpentity Assert  test if we can obtain contain multiple times isChunked assertTrue isStreaming bytes assertNotNull Message content ,httpcore,0
key1 key2 value2 value1 key3 keys value3 values compareTo bValue inMap getBytes put assertTrue get lastKey keySet key  This will work because we know what we put into each set getKey a b maps e entrySet map2 containsKey map1 copyOfMapOfMaps unchecked assertEquals testSortedMapWritable getValue size mapOfMaps firstKey  Now for something a little harder... outMap aValue ,hadoop,0
kills a b addNode def f enters start j assertEquals testKillWithRunningNodes WorkflowInstance getStatus kill asList wf 1 exits size <worklfow-app/> end Arrays job fails ,oozie,1
 a l1 l2 start assertEquals sb Thread sleep a:1-L a:1-U a:2-L a:2-U trim testReadWriteLock finish toString ,oozie,1
getName getStatus SubWorkflowActionExecutor protoConf createBaseWorkflow getWorkflowClient create action </app-path> setId workflow.xml write getBaseProtoConf waitFor workflow getFileSystem check       </configuration> WorkflowAction File evaluate getParentId setName       <app-path>       <configuration> getJobInfo           <name>a</name>         </property> getActions getId getExternalId fs APP1           <value>A</value> W get end extId WorkflowJob close <sub-workflow xmlns='uri:oozie:workflow:0.1'> oozieClient         <property> start subWorkflowAppPath subWorkflow assertEquals JOB_TIMEOUT setConf       <app-path>wrongAppPath</app-path> </sub-workflow> writer action1 testSubWorkflowRecovery getFsTestCaseDir ,oozie,1
conn inStream assertFalse getContent assertEquals createIncomingEntity message getContentLength content ContentLengthStrategy Assert isChunked Mockito assertTrue assertNotNull mock testCreateEntityInputUndefined OK entity ,httpcore,0
testPartialFrameWrite assertFalse isEmpty outbuffer ByteBuffer assertArrayEquals FrameFlag getValue Assert flush FrameType toByteArray FrameConsts wrap write writableChannel frame ,httpcore,0
_testTransient testEndTransient assertTrue end.transient end WorkflowActionBean ,oozie,1
_testUpdateWF after _testGetActions() _testGetWF _testGetStatusCount _testInsertWF  _testGetWFInfos(); _testGetPendingActions after _testPendingAction() after _testWFInfo() _testPurge System _testGetActionForWFFailure _testGetWFIDWithExtID _testGetActionsForWF after _testGetActionForWFFailure() testDBWorkflowStore _testLoadAction _testSaveAction _testDeleteAction  _testWaitWriteLock(); _testUpdateAction after _testGetWFInfos() _testGetWFInfo ,oozie,1
" ullamcorper metus quis diam cursus facilisis. Sed mollis quam id justo rutrum  laoreet rutrum est, nec convallis mauris condimentum sit amet. Phasellus gravida,  diam, lobortis eu tristique ac, p. In ut magna vel mauris malesuada dictum. Nulla testEncodeDecode  Phasellus gravida, justo et congue auctor, nisi ipsum viverra erat, eget hendrerit testEncodeDecode23  erat pulvinar nisi, id elementum sapien dolor et diam. In ut magna vel mauris malesuada dictum. Nulla ullamcorper metus quis diam  felis turpis nec lorem. Nulla ultrices, elit pellentesque aliquet laoreet, justo  est, nec convallis mauris condimentum sit amet. Phasellus gravida, justo et congue  cursus facilisis. Sed mollis quam id justo rutrum sagittis. Donec laoreet rutrum  ultrices, elit pellentesque aliquet laoreet, justo erat pulvinar nisi, id  Sed ornare luctus ornare. Vestibulum vehicula, massa at pharetra fringilla, risus  tristique ac, p.In ut magna vel mauris malesuada dictum. Nulla ullamcorper metus  justo et congue auctor, nisi ipsum viverra erat, eget hendrerit felis turpis nec  sagittis. Donec laoreet rutrum est, nec convallis mauris condimentum sit amet.  fringilla, risus justo faucibus erat, nec porttitor nibh tellus sed est. Ut justo  justo faucibus erat, nec porttitor nibh tellus sed est. Ut justo diam, lobortis eu  nisi, id elementum sapien dolor et diam. Donec ac nunc sodales elit placerat  eleifend. Sed ornare luctus ornare. Vestibulum vehicula, massa at pharetra  elementum sapien dolor et diam. Donec ac nunc sodales elit placerat eleifend.  quis diam cursus facilisis. Sed mollis quam id justo rutrum sagittis. Donec  auctor, nisi ipsum viverra erat, eget hendrerit felis turpis nec lorem. Nulla  lorem. Nulla ultrices, elit pellentesque aliquet laoreet, justo erat pulvinar ",zxing,0
getValue getName Assert param name assertEquals testConstructor value ,httpcore,0
add a b % \%\(\t\)\r\n \% ) Token assertEquals %x\_a tokenize witness testEscape %x\) tl \\%x %x\_%b %(	)  \ ,logback,0
Unknown property:  getChangedProperties getStatus when dummy reconfigurePropertyImpl Lists NEW3 add new3 new2 getKey new1 entrySet anyString OLD3 conf1 eq waitAsyncReconfigureTaskFinish assertThat fail doThrow name3 size name2 spy name1 status assertFalse changes containsString isPresent result Property name2 is not reconfigurable io exception getReconfigurationTaskStatus get old3 old1 old2 NAME3 newArrayList isPropertyReconfigurable doReturn change assertEquals testAsyncReconfigure any getValue equals startReconfigurationTask ,hadoop,0
callable2 callable3 callables other callable1 callable6 callable4 Callable C executed : callable5 Math queueservice asList System Callable callableOther executed : assertTrue get testConcurrencyReachedAndChooseNextEligible waitFor CLCallable init c queueSize XTestCase last callableOther max CallableQueueService destroy originalRatio Services setSystemProperty true Long resetConcurrency Callable Queue Size : Arrays evaluate queue ,oozie,1
testMatLookupCommand1 checkCoordJobs 2009-02-01T01:00Z getId DateUtils parseDateOozieTZ addRecordToCoordJobTable call CoordinatorJob 2009-02-03T23:59Z startTime endTime job ,oozie,1
custom-key src StandardCharsets testPlainStringDecoding createByteBuffer hasRemaining assertFalse length assertEquals Decoding completed Assert array decodePlainString buffer HPackDecoder ,httpcore,0
data CommonConfigurationKeys valueOf conf String testDUGetUsedWillNotReturnNegative duSize du setLong file assertTrue getUsed Long DU_DIR createNewFile incDfsUsed ,hadoop,0
END_POINTS RestConstants IS_SECURITY_ENABLED getContextURL oozieUrl MockDagEngineService run assertEquals args call 1 -oozie size job testSuspend SERVLET_CLASSES -suspend runTest ,oozie,1
testParseUTF8String testParseUTF8Ampersand2String ,httpcore,0
init as getTestUser assertNotNull get addRecordToBundleJobTable getId services Job job testAuthorizationServiceForBundle authorizeForJob ,oozie,1
"validateAndParse conf wf-invalid-fork.xml  oozie level default, wf level disabled  oozie level enabled, wf level enabled oozie.wf.validate.ForkJoin  oozie level enabled, wf level default getErrorCode get  oozie level enabled, wf level disabled  oozie level disabled, wf level default  oozie level disabled, wf level disabled init set false getMessage destroy assertEquals oozie.validate.ForkJoin  oozie level disabled, wf level enabled testDisableWFValidateForkJoin Services IOUtils parser E0730: Fork/Join not in pair wfe setSystemProperty getResourceAsReader true  oozie level default, wf level enabled ErrorCode  oozie level default, wf level default ",oozie,1
testHardLeaseRecoveryAfterNameNodeRestart hardLeaseRecoveryRestartHelper ,hadoop,1
"getJobTrackerUri getName <java> conf createContext appPath setupActionConf createBaseHadoopConf actionXml Scheme [localfs] not supported assertTrue get context hdfs,viewfs <job-tracker> testFilesystemScheme getNameNodeUri localfs://namenode:port/mydir eActionXml init ae </java> XmlUtils </main-class> parseXml getMessage </job-tracker> destroy HadoopAccessorService <name-node> <main-class> Supposed to throw exception due to unsupported fs scheme - localfs </name-node> E0904 Services fail contains setSystemProperty ",oozie,1
/*/* Pattern assertEquals USER_DIR prepareTesting path testPathFilter /a /a/b quote files matchedPath ^.* cleanupDFS ,hadoop,1
" advance clock tester assertEquals 1234567,2345678,3456789,4567890  advance SysInfoWindows  verify information has not been refreshed  test with 12 cores getAvailablePhysicalMemorySize 17177038848,8589467648,15232745472,6400417792,12,2805000,6261812, setSysinfoString getNumVCoresUsed  verify information has been refreshed 17177038848,8589467648,15232745472,5400417792,12,2805000,6263012, getCpuUsagePercentage refreshAndCpuUsageMulticore ",hadoop,0
" Wait for the async task to finish test SyncGenerationPolicy k1 assertEquals getNext  Trigger a prefill (5) and an async refill (6)  the prefill to the low watermark, 1 consumed by getNext()) waitForRefill Assert  Wait a while to make sure that no async refills are triggered getTop filler vq  Take another value, queue is still above the watermark testNoRefill shutdown ",hadoop,0
getConnectionContext getEventMessage wfSuccMessage endDate session JMSMessagingUtils getEventStatus getUser EventStatus conf getId parseDateUTC DateUtils getStatus createSession getTopic wf-app-name1 getEndTime caId1 2012-07-22T00:00Z wfId1 getStartTime WorkflowJob jmsContext consumer MessageType user1 getMessageType init receive getAppName printStackTrace e getMessage destroy assertEquals message wfEventListener fail onWorkflowJobEvent wfe createConsumer testOnWorkflowJobSuccessEvent AppType startDate getParentId Session getAppType ,oozie,1
readValue getServerAddress ninjaTestBrowser assertEquals System testPostPersonJson result j:  postJson person response zeeess name - and some utf8 => Ã¶Ã¤Ã¼ api/person.json ,ninja,1
"       <name>a</name>    <job-tracker>foo</job-tracker>  expectedE   <param>x</param>  testParserGlobalLocalAlreadyExists validateAndParse   </prepare>      </property>  replaceAll </pig>   <configuration>  wf-schema-valid-global.xml   </configuration>  app     <file>/tmp</file>      <mkdir path=""/tmp"" />        <value>A2</value>  getConf e <pig xmlns=""uri:oozie:workflow:0.4"">    <prepare>        <name>b</name>  assertEquals       <value>B</value>  IOUtils   <script>/tmp</script>  parser getResourceAsReader     <property>  getNode     <delete path=""/tmp"" />    <name-node>bar</name-node>  ",oozie,1
 integer=x testParamTypes MyJsonRestServlet integer=1 string=a HttpServletResponse invoke assertEquals call boolean=x GET boolean=true boolean=false runTest ,oozie,1
testReconstruction initialCount res TABLE_NAME createTable newCount toBytes loadTable scan count assertEquals TEST_UTIL FAMILY Bytes createMultiRegions  Load up the table with simple rows and count them family getScanner expireRegionServerSession results close table ,hadoop,1
Coord Action event WAITING Coord Action event SUCCESS _testEventHandlerService           * Coordinator Action events           run myapp parentid output jobid Coord Action event STARTED assertTrue testEventListener queueEvent CoordinatorAction WorkflowJob event event2 Workflow Job event SUCCESS Workflow Job event FAILURE Workflow Job event STARTED Coord Action event SUSPEND           * Workflow Job events           setStatus ehs Workflow Job event SUSPEND contains setLength getTestUser toString Coord Action event FAILURE ,oozie,1
"cluster parent  4: count -q /test  15a: clear quota on a file getCurrentUser  try setting space quota with a 'binary prefix'  14b: set quota on a file  check disk space consumed  create a file that is greater than the size of space quota conf String  need final ref for doAs block createFile  9: clear quota /test/data0  6: create a directory /test/data1 ugi childFile0 fout childFile1 childFile2 childFile3 childFile4 write childFile5 UserGroupInformation userxx testQuotaCommands in getFileSystem / dfs 0 1 doAs 3 childDir0  clear space quota mkdirs  HADOOP-5872 - we can set quota even if it is immediately violated  18: clrQuota by a non-administrator hasException  19: clrQuota on the root directory (""/"") should fail  2: create directory /test/data0 Not running as new user  16a: set the quota of /test to be 0  2: create directory /test/data2 33aa1.5  8: clear quota /test  delete the file assertTrue getFileCount 1g spaceQuota getSpaceConsumed close DEFAULT_BLOCK_SIZE replication DFSTestUtil c 1t isFile data2 data1 data0 assertEquals m  1: create a directory /test and set its quota to be 3 IOUtils datafile3 exists args2 datafile2 toString args3  9.s: clear diskspace quota fileLen2 datafile1 setBoolean datafile0  16c: set the quota of /test to be Long.MAX_VALUE+1 2t  17:  setQuota by a non-administrator getSpaceQuota nonExistentPath run  16d: set the quota of /test to be a non integer /test -clrQuota  14a: set quota on a non-existent directory  16b: set the quota of /test to be -1 create  now test the same for root -clrSpaceQuota  now set space quota again. This should succeed  set diskspace quota to 10000 createUserForTesting groupyy  20: setQuota on the root directory (""/"") should succeed DFSConfigKeys  16e: set space quota with a value larger than Long.MAX_VALUE -1 getDirectoryCount setLong  15b: clear quota on a non-existent directory numDataNodes  now creating childFile1 should succeed -setSpaceQuota Long getUri shutdown  set space quota to a real low value -setQuota  10.s: but writing fileLen bytes should result in an quota exception 1000000  12: set the quota of /test/data0 to be 1  5: count -q /test/data0 assertFalse admin  7: create a file /test/datafile1 userAdmin childDir1 fs delete childDir2 getQuota  same for space quota /test1 closeStream runCommand getShortUserName valueOf  10: create a file /test/datafile1 getContentSummary Not a HDFS:  fileLen args Integer 100 dfs.support.append spaceQuota2 build  3: create a file /test/datafile0  for space quota  13: not able create a directory under data0 clone  Space quotas username ",hadoop,1
noOfMillisecondsinOneHour lenientDate bad  Testing for the number of coordinator actions in a date range that spans from half an hour prior to the nominal time to 1 hour after the nominal time getCoordActionIdsFromDates  Test a bad scope.  Like date2 but with the 50th day of the month DateUtils addRecordToCoordActionTable noOfActions [^-]*T CoordinatorAction badDate 50T badScope CoordActionsInDateRange Accepted bad range scope:  actionNum printStackTrace fail CoordinatorJob actionId1 testCoordActionsInDateRange size nominalTimeMilliseconds formatDateOozieTZ  Pass job  Test inverted start and end dates. Accepted lenient date:  ::  Test a lenient date getTime Accepted inverted dates: [Start::End] =  getId replaceAll Accepted badly formatted date:  getErrorCode 0xbad5c09e  Testing for the number of coordinator actions in a date range that spans from half an hour after the nominal time to 1 hour after the nominal time nominalTime e  Test a bad date format. assertEquals date2 getNominalTime date1 addRecordToCoordJobTable coord-action-get.xml toString ErrorCode ,oozie,1
setNinjaProperties testThatSettingNinjaPropertiesTwiceDoesNotWork NinjaMode equalTo ninjaServletListener ninjaProperties assertThat  first setting works  setting the properties a second time does not work... gotException ,ninja,0
doAnEdit  Make sure runtime.exit(...) hasn't been called at all yet.  have halted the NN.  Invalidate both edits journals. assertTrue assertExitInvocations testAllEditsDirsFailOnFlush invalidateEditsDirAtIndex ,hadoop,1
date scriptExecutor session  Given simple SELECT * FROM simple WHERE id =  crud  When of id table should_delete_by_id executeScriptTemplate all RandomUtils manager isEmpty nextLong rows assertThat execute SimpleEntity/insert_single_row.cql ImmutableMap  Then Long deleteById buildDateKey ,achilles,1
addRecordToBundleActionTable addRecordToWfActionTable coordActionGetCmd getNumDaysToNotBePurged testPurgeBundleWithCoordChildWithWFChildWithSubWF1 DateUtils WorkflowInstance getStatus addRecordToCoordActionTable parseDateOozieTZ SubWorkflow Job should not have been purged bundleJob BundleJobBean assertNotNull CoordinatorAction Job wfAction wfJobGetCmd Bundle Action should not have been purged execute subwfActionGetCmd Bundle Job should not have been purged CoordinatorJob 1 coordJobGetCmd fail WorkflowAction coordAction SUCCEEDED Workflow Action should not have been purged subwfJobGetCmd bundleJobGetCmd getId coordJob SubWorkflow Action should not have been purged wfJob addRecordToWfJobTable get Workflow Job should not have been purged WorkflowJob subwfAction getAppName bundleAction wfActionGetCmd Coordinator Action should not have been purged 2011-01-01T01:00Z addRecordToBundleJobTable assertEquals getLastModifiedTime addRecordToCoordJobTable Coordinator Job should not have been purged call Services coord-action-get.xml subwfJob jpaService bundleActionGetCmd ,oozie,1
createUserForTesting  test without setting a default MachineList IP_RANGE set  test with a default MachineList drwho refresh conf drwho@EXAMPLE.COM group2 group1 security.service.authorization.default.hosts serviceAuthorizationManager fail testDefaultMachineList UNAUTHORIZED_IP getByName InetAddress authorize 10.222.0.0 UserGroupInformation ,hadoop,0
testSetBulk array assertTrue get assertFalse setBulk ,zxing,0
isAvailable createJettyConfiguration /mycontext/request_path containsString jettyConfigurationWithContext  is the port correct (otherwise logging will be wrong) /mycontext/context_path  port won't be correct b/c actually configured via jetty file nullValue not http://localhost: /mycontext/home conf/jetty.com.example.conf get RANDOM_PORT Hello World! externalConfigurationPath contextPath standalone start is isStarted assertThat jettyConfiguration /mycontext getPort jetty.xml  random port and then write the file back out page  requestPath removes contextPath shutdown /request_path ,ninja,0
cluster sub runCmd getLocalizedMessage  destination files conf run f1 f2 fs f3 delete System f4 f5 copyToLocal2 f6 Exception raised from DFSShell.run  -copyToLocal assertTrue TEST_ROOT_DIR root close isFile e createTree * assertEquals getFileSystem setConf Not a HDFS:  dfs nosuchfile args build shell numDataNodes  Verify copying the tree testCopyToLocal Copying failed. exists localroot copyToLocal localroot2 getUri shutdown isDirectory ,hadoop,1
" Write some more data and flush cluster initBuffer  still have interrupted status. assertFalse Got expected exception during flush conf /hflush-interrupted testHFlushInterrupted p= fs System createFile hflush assertTrue interrupt Failed to deal with thread interruptions  create a new file. write close currentThread  Try again to flush should succeed since we no longer have interrupt status Got expected exception during close getFileSystem interrupted fileContents stm AppendTestUtil Thread checkFullFile  verify that entire file is good fileLen p  Now do a successful close. build numDataNodes DATANODE_NUM  If we got the exception, we shouldn't have interrupted status anymore.  Write some data and close while interrupted shutdown ",hadoop,1
getPathParameter thenReturn session multiple invoke when multipleDifferentExtractorsShouldWorkFine param1 param2 context create verify value 20 mockController getParameter ,ninja,0
suspend resume testWorkflowStates addNode def one start assertEquals WorkflowInstance getStatus kill asList wf 1 fail <worklfow-app/> end Arrays job ,oozie,1
 Let half the threads continue with more metrics and let half die opTotalTime seed  the totals are as expected secondSnapshotsFinished run  snapshot to complete; else their metrics may be lost to GC sleep  total await snapshotMutableRatesWithAggregation countDown  Initialize so that the getLongCounter() method doesn't complain tIdx firstAddsFinished info add testMutableRatesWithAggregationManyThreads LOG rates start threads Random seed =  assertEquals nextInt  Sleep so additions can be interleaved with snapshots nextLong  count n Thread  opCount / opTotalTime threadIdx t metric opCount  add metrics correctly and that snapshot occurs correctly sleepRandom firstSnapshotsFinished secondAddsFinished ,hadoop,0
"de DATE_1970_JAN NinjaConstant language when  fr as language empty result get of  en as language lang das ist ein datum: 01.01.1970 Optional thenReturn toDate en assertEquals that's a date: Jan 1, 1970 testGetWithSpecialI18nPlaceholder message_with_placeholder_date messages getStringArray  test fallback to default (english in that case) c'est la date: 1 janv. 1970  de as language fr-FR ninjaProperties ",ninja,0
"oryx.input-schema.target-feature startServerProduceConsumeTopics getName oryx.input-schema.feature-names ConfigUtils dist put numUpdates red  Not testing the model much here: getFirst UP nodeID countMap info containsKey oryx.speed.streaming.block-interval-sec unchecked count getValueEncodingMap getDataDictionary [""color"",""fruit""] NUM_INPUT size  Should be about 9x more yellow oryx.input-schema.numeric-features overlayOn isDebugEnabled fields yellowCount PMMLUtils log fruit yellow update buildCategoricalValueEncodings updates startMessaging treeID  Should be about 9x more red assertTrue fruitEncoding get redCount MAPPER readValue [] {} debug encodings pmml AppPMMLUtils assertEquals MODEL  Model, and then pairs of positive / negative getConfig Integer oryx.speed.streaming.generation-interval-sec equals getSecond checkProbability r+ overlayConfig toString fromString r- oryx.speed.model-manager-class config testRDFSpeedClassification ",oryx,1
"cluster     * Creates a block with all datanodes on the same rack, though the block    * is sufficiently replicated. Adds an additional datanode on a new rack.     * The block should be replicated to the new rack.     testSufficientlyReplBlocksUsesNewRack racks conf waitForReplication /rack2 /rack1 fs createFile waitActive  Create a file with one block with a replication factor of 3  All datanodes are on the same rack DFSTestUtil b startDataNodes getConf newRacks  Add a new datanode on a different rack filePath getFileSystem REPLICATION_FACTOR /testFile build numDataNodes getFirstBlock shutdown ",hadoop,1
request when filterConfig setHeader testDefaultOptionsValue doAnswer Assert DENY X_FRAME_OPTIONS assertTrue doFilter Options value incorrect should be DENY but is:  add headers init isOne chain thenReturn assertThat any args filter X-Frame-Options count not equal to 1. invocation withFailMessage header should be visible inside chain and filters. getInitParameter answer size Mockito response equals mock getArguments XFrameOptionsFilter containsHeader ,hadoop,0
Assert isSet assertTrue assertFalse foo toString assertEquals testToken token ,hadoop,0
" <execution>LIFO</execution> </controls> <datasets>  testJobMethods LocalOozie conf xmlns=""uri:oozie:coordinator:0.1""> <controls> <timeout>10</timeout> <concurrency>1</concurrency>  run </input-events>  <app-path>hdfs:///tmp/workflows/</app-path>  </property></configuration> </workflow> </action> </coordinator-app> getCoordClient file:// getTestCaseDir <coordinator-app name=""NAME"" frequency=""${coord:minutes(20)}""  <output-events> <data-out name=""LOCAL_A"" dataset=""local_a"">  timezone=""UTC""> <uri-template>file:///tmp/coord/workflows/${YEAR}/${DAY}</uri-template> </dataset>  suspend <configuration> <property> <name>inputA</name> <value>${coord:dataIn('A')}</value> </property>  list NAME OozieClient jobId size </datasets> <input-events>  setProperty createConfiguration job File start=""2009-02-01T01:00Z"" end=""2009-02-03T23:59Z"" timezone=""UTC""  submit getCoordJobsInfo appPath writeToFile appXml jobId0  Just in case, check that there are no Coord job records left by previous tests: <property> <name>inputB</name> <value>${coord:dataOut('LOCAL_A')}</value>  getCoordJobInfo client <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow>  <dataset name=""local_a"" frequency=""${coord:minutes(20)}"" initial-instance=""2009-02-01T01:00Z""  <dataset name=""a"" frequency=""${coord:minutes(20)}"" initial-instance=""2009-02-01T01:00Z""  resume coordinator.xml getAppName appName assertEquals kill list0 <data-in name=""A"" dataset=""a""> <instance>${coord:latest(0)}</instance> </data-in>   ",oozie,1
dst src assertFalse dir2 testRenameReplaceExistingEmptyDirectory dir1 delete assertTrue rename TEST_ROOT_DIR mkdirs fileSys file2 exists file1 writeFile ,hadoop,0
addRecordToBundleActionTable addRecordToBundleJobTable getId run assertEquals getStatus execute Services jobId runnable ba1 testBundleStatusTransitServiceSucceeded1 assertNotNull get equals action1 Job job action2 jpaService action3 bundle evaluate waitFor ,oozie,1
 log4j.appender.oozie.RollingPolicy.FileNamePattern ${oozie.log.dir}/oozie.log-blah getName  Test missing appender class getTestCaseConfDir ${oozie.log.dir}/oozie.log-%d{yyyy-MM-dd-HH}.gz ls assertFalse  Test non-absolute path for logfile  Test DailyRollingFileAppender but DatePattern that doesn't end with 'HH' or 'dd' fos log4j.appender.oozie.File doStreamDisabledCheck ${oozie.log.dir}/oozie.log-%d{yyyy-MM-dd-HH} propsFile '.'yyyy-MM-dd '.'yyyy-MM-dd-HH  Test missing logfile  Test appender class not DailyRollingFileAppender or RollingFileAppender assertTrue oozie.log  Test DailyRollingFileAppender with everything correct (dd)  Test DailyRollingFileAppender with everything correct (HH)  Test RollingFileAppender but FileNamePattern with incorrect beginning '.'yyyy-MM  Test RollingFileAppender with everything correct (gz)  Test RollingFileAppender with everything correct init testDisableLogOverWS XLogService ${oozie.log.dir}/oozie.log destroy store props test-disable-log-over-ws-log4j.properties org.apache.log4j.DailyRollingFileAppender log4j.appender.oozie log4j.appender.oozie.DatePattern  Test RollingFileAppender but missing FileNamePattern setProperty setSystemProperty org.blah.blah org.apache.log4j.rolling.RollingFileAppender  Test RollingFileAppender but FileNamePattern with incorrect ending  Test DailyRollingFileAppender but missing DatePattern ${oozie.log.dir}/blah.log-%d{yyyy-MM-dd-HH} ,oozie,1
getJobTrackerUri getName <java> assertFalse getStatus createContext actionXml isSuccessful assertTrue context waitFor <job-tracker> KILLED isCompleted getNameNodeUri </java> ae </main-class> </job-tracker> runningJob getAction assertEquals kill getExternalStatus <name-node> <main-class> </name-node> testKill WorkflowAction submitAction evaluate isComplete ,oozie,1
testMultiThreadedDecompressorPool submit returnDecompressor Executors threadpool put TimeUnit awaitTermination LEASE_COUNT_ERR consumer CodecPool c newFixedThreadPool assertEquals iterations call getDecompressor take codec producer  wait for completion getLeasedDecompressorsCount queue shutdown dc ,hadoop,0
conn setRequestMethod IS_SECURITY_ENABLED /v0/admin/* assertTrue get json content-type Collections runTest getBuildInfo JsonTags RestConstants getProperty openConnection testVersion HttpServletResponse assertEquals parse getInputStream url JSONValue call getHeaderField GET getResponseCode BuildInfo createURL startsWith ,oozie,1
formatDate  server request code string assertEquals setResponseCode body newCall execute url / enqueue getUrl HttpURLConnection build response clientSuppliedConditionWithoutCachedResult If-Modified-Since TimeUnit header client ,okhttp,1
"getName defaultfs://host2 conf //host2 URI  has scheme, same auth fs.defaultfs.impl FileSystem get testDefaultFsUris defaultUri create defaultFs  no scheme, no auth set defaultfs://host assertEquals assertSame defaultfs:/// /  sanity check default fs //host  no scheme, same auth setDefaultUri intercept assertNotSame  has scheme, no auth  has scheme, different auth getUri defaultfs:/ ",hadoop,0
actionNum CoordinatorJob testCoordActionGet coord-action-get.xml CoordinatorAction getId job addRecordToCoordActionTable addRecordToCoordJobTable _testActiveActionsCount ,oozie,1
"a a-InsideInclude b startInclude b-OutsideInclude endConfig startConfig conf assertEquals CONFIG2 tearDown  Property ""a"" is set to different values inside and outside of includes. appendProperty out CONFIG endInclude addResource a-OutsideInclude get fileResource b-InsideInclude testOrderOfDuplicatePropertiesWithInclude ",hadoop,0
getRecoveryPath <chmod path=''{5}'' permissions=''-rwxrwxrwx''/> chmod1 chmod2 <chmod path=''{6}'' permissions=''-rwxrwx---'' dir-files=''false''/> source getStatus createContext newFile2X chmod2X getPath context getFileStatus action mkdirX mkdir <touchz path=''{8}''/> <move source=''{3}'' target=''{4}''/> getPermission ae format <mkdir path=''{1}''/> getFileSystem check <fs><name-node>{0}</name-node> chmod1X rwxrwx--- newFile1X WorkflowAction mkdirs newFile2 newFile1 assertFalse <touchz path=''{7}''/> child2 fs delete child1 actionXml <delete path=''{2}''/> testSubmitWithNameNode assertTrue </fs> end OK getData getNameNodeUri sourceX MessageFormat toUri deleteX start getAction assertEquals getExternalStatus rwxrwxrwx target assertNull assertNotSame exists toString createNewFile getFsTestCaseDir ,oozie,1
cc email-action ctx  Multiple <to>s subject body createNormalContext fail  Multiple <cc>s testValidation  Multiple <subject>s prepareBadElement  Multiple <body>s validateAndMail to email ,oozie,1
" de conn /app POST put getJob setRequestProperty create workflow.xml /v0/jobs  runTest(""/jobs"", BaseJobsServlet.class, IS_SECURITY_ENABLED, new Callable<Void>() { openConnection conf1 getFileSystem params getInputStream getDagEngine JSONValue OozieClient size reset setDoOutput jobConf setRequestMethod IS_SECURITY_ENABLED assertFalse writeXml testSubmit appPath fs assertTrue get content-type jobXmlPath runTest sr JsonTags set RestConstants getConf undef MockDagEngineService HttpServletResponse assertEquals parse services url call Services getTestUser obj getResponseCode wfCount createURL toString getOutputStream getFsTestCaseDir ",oozie,1
