DagELFunctions
"FEATURES":"UNKNOWN",
ActionType
"RETURN_CODE":"0",
"ERROR_MESSAGE":null,
put
${hadoop:counters('H')['JOB_GRAPH']}
createEvaluator
${hadoop:counters('H')['ACTION_TYPE']}
split
"0"
{"ACTION_TYPE":"PIG",
"ERROR_CODE":"-1",
tmp
context
setId
action
indexOf
"job_201111300933_0004"
item
workflow
"HADOOP_VERSION":"0.20.2",
${hadoop:counters('H')['job_201111300933_0004']}
,
version
"RECORD_WRITTEN":"33",
1
ApplicationType
eval
null
job1StatusResArray
${hadoop:counters('H')['job_201111300933_0004']['MAP_INPUT_RECORDS']}
"NUMBER_JOBS":"2",
job1StatusMap
:
evaluate
"JOB_GRAPH":"job_201111300933_0004,job_201111300933_0005",
"MIN_REDUCE_TIME"
"job_201111300933_0005"
status
setName
addNode
"job_201111300933_0005":{"MAP_INPUT_RECORDS":"37","MIN_REDUCE_TIME":"0","MULTI_STORE_COUNTERS":{},"ERROR_MESSAGE":null,"JOB_ID":"job_201111300933_0005"},
0.9.0
generateId
H
jobStatusItems
job2StatusMap
"37"
pigStats
${hadoop:counters('H')['job_201111300933_0005']}
"job_201111300933_0004":{"MAP_INPUT_RECORDS":"33","MIN_REDUCE_TIME":"0","MULTI_STORE_COUNTERS":{},"ERROR_MESSAGE":null,"JOB_ID":"job_201111300933_0004"},
substring
"ERROR_MESSAGE"
wi
"BYTES_WRITTEN":"1410",
configureEvaluator
"PIG_VERSION":"0.9.0",
get
<workflow-app/>
MapReduceActionExecutor
"MULTI_STORE_COUNTERS"
setProtoActionConf
setWorkflowInstance
a
{}
job2StatusResArray
testELFunctionsReturningPigStats
setVar
assertEquals
wfApp
"33"
Services
"JOB_ID"
lastIndexOf
<configuration/>
job_201111300933_0004,job_201111300933_0005
${hadoop:counters('H')['PIG_VERSION']}
jobGraph
"MAP_INPUT_RECORDS"
toString
job2StatusResult
job2StatusResMap
}
job1StatusResMap
job1StatusResult
