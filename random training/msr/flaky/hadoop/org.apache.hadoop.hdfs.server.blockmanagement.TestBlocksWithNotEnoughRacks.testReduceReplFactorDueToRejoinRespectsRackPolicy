cluster
 The block now has sufficient # replicas, across racks
testReduceReplFactorDueToRejoinRespectsRackPolicy
ns
racks
 not on the restarted datanode as that would violate the rack policy.
dm
conf
/rack2
getBlockManager
waitForReplication
/rack1
fs
createFile
rack2
waitActive

   * Test that when the excess replicas of a block are reduced due to
   * a node re-joining the cluster the rack policy is not violated.
   
getDatanodeManager
get
stopDataNode
DFSTestUtil
b
getDataNodes
startDataNodes
getConf
filePath
 to heartbeat by stopping it and calling removeDatanode.
assertEquals
dnId
getFileSystem
dataNode
 available and only 2 replicas required).
REPLICATION_FACTOR
getNameNode
datanodes
/testFile
 Last datanode is on a different rack
size
build
removeDatanode
numDataNodes
 Create a file with one block
getFirstBlock
shutdown
getDatanodeId
getNamesystem
