__label__flaky cluster  sub  get  current  user  conf  lsr  run  assert  true  ugi  root  set  permission  results  user  group  information  get  short  user  name  create  user  for  testing  create  tree  tmp  ugi  get  file  system  run  lsr  tmpusername  test  lsr  dfs  1  do  as  contains  build  num  data  nodes  mkdirs  zzz  shutdown  cluster  sub  getcurrentuser  conf  lsr  run  asserttrue  ugi  root  setpermission  results  usergroupinformation  getshortusername  createuserfortesting  createtree  tmpugi  getfilesystem  runlsr  tmpusername  testlsr  dfs  1  doas  contains  build  numdatanodes  mkdirs  zzz  shutdown
__label__nflaky gid  name  map  get  gid  clear  map  and  update  static  map  file  assume  not  windows  nid  conf  get  gid  name  map  rid  delete  sleep  get  uid  uid  name  map  ref  id  mapping  get  path  me  id  clear  name  maps  smap  str  nfs-  get  key  set  get  uid  name  map  entry  set  get  gid (  )   uid  incr  id  mapping  the  static  map  create  temp  file  assert  equals  temp  static  map  file  the  same  as   \ ""id \ ""  gid  test  static  map  update  thread  get  value  id  mapping  constant  set  long  get  uid (  )   test  static  map  refreshing   . map  name  sleep  a  bit  to  avoid  that  two  changes  have  the  same  modification  time  file  create  static  map  file  gidnamemap  getgid   clear map and update staticmap file  assumenotwindows  nid  conf  getgidnamemap  rid  delete  sleep  getuid  uidnamemap  refidmapping  getpath  me  id  clearnamemaps  smapstr     nfs-  getkey  set  getuidnamemap  entryset   getgid (  )   uid   incridmapping   the staticmap  createtempfile  assertequals  tempstaticmapfile   the same as  \ ""id \ ""  gid   teststaticmapupdate  thread  getvalue  idmappingconstant  setlong   getuid (  )    test staticmap refreshing   . map  name   sleep a bit to avoid that two changes have the same modification time  file  createstaticmapfile
__label__flaky get  current  dateafter  incrementing  in  months  get  id  run  date  utils  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  sleep  get  test  coord  status  transit  service  done  with  error  coordinator  action  end  current  date  plus  month  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  coordinator  job  services  runnable  coord-action-get . xml  job  jpa  service  getcurrentdateafterincrementinginmonths  getid  run  dateutils  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  sleep  get  testcoordstatustransitservicedonewitherror  coordinatoraction  end  currentdateplusmonth  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  coordinatorjob  services  runnable  coord-action-get . xml  job  jpaservice
__label__nflaky charset  submit  executor  service  executors  get  cause  test  multithreading  write  stream  abort  get  bytes  write  completed  sleep  assert  1234567890  get  duration  assert  true  tmp  get  boolean  task1  write  task2  output  buffer  new  fixed  thread  pool  standard  charsets  assert  equals  thread  get  time  unit  call  ex  abort  timeout  charset  submit  executorservice  executors  getcause  testmultithreadingwritestreamabort  getbytes  writecompleted  sleep  assert  1234567890  getduration  asserttrue  tmp  get  boolean  task1  write  task2  outputbuffer  newfixedthreadpool  standardcharsets  assertequals  thread  gettimeunit  call  ex  abort  timeout
__label__flaky action  num  coordinator  job  test  coord  action  get  coord-action-get . xml  coordinator  action  get  id  job  add  record  to  coord  action  table  add  record  to  coord  job  table  _test  active  actions  count  actionnum  coordinatorjob  testcoordactionget  coord-action-get . xml  coordinatoraction  getid  job  addrecordtocoordactiontable  addrecordtocoordjobtable  _testactiveactionscount
__label__nflaky test  no  args  check  arg  limits  testnoargs  checkarglimits
__label__flaky mock  coordinator  engine  service  -log  end_  points  rest  constants  is_  security_  enabled  get  context  url  -action  oozie  url  test  job  log  mock  dag  engine  service  2009-12-16  t01:00  z  run  assert  equals  0  args  call  -date  -oozie  reset  job  servlet_  classes  run  test  mockcoordinatorengineservice  -log  end_points  restconstants  is_security_enabled  getcontexturl  -action  oozieurl  testjoblog  mockdagengineservice  2009-12-16t01:00z  run  assertequals  0  args  call  -date  -oozie  reset  job  servlet_classes  runtest
__label__nflaky cursor  copy  quoted  content  strbuf2  assert  false  token  parser  create  buffer  assert  copy  content  assert  true  get  pos  some  stuff  update  pos  skip  white  space  strbuf1  at  end  length  raw  assert  equals  raw:   \ ""  some  stuff   \ ""  parser  to  string  init_  bitset  char  at  test  basic  token  parsing  cursor  copyquotedcontent  strbuf2  assertfalse  tokenparser  createbuffer  assert  copycontent  asserttrue  getpos   some stuff   updatepos  skipwhitespace  strbuf1  atend  length  raw  assertequals     raw:  \ "" some stuff  \ ""  parser  tostring  init_bitset  charat  testbasictokenparsing
__label__flaky bundle  job  get  executor  get  time  add  record  to  bundle  job  table  with  paused  time  get  id  assert  equals  get  status  execute  test  bundle  rerun  in  prep  call  services  pause  time  assert  not  null  get  curr  job  job  action2  jpa  service  bundlejobgetexecutor  gettime  addrecordtobundlejobtablewithpausedtime  getid  assertequals  getstatus  execute  testbundlereruninprep  call  services  pausetime  assertnotnull  get  curr  job  job  action2  jpaservice
__label__nflaky before  we  destroy  stuff  the  injector  is  there  after  destroying  the  context  the  injector  is  null .   context  initialized  get  injector  not  null  value  servlet  context  event  test  that  context  destroyed  works  ninja  servlet  listener  assert  that  context  destroyed  null  value   before we destroy stuff the injector is there   after destroying the context the injector is null .   contextinitialized  getinjector  notnullvalue  servletcontextevent  testthatcontextdestroyedworks  ninjaservletlistener  assertthat  contextdestroyed  nullvalue
__label__flaky bundle  job  get  executor  bundle-app-name  job  conf  log  submit  cmd  get  id  get  status  app  path  configuration  parse  error .   read  from  db  :  get  job  sleep  assert  not  null  get  get  auth  token  job  get  bundle  id  wait  for  get  app  name  set  get  conf  add  record  to  bundle  job  table  test  bundle  start2  assert  equals  execute  bundle . xml  call  services  warn  oozie  client  size  bundle  actions  get  executor  equals  to  string  is  critical  error  code  job  jpa  service  actions  evaluate  ioe  bundlejobgetexecutor  bundle-app-name  jobconf  log  submitcmd  getid  getstatus  apppath  configuration parse error .  read from db :  getjob  sleep  assertnotnull  get  getauthtoken  job  getbundleid  waitfor  getappname  set  getconf  addrecordtobundlejobtable  testbundlestart2  assertequals  execute  bundle . xml  call  services  warn  oozieclient  size  bundleactionsgetexecutor  equals  tostring  iscritical  errorcode  job  jpaservice  actions  evaluate  ioe
__label__nflaky parent  init  incorrect  number  of  services  test  add  uninited  sibling  in  stop  assert  in  state  start  state  assert  equals  sibling  stop  size  add  service  get  services  parent  init  incorrect number of services  testadduninitedsiblinginstop  assertinstate  start  state  assertequals  sibling  stop  size  addservice  getservices
__label__flaky  (   feature_  name   feature_  enabled   strategy_  id   strategy_  params )   state  no  entry  update  mytable  where  feature_  name  =   \  '   f1 \  '   get  strategy  id  insert  into  mytable  inserted  state  enabled  foobar  param  assert  not  null  some  strategy  get  parameter  jdbc  features  state  disabled  assert  equals  values   (  \  '   f1 \  '    1    \  '   some  strategy \  '     \  ' param=foobar \  '  )   test  get  feature  state  from  jdbc  repository  get  feature  state  feature  context  feature  manager  size  get  feature  manager  is  enabled  get  parameter  names  set  feature_  enabled  =  0   strategy_  id  =  null   strategy_  params  =  null  data  source  execute  update   ( feature_name  feature_enabled  strategy_id  strategy_params )    statenoentry  update mytable   where feature_name =  \  ' f1 \  '   getstrategyid  insert into mytable   inserted  stateenabled  foobar  param  assertnotnull  somestrategy  getparameter  jdbcfeatures  statedisabled  assertequals  values  (  \  ' f1 \  '   1   \  ' somestrategy \  '    \  ' param=foobar \  '  )   testgetfeaturestatefromjdbcrepository  getfeaturestate  featurecontext  featuremanager  size  getfeaturemanager  isenabled  getparameternames  set feature_enabled = 0  strategy_id = null  strategy_params = null   datasource  executeupdate
__label__nflaky append  if  exists  none  with  codec  verify  failure  if  the  compression  details  are  different  or  not  provided  root_  path  key  class  compress  option  conf  fs  delete  two  three  verify  all4  values  wrong  compress  option  file  codec  should  be  ignored  sequence  file  four  testseqappendnonecompr . seq  close  delete  on  exit  test  append  none  compression  one  fail  create  writer  expected  illegal  argument  exception  for  compression  options  verify  failure  if  the  compression  details  are  different  value  class  writer  compression  compression  type  verify2  values  writer  append  appendifexists  nonewithcodec   verify failure if the compression details are different or not provided  root_path  keyclass  compressoption  conf  fs  delete  two  three  verifyall4values  wrongcompressoption  file   codec should be ignored  sequencefile  four  testseqappendnonecompr . seq  close  deleteonexit  testappendnonecompression  one  fail  createwriter  expected illegalargumentexception for compression options   verify failure if the compression details are different  valueclass  writer  compression  compressiontype  verify2values  writer  append
__label__flaky play  server  get  sequence  number  clear  headers  assert  content  http  url  connection  connection1  client  request  b  request  a  connection2  add  header  b  no  transparent  gzip  for304  not  modified  take  request  assert  equals  set  response  code  set  body  content-  encoding:  gzip   /   enqueue  get  url  get  response  code  open  play    server  getsequencenumber  clearheaders  assertcontent  httpurlconnection  connection1  client  requestb  requesta  connection2  addheader  b  notransparentgzipfor304notmodified  takerequest  assertequals  setresponsecode  setbody  content-encoding: gzip   /   enqueue  geturl  getresponsecode  open
__label__nflaky get  name  when  as  list  get  init  parameter  names  parse  cookie  map  set  header  assert  assert  not  null  auth  failed  set-  cookie  management . operation . return  cookie  missing  http: /  / foo:8080 / bar  get  request  url  init  cookie  map  then  return  any  string  destroy  eq  fail  never  invocation  test  do  filter  authentication  failure  get  init  parameter  shouldn \  ' t  get  here  true  mock  get  arguments  arrays  request  send  error  get  header  do  answer  dummyauth  do  filter  get  cookies  get  verify  value  authenticated  url  chain  add  header  authentication  filter  www-  authenticate  http  servlet  response  assert  equals  any  filter  args  get  mocked  servlet  context  with  string  signer  answer  mockito  response  elements  config    getname  when  aslist  getinitparameternames  parsecookiemap  setheader  assert  assertnotnull  auth failed  set-cookie  management . operation . return  cookie missing  http: /  / foo:8080 / bar  getrequesturl  init  cookiemap  thenreturn  anystring  destroy  eq  fail  never  invocation  testdofilterauthenticationfailure  getinitparameter  shouldn \  ' t get here  true  mock  getarguments  arrays  request  senderror  getheader  doanswer  dummyauth  dofilter  getcookies  get  verify  value  authenticatedurl  chain  addheader  authenticationfilter  www-authenticate  httpservletresponse  assertequals  any  filter  args  getmockedservletcontextwithstringsigner  answer  mockito  response  elements  config
__label__flaky get  waiting  actions  system  dep  sleep  get  test  eviction  on  time  to  live  setup  services  start  time  info  time  to  live  seconds  is  1  add  missing  dependency  log  pdms  hcat: /  / hcat . server . com:5080 / mydb / mytbl / id=  time  taken  to  insert  and  retrive  num  items  verify  waiting  action  thread  services  assert  null  items  is  current  time  millis  testevictionontimetolive    getwaitingactions  system  dep  sleep  get  testevictionontimetolive  setupservices  starttime  info   timetoliveseconds is 1  addmissingdependency  log  pdms  hcat: /  / hcat . server . com:5080 / mydb / mytbl / id=  time taken to insert and retrive   numitems  verifywaitingaction  thread  services  assertnull   items is   currenttimemillis  testevictionontimetolive
__label__nflaky string  writer  session  equal  to  test  that  it  works  assert  that  execute  get  authenticity  token  environment  mockito  template  engine  freemarker  authenticity  token  directive  12345  verify  to  string  parameters  loop  vars  stringwriter  session  equalto  testthatitworks  assertthat  execute  getauthenticitytoken  environment  mockito  templateenginefreemarkerauthenticitytokendirective  12345  verify  tostring  parameters  loopvars
__label__flaky json  tags  action  status=  failed   killed;startcreatedtime=2012-07-21  t00:00  z   / v1 / jobs  ;coordinators=  coord1;  assert  equals  jaction1  jaction2  test  multiple  records  call  size  failed  array  assert  not  null  get  bundle  name  _request  to  server  bulk  request  bundle=  killed  run  test  jbundle  jsontags  actionstatus=failed killed;startcreatedtime=2012-07-21t00:00z   / v1 / jobs  ;coordinators=coord1;  assertequals  jaction1  jaction2  testmultiplerecords  call  size  failed  array  assertnotnull  get  bundlename  _requesttoserver  bulkrequest  bundle=  killed  runtest  jbundle
__label__nflaky content  type  listener  core  matchers  set  exception  callback  get  cause  async  server  bootstrap  listen  instance  of  io  reactor  config  assert  get  duration  create  https   / stuff  set  lookup  registry  requester  localhost  set  stream  listener  logging  exception  callback  logging  http1  stream  listener  set  io  session  listener  result  future1  *  set  so  timeout  method  assert  that  execute  logging  conn  pool  listener  fail  ex  secure  all  ports  strategy  timeout  server  set  io  reactor  config  cause  bootstrap  h2  requester  bootstrap  set  conn  pool  listener  set  tls  strategy  some  stuff  set  io  session  decorator  test  tls  trust  failure  create  server  ssl  context  get  execution  exception  expected  get  address  create  default  ssl  contexts  ssl  test  contexts  address  custom  start  target  get  time  unit  logging  io  session  decorator  get  port  build  future  logging  io  session  listener  register  contenttype  listener  corematchers  setexceptioncallback  getcause  asyncserverbootstrap  listen  instanceof  ioreactorconfig  assert  getduration  create  https   / stuff  setlookupregistry  requester  localhost  setstreamlistener  loggingexceptioncallback  logginghttp1streamlistener  setiosessionlistener  resultfuture1  *  setsotimeout  method  assertthat  execute  loggingconnpoollistener  fail  ex  secureallportsstrategy  timeout  server  setioreactorconfig  cause  bootstrap  h2requesterbootstrap  setconnpoollistener  settlsstrategy  some stuff  setiosessiondecorator  testtlstrustfailure  createserversslcontext  get  executionexception expected  getaddress  createdefault  sslcontexts  ssltestcontexts  address  custom  start  target  gettimeunit  loggingiosessiondecorator  getport  build  future  loggingiosessionlistener  register
__label__flaky next  key  value  starting  from  each  row   validate  results  should  contain  the  starting  row  nr  count  of  columns  row  name  system  family  sleep  bytes  start  row  id  add  rows  get  next  row  assert  true  get  scanner  row  results  is  expected  row  without  timestamps  add  to  bytes  clear  assert  equals  add  more  versions  to  make  it  a  little  more  interesting .   kv  memstore  clear  out  set .   otherwise  row  results  accumulate .   thread  row  id  integer  row_  count  size  compare  rows  test  get  next  row  current  time  millis  get  scanners  qualifier_  count  closest  to  empty  next  keyvalue   starting from each row  validate results should contain the starting row  nr  count of columns  row name  system  family  sleep  bytes  startrowid  addrows  getnextrow  asserttrue  get  scanner  row  results  isexpectedrowwithouttimestamps  add  tobytes  clear  assertequals   add more versions to make it a little more interesting .   kv  memstore   clear out set .   otherwise row results accumulate .   thread  rowid  integer  row_count  size  comparerows  testgetnextrow  currenttimemillis  getscanners  qualifier_count  closesttoempty
__label__nflaky wait  get  local  port  local  client  accept  client  server  socket  start  is  connected  listener  set  so  timeout  thread  get  local  host  test  accept  client  retries  assert  true  assert  not  null  client  inet  address  close  wait  getlocalport  localclient  acceptclient  serversocket  start  isconnected  listener  setsotimeout  thread  getlocalhost  testacceptclient  retries  asserttrue  assertnotnull  client  inetaddress  close
__label__flaky get  name  get  log  put  create  table  descriptor  t40  bytes  t20  assert  true  htd  columns  close  add  print  stack  trace  e  test  get  closest  row  before2  get  row  c0  close  and  delete  flushcache  create  new  h  region  p  t30  t10  get  closest  row  before  r  try  finding   \ ""035 \ ""  t35  equals  region  getname  getlog  put  createtabledescriptor  t40  bytes  t20  asserttrue  htd  columns  close  add  printstacktrace  e  testgetclosestrowbefore2  getrow  c0  closeanddelete  flushcache  createnewhregion  p  t30  t10  getclosestrowbefore  r   try finding  \ ""035 \ ""  t35  equals  region
__label__nflaky set  native  zlib  loaded  get  class  seed  gzbuf  dflchk  conf  next  bytes  assert  array  equals  decom  zlib  factory  assert  not  null  write  close  get  data  copy  bytes  info  gzout  b  log  test  gzip  compatibility  gzin  new  instance  assert  equals  next  int  next  long  seed:  copy  of  create  input  stream  codec  r  io  utils  don \  ' t  use  native  libs  create  decompressor  get  length  reset  set  seed  reflection  utils  arrays  dflbuf  setnativezlibloaded  getclass  seed  gzbuf  dflchk  conf  nextbytes  assertarrayequals  decom  zlibfactory  assertnotnull  write  close  getdata  copybytes  info  gzout  b  log  testgzipcompatibility  gzin  newinstance  assertequals  nextint  nextlong  seed:   copyof  createinputstream  codec  r  ioutils   don \  ' t use native libs  createdecompressor  getlength  reset  setseed  reflectionutils  arrays  dflbuf
__label__flaky aap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /    /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  q  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaa  this  specially-formatted  frame  has  trailing  deflated  bytes  after  the  name  value  block .   aaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad  a /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9   /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  header  block  has  trailing  compressed  bytes2048  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaa  g  ama  ag  aab / s  aaaa  be  lvjxqf  c  aq  yj  rh  ag  jmx  gx  uqaaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaa  header  block  has  trailing  compressed  bytes  aaad /  / 0o  eaaaa /  / 8=  frame  aap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /    / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgq  kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaa   this specially-formatted frame has trailing deflated bytes after the name value block .   aaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad  a /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9   /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0o  headerblockhastrailingcompressedbytes2048  eaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaa  gamaagaab / saaaabelvjxqfcaqyjrhagjmxgxuqaaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaa  headerblockhastrailingcompressedbytes  aaad /  / 0oeaaaa /  / 8=  frame
__label__nflaky  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /    / {name} / dashboard   / dashboard  build  route  assert  false  john  assert  true  get   / {name} / {id} / dashboard  id  map   /   john / 20 / dashboard  entry  set  get  path  parameters  encoded  assert  equals  matches  ninja  base  directory  resolver  route   /   john / dashboard  size  get  name  route  builder  ninja  properties  20  basic  placeholers  and  parameters    /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /    / {name} / dashboard   / dashboard  buildroute  assertfalse  john  asserttrue  get   / {name} / {id} / dashboard  id  map   / john / 20 / dashboard  entryset  getpathparametersencoded  assertequals  matches  ninjabasedirectoryresolver  route   / john / dashboard  size  get  name  routebuilder  ninjaproperties  20  basicplaceholersandparameters
__label__flaky date  session  given  insert  should_insert_with_timestamp  crud  using  timestamp  when  id  row  value  wt  is  not  null  random  utils  manager  select  writetime ( value )   as  wt  from  simple  where  id  =  one  next  long  assert  that  execute  get  long  then  long  build  date  key  is  equal  to  entity  date  session   given  insert  should_insert_with_timestamp  crud  usingtimestamp   when  id  row  value  wt  isnotnull  randomutils  manager  select writetime ( value )  as wt from simple where id =   one  nextlong  assertthat  execute  getlong   then  long  builddatekey  isequalto  entity
__label__nflaky path  request  add  request .   already  checked  response  put  stuff  parm  parameters  appended  to  the  path  should  have  been  put  in  the  query .   assert  assert  true  run  tests  get  add  test   / stuff  parameter  in  path  adapter  test  contains  key  query  unchecked  stuff2  assert  equals  execute  framework  query  request  new  framework  and  set  adapter  stuff  parm2   / stuff ? stuff  parm=stuff&stuff  parm2=stuff2  stuff  path  request   add request .   alreadycheckedresponse  put  stuffparm  parameters appended to the path should have been put in the query .   assert  asserttrue  runtests  get  addtest   / stuff  parameterinpath  adapter  test  containskey  query  unchecked  stuff2  assertequals  execute  framework  query  request  newframeworkandsetadapter  stuffparm2   / stuff ? stuffparm=stuff&stuffparm2=stuff2  stuff
__label__flaky assert  false  topic . topic1  sleep  is  topic  in  retry  list  is  connection  in  retry  list  h  cat  accessor  service  should  not  retry  again  as  max  attempt  is  1  assert  true  publisher  authority  get  services  conf  register  for  notification  java . naming . factory . initial#  jndi  properties  string  init  set  get  jms  connection  info  get  conf  hcat  service  hcat . server . com:5080  destroy  jms  service  get  num  connection  attempts  assert  equals  services  hcat: /  / hcat . server . com:8020  jms  accessor  service  active  mq  conn  factory  thread  1  services  java . naming . provider . url#  conn  info  setup  services  for  h  catalog  is  listening  to  topic  topic  retry  connection  default=  test  connection  retry  max  attempt  ;  tcp: /  / localhost:12345;connection  factory  names#  connection  factory  assertfalse  topic . topic1  sleep  istopicinretrylist  isconnectioninretrylist  hcataccessorservice   should not retry again as max attempt is 1  asserttrue  publisherauthority  get  servicesconf  registerfornotification  java . naming . factory . initial#  jndipropertiesstring  init  set  getjmsconnectioninfo  getconf  hcatservice  hcat . server . com:5080  destroy  jmsservice  getnumconnectionattempts  assertequals  services  hcat: /  / hcat . server . com:8020  jmsaccessorservice  activemqconnfactory  thread  1  services  java . naming . provider . url#  conninfo  setupservicesforhcatalog  islisteningtotopic  topic  retryconnection  default=  testconnectionretrymaxattempt  ;  tcp: /  / localhost:12345;connectionfactorynames#connectionfactory
__label__nflaky init  get  servlet  context  servlet  context  assert  not  null  context  test  get  servlet  context  assert  equals  http  servlet  request  http  servlet  response  init  the  context  from  a   ( mocked )   servlet  o  init  getservletcontext  servletcontext  assertnotnull  context  testgetservletcontext  assertequals  httpservletrequest  httpservletresponse   init the context from a  ( mocked )  servlet  o
__label__flaky get  context  url  oozie  url  admin  run  assert  equals  args  call  -auth  -oozie  test  client  auth  method  bad  method  -status  simple  fake  run  test  getcontexturl  oozieurl  admin  run  assertequals  args  call  -auth  -oozie  testclientauthmethod   bad method  -status  simple  fake  runtest
__label__nflaky file  set  url  stream  handler  factory  assert  false  file  system  conf  get  file  system  class  we  might  get  an  exception  but  this  not  related  to  infinite  loop  problem  url  test  initialization  with  registered  stream  factory  file  seturlstreamhandlerfactory  assertfalse  filesystem  conf  getfilesystemclass   we might get an exception but this not related to infinite loop problem  url  testinitializationwithregisteredstreamfactory
__label__flaky test  activation  strategy  saving  and  loading  test  feature  reflection  equals  set  strategy  id  user1   user2   user3  is  assert  that  get  feature  state  loaded  feature  state  saved  feature  state  set  parameter  set  feature  state  username  activation  strategy  state  repository  testactivationstrategysavingandloading  testfeature  reflectionequals  setstrategyid  user1  user2  user3  is  assertthat  getfeaturestate  loadedfeaturestate  savedfeaturestate  setparameter  setfeaturestate  usernameactivationstrategy  staterepository
__label__nflaky args  number  test  int  range  fail  high  check  range  args  number  testintrangefailhigh  checkrange
__label__flaky @  close  trx  coord  client  get  store  get  time  local  oozie  could  not  update  db .   exception  expected  because  action  is  not  in  terminal  state .   get  status  -test  coord  rerun-  c  get  coord  client  get  error  code  get  begin  trx  coordinator  action  re  run  coord  commit  trx  action  num  rest  constants  print  stack  trace  e  store2  error  code  should  be  e1018  when  action  is  not  in  terminal  state .   test  coord  rerun  actions  neg2  assert  equals  store  add  record  to  job  table  integer  job  id  services  fail  coordinator  job  ex  add  record  to  action  table  equals  action  id  0000000-  to  string  error  code  action2  coord-rerun-action1 . xml  get  coordinator  action  @  closetrx  coordclient  getstore  gettime  localoozie  could not update db .   exception expected because action is not in terminal state .   getstatus  -testcoordrerun-c  getcoordclient  geterrorcode  get  begintrx  coordinatoraction  reruncoord  committrx  actionnum  restconstants  printstacktrace  e  store2  error code should be e1018 when action is not in terminal state .   testcoordrerunactionsneg2  assertequals  store  addrecordtojobtable  integer  jobid  services  fail  coordinatorjob  ex  addrecordtoactiontable  equals  actionid  0000000-  tostring  errorcode  action2  coord-rerun-action1 . xml  getcoordinatoraction
__label__nflaky renderable  assets  controller  helper  make  sure  we  get  the  correct  result .  .  .   assets  controller  when  result  captor  result  result  mime  types  get  renderable  response  streams  verify   / webjar_asset . txt  ok  render  result2  serve  web  jars  finalize  headers  without  flash  and  session  cookie  byte  array  output  stream  then  return  capture  assert  equals  normalize  path  without  leading  slash  context  renderable  eq  http  cache  toolkit  get  value  get  status  code  mockito  results  mock  get  output  stream  to  string  webjar_asset  ninja  properties  test  serve  web  jars  get  request  path  renderable  assetscontrollerhelper   make sure we get the correct result .  .  .   assetscontroller  when  resultcaptor  result  result  mimetypes  getrenderable  responsestreams  verify   / webjar_asset . txt  ok  render  result2  servewebjars  finalizeheaderswithoutflashandsessioncookie  bytearrayoutputstream  thenreturn  capture  assertequals  normalizepathwithoutleadingslash  contextrenderable  eq  httpcachetoolkit  getvalue  getstatuscode  mockito  results  mock  getoutputstream  tostring  webjar_asset  ninjaproperties  testservewebjars  getrequestpath
__label__flaky check  subworkflow  lib  helper  child  libs1  expected  libs1  expected  libs2  expected  libs3  expected  libs4  expected  libs5  test  create  proto  conf  with  sub  workflow  lib4  same . jar  child  libs3  parent2 . jar  child  libs2  child  libs5  child1 . jar  child  libs4  inherit  wf  false  parent  libs2  parent  libs3  parent  libs1  parent1 . jar  parent  libs4  parent  libs5  inherit  child2 . so  true  checksubworkflowlibhelper  childlibs1  expectedlibs1  expectedlibs2  expectedlibs3  expectedlibs4  expectedlibs5  testcreateprotoconfwithsubworkflowlib4  same . jar  childlibs3  parent2 . jar  childlibs2  childlibs5  child1 . jar  childlibs4  inheritwf  false  parentlibs2  parentlibs3  parentlibs1  parent1 . jar  parentlibs4  parentlibs5  inherit  child2 . so  true
__label__nflaky e  succeeds  once  then  fails  returning  string  should  not  have  succeeded  twice  succeeds  once  then  fails  returning  string  idempotent  impl2  get  message  io  exception  and  this  method  is  not  idempotent  assert  equals  impl1  retry  proxy  fail  io  exception  and  this  method  is  idempotent .   test  failover  on  network  exception  idempotent  operation  type  of  exception  to  fail  with  retry  policies  unreliable  create  failover  on  network  exception  new  flip  flop  proxy  provider  e  succeedsoncethenfailsreturningstring  should not have succeeded twice  succeedsoncethenfailsreturningstringidempotent  impl2  getmessage   ioexception and this method is not idempotent  assertequals  impl1  retryproxy  fail   ioexception and this method is idempotent .   testfailoveronnetworkexceptionidempotentoperation  typeofexceptiontofailwith  retrypolicies  unreliable  create  failoveronnetworkexception  newflipflopproxyprovider
__label__flaky hdfs11  submit  reader  get  job  info  local  oozie  conf  in  path  get  status  sleep  job  id1  get  test  case  dir   / workflow . xml  file: /  /   workflow . xml  test  redeploy  workflow  job  wait  for  rerun-el-wf . xml  wf  client  rerun-elerr-wf . xml  start  assert  equals  get  client  re  run   / check  oozie  client  io  utils  get  test  user  copy  char  stream  set  property  get  resource  as  reader  create  configuration  to  string  writer  file  evaluate  get  fs  test  case  dir  check  dir  hdfs11  submit  reader  getjobinfo  localoozie  conf  inpath  getstatus  sleep  jobid1  gettestcasedir   / workflow . xml  file: /  /   workflow . xml  testredeploy  workflowjob  waitfor  rerun-el-wf . xml  wfclient  rerun-elerr-wf . xml  start  assertequals  getclient  rerun   / check  oozieclient  ioutils  gettestuser  copycharstream  setproperty  getresourceasreader  createconfiguration  tostring  writer  file  evaluate  getfstestcasedir  checkdir
__label__nflaky ftp: /  / google . com / fake  google . com  http: /  / google . com / foobar  google . com:443 /   parsed  result  type  do  test  result  gopher: /  / google . com / obsolete  test  uri  http: /  / google . com:443 /   http: /  / google . com:443 / foobar  google . com:443 / foobar  google . com:443  http: /  / google . com:443  http: /  / google . com  https: /  / google . com  http: /  / google . com  https: /  / google . com:443 / foobar  ftp: /  / google . com / fake  google . com  http: /  / google . com / foobar  google . com:443 /   parsedresulttype  dotestresult  gopher: /  / google . com / obsolete  testuri  http: /  / google . com:443 /   http: /  / google . com:443 / foobar  google . com:443 / foobar  google . com:443  http: /  / google . com:443  http: /  / google . com  https: /  / google . com  http: /  / google . com  https: /  / google . com:443 / foobar
__label__flaky init  a  generate  child  id  generate  id  destroy  get  id  assert  equals  counter  services  child  id  uuid  get  child  name  application  type  random  test  child  id  set  system  property  get  uuid  service  id  init  a  generatechildid  generateid  destroy  getid  assertequals  counter  services  childid  uuid  getchildname  applicationtype  random  testchildid  setsystemproperty  get  uuidservice  id
__label__nflaky test  metrics  system  init  test  source  sa2  ms  test  register  source  without  name  sa  get  source  adapter  ts2  assert  not  null  test  source2  the  class  name  will  be  used  as  the  name  shutdown  ts  register  testmetricssystem  init  testsource  sa2  ms  testregistersourcewithoutname  sa  getsourceadapter  ts2  assertnotnull  testsource2   the class name will be used as the name  shutdown  ts  register
__label__flaky system_  mode  end_  points  is_  security_  enabled  get  context  url  oozie  url  get  system  mode  set  system  mode  assert  equals  wc  call  test  safe  mode  system  mode  servlet_  classes  run  test  system_mode  end_points  is_security_enabled  getcontexturl  oozieurl  getsystemmode  setsystemmode  assertequals  wc  call  testsafemode  systemmode  servlet_classes  runtest
__label__nflaky test  unknown  class  assert  service  creation  fails  no . such . classname  testunknownclass  assertservicecreationfails  no . such . classname
__label__flaky test  skip  filter  test  qualifier  one-2  f  rows_  two  to  bytes  kvs  set  filter  bytes  qualifiers_  two  verify  scan  full  families  should  only  get  rows  from  second  group   and  all  keys  values  compare  op  test  row  two-3  test  row  two-2  testskipfilter  testqualifierone-2  f  rows_two  tobytes  kvs  setfilter  bytes  qualifiers_two  verifyscanfull  families   should only get rows from second group  and all keys  values  compareop   testrowtwo-3   testrowtwo-2
__label__nflaky release  set  max  total  get  connection  assert  assert  true  assert  not  null  get  set  max  per  route  verify  entry4  close  entry2  get  leased  entry3  update  state  conn2  entry1  test  stateful  connection  redistribution  on  per  route  max  limit  conn1  assign  connection  argument  matchers  somehost  pool  assert  equals  some-other-stuff  totals  future3  assert  same  is  done  future4  any  future5  some-stuff  never  future1  future2  mockito  close  mode  mock  lease  get  pending  get  total  stats  get  available  release  setmaxtotal  getconnection  assert  asserttrue  assertnotnull  get  setmaxperroute  verify  entry4  close  entry2  getleased  entry3  updatestate  conn2  entry1  teststatefulconnectionredistributiononperroutemaxlimit  conn1  assignconnection  argumentmatchers  somehost  pool  assertequals  some-other-stuff  totals  future3  assertsame  isdone  future4  any  future5  some-stuff  never  future1  future2  mockito  closemode  mock  lease  getpending  gettotalstats  getavailable
__label__flaky check  coord  action  get  time  date  utils  parse  date  oozie  tz  add  record  to  job  table  call  job  id  @1  test  action  mater  2009-03-06  t010:00  z  2009-03-11  t10:00  z  -test  action  mater-  c  action  0000000-  start  time  end  time  checkcoordaction  gettime  dateutils  parsedateoozietz  addrecordtojobtable  call  jobid  @1  testactionmater  2009-03-06t010:00z  2009-03-11t10:00z  -testactionmater-c  action  0000000-  starttime  endtime
__label__nflaky store  password   / test . p12  get  resource  to  char  array  get  local  port  submit  server  socket  new  single  thread  executor  executors  server  ssl  context  get  server  socket  factory  client  socket  assert  bind  key  password  assert  not  null  nopassword  create  boolean  ssl  context  builder  close  connect  localhost  start  handshake  local  port  load  key  material  load  trust  material  resource2  thrown  set  so  timeout  test  ssl  handshake  server  not  trusted   / test-server . p12  resource1  accept  call  get  socket  factory  expect  create  socket  build  to  milliseconds  int  bound  client  ssl  context  socket  timeout  get  session  create  server  socket  storepassword   / test . p12  getresource  tochararray  getlocalport  submit  serversocket  newsinglethreadexecutor  executors  serversslcontext  getserversocketfactory  clientsocket  assert  bind  keypassword  assertnotnull  nopassword  create  boolean  sslcontextbuilder  close  connect  localhost  starthandshake  localport  loadkeymaterial  loadtrustmaterial  resource2  thrown  setsotimeout  testsslhandshakeservernottrusted   / test-server . p12  resource1  accept  call  getsocketfactory  expect  createsocket  build  tomillisecondsintbound  clientsslcontext  socket  timeout  getsession  createserversocket
__label__flaky build  test  model  test  table  create  and  delete  pb  assert  false  admin  table  exists  delete  table2  put  make  sure  h  base  concurs  get  client  model  check  model  retrieve  the  schema  and  validate  it  get  code  delete  the  table  get  body  schema  path  constants  assert  equals  test  table  schema  model  get  object  from  message   /   make  sure  h  base  concurs   and  wait  for  the  table  to  come  online   / schema  response  create  protobuf  output  enable  table  create  the  table  buildtestmodel  testtablecreateanddeletepb  assertfalse  admin  tableexists  delete  table2  put   make sure hbase concurs  get  client  model  checkmodel   retrieve the schema and validate it  getcode   delete the table  getbody  schemapath  constants  assertequals  testtableschemamodel  getobjectfrommessage   /    make sure hbase concurs  and wait for the table to come online   / schema  response  createprotobufoutput  enabletable   create the table
__label__nflaky x   \ %a   \ %-12 . 550 ( hello   \ %class{ . 4 ? } )   add  test  simple  p2  a  x  token  assert  equals  tokenize  witness  hello  tl   . 4 ?   -12 . 550  class  ol  x  \ %a  \ %-12 . 550 ( hello  \ %class{ . 4 ? } )   add     testsimplep2  a  x   token  assertequals  tokenize  witness  hello   tl   . 4 ?   -12 . 550  class  ol
__label__flaky set  job  id  get  time   / v1 / jobs  parse  date  utc  date  utils  coord3@1  cal  array  test  default  status  coordinator  action  set  id  create_  time  set  created  time  coord3  adding  coordinator  action  #4  to  coord#3  run  test  set  time  add  set  nominal  time  calendar  assert  equals  execute  set  status  action  insert  call  size  bundle  name  get  instance  _request  to  server  bulk  request  jpa  service  bundle=  action4  setjobid  gettime   / v1 / jobs  parsedateutc  dateutils  coord3@1  cal  array  testdefaultstatus  coordinatoraction  setid  create_time  setcreatedtime  coord3   adding coordinator action #4 to coord#3  runtest  settime  add  setnominaltime  calendar  assertequals  execute  setstatus  actioninsert  call  size  bundlename  getinstance  _requesttoserver  bulkrequest  jpaservice  bundle=  action4
__label__nflaky test  writable  test  simple  versioned  writable  test  writable  testwritable  testsimpleversionedwritable  testwritable
__label__flaky <configuration>  <name>a< / name>  < / property>  get  actions  <value>  a< / value>  sub  workflow  action  executor  http: /  / localhost:8080 / oozie  proto  conf  create  base  workflow  get  workflow  client  assert  not  null  w  get  action  get  base  proto  conf  test  sub  workflow  conf  creation  workflow  <sub-workflow  xmlns= \  ' uri:oozie:workflow:0 . 1 \  ' >  oozie  client  <property>  sub  workflow  set  conf  < / configuration>  <app-path>hdfs: /  / foo:9000 / user / bar / workflow . xml< / app-path>  < / sub-workflow>        <configuration>            <name>a< / name>          < / property>  getactions            <value>a< / value>  subworkflowactionexecutor  http: /  / localhost:8080 / oozie  protoconf  createbaseworkflow  getworkflowclient  assertnotnull  w  get  action  getbaseprotoconf  testsubworkflowconfcreation  workflow  <sub-workflow xmlns= \  ' uri:oozie:workflow:0 . 1 \  ' >  oozieclient          <property>  subworkflow  setconf        < / configuration>        <app-path>hdfs: /  / foo:9000 / user / bar / workflow . xml< / app-path>  < / sub-workflow>
__label__nflaky 10 . 119 . 103 . 112  10 . 113 . 221 . 222  10 . 222 . 103 . 121  is  in  the  list  10 . 113 . 221 . 221  assert  false  10 . 222 . 103 . 121  is  not  in  the  list  10 . 221 . 102 . 0 / 23  cipl  ips  10 . 222 . 103 . 121  thread  sleep  create  file  with  entries  remove  file  assert  true  ips . txt  test  file  based  ip  list  ips2  test  removal  with  sleep  for  cache  timeout  10 . 222 . 0 . 0 / 16  10 . 113 . 221 . 222  is  in  the  list  10 . 113 . 221 . 222  is  not  in  the  list  is  in  10 . 119 . 103 . 112  10 . 113 . 221 . 222  10 . 222 . 103 . 121 is  in the list  10 . 113 . 221 . 221  assertfalse  10 . 222 . 103 . 121 is not in the list  10 . 221 . 102 . 0 / 23  cipl  ips  10 . 222 . 103 . 121  thread  sleep  createfilewithentries  removefile  asserttrue  ips . txt  testfilebasediplist  ips2  testremovalwithsleepforcachetimeout  10 . 222 . 0 . 0 / 16  10 . 113 . 221 . 222 is in the list  10 . 113 . 221 . 222 is not in the list  isin
__label__flaky add  next  row_1  qualifier_1  row_2  row_3  row_4  assert  equals  get  row  test  scanner  put  puts  bytes  assert  null  column_1  assert  true  assert  not  null  equals  remote  table  scanner  value_1  get  scanner  results  close  add  next  row_1  qualifier_1  row_2  row_3  row_4  assertequals  getrow  testscanner  put  puts  bytes  assertnull  column_1  asserttrue  assertnotnull  equals  remotetable  scanner  value_1  getscanner  results  close
__label__nflaky key1  config  property  >  default  value  key2  conf / overlayed . conf  key3  get  integer  conf / overlayed . empty . conf  null  value  test1  system  precedence  clear  property  ninja  mode  default  current  no  value  anywhere  get  get  boolean  boolean  default  value  >  nothing  current  value  >  system  property  is  assert  that  2  system  set  property  true  ninja  properties  system  property  >  config  property  key1   configproperty > defaultvalue  key2  conf / overlayed . conf  key3  getinteger  conf / overlayed . empty . conf  nullvalue  test1  system  precedence  clearproperty  ninjamode  default  current   no value anywhere  get  getboolean  boolean   defaultvalue > nothing   currentvalue > systemproperty  is  assertthat  2  system  setproperty  true  ninjaproperties   systemproperty > configproperty
__label__flaky now  delete   \  '   c \  '   and  make  sure  i  don \  ' t  get  entries  from   \  '   b \  '  .   h  constants  conf  get  region  name  put  get  bytes  bytes  get  table  desc  file  system  create  region  name  hri  info  add  last  mr  log  first  row  in  c  to  bytes  rootdir  write  rows  for  three  tables   \  '   a \  '     \  '   b \  '    and   \  '   c \  '  .   get  row  h  region  mkdirs  interval  up  flush  size  else  we  bind  up  when  we  use  default  catalog  flush  of  16k .   next  assert  we  get  null  back   ( pass  -1 )  .   find  row  keys  scan  catalog_  family  delete  test  using  meta  and  binary  h  region  info  get  htd  close  writables  c  regioninfo_  qualifier  clear  filesystem  flushcache  set  mem  store  flush  size  make  qualified  create  h  region  get  scanner     now delete  \  ' c \  '  and make sure i don \  ' t get entries from  \  ' b \  '  .   hconstants  conf  getregionname  put  getbytes  bytes  gettabledesc  filesystem  createregionname  hri  info  add  last  mr  log  firstrowinc  tobytes  rootdir   write rows for three tables  \  ' a \  '    \  ' b \  '   and  \  ' c \  '  .   getrow  hregion  mkdirs  interval   up flush size else we bind up when we use default catalog flush of 16k .   next   assert we get null back  ( pass -1 )  .   findrow  keys  scan  catalog_family  delete  testusingmetaandbinary  hregioninfo  get  htd  close  writables  c  regioninfo_qualifier  clear  filesystem  flushcache  setmemstoreflushsize  makequalified  createhregion  getscanner
__label__nflaky handler  init  kn  destroy  get  realm  assert  equals  kerberos  test  utils  kerberos  name  remove  props  kerberos  authentication  handler  get  rule  mechanism  assert  get  new  authentication  handler  set  rule  mechanism  get  server  principal  mit  get  default  properties  get  rules  set  rules  default  destroy  handler  created  in  set  up (  )   test  null  properties  handler  init  kn  destroy  getrealm  assertequals  kerberostestutils  kerberosname  remove  props  kerberosauthenticationhandler  getrulemechanism  assert  getnewauthenticationhandler  setrulemechanism  getserverprincipal  mit  getdefaultproperties  getrules  setrules  default   destroy handler created in setup (  )   testnullproperties
__label__flaky app  set  rest  constants  conf  get  file  system  test  re  run  app  path  oozie  client  get  test  user  _test  action  mkdirs  create  workflow . xml  to  string  close  get  fs  test  case  dir  app  set  restconstants  conf  getfilesystem  testrerun  apppath  oozieclient  gettestuser  _testaction  mkdirs  create  workflow . xml  tostring  close  getfstestcasedir
__label__nflaky keys  put  remove  num  elements  expected  all  entries  to  be  removed  capacity  test  additions  and  removals  key  assert  assert  true  get  add  keys  empty   but  found  debug  log  visit  all  value  of  is  empty  assert  equals  store  k  expected  the  store  to  be  accept  integer  fail  generating  contains  elements .   num_  keys  keys  put  remove  numelements  expected all entries to be removed  capacity  testadditionsandremovals  key   assert  asserttrue  get  add   keys  empty  but found   debug  log  visitall  valueof  isempty  assertequals  store  k  expected the store to be   accept  integer  fail  generating   contains   elements .   num_keys
__label__flaky check  subworkflow  lib  helper  child  libs1  expected  libs1  expected  libs2  expected  libs3  expected  libs4  expected  libs5  same . jar  test  create  proto  conf  with  sub  workflow  lib3  child  libs3  parent2 . jar  child  libs2  child  libs5  child1 . jar  child  libs4  inherit  wf  parent  libs2  parent  libs3  parent  libs1  parent1 . jar  parent  libs4  parent  libs5  inherit  child2 . so  true  checksubworkflowlibhelper  childlibs1  expectedlibs1  expectedlibs2  expectedlibs3  expectedlibs4  expectedlibs5  same . jar  testcreateprotoconfwithsubworkflowlib3  childlibs3  parent2 . jar  childlibs2  childlibs5  child1 . jar  childlibs4  inheritwf  parentlibs2  parentlibs3  parentlibs1  parent1 . jar  parentlibs4  parentlibs5  inherit  child2 . so  true
__label__nflaky local  fs  assert  true  test_  root_  dir  src  path  mkdirs  test  rename  src  test  rename  dir / test  rename  dst  verify  rename  test  rename  file  into  dir  file  dst  path  localfs  asserttrue  test_root_dir  srcpath  mkdirs  testrenamesrc  testrenamedir / testrenamedst  verifyrename  testrenamefileintodirfile  dstpath
__label__flaky assert  false  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  is  pending  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  test  coord  status  transit  service  running1  assert  not  null  get  coordinator  action  end  current  date  plus  month  job  wait  for  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  coordinator  job  job  id  services  runnable  coord-action-get . xml  job  jpa  service  evaluate  assertfalse  getcurrentdateafterincrementinginmonths  getid  run  dateutils  ispending  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  testcoordstatustransitservicerunning1  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  job  waitfor  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  coordinatorjob  jobid  services  runnable  coord-action-get . xml  job  jpaservice  evaluate
__label__nflaky watcher  restart  context  property  verify  what  actually  got  to  ninja  machine  project  run  is  assert  that   / test  execute  target / classes  setup  machine  and  watcher  stubs  get  value  times  jvm  arguments  captor  dev  -  dninja . mode=dev  machine  -  dninja . context= / test  get  ninja  run  mojo  verify  watcher  restart  contextproperty   verify what actually got to ninja machine  project  run  is  assertthat   / test  execute  target / classes  setupmachineandwatcherstubs  getvalue  times  jvmargumentscaptor  dev  -dninja . mode=dev  machine  -dninja . context= / test  get  ninjarunmojo  verify
__label__flaky i  nodes  in  path  i  node  get  path  components  components  resolve  get  the  inodes  by  resolving  the  path  of  a  normal  file  inodes  sub1  dir     nodes  in  path=  assert  snapshot  assert  true  nodes  in  path  test  non  snapshot  path  i  nodes  get  path  names  file1=  the  returned  nodes  in  path  should  be  non-snapshot  when  identifying  the  parent  i  node  of  a  given  path .   assert  equals  the  last  i  node  should  be  associated  with  file1  the  number  of  inodes  should  be  equal  to  components . length  when  identifying  the  i  node  for  a  given  path .   get  full  path  name  names  fsdir  to  string  file1  get  i  nodes  inodesinpath  inode  getpathcomponents  components  resolve   get the inodes by resolving the path of a normal file  inodes  sub1  dir    nodesinpath=  assertsnapshot  asserttrue  nodesinpath  testnonsnapshotpathinodes  getpathnames  file1=   the returned nodesinpath should be non-snapshot   when identifying the parent inode of a given path .   assertequals   the last inode should be associated with file1   the number of inodes should be equal to components . length   when identifying the inode for a given path .   getfullpathname  names  fsdir  tostring  file1  getinodes
__label__nflaky release  times  assert  assert  not  null  get  verify  close  entry2  entry3  get  leased  conn3  conn2  entry1  conn1  assign  connection  argument  matchers  somehost  pool  assert  equals  totals  future3  any  never  future1  future2  mockito  otherhost  close  mode  mock  lease  get  pending  test  lease  release  get  total  stats  get  available  release  times  assert  assertnotnull  get  verify  close  entry2  entry3  getleased  conn3  conn2  entry1  conn1  assignconnection  argumentmatchers  somehost  pool  assertequals  totals  future3  any  never  future1  future2  mockito  otherhost  closemode  mock  lease  getpending  testleaserelease  gettotalstats  getavailable
__label__flaky endtime=2011-12-01  t05:00  conn  set  request  method  is_  security_  enabled  test  coord  change  put  set  request  property  endtime=2011-12-01  t05:00  z  concurrency=200   / v1 / job / *  content-type  run  test  mock  coordinator  engine  service  endtime=2011-12-01  t05:00  z;concurrency=200  rest  constants  open  connection  http  servlet  response  assert  equals  params  url  put  call  size  get  response  code  reset  create  url  change  value  set  do  output  endtime=2011-12-01t05:00  conn  setrequestmethod  is_security_enabled  testcoordchange  put  setrequestproperty  endtime=2011-12-01t05:00z  concurrency=200   / v1 / job / *  content-type  runtest  mockcoordinatorengineservice  endtime=2011-12-01t05:00z;concurrency=200  restconstants  openconnection  httpservletresponse  assertequals  params  url  put  call  size  getresponsecode  reset  createurl  changevalue  setdooutput
__label__nflaky process  watch  event  data  mock  no  prior  active  first  sync  connected  should  not  do  anything  when  zk_  lock_  name  notify  fatal  error  assert  ids  create  create  znode  success .   become  master  and  monitor  verify  exist  call  any  boolean  mock  app  then  return  any  string  unexpected  zookeeper  watch  event  state:  auth  failed  enter  neutral  mode  count  process  result  code  test  process  callback  event  none  create  mode  get  type  become  active  error  event  results  in  fatal  error  mock  already  in  safe  mode  above .   should  not  enter  safe  mode  again  disconnection  should  enter  safe  mode  assert  false  times  only  1  state  change  callback  is  called  at  a  time  assert  true  mock  event  verify  constructor  int  value  assert  equals  elector  any  is  monitor  lock  node  pending  mock  zk  get  state  once  in  initial  join  election  and  one  now  mockito  join  election  call  to  create  lock  znode  event  exists  re-connection  should  monitor  master  status  processwatchevent  data  mocknoprioractive   first syncconnected should not do anything  when  zk_lock_name  notifyfatalerror  assert  ids  create   create znode success .  become master and monitor  verifyexistcall  anyboolean  mockapp  thenreturn  anystring  unexpected zookeeper watch event state: authfailed  enterneutralmode  count  processresult  code  testprocesscallbackeventnone  createmode  gettype  becomeactive   error event results in fatal error  mock   already in safe mode above .  should not enter safe mode again   disconnection should enter safe mode  assertfalse  times   only 1 state change callback is called at a time  asserttrue  mockevent  verify   constructor  intvalue  assertequals  elector  any  ismonitorlocknodepending  mockzk  getstate   once in initial joinelection and one now  mockito  joinelection   call to create lock znode  event  exists   re-connection should monitor master status
__label__flaky unexpected  exception  f-> ( 2 3 )    ( 2 3 ) ->j  add  node  def  print  stack  trace  e  f  one  j  test  simple  fork  join  k  kill  three  two  as  list  wf  fail  invoke  fork  join  parser  four  <worklfow-app / >  dummy  conf  end  arrays  unexpected exception        f-> ( 2 3 )        ( 2 3 ) ->j        addnode  def  printstacktrace  e  f  one  j  testsimpleforkjoin  k  kill  three  two  aslist  wf  fail  invokeforkjoin  parser  four  <worklfow-app / >  dummyconf  end  arrays
__label__nflaky offer  c  size  fcq  assert  true  it \  ' s  full  test  offer  fails  when  full  assert  false  assert  equals  mock  call  offer  c  size  fcq  asserttrue   it \  ' s full  testofferfailswhenfull  assertfalse  assertequals  mockcall
__label__flaky init  get  name  set  get  conf  oozie . service .   proxy  user  service . proxyuser . foo . groups  destroy  conf  *  services     as  list  services  fail  string  utils  test  wrong  config  hosts  join  arrays  init  getname  set  getconf  oozie . service . proxyuserservice . proxyuser . foo . groups  destroy  conf  *  services     aslist  services  fail  stringutils  testwrongconfighosts  join  arrays
__label__nflaky test  kerberos  delegation  token  authenticator  test  kerberos  delegation  token  authenticator  with  do  as  testkerberosdelegationtokenauthenticator  testkerberosdelegationtokenauthenticatorwithdoas
__label__flaky add  record  to  bundle  action  table  bundle  action  jpa  add  record  to  bundle  job  table  bundle  id  get  id  assert  equals  execute  add  record  to  coord  job  table  with  bundle  call  sleep  coordinator  job  services  test  bundle  rerun  killed  coordinator  assert  not  null  get  action1  job  job  get  pending  jpa  service  ba  addrecordtobundleactiontable  bundleactionjpa  addrecordtobundlejobtable  bundleid  getid  assertequals  execute  addrecordtocoordjobtablewithbundle  call  sleep  coordinatorjob  services  testbundlererunkilledcoordinator  assertnotnull  get  action1  job  job  getpending  jpaservice  ba
__label__nflaky simulated  time  compare  get  name  }-clean .  \ %i  bytes  per  period  f0  f1  compare  to  simulated  number  of  periods  system  2016-03-05  00:14:39  cet  context  set  max  file  size   \  \ d{4}- \  \ d{2}- \  \ d{2}-clean (  \  \  .  \  \ d )   collections  daily  size  based  rollover  with  size  cap  s0  s1  compute  slash  count  check  file  count  found  files  ticks  per  period  status  printer  file  name  pattern  max  history  sort  params  size  cap  expected  file  count  print  file  size  random  output  dir   /  \ %d{  tbfnatp  log  over  multiple  periods  to  string  find  files  by  pattern  daily_  date_  pattern  size  and  time  based  fnatp  simulatedtime  compare  getname  }-clean .  \ %i  bytesperperiod  f0  f1  compareto  simulatednumberofperiods  system   2016-03-05 00:14:39 cet  context  setmaxfilesize   \  \ d{4}- \  \ d{2}- \  \ d{2}-clean (  \  \  .  \  \ d )   collections  dailysizebasedrolloverwithsizecap  s0  s1  computeslashcount  checkfilecount  foundfiles  ticksperperiod  statusprinter  filenamepattern  maxhistory  sort  params  sizecap  expectedfilecount  print  filesize  randomoutputdir   /  \ %d{  tbfnatp  logovermultipleperiods  tostring  findfilesbypattern  daily_date_pattern  sizeandtimebasedfnatp
__label__flaky lm  job  conf  prepare  block  < / prepare>  user . name  when  there  is  prepare  block  in  workflow  xml  fs  create  job  conf  oozie . action . prepare . xml  1@a  assert  true  <prepare>  <mkdir  path= \  '    \  '  / >  get  get  name  node  uri  set  action  conf  1@a-0  action  dir  get  file  system  test  setup  launcher  info  with  non  empty  prepare  xml  get  authority  services  1  get  test  user  new  dir  equals  fs . default . name  setup  launcher  info  setting  up  the  job  configuration  get  fs  test  case  dir  lm  jobconf  prepareblock  < / prepare>  user . name   when there is prepare block in workflow xml  fs  createjobconf  oozie . action . prepare . xml  1@a  asserttrue  <prepare>  <mkdir path= \  '    \  '  / >  get  getnamenodeuri  set  actionconf  1@a-0  actiondir  getfilesystem  testsetuplauncherinfowithnonemptypreparexml  getauthority  services  1  gettestuser  newdir  equals  fs . default . name  setuplauncherinfo   setting up the job configuration  getfstestcasedir
__label__nflaky get  bytes  transferred  rw  stuff;  codec  test  utils  more  stuff;  channel  assert  inbuf  get  channel  pos  stuff;  more  stuff;  a  lot  more  stuff !   a  lot  more  stuff !  !  !   close  fchannel  is  completed  testfile  standard  charsets  length  bytes  read  assert  equals  create  temp  file  decoder  fill  transfer  read  from  file  metrics  test  decoding  file  with  buffered  session  data  getbytestransferred  rw  stuff;   codectestutils  more stuff;   channel  assert  inbuf  getchannel  pos  stuff; more stuff; a lot more stuff !   a lot more stuff !  !  !   close  fchannel  iscompleted  testfile  standardcharsets  length  bytesread  assertequals  createtempfile  decoder  fill  transfer  readfromfile  metrics  testdecodingfilewithbufferedsessiondata
__label__flaky bundle  job  get  executor  add  record  to  bundle  action  table  get  id  get  status  assert  not  null  get  job  init  false  add  record  to  bundle  job  table  destroy  assert  equals  test  bundle  rerun  in  suspended  with  error  services  execute  add  record  to  coord  job  table  call  services  coordinator  job  set  system  property  status  transit  service  action1  job  action2  jpa  service  bundlejobgetexecutor  addrecordtobundleactiontable  getid  getstatus  assertnotnull  get  job  init  false  addrecordtobundlejobtable  destroy  assertequals  testbundlereruninsuspendedwitherror  services  execute  addrecordtocoordjobtable  call  services  coordinatorjob  setsystemproperty  statustransitservice  action1  job  action2  jpaservice
__label__nflaky regex  validate  jsr303  with  optional  build  dto  context  length  -  too  long  do  check  validation  failed  length  validation  with  optional  failed  length  regex  validatejsr303withoptional  builddto  context  length - too long  docheckvalidationfailedlength  validationwithoptionalfailedlength
__label__flaky conn  set  request  method  is_  security_  enabled  test  job  info  put  assert  true  get  content-type  run  test  json  tags  rest  constants  open  connection  mock  dag  engine  service  http  servlet  response  assert  equals  parse  params  get  input  stream  url  json  value  call   / v0 / job / *  get  header  field  size  obj  get  get  response  code  reset  create  url  starts  with  conn  setrequestmethod  is_security_enabled  testjobinfo  put  asserttrue  get  content-type  runtest  jsontags  restconstants  openconnection  mockdagengineservice  httpservletresponse  assertequals  parse  params  getinputstream  url  jsonvalue  call   / v0 / job / *  getheaderfield  size  obj  get  getresponsecode  reset  createurl  startswith
__label__nflaky multi  service  fs2  add  delegation  tokens  credentials  create  file  system  for  service  name  fs1  fs4  fs3  test  fs  with  nested  duplicates  children  fs1  b  down:  multi-filter-multi-filter-filter-fs4 .   number  of  tokens  fs1+fs2+fs4+multifs   ( fs3=0 )   assert  not  null  token2  we  had  added  its  token  to  credentials  add  token  super  multi  fs  multi  token  fs  renewer  service2  service1  does  not  have  its  own  token  service4  has  its  own  token  assert  equals  assert  same  single  token  fs1  multi  fs  has  no  tokens  single  token  fs4  single  token  fs2  get  token  mock  verify  token  fetch  multiservice  fs2  adddelegationtokens  credentials  createfilesystemforservicename  fs1  fs4  fs3  testfswithnestedduplicateschildren  fs1b   down: multi-filter-multi-filter-filter-fs4 .   numberoftokens   fs1+fs2+fs4+multifs  ( fs3=0 )   assertnotnull  token2   we had added its token to credentials  addtoken  supermultifs  multitokenfs  renewer  service2  service1   does not have its own token  service4   has its own token  assertequals  assertsame  singletokenfs1  multifs   has no tokens  singletokenfs4  singletokenfs2  gettoken  mock  verifytokenfetch
__label__flaky play  handler  increment  and  get  android  play  it  back  header  entries  verify  the  peer  received  what  was  expected  type_  rst_  stream  cola  accept  frame  stream  get  error  code  type_  headers  peer  receive  count  reply  protocol_  error  syn_  reply  take  frame  rst  stream  banana  a  receive  b  c  open  socket  int  value  remote  double  syn  stream  assert  equals  rst_  stream  headers  mode  get  request  headers  send  frame  build  write  the  mocking  script  syn  stream  play  handler  incrementandget  android   play it back  headerentries   verify the peer received what was expected  type_rst_stream  cola  acceptframe  stream  geterrorcode  type_headers  peer  receivecount  reply  protocol_error   syn_reply  takeframe  rststream  banana  a  receive  b  c  opensocket  intvalue  remotedoublesynstream  assertequals   rst_stream  headersmode  getrequestheaders  sendframe  build   write the mocking script  synstream
__label__nflaky thinks  that  it  is  single  rack  assert  single  switch  n1  n2  resolve  l1  dump  topology  get  switch  map  conf  unknown  n1= / r1 n2= / r2  static  mapping  test  read  nodes  from  config  get  resolved  info  add  mapping  set  switch  map  log  topology  new  instance  assert  equals  set  conf   / r1   / r2  assert  null  size  network  topology   thinks that it is single rack  assertsingleswitch  n1  n2  resolve  l1  dumptopology  getswitchmap  conf  unknown  n1= / r1 n2= / r2  staticmapping  testreadnodesfromconfig  get  resolved  info  add  mapping  set  switchmap  log  topology  newinstance  assertequals  setconf   / r1   / r2  assertnull  size  networktopology
__label__flaky get  name  get  context  url  oozie  url  false  admin  run  assert  equals  oozie . authentication . simple . anonymous . allowed  authenticator4  test  test  client  with  custom  authenticator  args  call  -oozie  assert  true  set  system  property  authenticator . class  -status  run  test  getname  getcontexturl  oozieurl  false  admin  run  assertequals  oozie . authentication . simple . anonymous . allowed  authenticator4test  testclientwithcustomauthenticator  args  call  -oozie  asserttrue  setsystemproperty  authenticator . class  -status  runtest
__label__nflaky get  class  fs . trash . classname  assert  true  set  class  equals  conf  test  plugged  trash  policy  test  pluggable  trash  trash  get  trash  policy  getclass  fs . trash . classname  asserttrue  setclass  equals  conf   test plugged trashpolicy  testpluggabletrash  trash  gettrashpolicy
__label__flaky status  half  of  it   so  no  checksum_  ok  reader  send  read  result  file_  size_  k  test  incomplete  read  never  read  and  check  eos  util  test  block  get  block  reader  verify  spy  close  status   half of it  so no checksum_ok  reader  sendreadresult  file_size_k  testincompleteread  never  readandcheckeos  util  testblock  getblockreader  verify  spy  close
__label__nflaky encode  mode:  kanji  1  1  1  0  0  1  0  1  0  0  0  1  1  1  0  1  1  0  1  0  0  1  0  1  1  1  0  1  0  1  0  0  0  1  0  1  0  1  0  1  0  1  test  encode  kanji  mode  1  1  1  1  1  1  1  0  1  1  0  1  0  1  1  1  0  0  1  0  0  <<  >>  1  0  0  0  0  0  1  0  0  1  1  1  0  0  1  0  0  0  0  0  1  put  mask  pattern:  0  1  1  1  1  1  1  1  0  0  1  0  1  0  0  1  1  1  1  1  1  1  0  1  0  0  0  0  1  1  1  1  1  1  0  1  1  1  0  1  0  1  0  1  1  0  1  0  0  0  1  0  1  1  1  0  1  0  1  0  1  0  0  0  nihon  in  kanji  encode  hint  type  qr  code  encoder  1  0  1  1  1  0  1  0  0  1  1  1  1  0  1  0  1  1  1  0  1  1  0  1  0  1  0  1  0  0  0  1  0  1  0  0  0  1  0  0  1  0  1  0  1  1  1  0  1  0  1  0  1  1  0  1  1  1  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  1  1  1  0  1  0  0  0  0  0  1  0  1  0  1  1  1  0  1  1  0  1  1  1  0  1  0  1  1  1  1  1  0  1  0  1  1  1  0  1  shift_  jis  0  1  1  0  0  1  1  0  1  1  0  1  0  1  1  1  0  1  0  0  1  1  1  1  1  1  1  1  0  0  0  0  0  1  0  0  0  1  0  0  1  1  0  0  0  0  0  0  0  0  1  0  1  0  0  0  1  0  0  0  1  0  1  matrix:  1  0  0  0  0  0  1  0  0  0  0  1  1  1  0  1  1  1  0  1  0  hints  expected  ec  level:  m  assert  equals    version:  1  1  0  0  0  0  0  1  0  0  0  1  0  0  0  1  0  0  0  1  1  1  1  0  1  1  1  0  1  0  0  0  0  1  0  1  0  1  0  1  0  1  0  to  string  1  1  1  1  1  1  1  0  1  0  1  0  1  0  1  1  1  1  1  1  1  error  correction  level  1  0  0  0  0  0  1  0  1  1  0  0  0  0  1  0  0  0  0  0  1  encode   mode: kanji     1 1 1 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0     1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1    testencodekanjimode   1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0    <<    >>     1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1    put   maskpattern: 0     1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1     0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0     1 1 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0     nihon in kanji  encodehinttype  qrcode  encoder   1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1     1 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0     1 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 0 1 0 1     0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0     1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1     1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1    shift_jis   0 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1     1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1     0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1     matrix:     1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 0    hints  expected   eclevel: m    assertequals     version: 1     1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1     1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0    tostring   1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1    errorcorrectionlevel   1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1
__label__flaky add  record  to  wf  action  table  get  num  days  to  not  be  purged  workflow  instance  get  status  add  record  to  coord  action  table  wf  action5  get  cmd  wf  job5  get  cmd  workflow  job  1  should  not  have  been  purged  workflow  action  4  should  not  have  been  purged  wf  action1  get  cmd  coordinator  action  5  should  not  have  been  purged  coord  action4  get  cmd  get  end  time  coord  action3  coord  action4  assert  not  null  coord  action5  coordinator  action  wf  job2  get  cmd  coord  action1  coord  action2  workflow  job  4  should  not  have  been  purged  wf  job1  get  cmd  execute  workflow  job  3  should  not  have  been  purged  workflow  action  2  should  not  have  been  purged  coordinator  job  1  coord  job  get  cmd  fail  coordinator  action  3  should  not  have  been  purged  workflow  action  coord  action3  get  cmd  succeeded  wf  action2  get  cmd  workflow  action  5  should  not  have  been  purged  coordinator  action  4  should  not  have  been  purged  get  id  coord  action5  get  cmd  coord  job  wf  job1  wf  job3  wf  job4  get  cmd  add  record  to  wf  job  table  wf  job2  wf  job5  get  wf  job4  test  purge  coord  with  wf  child2  more  than  limit  coord  action2  get  cmd  workflow  job  workflow  action  3  should  not  have  been  purged  coordinator  action  1  should  not  have  been  purged  wf  action3  get  cmd  wf  action4  get  cmd  coord  action1  get  cmd  assert  equals  wf  action1  coordinator  action  2  should  not  have  been  purged  wf  action2  add  record  to  coord  job  table  wf  action3  coordinator  job  should  not  have  been  purged  wf  action4  wf  action5  call  services  wf  job3  get  cmd  workflow  action  1  should  not  have  been  purged  coord-action-get . xml  workflow  job  5  should  not  have  been  purged  jpa  service  workflow  job  2  should  not  have  been  purged  addrecordtowfactiontable  getnumdaystonotbepurged  workflowinstance  getstatus  addrecordtocoordactiontable  wfaction5getcmd  wfjob5getcmd  workflow job 1 should not have been purged  workflow action 4 should not have been purged  wfaction1getcmd  coordinator action 5 should not have been purged  coordaction4getcmd  getendtime  coordaction3  coordaction4  assertnotnull  coordaction5  coordinatoraction  wfjob2getcmd  coordaction1  coordaction2  workflow job 4 should not have been purged  wfjob1getcmd  execute  workflow job 3 should not have been purged  workflow action 2 should not have been purged  coordinatorjob  1  coordjobgetcmd  fail  coordinator action 3 should not have been purged  workflowaction  coordaction3getcmd  succeeded  wfaction2getcmd  workflow action 5 should not have been purged  coordinator action 4 should not have been purged  getid  coordaction5getcmd  coordjob  wfjob1  wfjob3  wfjob4getcmd  addrecordtowfjobtable  wfjob2  wfjob5  get  wfjob4  testpurgecoordwithwfchild2morethanlimit  coordaction2getcmd  workflowjob  workflow action 3 should not have been purged  coordinator action 1 should not have been purged  wfaction3getcmd  wfaction4getcmd  coordaction1getcmd  assertequals  wfaction1  coordinator action 2 should not have been purged  wfaction2  addrecordtocoordjobtable  wfaction3  coordinator job should not have been purged  wfaction4  wfaction5  call  services  wfjob3getcmd  workflow action 1 should not have been purged  coord-action-get . xml  workflow job 5 should not have been purged  jpaservice  workflow job 2 should not have been purged
__label__nflaky date  https: /  / www . example . com  private  get  dynamic  entry  foo=  asdjkhqkbzxoqweopiuaxqweoiu;  max-age=3600;  version=1  content-encoding  assert  header  equals  dynamic  table  set  max  size  as  list  assert  array  equals  get  current  size  encode  headers  set-cookie  assert  create  byte  array  :status  cache-control  standard  charsets  mon   21  oct  2013  20:13:22  gmt  clear  mon   21  oct  2013  20:13:21  gmt  assert  equals  headers2  gzip  headers3  encoder  headers1  expected1  buf  200  expected3  expected2  302  to  byte  array  location  307  arrays  dynamic  length  test  response  encoding  without  huffman  rfc7541  examples  date  https: /  / www . example . com  private  getdynamicentry  foo=asdjkhqkbzxoqweopiuaxqweoiu; max-age=3600; version=1  content-encoding  assertheaderequals  dynamictable  setmaxsize  aslist  assertarrayequals  getcurrentsize  encodeheaders  set-cookie  assert  createbytearray  :status  cache-control  standardcharsets  mon  21 oct 2013 20:13:22 gmt  clear  mon  21 oct 2013 20:13:21 gmt  assertequals  headers2  gzip  headers3  encoder  headers1  expected1  buf  200  expected3  expected2  302  tobytearray  location  307  arrays  dynamiclength  testresponseencodingwithouthuffmanrfc7541examples
__label__flaky check  coord  action  get  id  date  utils  parse  date  oozie  tz  add  record  to  coord  job  table  call  coordinator  job  @1  test  action  mater  2009-03-06  t010:00  z  2009-03-11  t10:00  z  start  time  end  time  job  checkcoordaction  getid  dateutils  parsedateoozietz  addrecordtocoordjobtable  call  coordinatorjob  @1  testactionmater  2009-03-06t010:00z  2009-03-11t10:00z  starttime  endtime  job
__label__nflaky old  token  test  url  select  token  ip  port  test  url  select  token  oldtoken  testurlselecttokenipport  testurlselecttoken
__label__flaky get  id  assert  equals  get  status  execute  add  record  to  coord  job  table  call  coordinator  job  services  coord  job  get  cmd  test  coord  suspend  negative  assert  not  null  get  job  jpa  service  getid  assertequals  getstatus  execute  addrecordtocoordjobtable  call  coordinatorjob  services  coordjobgetcmd  testcoordsuspendnegative  assertnotnull  get  job  jpaservice
__label__nflaky content  types  test  get  json  p  create  template  engine  manager  get  template  engine  for  content  type  assert  that  instance  of  contenttypes  testgetjsonp  createtemplateenginemanager  gettemplateengineforcontenttype  assertthat  instanceof
__label__flaky server  time  out  creation  time  check  coord  action  coord  el  functions  timeout .   assert  false  add  partition  add  init  records  get  waiting  actions  system  check  dependencies  sleep  test  time  out  with  unresolved  missing  dependencies  default   / dt=20120430;country=usa  assert  true  get  coordinator  action   / dt=20120430;country=uk  tablename  new  h  cat  dependency  table  set  coord  action  creation  time  new  h  cat  dependency2  new  h  cat  dependency1  hcat  service  populate  table  dt=20120430;country=brazil  new  h  cat  dependency3  hcat: /  /   set  missing  dependencies  pdms  is  registered  for  notification   /   thread  call  services  contains  assert  null  current  time  millis  we  are  only  interested  in  ensuring  coord  action  input  check  x  command  is  run   / dt=20120430;country=brazil  action  id  db    server  timeoutcreationtime  checkcoordaction  coordelfunctions   timeout .   assertfalse  addpartition  addinitrecords  getwaitingactions  system  checkdependencies  sleep  testtimeoutwithunresolvedmissingdependencies  default   / dt=20120430;country=usa  asserttrue  get  coordinatoraction   / dt=20120430;country=uk  tablename  newhcatdependency  table  setcoordactioncreationtime  newhcatdependency2  newhcatdependency1  hcatservice  populatetable  dt=20120430;country=brazil  newhcatdependency3  hcat: /  /   setmissingdependencies  pdms  isregisteredfornotification   /   thread  call  services  contains  assertnull  currenttimemillis   we are only interested in ensuring coordactioninputcheckxcommand is run   / dt=20120430;country=brazil  actionid  db
__label__nflaky reader  get  temp  path  key  class  conf  fs  delete  path  file  sequence  file  sequencefile . sync . test  stream  file  system  get  len  get  file  status  uses  the  default  sync  interval  of  100  kb  numrecords  this  sync  interval  close  write  sequence  file  val  try  different  sequence  file .   reader  constructors  in  length  start  generic  test  utils  io . file . buffer . size  buffersize  input  get  int  for  offset  get  local  value  class  writer  compression  test  default  sync  interval  compression  type  open  buffer  size  reader  gettemppath  keyclass  conf  fs  delete  path  file  sequencefile  sequencefile . sync . test  stream  filesystem  getlen  getfilestatus   uses the default sync interval of 100 kb  numrecords   this sync interval  close  writesequencefile  val   try different sequencefile . reader constructors  in  length  start  generictestutils  io . file . buffer . size  buffersize  input  getint  foroffset  getlocal  valueclass  writer  compression  testdefaultsyncinterval  compressiontype  open  buffersize
__label__flaky cluster  lm  lease   expected  1  wait  lease  recovery  conf  replication_  num  create  file  wait  active  old  size  lastblock  testing  that  lease  recovery  cannot  happen  during  safemode .   filepath  connect  to  data  nodes  data  node  verify  that  we  still  cannot  recover  the  lease  current  gs  get  namenode  datanodeinfos  create  test  block  synchronization  get  last  located  block  info   / foo  dfs  config  keys  get  block  pool  id  newblocks=  get  file  system  dfs  count  lease  set  long  get  generation  stamp  num  data  nodes  dfs . dfs . client  name=  expire  lease  to  trigger  block  recovery .   get  data  node  found  get  locations  updatedmetainfo  shutdown  filestr  org_  file_  size  name  node  adapter  hdfs  constants  block_  size  wait  replication  system  test  inter  datanode  protocol  get  num  bytes  get  block  id  assert  true   / foo . safemode  verify  that  lease  recovery  does  not  occur  when  namenode  is  in  safemode  dfs  test  util  get  lease  manager  get  block  assert  equals  set  safe  mode  get  block  info  for  the  last  block  get  name  node  rpc  get  stored  block  datanodes  locatedblock  verify  block  info  dfs . support . append  get  ipc  port  build  check  meta  info  create  a  file  exists  append  set  boolean  get  namesystem  cluster  lm   lease  expected 1  waitleaserecovery  conf  replication_num  createfile  waitactive  oldsize  lastblock  testing that lease recovery cannot happen during safemode .   filepath   connect to data nodes  datanode   verify that we still cannot recover the lease  currentgs  getnamenode  datanodeinfos  create  testblocksynchronization  getlastlocatedblock  info   / foo  dfsconfigkeys  getblockpoolid  newblocks=  getfilesystem  dfs  countlease  setlong  getgenerationstamp  numdatanodes  dfs . dfs . clientname=   expire lease to trigger block recovery .   getdatanode  found   getlocations  updatedmetainfo  shutdown  filestr  org_file_size  namenodeadapter  hdfsconstants  block_size  waitreplication  system  testinterdatanodeprotocol  getnumbytes  getblockid  asserttrue   / foo . safemode   verify that lease recovery does not occur when namenode is in safemode  dfstestutil  getleasemanager  getblock  assertequals  setsafemode   get block info for the last block  getnamenoderpc  getstoredblock  datanodes  locatedblock   verify block info  dfs . support . append  getipcport  build  checkmetainfo   create a file  exists  append  setboolean  getnamesystem
__label__nflaky bytes  missing  format  specification   this  should  throw .   1  t  conf  illegal  number  specification   this  should  throw .   1  gb  this  call  returns  the  value  specified  in  the  key  as  a  double  in  m  bs .   mb  set  strings  non  key  kb  1k  illegal  format  specification   this  should  throw .   gb  suffix .   key  1  tb  1bytes  1  pb  get  storage  size  hadoop  gb  thrown  is  1  hb  assert  that  64  gb  during  read   we  also  try  to  read  using  a  different  storage  units .   tb  10m  valid . key  100  expect  test  storage  unit  to  m  bs  are  returns  that  value .   2048b  set  storage  size  not . a . key  bytes   missing format specification  this should throw .   1t  conf   illegal number  specification  this should throw .   1gb   this call returns the value specified in the key as a double in mbs .   mb  setstrings  nonkey  kb  1k   illegal format specification  this should throw .   gb   suffix .   key  1tb  1bytes  1pb  getstoragesize  hadoopgb  thrown  is  1hb  assertthat  64 gb   during read  we also try to read using a different storage units .   tb  10m  valid . key  100  expect  teststorageunit   to mbs are returns that value .   2048b  setstoragesize  not . a . key
__label__flaky add  node  def  one  start  assert  equals  workflow  instance  get  status  two  as  list  wf  1  fail  ex  get  error  code  <worklfow-app / >  end  test  loop  simple  error  code  arrays  job  addnode  def  one  start  assertequals  workflowinstance  getstatus  two  aslist  wf  1  fail  ex  geterrorcode  <worklfow-app / >  end  testloopsimple  errorcode  arrays  job
__label__nflaky user  creds  runnable  subject  set  the  runnable  to  not  to  run  in  a  loop  run  when  at  least  once  ugi  set  run  renewal  loop  create  and  destroy  the  kerberos  ticket   so  end  time  will  be  null  verify  create  user  group  information  boolean  throw  io  exception  in  the  middle  of  the  auto  renewal  for  user  creds  user  group  information  add  tgt  test  kerberos  ticket  is  destroyed  checked  relogin  from  ticket  cache  d  set  log  level  kp  foo  is  destroyed  generic  test  utils  destroy  there  should  be  no  exception  when  calling  this  users  do  throw  mockito  run  auto  renewal  for  user  creds  runnable  with  this  is  destroyed  should  be  called  at  least  once  level  to  string  spy  usercredsrunnable  subject   set the runnable to not to run in a loop  run  when  atleastonce  ugi  setrunrenewalloop   create and destroy the kerberosticket  so endtime will be null  verify   create usergroupinformation  boolean   throw ioexception in the middle of the autorenewalforusercreds  usergroupinformation  add  tgt  testkerberosticketisdestroyedchecked  reloginfromticketcache  d  setloglevel  kp  foo  isdestroyed  generictestutils  destroy   there should be no exception when calling this  users  dothrow  mockito   run autorenewalforusercredsrunnable with this   isdestroyed should be called at least once  level  tostring  spy
__label__flaky <chmod  path= \  '  \  ' {5} \  '  \  '   permissions= \  '  \  ' -rwxrwxrwx \  '  \  '  / >  chmod1  chmod2  chmod3  <chmod  path= \  '  \  ' {6} \  '  \  '   permissions= \  '  \  ' -rwxrwx--- \  '  \  '   dir-files= \  '  \  ' false \  '  \  '  / >  source  create  context  grandchild1  grandchild3  new  file2  x  xml  chmod2  x  get  path  get  file  status  mkdir  x  mkdir  <touchz  path= \  '  \  ' {8} \  '  \  '  / >  <move  source= \  '  \  ' {3} \  '  \  '   target= \  '  \  ' {4} \  '  \  '  / >  get  permission  ae  format  parse  xml  <mkdir  path= \  '  \  ' {1} \  '  \  '  / >  get  file  system  < / root>  chmod1  x  str  rwxrwx---  new  file1  x  mkdirs  <chmod  path= \  '  \  ' {9} \  '  \  '   permissions= \  '  \  ' -rwxrwx--- \  '  \  ' >  <recursive / >  < / chmod>  new  file2  <fs / >  new  file1  assert  false  do  operations  <touchz  path= \  '  \  ' {7} \  '  \  '  / >  child2  fs  delete  child3  child1  <delete  path= \  '  \  ' {2} \  '  \  '  / >  assert  true  get  name  node  uri  source  x  message  format  xml  utils  to  uri  delete  x  <root><name-node>{0}< / name-node>  test  do  operations  with  name  node  element  assert  equals  rwxrwxrwx  target  chmod3  x  assert  not  same  exists  to  string  create  new  file  get  fs  test  case  dir  <chmod path= \  '  \  ' {5} \  '  \  '  permissions= \  '  \  ' -rwxrwxrwx \  '  \  '  / >  chmod1  chmod2  chmod3  <chmod path= \  '  \  ' {6} \  '  \  '  permissions= \  '  \  ' -rwxrwx--- \  '  \  '  dir-files= \  '  \  ' false \  '  \  '  / >  source  createcontext  grandchild1  grandchild3  newfile2x  xml  chmod2x  getpath  getfilestatus  mkdirx  mkdir  <touchz path= \  '  \  ' {8} \  '  \  '  / >  <move source= \  '  \  ' {3} \  '  \  '  target= \  '  \  ' {4} \  '  \  '  / >  getpermission  ae  format  parsexml  <mkdir path= \  '  \  ' {1} \  '  \  '  / >  getfilesystem  < / root>  chmod1x  str  rwxrwx---  newfile1x  mkdirs  <chmod path= \  '  \  ' {9} \  '  \  '  permissions= \  '  \  ' -rwxrwx--- \  '  \  ' > <recursive / > < / chmod>  newfile2  <fs / >  newfile1  assertfalse  dooperations  <touchz path= \  '  \  ' {7} \  '  \  '  / >  child2  fs  delete  child3  child1  <delete path= \  '  \  ' {2} \  '  \  '  / >  asserttrue  getnamenodeuri  sourcex  messageformat  xmlutils  touri  deletex  <root><name-node>{0}< / name-node>  testdooperationswithnamenodeelement  assertequals  rwxrwxrwx  target  chmod3x  assertnotsame  exists  tostring  createnewfile  getfstestcasedir
__label__nflaky request  http  headers  header  elements  conn  test  execution  entity  enclosing  request  with  expect  continue  success  continue  when  set  entity  times  is  data  available  flush  executor  context  create  verify  ok  boolean  post  process  add  header  process  then  return  argument  matchers  method  get  entity  execute   /   any  int  mockito  response  http  core  context  httprocessor  mock  pre  process  entity  receive  response  header  send  request  entity  send  request  header  receive  response  entity  request  httpheaders  headerelements  conn  testexecutionentityenclosingrequestwithexpectcontinuesuccess  continue  when  setentity  times  isdataavailable  flush  executor  context  create  verify  ok  boolean  postprocess  addheader  process  thenreturn  argumentmatchers  method  getentity  execute   /   anyint  mockito  response  httpcorecontext  httprocessor  mock  preprocess  entity  receiveresponseheader  sendrequestentity  sendrequestheader  receiveresponseentity
__label__flaky inherit  wf  false  parent  libs2  parent  libs3  check  subworkflow  lib  helper  parent  libs1  parent  libs4  parent  libs5  child  libs1  expected  libs1  expected  libs2  expected  libs3  expected  libs4  inherit  child2 . so  expected  libs5  same . jar  child  libs3  child  libs2  child  libs5  child1 . jar  child  libs4  test  create  proto  conf  with  sub  workflow  lib6  inheritwf  false  parentlibs2  parentlibs3  checksubworkflowlibhelper  parentlibs1  parentlibs4  parentlibs5  childlibs1  expectedlibs1  expectedlibs2  expectedlibs3  expectedlibs4  inherit  child2 . so  expectedlibs5  same . jar  childlibs3  childlibs2  childlibs5  child1 . jar  childlibs4  testcreateprotoconfwithsubworkflowlib6
__label__nflaky test  prod  mode   / base / middle / app / mode / prod  request  core  matchers  equal  to  server  runs  in  test  mode .   this  route  is  prod .   assert  that  make  request  url  result  path  assert  response  get  test  server  url  testprodmode   / base / middle / app / mode / prod  request  corematchers  equalto   server runs in test mode .  this route is prod .   assertthat  makerequest  url  result  path  assert  response  get  testserverurl
__label__flaky test  sla  end_  points  is_  security_  enabled  get  context  url  data  oozie  url  wc  < / sla-message>  system  set  out  call  contains  old  stream  assert  true  <sla-message>  to  string  servlet_  classes  get  sla  info  run  test  <last-sequence-id>0< / last-sequence-id>  testsla  end_points  is_security_enabled  getcontexturl  data  oozieurl  wc  < / sla-message>  system  setout  call  contains  oldstream  asserttrue  <sla-message>  tostring  servlet_classes  getslainfo  runtest  <last-sequence-id>0< / last-sequence-id>
__label__nflaky test  read  symlink  get  absolute  path  assert  false  link  del  sym  link  assert  equals  delete  result  assert  file  _link  read  link  mkdirs  exists  create  a  symbolic  link  file  file  util  testreadsymlink  getabsolutepath  assertfalse  link  del  symlink  assertequals  delete  result  assert  file  _link  readlink  mkdirs  exists   create a symbolic link  file  fileutil
__label__flaky todo:  create  the  directories  coord  el  functions  2009-09-10  t23:59  z  test  latest  conf  coord-action-start  todo:  set  hadoop  properties  ds  2009-09-09  t23:59  z  eval  and  wrap   / 2009 / 09 / 10  get  test  case  dir  file: /  /   set  uri  template  create  dir  expr  2009-09-08  t23:59  z  ${coord:latest ( 0 ) }   / ${  year} / ${  month} / ${  day}  ${coord:latest ( 1 ) }  init  ds . set  uri  template (  \ ""file: /  /  / tmp / coord / ${  year} / ${  month} / ${  day} \ "" ) ;  ${coord:latest ( -100 ) }  set  variable  assert  equals  test  dir   / 2009 / 09 / 08   / 2009 / 09 / 09  fail  eval  should  throw  exception   because  latest  for  +ve  instance  is  not  valid  ${coord:latest ( -2 ) }  ${coord:latest ( -1 ) }   todo: create the directories  coordelfunctions  2009-09-10t23:59z  testlatest  conf  coord-action-start   todo:set hadoop properties  ds  2009-09-09t23:59z  evalandwrap   / 2009 / 09 / 10  gettestcasedir  file: /  /   seturitemplate  createdir  expr  2009-09-08t23:59z  ${coord:latest ( 0 ) }   / ${year} / ${month} / ${day}  ${coord:latest ( 1 ) }  init   ds . seturitemplate (  \ ""file: /  /  / tmp / coord / ${year} / ${month} / ${day} \ "" ) ;  ${coord:latest ( -100 ) }  setvariable  assertequals  testdir   / 2009 / 09 / 08   / 2009 / 09 / 09  fail  eval  should throw exception  because latest for +ve instance is not valid  ${coord:latest ( -2 ) }  ${coord:latest ( -1 ) }
__label__nflaky request  handler  add  header  authenticate  www_  authenticate_  header  negotiate  http  servlet  response  basic  set  status  assert  assert  null  mockito  response  mock  verify  test  request  without  authorization  request  handler  addheader  authenticate  www_authenticate_header  negotiate  httpservletresponse  basic  setstatus  assert  assertnull  mockito  response  mock  verify  testrequestwithoutauthorization
__label__flaky assert  false  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  get  status  is  pending  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  assert  not  null  get  coordinator  action  end  keeping  wait  time  to  20s  to  ensure  status  is  updated  current  date  plus  month  wait  for  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  coordinator  job  job  id  services  runnable  coord-action-get . xml  test  coord  status  transit  service  suspended  bottom  up  job  jpa  service  evaluate  assertfalse  getcurrentdateafterincrementinginmonths  getid  run  dateutils  getstatus  ispending  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  assertnotnull  get  coordinatoraction  end   keeping wait time to 20s to ensure status is updated  currentdateplusmonth  waitfor  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  coordinatorjob  jobid  services  runnable  coord-action-get . xml  testcoordstatustransitservicesuspendedbottomup  job  jpaservice  evaluate
__label__nflaky test  boolean  param  parser  get  parsed  type  parse  parameter  asdfasdf  false  true  is  +  matchers  assert  that  null  value  -  param1  123123  true  false  boolean  boolean  param  parser  validation  testbooleanparamparser  getparsedtype  parseparameter  asdfasdf  false  true  is  +  matchers  assertthat  nullvalue  -  param1  123123  true  false  boolean  booleanparamparser  validation
__label__flaky io  utils  original  os  test  copy  stream  copy  stream  to  byte  array  is  assert  equals  copy  ioutils  original  os  testcopystream  copystream  tobytearray  is  assertequals  copy
__label__nflaky num  windows  replace  scheduled  task  rolling  total  any  double  monotonic  now  insert  value  time  rolling  averages  *  #1  window  with  a  series  of  1  1000  *  times   e . g .   1   1 .  .  . 1   similarly   #2  window   e . g .   2   2 .  .  . 2   *  #3  window   e . g .   3   3 .  .  . 3  sleep  5s  roll  over  interval  times  time  unit  rolling  average  time  for  foo2  verify  verify  the  metrics  were  added  the  right  number  of  times  one  empty  window  or  all  2  windows  full  foo2  num  ops  per  iteration  info  add  window  size  ms  verify  that  the  window  reset   check  it  has  the  values  we  pushed  in  add  gauge  start  push  values  for  three  intervals  j  eq  rolling  sum  thread  rb    foo2  rolling  avg  time  test  rolling  averages  rollover  mock  metrics  record  builder  name  snapshot  numwindows  replacescheduledtask  rollingtotal  anydouble  monotonicnow   insert value   time  rollingaverages             * #1 window with a series of 1 1000           * times  e . g .  1  1 .  .  . 1  similarly  #2 window  e . g .  2  2 .  .  . 2            * #3 window  e . g .  3  3 .  .  . 3             sleep   5s roll over interval  times  timeunit  rolling average time for foo2  verify   verify the metrics were added the right number of times    one empty window or all 2 windows full   foo2  numopsperiteration  info  add  windowsizems   verify that the window reset  check it has the values we pushed in   addgauge  start   push values for three intervals   j  eq  rollingsum  thread  rb  foo2rollingavgtime  testrollingaveragesrollover  mockmetricsrecordbuilder  name  snapshot
__label__flaky cluster  create  table  get  cluster  status  hcd  test_  util  get  regions  in  transition  table  that  splits  like  crazy  get  configuration  htd  set  max  file  size  info  check  that  there \  ' s  no  region  in  flight   hbase-2515  expected  tablename  log  load  table  get  region  server  operation  queue  assert  equals  list  m  register  region  server  operation  listener  we  disable  the  table  during  a  split   we  will  end  up  here  test  disable  between  split  ex  t  size  set  mem  store  flush  size  add  family  get  h  base  cluster  get  h  base  admin  get  master  familyname  cluster  createtable  getclusterstatus  hcd  test_util  getregionsintransition   table that splits like crazy  getconfiguration  htd  setmaxfilesize  info   check that there \  ' s no region in flight  hbase-2515  expected  tablename  log  loadtable  getregionserveroperationqueue  assertequals  list  m  registerregionserveroperationlistener   we disable the table during a split  we will end up here  testdisablebetweensplit  ex  t  size  setmemstoreflushsize  addfamily  gethbasecluster  gethbaseadmin  getmaster  familyname
__label__nflaky handler  request  jwt  public  key  set  public  key  when  alternate  authentication  should  not  have  thrown  a  authentication  exception  service_  url  assert  assert  not  null  get  cookies  get  jwt  get  user  name  get  request  url  init  cookie  alternate  authentication  should  not  have  thrown  a  servlet  exception  then  return  get  properties  hadoop-jwt  encode  redirect  url  test  no  expiration  jwt  alternate  authenticate  assert  equals  props  token  fail  private  key  serialize  bob  mockito  token  should  not  be  null .   response  mock  handler  request  jwt  publickey  setpublickey  when  alternateauthentication should not have thrown a authenticationexception  service_url  assert  assertnotnull  getcookies  getjwt  getusername  getrequesturl  init  cookie  alternateauthentication should not have thrown a servletexception  thenreturn  getproperties  hadoop-jwt  encoderedirecturl  testnoexpirationjwt  alternateauthenticate  assertequals  props  token  fail  privatekey  serialize  bob  mockito  token should not be null .   response  mock
__label__flaky date  script  executor  session  local_  one  given  update  simple  eq  consistencylist  as  list  contains  exactly  quorum  when  get  list  of  should_dsl_update_list_append  all  where  id  row  table  execute  script  template  random  utils  manager  one  consistency  list_  append  all  to  next  long  assert  that  two  execute  simple  entity / insert_single_row . cql  immutable  map  select  consistencylist  from  simple  where  id  =  then  long  build  date  key  from  base  table  consistency  list  dsl  three  date  scriptexecutor  session  local_one   given  update  simple  eq  consistencylist  aslist  containsexactly  quorum   when  getlist  of  should_dsl_update_list_appendall  where  id  row  table  executescripttemplate  randomutils  manager  one  consistencylist_appendallto  nextlong  assertthat  two  execute  simpleentity / insert_single_row . cql  immutablemap  select consistencylist from simple where id =    then  long  builddatekey  frombasetable  consistencylist  dsl  three
__label__nflaky add   \ %x{ \  ' opt} \  ' }   \ %x{t y}  hello  world .   token  assert  equals  tokenize   \ %x{t}  witness  12y  test  options  t  tl  y   \ %x{ \ ""hello  world .  \ ""    \ ""12y   \ ""}  ol  opt}  add   \ %x{ \  ' opt} \  ' }   \ %x{t y}  hello world .   token  assertequals  tokenize   \ %x{t}  witness  12y    testoptions  t  tl  y   \ %x{ \ ""hello world .  \ ""   \ ""12y   \ ""}  ol  opt}
__label__flaky localhost  request  init  chain  set  get  remote  addr  then  return  destroy  when  filter  test  hostname  contains  assert  assert  null  mockito  hostname  filter  assert  true  do  filter  response  get  mock  invoked  localhost  request  init  chain  set  getremoteaddr  thenreturn  destroy  when  filter  testhostname  contains  assert  assertnull  mockito  hostnamefilter  asserttrue  dofilter  response  get  mock  invoked
__label__nflaky pp  test  smoke  foo  3  foo  foo3 . xixo  foo \ %i . xixo  assert  equals  foo .  \ %3i . log  foo . 43 . log  foo .  \ %1i . log   \ %i  foo  foo .  \ %i . log  foo . 003 . log  t  convert  int  context  foo3 . log  foo \ %i . log  foo . 3 . log  pp  testsmoke  foo  3 foo  foo3 . xixo  foo \ %i . xixo  assertequals  foo .  \ %3i . log  foo . 43 . log  foo .  \ %1i . log   \ %i foo  foo .  \ %i . log  foo . 003 . log  t  convertint  context  foo3 . log  foo \ %i . log  foo . 3 . log
__label__flaky cluster  test  file  creation  delete  parent  name  node  port  create  cluster  conf  test  file  creation  delete  parent:  create  file2 .   dir  fs  delete  create  file  system  wait  active  this  ensures  that  leases  are  persisted  in  fsimage .   sleep  hflush  assert  true  rm  dir  ipc . client . connection . maxidletime  close  write  file  2s   / foo  dfs  config  keys   / file2  format  create  file1 .   created  file  get  file  system  test  file  creation  set  int  thread  persistent  leases  from  fsimage .   stm2  max_  idle_  time  dfs . support . append  stm1  build  nnport  file2  get  name  node  port  exists  file1  shutdown  set  boolean  cluster  testfilecreationdeleteparent  namenodeport   create cluster  conf  testfilecreationdeleteparent:    create file2 .   dir  fs  delete  createfile  system  waitactive   this ensures that leases are persisted in fsimage .   sleep  hflush  asserttrue   rm dir  ipc . client . connection . maxidletime  close  writefile   2s   / foo  dfsconfigkeys   / file2  format   create file1 .   created file   getfilesystem  testfilecreation  setint  thread   persistent leases from fsimage .   stm2  max_idle_time  dfs . support . append  stm1  build  nnport  file2  getnamenodeport  exists  file1  shutdown  setboolean
__label__nflaky eval  intercept  test  eval  does  wrap  io  es  verify  cause  ioe  eval  intercept  testevaldoeswrapioes  verifycause  ioe
__label__flaky @  close  trx  coord  client  get  store  get  time  local  oozie  could  not  update  db .   get  status  -test  coord  rerun-  c  get  coord  client  get  begin  trx  coordinator  action  re  run  coord  commit  trx  action  num  rest  constants  print  stack  trace  store1  e  store2  assert  equals  store  test  coord  rerun  actions1  add  record  to  job  table  integer  job  id  services  fail  coordinator  job  add  record  to  action  table  assert  not  same  action  id  0000000-  to  string  action1  action2  coord-rerun-action1 . xml  get  coordinator  action  @  closetrx  coordclient  getstore  gettime  localoozie  could not update db .   getstatus  -testcoordrerun-c  getcoordclient  get  begintrx  coordinatoraction  reruncoord  committrx  actionnum  restconstants  printstacktrace  store1  e  store2  assertequals  store  testcoordrerunactions1  addrecordtojobtable  integer  jobid  services  fail  coordinatorjob  addrecordtoactiontable  assertnotsame  actionid  0000000-  tostring  action1  action2  coord-rerun-action1 . xml  getcoordinatoraction
__label__nflaky handler  request  get  time  jwt  alternate  authentication  should  have  thrown  an  authentication  exception  public  key  set  public  key  jwt  redirect  authentication  handler  when  remove  alternate  authentication  should  not  have  thrown  a  authentication  exception  se  service_  url  assert  true  get  cookies  get  jwt  test  no  provider  urljwt  authentication  provider  url  must  not  be  null  get  request  url  init  cookie  then  return  get  properties  hadoop-jwt  encode  redirect  url  get  message  alternate  authenticate  props  token  fail  private  key  serialize  contains  bob  mockito  response  mock  handler  request  gettime  jwt  alternateauthentication should have thrown an authenticationexception  publickey  setpublickey  jwtredirectauthenticationhandler  when  remove  alternateauthentication should not have thrown a authenticationexception  se  service_url  asserttrue  getcookies  getjwt  testnoproviderurljwt  authentication provider url must not be null  getrequesturl  init  cookie  thenreturn  getproperties  hadoop-jwt  encoderedirecturl  getmessage  alternateauthenticate  props  token  fail  privatekey  serialize  contains  bob  mockito  response  mock
__label__flaky a  b  add  node  def  get  transient  var  get  id  workflow  instance  get  status  as  list  wf  array  test  job  persistance  end  signal  from  byte  array  a  b  writable  utils  one  set  var  start  assert  equals   /   1  <worklfow-app / >  to  byte  array  get  var  arrays  job  set  transient  var    a  b  addnode  def  gettransientvar  getid  workflowinstance  getstatus  aslist  wf  array  testjobpersistance  end  signal  frombytearray  a  b  writableutils  one  setvar  start  assertequals   /   1  <worklfow-app / >  tobytearray  getvar  arrays  job  settransientvar
__label__nflaky store  password  get  resource  to  char  array  server  socket  new  single  thread  executor  executors  server  ssl  context  get  server  socket  factory  assert  bind  assert  not  null  nopassword  create  boolean  ssl  context  builder   / test-client . p12  localhost  start  handshake  read  local  port  load  key  material  load  trust  material  resource2  thrown  input  stream  set  so  timeout  get  input  stream   / test-server . p12  resource1  accept  create  socket  test  ssl  handshake  client  unauthenticated  error  client  ssl  context  timeout  set  need  client  auth  get  local  port  submit  client  socket  key  password  close  connect  assert  equals  call  get  socket  factory  expect  build  to  milliseconds  int  bound  socket  get  session  create  server  socket  storepassword  getresource  tochararray  serversocket  newsinglethreadexecutor  executors  serversslcontext  getserversocketfactory  assert  bind  assertnotnull  nopassword  create  boolean  sslcontextbuilder   / test-client . p12  localhost  starthandshake  read  localport  loadkeymaterial  loadtrustmaterial  resource2  thrown  inputstream  setsotimeout  getinputstream   / test-server . p12  resource1  accept  createsocket  testsslhandshakeclientunauthenticatederror  clientsslcontext  timeout  setneedclientauth  getlocalport  submit  clientsocket  keypassword  close  connect  assertequals  call  getsocketfactory  expect  build  tomillisecondsintbound  socket  getsession  createserversocket
__label__flaky new  hash  map  router .   get (  )  . route (  \ "" / user / {id} / {email} / user  dashboard \ "" )  . with (   application  controller . class    \ ""user  dashboard \ "" ) ;  assert  equals  put  my  email  test  reverse  routing  with  array  and  wrong  amount  of  query  parameters  100  1  user  dashboard  2  router  maps  paging_size  3  start  server  my  id  generated  reverse  route  id  page  get  reverse  route  map  email  newhashmap   router . get (  )  . route (  \ "" / user / {id} / {email} / userdashboard \ "" )  . with ( applicationcontroller . class   \ ""userdashboard \ "" ) ;  assertequals  put  myemail  testreverseroutingwitharrayandwrongamountofqueryparameters  100  1  userdashboard  2  router  maps  paging_size  3  startserver  myid  generatedreverseroute  id  page  getreverseroute  map  email
__label__nflaky @  locale  send  uppercase  hostname  when  lowercase  hostname  is  sent  get  default  realm  protected  check  that  the  test  environment  is  as  expected  test  get  server  principal  foo  bar  when  uppercase  hostname  is  sent  test  kerberos  util  at  default  realm  when  no  hostname  is  sent  0 . 0 . 0 . 0  local  hostname  assert  when  empty  hostname  is  sent  send  lowercase  hostname  get  local  host  name  test  get  server  principal  assumes  localhost  realm  is  default  send  empty  hostname  to  lower  case  when  0 . 0 . 0 . 0  hostname  is  sent  assert  equals  test  get  server  principal  assumes  realm  of  test  host   \  '   foo  bar \  '   is  default  kerberos  util  send  null  hostname  send  0 . 0 . 0 . 0  hostname   /   default  realm  service  equals  test  host  get  domain  realm  get  service  principal    @  locale   send uppercase hostname  when lowercase hostname is sent  getdefaultrealmprotected   check that the test environment is as expected  testgetserverprincipal  foobar  when uppercase hostname is sent  testkerberosutil  atdefaultrealm  when no hostname is sent  0 . 0 . 0 . 0  localhostname  assert  when empty hostname is sent   send lowercase hostname  getlocalhostname  testgetserverprincipal assumes localhost realm is default   send empty hostname  tolowercase  when 0 . 0 . 0 . 0 hostname is sent  assertequals  testgetserverprincipal assumes realm of testhost  \  ' foobar \  '  is default  kerberosutil   send null hostname   send 0 . 0 . 0 . 0 hostname   /   defaultrealm  service  equals  testhost  getdomainrealm  getserviceprincipal
__label__flaky bcb  bc  ef  el  constants  functions  acd  aefefd  assert  equals     replace  all  test  replace  all  ayyycd  d1  d2  d3  abcbcd  yyy  xyz  d1 d2 d3     bcb    bc  ef  elconstantsfunctions  acd  aefefd  assertequals     replaceall  testreplaceall  ayyycd  d1 d2 d3  abcbcd  yyy  xyz  d1 d2 d3
__label__nflaky exit_  interrupted  get  name  escalator  call  the  interrupt  operation  directly  e  is  forced  shutdown  timed  out (  )   ==  true  in  assert  false  test  interrupt  escalation  shutdown  interrupted  is  signal  already  received (  )   ==  false  in  assert  exception  details  int  is  forced  shutdown  timed  out  set  service  fail  expected  an  exception  to  be  raised  in  is  signal  already  received  now  interrupt  it  a  second  time  and  expect  it  to  escalate  to  a  halt  assert  stopped  assert  true  service  the  service  is  now  stopped  launcher    exit_interrupted  getname  escalator   call the interrupt operation directly  e  isforcedshutdowntimedout (  )  == true in   assertfalse  testinterruptescalationshutdown  interrupted  issignalalreadyreceived (  )  == false in   assertexceptiondetails  int  isforcedshutdowntimedout  setservice  fail  expected an exception to be raised in   issignalalreadyreceived   now interrupt it a second time and expect it to escalate to a halt  assertstopped  asserttrue  service   the service is now stopped  launcher
__label__flaky next  shutdown  dfs     scanned  get  log  set  batch  scan  assert  that  the  result  set  is  no  larger  than  batch  h  constants  assert  that  the  scanner  returned  all  values  bytes  total  inserted  assert  true  get  table  desc  get  assert  that  all  results  are  from  the  same  row  region_  info  batch  row  close  results  inserted  info  iteration  #  log  more  clear  kv  get  row  close  and  delete  create  new  h  region  r  add  wide  content  test  wide  scan  batching     results . size=  size  add  family  equals  get  scanner  next  shutdowndfs    scanned   getlog  setbatch  scan   assert that the result set is no larger than batch  hconstants   assert that the scanner returned all values  bytes  total  inserted  asserttrue  gettabledesc  get   assert that all results are from the same row  region_info  batch  row  close  results  inserted   info  iteration #  log  more  clear  kv  getrow  closeanddelete  createnewhregion  r  addwidecontent  testwidescanbatching    results . size=  size  addfamily  equals  getscanner
__label__nflaky get  class  get  declared  methods  including  inherited  contains  parent  method  get  name  missing  child  method  methods  get  parent  field  contains  child  field  missing  child  field  test  get  declared  fields  including  inherited  get  child  field  assert  true  get  declared  fields  including  inherited  child  field  method  contains  parent  field  parent  field  missing  parent  field  field  contains  child  method  equals  unused  reflection  utils  fields  missing  parent  method  child  getclass  getdeclaredmethodsincludinginherited  containsparentmethod  getname  missing child method  methods  getparentfield  containschildfield  missing child field  testgetdeclaredfieldsincludinginherited  getchildfield  asserttrue  getdeclaredfieldsincludinginherited  childfield  method  containsparentfield  parentfield  missing parent field  field  containschildmethod  equals  unused  reflectionutils  fields  missing parent method  child
__label__flaky cluster   / testfile  -cat  returned  1  rmr  prints  reasonable  error  -mkdir  returned  file  exists  -mkdir  returned  1  conf  run  bak  -mkdir  returned  1  get  bytes  tool  runner  -ls  does  not  return  found  0  items  renamed  get  home  directory  tmp  -mv  no  such  file  or  get  path  outtmp  test  err  out  put  -ls  does  not  print  out  anything  create  no  output  from  rename  unix  like  output  -cat   / nonexistentfile  write  ret  -dus  mv  failed  to  rename  set  err   / testdir  no  such  file  or  directory  -rm  -mkdir  returned  this  is  a  file  get  file  system  file  exists  -rm  returned  1  test  file   / testfiletest   / testfiletmp  rm  prints  reasonable  error  shell  num  data  nodes  mkdirs  -dus  prints  reasonable  error  reset  shutdown   / user / nonxistant / *  -du  prints  reasonable  error  argv  system  out  cat  does  not  print  exceptions  file  assert  true  root  -lsr  should  fail  src  fs   / nonexistenfile  not  a  directory  -ls  on  nonexistent  glob  returns  1  -rmr  close  -rmr  returned  1  -mkdir  empty  string  no  error  to  uri  assert  equals  set  conf  found  0  last  index  of  -ls  build  empty  path  specified  to  string  returned  -du  cluster   / testfile   -cat returned 1   rmr prints reasonable error    -mkdir returned file exists   -mkdir returned 1  conf  run  bak   -mkdir returned 1   getbytes  toolrunner   -ls does not return found 0 items  renamed  gethomedirectory  tmp  -mv  no such file or  getpath  outtmp  testerroutput   -ls does not print out anything   create  no output from rename   unix like output  -cat   / nonexistentfile  write  ret  -dus  mv failed to rename  seterr   / testdir  no such file or directory  -rm   -mkdir returned this is a file   getfilesystem  file exists   -rm returned 1   testfile   / testfiletest   / testfiletmp  rm prints reasonable error   shell  numdatanodes  mkdirs   -dus prints reasonable error  reset  shutdown   / user / nonxistant / *   -du prints reasonable error   argv  system  out  cat does not print exceptions   file  asserttrue  root   -lsr should fail   srcfs   / nonexistenfile  not a directory   -ls on nonexistent glob returns 1  -rmr  close   -rmr returned 1  -mkdir  empty string   no error   touri  assertequals  setconf  found 0  lastindexof  -ls  build  empty path specified  tostring  returned  -du
__label__nflaky header  iterator  assert  headergroup  assert  not  null  assert  false  has  next  test  iterator  headeriterator  assert  headergroup  assertnotnull  assertfalse  hasnext  testiterator
__label__flaky server  check  for  timeout  status  and  unregistered  missing  dependencies  time  out  creation  time  check  coord  action  coord  el  functions  timeout .   assert  false  add  init  records  get  waiting  actions  system  sleep  default   / dt=20120430;country=usa  assert  true  test  time  out  with  exception2  get  coordinator  action  tablename  new  h  cat  dependency  test  timeout  when  table  containing  missing  dependencies  is  dropped  in  between  table  drop  table  set  coord  action  creation  time  new  h  cat  dependency2  new  h  cat  dependency1  hcat  service  e  populate  table  hcat: /  /   get  message  pdms  is  registered  for  notification   /   thread  call  services  fail  contains  assert  null  current  time  millis   / dt=20120430;country=brazil  action  id  no  such  object  exception  db  server   check for timeout status and unregistered missing dependencies  timeoutcreationtime  checkcoordaction  coordelfunctions   timeout .   assertfalse  addinitrecords  getwaitingactions  system  sleep  default   / dt=20120430;country=usa  asserttrue  testtimeoutwithexception2  get  coordinatoraction  tablename  newhcatdependency   test timeout when table containing missing dependencies is dropped in between  table  droptable  setcoordactioncreationtime  newhcatdependency2  newhcatdependency1  hcatservice  e  populatetable  hcat: /  /   getmessage  pdms  isregisteredfornotification   /   thread  call  services  fail  contains  assertnull  currenttimemillis   / dt=20120430;country=brazil  actionid  nosuchobjectexception  db
__label__nflaky test  factory  for  nanoseconds  time  unit  test  factory  testfactoryfornanoseconds  timeunit  testfactory
__label__flaky cluster  conf  get  file  system  create  two  files  get  test  configuration  build  num  data  nodes  file  sys  create   / test / dfsclose / file-1   / test / dfsclose / file-0  test  dfs  close  close  shutdown  cluster  conf  getfilesystem   create two files  gettestconfiguration  build  numdatanodes  filesys  create   / test / dfsclose / file-1   / test / dfsclose / file-0  testdfsclose  close  shutdown
__label__nflaky get  name  the  sink  that  will  wait  on  put  metric  when  get  test  filename  test  put  metrics  find  time  unit  add  on  timer  event  mr  ms  proceed  signal  get  all  values  capture  test . sink . test . class  input  stop  * . period  test  metrics  config  name  mock  metrics  * . queue . capacity  save  trigger  metric  collection  first  time  q  size  timeout  iterables  do  answer  slow  sink  times  assert  true  get  await  verify  count  down  value  hadoop-metrics2-test  reached  put  metric  signal  register  sink  its  queue  length  should  be  1  for  the  second  collection .   apply  start  assert  equals  sink_slow  sink  qsize  any  the  sink  i \  ' ll  use  to  get  info  about  slow  sink  answer  test  q  size  equals  data  sink  r1  getname  the sink that will wait on putmetric  when  gettestfilename  test  putmetrics  find  timeunit  add  ontimerevent  mr  ms  proceedsignal  getallvalues  capture  test . sink . test . class  input  stop  * . period  testmetricsconfig  name  mock  metrics  * . queue . capacity  save   trigger metric collection first time  qsize  timeout  iterables  doanswer  slowsink  times  asserttrue  get  await  verify  countdown  value  hadoop-metrics2-test  reachedputmetricsignal  registersink   its queue length should be 1 for the second collection .   apply  start  assertequals  sink_slowsinkqsize  any  the sink i \  ' ll use to get info about slowsink  answer  testqsize  equals  datasink  r1
__label__flaky get  class  reduce  task  get  name  conf  get  status  get  attempts  iterator  assert  send  fetch  failure  wait  for  map  task  state  move  back  to  running  job  state  send  3  fetch  failures  from  reduce  to  trigger  map  re  execution  reduce  attempt  events  send  done  to  reduce  app  the  map  is  not  in  a  succeeded  state  after  restart  of  am  get  event  handler  num  completion  events  not  correct  get  id  handle  it  size  stop  task  attempt  state  send  the  done  signal  to  the  map  attempt  mr  job  config  job  next  test  fetch  failure  with  recovery  get  task  attempt  completion  events  submit  values  wait  for  reduce  to  start  running  task  attempt  completion  event  status  rerun  wait  for  map  success  wait  for  state  num  tasks  not  correct  task  attempt  event  type  all  maps  would  be  running  map  attempt1  run  count  map  task  crash  the  app  again .   sequential   single-task-attempt  approach  in  uber-  am   so  disable:  assert  equals  event  status  not  correct  get  tasks  task  state  get  context  set  boolean  wait  for  task  state  move  to  running  getclass  reducetask  getname  conf  getstatus  getattempts  iterator  assert  sendfetchfailure   wait for map task state move back to running  jobstate   send 3 fetch failures from reduce to trigger map re execution  reduceattempt  events   send done to reduce  app   the map is not in a succeeded state after restart of am  geteventhandler  num completion events not correct  getid  handle  it  size  stop  taskattemptstate   send the done signal to the map attempt  mrjobconfig  job  next  testfetchfailurewithrecovery  gettaskattemptcompletionevents  submit  values   wait for reduce to start running  taskattemptcompletioneventstatus   rerun   wait for map success  waitforstate  num tasks not correct  taskattempteventtype   all maps would be running  mapattempt1  runcount  maptask   crash the app again .    sequential  single-task-attempt approach in uber-am  so disable:  assertequals  event status not correct  gettasks  taskstate  getcontext  setboolean   wait for task state move to running
__label__nflaky compressed  date  march12th2010   ( 01 ) 90012345678908 ( 3200 ) 001750 ( 17 ) 100312  data  test01320  x171  expected  compressed  gtin900123456798908  compressed20bit  weight1750  header320x17  assert  correct  binary  string  compresseddatemarch12th2010   ( 01 ) 90012345678908 ( 3200 ) 001750 ( 17 ) 100312  data  test01320x171  expected  compressedgtin900123456798908  compressed20bitweight1750  header320x17  assertcorrectbinarystring
__label__flaky unexpected  exception  add  node  def  j1  f1  three  two  *  f-> ( 2 3 )   *  2->ok->j  *  3->ok->j  *  j->6  *  2->error->f1  *  3->error->f1  *  f1-> ( 4 5 )   *   ( 4 5 ) ->j1  *  j1->6  *  6->k  as  list  wf  test  error  transition  fork  join  invoke  fork  join  four  dummy  conf  end  five  six  print  stack  trace  e  f  one  j  k  kill  fail  parser  <worklfow-app / >  arrays  unexpected exception  addnode  def  j1  f1  three  two        * f-> ( 2 3 )       * 2->ok->j      * 3->ok->j      * j->6      * 2->error->f1      * 3->error->f1      * f1-> ( 4 5 )       *  ( 4 5 ) ->j1      * j1->6      * 6->k        aslist  wf  testerrortransitionforkjoin  invokeforkjoin  four  dummyconf  end  five  six  printstacktrace  e  f  one  j  k  kill  fail  parser  <worklfow-app / >  arrays
__label__nflaky bad:-port  set  host4:5  host2  my  address  get  message  conf  assert  equals  threw  exception  iae  get  socket  addr  does  not  contain  a  valid  host:port  authority:  default  port  get  host  port  string  net  utils  host:1  assert  true  bad:-port   ( configuration  property   \  ' my  address \  '  )   default  addr  host2:  host4:5  addr  test  socket  address  host2:3  bad:-port  set       \ t    host4:5      \ t        host2  myaddress  getmessage  conf  assertequals  threwexception  iae  getsocketaddr  does not contain a valid host:port authority:   defaultport  gethostportstring  netutils  host:1  asserttrue  bad:-port  ( configuration property  \  ' myaddress \  '  )   defaultaddr  host2:  host4:5  addr  testsocketaddress  host2:3
__label__flaky bundle  job  should  have  been  purged  bundle  action  should  have  been  purged  add  record  to  bundle  action  table  test  purge  bundle  with  coord  child  with  wf  child  with  sub  wf3  add  record  to  wf  action  table  coord  action  get  cmd  date  utils  workflow  instance  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  bundle  job  bundle  job  bean  assert  not  null  coordinator  action  should  have  been  purged  coordinator  action  job  wf  action  wf  job  get  cmd  sub  workflow  job  should  have  been  purged  execute  subwf  action  get  cmd  coordinator  job  1  coord  job  get  cmd  fail  workflow  action  coord  action  succeeded  je  subwf  job  get  cmd  bundle  job  get  cmd  get  id  sub  workflow  action  should  have  been  purged  coord  job  wf  job  workflow  job  should  have  been  purged  add  record  to  wf  job  table  get  error  code  get  workflow  job  subwf  action  get  app  name  bundle  action  coordinator  job  should  have  been  purged  workflow  action  should  have  been  purged  wf  action  get  cmd  2011-01-01  t01:00  z  add  record  to  bundle  job  table  assert  equals  add  record  to  coord  job  table  call  services  coord-action-get . xml  subwf  job  error  code  jpa  service  bundle  action  get  cmd  bundle job should have been purged  bundle action should have been purged  addrecordtobundleactiontable  testpurgebundlewithcoordchildwithwfchildwithsubwf3  addrecordtowfactiontable  coordactiongetcmd  dateutils  workflowinstance  getstatus  addrecordtocoordactiontable  parsedateoozietz  bundlejob  bundlejobbean  assertnotnull  coordinator action should have been purged  coordinatoraction  job  wfaction  wfjobgetcmd  subworkflow job should have been purged  execute  subwfactiongetcmd  coordinatorjob  1  coordjobgetcmd  fail  workflowaction  coordaction  succeeded  je  subwfjobgetcmd  bundlejobgetcmd  getid  subworkflow action should have been purged  coordjob  wfjob  workflow job should have been purged  addrecordtowfjobtable  geterrorcode  get  workflowjob  subwfaction  getappname  bundleaction  coordinator job should have been purged  workflow action should have been purged  wfactiongetcmd  2011-01-01t01:00z  addrecordtobundlejobtable  assertequals  addrecordtocoordjobtable  call  services  coord-action-get . xml  subwfjob  errorcode  jpaservice  bundleactiongetcmd
__label__nflaky java . version  env  util  set  property  assert  false  1 . 4 . xx  is  jdk6  or  higher  is  jdk5  test  java1_4  system  is  jdk7  or  higher  java . version  envutil  setproperty  assertfalse  1 . 4 . xx  isjdk6orhigher  isjdk5  testjava1_4  system  isjdk7orhigher
__label__flaky get  connection  context  get  event  message  cae  session  coord  event  listener  jms  messaging  utils  get  user  conf  parse  date  utc  coord  action  fail  message  date  utils  get  status  create  session  get  topic  = \  ' user1 \  '   wf-app-name1  on  coordinator  action  event  assert  ca  job  id1  ca  id1  coordinator  action  2012-07-22  t00:00  z  selector  jms  context  test  coordinator  action  selectors  consumer  message  type  2011-07-11  t00:00  z  user1  get  message  type  init  nominal  time  receive  print  stack  trace  e  get  message  assert  equals  message  fail  jms  header  constants  create  consumer  start  date  session  getconnectioncontext  geteventmessage  cae  session  coordeventlistener  jmsmessagingutils  getuser  conf  parsedateutc  coordactionfailmessage  dateutils  getstatus  createsession  gettopic  = \  ' user1 \  '   wf-app-name1  oncoordinatoractionevent  assert  cajobid1  caid1  coordinatoraction  2012-07-22t00:00z  selector  jmscontext  testcoordinatoractionselectors  consumer  messagetype  2011-07-11t00:00z  user1  getmessagetype  init  nominaltime  receive  printstacktrace  e  getmessage  assertequals  message  fail  jmsheaderconstants  createconsumer  startdate  session
__label__nflaky conn  then  return  get  endpoint  details  assert  equals  send  response  header  ascii  out  stream  go  on  when  test  write  response100  head  bind  assert  flush  mockito  response  to  byte  array  get  output  stream  http / 1 . 1  100  go  on  socket  get  response  count  conn  thenreturn  getendpointdetails  assertequals  sendresponseheader  ascii  outstream  go on  when  testwriteresponse100head  bind  assert  flush  mockito  response  tobytearray  getoutputstream  http / 1 . 1 100 go on      socket  getresponsecount
__label__flaky template  execution  <ul>{{#list}}<li>{{name}}< / li>{{ / list}}< / ul>  start  length  js  assert  equals  run  assert  concurrent  to  java  script  system  printf  compile  to  shared  java  script  current  time  millis  shared  execution:   \ %s  took:   \ %sms  end  template  execution  <ul>{{#list}}<li>{{name}}< / li>{{ / list}}< / ul>  start  length  js  assertequals  run  assertconcurrent  tojavascript  system  printf  compile  tosharedjavascript  currenttimemillis  shared execution:  \ %s took:  \ %sms    end
__label__nflaky mock  res  init  mock  req  object  under  test  then  return  csrf  has  not  been  sent  objects  to  verify  interactions  based  on  request  test  no  header  default  config  non  browser  good  request  setup  the  configuration  settings  of  the  server  when  filter  config  get  header  filter  mock  chain  get  init  parameter  mockito  do  filter  mock  verify  non_  browser  rest  csrf  prevention  filter  mockres  init  mockreq   object under test  thenreturn   csrf has not been sent   objects to verify interactions based on request  testnoheaderdefaultconfignonbrowsergoodrequest   setup the configuration settings of the server  when  filterconfig  getheader  filter  mockchain  getinitparameter  mockito  dofilter  mock  verify  non_browser  restcsrfpreventionfilter
__label__flaky <execution>  lifo< / execution>  < / controls>  <datasets>  < / property>< / configuration>  < / workflow>  check  coord  jobs  conf  < / input-events>  xmlns:sla= \  ' uri:oozie:sla:0 . 1 \  ' >  <controls>  <timeout>${coord:minutes ( 10 ) }< / timeout>  <concurrency>2< / concurrency>  file: /  /   get  test  case  dir  unit_  testing  <output-events>  <data-out  name= \ ""  local_  a \ ""  dataset= \ ""local_a \ "">  timezone= \ ""  utc \ "">  <uri-template>file: /  /  / tmp / coord / workflows / ${  year} / ${  day}< / uri-template>  < / dataset>  10  <configuration>  <property>  <name>input  a< / name>  <value>${coord:data  in (  \  '   a \  '  ) }< / value>  < / property>  <dataset  name= \ ""local_a \ ""  frequency= \ ""${coord:days ( 7 ) } \ ""  initial-instance= \ ""2009-02-01  t01:00  z \ ""  sla_  offset  oozie  client  job  id  < / datasets>  <input-events>  -  c  <dataset  name= \ ""a \ ""  frequency= \ ""${coord:days ( 7 ) } \ ""  initial-instance= \ ""2009-02-01  t01:00  z \ ""  job  file  <sla:se-contact>abc@example . com< / sla:se-contact>  app  path  substring  sc  write  to  file  app  xml  <property>  <name>input  b< / name>  <value>${coord:data  out (  \  '   local_  a \  '  ) }< / value>  get  timeout  <sla:info>  <sla:alert-contact>abc@example . com< / sla:alert-contact>  <sla:should-end>${  sla_  offset  *  hours}< / sla:should-end>  test  basic  submit  with  sla  <sla:dev-contact>abc@example . com< / sla:dev-contact>  coordinator . xml  set  <sla:alert-frequency>  last_  hour< / sla:alert-frequency>  < / sla:info>  length  < / action>  < / coordinator-app>  <sla:should-start>${5  *  minutes}< / sla:should-start>  assert  equals  <sla:app-name>test-app< / sla:app-name>  call  <coordinator-app  name= \ ""  name \ ""  frequency= \ ""${coord:days ( 1 ) } \ ""  start= \ ""2009-02-01  t01:00  z \ ""  end= \ ""2009-02-03  t23:59  z \ ""  timezone= \ ""  utc \ ""  <sla:alert-percentage>10< / sla:alert-percentage>  get  test  user  xmlns:xsi= \  ' http: /  / www . w3 . org / 2001 /   xml  schema-instance \  '   xmlns= \  ' uri:oozie:coordinator:0 . 2 \  '   <instance>${coord:current ( -1 ) }< / instance>  < / data-out>  < / output-events>  <action>  <workflow>  <app-path>hdfs: /  /  / tmp / workflows / < / app-path>  <sla:nominal-time>${coord:nominal  time (  ) }< / sla:nominal-time>  <data-in  name= \ ""  a \ ""  dataset= \ ""a \ "">  <instance>${coord:latest ( 0 ) }< / instance>  < / data-in>  <sla:qa-contact>abc@example . com< / sla:qa-contact>  <sla:notification-msg>  notifying  user  for  ${coord:nominal  time (  ) }  nominal  time  < / sla:notification-msg>  <execution>lifo< / execution> < / controls> <datasets>   < / property>< / configuration> < / workflow>   checkcoordjobs  conf  < / input-events>   xmlns:sla= \  ' uri:oozie:sla:0 . 1 \  ' > <controls> <timeout>${coord:minutes ( 10 ) }< / timeout>   <concurrency>2< / concurrency>   file: /  /   gettestcasedir  unit_testing  <output-events> <data-out name= \ ""local_a \ "" dataset= \ ""local_a \ "">   timezone= \ ""utc \ ""> <uri-template>file: /  /  / tmp / coord / workflows / ${year} / ${day}< / uri-template> < / dataset>   10  <configuration> <property> <name>inputa< / name> <value>${coord:datain (  \  ' a \  '  ) }< / value> < / property>   <dataset name= \ ""local_a \ "" frequency= \ ""${coord:days ( 7 ) } \ "" initial-instance= \ ""2009-02-01t01:00z \ ""   sla_offset  oozieclient  jobid  < / datasets> <input-events>   -c  <dataset name= \ ""a \ "" frequency= \ ""${coord:days ( 7 ) } \ "" initial-instance= \ ""2009-02-01t01:00z \ ""   job  file   <sla:se-contact>abc@example . com< / sla:se-contact>  apppath  substring  sc  writetofile  appxml  <property> <name>inputb< / name> <value>${coord:dataout (  \  ' local_a \  '  ) }< / value>   gettimeout   <sla:info>   <sla:alert-contact>abc@example . com< / sla:alert-contact>   <sla:should-end>${ sla_offset * hours}< / sla:should-end>  testbasicsubmitwithsla   <sla:dev-contact>abc@example . com< / sla:dev-contact>  coordinator . xml  set   <sla:alert-frequency>last_hour< / sla:alert-frequency>  < / sla:info>  length  < / action> < / coordinator-app>   <sla:should-start>${5 * minutes}< / sla:should-start>  assertequals   <sla:app-name>test-app< / sla:app-name>  call  <coordinator-app name= \ ""name \ "" frequency= \ ""${coord:days ( 1 ) } \ "" start= \ ""2009-02-01t01:00z \ "" end= \ ""2009-02-03t23:59z \ "" timezone= \ ""utc \ ""    <sla:alert-percentage>10< / sla:alert-percentage>  gettestuser  xmlns:xsi= \  ' http: /  / www . w3 . org / 2001 / xmlschema-instance \  '  xmlns= \  ' uri:oozie:coordinator:0 . 2 \  '    <instance>${coord:current ( -1 ) }< / instance> < / data-out> < / output-events> <action> <workflow> <app-path>hdfs: /  /  / tmp / workflows / < / app-path>    <sla:nominal-time>${coord:nominaltime (  ) }< / sla:nominal-time>  <data-in name= \ ""a \ "" dataset= \ ""a \ ""> <instance>${coord:latest ( 0 ) }< / instance> < / data-in>     <sla:qa-contact>abc@example . com< / sla:qa-contact>   <sla:notification-msg>notifying user for ${coord:nominaltime (  ) } nominal time < / sla:notification-msg>
__label__nflaky generate  certificate  truststore  location  basedir  assert  false  cert  wait  for  failed  reload  at  least  once  sleep  wait  so  that  the  file  modification  time  is  different  password  stop  capturing  jks  sha1with  rsa  test  reload  corrupt  trust  store  write  close  get  output  rsa  init  os  kp  create  trust  store  get  reload  interval  reloading  x509  trust  manager  reloader  log  destroy  assert  equals  cert2  generate  key  pair  cert1  thread  cn=  cert2  contains  cn=  cert1   / testcorrupt . jks  tm  get  accepted  issuers  generatecertificate  truststorelocation  basedir  assertfalse  cert  waitforfailedreloadatleastonce  sleep   wait so that the file modification time is different  password  stopcapturing  jks  sha1withrsa  testreloadcorrupttruststore  write  close  getoutput  rsa  init  os  kp  createtruststore  getreloadinterval  reloadingx509trustmanager  reloaderlog  destroy  assertequals  cert2  generatekeypair  cert1  thread  cn=cert2  contains  cn=cert1   / testcorrupt . jks  tm  getacceptedissuers
__label__flaky verify  that  cp  from  a  directory  to  a  subdirectory  fails  cluster   / test / dir1 / dir2  my  file   / test / mkdirs / my  file  conf  run  -test  exception  raised  from  dfs  shell . run  this  tests  some  properties  of  checksum  file  system  as  well .   *  make  sure  that  we  create  checksum  dfs  -cat  val  -rm  stringify  exception   / test / dir1  get  file  system   / test / dir1foo  shell  -touchz  num  data  nodes  first  create  a  new  directory  with  mkdirs  mkdirs  file  sys  this  should  succeed  get  uri  shutdown  my  path  exception  raised  from  dfs  shell . run:  re-create  the  files  for  other  tests  get  localized  message  verify  that  we  succeed  in  removing  the  file  we  created  assert  false  fs  delete  second   create  a  file  in  that  directory .   system  test  dfs  shell  assert  true  string  utils  -d  -e  -cp  verify  touch / test  close  write  file  verify  that  rm  with  a  pattern  -mkdir   / test / mkdirs  e   / test / mkdirs / my  file*  verify  that  we  get  an  error  while  trying  to  delete  an  nonexistent  file  my  file2  this  should  fail  assert  equals  verify  that  we  get  an  error  while  trying  to  read  an  nonexistent  file  -z  set  conf   / test / mkdirs / my  file2  not  a  hdfs:   / test / mkdirs / my  file1  args  build  verify  that  we  can  read  the  file  args1  exists   / test / mkdirs / no  file  here   verify that cp from a directory to a subdirectory fails  cluster   / test / dir1 / dir2  myfile   / test / mkdirs / myfile  conf  run  -test  exception raised from dfsshell . run    this tests some properties of checksumfilesystem as well .        * make sure that we create checksumdfs   -cat  val  -rm  stringifyexception   / test / dir1  getfilesystem   / test / dir1foo  shell  -touchz  numdatanodes   first create a new directory with mkdirs  mkdirs  filesys   this should succeed  geturi  shutdown  mypath  exception raised from dfsshell . run:    re-create the files for other tests  getlocalizedmessage   verify that we succeed in removing the file we created  assertfalse  fs  delete   second  create a file in that directory .   system  testdfsshell  asserttrue  stringutils  -d  -e  -cp   verify touch / test  close  writefile   verify that rm with a pattern  -mkdir   / test / mkdirs  e   / test / mkdirs / myfile*   verify that we get an error while trying to delete an nonexistent file  myfile2   this should fail  assertequals   verify that we get an error while trying to read an nonexistent file  -z  setconf   / test / mkdirs / myfile2  not a hdfs:    / test / mkdirs / myfile1  args  build   verify that we can read the file  args1  exists   / test / mkdirs / nofilehere
__label__nflaky svc  init  stop  test  service  notifications  listener  start  register  service  listener  assert  event  count  svc  init  stop  testservicenotifications  listener  start  registerservicelistener  asserteventcount
__label__flaky select  *  from  entitywithstaticcolumn  where  id  =  session  given  insert  uui  ds  uuid  crud  when  id  value  static_col  val  is  not  null  static_val  actual  random  utils  manager  one  time  based  get  string  next  long  assert  that  execute  and  uuid  =  should_insert  then  long  is  equal  to  entity  select * from entitywithstaticcolumn where id =   session   given  insert  uuids  uuid  crud   when  id  value  static_col  val  isnotnull  static_val  actual  randomutils  manager  one  timebased  getstring  nextlong  assertthat  execute   and uuid =   should_insert   then  long  isequalto  entity
__label__nflaky get  checksum  file  checksum  deleted  delete  get  bytes  testing  you  copying  the  wrong  checksum  file  assert  true  test_  root_  dir  fout  checksum  exists  create  now  setting  verify  false   the  read  should  succeed  copy  write  close  error  read  the  chunk  size   2x  chunk  size   and  + / -1  around  these .   read  get  conf  test  path11  testing  set  verify  checksum  str  test  verify  checksum  local  fs  test  path  error  reading  read  file  equals  exists  to  string  file  util  getchecksumfile  checksum deleted  delete  getbytes  testing you   copying the wrong checksum file  asserttrue  test_root_dir  fout  checksum exists  create   now setting verify false  the read should succeed  copy  write  close  errorread   the chunk size  2x chunk size  and + / -1 around these .   read  getconf  testpath11  testing  setverifychecksum  str  testverifychecksum  localfs  testpath  error reading  readfile  equals  exists  tostring  fileutil
__label__flaky delete  list  000-123-  c  bulk  del  rerun  cmd  check  for  non  existence  after  running  bulk  delete  jpa  add  record  to  wf  action  table  should  not  be  found  get  id  add  record  to  coord  action  table  000-123-  w  get  error  code  assert  not  null  get  coordinator  action  jex  add  set  delete  list  assert  equals  execute  services  fail  2  coord-action-get . xml  workflow  action  test  deletes  action1  insert  one  workflow  job  and  two  actions  error  code  action2  jpa  service  deletelist  000-123-c  bulkdelreruncmd   check for non existence after running bulkdeletejpa  addrecordtowfactiontable   should not be found  getid  addrecordtocoordactiontable  000-123-w  geterrorcode  assertnotnull  get  coordinatoraction  jex  add  setdeletelist  assertequals  execute  services  fail  2  coord-action-get . xml  workflowaction  testdeletes  action1   insert one workflow job and two actions  errorcode  action2  jpaservice
__label__nflaky encode  a  data  size  get  bake_in_a_header_a_  unicode_value  assert  equals  decode  in  map  put  out  map  "
__label__flaky cluster  fs2  fs1  waiting  for  close  to  get  to  latch .  .  .   conf  run  when  wait  active  wait  for  call  assert  not  null  delayer  create  join  write  write  1 / 2  block   / test  recover  finalized  info  proceed  log  any  string  interrupt  and  join  waiting  for  close  to  finish .   get  file  system  any  object  stm  killing  lease  checker  pre  spy  nn  contains  no  lease  on   / test  recover  finalized  num  data  nodes  spy  shutdown  recover  file  telling  close  to  proceed .   test  recover  finalized  block  do  answer  assert  true  get  client  error .   close  lose  the  leases  set  err  get  conf  start  recovering  file  get  message  get  name  node  rpc  delay  complete  file  append  test  util  t  build  spy  nn  create  hdfs  with  different  username  close  finished .   thrown  by  close  file1  complete  cluster  fs2  fs1  waiting for close to get to latch .  .  .   conf  run  when  waitactive  waitforcall  assertnotnull  delayer  create  join  write   write 1 / 2 block   / testrecoverfinalized  info  proceed  log  anystring  interruptandjoin  waiting for close to finish .   getfilesystem  anyobject  stm  killing lease checker  prespynn  contains  no lease on  / testrecoverfinalized  numdatanodes  spy  shutdown  recoverfile  telling close to proceed .   testrecoverfinalizedblock  doanswer  asserttrue  get  client   error .   close   lose the leases  set  err  getconf  start  recovering file  getmessage  getnamenoderpc   delay completefile  appendtestutil  t  build  spynn  createhdfswithdifferentusername  close finished .   thrownbyclose  file1  complete
__label__nflaky get  stats  release  sleep  assert  update  expiry  assert  true  stats  assert  not  null  get  of  time  unit  verify  collections  close  time  value  get  leased  singleton  test  create  new  if  expired  entry1  conn1  assign  connection  somehost  pool  assert  equals  totals  is  done  thread  future1  get  routes  future2  mockito  close  mode  mock  lease  get  total  stats  get  available  getstats  release  sleep  assert  updateexpiry  asserttrue  stats  assertnotnull  get  of  timeunit  verify  collections  close  timevalue  getleased  singleton  testcreatenewifexpired  entry1  conn1  assignconnection  somehost  pool  assertequals  totals  isdone  thread  future1  getroutes  future2  mockito  closemode  mock  lease  gettotalstats  getavailable
__label__flaky date  script  executor  session  local_  one  given  update  simple  eq  consistencylist  as  list  quorum  when  of  where  id  row  table  execute  script  template  should_dsl_update_list_remove  all  random  utils  manager  one  next  long  assert  that  execute  simple  entity / insert_single_row . cql  immutable  map  is  true  select  consistencylist  from  simple  where  id  =  consistency  list_  remove  all  from  then  is  null  long  build  date  key  from  base  table  consistency  list  dsl  date  scriptexecutor  session  local_one   given  update  simple  eq  consistencylist  aslist  quorum   when  of  where  id  row  table  executescripttemplate  should_dsl_update_list_removeall  randomutils  manager  one  nextlong  assertthat  execute  simpleentity / insert_single_row . cql  immutablemap  istrue  select consistencylist from simple where id =   consistencylist_removeallfrom   then  isnull  long  builddatekey  frombasetable  consistencylist  dsl
__label__nflaky 5  days  12  8  milliseconds  10 . 7  millisecond  1  hour  d  test  159  milli  value  of  duration  assert  equals  hours_  co  2 . 2  minutes  get  milliseconds  12seconde  days_  co  12second  4 . 2  hours  15  millis  10  sec  onds  10 . 7  seconds  14  secondes  1  minute  5 days  12  8 milliseconds  10 . 7 millisecond  1 hour  d  test  159 milli  valueof  duration  assertequals  hours_co  2 . 2 minutes  getmilliseconds  12seconde  days_co  12second  4 . 2 hours  15 millis  10 seconds  10 . 7 seconds  14 secondes  1 minute
__label__flaky tested  value  get  time  tz  get  id  caicc  date  utils  parse  date  oozie  tz  effective  value  2009-02-01  t23:59  get  start  time  verify  if  two  values  are  same .   get  conf  assert  equals  override  the  property  value  for  testing  purpose  only .   -  test  coord  action  input  check  x  command-  c  *  create  a  dummy  coordinator  job  to  pass  to  *  coord  action  input  check  x  command  constructor .   2009-02-02  t23:59  add  record  to  coord  job  table  test  requeue  interval  job  id  services  @1  set  long  get  coord  input  check  requeue  interval  0000000-  end  time  coord  action  input  check  x  command  job  testedvalue  gettime  tz  getid  caicc  dateutils  parsedateoozietz  effectivevalue  2009-02-01t23:59  get  starttime   verify if two values are same .   getconf  assertequals   override the property value for testing purpose only .    -testcoordactioninputcheckxcommand-c             * create a dummy coordinator job to pass to           * coordactioninputcheckxcommand constructor .              2009-02-02t23:59  addrecordtocoordjobtable  testrequeueinterval  jobid  services  @1  setlong  getcoordinputcheckrequeueinterval  0000000-  endtime  coordactioninputcheckxcommand  job
__label__nflaky set  handler  delegation  token  authentication  filter  get  kind  auth  url   / bar  set  attribute  assert  foo_  user  assert  not  null  of  context  start  threads  jetty   / *   / foo / bar ? authenticated=foo  dispatcher  type  get  jetty  url  foo  kind   / foo  secret  mgr  a  url  add  servlet  enum  set  start  set  context  path  assert  equals  create  jetty  server  stop  threads  test  external  delegation  token  secret  manager  token  stop  add  filter  get  delegation  token  sethandler  delegationtokenauthenticationfilter  getkind  authurl   / bar  setattribute  assert  foo_user  assertnotnull  of  context  startthreads  jetty   / *   / foo / bar ? authenticated=foo  dispatchertype  getjettyurl  fookind   / foo  secretmgr  aurl  addservlet  enumset  start  setcontextpath  assertequals  createjettyserver  stopthreads  testexternaldelegationtokensecretmanager  token  stop  addfilter  getdelegationtoken
__label__flaky next  task  event  type  submit  wait  and  validate  for  job  to  become  succeeded  values  send  the  kill  signal  to  the  first  task  get  report  no  of  attempts  is  not  correct  wait  for  state  get  attempts  get  task  attempt  state  iterator  assert  job  is  succeeded  job  state  get  task  state  latch  count  down  task1  task2  tasks  wait  and  vailidate  for  job  to  become  running  attempts  app  get  event  handler  this  will  start  the  job  but  job  won \  ' t  complete  as  task  is  blocked  iter  assert  equals  get  id  handle  it  attempt  state  not  correct  unblock  task  test  kill  task  task  state  not  correct  size  task  attempt  state  get  tasks  job  no  of  tasks  is  not  correct  get  context  task  state  next  taskeventtype  submit   wait and validate for job to become succeeded  values   send the kill signal to the first task  getreport  no of attempts is not correct  waitforstate  getattempts  gettaskattemptstate  iterator  assert   job is succeeded  jobstate  gettaskstate  latch  countdown  task1  task2  tasks   wait and vailidate for job to become running  attempts  app  geteventhandler   this will start the job but job won \  ' t complete as task is blocked  iter  assertequals  getid  handle  it  attempt state not correct   unblock task  testkilltask  task state not correct  size  taskattemptstate  gettasks  job  no of tasks is not correct  getcontext  taskstate
__label__nflaky next  float  random  rand1  rand2  test  random  float  nextfloat  random  rand1  rand2  testrandomfloat
__label__flaky play  a  request  cookie:  $  version= \ ""1 \ "";  location:  set  domain  accept_  original_  server  http  url  connection  test  redirects  do  not  include  too  many  cookies  get  port  list  cookie  manager  get  cookie  store  redirect  source  add   \ "";$  port= \ ""  cookie  add  header   \ ""  c  cookie  get  headers  take  request  set  portlist  to  uri  set  path  redirect  target  set  body  set  response  code  set  default  assert  contains   /   integer  enqueue  get  url  fail  get  port  get  cookie  domain  header  to  string  cookie  handler  c= \ ""cookie \ "";$  path= \ "" /  \ "";$  domain= \ ""  starts  with  play  a  request  cookie: $version= \ ""1 \ "";   location:   setdomain  accept_original_server  httpurlconnection  testredirectsdonotincludetoomanycookies  get  portlist  cookiemanager  getcookiestore  redirectsource  add   \ "";$port= \ ""  cookie  addheader   \ ""  c  cookie  getheaders  takerequest  setportlist  touri  setpath  redirecttarget  setbody  setresponsecode  setdefault  assertcontains   /   integer  enqueue  geturl  fail  getport  getcookiedomain  header  tostring  cookiehandler  c= \ ""cookie \ "";$path= \ "" /  \ "";$domain= \ ""  startswith
__label__nflaky http  headers  process  http  status  get  first  header  h1  interceptor  h2  get  entity  set  entity  test  response  content  entity  no  content  type  and  encoding  assert  assert  null  empty  input  stream  response  context  ok  httpheaders  process  httpstatus  getfirstheader  h1  interceptor  h2  getentity  setentity  testresponsecontententitynocontenttypeandencoding  assert  assertnull  emptyinputstream  response  context  ok
__label__flaky a  b  get  variables  test  variables  assert  equals  counter  add  variable  1  get  value  2  size  inst  get  a  b  getvariables  testvariables  assertequals  counter  addvariable  1  getvalue  2  size  inst  get
__label__nflaky address  factory  address  host4  host_  list  address  mock  host4  address  mock  host5  assert  false  test  for  exclusion  with  an  unknown  ip  test  for  inclusion  with  an  known  ip  when  address  host1  assert  true  string  utils  get  by  name  get  trimmed  string  collection  1 . 2 . 3 . 1  ml  host5  test  host  names  reverser  ip  match  host4  host1  1 . 2 . 3 . 4  get  canonical  host  name  then  return  1 . 2 . 3 . 5  includes  create  machine  list  with  a  list  of  of  hostnames  mockito  mock  inet  address  addressfactory  addresshost4  host_list  addressmockhost4  addressmockhost5  assertfalse   test for exclusion with an unknown ip   test for inclusion with an known ip  when  addresshost1  asserttrue  stringutils  getbyname  gettrimmedstringcollection  1 . 2 . 3 . 1  ml  host5  testhostnamesreverseripmatch  host4  host1  1 . 2 . 3 . 4  getcanonicalhostname  thenreturn  1 . 2 . 3 . 5  includes   create machinelist with a list of of hostnames  mockito  mock  inetaddress
__label__flaky add  record  to  bundle  action  table  _test  get  for  job  count  add  record  to  bundle  job  table  get  id  action1  job  job  action2  action3  test  bundle  actions  for  job  count  get  addrecordtobundleactiontable  _testgetforjobcount  addrecordtobundlejobtable  getid  action1  job  job  action2  action3  testbundleactionsforjobcountget
__label__nflaky the  server  is  stopped  assert  false  changes  an  active  reconfiguration  task  is  running .   get  changed  properties  when  dummy  get  end  time  test  start  reconfiguration  failure  due  to  existing  running  task  get  reconfiguration  task  status  lists  assert  true  expect  to  throw  io  exception  count  down  get  start  time  old1  the  first  task  has  finished .   new1  stopped  prop1  new  array  list  e  do  return  generic  test  utils  conf1  expect  to  throw  io  exception .   wait  async  reconfigure  task  finish  status2  any  fail  has  task  another  reconfiguration  task  is  running  assert  exception  contains  shutdown  reconfiguration  task  spy  start  reconfiguration  task  status  the server is stopped  assertfalse  changes   an active reconfiguration task is running .   getchangedproperties  when  dummy  getendtime  teststartreconfigurationfailureduetoexistingrunningtask  getreconfigurationtaskstatus  lists  asserttrue  expect to throw ioexception  countdown  getstarttime  old1   the first task has finished .   new1  stopped  prop1  newarraylist  e  doreturn  generictestutils  conf1  expect to throw ioexception .   waitasyncreconfiguretaskfinish  status2  any  fail  hastask  another reconfiguration task is running  assertexceptioncontains  shutdownreconfigurationtask  spy  startreconfigurationtask  status
__label__flaky next  end_  points  is_  security_  enabled  oozie  url  wc  set  header  contains  value  get  header  found  test  headers  assert  true  get  headers  does  not  contain  header !   servlet_  classes  run  test  headers  get  context  url  test  get  headers  validate  ws  version  header  testing  version  servlet  contains  key  clear  assert  equals  has  next  remove  header  call  assert  null  equals  get  header  names  header  next  end_points  is_security_enabled  oozieurl  wc  setheader  containsvalue  getheader  found  testheaders  asserttrue  get  headers does not contain header !   servlet_classes  runtest  headers  getcontexturl  test  getheaders  validatewsversion  headertestingversionservlet  containskey  clear  assertequals  hasnext  removeheader  call  assertnull  equals  getheadernames  header
__label__nflaky server  new  server  builder  rpc  thread  new  slow  ping  request  num  rpc  got  exception  conf  run  set  secret  manager  error  sleep  test  rpc  interrupted  barrier  leader  running  assert  true  thread  get  builder  await  interrupt  num  concurrent  rpc  latch  count  down  addr  set  num  handlers  set  e  log  start  get  client  set  verbose  leader  thread  thread  proxy  stop  slow  ping  setup  test  server  stop  a  single  thread  let  threads  get  past  the  barrier  should  not  cause  any  other  thread  to  get  an  error  server  newserverbuilder  rpcthread  newslowpingrequest  num  rpc got exception   conf  run  setsecretmanager  error  sleep  testrpcinterrupted  barrier  leaderrunning  asserttrue  thread   get  builder  await  interrupt  numconcurrentrpc  latch  countdown  addr  setnumhandlers  set  e  log  start  getclient  setverbose  leaderthread  thread  proxy  stop  slowping  setuptestserver   stop a single thread   let threads get past the barrier   should not cause any other thread to get an error
__label__flaky subwf  job  get  cmd  add  record  to  wf  action  table  coord  action  get  cmd  get  id  workflow  instance  get  status  add  record  to  coord  action  table  sub  workflow  action  should  have  been  purged  coord  job  wf  job  workflow  job  should  have  been  purged  add  record  to  wf  job  table  get  error  code  assert  not  null  coordinator  action  should  have  been  purged  get  coordinator  action  workflow  job  wf  action  subwf  action  wf  job  get  cmd  coordinator  job  should  have  been  purged  workflow  action  should  have  been  purged  sub  workflow  job  should  have  been  purged  wf  action  get  cmd  assert  equals  execute  add  record  to  coord  job  table  subwf  action  get  cmd  call  services  coordinator  job  1  coord  job  get  cmd  fail  coord-action-get . xml  workflow  action  coord  action  test  purge  coord  with  wf  child  with  sub  wf3  succeeded  subwf  job  error  code  je  jpa  service  subwfjobgetcmd  addrecordtowfactiontable  coordactiongetcmd  getid  workflowinstance  getstatus  addrecordtocoordactiontable  subworkflow action should have been purged  coordjob  wfjob  workflow job should have been purged  addrecordtowfjobtable  geterrorcode  assertnotnull  coordinator action should have been purged  get  coordinatoraction  workflowjob  wfaction  subwfaction  wfjobgetcmd  coordinator job should have been purged  workflow action should have been purged  subworkflow job should have been purged  wfactiongetcmd  assertequals  execute  addrecordtocoordjobtable  subwfactiongetcmd  call  services  coordinatorjob  1  coordjobgetcmd  fail  coord-action-get . xml  workflowaction  coordaction  testpurgecoordwithwfchildwithsubwf3  succeeded  subwfjob  errorcode  je  jpaservice
__label__nflaky get  bytes  transferred  codec  test  utils  test  coding  fragment  buffering  channel  saturated  channel  times  assert  flush  verify  more  stuff  dump  write  argument  matchers  standard  charsets  length  assert  equals  encoder  -  any  stuff---  mockito  outbuf  metrics  spy  wrap  stuff  getbytestransferred  codectestutils  testcodingfragmentbufferingchannelsaturated  channel  times  assert  flush  verify  more stuff  dump  write  argumentmatchers  standardcharsets  length  assertequals  encoder  -  any  stuff---  mockito  outbuf  metrics  spy  wrap  stuff
__label__flaky add  record  to  bundle  action  table  add  record  to  wf  action  table  coord  action  get  cmd  get  num  days  to  not  be  purged  test  purge  bundle  with  coord  child  with  wf  child1  date  utils  workflow  instance  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  bundle  job  bundle  job  bean  assert  not  null  coordinator  action  job  wf  action  wf  job  get  cmd  bundle  action  should  not  have  been  purged  execute  bundle  job  should  not  have  been  purged  coordinator  job  1  coord  job  get  cmd  fail  workflow  action  coord  action  succeeded  workflow  action  should  not  have  been  purged  bundle  job  get  cmd  get  id  coord  job  wf  job  add  record  to  wf  job  table  get  workflow  job  should  not  have  been  purged  workflow  job  get  app  name  bundle  action  wf  action  get  cmd  coordinator  action  should  not  have  been  purged  2011-01-01  t01:00  z  add  record  to  bundle  job  table  assert  equals  get  last  modified  time  add  record  to  coord  job  table  coordinator  job  should  not  have  been  purged  call  services  coord-action-get . xml  jpa  service  bundle  action  get  cmd  addrecordtobundleactiontable  addrecordtowfactiontable  coordactiongetcmd  getnumdaystonotbepurged  testpurgebundlewithcoordchildwithwfchild1  dateutils  workflowinstance  getstatus  addrecordtocoordactiontable  parsedateoozietz  bundlejob  bundlejobbean  assertnotnull  coordinatoraction  job  wfaction  wfjobgetcmd  bundle action should not have been purged  execute  bundle job should not have been purged  coordinatorjob  1  coordjobgetcmd  fail  workflowaction  coordaction  succeeded  workflow action should not have been purged  bundlejobgetcmd  getid  coordjob  wfjob  addrecordtowfjobtable  get  workflow job should not have been purged  workflowjob  getappname  bundleaction  wfactiongetcmd  coordinator action should not have been purged  2011-01-01t01:00z  addrecordtobundlejobtable  assertequals  getlastmodifiedtime  addrecordtocoordjobtable  coordinator job should not have been purged  call  services  coord-action-get . xml  jpaservice  bundleactiongetcmd
__label__nflaky x   .   x  x  x   .    .   x   .   x   .   x   .    .    .   x   .   x   .   x  x  x   .    .    .   x  x  x  x   .   x  x   .    .   x   .    .    .   x  x   .    .    .   x  x   .   x  x  x   .   x   .   x  x  x   .   x  x   .    .   x   .    .    .   x  x   .   x  x   .   x   .   x  x   .    .    .    .    .   x   .    .    .   x  x  x  x  x   .   x   .    .    .    .   x  x  x  x   .    .   x  x  x   .   x   .   x   .   x   .    .   x   .   x  x  x  x   .   x   .   x   .    .    .    .   x   .   x  x   .   x   .    .   x   .   x   .    .   x   .    .    .    .    .    .   x   .    .    .   x   .   x  x  x  x  x  x  x   .    .    .   x  x  test  decode  too  many  errors2   .    .    .    .    .    .    .   x   .   x   .    .    .    .    .    .    .   x  x  x  x   .    .    .   x  x  x  bit  matrix  matrix  decode  x   .    .   x  x  x   .   x  x  x  x  x  x  x  x  x  x  x  x  x   .    .    .   x   .   x  x  x   .    .    .   x  x   .   x   .   x  x  x  x  x  x  x  x   .   x  x  x  x   .    .   x  x   .    .   x  x  x  x   .    .   x   .    .   x  x  x   .   x  x   .    .   x   .    .    .    .   x  x  x   .   x   .    .   x  x   .    .   x   .    .   x  x   .    .    .    .    .   x   .    .    .    .    .   x  x  x   .   x   .    .    .   x   .   x   .   x  x  x  x  x  x   .    .   x   .   x  x  x  x  x   .   x   .    .   x  x   .   x   .    .   x   .   x  x   .    .    .    .    .   x  x   .    .    .    .    .   x   .    .    .   x   .   x   .    .    .   x  x  x   .    .    .    .    .   x   .    .    .    .    .   x  x  x  x  x   .   x   .   x  x   .    .   x   .    .   x   .   x  x  x  x  x  x  x  x  x  x  x  x  x   .    .   x   .   x  no_  points   .    .    .    .   x  x   .    .    .   x   .    .    .    .    .    .    .   x  x   .    .    .   x  x   .   x   .   x   .    .    .    .   x   .   x   .   x   .   x   .    .    .   x   .   x   .   x  x   .   x  x   .   x  x  x   .    .    .   x   .   x  x  x  x  x  x   .    .   x  x  x   .   x   .   x  x  x  x  x  x   .    .    .    .   x  x  x   .    .   x  x   .   x  x  x  x  x   .   x   .    .   x   .    .    .    .    .    .   x  x  x  x  x  x  x  x   .   x   .   x  x  x  x  x   .   x   .   x   .   x   .   x  x  x   .    .    .   x  x   .   x   .   x   .    .    .   x   .   x  x   .   x  x   .    .    .    .   x  x   .    .    .   parse  x   .   x   .    .   x   .   x   .   x   .   x   .   x   .   x   .   x   .    .    .    .    .   x   .   x  x  x  x  x   .   x  x  x  x   .    .   x  x  x  x   .    .   x   .    .    .    .   x   .    .   x  x  x   .   r   .    .   x  x  x  x   .   x   .    .    .    .    .   x  x  x  x  x  x   .    .    .    .    .    .   x  x  x  x   .    .    .   x  x   .    .   x   .   x   .    .    .    .   x  x   .   x   .    .   x   .   x   .   x   .   x  x   .    .   x   .   x  x   .    .    .   x   .    .   x  x  x   .    .    .   x  x   .   x  x   .    .    .    .    .   x   .    .    .   x  x  x   .   x  x   .   x  x  x  x   .   x  x   .    .   x   .    .     x  .  x x x  .   .  x  .  x  .  x  .   .   .  x  .  x  .  x x x  .   .   .  x x     x x  .  x x  .   .  x  .   .   .  x x  .   .   .  x x  .  x x x  .  x  .  x x     x  .  x x  .   .  x  .   .   .  x x  .  x x  .  x  .  x x  .   .   .   .   .  x  .       .   .  x x x x x  .  x  .   .   .   .  x x x x  .   .  x x x  .  x  .  x  .      x  .   .  x  .  x x x x  .  x  .  x  .   .   .   .  x  .  x x  .  x  .   .  x  .      x  .   .  x  .   .   .   .   .   .  x  .   .   .  x  .  x x x x x x x  .   .   .  x     x   testdecodetoomanyerrors2   .   .   .   .   .   .   .  x  .  x  .   .   .   .   .   .   .  x x x x  .   .   .  x x x     bitmatrix  matrix  decode  x  .   .  x x x  .  x x x x x x x x x x x x x  .   .   .  x  .  x x     x  .   .   .  x x  .  x  .  x x x x x x x x  .  x x x x  .   .  x x  .       .  x x x x  .   .  x  .   .  x x x  .  x x  .   .  x  .   .   .   .  x x x  .      x  .   .  x x  .   .  x  .   .  x x  .   .   .   .   .  x  .   .   .   .   .  x x x  .      x  .   .   .  x  .  x  .  x x x x x x  .   .  x  .  x x x x x  .  x  .   .      x x  .  x  .   .  x  .  x x  .   .   .   .   .  x x  .   .   .   .   .  x  .   .   .  x      .  x  .   .   .  x x x  .   .   .   .   .  x  .   .   .   .   .  x x x x x  .  x  .      x x  .   .  x  .   .  x  .  x x x x x x x x x x x x x  .   .  x  .  x     no_points   .   .   .   .  x x  .   .   .  x  .   .   .   .   .   .   .  x x  .   .   .  x x  .  x  .      x  .   .   .   .  x  .  x  .  x  .  x  .   .   .  x  .  x  .  x x  .  x x  .  x x     x  .   .   .  x  .  x x x x x x  .   .  x x x  .  x  .  x x x x x x  .       .   .   .  x x x  .   .  x x  .  x x x x x  .  x  .   .  x  .   .   .   .   .   .      x x x x x x x x  .  x  .  x x x x x  .  x  .  x  .  x  .  x x x  .       .   .  x x  .  x  .  x  .   .   .  x  .  x x  .  x x  .   .   .   .  x x  .   .   .      parse  x  .  x  .   .  x  .  x  .  x  .  x  .  x  .  x  .  x  .   .   .   .   .  x  .  x x     x x x  .  x x x x  .   .  x x x x  .   .  x  .   .   .   .  x  .   .  x x x      .    r   .   .  x x x x  .  x  .   .   .   .   .  x x x x x x  .   .   .   .   .   .  x x     x x  .   .   .  x x  .   .  x  .  x  .   .   .   .  x x  .  x  .   .  x  .  x  .  x      .  x x  .   .  x  .  x x  .   .   .  x  .   .  x x x  .   .   .  x x  .  x x  .       .   .   .   .  x  .   .   .  x x x  .  x x  .  x x x x  .  x x  .   .  x  .   . 
__label__flaky actual  random  utils  manager  incr  session  one  given  next  long  select  *  from  entity_counter  where  id  =  assert  that  delete  execute  should_delete_instance  crud  when  then  is  null  long  id  entity  actual  randomutils  manager  incr  session  one   given  nextlong  select * from entity_counter where id =   assertthat  delete  execute  should_delete_instance  crud   when   then  isnull  long  id  entity
__label__nflaky guice  argument  extractor  with  optional  optional  of  context  create  verify  invoke  custom  argument  extractor  with  optional  and  guice  should  be  instantiated  dep:bar:java . lang .   string  mock  controller  dep  guiceargumentextractorwithoptional  optional  of  context  create  verify  invoke  customargumentextractorwithoptionalandguiceshouldbeinstantiated  dep:bar:java . lang . string  mockcontroller  dep
__label__flaky bundle  job  get  cmd  add  record  to  bundle  job  table  get  id  assert  equals  get  status  execute  test  bundle  pause  unpause  neg1  call  services  fail  assert  not  null  get  job  job  jpa  service  should  not  reach  here .   bundlejobgetcmd  addrecordtobundlejobtable  getid  assertequals  getstatus  execute  testbundlepauseunpauseneg1  call  services  fail  assertnotnull  get  job  job  jpaservice  should not reach here . 
__label__nflaky name  value  pair  assert  test  null  value  not  equal  name  value  pair2  name  value  assert  not  equals  namevaluepair  assert  testnullvaluenotequal  namevaluepair2  name  value  assertnotequals
__label__flaky action  id  *  create  coordinator  job  < / output-events>  utc  tz  <instance>${coord:current ( 0 ) }< / instance>   \  '   timezone= \  '   utc \  '   freq_timeunit= \  '   day \  '   end_of_duration= \  '   none \  ' >  < / coordinator-app>  <action>  date  utils  get  status  parse  date  oozie  tz  set  frequency  <start-instance>${coord:current ( -3 ) }< / start-instance>  *  check  coord  action  ready  get  resource  as  string  2009-02-01  t23:59  <output-events>  coordinator  action  set  id  test  app  action  workflow . xml  set  created  time  set  user  unable  to  insert  the  test  job  record  to  table  print  stack  trace  <uri-template>file: /  /   execute  2009-02-02  t23:59  test  no  dataset  dependency  test  app  path  coordinator  job  set  group  fail  oozie  client  set  time  unit  notoken  <workflow>  <dataset  name= \  ' local_a \  '   frequency= \  ' 7 \  '   initial-instance= \  ' 2009-01-01  t01:00  < / workflow>  job  conf   \  '   end= \  ' 2009-02-03  t23:59  get  time  <coordinator-app  xmlns= \  ' uri:oozie:coordinator:0 . 2 \  '   name= \  '   name \  '   frequency= \ ""1 \ ""  start= \  ' 2009-02-01  t01:00  < / data-out>  get  id  set  app  path  < / dataset>  coord  job  wf-no-op . xml  write  to  file  set  mat  throttling  app  xml  < / action>  <app-path>  get  test  group  set  auth  token  set  time  zone  test  user  set  start  time  conf  str   / ${  year} / ${  month} / ${  day}< / uri-template>  set  app  name  set  set  last  action  number  set  job  xml  e  timeunit  set  concurrency  set  last  modified  time  assert  equals  -  test  coord  action  input  check  x  command-  c  set  status  set  conf  could  not  set  date / time  call  services  @1  was  not  stored  properly  in  db  io  utils  get  test  user  <data-out  name= \  '   local_  a \  '   dataset= \  ' local_a \  ' >  wf  xml  set  end  time  to  xml  string   / workflow . xml< / app-path>  jpa  service  0000000  get  fs  test  case  dir  action id              * create coordinator job             < / output-events>  utc  tz  <instance>${coord:current ( 0 ) }< / instance>   \  '  timezone= \  ' utc \  '  freq_timeunit= \  ' day \  '  end_of_duration= \  ' none \  ' >  < / coordinator-app>  <action>  dateutils  getstatus  parsedateoozietz  setfrequency  <start-instance>${coord:current ( -3 ) }< / start-instance>             * check coord action ready             getresourceasstring  2009-02-01t23:59  <output-events>  coordinatoraction  setid  testapp  action  workflow . xml  setcreatedtime  setuser  unable to insert the test job record to table  printstacktrace  <uri-template>file: /  /   execute  2009-02-02t23:59  testnodatasetdependency  testapppath  coordinatorjob  setgroup  fail  oozieclient  settimeunit  notoken  <workflow>  <dataset name= \  ' local_a \  '  frequency= \  ' 7 \  '  initial-instance= \  ' 2009-01-01t01:00  < / workflow>  jobconf   \  '  end= \  ' 2009-02-03t23:59  gettime  <coordinator-app xmlns= \  ' uri:oozie:coordinator:0 . 2 \  '  name= \  ' name \  '  frequency= \ ""1 \ "" start= \  ' 2009-02-01t01:00  < / data-out>  getid  setapppath  < / dataset>  coordjob  wf-no-op . xml  writetofile  setmatthrottling  appxml  < / action>  <app-path>  get  testgroup  setauthtoken  settimezone  testuser  setstarttime  confstr   / ${year} / ${month} / ${day}< / uri-template>  setappname  set  setlastactionnumber  setjobxml  e  timeunit  setconcurrency  setlastmodifiedtime  assertequals  -testcoordactioninputcheckxcommand-c  setstatus  setconf  could not set date / time  call  services  @1   was not stored properly in db  ioutils  gettestuser  <data-out name= \  ' local_a \  '  dataset= \  ' local_a \  ' >  wfxml  setendtime  toxmlstring   / workflow . xml< / app-path>  jpaservice  0000000  getfstestcasedir
__label__nflaky cluster  chi  square  test  rejected  counter  get  name  random  node  random  is  not  selecting  all  nodes  pick  random  nodes  excluding  the  2  nodes  in   / d1 / r3  check  that  they  have  the  proper  distribution  values  assert  false  get  new  node  occurrence  random  is  not  selecting  the  nodes  it  should  put  random  not  choosing  nodes  with  proper  distribution  observed  node  base  num  iterations  pick  random  nodes  num  test  runs  get  check  with  99 \ %  confidence  alpha=0 . 01  as  confidence  =  100  *   ( 1  -  alpha )   chi  square  test  chi  square  test  rejected  add  test  choose  random  contains  key  create  the  topology  expected  assert  equals  j  node1  choose  random  test  run  ~ / d1 / r3  node4  histogram  number  of  test  runs  node2  node3  size  number  of  iterations  to  do  the  test  network  topology   / d1 / r2   / d1 / r1  get  instance   / d1 / r3  cluster  chisquaretestrejectedcounter  getname  randomnode  random is not selecting all nodes   pick random nodes excluding the 2 nodes in  / d1 / r3   check that they have the proper distribution  values  assertfalse  getnewnode  occurrence  random is not selecting the nodes it should  put  random not choosing nodes with proper distribution  observed  nodebase  numiterations   pick random nodes  numtestruns  get   check with 99 \ % confidence alpha=0 . 01 as confidence = 100 *  ( 1 - alpha )   chisquaretest  chisquaretestrejected  add  testchooserandom  containskey   create the topology  expected  assertequals  j  node1  chooserandom  testrun  ~ / d1 / r3  node4  histogram   number of test runs  node2  node3  size   number of iterations to do the test  networktopology   / d1 / r2   / d1 / r1  getinstance   / d1 / r3
__label__flaky index  router .   get (  )  . route (  \ "" / user / {id} / {email} / user  dashboard \ "" )  . with (   application  controller . class    \ ""user  dashboard \ "" ) ;  assert  equals  this  looks  strange   but  is  expected:   /   test  reverse  routing  without  map  router  user  dashboard  start  server  test  1:  a  simple  route  without  replacements:  generated  reverse  route  get  reverse  route   / user / {id} / {email} / user  dashboard  index   router . get (  )  . route (  \ "" / user / {id} / {email} / userdashboard \ "" )  . with ( applicationcontroller . class   \ ""userdashboard \ "" ) ;  assertequals   this looks strange  but is expected:   /   testreverseroutingwithoutmap  router  userdashboard  startserver   test 1: a simple route without replacements:  generatedreverseroute  getreverseroute   / user / {id} / {email} / userdashboard
__label__nflaky date  dd  integer  primitive  equal  to  invoke  is  uuid  is  integer  uuid  when  put  context  validation  is  date  character  primitive  ee  something  else  what  should  be  skipped  assert  violation  then  return  some  setup  for  this  method:  test  body  parser  with  validation  errors  long  object  do  assert  that  character  object  is  float  float  primitive  and  test:  body  parser  engine  post  get  validation  has  violations  assert  true  test  object  double  primitive  map  timestamp  cc  a  b  c  d  integer  object  e  f  g  h  float  object  assert  null  mockito  long  primitive  get  parameters  double  object  date  dd  integerprimitive  equalto  invoke  isuuid  isinteger  uuid  when  put  context  validation  isdate  characterprimitive  ee  somethingelsewhatshouldbeskipped  assertviolation  thenreturn   some setup for this method:  testbodyparserwithvalidationerrors  longobject   do  assertthat  characterobject  isfloat  floatprimitive   and test:  bodyparserenginepost  getvalidation  hasviolations  asserttrue  testobject  doubleprimitive  map  timestamp  cc  a  b  c  d  integerobject  e  f  g  h  floatobject  assertnull  mockito  longprimitive  getparameters  doubleobject
__label__flaky build  test  model  assert  false  table1  admin  to  xml  table  exists  delete  put  make  sure  h  base  concurs  get  client  model  check  model  retrieve  the  schema  and  validate  it  get  code  from  xml  test  table  create  and  delete  xml  delete  the  table  get  body  schema  path  assert  equals  test  table  schema  model   /   make  sure  h  base  concurs   and  wait  for  the  table  to  come  online   / schema  response  enable  table  mimetype_  xml  create  the  table  buildtestmodel  assertfalse  table1  admin  toxml  tableexists  delete  put   make sure hbase concurs  get  client  model  checkmodel   retrieve the schema and validate it  getcode  fromxml  testtablecreateanddeletexml   delete the table  getbody  schemapath  assertequals  testtableschemamodel   /    make sure hbase concurs  and wait for the table to come online   / schema  response  enabletable  mimetype_xml   create the table
__label__nflaky  / foo  is  file   / new  dir / new  dir2 / foo  foo  assert  false  f  sys  chrooted  to  new  dir / foo  f  sys  target  test  create  delete  delete  create  file  create  file  with  a  2  component  dirs  recursively  assert  create  file  assert  true  create  file  with  recursive  dir  exists   / new  dir / foo  file  system  test  helper  delete  the  created  file  new  dir / new  dir2 / foo   / foo  isfile   / newdir / newdir2 / foo  foo  assertfalse  fsys  chrootedto  newdir / foo  fsystarget  testcreatedelete  delete  createfile   create file with a 2 component dirs recursively  assert   create file  asserttrue   create file with recursive dir  exists   / newdir / foo  filesystemtesthelper   delete the created file  newdir / newdir2 / foo
__label__flaky sla-  end  stage  job  is  removed  from  map  2  hours  ahead  _create  sla  registration  run  run  sla  worker  output  test  update  sla  action-1  test  same  job  multiple  events   ( start-miss   end-miss )   through  regular  check  assert  not  null  coordinator  action  add  status  event  1  hour  back  set  expected  end  test  start-miss  get  job  id  job-1  job-3  get  event  queue  job-2  job-4  ehs  coordinator  job  contains  set  length  size  is  enabled  name  sla1  app  type  set  expected  start  sla2  add  registration  event  sla  end  -  met !  !  !   sla  service  event  status  system  remains  same  as  before  since  assert  true  get  workflow  job  sla  start  -  miss !  !  !   assert  equals  1  hour  ahead  only  for  testing  get  sla  calculator  2  hours  back  test  same  job  multiple  events   ( start-met   end-met )   through  job  status  event  services  test  different  jobs  and  events  start-met  and  end-miss  current  time  millis  1  hour  ahead  sla  start  -  miss !  !  !   to  string  sla  start  -  met !  !  !   slas  sla  end  -  miss !  !  !    sla-end stage job is removed from map   2 hours ahead  _createslaregistration  run  runslaworker  output  testupdatesla  action-1   test same job multiple events  ( start-miss  end-miss )  through regular check  assertnotnull  coordinatoraction  addstatusevent   1 hour back  setexpectedend   test start-miss  getjobid  job-1  job-3  geteventqueue  job-2  job-4  ehs  coordinatorjob  contains  setlength  size  isenabled  name  sla1  apptype  setexpectedstart  sla2  addregistrationevent   sla end - met !  !  !   slaservice  eventstatus  system   remains same as before since  asserttrue  get  workflowjob   sla start - miss !  !  !   assertequals   1 hour ahead only for testing  getslacalculator   2 hours back   test same job multiple events  ( start-met  end-met )  through job status event  services   test different jobs and events start-met and end-miss  currenttimemillis   1 hour ahead  sla start - miss !  !  !   tostring   sla start - met !  !  !   slas   sla end - miss !  !  ! 
__label__nflaky server  create  test  server  test  created  server  is  not  alive  assert  not  live  server  createtestserver  testcreatedserverisnotalive  assertnotlive
__label__flaky end_  points  is_  security_  enabled  get  context  url  oozie  url  test  oozie  status  header  testing  version  servlet  clear  admin  run  assert  equals  -systemmode  args  call  -oozie  -status  servlet_  classes  normal  run  test  end_points  is_security_enabled  getcontexturl  oozieurl  testooziestatus  headertestingversionservlet  clear  admin  run  assertequals  -systemmode  args  call  -oozie  -status  servlet_classes  normal  runtest
__label__nflaky test  fix  block  compress  compress  blocksize  reader  map  file  key  class  conf  dir  suffix  fs  delete  cleanup  with  logger   . orig  fix  with  map  file . fix-ed  index   could  not  get  entries  #  file  system  get  value  close  test_  dir  key  io . seqfile . compress . blocksize  val  index  less  map  file  index  interval  length  index  assert  equals  set  int  no  of  valid  map  file  entries  wrong  io  utils  set  index  interval  size  rename  get  local  value-  exists  test  fix  block  compress . mapfile  not  found  writer  value  class  compression  no  blocks  compression  type  append  testfixblockcompress  compressblocksize  reader  mapfile  keyclass  conf  dir  suffix  fs  delete  cleanupwithlogger   . orig  fix  with mapfile . fix-ed index  could not get entries #   filesystem  get  value  close  test_dir  key  io . seqfile . compress . blocksize  val  indexlessmapfile  indexinterval  length  index  assertequals  setint  no of valid mapfile entries wrong  ioutils  setindexinterval  size  rename  getlocal  value-  exists  testfixblockcompress . mapfile  notfound  writer  valueclass  compression  noblocks  compressiontype  append
__label__flaky subwf  job  get  cmd  add  record  to  wf  action  table  get  id  workflow  instance  get  status  add  record  to  wf  job  table  for  neg  case  sub  workflow  job  should  not  have  been  purged  sub  workflow  action  should  not  have  been  purged  wf  job  add  record  to  wf  job  table  assert  not  null  get  workflow  job  should  not  have  been  purged  workflow  job  wf  action  subwf  action  wf  job  get  cmd  test  purge  wf  with  sub  wf2  wf  action  get  cmd  assert  equals  execute  subwf  action  get  cmd  call  services  1  fail  workflow  action  subwf  job  jpa  service  workflow  action  should  not  have  been  purged  subwfjobgetcmd  addrecordtowfactiontable  getid  workflowinstance  getstatus  addrecordtowfjobtablefornegcase  subworkflow job should not have been purged  subworkflow action should not have been purged  wfjob  addrecordtowfjobtable  assertnotnull  get  workflow job should not have been purged  workflowjob  wfaction  subwfaction  wfjobgetcmd  testpurgewfwithsubwf2  wfactiongetcmd  assertequals  execute  subwfactiongetcmd  call  services  1  fail  workflowaction  subwfjob  jpaservice  workflow action should not have been purged
__label__nflaky handler  request  get  time  jwt  public  key  for  signature  validation  must  be  provisioned  when  alternate  authentication  should  not  have  thrown  a  authentication  exception  se  service_  url  assert  true  get  cookies  get  jwt  get  request  url  init  cookie  test  no  public  key  jwt  then  return  get  properties  hadoop-jwt  encode  redirect  url  get  message  alternate  authenticate  alternate  authentication  should  have  thrown  a  servlet  exception  props  token  fail  private  key  serialize  contains  bob  mockito  response  mock  handler  request  gettime  jwt  public key for signature validation must be provisioned  when  alternateauthentication should not have thrown a authenticationexception  se  service_url  asserttrue  getcookies  getjwt  getrequesturl  init  cookie  testnopublickeyjwt  thenreturn  getproperties  hadoop-jwt  encoderedirecturl  getmessage  alternateauthenticate  alternateauthentication should have thrown a servletexception  props  token  fail  privatekey  serialize  contains  bob  mockito  response  mock
__label__flaky app  _  l3  a_  applications  org . apache . oozie . core . command .   workflow  runner  callable  respectively  _  l11_  ferr  check  if  the  lines  of  the  log  contain  the  expected  strings  _  l4_  str1  2009-06-24  02:43:13 958  debug  _  l10_:323  -  2009-06-24  02:43:13 958  debug  _  l12_:323  -  token  write  fwerr  2009-06-24  02:43:13 961  info  _  l9_:317  -  see  job  conf (   class )   or  job  conf#set  jar (   string )  .   test  stream  log  filename  date  below  is  equivalent  to  floor ( 6  hours  ago )   2009-06-24  02:43:13 986  warn  _  l3_:539  -   /   str  use  generic  options  parser  for  parsing  contains  sberr  reset  write  to  gz  file  debug|  info  released  lock  may  not  be  found .   sw1  end  workflow  state  change  sb  out  group  oozie . log  2009-06-24  02:43:14 505  info  _  l5_:317  -  useroozie  groupoozie  token-  app-  job-  define  parameter  set  parameter  log  statement  curr  time  close   / testerr . log  sw  f   / oozie . log  number  of  pending  actions  0  2009-06-24  02:43:13 958  debug  _  l8_:323  -  assert  equals  command .   workflow  runner  callable  _  l10_  2009-06-24  02:43:13 961  info  _  l2_:317  -  2009-06-24  02:43:13 958  warn  _  l1_:323  -   \ ""oozie . log \ ""  current  time  millis  oozie . log-  to  string  fw2  _  l10  fw1  fw3  f1  stream  log  f2  f3  8  hours  ago  2009-06-24  02:43:19 344  debug  _  l6_:323  -  useroozie  groupoozie  token  m  ytoken  app-  job-  split  get  test  case  dir  _  l8_  2009-06-24  02:43:13 961  info  _  l13_:317  -  oozie . log . gz  job  2009-06-24  02:43:13 958  debug  _  l1_:323  -  2009-06-24  02:43:13 961  info  _  l11_:317  -  and  corresponding  log  content  is  retrieved  properly  should  implement  tool  for  the  same .   _  l3  b_  multi  line  test  action-  released  lock   . gz  set  log  level  org . apache . oozie . core .   format  action-  number  of  pending  signals  to  check  0  oozie . log-2011-12-03-15 . bz2 . gz  between  the  start  and  end  times  of  the  job  _  l7_  excluded  from  log  retrieval  pattern  and  parameters  like  job  id   username  etc .   and / or  based  on  log  level  like  info   debug   etc .   out  filename  sb2  sb1  no  job  jar  file  set .   user  classes  sb3  system   / oozie . log . 2   / oozie . log . 1  14-200904160239--example-forkjoinwf  9  hours  ago  _  l2_  2009-06-24  02:43:29 151  debug  _  l7_:323  -  filename  date  formatter  generate  and  write  log  content  to  the  g  zip  file  x  log  streamer  2009-06-24  02:43:14 431  info  _  l4_:661  -  user  xf  action  oozie . log . gz  g  zip  file  would  always  be  included  in  list  of  files  for  log  retrieval  _  l1_  the  arguments .   append  set  last  modified  _  l9_  app  _l3a_applications   org . apache . oozie . core . command . workflowrunnercallable        respectively  _l11_  ferr   check if the lines of the log contain the expected strings  _l4_  str1    2009-06-24 02:43:13 958 debug _l10_:323 -    2009-06-24 02:43:13 958 debug _l12_:323 -  token  write  fwerr    2009-06-24 02:43:13 961 info _l9_:317 -  see jobconf ( class )  or jobconf#setjar ( string )  .   teststreamlog   filename date below is equivalent to floor ( 6 hours ago )     2009-06-24 02:43:13 986 warn _l3_:539 -   /   str  use genericoptionsparser for parsing   contains  sberr  reset  writetogzfile  debug|info  released lock  may not be found .    sw1  end workflow state change  sb  out  group  oozie . log    2009-06-24 02:43:14 505 info _l5_:317 - useroozie groupoozie token- app- job-   defineparameter  setparameter  logstatement  currtime  close   / testerr . log  sw  f   / oozie . log  number of pending actions 0     2009-06-24 02:43:13 958 debug _l8_:323 -  assertequals  command . workflowrunnercallable   _l10_    2009-06-24 02:43:13 961 info _l2_:317 -  2009-06-24 02:43:13 958 warn _l1_:323 -    \ ""oozie . log \ ""  currenttimemillis  oozie . log-  tostring  fw2  _l10  fw1  fw3  f1  streamlog  f2  f3   8 hours ago    2009-06-24 02:43:19 344 debug _l6_:323 - useroozie groupoozie tokenmytoken app- job-   split  gettestcasedir  _l8_    2009-06-24 02:43:13 961 info _l13_:317 -  oozie . log . gz  job  2009-06-24 02:43:13 958 debug _l1_:323 -    2009-06-24 02:43:13 961 info _l11_:317 -   and corresponding log content is retrieved properly  should implement tool for the same .    _l3b_multi line test  action- released lock   . gz  setloglevel  org . apache . oozie . core .   format  action- number of pending signals to check 0  oozie . log-2011-12-03-15 . bz2 . gz   between the start and end times of the job  _l7_   excluded from log retrieval   pattern and parameters like jobid  username etc .  and / or based on log level like info  debug  etc .   outfilename  sb2  sb1  no job jar file set .  user classes   sb3  system   / oozie . log . 2   / oozie . log . 1  14-200904160239--example-forkjoinwf   9 hours ago  _l2_    2009-06-24 02:43:29 151 debug _l7_:323 -  filenamedateformatter   generate and write log content to the gzip file  xlogstreamer    2009-06-24 02:43:14 431 info _l4_:661 -  user  xf  action   oozie . log . gz gzip file would always be included in list of files for log retrieval  _l1_  the   arguments .    append  setlastmodified  _l9_
__label__nflaky 231  44  108  59  226  126  1  141  36  147  231  shifts  to  base256  encodation  146  40  194  129  231  55  108  59  226  126  1  104  99  10  161  167  185  142  164  186  208  231  44  108  59  226  126  1  141  36  5  37  187  80  230  123  17  166  60  210  103  253  150  padding  necessary  at  the  end  231  63  108  59  226  126  1  141  36  5  37  187  80  230  123  17  166  60  210  103  1  129  231  38  220  2  208  120  20  150  35    231  38  219  2  208  120  20  150  35    23  1234567890123456789  146  40  190  87    assert  ends  with  assert  starts  with  visualized  mixed  base256  +  ascii  33  153  235  36  129  assert  equals  220  142  164  186  208  58  129  59  209  104  254  150  45  23  test  base256  encodation  231  44  108  59  226  126  1  104  create  binary  message  ascii  only   ( for  reference )   231  51  108  59  226  126  1  104  99  153  53  129    231  51  108  59  226  126  1  141  254  129    234  encode  high  level  231 44 108 59 226 126 1 141 36 147   231 shifts to base256 encodation  146 40 194 129  231 55 108 59 226 126 1 104 99 10 161 167 185 142 164 186 208  231 44 108 59 226 126 1 141 36 5 37 187 80 230 123 17 166 60 210 103 253 150   padding necessary at the end  231 63 108 59 226 126 1 141 36 5 37 187 80 230 123 17 166 60 210 103 1 129  231 38 220 2 208 120 20 150 35    231 38 219 2 208 120 20 150 35   23 1234567890123456789  146 40 190 87    assertendswith  assertstartswith  visualized   mixed base256 + ascii  33 153 235 36 129  assertequals   220 142 164 186 208 58 129 59 209 104 254 150 45   23  testbase256encodation  231 44 108 59 226 126 1 104  createbinarymessage   ascii only  ( for reference )   231 51 108 59 226 126 1 104 99 153 53 129    231 51 108 59 226 126 1 141 254 129   234  encodehighlevel
__label__flaky 2009-02-01  t01:00  z  get  id  date  utils  parse  date  oozie  tz  add  record  to  coord  job  table  call  get  mat  throttling  coordinator  job  test  mat  throttle  2009-02-03  t23:59  z  start  time  end  time  job  check  coord  waiting  2009-02-01t01:00z  getid  dateutils  parsedateoozietz  addrecordtocoordjobtable  call  getmatthrottling  coordinatorjob  testmatthrottle  2009-02-03t23:59z  starttime  endtime  job  checkcoordwaiting
__label__nflaky scheduler  a  test  using  weighted  time  cost  provider  no  requests  get  scheduler  with  weighted  time  cost  provider  assert  equals  get  priority  level  mock  call  scheduler  a  testusingweightedtimecostprovidernorequests  getschedulerwithweightedtimecostprovider  assertequals  getprioritylevel  mockcall
__label__flaky server  check  coord  action  coord  el  functions  add  partition  add  init  records  default  be  ready   / dt=20120430;country=usa  make  first  dependency  available  coordinator  action  test  update  coord  table  multiple  deps  v2  tablename  new  h  cat  dependency  table  new  h  cat  dependency2  new  h  cat  dependency1  populate  table  dt=20120430;country=brazil  hcat: /  /   checks  dependencies  in  order .   so  list  does  not  change  if  first  one  is  not  available  dt=20120430;country=usa   /   call   / dt=20120430;country=brazil  action  id  drop  partition  db  checks  only  for  first  missing  dependency    server  checkcoordaction  coordelfunctions  addpartition  addinitrecords  default   be ready   / dt=20120430;country=usa   make first dependency available  coordinatoraction  testupdatecoordtablemultipledepsv2  tablename  newhcatdependency  table  newhcatdependency2  newhcatdependency1  populatetable  dt=20120430;country=brazil  hcat: /  /    checks dependencies in order .  so list does not change if first one is not available  dt=20120430;country=usa   /   call   / dt=20120430;country=brazil  actionid  droppartition  db   checks only for first missing dependency
__label__nflaky assert  false  run  dir  create  file  assert  helper  assert  true  get  paths  are  cleaned  up  ensure  shutdown  hook  is  added  get  test  root  path  delete  on  exit  check  delete  on  exit  data  block  size  dir1 / file2  dir3 / dir4 / dir5 / dir6  test  delete  on  exit  num  blocks  has  shutdown  hook  file2  exists  create  delete  on  exit  entries  file1  shutdown  hook  manager  fc  file  context  assertfalse  run  dir  createfile  assert  helper  asserttrue  get   paths are cleaned up   ensure shutdown hook is added  gettestrootpath  deleteonexit  checkdeleteonexitdata  blocksize  dir1 / file2  dir3 / dir4 / dir5 / dir6  testdeleteonexit  numblocks  hasshutdownhook  file2  exists   create deleteonexit entries  file1  shutdownhookmanager  fc  filecontext
__label__flaky <execution>  lifo< / execution>  < / controls>  <datasets>  xmlns= \ ""uri:oozie:coordinator:0 . 2 \ "">  <controls>  <timeout>10< / timeout>  <concurrency>2< / concurrency>  conf  < / input-events>  app  path  sc  < / property>< / configuration>  < / workflow>  < / action>  < / coordinator-app>  write  to  file  app  xml  <coordinator-app  name= \ ""  name \ ""  frequency  error= \ ""10 \ ""  start= \ ""2009-02-01  t01:00  z \ ""  end= \ ""2009-02-03  t23:59  z \ ""  timezone= \ ""  utc \ ""  <property>  <name>input  b< / name>  <value>${coord:data  out (  \  '   local_  a \  '  ) }< / value>  file: /  /   get  test  case  dir  unit_  testing  <dataset  name= \ ""local_a \ ""  frequency= \ ""120 \ ""  initial-instance= \ ""2009-02-01  t01:00  z \ ""  <output-events>  <data-out  name= \ ""  local_  a \ ""  dataset= \ ""local_a \ "">  timezone= \ ""  utc \ "">  <uri-template>file: /  /  / tmp / coord / workflows / ${  year} / ${  day}< / uri-template>  < / dataset>  coordinator . xml  set  <configuration>  <property>  <name>input  a< / name>  <value>${coord:data  in (  \  '   a \  '  ) }< / value>  < / property>  <dataset  name= \ ""a \ ""  frequency= \ ""60 \ ""  initial-instance= \ ""2009-02-01  t01:00  z \ ""  call  oozie  client  fail  test  schema  error  get  test  user  < / datasets>  <input-events>  <instance>${coord:current ( -1 ) }< / instance>  < / data-out>  < / output-events>  <action>  <workflow>  <app-path>hdfs: /  /  / tmp / workflows / < / app-path>  exception  expected  if  schema  has  errors !   <data-in  name= \ ""  a \ ""  dataset= \ ""a \ "">  <instance>${coord:latest ( 0 ) }< / instance>  < / data-in>  file  <execution>lifo< / execution> < / controls> <datasets>   xmlns= \ ""uri:oozie:coordinator:0 . 2 \ ""> <controls> <timeout>10< / timeout> <concurrency>2< / concurrency>   conf  < / input-events>   apppath  sc  < / property>< / configuration> < / workflow> < / action> < / coordinator-app>  writetofile  appxml  <coordinator-app name= \ ""name \ "" frequencyerror= \ ""10 \ "" start= \ ""2009-02-01t01:00z \ "" end= \ ""2009-02-03t23:59z \ "" timezone= \ ""utc \ ""   <property> <name>inputb< / name> <value>${coord:dataout (  \  ' local_a \  '  ) }< / value>   file: /  /   gettestcasedir  unit_testing  <dataset name= \ ""local_a \ "" frequency= \ ""120 \ "" initial-instance= \ ""2009-02-01t01:00z \ ""   <output-events> <data-out name= \ ""local_a \ "" dataset= \ ""local_a \ "">   timezone= \ ""utc \ ""> <uri-template>file: /  /  / tmp / coord / workflows / ${year} / ${day}< / uri-template> < / dataset>   coordinator . xml  set  <configuration> <property> <name>inputa< / name> <value>${coord:datain (  \  ' a \  '  ) }< / value> < / property>   <dataset name= \ ""a \ "" frequency= \ ""60 \ "" initial-instance= \ ""2009-02-01t01:00z \ ""   call  oozieclient  fail  testschemaerror  gettestuser  < / datasets> <input-events>   <instance>${coord:current ( -1 ) }< / instance> < / data-out> < / output-events> <action> <workflow> <app-path>hdfs: /  /  / tmp / workflows / < / app-path>   exception expected if schema has errors !   <data-in name= \ ""a \ "" dataset= \ ""a \ ""> <instance>${coord:latest ( 0 ) }< / instance> < / data-in>    file
__label__nflaky view  fs  config  util  get  canonical  service  name  conf  file: /  /  /   service  name  fs  constants  test  get  canonical  service  name  with  default  mount  table  assert  null   / user  file  system  get  add  link  viewfs  configutil  getcanonicalservicename  conf  file: /  /  /   servicename  fsconstants  testgetcanonicalservicenamewithdefaultmounttable  assertnull   / user  filesystem  get  addlink
__label__flaky end_  points  is_  security_  enabled  get  context  url  oozie  url  e  length  assert  equals  unsupported_  version  :  supported  version  2  or  less   unsupported  versions-11-10  wc  substring  call  test  urls  fail  wrong  version  should  run  throw  exception  assert  true  v  get  oozie  url  to  string  servlet_  classes  get  protocol  url  run  test  starts  with  end_points  is_security_enabled  getcontexturl  oozieurl  e  length  assertequals  unsupported_version : supported version 2 or less  unsupported versions-11-10  wc  substring  call  testurls  fail  wrong version should run throw exception  asserttrue  v  getoozieurl  tostring  servlet_classes  getprotocolurl  runtest  startswith
__label__nflaky codec  test  utils  standard  charsets  channel  assert  equals  encoder  byte  buffer  empty  test  coding  empty  src  buffer  assert  allocate  flush  outbuf  assert  true  metrics  dump  complete  wrap  write  flip  stuff  is  completed  codectestutils  standardcharsets  channel  assertequals  encoder  bytebuffer  empty  testcodingemptysrcbuffer  assert  allocate  flush  outbuf  asserttrue  metrics  dump  complete  wrap  write  flip  stuff  iscompleted
__label__flaky position  read  fname  stat  position  read  option  assert  equals  num  times  test  write  and  read  rd  begin  pos  block  size  wr  chunk  size  assert  filename  option  test  read  pos  current  block   position read  fname  stat  positionreadoption  assertequals  numtimes  testwriteandread  rdbeginpos  blocksize  wrchunksize  assert  filenameoption  testreadposcurrentblock
__label__nflaky test  data  assert  false  parse  ac  ls  commit  delete  zk  util  get  bytes  fencing  node  path   / node2   / node1  assert  true  create  get  data  common  configuration  keys  set  data  utf-8  txn  node1  zk  acl  node2  curator  create  mode   / fencing  equals  exists  arrays  create  transaction  test  transaction  testdata  assertfalse  parseacls  commit  delete  zkutil  getbytes  fencingnodepath   / node2   / node1  asserttrue  create  getdata  commonconfigurationkeys  setdata  utf-8  txn  node1  zkacl  node2  curator  createmode   / fencing  equals  exists  arrays  createtransaction  testtransaction
__label__flaky play  a  server   / foo  read  ascii  add  header  b  open  connection  assert  equals  set  body  enqueue  get  url   / bar  cache-  control:  max-age=60  content-  location:   / bar  content  location  does  not  populate  cache  play  a  server   / foo  readascii  addheader  b  openconnection  assertequals  setbody  enqueue  geturl   / bar  cache-control: max-age=60  content-location:  / bar  contentlocationdoesnotpopulatecache
__label__nflaky value2  value1  value4  value3  this \  \ that  assert  param  format  elements  param= \ ""this \  \  \  \ that \ ""   name3=value3;  param= \ ""this that \ ""   name4=value4;  param   name5  name1=value1;  param=regular_stuff   name2=value2;  assert  equals  param3  param4  test  elements  formatting  param1  param2  name5  name4  buf  regular_stuff  name3  element1  element2  element3  elements  element4  element5  to  string  name2  name1  this that  value2  value1  value4  value3  this \  \ that  assert  param  formatelements  param= \ ""this \  \  \  \ that \ ""  name3=value3; param= \ ""this that \ ""    name4=value4; param  name5  name1=value1; param=regular_stuff  name2=value2;   assertequals  param3  param4  testelementsformatting  param1  param2  name5  name4  buf  regular_stuff  name3  element1  element2  element3  elements  element4  element5  tostring  name2  name1  this that
__label__flaky prep  get  id  workflow  instance  action  get  cmd  coord  job  wf  bean  add  record  to  wf  job  table  assert  not  null  get  add  two  jobs  to  update  list  workflow  job  job  test  bulk  insert  updates  update  list  add  get  status  str  insert  list  running  wf  get  cmd  assert  equals  add  two  actions  to  insert  list  execute  add  record  to  coord  job  table  set  status  coordinator  job  1  services  2  workflow  action  bulk  update  cmd  succeeded  create  workflow  action  action1  job  action2  jpa  service  prep  getid  workflowinstance  actiongetcmd  coordjob  wfbean  addrecordtowfjobtable  assertnotnull  get   add two jobs to update list  workflowjob  job  testbulkinsertupdates  updatelist  add  getstatusstr  insertlist  running  wfgetcmd  assertequals   add two actions to insert list  execute  addrecordtocoordjobtable  setstatus  coordinatorjob  1  services  2  workflowaction  bulkupdatecmd  succeeded  createworkflowaction  action1  job  action2  jpaservice
__label__nflaky test  fail  in  start  fail  in  start  service  assert  launch  outcome    testfailinstart  failinstartservice  assertlaunchoutcome
__label__flaky worker_  capacity_  bytes  common  utils  write  type  assert  false  get  used  bytes  user_  quota_  unit_  bytes  delete  get  file  test  utils  assert  file  assert  true  get  file  uri  delete  non-existing  files .   workers  uniq  path  get  workers  info  create  byte  file  sleep_  ms  assert  equals  k  sleep  ms  get  capacity  bytes  exist  get  file  id  write  bytes  delete  file  test  size  is  in  memory  s  tfs  file  id  worker_capacity_bytes  commonutils  writetype  assertfalse  getusedbytes  user_quota_unit_bytes  delete  getfile  testutils  assert  file  asserttrue  get  fileuri   delete non-existing files .   workers  uniqpath  getworkersinfo  createbytefile  sleep_ms  assertequals  k  sleepms  getcapacitybytes  exist  getfileid  writebytes  deletefiletest  size  isinmemory  stfs  fileid
__label__nflaky server  content  type  test  force  http1  listener  core  matchers  not  null  value  equal  to  connect  future  some  stuff  listen  endpoint  assert  get  duration  http  version  policy  get  head  get  get  address  https   / stuff  get  code  http  version  connect  requester  localhost  get  version  address  http  status  start  result  future1  method  assert  that  execute  target  get  time  unit  get  port  future  timeout  response1  message1  server  contenttype  testforcehttp1  listener  corematchers  notnullvalue  equalto  connectfuture  some stuff  listen  endpoint  assert  getduration  httpversionpolicy  gethead  get  getaddress  https   / stuff  getcode  httpversion  connect  requester  localhost  getversion  address  httpstatus  start  resultfuture1  method  assertthat  execute  target  gettimeunit  getport  future  timeout  response1  message1
__label__flaky cluster  get  name  starting  test  test  decommission  conf  all  datanodes  must  be  alive  num  namenodes  start  cluster  decommissioned  nodes  get  iteration  client  test  decommission  num  datanodes  write  file  cleanup  file  info  check  file  add  start  decommissioning  one  namenode  at  a  time  get  dfs  client  log  datanode  report  replicas  decom  node  decommission  one  node .   verify  that  node  is  decommissioned .   ensure  decommissioned  datanode  is  not  automatically  shutdown  assert  equals  get  file  system  get  name  node  admin  states  assert  null  are  allowed  to  register  with  the  namenode  file  sys  file1  namenode  decom  list  decommission  node  shutdown  test  decommission . dat  datanode  report  type  cluster  getname  starting test testdecommission  conf  all datanodes must be alive  numnamenodes  startcluster  decommissionednodes  get  iteration  client  testdecommission  numdatanodes  writefile  cleanupfile  info  checkfile  add   start decommissioning one namenode at a time  getdfsclient  log  datanodereport  replicas  decomnode   decommission one node .  verify that node is decommissioned .    ensure decommissioned datanode is not automatically shutdown  assertequals  getfilesystem  getnamenode  adminstates  assertnull   are allowed to register with the namenode  filesys  file1  namenodedecomlist  decommissionnode  shutdown  testdecommission . dat  datanodereporttype
__label__nflaky is  available  create  jetty  configuration   / mycontext / request_path  contains  string  jetty  configuration  with  context  is  the  port  correct   ( otherwise  logging  will  be  wrong )    / mycontext / context_path  port  won \  ' t  be  correct  b / c  actually  configured  via  jetty  file  null  value  not  http: /  / localhost:   / mycontext / home  conf / jetty . com . example . conf  get  random_  port  hello  world !   external  configuration  path  context  path  standalone  start  is  is  started  assert  that  jetty  configuration   / mycontext  get  port  jetty . xml  random  port  and  then  write  the  file  back  out  page  request  path  removes  context  path  shutdown   / request_path  isavailable  createjettyconfiguration   / mycontext / request_path  containsstring  jettyconfigurationwithcontext   is the port correct  ( otherwise logging will be wrong )    / mycontext / context_path   port won \  ' t be correct b / c actually configured via jetty file  nullvalue  not  http: /  / localhost:   / mycontext / home  conf / jetty . com . example . conf  get  random_port  hello world !   externalconfigurationpath  contextpath  standalone  start  is  isstarted  assertthat  jettyconfiguration   / mycontext  getport  jetty . xml   random port and then write the file back out  page   requestpath removes contextpath  shutdown   / request_path
__label__flaky a  write  str  b  writable  utils  dos  assert  equals  baos  dis  assert  null  to  byte  array  test  write  read  str  close  read  str  a  writestr  b  writableutils  dos  assertequals  baos  dis  assertnull  tobytearray  testwritereadstr  close  readstr
__label__nflaky code  sessions  are  not  shared  on  single  result  instances  request  above )   got  assigned  to  us !   conf / jetty . com . session . conf  client2  null  value  client1  client0  should  not  get  a  session  value  back  establish  session  with  a  set-cookie  header  not  follow  redirects  get  set-  cookie  random_  port  http  request  cookie  external  configuration  path  standalone  start  is  assert  that   / bad  route  port  get  base  urls   / get  or  create  session  call  redirect  so  its  session  is  processed  first  time   ( triggers  bug  for  issue  #450 )   header  this  test  is  not  really  specific  to  jetty   but  its  easier  to  test  here  shutdown  code  sessionsarenotsharedonsingleresultinstances   request above )  got assigned to us !   conf / jetty . com . session . conf  client2  nullvalue  client1  client0   should not get a session value back   establish session with a set-cookie header  not  followredirects  get  set-cookie  random_port  httprequest  cookie  externalconfigurationpath  standalone  start  is  assertthat   / badroute  port  getbaseurls   / getorcreatesession   call redirect so its session is processed first time  ( triggers bug for issue #450 )   header   this test is not really specific to jetty  but its easier to test here  shutdown
__label__flaky date  script  executor  session  given  simple  select  *  from  simple  where  id  =  crud  when  of  id  table  should_delete_by_id  execute  script  template  all  random  utils  manager  is  empty  next  long  rows  assert  that  execute  simple  entity / insert_single_row . cql  immutable  map  then  long  delete  by  id  build  date  key  date  scriptexecutor  session   given  simple  select * from simple where id =   crud   when  of  id  table  should_delete_by_id  executescripttemplate  all  randomutils  manager  isempty  nextlong  rows  assertthat  execute  simpleentity / insert_single_row . cql  immutablemap   then  long  deletebyid  builddatekey
__label__nflaky fail  test  set  max  invalid  assert  set  default  max  per  route  pool  set  max  per  route  illegal  argument  exception  should  have  been  thrown  fail  testsetmaxinvalid  assert  setdefaultmaxperroute  pool  setmaxperroute  illegalargumentexception should have been thrown
__label__flaky init  as  get  test  user  assert  not  null  get  add  record  to  bundle  job  table  get  id  services  job  job  test  authorization  service  for  bundle  authorize  for  job  init  as  gettestuser  assertnotnull  get  addrecordtobundlejobtable  getid  services  job  job  testauthorizationserviceforbundle  authorizeforjob
__label__nflaky object  under  test  no  origin  in  list  is  allowed  assert  false  conf  regex:https ? : \  \  /  \  \  / sub1 . example . com ( :0-9+ )  ?    foo . nomatch . com  foo . example2 . com  https: /  / sub1 . example . com:8080  example2 . com  put  filter  config  foo . example2 . com  match  multiple  sub-domains  assert  assert  true  http: /  / sub1 . example . com  foo . nomatch1 . com  foo . nomatch2 . com  * . example2 . com  test  mixed  regex  pattern  matching  origins  init  setup  the  configuration  settings  of  the  server  http: /  / sub1 . example . com:1234  second  origin  is  allowed  cross  origin  filter  are  origins  allowed  filter  first  origin  is  allowed  foo . example2 . com  foo . nomatch . com  https: /  / sub1 . example . com  foo . bar . example2 . com  foo:example2 . com   object under test   no origin in list is allowed  assertfalse  conf  regex:https ? : \  \  /  \  \  / sub1 . example . com ( :0-9+ )  ?     foo . nomatch . com foo . example2 . com  https: /  / sub1 . example . com:8080  example2 . com  put  filterconfig  foo . example2 . com   match multiple sub-domains  assert  asserttrue  http: /  / sub1 . example . com  foo . nomatch1 . com foo . nomatch2 . com  * . example2 . com  testmixedregexpatternmatchingorigins  init   setup the configuration settings of the server  http: /  / sub1 . example . com:1234   second origin is allowed  crossoriginfilter  areoriginsallowed  filter   first origin is allowed  foo . example2 . com foo . nomatch . com  https: /  / sub1 . example . com  foo . bar . example2 . com  foo:example2 . com
__label__flaky 2009-02-02  t23:59  z  get  time  2009-02-01  t23:59  z  get  id  replace  first  should  throw  exception  due  to  non-existent  nn  path .   therefore  fail  parse  date  utc  caicc  path  exists  date  utils  localhost:5330  app  path  test  non  existing  name  node  coord  assert  true  start  time  non  exist  dir  localhost  get  coord  action  error  code  load  state  init   / coord-input / 2010 / 07 / 09 / 01 / 00  non  exist  destroy  assert  equals  services  -  test  coord  action  input  check  x  command-  c  e0901  hadoop  accessor  service  input  dir  add  record  to  coord  job  table  call  job  id  @1  get  coord  action  error  msg  fail  contains  get  test  user  not  in  oozies  whitelist  set  system  property  0000000-  white  list  to  string  end  time  job  setting  the  test  path  with  non  exist  dir  override  the  name  node  while  list  for  testing  purpose  only .   get  fs  test  case  dir  2009-02-02t23:59z  gettime  2009-02-01t23:59z  getid  replacefirst  should throw exception due to non-existent nn path .  therefore fail  parsedateutc  caicc  pathexists  dateutils  localhost:5330  apppath  testnonexistingnamenode  coord  asserttrue  starttime  nonexistdir  localhost  getcoordactionerrorcode  loadstate  init   / coord-input / 2010 / 07 / 09 / 01 / 00  nonexist  destroy  assertequals  services  -testcoordactioninputcheckxcommand-c  e0901  hadoopaccessorservice  inputdir  addrecordtocoordjobtable  call  jobid  @1  getcoordactionerrormsg  fail  contains  gettestuser  not in oozies whitelist  setsystemproperty  0000000-  whitelist  tostring  endtime  job   setting the test path with nonexistdir   override the name node while list for testing purpose only .   getfstestcasedir
__label__nflaky memory:foo  name1:  sean  tel1:+12125551212  test  address  book  au  do  test  foo  sean  +12125551212  memory:foo  name1:sean  tel1:+12125551212    testaddressbookau  dotest  foo  sean  +12125551212
__label__flaky get  time  date  utils  some_bundle_parent_id  parse  date  oozie  tz  insert  job  job  id2  job  id1  assert  not  null  executor  get  00002-  set  bundle  id  job2  shouldn \  ' t  be  in  the  list  because  it  has  a  parent  job2  2011-01-01  t01:00  z  assert  equals  test  coord  jobs  get  for  purge  jpa  executor  with  parent  execute  services  coordinator  job  -  test  coord  jobs  get  for  purge  jpa  executor-  c  size  job  list  jpa  service  00001-  gettime  dateutils  some_bundle_parent_id  parsedateoozietz  insertjob  jobid2  jobid1  assertnotnull  executor  get  00002-  setbundleid   job2 shouldn \  ' t be in the list because it has a parent  job2  2011-01-01t01:00z  assertequals  testcoordjobsgetforpurgejpaexecutorwithparent  execute  services  coordinatorjob  -testcoordjobsgetforpurgejpaexecutor-c  size  joblist  jpaservice  00001-
__label__nflaky aaa  find  min  max  lengths  in  symbols  assert  equals  results  empty  string  values  should  be  ignored  by  find  min  max  lengths  in  symbols  symbols  char  sequence  to  regex  mapper  aaa    findminmaxlengthsinsymbols  assertequals  results  emptystringvaluesshouldbeignoredbyfindminmaxlengthsinsymbols  symbols  charsequencetoregexmapper
__label__flaky play  bogus  data  ping  play  it  back  verify  the  peer  received  what  was  expected  assert  equals  invalid_  stream  rst_  stream  type_  rst_  stream  bogus  data  frame  does  not  disrupt  connection  accept  frame  send  frame  peer  spdy3  write  the  mocking  script  ping  connection  write  utf8  take  frame  rst  stream  play  bogus  data  ping   play it back   verify the peer received what was expected  assertequals  invalid_stream   rst_stream  type_rst_stream  bogusdataframedoesnotdisruptconnection  acceptframe  sendframe  peer  spdy3   write the mocking script   ping  connection  writeutf8  takeframe  rststream
__label__nflaky get  class  bad  contents  resolve  conf  test  bad  file  result   . test  bad  file   . txt  get  files  write  delete  on  exit  add  map  file  mapping  get  canonical  path  set  as  char  sink  create  temp  file  assert  equals  set  conf  net_  topology_  table_  mapping_  file_  key  names  size  network  topology  host  name2  host  name1  get  simple  name  file  charsets  getclass  bad contents  resolve  conf  testbadfile  result   . testbadfile   . txt  get  files  write  deleteonexit  add  mapfile  mapping  getcanonicalpath  set  ascharsink  createtempfile  assertequals  setconf  net_topology_table_mapping_file_key  names  size  networktopology  hostname2  hostname1  getsimplename  file  charsets
__label__flaky rows_  one  expect  four  keys   ( two  from  each  family )   in  half  the  rows  test  row  two  test  row  one-2  h  constants  only  look  in  first  group  of  rows  test  row  one-3  bytes  qualifiers_  one  families  values  expect  only  two  keys   ( one  from  each  family )   in  half  the  rows  expect  varied  numbers  of  keys   4  per  row  in  group  one   6  per  row  in  group  two  expected  keys  verify  scan  no  early  out  expected  rows  test  qualifier  one-2  f  rows_  two  to  bytes  test . +-2  test  qualifier  filter  kvs  set  filter  test  row  two-0  qualifiers_  two  match  two  keys   ( one  from  each  family )   in  half  the  rows  verify  scan  full  compare  op  expect  4  keys  per  row  across  both  groups  test  row  two-3  test  row  two-2  rows_one   expect four keys  ( two from each family )  in half the rows  testrowtwo   testrowone-2  hconstants   only look in first group of rows   testrowone-3  bytes  qualifiers_one  families  values   expect only two keys  ( one from each family )  in half the rows   expect varied numbers of keys  4 per row in group one  6 per row in group two  expectedkeys  verifyscannoearlyout  expectedrows  testqualifierone-2  f  rows_two  tobytes  test . +-2  testqualifierfilter  kvs  setfilter   testrowtwo-0  qualifiers_two   match two keys  ( one from each family )  in half the rows  verifyscanfull  compareop   expect 4 keys per row across both groups   testrowtwo-3   testrowtwo-2
__label__nflaky urlto:foo:bar . com  test  urlto  type  http: /  / bar . com  urlto::bar . com  urlto::http: /  / bar . com  foo  http: /  / bar . com  urlto:foo:bar . com  parsed  result  type  do  test  result  urlto:foo:bar . com  testurltotype  http: /  / bar . com  urlto::bar . com  urlto::http: /  / bar . com  foo  http: /  / bar . com  urlto:foo:bar . com  parsedresulttype  dotestresult
__label__flaky cluster  sleep  at  least  ignore  interrupts  get  modification  time  conf  fs   / test  out  open  a  file   and  get  its  initial  modification  time .   assert  true  10  milliseconds  mod  time  after  close  get  file  status  create  close  restart  name  node  restart  the  nn   and  make  sure  that  the  later  mod  time  is  still  used .   initial  mod  time  assert  equals  get  file  system  wait  and  then  close  the  file .   ensure  that  the  mod  time  goes  up .   mod  time  after  restart  test  path  build  sleep  time  thread  util  shutdown  test  mod  time  persists  after  restart  cluster  sleepatleastignoreinterrupts  getmodificationtime  conf  fs   / test  out   open a file  and get its initial modification time .   asserttrue   10 milliseconds  modtimeafterclose  getfilestatus  create  close  restartnamenode   restart the nn  and make sure that the later mod time is still used .   initialmodtime  assertequals  getfilesystem   wait and then close the file .  ensure that the mod time goes up .   modtimeafterrestart  testpath  build  sleeptime  threadutil  shutdown  testmodtimepersistsafterrestart
__label__nflaky content  type  listener  core  matchers  set  exception  callback  get  cause  async  server  bootstrap  listen  instance  of  io  reactor  config  assert  get  duration  create  https   / stuff  set  lookup  registry  requester  localhost  set  stream  listener  logging  exception  callback  logging  http1  stream  listener  set  io  session  listener  result  future1  *  set  so  timeout  method  assert  that  execute  logging  conn  pool  listener  fail  ex  secure  all  ports  strategy  timeout  set  need  client  auth  server  set  io  reactor  config  create  client  ssl  context  cause  bootstrap  h2  requester  bootstrap  set  conn  pool  listener  set  tls  strategy  some  stuff  set  io  session  decorator  create  server  ssl  context  get  execution  exception  expected  get  address  ssl  test  contexts  address  custom  start  ssl  engine  test  tls  client  auth  failure  target  get  time  unit  logging  io  session  decorator  get  port  build  future  logging  io  session  listener  initialize  register  contenttype  listener  corematchers  setexceptioncallback  getcause  asyncserverbootstrap  listen  instanceof  ioreactorconfig  assert  getduration  create  https   / stuff  setlookupregistry  requester  localhost  setstreamlistener  loggingexceptioncallback  logginghttp1streamlistener  setiosessionlistener  resultfuture1  *  setsotimeout  method  assertthat  execute  loggingconnpoollistener  fail  ex  secureallportsstrategy  timeout  setneedclientauth  server  setioreactorconfig  createclientsslcontext  cause  bootstrap  h2requesterbootstrap  setconnpoollistener  settlsstrategy  some stuff  setiosessiondecorator  createserversslcontext  get  executionexception expected  getaddress  ssltestcontexts  address  custom  start  sslengine  testtlsclientauthfailure  target  gettimeunit  loggingiosessiondecorator  getport  build  future  loggingiosessionlistener  initialize  register
__label__flaky test  request  is  bound  to  holder  number=42  get  page  get  content  assert  that  url  send  a  request  to  the  servlet  with  a  query  string  part  base  url  contains  get  status  code  verify  the  servlet  sends  back  the  query  string   ? number=42  http  servlet  request  holder  servlet  page  get  web  response  is  equal  to  testrequestisboundtoholder  number=42  getpage  getcontent  assertthat  url   send a request to the servlet with a query string part  baseurl  contains  getstatuscode   verify the servlet sends back the query string   ? number=42  httpservletrequestholderservlet  page  getwebresponse  isequalto
__label__nflaky assert  size  incorrect  encoded  size  byte  test  v  long4  bytes  assert  equals  write  and  verify  short  assert  size  incorrect encoded size  byte  testvlong4bytes  assertequals  writeandverify  short
__label__flaky fake  dn  id  get  default  socket  factory  conf  block  key  update  interval  client  datanode  protocol  get  replica  visible  length  num  open  fds:  set  block  token  fds  at  end  fds !   user  group  information  info  1 . 1 . 1 . 1  log  block3  create  remote  user  proxy  to  no  where  get  connect  address  fd_  dir  proxy  fail  block  token  lifetime  create  client  datanode  protocol  proxy  stop  localhost:  assume  server  leaked  test  block  token  rpc  leak  rpc  get  proxy  fake  block  fake-pool  system  all  of  generate  token  get  block  id  stop  proxy  sm  count  open  file  descriptors  addr  actually  close  the  tcp  connections  to  the  real  target  dn .   create  mock  datanode  b  fake-storage  enum  set  dfs  util  start  assert  equals  fds  at  start  token  assume  true  net  utils  get  port  current  time  millis  exists  junk  end  time  fakednid  getdefaultsocketfactory  conf  blockkeyupdateinterval  clientdatanodeprotocol  getreplicavisiblelength  num open fds:  setblocktoken  fdsatend   fds !   usergroupinformation  info  1 . 1 . 1 . 1  log  block3  createremoteuser  proxytonowhere  getconnectaddress  fd_dir  proxy  fail  blocktokenlifetime  createclientdatanodeprotocolproxy  stop  localhost:  assume  server  leaked   testblocktokenrpcleak  rpc  getproxy  fakeblock  fake-pool  system  allof  generatetoken  getblockid  stopproxy  sm  countopenfiledescriptors  addr   actually close the tcp connections to the real target dn .   createmockdatanode  b  fake-storage  enumset  dfsutil  start  assertequals  fdsatstart  token  assumetrue  netutils  getport  currenttimemillis  exists  junk  endtime
__label__nflaky verify  paths  with  non-standard  ports  test  short  authority  with  other  port  myfs: /  / host:456  myfs: /  / host . a . b:456  fs  ips  authorities  get  verified  fs  verifypaths   with non-standard ports  testshortauthoritywithotherport  myfs: /  / host:456  myfs: /  / host . a . b:456  fs  ips  authorities  getverifiedfs
__label__flaky delete  list  coordinator  action  b1  should  have  been  deleted  coordinator  action  c2  should  have  been  deleted  coordinator  job  c  should  have  been  deleted  test  delete  coords  get  id  action  c1  add  record  to  coord  action  table  action  c2  action  a1  action  a2  coordinator  job  b  should  have  been  deleted  job  b  job  a  get  error  code  coordinator  job  a  should  have  been  deleted  assert  not  null  job  c  get  coordinator  action  coordinator  action  c1  should  have  been  deleted  add  coordinator  action  a2  should  have  been  deleted  assert  equals  action  b1  execute  add  record  to  coord  job  table  action  b2  coordinator  job  services  fail  coord-action-get . xml  coordinator  action  a1  should  have  been  deleted  coordinator  action  b2  should  have  been  deleted  error  code  je  jpa  service  deletelist  coordinator action b1 should have been deleted  coordinator action c2 should have been deleted  coordinator job c should have been deleted  testdeletecoords  getid  actionc1  addrecordtocoordactiontable  actionc2  actiona1  actiona2  coordinator job b should have been deleted  jobb  joba  geterrorcode  coordinator job a should have been deleted  assertnotnull  jobc  get  coordinatoraction  coordinator action c1 should have been deleted  add  coordinator action a2 should have been deleted  assertequals  actionb1  execute  addrecordtocoordjobtable  actionb2  coordinatorjob  services  fail  coord-action-get . xml  coordinator action a1 should have been deleted  coordinator action b2 should have been deleted  errorcode  je  jpaservice
__label__nflaky vv  get  key  d  k  found  set  configuration  regular  key  not  found  conf  assert  equals  deprecated  key  not  found  k  add  deprecation  entry  get  value  k  found  n  k  found  assert  true  v  v  get  equals  test  iterator  with  deprecated  keys  n  k_iterator  d  k_iterator  new  key  not  found  vv  getkey  dkfound  set  configuration  regular key not found  conf  assertequals  deprecated key not found  k  adddeprecation  entry  getvalue  kfound  nkfound  asserttrue  v  v  get  equals  testiteratorwithdeprecatedkeys  nk_iterator  dk_iterator  new key not found
__label__flaky get  name  user . name  conf  as  list  system  assert  string  utils  assert  not  null  get  join  get  groups  test  service  init  set  get  property  get  conf  g  destroy  groups  services     services  size  assert  not  same  arrays  getname  user . name  conf  aslist  system  assert  stringutils  assertnotnull  get  join  getgroups  testservice  init  set  getproperty  getconf  g  destroy  groups  services     services  size  assertnotsame  arrays
__label__nflaky se  list  status  increment  inc . xml  assert  equals  status  checker  get  highest  level  1  get  value  se  test  attribute  processing  get  attribute  by  name  size  do  test  assert  true  assert  not  null  get  attr  selist  status  increment  inc . xml  assertequals  statuschecker  gethighestlevel  1  getvalue  se  testattributeprocessing  getattributebyname  size  dotest  asserttrue  assertnotnull  get  attr
__label__flaky date  script  executor  session  one  given  update  simple  eq  consistencylist  contains  exactly  when  get  list  of  where  should_dsl_update_list_set  at  index  id  row  table  execute  script  template  random  utils  manager  one  next  long  consistency  list_  set  at  index  assert  that  two  execute  simple  entity / insert_single_row . cql  immutable  map  select  consistencylist  from  simple  where  id  =  then  long  build  date  key  from  base  table  consistency  list  dsl  date  scriptexecutor  session  one   given  update  simple  eq  consistencylist  containsexactly   when  getlist  of  where  should_dsl_update_list_setatindex  id  row  table  executescripttemplate  randomutils  manager  one  nextlong  consistencylist_setatindex  assertthat  two  execute  simpleentity / insert_single_row . cql  immutablemap  select consistencylist from simple where id =    then  long  builddatekey  frombasetable  consistencylist  dsl
__label__nflaky path  random  test  get  file  block  locations2  get  len  off  begin  one  test  get  file  status  off  end  next  int  fs  status  path  random  testgetfileblocklocations2  getlen  offbegin  onetest  getfilestatus  offend  nextint  fs  status
__label__flaky bb  next  key  value  mid  row  reader  familyname  is  seeked  conf  timestamp .   dir  get  last  key  fs  keys  from  top  half  of  the  file .   bytes  split  make  a  reference  1234567890  storedir  assert  true  regionname  store  file  get  path  test  reference  final  row  midkey  get  key  get  reader  create  key  value  from  key  kv  get  row  range  ref  hsf  seek  to  write  store  file  get  writer  equals  hsf  writer  make  a  store  file  and  write  data  to  it .   ref  path  get  scanner  first  bb  next  keyvalue  midrow  reader  familyname  isseeked  conf   timestamp .   dir  getlastkey  fs   keys from top half of the file .   bytes  split   make a reference  1234567890  storedir  asserttrue  regionname  storefile  getpath  testreference  finalrow  midkey  getkey  getreader  createkeyvaluefromkey  kv  getrow  range  refhsf  seekto  writestorefile  getwriter  equals  hsf  writer   make a store file and write data to it .   refpath  getscanner  first
__label__nflaky fail  10 . 119 . 103 . 112  create  file  with  entries  ips . txt  10 . 221 . 204 . 1 / 23  10 . 221 . 102 / 23  ips  test  with  a  wrong  entry  fail  10 . 119 . 103 . 112  createfilewithentries  ips . txt  10 . 221 . 204 . 1 / 23  10 . 221 . 102 / 23  ips  testwithawrongentry
__label__flaky end_  points  rest  constants  is_  security_  enabled  get  context  url  oozie  url  test  job  status  get  job  info  mock  dag  engine  service  assert  equals  get  id  wc  wf  call  1  servlet_  classes  run  test  end_points  restconstants  is_security_enabled  getcontexturl  oozieurl  testjobstatus  getjobinfo  mockdagengineservice  assertequals  getid  wc  wf  call  1  servlet_classes  runtest
__label__nflaky parent  init  test  add  started  sibling  in  start  incorrect  number  of  services  start  assert  in  state  state  assert  equals  sibling  stop  size  add  service  get  services  parent  init  testaddstartedsiblinginstart  incorrect number of services  start  assertinstate  state  assertequals  sibling  stop  size  addservice  getservices
__label__flaky add  record  to  coord  job  table  for  waiting  get  id  date  utils  parse  date  oozie  tz  test  action  mater  for  hcatalog  incorrect  uri  get  error  code  get  2009-03-11  t10:00  z  start  time  init  print  stack  trace  e  destroy  get  message  assert  equals  services  coord-job-for-matd-neg-hcat . xml  expected  command  exception  but  didn \  ' t  catch  any  call  services  coordinator  job  fail  2009-03-06  t010:00  z  setup  services  for  h  catalog  end  time  error  code  job  unexpected  exception  addrecordtocoordjobtableforwaiting  getid  dateutils  parsedateoozietz  testactionmaterforhcatalogincorrecturi  geterrorcode  get  2009-03-11t10:00z  starttime  init  printstacktrace  e  destroy  getmessage  assertequals  services  coord-job-for-matd-neg-hcat . xml  expected command exception but didn \  ' t catch any  call  services  coordinatorjob  fail  2009-03-06t010:00z  setupservicesforhcatalog  endtime  errorcode  job  unexpected exception
__label__nflaky result  assert  read  link  test  read  symlink  with  null  input  assert  equals  file  util  result    assert  readlink  testreadsymlinkwithnullinput  assertequals  fileutil
__label__flaky wait  finish  new  file  finished  add  task  latch  callback  latch  starting  add  copy  to  file  random  stream  file  get  staging  cache  stats  assert  true  assert  not  null  count  down  id_  prefix  get  if  present  info  add  cache  log  f  start  accepted  assert  cache  stats  folder  stage  assert  file  waitfinish  newfile  finished add  tasklatch  callbacklatch  starting add  copytofile  randomstream  file  getstagingcachestats  asserttrue  assertnotnull  countdown  id_prefix  getifpresent  info  add  cache  log  f   start  accepted  assertcachestats  folder  stage  assertfile
__label__nflaky bad  matrix  set  region  expected  matrix  flip  matrix  inverted  center  matrix  assert  equals  full  matrix  matrix  unset  fail  empty  matrix  clone  xor  center  matrix  data  matrix  test  xor  badmatrix  setregion  expectedmatrix  flipmatrix  invertedcentermatrix  assertequals  fullmatrix  matrix  unset  fail  emptymatrix  clone  xor  centermatrix  datamatrix  testxor
__label__flaky get  job  tracker  uri  get  name  <arg>exit1< / arg>  is  main  successful  <java>  assert  false  get  status  create  context  action  xml  failed /   killed  test  exit1  submit  error  is  successful  assert  true  launcher  mapper  get  error  code  context  end  wait  for  <job-tracker>  get  data  is  completed  get  name  node  uri  < / java>  ae  < / main-class>  < / job-tracker>  running  job  get  action  assert  equals  check  get  external  status  <name-node>  <main-class>  < / name-node>  1  assert  null  workflow  action  submit  action  evaluate  is  complete  getjobtrackeruri  getname  <arg>exit1< / arg>  ismainsuccessful  <java>  assertfalse  getstatus  createcontext  actionxml  failed / killed  testexit1submiterror  issuccessful  asserttrue  launchermapper  geterrorcode  context  end  waitfor  <job-tracker>  getdata  iscompleted  getnamenodeuri  < / java>  ae  < / main-class>  < / job-tracker>  runningjob  getaction  assertequals  check  getexternalstatus  <name-node>  <main-class>  < / name-node>  1  assertnull  workflowaction  submitaction  evaluate  iscomplete
__label__nflaky codec  never  test  output  stream  not  closing  cos  mock  verify  output  stream  close  codec  never  testoutputstreamnotclosing  cos  mock  verify  outputstream  close
__label__flaky cluster  name  node  adapter  ns  racks  conf   / rack2  wait  for  replication   / rack1  fs  *  like  the  previous  test  but  the  block  starts  with  a  single  replica   *  and  therefore  unlike  the  previous  test  the  block  does  not  start  *  off  needing  replicas .   create  file  create  a  file  with  one  block  with  a  replication  factor  of  1  dfs  test  util  test  sufficiently  single  repl  block  uses  new  rack  b  get  conf  file  path  get  file  system  set  replication  replication_  factor  get  name  node   / test  file  build  num  data  nodes  get  first  block  shutdown  get  namesystem  cluster  namenodeadapter  ns  racks  conf   / rack2  waitforreplication   / rack1  fs       * like the previous test but the block starts with a single replica      * and therefore unlike the previous test the block does not start     * off needing replicas .        createfile   create a file with one block with a replication factor of 1  dfstestutil  testsufficientlysinglereplblockusesnewrack  b  getconf  filepath  getfilesystem  setreplication  replication_factor  getnamenode   / testfile  build  numdatanodes  getfirstblock  shutdown  getnamesystem
__label__nflaky set  name  renaming  is  not  allowed  fail  context  rename  test  setname  renaming is not allowed  fail  context  renametest
__label__flaky bundle  job  get  executor  add  record  to  bundle  action  table  action  should  be  purged .   should  fail .   job  should  be  purged .   should  fail .   get  id  run  date  utils  get  status  parse  date  oozie  tz  engine  assert  not  null  get  purge  runnable  get  bundle  job  job  wait  for  a  test  purge  service  for  bundle  2011-01-01  t01:00  z  add  record  to  bundle  job  table  assert  equals  execute  job  id  services  fail  bundle  action  get  executor1  bundle  action  get  executor2  u  action1  job  action2  jpa  service  evaluate  bundlejobgetexecutor  addrecordtobundleactiontable  action should be purged .  should fail .   job should be purged .  should fail .   getid  run  dateutils  getstatus  parsedateoozietz  engine  assertnotnull  get  purgerunnable  getbundlejob  job  waitfor  a  testpurgeserviceforbundle  2011-01-01t01:00z  addrecordtobundlejobtable  assertequals  execute  jobid  services  fail  bundleactiongetexecutor1  bundleactiongetexecutor2  u  action1  job  action2  jpaservice  evaluate
__label__nflaky _test  authentication  auth  authentication  filter  authenticator  test  case  set  property  true  simple  pseudo  authentication  handler  set  authentication  handler  config  test  fallbackto  pseudo  authenticator  anonymous  props  _testauthentication  auth  authenticationfilter  authenticatortestcase  setproperty  true  simple  pseudoauthenticationhandler  setauthenticationhandlerconfig  testfallbacktopseudoauthenticatoranonymous  props
__label__flaky get  name  set  hdfs: /  / foo:12345 /   generic  test  utils  conf  did  not  fail  with  fake  fs  get  file  system   . foo  p  fail  does  not  use  port  information  assert  exception  contains  exists  test  logical  uri  should  not  have  ports  dfs_  client_  failover_  proxy_  provider_  key_  prefix  ioe  getname  set  hdfs: /  / foo:12345 /   generictestutils  conf  did not fail with fake fs  getfilesystem   . foo  p  fail  does not use port information  assertexceptioncontains  exists  testlogicalurishouldnothaveports  dfs_client_failover_proxy_provider_key_prefix  ioe
__label__nflaky handler  assert  nothing  thrown  handle  handler  assertnothingthrown  handle
__label__flaky play  server  c  get  sequence  number  connection  reused .   redirected  by  location:   / b  assert  code  location:   / c  assert  body   / a  test  redirect  from   / b  to   / c  assert  contains  headers   / a  has  moved !   test:  redirect  from   / b  to   / c  connection  reused  again !   redirect  add  header  take  request  assert  equals  set  response  code  set  body   / b  has  moved !   url  new  connection .   enqueue  test:  redirect  from   / a  to   / b  get  url  build  redirect  from   / a  to   / b  on  success  play  server  c  getsequencenumber   connection reused .   redirectedby  location:  / b  assertcode  location:  / c  assertbody   / a  test  redirect from  / b to  / c  assertcontainsheaders   / a has moved !   test: redirect from  / b to  / c   connection reused again !   redirect  addheader  takerequest  assertequals  setresponsecode  setbody   / b has moved !   url   new connection .   enqueue  test: redirect from  / a to  / b  geturl  build  redirect from  / a to  / b  onsuccess
__label__nflaky result  json  view  test  set  and  get  json  view  get  json  view  assert  equals  result  result  jsonview  testsetandgetjsonview  getjsonview  assertequals  result
__label__flaky status  _test  get  sla  events  for  seq  id  test  sla  events  get  for  seq  id  -  test  sla  events  get  for  seq  id  jpa  executor-  w  current  add  record  to  sla  event  table  get  time  0000000-  wf  id  status  _testgetslaeventsforseqid  testslaeventsgetforseqid  -testslaeventsgetforseqidjpaexecutor-w  current  addrecordtoslaeventtable  gettime  0000000-  wfid
__label__nflaky renderable  contains  string  make  sure  we  get  the  correct  result .  .  .   assets  controller  when  result  captor  content  result  result  check  etag  has  been  called  mime  types  get  renderable  user-agent:  *  add  etag  response  streams  verify  ok  render  result2  serve  static  disallow:   /   finalize  headers  without  flash  and  session  cookie  byte  array  output  stream  then  return  any  string  capture  we  mocked  this  one:  assert  equals  test  serve  static  robots  txt  context  renderable  eq  assert  that  http  cache  toolkit  get  value  get  status  code  results  mockito  any  long  get  content  type  mimetype  get  output  stream  to  string   / robots . txt  get  request  path  renderable  containsstring   make sure we get the correct result .  .  .   assetscontroller  when  resultcaptor  content  result  result   check etag has been called  mimetypes  getrenderable  user-agent: *  addetag  responsestreams  verify  ok  render  result2  servestatic  disallow:  /   finalizeheaderswithoutflashandsessioncookie  bytearrayoutputstream  thenreturn  anystring  capture   we mocked this one:  assertequals  testservestaticrobotstxt  contextrenderable  eq  assertthat  httpcachetoolkit  getvalue  getstatuscode  results  mockito  anylong  getcontenttype  mimetype  getoutputstream  tostring   / robots . txt  getrequestpath
__label__flaky @  time  out  creation  time  check  coord  action  timeout .   tz  test  timeout  add  init  records  substring  system  thread  call  sleep  current  time  millis  coordinator  action  missing  deps  action  id  hdfs: /  /  / dirx / filex  index  of  set  coord  action  creation  time  @  timeoutcreationtime  checkcoordaction   timeout .   tz  testtimeout  addinitrecords  substring  system  thread  call  sleep  currenttimemillis  coordinatoraction  missingdeps  actionid  hdfs: /  /  / dirx / filex  indexof  setcoordactioncreationtime
__label__nflaky door  get  class  name  via  implicit  rules  default  component  registry  assert  equals  comp  class  setter  aggregation  type  testget  class  name  via  implicit  rules  door  getclassnameviaimplicitrules  defaultcomponentregistry  assertequals  compclass  setter  aggregationtype  testgetclassnameviaimplicitrules
__label__flaky coord  el  functions  e  action   / dt=20120430;country=usa  coordinator  action  property  action  coord-job-for-action-input-check . xml  test  resolve  coord  configuration  add  record  to  coord  action  table  for  waiting  new  h  cat  dependency  coord-action-for-action-push-check . xml  element  list  workflow  populate  table  get  child  parse  xml   /   hcat: /  / dummyhcat:1000 / db1 / table1 / ds= / 2009-29  coordinator  job  get  children   / dt=20120412;country=brazil  get  namespace  action  id  job  server  add  record  to  coord  job  table  for  waiting  check  coord  action  configuration  ca  bean  get  id  hcat: /  / dummyhcat:1000 / db1 / table1 / ds= / 2009-29 hcat: /  / dummyhcat:1000 / db1 / table1 / ds= / 2009-29   default  get  z  tablename  value  table  new  h  cat  dependency2  xml  utils  new  h  cat  dependency1  hcat: /  /   assert  equals  e1  e2  call  get  value  get  action  xml  config  elem  db    coordelfunctions  eaction   / dt=20120430;country=usa  coordinatoraction  property  action  coord-job-for-action-input-check . xml  testresolvecoordconfiguration  addrecordtocoordactiontableforwaiting  newhcatdependency  coord-action-for-action-push-check . xml  elementlist  workflow  populatetable  getchild  parsexml   /   hcat: /  / dummyhcat:1000 / db1 / table1 / ds= / 2009-29  coordinatorjob  getchildren   / dt=20120412;country=brazil  getnamespace  actionid  job  server  addrecordtocoordjobtableforwaiting  checkcoordaction  configuration  cabean  getid  hcat: /  / dummyhcat:1000 / db1 / table1 / ds= / 2009-29 hcat: /  / dummyhcat:1000 / db1 / table1 / ds= / 2009-29   default  get  z  tablename  value  table  newhcatdependency2  xmlutils  newhcatdependency1  hcat: /  /   assertequals  e1  e2  call  getvalue  getactionxml  configelem  db
__label__nflaky prepare  append  key  out  key  key0  assert  true  multiple  close  should  have  no  effect .   skip  test  failure  close  key  stream  many  times  in  writer  writer  close  write  get  bytes  prepareappendkey  outkey  key0  asserttrue  multiple close should have no effect .   skip  testfailureclosekeystreammanytimesinwriter  writer  close  write  getbytes
__label__flaky conn  set  request  method  is_  security_  enabled  assert  true  json  content-type   / v1 / admin / *  collections  run  test  rest  constants  test  configuration  open  connection  contains  key  http  servlet  response  assert  equals  parse  get  input  stream  url  json  value  call  services  get  header  field  get  get  response  code  create  url  starts  with  conn  setrequestmethod  is_security_enabled  asserttrue  json  content-type   / v1 / admin / *  collections  runtest  restconstants  testconfiguration  openconnection  containskey  httpservletresponse  assertequals  parse  getinputstream  url  jsonvalue  call  services  getheaderfield  get  getresponsecode  createurl  startswith
__label__nflaky test  do  filter  authentication  with  invalid  token  _test  do  filter  authentication  testdofilterauthenticationwithinvalidtoken  _testdofilterauthentication
__label__flaky date  script  executor  session  given  update  simple  should_dsl_update_set_add  eq  select  simpleset  from  simple  where  id  =  simpleset  contains  exactly  simple  set_  add  to  when  of  where  id  row  table  execute  script  template  random  utils  manager  get  set  one  next  long  assert  that  execute  simple  entity / insert_single_row . cql  immutable  map  simple  set  then  long  build  date  key  from  base  table  dsl  date  scriptexecutor  session   given  update  simple  should_dsl_update_set_add  eq  select simpleset from simple where id =   simpleset  containsexactly  simpleset_addto   when  of  where  id  row  table  executescripttemplate  randomutils  manager  getset  one  nextlong  assertthat  execute  simpleentity / insert_single_row . cql  immutablemap  simpleset   then  long  builddatekey  frombasetable  dsl
__label__nflaky test  set  bulk  array  assert  true  get  assert  false  set  bulk  testsetbulk  array  asserttrue  get  assertfalse  setbulk
__label__flaky file_  size  cluster  filepath1  recover  lease  using  create   / immediate  recover  lease-sameclient  namenode  triggers  lease  recovery  on  next  attempt  to  write-for-open .   block_  size  create  another  file  using  the  same  client   / immediate  recover  lease-longlease  replication_  num  create  file  recover  the  first  file  filepath  write  bytes  into  the  file .   test  recover  lese  from  a  different  client  create  set  lease  period  buffer  test  immediate  recovery  of  lease  write  close  actual   / immediate  recover  lease-shortlease  next  int  test  recoverlease  from  the  same  client  continue  to  write  to  the  second  file  stm  append  test  util  dfs  verify  file  size  long_  lease_  period  close  the  file  immediately  recover  lease  buf_  size  to  string  short_  lease_  period  file_size  cluster  filepath1  recoverleaseusingcreate   / immediaterecoverlease-sameclient   namenode triggers lease recovery on next attempt to write-for-open .   block_size   create another file using the same client   / immediaterecoverlease-longlease  replication_num  createfile   recover the first file  filepath   write bytes into the file .    test recoverlese from a different client  create  setleaseperiod  buffer  testimmediaterecoveryoflease  write  close  actual   / immediaterecoverlease-shortlease  nextint   test recoverlease from the same client   continue to write to the second file  stm  appendtestutil  dfs  verifyfile  size  long_lease_period   close the file immediately  recoverlease  buf_size  tostring  short_lease_period
__label__nflaky get  bytes  transferred  payload2  get  metrics  outbuffer  in  buffer  readable  channel  test  read  write  frame  assert  assert  not  null  frame  type  get  frame  consts  get  frames  transferred  write  get  payload  content  read  frame2  get  stream  id  assert  equals  byte  buffer  remaining  get  value  allocate  get  type  bytes  to  byte  array  get  flags  wrap  writable  channel  frame  getbytestransferred  payload2  getmetrics  outbuffer  inbuffer  readablechannel  testreadwriteframe  assert  assertnotnull  frametype  get  frameconsts  getframestransferred  write  getpayloadcontent  read  frame2  getstreamid  assertequals  bytebuffer  remaining  getvalue  allocate  gettype  bytes  tobytearray  getflags  wrap  writablechannel  frame
__label__flaky coord  id2  coord  id1  coord  action  id2  assert  equals  create  filter  list  list  coord  action  id1  execute  jobid  services  sla  events  get  cmd  last  seq  id  size  assert  not  null  get  filter  list  jpa  service  test  get  sla  events  for  combined  with  range  coordid2  coordid1  coordactionid2  assertequals  createfilterlist  list  coordactionid1  execute  jobid  services  slaeventsgetcmd  lastseqid  size  assertnotnull  get  filterlist  jpaservice  testgetslaeventsforcombinedwithrange
__label__nflaky get  payload  content  read  payload1  payload2  frame1  value  of  frame2  get  stream  id  assert  equals  in  buffer  readable  channel  byte  buffer  test  read  frame  multiple  remaining  frame  flag  assert  allocate  get  type  assert  not  null  frame  type  get  of  get  flags  getpayloadcontent  read  payload1  payload2  frame1  valueof  frame2  getstreamid  assertequals  inbuffer  readablechannel  bytebuffer  testreadframemultiple  remaining  frameflag  assert  allocate  gettype  assertnotnull  frametype  get  of  getflags
__label__flaky get  job  tracker  uri  map-reduce  conf  get  status  create  context  get  job  hadoop . counters  will  always  be  set  in  case  of  mr  action .   output  counter  get  execution  stats  assert  not  null  <map-reduce>  context  create  write  wait  for  <job-tracker>  group  group . name  ae  counters  parse  xml  < / job-tracker>  dummy  get  file  system  check  <name-node>  assert  for  stats  info  stored  in  the  context .   < / name-node>  configuration .   input  contains  workflow  action  succeeded  true  get  oozie  action  external  stats  write  property  submit  action  get  external  child  i  ds  data . txt  evaluate  job  id  launcher  id  external  child  i  ds  will  always  be  null  in  case  of  mr  action .   assert  false  user . name  get  external  id  fs  has  id  swap  create  base  hadoop  conf  action  xml  is  successful  assert  true  launcher  mapper  write  property  as  true .   get  end  test  set  execution  stats_when_user_has_specified_stats_write_  true  close  get  data  action_  type  get  name  node  uri  output  dir  launcher  job  xml  utils  for  name  get  action  assert  equals  mr  job  hadoop . counters  input  dir  get  external  status  < / map-reduce>  services  create  job  client  assert  null  w  to  xml  string  equals  get  var  to  string  job  client  user  get  fs  test  case  dir  is  complete  getjobtrackeruri  map-reduce  conf  getstatus  createcontext  getjob   hadoop . counters will always be set in case of mr action .   output  counter  getexecutionstats  assertnotnull  <map-reduce>  context  create  write  waitfor  <job-tracker>  group  group . name  ae  counters  parsexml  < / job-tracker>  dummy    getfilesystem  check  <name-node>   assert for stats info stored in the context .   < / name-node>   configuration .   input  contains  workflowaction  succeeded  true  getoozieactionexternalstatswriteproperty  submitaction  getexternalchildids  data . txt  evaluate  jobid  launcherid   external child ids will always be null in case of mr action .   assertfalse  user . name  getexternalid  fs  hasidswap  createbasehadoopconf  actionxml  issuccessful  asserttrue  launchermapper   write property as true .   get  end  testsetexecutionstats_when_user_has_specified_stats_write_true  close  getdata  action_type  getnamenodeuri  outputdir  launcherjob  xmlutils  forname  getaction  assertequals  mrjob  hadoop . counters  inputdir  getexternalstatus  < / map-reduce>  services  createjobclient  assertnull  w  toxmlstring  equals  getvar  tostring  jobclient  user  getfstestcasedir  iscomplete
__label__nflaky zero  add  witness  one  assert  size  clone  clear  assert  equals  arrays  as  list  cloning  cb  zero  add  witness  one  assertsize  clone  clear  assertequals  arrays  aslist  cloning  cb
__label__flaky get  time  get  status  myapp  xml  schema  error   cvc-pattern-valid:  value   \  ' ${some  param} \  '   expected  status  was  failed  due  to  incorrect  xml  element  <start  to= \  ' ${some  param} \  '    / >  mytoken  get  error  code  assert  true  get  me  coordinator  action  action  is  not  facet-valid  with  respect  to  pattern  -  coord-  action  start  command-  c@1  myjob  test  action  start  with  error  reported  assert  equals  execute  wf  app  call  services  fail  contains  add  record  to  action  table  action  id  to  string  error  code  jpa  service  get  error  message  gettime  getstatus  myapp  xml schema error  cvc-pattern-valid: value  \  ' ${someparam} \  '    expected status was failed due to incorrect xml element  <start to= \  ' ${someparam} \  '   / >  mytoken  geterrorcode  asserttrue  get  me  coordinatoraction  action  is not facet-valid with respect to pattern  -coord-actionstartcommand-c@1  myjob  testactionstartwitherrorreported  assertequals  execute  wfapp  call  services  fail  contains  addrecordtoactiontable  actionid  tostring  errorcode  jpaservice  geterrormessage
__label__nflaky max  queue  flush  timeout   \  \  (   assert  contains  match  ms \  \  )   exceeded .   @  suppress  warnings (  \ ""deprecation \ "" )   max  flush  time  start  stop  exits  when  max  runtime  reached  loop  len  status  checker  set  max  flush  time  runtime  of  0  means  wait  forever   so  use  1  ms  instead  confirms  that  stop  exited  when  runtime  reached  add  appender  stop  la  do  append  verify  confirms  that  all  entries  do  end  up  being  flushed  if  we  wait  long  enough  delaying  list  appender  join  async  appender  base  max queue flush timeout  \  \  (   assertcontainsmatch   ms \  \  )  exceeded .    @suppresswarnings (  \ ""deprecation \ "" )   maxflushtime  start  stopexitswhenmaxruntimereached  looplen  statuschecker  setmaxflushtime   runtime of 0 means wait forever  so use 1 ms instead   confirms that stop exited when runtime reached  addappender  stop  la  doappend  verify   confirms that all entries do end up being flushed if we wait long enough  delayinglistappender  join  asyncappenderbase
__label__flaky _test  is  main  successful  test  output  action  dir  has  output  data  assert  false  running  job  is  main  done  get  file  system  fs  has  id  swap  out  get  id  swap  path  is  successful  assert  true  launcher  mapper  get  error  path  exists  get  output  data  path  evaluate  wait  for  get  fs  test  case  dir  is  complete  _test  ismainsuccessful  testoutput  actiondir  hasoutputdata  assertfalse  runningjob  ismaindone  getfilesystem  fs  hasidswap  out  getidswappath  issuccessful  asserttrue  launchermapper  geterrorpath  exists  getoutputdatapath  evaluate  waitfor  getfstestcasedir  iscomplete
__label__nflaky then  return  invoke  when  param1  enum  csv  param  validation  should  work  enum  csv  param  assert  true  context  create  verify  white   black  mock  controller  validation  has  violation  get  parameter  thenreturn  invoke  when  param1  enumcsvparamvalidationshouldwork  enumcsvparam  asserttrue  context  create  verify  white black  mockcontroller  validation  hasviolation  getparameter
__label__flaky play  server  read  ascii  abc  the  request  should  work  once  and  then  fail  assert  equals  get  keep  alive  set  body  get  input  stream  integer  enqueue  get  url  set  read  timeout  input  fail  connection1  client  open  shutdown  connection2  play    server  readascii  abc   the request should work once and then fail  assertequals  getkeepalive  setbody  getinputstream  integer  enqueue  geturl  setreadtimeout  input  fail  connection1  client  open  shutdown  connection2
__label__nflaky get  cpu  frequency  write  fake   / proc / stat  file .   write  fake   / proc / cpuinfo  file .   cpuinfo_  format  in  this  case   cpu  usage  should  not  be  updated .   string  cpu  time  tracker  f  writer  cpu  frequency  k  hz  fake_  jiffy_  length  temp  file  s  time  write  close  num  processors  delete  on  exit  parsing  proc  stat  and  cpu  file  fake_  statfile  fake_  cpufile  advance  the  time  and  sample  again .   this  time   we  call  get  cpu  usage  percentage (  )   only .   get  cumulative  cpu  time  advance  time  format  get  num  processors  assert  equals  n  time  advance  the  time  and  sample  again  to  test  the  cpu  usage  calculation  plugin  update  stat  file  u  time  get  num  v  cores  used  file  content  get  cpu  usage  percentage  cpu  usage  is  not  updated .     getcpufrequency   write fake  / proc / stat file .    write fake  / proc / cpuinfo file .   cpuinfo_format       in this case  cpu usage should not be updated .   string  cputimetracker  fwriter  cpufrequencykhz  fake_jiffy_length  tempfile  stime  write  close  numprocessors  deleteonexit  parsingprocstatandcpufile  fake_statfile  fake_cpufile   advance the time and sample again .  this time  we call getcpuusagepercentage (  )  only .   getcumulativecputime  advancetime  format  getnumprocessors  assertequals  ntime   advance the time and sample again to test the cpu usage calculation  plugin  updatestatfile  utime  getnumvcoresused  filecontent  getcpuusagepercentage   cpu usage is not updated . 
__label__flaky set  test  workflow  job  sla  new  conf  services  app  path  _test  workflow  job  commands  ehs  write  to  file  oozie  client  io  utils  get  test  user  wf  xml  assert  not  null  get  resource  as  string  get  workflow . xml  to  string  wf-job-sla . xml  slas  get  fs  test  case  dir  set  testworkflowjobslanew  conf  services  apppath  _testworkflowjobcommands  ehs  writetofile  oozieclient  ioutils  gettestuser  wfxml  assertnotnull  getresourceasstring  get  workflow . xml  tostring  wf-job-sla . xml  slas  getfstestcasedir
__label__nflaky x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  test  encode2  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  of  nominally  square  symbols  built  on  a  square  grid  with  a  distinctive  square  bullseye  pattern  at  their  center .   test  encode  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  aztec  code  is  a  public  domain  2  d  matrix  barcode  symbology  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x      x     x   x x     x x x x     x   x     x x x x   x x   x x   x x x     x   x     x x x   x             x         x x x x x   x   x x   x   x   x x   x   x   x   x             x   x x   x x x x x x   x x x x x x x x x   x     x x           x x x x             x     x     x     x x     x   x x   x x   x         x x       x       x   x     x   x   x   x   x   x   x   x   x   x   x   x   x   x   x   x   x   x   x   x   x       x x x x x               x     x x x   x       x x   x x   x x x x     x x                   x x     x x     x     x     x   x x x         x   x         x   x x           x x   x x   x   x x x x   x x x x x x x x   x   x       x x   x x x x   x x x                   x x x   x     x   x   x               x   x x     x x x   x x                   x x x x   x         x   x x x x x x x x x x x x x x   x       x x   x x   x x         x     x       x         x   x   x       x   x   x     x   x x                             x x     x x x x x   x   x   x x x x x   x   x x x     x x x x   x             x x     x       x       x x x x   x   x x       x   x x   x       x x   x x   x       x     x   x   x         x   x   x               x   x x   x x   x x x     x   x       x   x x     x               x x x x x     x x     x x x x x x x x     x   x   x x       x       x x     x   x x   x x       x             x     x   x x   x           x         x x                 x   x                       x x   x       x         x x x         x   x x       x     x       x   x x x x x x   x x   x x x x x x x x x   x   x     testencode2      x x   x   x   x x x     x                       x x x   x x   x   x     x             x x   x   x   x x x               x       x       x x     x x   x x       x                   x   x   x x       x x x x x     x x x       x       x x x         x       x x     x     x   x   x   x x   x   x x x x x   x   x x x x x x x       x   x x x     x           x     x x x x     x     x         x         x   x       x x   x x x       x x x x       x       x   x x   x   x       x   x   x     x x x     x x       x x     x             x         x   x x   x x     x     x     x   x   x x x x                 x   x   x x   x x x   x         x x     x x x x     x x   x   x     x   x       x               x       x x x   x x     x   x           x   x x x x   x x                       x         x x   x       x     x   x   x       x     x x x     x       x x x x     x     x x     x x x x x x             x x x   x               x   x     x     x x      of nominally square symbols built on a square grid with a   distinctive square bullseye pattern at their center .   testencode    x       x   x     x x   x   x x   x x   x x x x x x   x x           x   x   x x       x   x x x   x x       x x x         x x           x   x   x   x x x   x x     x       x     x x   x   x       x x x x x x x x x x x x x x x   x   x x   x   x x x         x       x         x   x x x x   x     x x     x x     x x           x   x       x       x   x x x   x   x x   x x x   x x x x x x x x x   x x         x x     x x x x         x       x   x     x       x x     x x   x   x   x     x x   x x x   x     x x x     x     x       x x x x x     x   x x x x   x x x     x       x x x x   x   x x   x     x       x           x   x   x     x x   x               x     x     x x x             aztec code is a public domain 2d matrix barcode symbology    x   x x x     x   x   x x     x x x   x   x x               x x       x x     x     x x x             x   x         x         x     x     x   x     x x       x   x
__label__flaky @  close  trx  coord  client  get  store  get  time  local  oozie  2009-12-15  t01:00  z  2009-12-16  t01:00  z  could  not  update  db .   get  status  -test  coord  rerun-  c  get  coord  client  rerun  scope  get  begin  trx  coordinator  action  re  run  coord  action  num2  commit  trx  action  num1  coord-rerun-action2 . xml  rest  constants  print  stack  trace  store1  e  store     action  id2  add  record  to  job  table  job  id  action  id1  services  fail  coordinator  job  add  record  to  action  table  assert  not  same  test  coord  rerun  date3  0000000-  action1  action2  coord-rerun-action1 . xml  get  coordinator  action  @  closetrx  coordclient  getstore  gettime  localoozie  2009-12-15t01:00z  2009-12-16t01:00z  could not update db .   getstatus  -testcoordrerun-c  getcoordclient  rerunscope  get  begintrx  coordinatoraction  reruncoord  actionnum2  committrx  actionnum1  coord-rerun-action2 . xml  restconstants  printstacktrace  store1  e  store     actionid2  addrecordtojobtable  jobid  actionid1  services  fail  coordinatorjob  addrecordtoactiontable  assertnotsame  testcoordrerundate3  0000000-  action1  action2  coord-rerun-action1 . xml  getcoordinatoraction
__label__nflaky release  times  assert  assert  not  null  get  verify  close  entry2  entry3  get  leased  conn3  conn2  entry1  conn1  assign  connection  argument  matchers  somehost  pool  assert  equals  totals  future3  any  never  future1  future2  mockito  otherhost  close  mode  mock  lease  get  pending  test  lease  release  get  total  stats  get  available  release  times  assert  assertnotnull  get  verify  close  entry2  entry3  getleased  conn3  conn2  entry1  conn1  assignconnection  argumentmatchers  somehost  pool  assertequals  totals  future3  any  never  future1  future2  mockito  otherhost  closemode  mock  lease  getpending  testleaserelease  gettotalstats  getavailable
__label__flaky get  job  tracker  uri  get  name  <java>  assert  false  < / prepare>  <delete  path= \  '   test  prepare  get  status  fs  delete  create  context  action  xml  is  successful  assert  true  <prepare>  <mkdir  path= \  '    \  '  / >  context  end  mkdir  wait  for  <job-tracker>  get  data  get  name  node  uri  < / java>  ae  < / main-class>  < / job-tracker>  running  job  get  action  assert  equals  get  file  system  check  get  external  status  <name-node>  <main-class>  < / name-node>  assert  null  workflow  action  mkdirs  succeeded  submit  action  exists  evaluate  get  fs  test  case  dir  is  complete  getjobtrackeruri  getname  <java>  assertfalse  < / prepare>  <delete path= \  '   testprepare  getstatus  fs  delete  createcontext  actionxml  issuccessful  asserttrue  <prepare>  <mkdir path= \  '    \  '  / >  context  end  mkdir  waitfor  <job-tracker>  getdata  getnamenodeuri  < / java>  ae  < / main-class>  < / job-tracker>  runningjob  getaction  assertequals  getfilesystem  check  getexternalstatus  <name-node>  <main-class>  < / name-node>  assertnull  workflowaction  mkdirs  succeeded  submitaction  exists  evaluate  getfstestcasedir  iscomplete
__label__nflaky prim  float  param  should  be  parsed  to  float  then  return  context  3 . 14  create  verify  invoke  when  param1  mock  controller  get  parameter  prim  float  param  primfloatparamshouldbeparsedtofloat  thenreturn  context  3 . 14  create  verify  invoke  when  param1  mockcontroller  getparameter  primfloatparam
__label__flaky delete  list  workflow  action  a2  should  have  been  deleted  add  record  to  wf  action  table  get  id  workflow  instance  action  c1  test  delete  workflows  action  c2  action  a1  workflow  action  a1  should  have  been  deleted  action  a2  job  b  add  record  to  wf  job  table  job  a  get  error  code  assert  not  null  job  c  get  workflow  job  add  workflow  action  c1  should  have  been  deleted  workflow  job  a  should  have  been  deleted  assert  equals  action  b1  execute  workflow  action  c2  should  have  been  deleted  action  b2  1  services  fail  2  workflow  action  b1  should  have  been  deleted  workflow  action  b2  should  have  been  deleted  workflow  action  workflow  job  c  should  have  been  deleted  error  code  je  jpa  service  workflow  job  b  should  have  been  deleted  deletelist  workflow action a2 should have been deleted  addrecordtowfactiontable  getid  workflowinstance  actionc1  testdeleteworkflows  actionc2  actiona1  workflow action a1 should have been deleted  actiona2  jobb  addrecordtowfjobtable  joba  geterrorcode  assertnotnull  jobc  get  workflowjob  add  workflow action c1 should have been deleted  workflow job a should have been deleted  assertequals  actionb1  execute  workflow action c2 should have been deleted  actionb2  1  services  fail  2  workflow action b1 should have been deleted  workflow action b2 should have been deleted  workflowaction  workflow job c should have been deleted  errorcode  je  jpaservice  workflow job b should have been deleted
__label__nflaky regex  length  build  dto  context  do  check  validation  passed  validate  jsr303  validation  passed  @  length ( min  =  5   max  =  10 )   string  param2   @  min ( 3 )   @  max ( 10 )   int  param3 ) ;  regex  length  builddto  context  docheckvalidationpassed  validatejsr303  validationpassed   @length ( min = 5  max = 10 )  string param2  @min ( 3 )  @max ( 10 )  int param3 ) ;
__label__flaky initial  callable  callables  type  key  int  queueservice  initial  key  assert  true  get  initial  type  lock  key  wait  for  key  exec_  order  add  init  c  initial  lock  key  ret  value  callable  queue  service  destroy  0  services  1  test  kill  int  callable  set  system  property  *  assuring  the  interrupts  will  not  be  inserted  in  the  map  when  it  reached  *  the  max  size  evaluate  queue  test  max  interrupt  map  size  initialcallable  callables  type  keyint  queueservice  initialkey  asserttrue  get  initialtype  lockkey  waitfor  key  exec_order  add  init  c  initiallockkey  retvalue  callablequeueservice  destroy  0  services  1  testkill  intcallable  setsystemproperty         * assuring the interrupts will not be inserted in the map when it reached       * the max size         evaluate  queue  testmaxinterruptmapsize
__label__nflaky 10000 2  get  name  get  default  retry  policy  path  io  exception  test  the  disabled  and  different  specifications  test  the  same  setting  retriable  exception  should  have  the  same  hash  code  hash  code  test  enabled  and  different  specifications  40000 5  assert  not  equals  no  such  method  exception  verify  retry  policy  equivalence  20000 3  should  be  equal  assert  equals  test  different  remote  exception  to  retry  rp1  50000 6  test  default  retry  policy  equivalence  rp3  rp2  60000 7  should  not  have  the  same  hash  code  30000 4  test  disabled  and  the  same  specifications  get  class  name  should  not  be  equal  10000 2  getname  getdefaultretrypolicy  path io exception   test the disabled and different specifications    test the same setting   retriable exception  should have the same hash code  hashcode   test enabled and different specifications   40000 5  assertnotequals  no such method exception  verifyretrypolicyequivalence  20000 3  should be equal  assertequals   test different remoteexceptiontoretry   rp1  50000 6  testdefaultretrypolicyequivalence  rp3  rp2  60000 7  should not have the same hash code  30000 4   test disabled and the same specifications   getclassname  should not be equal
__label__flaky non-unique  bundles  present  for  same  bundle  name  request  00002-12345-  b  assert  true  test  multiple  bundle  ids  for  name  set  id  set  start  time  jex  bundle  bundle  insert  set  app  name  exception  expected  due  to  >1  records  found  for  same  bulkjpa  bundle  engine  get  message  adding  another  bundle  having  same  name  execute  set  status  fail  contains  parse  bulk  filter  bundle  name  bundle  job  jpa  service  bundle=  non-unique bundles present for same bundle name  request  00002-12345-b  asserttrue  testmultiplebundleidsforname  setid  setstarttime  jex  bundle  bundleinsert  setappname   exception expected due to >1 records found for same  bulkjpa  bundleengine  getmessage   adding another bundle having same name  execute  setstatus  fail  contains  parsebulkfilter  bundlename  bundlejob  jpaservice  bundle=
__label__nflaky untar  file  files  to  tar  create  symbolic  link  test  create  symbolic  link  using  java  file  utils   / sl  create  symbolic  link  del  tmp  dir  is  symbolic  link  assert  true  tmp  get  path  get  parent  file  tos  dir1 /   file  files  close  file  systems  tmp  dir2  delete  the  directories  if  they  already  exist  os  tmp  dir1  to  absolute  path  get  default  sym  link  untar  using  java  put  entries  in  tar  file  tmp / test  2  simple  tar  to  path  mkdirs  check  symbolic  link  and  other  directories  are  there  in  untar  file  dir2 /   put  entries  in  tar  un  tar  using  java  exists  setup  dirs  to  string  delete  directory  file  util  untarfile   files to tar   create symbolic link  testcreatesymboliclinkusingjava  fileutils   / sl  createsymboliclink  del  tmpdir  issymboliclink  asserttrue  tmp  getpath  getparentfile  tos  dir1 /   file  files  close  filesystems  tmpdir2   delete the directories if they already exist  os  tmpdir1  toabsolutepath  getdefault  symlink   untar using java   put entries in tar file  tmp / test  2  simpletar  topath  mkdirs   check symbolic link and other directories are there in untar file  dir2 /   putentriesintar  untarusingjava  exists  setupdirs  tostring  deletedirectory  fileutil
__label__flaky get  working  directory  assert  false  assert  equals  fs  block  size  test  get  file  status  on  a  file  get  replication  get  block  size  file  size  get  len  make  qualified  get  file  status  get  path  should  be  a  file  to  string  test  get  file  status  on  file  file1  is  directory  get  uri  check  file  status  getworkingdirectory  assertfalse  assertequals  fs  blocksize   test getfilestatus on a file  getreplication  getblocksize  filesize  getlen  makequalified  getfilestatus  getpath   should be a file  tostring  testgetfilestatusonfile  file1  isdirectory  geturi  checkfile  status
__label__nflaky get  name  conf  cred1  get  kind  cred2  get  bytes  clear  property  password  test  external  token  files  token1  token2  create  path  for  token  files  user  group  information  token  id  write  token  storage  file     test  dir  create  new  token  and  store  it   /   contains  hadoop . token . files  token  full  pathnames  set  property  credsugi  tokens  test  dir  path  get  tokens  system  set  login  user  assert  true  string  utils  get  trimmed  strings  token  files  set  property  for  token  external  token  files  get  absolute  file  add  token  token1 token2  token-service2  get  absolute  path  token-service1  length  token  ugi  get  login  user  get  service  target  token  filenames  to  string  -tmp  dir  token  file  append  getname  conf  cred1  getkind  cred2  getbytes  clearproperty  password  testexternaltokenfiles  token1  token2   create path for token files  usergroupinformation  tokenid  writetokenstoragefile     testdir   create new token and store it   /   contains  hadoop . token . files  tokenfullpathnames  setproperty  credsugitokens  testdirpath  gettokens  system  setloginuser  asserttrue  stringutils  gettrimmedstrings  tokenfiles   set property for token external token files  getabsolutefile  addtoken  token1 token2  token-service2  getabsolutepath  token-service1  length  tokenugi  getloginuser  getservice  target  tokenfilenames  tostring  -tmpdir  tokenfile  append
__label__flaky play  server  icy-description:  rock  icy-metaint:16000  icy-url:http: /  / www .   a2  rradio . com  mp3  data  assert  content  server:  icecast  2 . 3 . 3-kh8  get  response  message  accept-  ranges:  none  expires:  mon   26  jul  1997  05:00:00  gmt  client  content-  type:  audio / mpeg  connection  shoutcast  ok  cache-  control:  no-cache  icy-br:128  add  header  icy-pub:1  icy-name:  a2  r  rock  assert  equals  set  body  set  status   /   pragma:  no-cache  enqueue  get  url  ice-audio-info:  bitrate=128;samplerate=44100;channels=2  get  response  code  icy-genre:riders  icy  200  ok  open  play  server  icy-description:rock  icy-metaint:16000  icy-url:http: /  / www . a2rradio . com  mp3 data  assertcontent  server: icecast 2 . 3 . 3-kh8  getresponsemessage  accept-ranges: none  expires: mon  26 jul 1997 05:00:00 gmt  client  content-type: audio / mpeg  connection  shoutcast  ok  cache-control: no-cache  icy-br:128  addheader  icy-pub:1  icy-name:a2rrock  assertequals  setbody  setstatus   /   pragma: no-cache  enqueue  geturl  ice-audio-info: bitrate=128;samplerate=44100;channels=2  getresponsecode  icy-genre:riders  icy 200 ok  open
__label__nflaky fully  delete  contents  ret  validate  and  set  writable  permissions  test  fail  fully  delete  contents  grant  permissions  setup  dirs  and  non  writable  permissions  del  file  util  this  time  the  directories  with  revoked  permissions  *should*  be  deleted:  fullydeletecontents  ret  validateandsetwritablepermissions  testfailfullydeletecontentsgrantpermissions  setupdirsandnonwritablepermissions  del  fileutil   this time the directories with revoked permissions *should* be deleted:
__label__flaky services  callable  assert  true  scheduled  test  delayed  queuing  get  current  time  millis  evaluate  wait  for  queueservice  system  queue  services  callable  asserttrue  scheduled  testdelayedqueuing  get  currenttimemillis  evaluate  waitfor  queueservice  system  queue
__label__nflaky p@ssw0rd  credential1  credential1  has  been  successfully  test  transient  provider  warning  run  assert  equals  delete  set  conf  deleted .   cs  user: /  /  /   rc  -value  contains  -provider  assert  true  transient  provider .   args1  create  -f  args2  to  string  out  content  warning:  you  are  modifying  a  p@ssw0rd  credential1  credential1 has been successfully   testtransientproviderwarning  run  assertequals  delete  setconf  deleted .   cs  user: /  /  /   rc  -value  contains  -provider  asserttrue  transient provider .   args1  create  -f  args2  tostring  outcontent  warning: you are modifying a
__label__flaky get  filenum  reader  h  constants  conf  compare  to  dir  get  region  name  table  name  bytes  hri  add  val  log  seq  id  get  key  to  bytes  get  row  entry  filename  size  start  cache  flush  compute  filename  idx  next  log  test  append  fs  system  get  key  values  get  tablename  assert  true  get  next  row .  .  .   the  meta  flushed  row .   row  tablename  close  cols  timestamp  now  open  a  reader  on  the  log  and  assert  append  worked .   col_  count  get  reader  column  1   2   3 .  .  .   complete  cache  flush  assert  equals  close  and  delete  integer  get  value  dfs . support . append  get  family  current  time  millis  equals  to  string  h  log  append  get  edit  set  boolean  getfilenum  reader  hconstants  conf  compareto  dir  getregionname  tablename  bytes  hri  add  val     logseqid  getkey  tobytes  getrow  entry  filename  size  startcacheflush  computefilename  idx  next  log  testappend  fs  system  getkeyvalues  gettablename  asserttrue   get next row .  .  .  the meta flushed row .   row  tablename  close  cols  timestamp   now open a reader on the log and assert append worked .   col_count  getreader  column   1  2  3 .  .  .   completecacheflush  assertequals  closeanddelete  integer  getvalue  dfs . support . append  getfamily  currenttimemillis  equals  tostring  hlog  append  getedit  setboolean
__label__nflaky get  parameter  values  hello_hello1  hello_hello2  needing  injection  param  parser  array  hello1  then  return  invoke  when  as  list  param1  context  create  verify  hello2  arrays  mock  controller  getparametervalues  hello_hello1  hello_hello2  needinginjectionparamparserarray  hello1  thenreturn  invoke  when  aslist  param1  context  create  verify  hello2  arrays  mockcontroller
__label__flaky <execution>  lifo< / execution>  < / controls>  <datasets>  pr   / workflows / ${  year} / ${  month} / ${  day}< / uri-template>  test  done  flag  creation  conf  <data-in  name= \ ""  a \ ""  dataset= \ ""local_a \ "">  <instance>${coord:current ( 0 ) }< / instance>  < / data-in>  < / input-events>  get  status  runtime  action  status  file: /  /   get  test  case  dir  unit_  testing  coordinator  action  action  missing  deps  get  runtime  wait  for  mkdir  -p  print  stack  trace  <coordinator-app  name= \ ""  name \ ""  frequency= \ ""${coord:days ( 1 ) } \ ""  start= \ ""2009-02-01  t01:00  z \ ""  end= \ ""2009-02-01  t02:00  z \ ""  timezone= \ ""  utc \ ""  <configuration>  <property>  <name>input  a< / name>  <value>${coord:data  in (  \  '   a \  '  ) }< / value>  < / property>  <action>  <workflow>  <app-path>hdfs: /  /  / tmp / workflows2 / < / app-path>  oozie  client  job  id  fail  size  < / datasets>  <input-events>  create  done  flag   / consume_me   / workflows / 2009 / 02 / 01  file  done  dir  actions  evaluate  exec  submit  job  get  missing  dependencies  get  actions  app  path  system  write  to  file  app  xml  <dataset  name= \ ""local_a \ ""  frequency= \ ""${coord:days ( 1 ) } \ ""  initial-instance= \ ""2009-02-01  t01:00  z \ ""  assert  true  get   .  .   missing  deps=  <done-flag>consume_me< / done-flag>  < / dataset>  xmlns= \ ""uri:oozie:coordinator:0 . 1 \ "">  <controls>  <timeout>10< / timeout>  <concurrency>2< / concurrency>  timezone= \ ""  utc \ "">  <uri-template>file: /  /   get  coord  job  coordinator . xml  ce  set  e  status=  < / configuration>  < / workflow>  < / action>  < / coordinator-app>  get  test  user  equals    <execution>lifo< / execution> < / controls> <datasets>   pr   / workflows / ${year} / ${month} / ${day}< / uri-template>   testdoneflagcreation  conf  <data-in name= \ ""a \ "" dataset= \ ""local_a \ ""> <instance>${coord:current ( 0 ) }< / instance> < / data-in>    < / input-events>   getstatus  runtime  actionstatus  file: /  /   gettestcasedir  unit_testing  coordinatoraction  action  missingdeps  getruntime  waitfor  mkdir -p   printstacktrace  <coordinator-app name= \ ""name \ "" frequency= \ ""${coord:days ( 1 ) } \ "" start= \ ""2009-02-01t01:00z \ "" end= \ ""2009-02-01t02:00z \ "" timezone= \ ""utc \ ""   <configuration> <property> <name>inputa< / name> <value>${coord:datain (  \  ' a \  '  ) }< / value> < / property>   <action> <workflow> <app-path>hdfs: /  /  / tmp / workflows2 / < / app-path>   oozieclient  jobid  fail  size  < / datasets> <input-events>    create done flag   / consume_me   / workflows / 2009 / 02 / 01  file  donedir  actions  evaluate  exec  submitjob  getmissingdependencies  getactions  apppath  system  writetofile  appxml  <dataset name= \ ""local_a \ "" frequency= \ ""${coord:days ( 1 ) } \ "" initial-instance= \ ""2009-02-01t01:00z \ ""   asserttrue  get   .  . missing deps=  <done-flag>consume_me< / done-flag> < / dataset>  xmlns= \ ""uri:oozie:coordinator:0 . 1 \ ""> <controls> <timeout>10< / timeout> <concurrency>2< / concurrency>   timezone= \ ""utc \ ""> <uri-template>file: /  /   getcoordjob  coordinator . xml  ce  set  e  status=  < / configuration> < / workflow> < / action> < / coordinator-app>  gettestuser  equals
__label__nflaky p  fail  assert  t  u  test  constructor  p    fail  assert  t  u  testconstructor
__label__flaky play  a  server  b  accept-  encoding  cache-  control:  max-age=60  identity  connection1  vary:  accept-  language   accept-  charset  connection2  accept-  charset  read  ascii  add  header  vary  multiple  fields  with  match  open  connection  utf-8  assert  equals  set  body  url  fr-  ca  add  request  property   /   enqueue  get  url  vary:  accept-  encoding  accept-  language  play  a  server  b  accept-encoding  cache-control: max-age=60  identity  connection1  vary: accept-language  accept-charset  connection2  accept-charset  readascii  addheader  varymultiplefieldswithmatch  openconnection  utf-8  assertequals  setbody  url  fr-ca  addrequestproperty   /   enqueue  geturl  vary: accept-encoding  accept-language
__label__nflaky further  lookups  will  have  a  delay  conf  as  list  advance  sleep  timer  cache  groups  add  me  set  get  groups  delay  ms  get  groups  grp3  get  request  count  common  configuration  keys  add  another  groups  clear  black  list  groups  refresh  fake  group  mapping  assert  equals  have  completed  then  expire  that  entry  assert  that  a  request  to  get  groups  yet .   another  call  to  get  groups  should  give  3  groups  instead  of  2  thread  set  long  test  thread  not  blocked  when  expired  entry  exists  with  background  refresh  my  groups  size  we  make  an  initial  request  to  populate  the  cache  starting  request  count  arrays  is  equal  to  set  boolean   further lookups will have a delay  conf  aslist  advance  sleep  timer  cachegroupsadd  me  setgetgroupsdelayms  getgroups  grp3  getrequestcount  commonconfigurationkeys   add another groups  clearblacklist  groups  refresh  fakegroupmapping  assertequals   have completed   then expire that entry  assertthat   a request to getgroups yet .    another call to get groups should give 3 groups instead of 2  thread  setlong  testthreadnotblockedwhenexpiredentryexistswithbackgroundrefresh  mygroups  size   we make an initial request to populate the cache  startingrequestcount  arrays  isequalto  setboolean
__label__flaky cluster  name  node  port  create  cluster  conf  test  file  creation  delete  parent:  fs  system  create  file  wait  active  this  ensures  that  leases  are  persisted  in  fsimage .   sleep  hflush  assert  true  ipc . client . connection . maxidletime  close  write  file  newfile  2s  dfs  config  keys  format  create  file1 .   created  file  dir2  get  file  system  dir1  test  file  creation  set  int  thread  persistent  leases  from  fsimage .   check  full  file  max_  idle_  time  test  while  open  rename  to  non  existent  directory  dfs . support . append  stm1  build   / user / dir1  rename  nnport   / user / dir2   / user  get  name  node  port  exists  file1  test  4************************************  shutdown  set  boolean  cluster  namenodeport   create cluster  conf  testfilecreationdeleteparent:   fs  system  createfile  waitactive   this ensures that leases are persisted in fsimage .   sleep  hflush  asserttrue  ipc . client . connection . maxidletime  close  writefile  newfile   2s  dfsconfigkeys  format   create file1 .   created file   dir2  getfilesystem  dir1  testfilecreation  setint  thread   persistent leases from fsimage .   checkfullfile  max_idle_time  testwhileopenrenametononexistentdirectory  dfs . support . append  stm1  build   / user / dir1  rename  nnport   / user / dir2   / user  getnamenodeport  exists  file1  test 4************************************  shutdown  setboolean
__label__nflaky cluster  allowing  svc1  to  become  active   expiring  svc0  ha  service  state  timeout  at  least  once  faking  svc0  unhealthy   should  not  successfully  transition  to  active  failover  to  svc1  verify  faking  svc0  healthy  again   should  go  back  to  svc0  info  log  svc1  start  wait  for  health  state  making  svc1  fail  to  become  active  test  becoming  active  fails  set  fail  to  become  active  wait  for  active  lock  holder  to  become  active   ( e . g  the  admin  has  restarted  it )   any  get  service  set  healthy  wait  for  ha  state  mockito  state  expire  and  verify  failover  cluster  allowing svc1 to become active  expiring svc0  haservicestate  timeout  atleastonce  faking svc0 unhealthy  should not successfully   transitiontoactive  failover to svc1  verify  faking svc0 healthy again  should go back to svc0  info  log  svc1  start  waitforhealthstate  making svc1 fail to become active  testbecomingactivefails  setfailtobecomeactive  waitforactivelockholder   to become active  ( e . g the admin has restarted it )   any  getservice  sethealthy  waitforhastate  mockito  state  expireandverifyfailover
__label__flaky get  connection  context  get  event  message  test  workflow  job  selectors  session  jms  messaging  utils  get  user  conf  get  status  create  session  get  topic  wf-app-name1  assert  user_1  = \  ' user_1 \  '   ca  id1  selector  wf  id1  workflow  job  jms  context  consumer  message  type  get  message  type  init  receive  print  stack  trace  e  get  message  destroy  assert  equals  message  wf  event  listener  fail  on  workflow  job  event  jms  header  constants  wfe  create  consumer  wf  fail  message  session  getconnectioncontext  geteventmessage  testworkflowjobselectors  session  jmsmessagingutils  getuser  conf  getstatus  createsession  gettopic  wf-app-name1  assert  user_1  = \  ' user_1 \  '   caid1  selector  wfid1  workflowjob  jmscontext  consumer  messagetype  getmessagetype  init  receive  printstacktrace  e  getmessage  destroy  assertequals  message  wfeventlistener  fail  onworkflowjobevent  jmsheaderconstants  wfe  createconsumer  wffailmessage  session
__label__nflaky  / user / me@me . com / 10000 ? q=froglegs  then  return  context  path  equal  to  get  context  path  assert  that  when  froglegs  q  router  route  id  get  reverse  route  ninja  properties  user  me@me . com  email  get  reverse  route  with  regex  and  query  parameters  works     / user / me@me . com / 10000 ? q=froglegs  thenreturn  contextpath  equalto  getcontextpath  assertthat  when  froglegs  q  router  route  id  getreverseroute  ninjaproperties  user  me@me . com  email  getreverseroutewithregexandqueryparametersworks
__label__flaky bundle  job  should  have  been  purged  add  record  to  bundle  action  table  workflow  job  5  should  have  been  purged  add  record  to  wf  action  table  workflow  action  2  should  have  been  purged  coordinator  action  3  should  have  been  purged  coord  job2  get  cmd  get  status  wf  action5  get  cmd  wf  job5  get  cmd  coord  action4  get  cmd  bundle  job  coord  action3  coord  action4  bundle  job  bean  coordinator  job  4  should  have  been  purged  assert  not  null  coord  action5  coordinator  action  wf  job2  get  cmd  coord  action1  coord  action2  bundle  action  5  should  have  been  purged  bundle  action4  bundle  action5  coordinator  job  3  should  have  been  purged  bundle  action1  bundle  action2  bundle  action3  execute  test  purge  bundle  with  coord  child  with  wf  child3  more  than  limit  bundle  action1  get  cmd  bundle  action  4  should  have  been  purged  coordinator  job  1  fail  succeeded  wf  action2  get  cmd  coordinator  action  2  should  have  been  purged  workflow  action  3  should  have  been  purged  je  bundle  job  get  cmd  workflow  job  4  should  have  been  purged  wf  job1  coord  job1  get  cmd  wf  job3  wf  job4  get  cmd  bundle  action  1  should  have  been  purged  wf  job2  get  error  code  wf  job5  get  wf  job4  coord  action2  get  cmd  bundle  action3  get  cmd  get  app  name  set  app  name  coord  action1  get  cmd  2011-01-01  t01:00  z  add  record  to  bundle  job  table  workflow  action  4  should  have  been  purged  assert  equals  coordinator  action  1  should  have  been  purged  wf  action1  wf  action2  add  record  to  coord  job  table  wf  action3  wf  action4  wf  action5  call  services  wf  job3  get  cmd  coordinator  job  2  should  have  been  purged  jpa  service  workflow  job  3  should  have  been  purged  coordinator  job  1  should  have  been  purged  bundle  action2  get  cmd  date  utils  workflow  instance  bundle  action  2  should  have  been  purged  add  record  to  coord  action  table  parse  date  oozie  tz  wf  action1  get  cmd  workflow  action  5  should  have  been  purged  job  coord2  coord3  coord4  coord5  coord  job3  get  cmd  wf  job1  get  cmd  coordinator  action  5  should  have  been  purged  workflow  job  2  should  have  been  purged  coord  job2  coord  job3  coord  job1  workflow  action  coord  action3  get  cmd  coord  job4  coord  job5  coord  job4  get  cmd  workflow  job  1  should  have  been  purged  coordinator  job  5  should  have  been  purged  bundle  action4  get  cmd  get  id  coord  action5  get  cmd  add  record  to  wf  job  table  workflow  action  1  should  have  been  purged  workflow  job  wf  action3  get  cmd  coordinator  action  4  should  have  been  purged  wf  action4  get  cmd  coord  job5  get  cmd  bundle  action5  get  cmd  coord-action-get . xml  error  code  bundle  action  3  should  have  been  purged  bundle job should have been purged  addrecordtobundleactiontable  workflow job 5 should have been purged  addrecordtowfactiontable  workflow action 2 should have been purged  coordinator action 3 should have been purged  coordjob2getcmd  getstatus  wfaction5getcmd  wfjob5getcmd  coordaction4getcmd  bundlejob  coordaction3  coordaction4  bundlejobbean  coordinator job 4 should have been purged  assertnotnull  coordaction5  coordinatoraction  wfjob2getcmd  coordaction1  coordaction2  bundle action 5 should have been purged  bundleaction4  bundleaction5  coordinator job 3 should have been purged  bundleaction1  bundleaction2  bundleaction3  execute  testpurgebundlewithcoordchildwithwfchild3morethanlimit  bundleaction1getcmd  bundle action 4 should have been purged  coordinatorjob  1  fail  succeeded  wfaction2getcmd  coordinator action 2 should have been purged  workflow action 3 should have been purged  je  bundlejobgetcmd  workflow job 4 should have been purged  wfjob1  coordjob1getcmd  wfjob3  wfjob4getcmd  bundle action 1 should have been purged  wfjob2  geterrorcode  wfjob5  get  wfjob4  coordaction2getcmd  bundleaction3getcmd  getappname  setappname  coordaction1getcmd  2011-01-01t01:00z  addrecordtobundlejobtable  workflow action 4 should have been purged  assertequals  coordinator action 1 should have been purged  wfaction1  wfaction2  addrecordtocoordjobtable  wfaction3  wfaction4  wfaction5  call  services  wfjob3getcmd  coordinator job 2 should have been purged  jpaservice  workflow job 3 should have been purged  coordinator job 1 should have been purged  bundleaction2getcmd  dateutils  workflowinstance  bundle action 2 should have been purged  addrecordtocoordactiontable  parsedateoozietz  wfaction1getcmd  workflow action 5 should have been purged  job  coord2  coord3  coord4  coord5  coordjob3getcmd  wfjob1getcmd  coordinator action 5 should have been purged  workflow job 2 should have been purged  coordjob2  coordjob3  coordjob1  workflowaction  coordaction3getcmd  coordjob4  coordjob5  coordjob4getcmd  workflow job 1 should have been purged  coordinator job 5 should have been purged  bundleaction4getcmd  getid  coordaction5getcmd  addrecordtowfjobtable  workflow action 1 should have been purged  workflowjob  wfaction3getcmd  coordinator action 4 should have been purged  wfaction4getcmd  coordjob5getcmd  bundleaction5getcmd  coord-action-get . xml  errorcode  bundle action 3 should have been purged
__label__nflaky get  name  token  signed  token_  validity_  sec  sign  test  get  token  expired  when  as  list  get  init  parameter  names  assert  secret  provider  token  not  expired  management . operation . return  signer  init  cookie  then  return  string  signer  secret  provider  creator  destroy  failed  ex  get  init  parameter  new  string  signer  secret  provider  set  property  true  mock  arrays  request  set  expires  secret  system  secret  provider  props  assert  true  get  cookies  dummy  authentication  handler  authenticated  url  authentication  token  expired  authentication  filter  get  message  assert  equals  token  filter  p  get  mocked  servlet  context  with  string  signer  mockito  u  elements  current  time  millis  get  token  to  string  config  getname  tokensigned  token_validity_sec  sign  testgettokenexpired  when  aslist  getinitparameternames  assert  secretprovider  token not expired  management . operation . return  signer  init  cookie  thenreturn  stringsignersecretprovidercreator  destroy  failed  ex  getinitparameter  newstringsignersecretprovider  setproperty  true  mock  arrays  request  setexpires  secret  system  secretproviderprops  asserttrue  getcookies  dummyauthenticationhandler  authenticatedurl  authenticationtoken expired  authenticationfilter  getmessage  assertequals  token  filter  p  getmockedservletcontextwithstringsigner  mockito  u  elements  currenttimemillis  gettoken  tostring  config
__label__flaky check  coord  jobs  to  date  get  id  date  utils  system  parse  date  oozie  tz  add  record  to  coord  job  table  call  coordinator  job  2099-02-03  t23:59  z  current  time  millis  start  time  end  time  job  test  mat  lookup  command3  checkcoordjobs  todate  getid  dateutils  system  parsedateoozietz  addrecordtocoordjobtable  call  coordinatorjob  2099-02-03t23:59z  currenttimemillis  starttime  endtime  job  testmatlookupcommand3
__label__nflaky test  put  metrics2  set  receive  buffer  size  get  local  port  metric  type  ms  info  get  local  address  received  data  did  not  match  data  sent  result  put  metrics  assert  true  record  process . jvm .   context . foo2:2|g  foo1  foo2  mock  stats  d  close  get  data  add  jvm  process . jvm .   context . foo1:1|c  receive  process  get  host  name  for  name  sink  utf-8  statsd  charset  tags  make  metric  whitebox  p  sock  equals  get  length  metrics  set  internal  state  testputmetrics2  setreceivebuffersize  getlocalport  metrictype  msinfo  getlocaladdress  received data did not match data sent  result  putmetrics  asserttrue  record  process . jvm . context . foo2:2|g  foo1  foo2  mockstatsd  close  getdata  add  jvm  process . jvm . context . foo1:1|c  receive  process  gethostname  forname  sink  utf-8  statsd  charset  tags  makemetric  whitebox  p  sock  equals  getlength  metrics  setinternalstate
__label__flaky cluster  get  block  locations   / tmp / test  bad  block  report  on  transfer / file1  waiting  until  block  is  marked  as  corrupt .  .  .   conf  dfs  client  fs  wait  replication  create  file  corrupted  too  few  blocks  repl  factor  wait  active  sleep  test  bad  block  report  on  transfer  replica  count  assert  true  corrupt  block  on  data  nodes  receiving  datanode  fails  on  checksum  and  reports  it  to  namenode  get  get  namenode  block  info  localhost  dfs  test  util  now  get  block  details  and  check  if  the  block  is  corrupt  is  corrupt  log  blocks  assert  equals  get  file  system  set  replication  corrupt  the  block  belonging  to  the  created  file  thread  create  file  with  replication  factor  of  1  block  files  corrupted  build  *  test  if  datanode  reports  bad  blocks  during  replication  request  num  data  nodes  long  get  name  node  port  get  locations  to  string  file1  get  first  block  shutdown  cluster  getblocklocations   / tmp / testbadblockreportontransfer / file1  waiting until block is marked as corrupt .  .  .   conf  dfsclient  fs  waitreplication  createfile  corrupted too few blocks  replfactor  waitactive  sleep  testbadblockreportontransfer  replicacount  asserttrue  corruptblockondatanodes   receiving datanode fails on checksum and reports it to namenode  get  getnamenode  block  info  localhost  dfstestutil   now get block details and check if the block is corrupt  iscorrupt  log  blocks  assertequals  getfilesystem  setreplication   corrupt the block belonging to the created file  thread   create file with replication factor of 1  blockfilescorrupted  build        * test if datanode reports bad blocks during replication request       numdatanodes  long  getnamenodeport  getlocations  tostring  file1  getfirstblock  shutdown
__label__nflaky end:  vevent  dtstart;  value=  date:20111110  do  test  20111110  t000000  z  begin:  vevent  dtend;  value=  date:20111110  test  all  day  value  date  end:vevent  dtstart;value=date:20111110    dotest  20111110t000000z  begin:vevent    dtend;value=date:20111110    testalldayvaluedate
__label__flaky add  record  to  bundle  action  table  bundle  job  get  cmd  get  current  dateafter  incrementing  in  months  get  id  date  utils  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  sleep  assert  not  null  get  coordinator  action  end  current  date  plus  month  job  add  record  to  bundle  job  table  bundle  id  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  with  bundle  call  services  coordinator  job  coord-action-get . xml  test  bundle  status  transit  service  succeeded3  action1  job  action2  jpa  service  addrecordtobundleactiontable  bundlejobgetcmd  getcurrentdateafterincrementinginmonths  getid  dateutils  getstatus  addrecordtocoordactiontable  parsedateoozietz  sleep  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  job  addrecordtobundlejobtable  bundleid  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtablewithbundle  call  services  coordinatorjob  coord-action-get . xml  testbundlestatustransitservicesucceeded3  action1  job  action2  jpaservice
__label__nflaky get  cpu  frequency  get  network  bytes  read  undef  on  first  call  parse  system  info  string  get  cumulative  cpu  time  tester  17177038848 8589467648 15232745472 6400417792 1 2805000 6261812   get  num  processors  get  storage  bytes  written  assert  equals  get  physical  memory  size  get  storage  bytes  read  1234567 2345678 3456789 4567890  get  virtual  memory  size  cpu  time  tracker  get  available  physical  memory  size  set  sysinfo  string  get  network  bytes  written  get  num  v  cores  used  info  str  derived  from  windows  shell  command  has   \  \ r   termination  get  available  virtual  memory  size  get  num  cores  get  cpu  usage  percentage  getcpufrequency  getnetworkbytesread   undef on first call  parsesysteminfostring  getcumulativecputime  tester  17177038848 8589467648 15232745472 6400417792 1 2805000 6261812   getnumprocessors  getstoragebyteswritten  assertequals  getphysicalmemorysize  getstoragebytesread  1234567 2345678 3456789 4567890    getvirtualmemorysize  cputimetracker  getavailablephysicalmemorysize  setsysinfostring  getnetworkbyteswritten  getnumvcoresused   info str derived from windows shell command has  \  \ r  termination  getavailablevirtualmemorysize  getnumcores  getcpuusagepercentage
__label__flaky server  check  for  timeout  status  and  unregistered  missing  dependencies  time  out  creation  time  check  coord  action  coord  el  functions  timeout .    / nodb / notable / dt=20120430;country=usa  assert  false  add  init  records  get  waiting  actions  system  sleep  assert  true  get  coordinator  action  test  time  out  with  exception1  new  h  cat  dependency  set  coord  action  creation  time  new  h  cat  dependency2  new  h  cat  dependency1  e  hcat  service  hcat: /  /   get  message  pdms  is  registered  for  notification  thread  call  fail  services  contains  test  timeout  when  missing  dependencies  are  from  a  non  existing  table  assert  null  current  time  millis  action  id  no  such  object  exception   / nodb / notable / dt=20120430;country=brazil  server   check for timeout status and unregistered missing dependencies  timeoutcreationtime  checkcoordaction  coordelfunctions   timeout .    / nodb / notable / dt=20120430;country=usa  assertfalse  addinitrecords  getwaitingactions  system  sleep  asserttrue  get  coordinatoraction  testtimeoutwithexception1  newhcatdependency  setcoordactioncreationtime  newhcatdependency2  newhcatdependency1  e  hcatservice  hcat: /  /   getmessage  pdms  isregisteredfornotification  thread  call  fail  services  contains   test timeout when missing dependencies are from a non existing table  assertnull  currenttimemillis  actionid  nosuchobjectexception   / nodb / notable / dt=20120430;country=brazil
__label__nflaky http  headers  conn  arg  that  in  stream  ack  response  captor  send  response  header  when  set  entity  receive  request  header  assert  assert  not  null  context  create  boolean  get  code  http  status  then  return  argument  matchers  get  all  values  capture  method  eq  matches   /   never  response  factory  size  new  http  response  mock  conn  reuse  strategy  request  header  elements  get  request  test  execution  entity  enclosing  request  with  expect  continue  times  httpservice  flush  get  for  class  verify  close  add  header  process  keep  alive  argument  captor  assert  equals  send  response  entity  assert  same  get  entity  error  response  mockito  response  http  core  context  httprocessor  responses  handle  request  entity  httpheaders  conn  argthat  instream  ack  responsecaptor  sendresponseheader  when  setentity  receiverequestheader  assert  assertnotnull  context  create  boolean  getcode  httpstatus  thenreturn  argumentmatchers  getallvalues  capture  method  eq  matches   /   never  responsefactory  size  newhttpresponse  mock  connreusestrategy  request  headerelements  getrequest  testexecutionentityenclosingrequestwithexpectcontinue  times  httpservice  flush  get  forclass  verify  close  addheader  process  keepalive  argumentcaptor  assertequals  sendresponseentity  assertsame  getentity  errorresponse  mockito  response  httpcorecontext  httprocessor  responses  handlerequest  entity
__label__flaky set  name  cf  def  dynamic  cf  update  column  family  get  cf  defs  birthdate  get  column  metadata  get  name  set  validation  class  comparator  type  column  definition  keyspace  definition  to  byte  buffer  as  list  dyn  keyspace3  test  edit  column  family  org . apache . cassandra . locator .   simple  strategy  get  h  factory  column  index  type  describe  keyspace  string  serializer  cassandra  cluster  from  cluster  create  keyspace  definition  add  column  definition  assert  equals  column  family  definition  add  keyspace  from  byte  buffer  set  index  type  set  keyspace  name  get  class  name  arrays  setname  cfdef  dynamiccf  updatecolumnfamily  getcfdefs  birthdate  getcolumnmetadata  getname  setvalidationclass  comparatortype  columndefinition  keyspacedefinition  tobytebuffer  aslist  dynkeyspace3  testeditcolumnfamily  org . apache . cassandra . locator . simplestrategy  get  hfactory  columnindextype  describekeyspace  stringserializer  cassandracluster  fromcluster  createkeyspacedefinition  addcolumndefinition  assertequals  columnfamilydefinition  addkeyspace  frombytebuffer  setindextype  setkeyspacename  getclassname  arrays
__label__nflaky config_  for_  enum  conf  config2  bis  append  property  out  config  prperties  that  were  included  from  the  first  resource .   second  level  include  file  config_  multi_  byte  end  include  add  resource  get  a  b  start  include  c  d  e  add  config  as  an  input  stream  resource .   f  g  h  end  config  start  config  assert  equals  test  includes  from  input  stream  when  resource  added  tear  down  add  another  resource  to  the  conf .   1  second  time  the  conf  is  parsed .   2  3  4  first  level  include  file  resource  config  includes  config2 .   config2  includes  config_  for_  enum  from  all  levels  of  includes .   config_for_enum  conf  config2  bis  appendproperty  out  config   prperties that were included from the first resource .   secondlevelinclude  file  config_multi_byte  endinclude  addresource  get  a  b  startinclude  c  d  e   add config as an inputstream resource .   f  g  h  endconfig  startconfig  assertequals  testincludesfrominputstreamwhenresourceadded  teardown   add another resource to the conf .   1   second time the conf is parsed .   2  3  4  firstlevelinclude  fileresource   config includes config2 .  config2 includes config_for_enum   from all levels of includes . 
__label__flaky ensure  time  to  poll  test  watch  for  multiple  event  types  resolve  immutable  list  foo  entry_  create  fs  delete  create  file  path  bar  foo / bar  of  get  path  create  directory  baz  files  create  directories  watcher  entry_  modify  watcher  polls   seeing  modification   then  polls  again   seeing  delete  this  could  be  __label__flaky;  may  need  to  increase  time  between  polling  if  so   ( or  just  not  test  it )   entry_  delete  register  assert  watcher  has  events  ensuretimetopoll  testwatchformultipleeventtypes  resolve  immutablelist  foo  entry_create  fs  delete  createfile  path  bar  foo / bar  of  getpath  createdirectory  baz  files  createdirectories  watcher  entry_modify   watcher polls  seeing modification  then polls again  seeing delete   this could be __label__flaky; may need to increase time between polling if so  ( or just not test it )   entry_delete  register  assertwatcherhasevents
__label__nflaky request  conn  get  request  count  add  header  test  write  request  entity  no  content  length  test  content  type  then  return  get  endpoint  details  user-  agent  assert  equals  method  out  stream  when  set  entity  123  bind  assert  mockito  get  output  stream  socket   / stuff  send  request  entity  send  request  header  request  conn  getrequestcount  addheader  testwriterequestentitynocontentlength  test  contenttype  thenreturn  getendpointdetails  user-agent  assertequals  method  outstream  when  setentity  123  bind  assert  mockito  getoutputstream  socket   / stuff  sendrequestentity  sendrequestheader
__label__flaky date  script  executor  session  given  update  simple  eq  select  simpleset  from  simple  where  id  =  simpleset  contains  exactly  sets  when  of  where  id  row  should_dsl_update_set_set  value  table  execute  script  template  random  utils  manager  get  set  one  next  long  assert  that  execute  simple  entity / insert_single_row . cql  immutable  map  simple  set_  set  simple  set  new  hash  set  then  long  build  date  key  from  base  table  dsl  date  scriptexecutor  session   given  update  simple  eq  select simpleset from simple where id =   simpleset  containsexactly  sets   when  of  where  id  row  should_dsl_update_set_setvalue  table  executescripttemplate  randomutils  manager  getset  one  nextlong  assertthat  execute  simpleentity / insert_single_row . cql  immutablemap  simpleset_set  simpleset  newhashset   then  long  builddatekey  frombasetable  dsl
__label__nflaky localhost  uribuilder  test  hierarchical  uri  assert  equals  uri  result  fragment  param=stuff  assert   / some  stuff  build  http  http: /  / stuff@localhost:80 / some \ %20stuff ? param=stuff#fragment  stuff  localhost  uribuilder  testhierarchicaluri  assertequals  uri  result  fragment  param=stuff  assert   / some stuff  build  http  http: /  / stuff@localhost:80 / some \ %20stuff ? param=stuff#fragment  stuff
__label__flaky when  add  error  then  given  start  appender  eq  any  when  some  event  deque  offer  do  throw  interrupted  exception  any  long  adds  error  message  when  appending  is  interrupted  while  waiting  for  the  queue  to  accept  the  event  verify  append  interrupted  while  appending  event  to  socket  appender   when  adderror   then   given  start  appender  eq  any  when  some event  deque  offer  dothrow  interruptedexception  anylong  addserrormessagewhenappendingisinterruptedwhilewaitingforthequeuetoaccepttheevent  verify  append  interrupted while appending event to socketappender
__label__nflaky erasure  code  constants  coder  test  get  coder  by  name  wrong  wrong_  rs  assert  null  get  coder  by  name  get  instance  codec  registry  erasurecodeconstants  coder  testgetcoderbynamewrong  wrong_rs  assertnull  getcoderbyname  getinstance  codecregistry
__label__flaky unexpected  exception  f-> ( 2 3 )   2->decision  node->{4 k 4}  3->decision  node->{k 5 k}  4->j  5->j  def  add  node  print  stack  trace  e  f  one  j  k  kill  three  two  as  list  fail  test  decisions  to  kill  fork  join  invoke  fork  join  parser  four  name  dummy  conf  end  arrays  five  unexpected exception        f-> ( 2 3 )       2->decision node->{4 k 4}      3->decision node->{k 5 k}      4->j      5->j        def  addnode  printstacktrace  e  f  one  j  k  kill  three  two  aslist  fail  testdecisionstokillforkjoin  invokeforkjoin  parser  four  name  dummyconf  end  arrays  five
__label__nflaky prefix  foo  conf  append  property  out  config  add  resource  get  postfix   . value  end  config  start  config  j  assert  equals  next  int  n  test  trim  name  ran  append  whitespaces    prefix  foo   \ t      conf  appendproperty  out  config  addresource  get  postfix      . value  endconfig  startconfig  j  assertequals  nextint  n  testtrim  name  ran  append  whitespaces
__label__flaky get  name  scan  test  get  scanner_  with  no  families  with  known  number   2  -  current  =  1  fam4  fam3  put  table  name  fam2  bytes  add  row1  get  heap  method  init  heap  to  bytes  is  assert  equals  families  setting  up  region  init  h  region  fam1  testtable  size  add  family  putting  data  in  region  i  dont  like  this  test  region  get  scanner  getname  scan  testgetscanner_withnofamilies   with known number  2 - current = 1  fam4  fam3  put  tablename  fam2  bytes  add  row1  getheap  method  initheap  tobytes  is  assertequals  families   setting up region  inithregion  fam1  testtable  size  addfamily   putting data in region   i dont like this test  region  getscanner
__label__nflaky args  is  follow  link  is  follow  arg  link  assert  true  find  -  h  path  process  options  follow  arg  link  assert  false  process  options  get  options  get  args  check  follow  arg  link  option  is  recognized  args  isfollowlink  isfollowarglink  asserttrue  find  -h path  processoptionsfollowarglink  assertfalse  processoptions  getoptions  getargs   check follow arg link option is recognized
__label__flaky 2009-02-01  t01:00  z  start  run  get  id  assert  equals  date  utils  get  status  execute  parse  date  oozie  tz  add  record  to  coord  job  table  coord  get  cmd  coord  job  sleep  get  mat  throttling  coordinator  job  services  runnable  test  coord  materialize  trigger  service1  get  num  waiting  actions  end  2009-02-20  t23:59  z  job  jpa  service  2009-02-01t01:00z  start  run  getid  assertequals  dateutils  getstatus  execute  parsedateoozietz  addrecordtocoordjobtable  coordgetcmd  coordjob  sleep  getmatthrottling  coordinatorjob  services  runnable  testcoordmaterializetriggerservice1  get  numwaitingactions  end  2009-02-20t23:59z  job  jpaservice
__label__nflaky conn  assert  bind  mockito  timeout  assert  equals  get  so  timeout  socket  test  get  socket  timeout  exception  get  socket  timeout  when  then  throw  conn  assert  bind  mockito  timeout  assertequals  getsotimeout  socket  testgetsockettimeoutexception  getsockettimeout  when  thenthrow
__label__flaky cluster  init  buffer  conf  test  pipeline  heartbeat  p=  fs  timeout  system  create  file  sleep  wrote  1  byte  and  hflush  hflush  create  a  new  file .   write  another  byte  failed  to  slowly  write  to  a  file  write  close  dfs  config  keys  get  file  system  file  contents   / pipeline  heartbeat / foo  stm  append  test  util  set  int  thread  check  full  file  verify  that  entire  file  is  good  file  len  p  build  num  data  nodes  datanode_  num  shutdown  cluster  initbuffer  conf  testpipelineheartbeat  p=  fs  timeout  system  createfile  sleep  wrote 1 byte and hflush   hflush   create a new file .    write another byte  failed to slowly write to a file  write  close  dfsconfigkeys  getfilesystem  filecontents   / pipelineheartbeat / foo  stm  appendtestutil  setint  thread  checkfullfile   verify that entire file is good  filelen  p  build  numdatanodes  datanode_num  shutdown
__label__nflaky handler  assert  get  type  test  type  assert  equals  get  expected  type  handler  assert  gettype  testtype  assertequals  getexpectedtype
__label__flaky cluster  conf  file  space  now   appending  more  than  1  file  len  should  result  in  an  error  create  file  make  sure  no  intermediate  directories  left  by  failed  rename  verify  space  quota  directory  should  exist  512  write  verify  space  for  its  parent  quota  dir2053  verify  increase  in  space  get  file  system  now  increase  the  quota  for  quota  dir1  dfs  quota  dir2053_  a  move   / nqdir0 / qdir1 / qdir21 / nqdir32   / nqdir0 / qdir1 / qdir20 / nqdir30  appending  1  file  len  should  succeed  quota  dir2053_  b  mkdirs  temp  path  quota  dir2053_  c   / nqdir0 / qdir1 / qdir20   / nqdir0 / qdir1 / qdir21  check  space  consumed  for   / hdfs-2053  dst  path   / nqdir0 / qdir1  identifiable  file  sizes  per  subdir   which  helps  during  debugging .   a  b  c  diskspace  quotas  has  exception  out  verify  space  before  the  move:  assert  true   / hdfs-2053  get  space  consumed  close  replication  dfs  test  util  set  create  directory   / nqdir0 / qdir1 / qdir20 / nqdir30  c  assert  equals  create  directory   / hdfs-2053  io  utils  rename  now  increase  the  quota  for  quota  dir1  and  quota  dir20  exists  5:  create  directory   / nqdir0 / qdir1 / qdir21 / nqdir32  set  boolean  create   / nqdir0 / qdir1 / qdir21  and  set  its  space  quota  to  2  *  file  space  file  dir / file2  verify  space  before  append;  verify  space  after  append;  quota  dir1  get  space  quota  file  b  file  c  create  a  file  under  nqdir32 / file  dir  after  partial  append  file  a  file  dir / file1  dfs  config  keys  now  try  to  increase  the  replication  and  and  expect  an  error .   create  a  file  under  subdirectory  c   ( which  has  a  space  quota )   src  path  verify  space  after  the  move  set  quota  set  the  quota  of   / nqdir0 / qdir1  to  4  *  file  space  set  the  quota  of   / nqdir0 / qdir1 / qdir20  to  6  *  file  space  nqdir30  num  data  nodes   / nqdir0 / qdir1 / qdir20 / nqdir30  nqdir33  nqdir32  delete  nqdir33  get  uri  shutdown  hdfs  constants  create  a  file  under  subdirectory  a  create  a  larger  file   / nqdir0 / qdir1 / qdir21 / nqdir33 /   assert  false  create  a  file  under  subdirectory  b  fs  delete  nqdir33 / file2  set  space  quota  for  subdirectory  c  create  a  larger  file  under   / nqdir0 / qdir1 / qdir20 / nqdir30  flush  first  reduce  the  replication  close  stream  create  subdirectories   / hdfs-2053 / {  a   b   c}  reverse:  move   / nqdir0 / qdir1 / qdir20 / nqdir30  to   / nqdir0 / qdir1 / qdir21 /   size  factor  c  size  factor  b  size  factor  a  verify  space  after  the  failed  move  then  increasing  replication  should  be  ok .   file2  len  get  content  summary  quota  dir21  verify  space  after  partial  append  set  replication  verify  that  space  is  reduced  by  file2  len  not  a  hdfs:  quota  dir20  file  len  verify  space  consumed  remains  unchanged .   dfs . support . append  build  after  append  file2  test  space  commands  append  verify  space  for  source  for  the  move  cluster  conf  filespace   now  appending more than 1 filelen should result in an error  createfile   make sure no intermediate directories left by failed rename   verify space quota   directory should exist  512  write   verify space for its parent  quotadir2053   verify increase in space  getfilesystem   now increase the quota for quotadir1  dfs  quotadir2053_a   move  / nqdir0 / qdir1 / qdir21 / nqdir32  / nqdir0 / qdir1 / qdir20 / nqdir30   appending 1 filelen should succeed  quotadir2053_b  mkdirs  temppath  quotadir2053_c   / nqdir0 / qdir1 / qdir20   / nqdir0 / qdir1 / qdir21   check space consumed for  / hdfs-2053  dstpath   / nqdir0 / qdir1   identifiable file sizes per subdir  which helps during debugging .   a  b  c   diskspace quotas  hasexception  out   verify space before the move:  asserttrue   / hdfs-2053  getspaceconsumed  close  replication  dfstestutil  set   create directory  / nqdir0 / qdir1 / qdir20 / nqdir30  c  assertequals   create directory  / hdfs-2053  ioutils  rename   now increase the quota for quotadir1 and quotadir20  exists   5: create directory  / nqdir0 / qdir1 / qdir21 / nqdir32  setboolean   create  / nqdir0 / qdir1 / qdir21 and set its space quota to 2 * filespace  filedir / file2   verify space before append;   verify space after append;  quotadir1  getspacequota  fileb  filec   create a file under nqdir32 / filedir   after partial append  filea  filedir / file1  dfsconfigkeys   now try to increase the replication and and expect an error .    create a file under subdirectory c  ( which has a space quota )   srcpath   verify space after the move  setquota   set the quota of  / nqdir0 / qdir1 to 4 * filespace   set the quota of  / nqdir0 / qdir1 / qdir20 to 6 * filespace  nqdir30  numdatanodes   / nqdir0 / qdir1 / qdir20 / nqdir30  nqdir33  nqdir32   delete nqdir33  geturi  shutdown  hdfsconstants   create a file under subdirectory a   create a larger file  / nqdir0 / qdir1 / qdir21 / nqdir33 /   assertfalse   create a file under subdirectory b  fs  delete  nqdir33 / file2   set space quota for subdirectory c   create a larger file under  / nqdir0 / qdir1 / qdir20 / nqdir30  flush   first reduce the replication  closestream   create subdirectories  / hdfs-2053 / {a b c}   reverse: move  / nqdir0 / qdir1 / qdir20 / nqdir30 to  / nqdir0 / qdir1 / qdir21 /   sizefactorc  sizefactorb  sizefactora   verify space after the failed move   then increasing replication should be ok .   file2len  getcontentsummary  quotadir21   verify space after partial append  setreplication   verify that space is reduced by file2len  not a hdfs:   quotadir20  filelen   verify space consumed remains unchanged .   dfs . support . append  build   after append  file2  testspacecommands  append   verify space for source for the move
__label__nflaky 1  test  limited  io  do  test  limited  io  foo  bar  baz  abcd  1  testlimitedio  dotestlimitedio  foo bar baz  abcd
__label__flaky session  given  insert  uuid  crud  get  uuid  when  get  id  row  value  val  all  select  *  from  entity_composite_pk  where  id  =  random  utils  manager  get  string  next  long  rows  assert  that  execute  and  uuid  =  get  long  has  size  should_insert  then  long  is  equal  to  entity  session   given  insert  uuid  crud  getuuid   when  get  id  row  value  val  all  select * from entity_composite_pk where id =   randomutils  manager  getstring  nextlong  rows  assertthat  execute   and uuid =   getlong  hassize  should_insert   then  long  isequalto  entity
__label__nflaky arg  that  core  matchers  not  null  value  equal  to  has  item  connect  future  when  impl  times  assert  boom  verify  test  get  session  failure  of  seconds  argument  matchers  any  string  then  return  timeout  somehost  failed  assert  that  eq  any  is  done  matches  future1  get  routes  future2  mockito  callback  connect  session  get  session  argthat  corematchers  notnullvalue  equalto  hasitem  connectfuture  when  impl  times  assert  boom  verify  testgetsessionfailure  ofseconds  argumentmatchers  anystring  thenreturn  timeout  somehost  failed  assertthat  eq  any  isdone  matches  future1  getroutes  future2  mockito  callback  connectsession  getsession
__label__flaky @  close  trx  coord  client  get  store  get  time  local  oozie  could  not  update  db .   -test  coord  rerun-  c  get  coord  client  rerun  scope  get  error  code  assert  true  get  begin  trx  coordinator  action  re  run  coord  action  num2  commit  trx  action  num1  coord-rerun-action2 . xml  2009-12-15  t01:00  z 2009-12-16  t01:00  z 2009-12-17  t01:00  z  rest  constants  print  stack  trace  e  store  action  id2  add  record  to  job  table  job  id  action  id1  services  fail  coordinator  job  ex  add  record  to  action  table  test  coord  rerun  date  neg  0000000-  to  string  error  code  exception  expected  because  one  action  is  missing  from  db .   coord-rerun-action1 . xml  @  closetrx  coordclient  getstore  gettime  localoozie  could not update db .   -testcoordrerun-c  getcoordclient  rerunscope  geterrorcode  asserttrue  get  begintrx  coordinatoraction  reruncoord  actionnum2  committrx  actionnum1  coord-rerun-action2 . xml  2009-12-15t01:00z 2009-12-16t01:00z 2009-12-17t01:00z  restconstants  printstacktrace  e  store  actionid2  addrecordtojobtable  jobid  actionid1  services  fail  coordinatorjob  ex  addrecordtoactiontable  testcoordrerundateneg  0000000-  tostring  errorcode  exception expected because one action is missing from db .   coord-rerun-action1 . xml
__label__nflaky test  close  expired  get  stats  release  close  expired  sleep  assert  update  expiry  assert  true  stats  assert  not  null  get  of  time  unit  verify  close  entry2  time  value  get  leased  conn2  entry1  conn1  assign  connection  argument  matchers  somehost  pool  assert  equals  totals  is  done  any  thread  never  future1  future2  mockito  close  mode  mock  lease  get  pending  get  total  stats  get  available  testcloseexpired  getstats  release  closeexpired  sleep  assert  updateexpiry  asserttrue  stats  assertnotnull  get  of  timeunit  verify  close  entry2  timevalue  getleased  conn2  entry1  conn1  assignconnection  argumentmatchers  somehost  pool  assertequals  totals  isdone  any  thread  never  future1  future2  mockito  closemode  mock  lease  getpending  gettotalstats  getavailable
__label__flaky  / 2009 / 01 / 01 /   coord  el  functions  tz  action-actual-time= \ ""  date  utils  sleep  for  sometime  as  it  gets  requeued  with  10ms  delay  on  failure  to  acquire  write  lock  ${coord:latest  range ( -3 0 ) }  before  and  after  action  creation  time  parse  date  oozie  tz  datasets  should  be  picked  up  based  on  current  time  and  not  action  creation / actual  time .   actual:  file: /  /   get  test  case  dir  coordinator  action  action  set  created  time  index  of   / 2009 / 01 / 08 /   resolved  list  execute  set  action  xml   / 2009 / 03 / 05  job  id  contains  coord  command  utils   / 2009 / 02 / 19 /   job  get  missing  dependencies  check  coord  action  expected:  set  push  missing  dependencies  get  time  get  id  2009-02-16  t23:59  < / uris>   / 2009 / 02 / 05  replace  all  system  substring  action  xml  sleep   / 2009 / 02 / 12 /   <uris>  test  action  input  check  latest  current  time  with  push  dependency  assert  true  get  create  dir  start  time  update  action  creation  time   \ "">  latest  2009-02-15  t23:59  action-actual-time= \ ""2009-02-15  t01:00   / 2009 / 03 / 05 /    / 2009 / 01 / 22 /   run  input  check  after  making  push  dependencies  available   / 2009 / 02 / 12  get  conf  action-actual-time= \ "" . * \ "">   / 2009 / 02 / 19  assert  equals  -  test  coord  action  input  check  x  command-  c  add  record  to  coord  job  table  thread  call  services  @1  push  missing  dependency  get  action  xml  run  input  check  after  making  latest  available  get  push  missing  dependencies  0000000-  end  time  2009-02-15  t01:00  action  creation  time  jpa  service  set  boolean  set  push  missing  dependency     / 2009 / 01 / 01 /   coordelfunctions  tz  action-actual-time= \ ""  dateutils   sleep for sometime as it gets requeued with 10ms delay on failure to acquire write lock  ${coord:latestrange ( -3 0 ) }   before and after action creation time  parsedateoozietz   datasets should be picked up based on current time and not action creation / actual time .   actual:   file: /  /   gettestcasedir  coordinatoraction  action  setcreatedtime  indexof   / 2009 / 01 / 08 /   resolvedlist  execute  setactionxml   / 2009 / 03 / 05  jobid  contains  coordcommandutils   / 2009 / 02 / 19 /   job  getmissingdependencies  checkcoordaction  expected:   setpushmissingdependencies  gettime  getid  2009-02-16t23:59  < / uris>   / 2009 / 02 / 05  replaceall  system  substring  actionxml  sleep   / 2009 / 02 / 12 /   <uris>  testactioninputchecklatestcurrenttimewithpushdependency  asserttrue  get  createdir  starttime   update action creation time   \ "">  latest  2009-02-15t23:59  action-actual-time= \ ""2009-02-15t01:00   / 2009 / 03 / 05 /    / 2009 / 01 / 22 /    run input check after making push dependencies available   / 2009 / 02 / 12  getconf  action-actual-time= \ "" . * \ "">   / 2009 / 02 / 19  assertequals  -testcoordactioninputcheckxcommand-c  addrecordtocoordjobtable  thread  call  services  @1  pushmissingdependency  getactionxml   run input check after making latest available  getpushmissingdependencies  0000000-  endtime  2009-02-15t01:00  actioncreationtime  jpaservice  setboolean   set push missing dependency
__label__nflaky is  static  get  name  log  get  declared  method  get  parameter  types  is  private  get  method  error  assert  that  m  har  file  system  must  not  implement  har  file  system  must  implement  get  declared  methods  methods  were  not  overridden  correctly  -  see  log  with  fail  message  is  less  than  or  equal  to  get  modifiers  is  final  test  inherited  methods  implemented  modifier  errors  isstatic  getname  log  getdeclaredmethod  getparametertypes  isprivate  getmethod  error  assertthat  m  harfilesystem must not implement   harfilesystem must implement   getdeclaredmethods   methods were not overridden correctly - see log  withfailmessage  islessthanorequalto  getmodifiers  isfinal  testinheritedmethodsimplemented  modifier  errors
__label__flaky get  jobs  info  get  job  info  test  get  jobs  info  foo  local  oozie  assert  equals  oozie  client  exception  expected .   oce  fail  get  coord  client  get  error  code  client  to  string  error  code  foo-id  getjobsinfo  getjobinfo  testgetjobsinfo  foo  localoozie  assertequals  oozieclientexception expected .   oce  fail  getcoordclient  geterrorcode  client  tostring  errorcode  foo-id
__label__nflaky http  headers  process  http  status  get  first  header  h1  interceptor  assert  equals  h2  get  entity  test  response  content  entity  content  lenght  delimited  set  entity  get  value  assert  assert  null  empty  input  stream  response  assert  not  null  context  ok  10  httpheaders  process  httpstatus  getfirstheader  h1  interceptor  assertequals  h2  getentity  testresponsecontententitycontentlenghtdelimited  setentity  getvalue  assert  assertnull  emptyinputstream  response  assertnotnull  context  ok  10
__label__flaky bundle  job  get  cmd  add  record  to  bundle  job  table  get  id  assert  equals  get  status  execute  call  services  assert  not  null  get  test  bundle  pause  unpause1  job  job  jpa  service  bundlejobgetcmd  addrecordtobundlejobtable  getid  assertequals  getstatus  execute  call  services  assertnotnull  get  testbundlepauseunpause1  job  job  jpaservice
__label__nflaky test  divide  to  milliseconds  assert  equals  to  microseconds  to  seconds  to  nanoseconds  nominator  is  0   result  should  be  0 .   to  minutes  assert  to  hours  of  milliseconds  to  milliseconds  int  bound  time  unit  divide  to  days  of  minutes  time  value  to  seconds  int  bound     testdivide  tomilliseconds  assertequals  tomicroseconds  toseconds  tonanoseconds   nominator is 0  result should be 0 .   tominutes  assert  tohours  ofmilliseconds  tomillisecondsintbound  timeunit  divide  todays  ofminutes  timevalue  tosecondsintbound
__label__flaky new  hash  map  index  router .   get (  )  . route (  \ "" / user / {id} / {email} / user  dashboard \ "" )  . with (   application  controller . class    \ ""user  dashboard \ "" ) ;  assert  equals  put   /   my  email   / user / my  id / my  email / user  dashboard  router  user  dashboard  maps  start  server  my  id  test  reverse  routing  with  map  test  1:  a  simple  route  without  replacements:  generated  reverse  route  get  reverse  route  id  map  email  newhashmap  index   router . get (  )  . route (  \ "" / user / {id} / {email} / userdashboard \ "" )  . with ( applicationcontroller . class   \ ""userdashboard \ "" ) ;  assertequals  put   /   myemail   / user / myid / myemail / userdashboard  router  userdashboard  maps  startserver  myid  testreverseroutingwithmap   test 1: a simple route without replacements:  generatedreverseroute  getreverseroute  id  map  email
__label__nflaky set  double  configuration  double_  delta  get  double  assert  equals  value  test  double  setdouble  configuration  double_delta  getdouble  assertequals  value  testdouble
__label__flaky workflow  job  5  should  have  been  purged  add  record  to  wf  action  table  workflow  action  2  should  have  been  purged  coordinator  action  3  should  have  been  purged  workflow  instance  get  status  add  record  to  coord  action  table  wf  action5  get  cmd  wf  job5  get  cmd  wf  action1  get  cmd  coord  action4  get  cmd  coord  action3  coord  action4  assert  not  null  coord  action5  coordinator  action  wf  job2  get  cmd  coord  action1  workflow  action  5  should  have  been  purged  test  purge  coord  with  wf  child3  more  than  limit  coord  action2  wf  job1  get  cmd  execute  coordinator  action  5  should  have  been  purged  workflow  job  2  should  have  been  purged  coordinator  job  1  coord  job  get  cmd  fail  workflow  action  coord  action3  get  cmd  succeeded  wf  action2  get  cmd  coordinator  action  2  should  have  been  purged  workflow  action  3  should  have  been  purged  je  workflow  job  1  should  have  been  purged  get  id  coord  action5  get  cmd  workflow  job  4  should  have  been  purged  coord  job  wf  job1  wf  job3  wf  job4  get  cmd  add  record  to  wf  job  table  wf  job2  get  error  code  wf  job5  get  wf  job4  coord  action2  get  cmd  workflow  action  1  should  have  been  purged  workflow  job  wf  action3  get  cmd  coordinator  action  4  should  have  been  purged  wf  action4  get  cmd  coordinator  job  should  have  been  purged  coord  action1  get  cmd  workflow  action  4  should  have  been  purged  assert  equals  coordinator  action  1  should  have  been  purged  wf  action1  wf  action2  add  record  to  coord  job  table  wf  action3  wf  action4  wf  action5  call  services  wf  job3  get  cmd  coord-action-get . xml  error  code  jpa  service  workflow  job  3  should  have  been  purged  workflow job 5 should have been purged  addrecordtowfactiontable  workflow action 2 should have been purged  coordinator action 3 should have been purged  workflowinstance  getstatus  addrecordtocoordactiontable  wfaction5getcmd  wfjob5getcmd  wfaction1getcmd  coordaction4getcmd  coordaction3  coordaction4  assertnotnull  coordaction5  coordinatoraction  wfjob2getcmd  coordaction1  workflow action 5 should have been purged  testpurgecoordwithwfchild3morethanlimit  coordaction2  wfjob1getcmd  execute  coordinator action 5 should have been purged  workflow job 2 should have been purged  coordinatorjob  1  coordjobgetcmd  fail  workflowaction  coordaction3getcmd  succeeded  wfaction2getcmd  coordinator action 2 should have been purged  workflow action 3 should have been purged  je  workflow job 1 should have been purged  getid  coordaction5getcmd  workflow job 4 should have been purged  coordjob  wfjob1  wfjob3  wfjob4getcmd  addrecordtowfjobtable  wfjob2  geterrorcode  wfjob5  get  wfjob4  coordaction2getcmd  workflow action 1 should have been purged  workflowjob  wfaction3getcmd  coordinator action 4 should have been purged  wfaction4getcmd  coordinator job should have been purged  coordaction1getcmd  workflow action 4 should have been purged  assertequals  coordinator action 1 should have been purged  wfaction1  wfaction2  addrecordtocoordjobtable  wfaction3  wfaction4  wfaction5  call  services  wfjob3getcmd  coord-action-get . xml  errorcode  jpaservice  workflow job 3 should have been purged
__label__nflaky transfer-  encoding  add  header  keep  alive  connection  chunked  yadda   k  eep-alive   dumdy  assert  assert  true  response  context  test  connection  tokens2  use  http  1 . 1  reuse  strategy  ok  transfer-encoding  addheader  keepalive  connection  chunked  yadda  keep-alive  dumdy  assert  asserttrue  response  context  testconnectiontokens2   use http 1 . 1  reusestrategy  ok
__label__flaky date  rs   \ %msg  -   \ %thread \ %n  async_  logger_  string  session  given  insert  select  *  from  simple  where  id  =  crud  prepare  log  level  should_insert_async  when  get  timestamp  get  await  id  latch  count  down  row  value  execute  async  info  log  asserter  all  random  utils  manager  with  result  set  async  listener  get  string  next  long  rows  assert  that  execute  assert  contains  get  long  called  has  size  then  long  logger  called  -  achilles-default-executor  is  equal  to  entity  date  rs   \ %msg -  \ %thread \ %n  async_logger_string  session   given  insert  select * from simple where id =   crud  prepareloglevel  should_insert_async   when  gettimestamp  get  await  id  latch  countdown  row  value  executeasync  info  logasserter  all  randomutils  manager  withresultsetasynclistener  getstring  nextlong  rows  assertthat  execute  assertcontains  getlong  called  hassize   then  long  logger  called - achilles-default-executor  isequalto  entity
__label__nflaky simulate  4  failures  to  test  cycling  through  the  bind  users  conf  ldap_  num_  attempts_  key  as  list   . bob  alice  password  file2 . txt  create  password  file  bob  bind  password   . alice  expected  bind  users  bob alice  bob  password  file1 . txt  set  expected  bind  passwords  set  int  bind_  user_  suffix  bob  username  test  bind  user  switch  password  from  file  bind_  password_  file_  suffix  bind_  users_  key  alice  username  alice  bind  password  do  test  bind  user  switch  arrays  get  base  conf   simulate 4 failures to test cycling through the bind users  conf  ldap_num_attempts_key  aslist   . bob  alicepasswordfile2 . txt  createpasswordfile  bobbindpassword   . alice  expectedbindusers  bob alice  bobpasswordfile1 . txt  set  expectedbindpasswords  setint  bind_user_suffix  bobusername  testbinduserswitchpasswordfromfile  bind_password_file_suffix  bind_users_key  aliceusername  alicebindpassword  dotestbinduserswitch  arrays  getbaseconf
__label__flaky date  script  executor  session  given  simple  map_  remove  by  key  update  simple  simplemap  eq  does  not  contain  entry  when  of  where  id  row  ten  table  twenty  execute  script  template  contains  entry  random  utils  manager  one  simple  map  next  long  assert  that  execute  simple  entity / insert_single_row . cql  immutable  map  get  map  has  size  then  long  build  date  key  from  base  table  dsl  select  simplemap  from  simple  where  id  =  should_dsl_update_map_remove  by  key  date  scriptexecutor  session   given  simplemap_removebykey  update  simple  simplemap  eq  doesnotcontainentry   when  of  where  id  row  ten  table  twenty  executescripttemplate  containsentry  randomutils  manager  one  simplemap  nextlong  assertthat  execute  simpleentity / insert_single_row . cql  immutablemap  getmap  hassize   then  long  builddatekey  frombasetable  dsl  select simplemap from simple where id =   should_dsl_update_map_removebykey
__label__nflaky prepare  test  coding  both  buffers_erasing_d5  test  coding  prepare  testcodingbothbuffers_erasing_d5  testcoding
__label__flaky integer=x  test  param  types  my  json  rest  servlet  integer=1  string=a  http  servlet  response  invoke  assert  equals  call  boolean=x  get  boolean=true  boolean=false  run  test    integer=x  testparamtypes  myjsonrestservlet  integer=1  string=a  httpservletresponse  invoke  assertequals  call  boolean=x  get  boolean=true  boolean=false  runtest
__label__nflaky version  40-  h .    ( 20  +  61 )   blocks .   version  3-  h .   2  blocks .   version  7-  h .    ( 4  +  1 )   blocks .   version  1-  h .   encoder  get  num  data  bytes  and  num  ec  bytes  for  block  id  num  data  bytes  test  get  num  data  bytes  and  num  ec  bytes  for  block  id  num  ec  bytes  assert  equals   version 40-h .   ( 20 + 61 )  blocks .    version 3-h .   2 blocks .    version 7-h .   ( 4 + 1 )  blocks .    version 1-h .   encoder  getnumdatabytesandnumecbytesforblockid  numdatabytes  testgetnumdatabytesandnumecbytesforblockid  numecbytes  assertequals
__label__flaky get  job  tracker  uri  get  name  <argument>  a< / argument>  get  app  path  test  perl  script  _test  submit  perl_  script_  content  create  a  sample  perl  script  fs  action  xml  <shell>  < / file>  create  script . pl  create  a  sample  shell  action  using  the  perl  script  write  close  <job-tracker>  get  name  node  uri  <exec>perl< / exec>  #  <capture-output / >  < / job-tracker>  <argument>script . pl< / argument>  get  file  system  script  <name-node>  <env-var>my_var1=my_val1< / env-var>  < / name-node>  < / shell>  testing  w  <file>  <argument>  b< / argument>  to  string  getjobtrackeruri  getname  <argument>a< / argument>  getapppath  testperlscript  _testsubmit  perl_script_content   create a sample perl script  fs  actionxml  <shell>  < / file>  create  script . pl   create a sample shell action using the perl script  write  close  <job-tracker>  getnamenodeuri  <exec>perl< / exec>  #  <capture-output / >  < / job-tracker>  <argument>script . pl< / argument>  getfilesystem  script  <name-node>  <env-var>my_var1=my_val1< / env-var>  < / name-node>  < / shell>  testing  w  <file>  <argument>b< / argument>  tostring
__label__nflaky get  outgoing  flash  cookie  data  make  sure  the  old  cookue  gets  parsed:  get  cookie  when  put  now  test  clear  current  flash  cookie  data  setup  this  testmethod  funny  new  flash  message  get  builder  context  test  that  flash  cookie  clear  works  flash  scope  cookie  init  ninja_  flash  cookie  then  return  hello=flash  scope  flash  cookie  assert  equals  size  build  is  there .  .  .   get  current  flash  cookie  data  clear  current  flash  cookie  data  ninja  properties  getoutgoingflashcookiedata   make sure the old cookue gets parsed:  getcookie  when  put   now test clearcurrentflashcookiedata   setup this testmethod  funny new flash message  get  builder  context  testthatflashcookieclearworks  flashscope  cookie  init  ninja_flash  cookie  thenreturn  hello=flashscope  flashcookie  assertequals  size  build  is there .  .  .   getcurrentflashcookiedata  clearcurrentflashcookiedata  ninjaproperties
__label__flaky coord-multiple-input-start-instance1 . xml  reader  test  basic  submit  with  multiple  start  instances  input  event  conf  get  status  coord-multiple-input-start-instance2 . xml  app  path  get  job  sc  get  error  code  assert  true  file: /  /   get  test  case  dir  unit_  testing  case  1:  failure  case  i . e .   multiple  data-in  start-instances  get  path  job  coordinator . xml  set  e  get  message  assert  equals  coordinator  app  definition  should  not  have  multiple  start-instances  call  oozie  client  fail  io  utils  contains  get  test  user  expected  to  catch  errors  due  to  incorrectly  specified  input  data  set  start-instances  copy  char  stream  unexpected  failure:  get  resource  as  reader  writer  error  code  file  case  2:  success  case  i . e .   single  start  instances  for  input  and  single  start  instance  for  output   but  both  with   \ ""  \ ""  coord-multiple-input-start-instance1 . xml  reader  testbasicsubmitwithmultiplestartinstancesinputevent  conf  getstatus  coord-multiple-input-start-instance2 . xml  apppath  getjob  sc  geterrorcode  asserttrue  file: /  /   gettestcasedir  unit_testing   case 1: failure case i . e .  multiple data-in start-instances  getpath  job  coordinator . xml  set  e  getmessage  assertequals  coordinator app definition should not have multiple start-instances  call  oozieclient  fail  ioutils  contains  gettestuser  expected to catch errors due to incorrectly specified input data set start-instances  copycharstream  unexpected failure:   getresourceasreader  writer  errorcode  file   case 2: success case i . e .  single start instances for input and single start instance for output  but both with  \ ""  \ ""
__label__nflaky test  set  max  per  route  assert  somehost  pool  set  max  per  route  assert  equals  get  max  per  route  testsetmaxperroute  assert  somehost  pool  setmaxperroute  assertequals  getmaxperroute
__label__flaky add  record  to  bundle  action  table  get  current  dateafter  incrementing  in  months  run  date  utils  workflow  instance  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  bundle  job  assert  not  null  coordinator  action  current  date  plus  month  job  wait  for  bundle  action1  bundle  action2  x  data  test  case  execute  add  record  to  coord  job  table  with  bundle  coord  job2  coordinator  job  coord  job1  test  bundle  status  transit  service  suspended  evaluate  assert  false  get  id  get  external  id  is  pending  wf  job  add  record  to  wf  job  table  get  end  coord  action1_3  workflow  job  coord  action1_4  bundle  coord  action1_1  coord  action1_2  add  record  to  bundle  job  table  bundle  id  start  assert  equals  call  services  runnable  coord-action-get . xml  equals  action1  action2  jpa  service  addrecordtobundleactiontable  getcurrentdateafterincrementinginmonths  run  dateutils  workflowinstance  getstatus  addrecordtocoordactiontable  parsedateoozietz  bundlejob  assertnotnull  coordinatoraction  currentdateplusmonth  job  waitfor  bundleaction1  bundleaction2  xdatatestcase  execute  addrecordtocoordjobtablewithbundle  coordjob2  coordinatorjob  coordjob1  testbundlestatustransitservicesuspended  evaluate  assertfalse  getid  getexternalid  ispending  wfjob  addrecordtowfjobtable  get  end  coordaction1_3  workflowjob  coordaction1_4  bundle  coordaction1_1  coordaction1_2  addrecordtobundlejobtable  bundleid  start  assertequals  call  services  runnable  coord-action-get . xml  equals  action1  action2  jpaservice
__label__nflaky result  test  that  correct  value  is  returned  with  default  setup  equal  to  resolve  application  class  name  ninja  properties  matchers  assert  that  ninja  base  directory  resolver  conf .   filters  result  testthatcorrectvalueisreturnedwithdefaultsetup  equalto  resolveapplicationclassname  ninjaproperties  matchers  assertthat  ninjabasedirectoryresolver  conf . filters
__label__flaky cluster  ha  test  util  get  canonical  service  name  spy  ns  list  status  conf  logical  host  eq  lookup  all  host  addr  fs  ensure  that  the  logical  hostname  was  never  resolved .   configure  failover  fs  make  a  few  calls  against  the  filesystem .    /   never  test  doesnt  dns  resolve  logical  uri  mockito  make  qualified  spy  on  name  service  verify  qualified  root  get  uri  get  host  cluster  hatestutil  getcanonicalservicename  spyns  liststatus  conf  logicalhost  eq  lookupallhostaddr  fs   ensure that the logical hostname was never resolved .   configurefailoverfs   make a few calls against the filesystem .    /   never  testdoesntdnsresolvelogicaluri  mockito  makequalified  spyonnameservice  verify  qualifiedroot  geturi  gethost
__label__nflaky set  handler  http / localhost  cancel  delegation  token  conf  get  kind  get  owner  keytab  file  get  cause  dis   / bar  assert   / foo / bar  foo_  user  assert  not  null  mini  kdc  context  random  uuid  id  uuid  dispatcher  type   / foo  ok_  user  hadoop . security . authentication  set  context  path  kdc  create  jetty  server  test . keytab  test  dir  token-kind  read  fields  test  kerberos  delegation  token  authenticator  fail  do  as  contains  ex  stop  mkdirs  make  sure  the  token  belongs  to  the  right  owner  403  create  principal  do  as  user  add  filter  do  as  kerberos  user  get  realm  kerberos  create  conf  gss  exception  assert  true  get  identifier  of  java . security . krb5 . realm  client  jetty   / *  close  get  jetty  url  set  a  url  add  servlet  get  absolute  path  enum  set  renew  delegation  token  start  kdta  filter  get  message  assert  equals  get  real  user  kerberos  test  utils  url  token  call  target /   buf  assert  null  to  string  get  delegation  token  sethandler  http / localhost  canceldelegationtoken  conf  getkind  getowner  keytabfile  getcause  dis   / bar  assert   / foo / bar  foo_user  assertnotnull  minikdc  context  randomuuid  id  uuid  dispatchertype   / foo  ok_user  hadoop . security . authentication  setcontextpath  kdc  createjettyserver  test . keytab  testdir  token-kind  readfields  testkerberosdelegationtokenauthenticator  fail  doas  contains  ex  stop  mkdirs   make sure the token belongs to the right owner  403  createprincipal  doasuser  addfilter  doaskerberosuser  getrealm  kerberos  createconf  gssexception  asserttrue  getidentifier  of  java . security . krb5 . realm  client  jetty   / *  close  getjettyurl  set  aurl  addservlet  getabsolutepath  enumset  renewdelegationtoken  start  kdtafilter  getmessage  assertequals  getrealuser  kerberostestutils  url  token  call  target /   buf  assertnull  tostring  getdelegationtoken
__label__flaky date  dsl_delete_with_schema  script  executor  table  name  for  session  given  eq  delete  select  *  from  simple  where  id  =  table  name  provider  when  of  where  id  row  table  simple  entity / create_simple_mirror_table . cql  execute  script  template  all  columns_  from  random  utils  manager  one  should_dsl_delete_with_schema_name  next  long  assert  that  execute  immutable  map  simple  entity / insert_single_row . cql  keyspace  for  then  is  null  long  build  date  key  dsl  default_  cassandra_  embedded_  keyspace_  name  date  dsl_delete_with_schema  scriptexecutor  tablenamefor  session   given  eq  delete  select * from simple where id =   tablename  provider   when  of  where  id  row  table  simpleentity / create_simple_mirror_table . cql  executescripttemplate  allcolumns_from  randomutils  manager  one  should_dsl_delete_with_schema_name  nextlong  assertthat  execute  immutablemap  simpleentity / insert_single_row . cql  keyspacefor   then  isnull  long  builddatekey  dsl  default_cassandra_embedded_keyspace_name
__label__nflaky conn  http / 1 . 1  200  ok  server:  test  transfer-  encoding:  identity  123  server  in  stream  test  read  response  entity  identity  get  endpoint  details  when  get  bytes  bind  assert  assert  true  assert  not  null  get  response  count  get  code  standard  charsets  then  return  assert  equals  get  input  stream  mockito  response  socket  contains  header  receive  response  header  receive  response  entity  conn  http / 1 . 1 200 ok  server: test  transfer-encoding: identity    123  server  instream  testreadresponseentityidentity  getendpointdetails  when  getbytes  bind  assert  asserttrue  assertnotnull  getresponsecount  getcode  standardcharsets  thenreturn  assertequals  getinputstream  mockito  response  socket  containsheader  receiveresponseheader  receiveresponseentity
__label__flaky a  a  b  el  constants  functions  <x>  xml  utils  < / x>  e  map2  &  get  text  parse  xml  assert  equals  parse  put  to  json  str  str  test  to  json  str  json  map  a  a  b  elconstantsfunctions  <x>  xmlutils  < / x>  e  map2  &  gettext  parsexml  assertequals  parse  put  tojsonstr  str  testtojsonstr  json  map
__label__nflaky store  password  get  resource  to  char  array  server  socket  new  single  thread  executor  executors  server  ssl  context  get  server  socket  factory  assert  bind  assert  not  null  nopassword  create  time  unit  boolean  ssl  context  builder  write  localhost  read  local  port  load  key  material  load  trust  material  input  stream  set  so  timeout  get  input  stream  resource1  accept  create  socket  client  ssl  context  timeout   / test . p12  get  local  port  submit  client  socket  result  test  ssl  handshake  server  trusted  flush  key  password  get  output  stream  close  connect  assert  equals  call  get  socket  factory  build  future  to  milliseconds  int  bound  get  output  stream  socket  create  server  socket  storepassword  getresource  tochararray  serversocket  newsinglethreadexecutor  executors  serversslcontext  getserversocketfactory  assert  bind  assertnotnull  nopassword  create  timeunit  boolean  sslcontextbuilder  write  localhost  read  localport  loadkeymaterial  loadtrustmaterial  inputstream  setsotimeout  getinputstream  resource1  accept  createsocket  clientsslcontext  timeout   / test . p12  getlocalport  submit  clientsocket  result  testsslhandshakeservertrusted  flush  keypassword  get  outputstream  close  connect  assertequals  call  getsocketfactory  build  future  tomillisecondsintbound  getoutputstream  socket  createserversocket
__label__flaky test  async  close_read  write  lock  got  async  close  exception  channel  executors  handler  latch  get  cause  sleep  uninterruptibly  write  cause  another  thread  trying  to  read  to  block  exc  assert  true  executor  get  await  lock  count  down  close  milliseconds  read  set  new  fixed  thread  pool  expected  store  completed  failed  give  enough  time  to  ensure  both  reads  start  blocking  byte  store  byte  buffer  read  fail  allocate  future  uninterruptibles  shutdown  testasyncclose_read  writelock  gotasynccloseexception  channel  executors  handlerlatch  getcause  sleepuninterruptibly  write   cause another thread trying to read to block  exc  asserttrue  executor  get  await  lock  countdown  close  milliseconds  read  set  newfixedthreadpool  expected  store  completed  failed   give enough time to ensure both reads start blocking  bytestore  bytebuffer  read  fail  allocate  future  uninterruptibles  shutdown
__label__nflaky conn  read  in  stream  then  return  argument  matchers  get  input  stream  when  any  any  int  test  stale  when  io  error  bind  assert  mockito  assert  true  ensure  open  mock  socket  is  stale  then  throw  conn  read  instream  thenreturn  argumentmatchers  getinputstream  when  any  anyint  teststalewhenioerror  bind  assert  mockito  asserttrue  ensureopen  mock  socket  isstale  thenthrow
__label__flaky session  given  update  eq  incr  when  where  id  is  not  null  should_dsl_update  actual  random  utils  manager  incr  one  count  next  long  assert  that  execute  get  long  then  long  select  count  from  entity_counter  where  id  =  from  base  table  dsl  is  equal  to  session   given  update  eq  incr   when  where  id  isnotnull  should_dsl_update  actual  randomutils  manager  incr  one  count  nextlong  assertthat  execute  getlong   then  long  select count from entity_counter where id =   frombasetable  dsl  isequalto
__label__nflaky add  is  order  size  is  use  atime  is  human  readable  is  order  reverse  ls  assert  false  -u  is  dir  recurse  process  options  atime  is  recursive  is  path  only  chheck  the  -u  option  is  recognised  assert  true  is  order  time  options  process  options  is  display  ec  policy  add  isordersize  isuseatime  ishumanreadable  isorderreverse  ls  assertfalse  -u  isdirrecurse  processoptionsatime  isrecursive  ispathonly   chheck the -u option is recognised  asserttrue  isordertime  options  processoptions  isdisplayecpolicy
__label__flaky json  tags  ;coordinators=  coord1   coord2;actionstatus=  killed   / v1 / jobs  test  multiple  coordinators  giving  range  as  2  of  the  total  3  coordinators  assert  equals  jaction1  jaction2  coord1@2  coord2@1  call  size  array  assert  not  null  get  bundle  name  _request  to  server  bulk  request  bundle=  run  test  jbundle  jsontags  ;coordinators=coord1 coord2;actionstatus=killed   / v1 / jobs  testmultiplecoordinators   giving range as 2 of the total 3 coordinators  assertequals  jaction1  jaction2  coord1@2  coord2@1  call  size  array  assertnotnull  get  bundlename  _requesttoserver  bulkrequest  bundle=  runtest  jbundle
__label__nflaky http / 1 . 1  200  test  sl  formatting  http  status  clear  assert  equals  format  status  line  buf  assert  statusline1  to  string  ok  http  version  http / 1 . 1  200  ok  statusline2  http / 1 . 1 200   testslformatting  httpstatus  clear  assertequals  formatstatusline  buf  assert  statusline1  tostring  ok  httpversion  http / 1 . 1 200 ok  statusline2
__label__flaky ss  bean  get  expected  duration  get  actual  end  get  time  act  end  assert  false  get  event  status  event  status  get  expected  start  set  insert  list  cal  bean1  assert  not  null  exp  end  bean2  get  _create  sla  summary  bean  get  actual  duration  is  start  processed  get  actual  start  set  time  add  get  job  status  act  start  running  get  job  id  _create  sla  calc  bean  is  end  processed  workflow-1  calendar  assert  equals  write  cmd  exp  start  list  read  cmd2  execute  read  cmd1  sc  bean  get  expected  end  services  jpa  service  wf  id  test  insert  ssbean  getexpectedduration  getactualend  gettime  actend  assertfalse  geteventstatus  eventstatus  getexpectedstart  setinsertlist  cal  bean1  assertnotnull  expend  bean2  get  _createslasummarybean  getactualduration  isstartprocessed  getactualstart  settime  add  getjobstatus  actstart  running  getjobid  _createslacalcbean  isendprocessed  workflow-1  calendar  assertequals  writecmd  expstart  list  readcmd2  execute  readcmd1  scbean  getexpectedend  services  jpaservice  wfid  testinsert
__label__nflaky unknown  property:  get  changed  properties  get  status  when  dummy  reconfigure  property  impl  lists  new3  add  new3  new2  get  key  new1  entry  set  any  string  old3  conf1  eq  wait  async  reconfigure  task  finish  assert  that  fail  do  throw  name3  size  name2  spy  name1  status  assert  false  changes  contains  string  is  present  result  property  name2  is  not  reconfigurable  io  exception  get  reconfiguration  task  status  get  old3  old1  old2  name3  new  array  list  is  property  reconfigurable  do  return  change  assert  equals  test  async  reconfigure  any  get  value  equals  start  reconfiguration  task  unknown property:   getchangedproperties  getstatus  when  dummy  reconfigurepropertyimpl  lists  new3  add  new3  new2  getkey  new1  entryset  anystring  old3  conf1  eq  waitasyncreconfiguretaskfinish  assertthat  fail  dothrow  name3  size  name2  spy  name1  status  assertfalse  changes  containsstring  ispresent  result  property name2 is not reconfigurable  io exception  getreconfigurationtaskstatus  get  old3  old1  old2  name3  newarraylist  ispropertyreconfigurable  doreturn  change  assertequals  testasyncreconfigure  any  getvalue  equals  startreconfigurationtask
__label__flaky test  single  cell  get  json  row_4  to  bytes  mimetype_  json  assert  equals  put   /   thread  table  path  bytes  delete  row  column_1  mimetype_  binary  response  yield  get  client  get  code  value_4  testsinglecellgetjson  row_4  tobytes  mimetype_json  assertequals  put   /   thread  table  path  bytes  deleterow  column_1  mimetype_binary  response  yield  get  client  getcode  value_4
__label__nflaky factory  guice  this  will  not  work  =>  we  expect  a  runtime  exception  with  the  impl  missing  does_not_exist  i . am . a . test . implementation  logger  thrown  expect  ninja  mode  create  injector  set  property  this  should  be  okay  since  we  want  to  defer  the  resolution  until  a   \  ' get \  '   create  ninja  properties  injector  missing  implementation  deferred  until  get  factory  guice   this will not work => we expect a runtime exception with the impl missing  does_not_exist  i . am . a . test . implementation  logger  thrown  expect  ninjamode  createinjector  setproperty   this should be okay since we want to defer the resolution until a  \  ' get \  '   create  ninjaproperties  injector  missingimplementationdeferreduntilget
__label__flaky end_  points  is_  security_  enabled  get  context  url  oozie  url  e  get  job  info  test  ws  errors  get  message  mock  dag  engine  service  wc  dummy  call  fail  get  error  code  assert  not  null  servlet_  classes  run  test  end_points  is_security_enabled  getcontexturl  oozieurl  e  getjobinfo  testwserrors  getmessage  mockdagengineservice  wc  dummy  call  fail  geterrorcode  assertnotnull  servlet_classes  runtest
__label__nflaky normalized  hosts  assert  false  test  normalize  host  name  as  list  network  not  resolving  unknown  host123  one  host  string  utils  for  normalizing  a  resolvable  hostname   resolved  ipaddress  is  expected  in  return  get  1 . kanyezone . appspot . com  get  by  name  join    localhost  summary  hosts  normalize  host  names  when  ipaddress  is  normalized   same  address  is  expected  in  return  assert  equals  normalized    return  the  same  hostname  after  normalizing  a  irresolvable  hostname .   assume  true  net  utils     its  ipaddress  is  expected  to  return  equals  element  2  equal  assume  element  1  equal  original    arrays  inet  address  127 . 0 . 0 . 1  normalizedhosts  assertfalse  testnormalizehostname  aslist  network not resolving   unknownhost123  onehost  stringutils   for normalizing a resolvable hostname  resolved ipaddress is expected in return  get  1 . kanyezone . appspot . com  getbyname  join    localhost  summary  hosts  normalizehostnames   when ipaddress is normalized  same address is expected in return  assertequals   normalized    return the same hostname after normalizing a irresolvable hostname .   assumetrue  netutils       its ipaddress is expected to return  equals  element 2 equal   assume  element 1 equal   original   arrays  inetaddress  127 . 0 . 0 . 1
__label__flaky init  res   . dataout .   abc . unresolved   \  ' region=us datastamp=20120230 \  '   hcat: /  / hcat . server . com:5080 / mydb / clicks / datastamp=20120230;region=us  coord  el  functions  ${coord:data  out  partitions (  \  '   abc \  '  ) }  set  variable   \  ' datastamp=20120230 region=us \  '   coord-action-start  eval  eval  and  wrap  assert  true   . dataout .   abc  equals  test  data  out  partitions  expr  boolean  init  res   . dataout . abc . unresolved   \  ' region=us datastamp=20120230 \  '   hcat: /  / hcat . server . com:5080 / mydb / clicks / datastamp=20120230;region=us  coordelfunctions  ${coord:dataoutpartitions (  \  ' abc \  '  ) }  setvariable   \  ' datastamp=20120230 region=us \  '   coord-action-start  eval  evalandwrap  asserttrue   . dataout . abc  equals  testdataoutpartitions  expr  boolean
__label__nflaky  ( 15 ) 991231 ( 15 ) 991231 ( 3103 ) 001750 ( 10 ) 12  a  check  fields  test  parse  field2   ( 15 ) 991231 ( 15 ) 991231 ( 3103 ) 001750 ( 10 ) 12a  checkfields  testparsefield2
__label__flaky log4j . appender . oozie .   rolling  policy .   file  name  pattern  ${oozie . log . dir} / oozie . log-blah  get  name  test  missing  appender  class  get  test  case  conf  dir  ${oozie . log . dir} / oozie . log- \ %d{yyyy-  mm-dd-  hh} . gz  ls  assert  false  test  non-absolute  path  for  logfile  test  daily  rolling  file  appender  but  date  pattern  that  doesn \  ' t  end  with   \  '   hh \  '   or   \  ' dd \  '   fos  log4j . appender . oozie .   file  do  stream  disabled  check  ${oozie . log . dir} / oozie . log- \ %d{yyyy-  mm-dd-  hh}  props  file   \  '  .  \  ' yyyy-  mm-dd   \  '  .  \  ' yyyy-  mm-dd-  hh  test  missing  logfile  test  appender  class  not  daily  rolling  file  appender  or  rolling  file  appender  assert  true  oozie . log  test  daily  rolling  file  appender  with  everything  correct   ( dd )   test  daily  rolling  file  appender  with  everything  correct   (   hh )   test  rolling  file  appender  but  file  name  pattern  with  incorrect  beginning   \  '  .  \  ' yyyy-  mm  test  rolling  file  appender  with  everything  correct   ( gz )   test  rolling  file  appender  with  everything  correct  init  test  disable  log  over  ws  x  log  service  ${oozie . log . dir} / oozie . log  destroy  store  props  test-disable-log-over-ws-log4j . properties  org . apache . log4j .   daily  rolling  file  appender  log4j . appender . oozie  log4j . appender . oozie .   date  pattern  test  rolling  file  appender  but  missing  file  name  pattern  set  property  set  system  property  org . blah . blah  org . apache . log4j . rolling .   rolling  file  appender  test  rolling  file  appender  but  file  name  pattern  with  incorrect  ending  test  daily  rolling  file  appender  but  missing  date  pattern  ${oozie . log . dir} / blah . log- \ %d{yyyy-  mm-dd-  hh}    log4j . appender . oozie . rollingpolicy . filenamepattern  ${oozie . log . dir} / oozie . log-blah  getname   test missing appender class  gettestcaseconfdir  ${oozie . log . dir} / oozie . log- \ %d{yyyy-mm-dd-hh} . gz  ls  assertfalse   test non-absolute path for logfile   test dailyrollingfileappender but datepattern that doesn \  ' t end with  \  ' hh \  '  or  \  ' dd \  '   fos  log4j . appender . oozie . file  dostreamdisabledcheck  ${oozie . log . dir} / oozie . log- \ %d{yyyy-mm-dd-hh}  propsfile   \  '  .  \  ' yyyy-mm-dd   \  '  .  \  ' yyyy-mm-dd-hh   test missing logfile   test appender class not dailyrollingfileappender or rollingfileappender  asserttrue  oozie . log   test dailyrollingfileappender with everything correct  ( dd )    test dailyrollingfileappender with everything correct  ( hh )    test rollingfileappender but filenamepattern with incorrect beginning   \  '  .  \  ' yyyy-mm   test rollingfileappender with everything correct  ( gz )    test rollingfileappender with everything correct  init  testdisablelogoverws  xlogservice  ${oozie . log . dir} / oozie . log  destroy  store  props  test-disable-log-over-ws-log4j . properties  org . apache . log4j . dailyrollingfileappender  log4j . appender . oozie  log4j . appender . oozie . datepattern   test rollingfileappender but missing filenamepattern  setproperty  setsystemproperty  org . blah . blah  org . apache . log4j . rolling . rollingfileappender   test rollingfileappender but filenamepattern with incorrect ending   test dailyrollingfileappender but missing datepattern  ${oozie . log . dir} / blah . log- \ %d{yyyy-mm-dd-hh}
__label__nflaky add  executing  thread  should  be  a  daemon  thread .   current  thread  wait  get  executor  service  notify  all  is  empty  executing  threads  run  execute  thread  assert  true  is  daemon  exec  svc  get  context  context  threadpool  is  daemonized  add  executing thread should be a daemon thread .   currentthread  wait  getexecutorservice  notifyall  isempty  executingthreads  run  execute  thread  asserttrue  isdaemon  execsvc  get  context  contextthreadpoolisdaemonized
__label__flaky mytbl1  get  waiting  actions  server2  server1  get  available  dependency  ur  is  should  not  contain  duplicates  remove  available  dependency  ur  is  1234465454  mydb  1234465452  1234465453  hcat: /  / hcat-server1 . domain . com:5080 / mydb / mytbl1 / dt=20120101;country=us  remove  missing  dependency  server1 db table1  get  jms  connection  info  hcat  service  dep3  jms  service  dep4  dep1  dep2  is  registered  for  notification   .   pdms  get  db  action  id2  action  id1  action  id4  contains  test  partition  dependency  action  id3  hcat: /  / hcat-server1 . domain . com:5080 / mydb / mytbl1 / country=us;dt=20120101  conn  info  size  get  table  is  listening  to  topic  hcat: /  / hcat-server2 . domain . com:5080 / mydb / mytbl2 / dt=20120102;country=us  get  partition  map  add  partition  as  missing  get  uri  mytbl2  server2 db table2  dt=20120101;country=us  assert  false  partition  available  hcat: /  / hcat-server2 . domain . com:5080 / mydb / mytbl2 / dt=20120102;country=us;state=  ca  table2  table1  hcat-server1 . domain . com:5080  assert  true  get  test  all  ap  is  related  to  dependency  caching  add  duplicates .   recovery  service  will  add  duplicates  1234465451  add  missing  dependency  and  register  assert  equals  dt=20120102;country=us;state=  ny  services  assert  null  hcat-server2 . domain . com:5080  to  string  dt=20120102;country=us;state=  ca  db  mytbl1  getwaitingactions  server2  server1  getavailabledependencyuris   should not contain duplicates  removeavailabledependencyuris  1234465454  mydb  1234465452  1234465453  hcat: /  / hcat-server1 . domain . com:5080 / mydb / mytbl1 / dt=20120101;country=us  removemissingdependency   server1 db table1  getjmsconnectioninfo  hcatservice  dep3  jmsservice  dep4  dep1  dep2  isregisteredfornotification   .   pdms  getdb  actionid2  actionid1  actionid4  contains  testpartitiondependency  actionid3  hcat: /  / hcat-server1 . domain . com:5080 / mydb / mytbl1 / country=us;dt=20120101  conninfo  size  gettable  islisteningtotopic  hcat: /  / hcat-server2 . domain . com:5080 / mydb / mytbl2 / dt=20120102;country=us  getpartitionmap   add partition as missing  geturi  mytbl2   server2 db table2  dt=20120101;country=us  assertfalse  partitionavailable  hcat: /  / hcat-server2 . domain . com:5080 / mydb / mytbl2 / dt=20120102;country=us;state=ca  table2  table1  hcat-server1 . domain . com:5080  asserttrue  get   test all apis related to dependency caching   add duplicates .  recoveryservice will add duplicates  1234465451  addmissingdependencyandregister  assertequals  dt=20120102;country=us;state=ny  services  assertnull  hcat-server2 . domain . com:5080  tostring  dt=20120102;country=us;state=ca  db
__label__nflaky file_  footer  file_  header  presentation_  footer  header  footer  check  presentation_  header  smoke  presentation_  footer  file_  header  file_footer  file_header  presentation_footer  headerfootercheck  presentation_header  smoke  presentation_footer   file_header
__label__flaky conn  open  connection  unchecked  http  servlet  response  assert  equals  params  error  url  put  call  get  response  code   / callback  create  url  id  collections  ok  run  test  test  callback  get  status    conn  openconnection  unchecked  httpservletresponse  assertequals  params  error  url  put  call  getresponsecode   / callback  createurl  id  collections  ok  runtest  testcallbackget  status
__label__nflaky request  http  headers  header  elements  conn  when  set  entity  test  execution  entity  enclosing  request  with  expect  continue  no  response  times  is  data  available  flush  executor  context  create  verify  ok  boolean  post  process  add  header  process  then  return  argument  matchers  method  get  entity  execute   /   any  int  mockito  response  http  core  context  httprocessor  mock  pre  process  entity  receive  response  header  send  request  entity  send  request  header  receive  response  entity  request  httpheaders  headerelements  conn  when  setentity  testexecutionentityenclosingrequestwithexpectcontinuenoresponse  times  isdataavailable  flush  executor  context  create  verify  ok  boolean  postprocess  addheader  process  thenreturn  argumentmatchers  method  getentity  execute   /   anyint  mockito  response  httpcorecontext  httprocessor  mock  preprocess  entity  receiveresponseheader  sendrequestentity  sendrequestheader  receiveresponseentity
__label__flaky kills  add  node  def  enters  one  start  test  asynch  simple  assert  equals  workflow  instance  get  status  as  list  wf   /   1  exits  size  <worklfow-app / >  end  arrays  job  signal  fails    kills  addnode  def  enters  one  start  testasynchsimple  assertequals  workflowinstance  getstatus  aslist  wf   /   1  exits  size  <worklfow-app / >  end  arrays  job  signal  fails
__label__nflaky set  ninja  properties  test  that  setting  ninja  properties  twice  does  not  work  ninja  mode  equal  to  ninja  servlet  listener  ninja  properties  assert  that  first  setting  works  setting  the  properties  a  second  time  does  not  work .  .  .   got  exception  setninjaproperties  testthatsettingninjapropertiestwicedoesnotwork  ninjamode  equalto  ninjaservletlistener  ninjaproperties  assertthat   first setting works   setting the properties a second time does not work .  .  .   gotexception
__label__flaky init  get  name  set  oozie . service .   proxy  user  service . proxyuser . foo . hosts  get  conf  destroy  conf  *  services     as  list  test  wrong  config  groups  services  fail  string  utils  join  arrays  init  getname  set  oozie . service . proxyuserservice . proxyuser . foo . hosts  getconf  destroy  conf  *  services     aslist  testwrongconfiggroups  services  fail  stringutils  join  arrays
__label__nflaky common  configuration  keys  public  test  connection  retries  on  socket  timeout  exceptions  set  max  retries  to  3  conf  set  max  retries  to  0  assert  retries  on  socket  timeouts  set  int  commonconfigurationkeyspublic  testconnectionretriesonsockettimeoutexceptions   set max retries to 3  conf   set max retries to 0  assertretriesonsockettimeouts  setint
__label__flaky fname  stat  need  to  run  long  enough  to  fail:  takes  25  to  35  seec  on  mac  log  position  read  option  assert  equals  test  write  and  read  test  write  read  seq  summary  status  from  test1:  status=  rd  begin  pos  wr_  ntimes  assert  filename  option  wr_  chunk_  size  use  fc  option  info  fname  stat   need to run long enough to fail: takes 25 to 35 seec on mac  log  positionreadoption  assertequals  testwriteandread  testwritereadseq  summary status from test1: status=   rdbeginpos  wr_ntimes  assert  filenameoption  wr_chunk_size  usefcoption  info
__label__nflaky verify  read  to  read  sequence  of  actions:  conf  write  random  bytes  to  file  math  fs  seek  @  system  next  bytes  sb  seek  off  min  stream  file  system  create  close  write  afe  set  class  reads  new  instance  j  next  int  stm  set  int  common  configuration  keys  public  buf  r  test_  path  record  the  sequence  of  seeks  and  reads  which  trigger  a  failure .   to  string  fs . file . impl  test  buffered  fs  input  stream  open  append  seeks  read      verifyread  toread  sequence of actions:    conf   write random bytes to file      math  fs  seek @   system  nextbytes  sb  seekoff  min  stream  filesystem  create  close  write  afe  setclass  reads  newinstance  j  nextint  stm  setint  commonconfigurationkeyspublic  buf  r  test_path   record the sequence of seeks and reads which trigger a failure .   tostring  fs . file . impl  testbufferedfsinputstream  open  append  seeks  read
__label__flaky wf  job  c  get  cmd  add  record  to  bundle  action  table  coord  action  c  coord  action  d  wf  action  f  get  cmd  subwf  action  a  get  cmd  add  record  to  wf  action  table  coord  action  a  coord  action  b  2011-02-01  t01:00  z  get  status  coord  job  c  get  cmd  wf  job  f  get  cmd  wf  action  c  get  cmd  get  end  time  bundle  action  a  bundle  job  bean  assert  not  null  bundle  action  b  coordinator  action  workflow  job  c  should  not  have  been  purged  2011-03-01  t01:00  z  sub  workflow  job  c  should  not  have  been  purged  bundle  job  a  get  cmd  job  relationships:  bundle  job  a  yes  yes  coord  job  a  yes  ^  wf  job  a  yes  ^  subwf  job  a  yes  ^  bundle  job  b  no  no  coord  job  b  yes  ^  wf  job  b  no  ^  coord  job  c  no  no  wf  job  c  no  ^  subwf  job  c  yes  ^  coord  job  d  yes  no  wf  job  d  no  ^  wf  job  e  yes  yes  wf  job  f  yes  no  subwf  job  f  no  ^  workflow  action  c  should  not  have  been  purged  subwf  job  c  get  cmd  execute  workflow  job  d  should  not  have  been  purged  sub  workflow  job  a  should  have  been  purged  coordinator  job  1  subwf  action  f  fail  sub  workflow  action  f  should  not  have  been  purged  succeeded  subwf  job  f  get  cmd  bundle  action  b  should  not  have  been  purged  bundle  action  a  get  cmd  je  coordinator  job  d  should  not  have  been  purged  subwf  action  f  get  cmd  wf  job  a  subwf  job  f  wf  job  c  2011-04-01  t01:00  z  wf  job  b  wf  job  e  wf  job  d  subwf  job  a  wf  job  f  subwf  action  a  workflow  job  b  should  not  have  been  purged  subwf  job  c  subwf  action  c  bundle  action  a  should  have  been  purged  coordinator  action  d  should  not  have  been  purged  2011-07-01  t01:00  z  coordinator  job  c  should  not  have  been  purged  get  error  code  get  wf  job  a  get  cmd  wf  action  e  get  cmd  get  app  name  bundle  job  b  should  not  have  been  purged  coordinator  job  b  should  not  have  been  purged  2011-01-01  t01:00  z  add  record  to  bundle  job  table  set  last  modified  time  assert  equals  get  last  modified  time  test  purge  lots  of  jobs  add  record  to  coord  job  table  call  services  wf  action  d  get  cmd  workflow  action  d  should  not  have  been  purged  wf  action  a  jpa  service  wf  action  b  wf  action  c  wf  action  d  wf  action  e  wf  action  f  bundle  job  b  get  cmd  sub  workflow  action  c  should  not  have  been  purged  workflow  action  e  should  have  been  purged  sub  workflow  job  f  should  not  have  been  purged  coord  action  a  get  cmd  get  num  days  to  not  be  purged  date  utils  workflow  instance  add  record  to  coord  action  table  parse  date  oozie  tz  workflow  job  f  should  not  have  been  purged  coord  job  d  get  cmd  2011-05-01  t01:00  z  coordinator  job  a  should  have  been  purged  job  coord  action  d  get  cmd  coordinator  action  a  should  have  been  purged  workflow  action  f  should  not  have  been  purged  coord  job  b  coord  job  c  coordinator  action  c  should  not  have  been  purged  coord  job  a  coord  job  d  wf  action  b  get  cmd  wf  job  b  get  cmd  wf  job  e  get  cmd  workflow  action  2011-06-01  t01:00  z  coord  action  c  get  cmd  workflow  action  a  should  have  been  purged  wf  action  a  get  cmd  bundle  job  a  should  have  been  purged  get  id  workflow  job  a  should  have  been  purged  subwf  action  c  get  cmd  bundle  action  b  get  cmd  bundle  job  a  bundle  job  b  add  record  to  wf  job  table  wf  job  d  get  cmd  workflow  action  b  should  not  have  been  purged  workflow  job  coord  job  a  get  cmd  sub  workflow  action  a  should  have  been  purged  coord  action  b  get  cmd  subwf  job  a  get  cmd  coord-action-get . xml  coord  job  b  get  cmd  set  end  time  workflow  job  e  should  have  been  purged  error  code  coordinator  action  b  should  not  have  been  purged  wfjobcgetcmd  addrecordtobundleactiontable  coordactionc  coordactiond  wfactionfgetcmd  subwfactionagetcmd  addrecordtowfactiontable  coordactiona  coordactionb  2011-02-01t01:00z  getstatus  coordjobcgetcmd  wfjobfgetcmd  wfactioncgetcmd  getendtime  bundleactiona  bundlejobbean  assertnotnull  bundleactionb  coordinatoraction  workflow job c should not have been purged  2011-03-01t01:00z  subworkflow job c should not have been purged  bundlejobagetcmd   job relationships:          bundlejoba              yes     yes              coordjoba           yes     ^                  wfjoba          yes     ^                      subwfjoba   yes     ^          bundlejobb              no      no              coordjobb           yes     ^                  wfjobb          no      ^          coordjobc               no      no              wfjobc              no      ^                  subwfjobc       yes     ^          coordjobd               yes     no              wfjobd              no      ^          wfjobe                  yes     yes          wfjobf                  yes     no              subwfjobf           no      ^            workflow action c should not have been purged  subwfjobcgetcmd  execute  workflow job d should not have been purged  subworkflow job a should have been purged  coordinatorjob  1  subwfactionf  fail  subworkflow action f should not have been purged  succeeded  subwfjobfgetcmd  bundle action b should not have been purged  bundleactionagetcmd  je  coordinator job d should not have been purged  subwfactionfgetcmd  wfjoba  subwfjobf  wfjobc  2011-04-01t01:00z  wfjobb  wfjobe  wfjobd  subwfjoba  wfjobf  subwfactiona  workflow job b should not have been purged  subwfjobc  subwfactionc  bundle action a should have been purged  coordinator action d should not have been purged  2011-07-01t01:00z  coordinator job c should not have been purged  geterrorcode  get  wfjobagetcmd  wfactionegetcmd  getappname  bundle job b should not have been purged  coordinator job b should not have been purged  2011-01-01t01:00z  addrecordtobundlejobtable  setlastmodifiedtime  assertequals  getlastmodifiedtime  testpurgelotsofjobs  addrecordtocoordjobtable  call  services  wfactiondgetcmd  workflow action d should not have been purged  wfactiona  jpaservice  wfactionb  wfactionc  wfactiond  wfactione  wfactionf  bundlejobbgetcmd  subworkflow action c should not have been purged  workflow action e should have been purged  subworkflow job f should not have been purged  coordactionagetcmd  getnumdaystonotbepurged  dateutils  workflowinstance  addrecordtocoordactiontable  parsedateoozietz  workflow job f should not have been purged  coordjobdgetcmd  2011-05-01t01:00z  coordinator job a should have been purged  job  coordactiondgetcmd  coordinator action a should have been purged  workflow action f should not have been purged  coordjobb  coordjobc  coordinator action c should not have been purged  coordjoba  coordjobd  wfactionbgetcmd  wfjobbgetcmd  wfjobegetcmd  workflowaction  2011-06-01t01:00z  coordactioncgetcmd  workflow action a should have been purged  wfactionagetcmd  bundle job a should have been purged  getid  workflow job a should have been purged  subwfactioncgetcmd  bundleactionbgetcmd  bundlejoba  bundlejobb  addrecordtowfjobtable  wfjobdgetcmd  workflow action b should not have been purged  workflowjob  coordjobagetcmd  subworkflow action a should have been purged  coordactionbgetcmd  subwfjobagetcmd  coord-action-get . xml  coordjobbgetcmd  setendtime  workflow job e should have been purged  errorcode  coordinator action b should not have been purged
__label__nflaky exit_  exception_  thrown  test  throwable  java . lang .   out  of  memory  error  arg_  throwable  assert  launch  outcome  name  exit_exception_thrown  testthrowable  java . lang . outofmemoryerror  arg_throwable  assertlaunchoutcome  name
__label__flaky get  job  tracker  uri  get  name  <java>  conf  create  context  app  path  setup  action  conf  create  base  hadoop  conf  action  xml  scheme  localfs  not  supported  assert  true  get  context  hdfs viewfs  <job-tracker>  test  filesystem  scheme  get  name  node  uri  localfs: /  / namenode:port / mydir  e  action  xml  init  ae  < / java>  xml  utils  < / main-class>  parse  xml  get  message  < / job-tracker>  destroy  hadoop  accessor  service  <name-node>  <main-class>  supposed  to  throw  exception  due  to  unsupported  fs  scheme  -  localfs  < / name-node>  e0904  services  fail  contains  set  system  property  getjobtrackeruri  getname  <java>  conf  createcontext  apppath  setupactionconf  createbasehadoopconf  actionxml  scheme localfs not supported  asserttrue  get  context  hdfs viewfs  <job-tracker>  testfilesystemscheme  getnamenodeuri  localfs: /  / namenode:port / mydir  eactionxml  init  ae  < / java>  xmlutils  < / main-class>  parsexml  getmessage  < / job-tracker>  destroy  hadoopaccessorservice  <name-node>  <main-class>  supposed to throw exception due to unsupported fs scheme - localfs  < / name-node>  e0904  services  fail  contains  setsystemproperty
__label__nflaky server  server  threads  server  assert  false  call  ids  run  conf  contains  every  expected  value .   start  id  get  client  synchronized  list  join  per  caller  call  count  collections  addr  get  call  id  caller  count  add  int  value  test  unique  sequential  call  ids  start  assert  equals  sort  get  connect  address  list  must  be  synchronized   because  multiple  server  threads  will  add  to  it .   net  utils  stop  size  callers  expected  call  count  server  serverthreads  server  assertfalse  callids  run  conf   contains every expected value .   startid  get  client  synchronizedlist  join  percallercallcount  collections  addr  getcallid  callercount  add  intvalue  testuniquesequentialcallids  start  assertequals  sort  getconnectaddress   list must be synchronized  because multiple server threads will add to it .   netutils  stop  size  callers  expectedcallcount
__label__flaky get  job  tracker  uri  < / configuration>  create  context  cache  files  str  context  create  get  cache  files  <job-tracker>  e  action  xml  action  lib  path  ae  test  adding  a  directory  < / value>< / property>  actionlibs  parse  xml  < / job-tracker>  get  file  system  test  adding  a  directory  and  a  file   ( comma  separated )      <name-node>  < / name-node>  setup  launcher  conf  set  lib  files  archives  contains  mkdirs  arrays  job  conf  cache  files  jar3 . jar  <java>  get  app  path  jar3  path  test  action  libs  path  create  base  hadoop  conf  action  xml  distributed  cache  <job-xml>job . xml< / job-xml>  assert  true  <property><name>oozie . launcher . oozie . libpath< / name><value>  <job-xml>job2 . xml< / job-xml>  jar2  path  close  get  name  node  uri  jar1  path  < / java>  xml  utils  jar1 . jar  <main-class>  main-  class< / main-class>  <configuration>  test  adding  a  file  to  string  jar2 . jar  get  fs  test  case  dir  getjobtrackeruri  < / configuration>  createcontext  cachefilesstr  context  create  getcachefiles  <job-tracker>  eactionxml  actionlibpath  ae   test adding a directory  < / value>< / property>  actionlibs  parsexml  < / job-tracker>  getfilesystem   test adding a directory and a file  ( comma separated )      <name-node>  < / name-node>  setuplauncherconf  setlibfilesarchives  contains  mkdirs  arrays  jobconf  cachefiles  jar3 . jar  <java>  getapppath  jar3path  testactionlibspath  createbasehadoopconf  actionxml  distributedcache  <job-xml>job . xml< / job-xml>  asserttrue  <property><name>oozie . launcher . oozie . libpath< / name><value>  <job-xml>job2 . xml< / job-xml>  jar2path  close  getnamenodeuri  jar1path  < / java>  xmlutils  jar1 . jar  <main-class>main-class< / main-class>  <configuration>   test adding a file  tostring  jar2 . jar  getfstestcasedir
__label__nflaky get  restart  count  conditions  timeout  sleep  wait  or  timeout  interrupt  wait  until  restart  count  is  1  verify  get  accumulated  trigger  count  restart  timeout  start  thread  needs  to  be  waiting  after  start  assert  equals  set  settle  down  millis  trigger  restart  trigger  thread  thread  needs  to  be  waiting  after  restart  wait  until  accumulated  trigger  is  set  back  to  zero  should  have  only  called  this  exactly  once  machine  long  settling  down  period  to  ensure  it \  ' ll  happen  mock  is  waiting  call  restart  quickly  in  a  row  is  satisfied  at  least  millis  shutdown  settle  time  millis  getrestartcount  conditions  timeout  sleep  waitortimeout  interrupt   wait until restart count is 1  verify  getaccumulatedtriggercount  restart  timeout  start   thread needs to be waiting after start  assertequals  setsettledownmillis  trigger  restarttrigger  thread   thread needs to be waiting after restart   wait until accumulated trigger is set back to zero   should have only called this exactly once  machine   long settling down period to ensure it \  ' ll happen  mock  iswaiting   call restart quickly in a row  issatisfied  atleast  millis  shutdown  settletimemillis
__label__flaky get  job  tracker  uri  conf  fs  create  job  conf  get  test  group  assert  not  null  get  test  accessor  has  create  file  system  group  get  name  node  uri  mapred . job . tracker  invalid  user  set  valid  user  services  uri  services  fail  create  job  client  get  test  user  fs . default . name  invalid  jc  user  getjobtrackeruri  conf  fs  createjobconf  gettestgroup  assertnotnull  get  testaccessor  has  createfilesystem  group  getnamenodeuri  mapred . job . tracker   invalid user  set   valid user  services  uri  services  fail  createjobclient  gettestuser  fs . default . name  invalid  jc  user
__label__nflaky get  name  set  provider  set  protocol  set  trust  manager  factory  algorithm  provider_  sun_  jsse  assert  assert  not  null  set  secure  random  get  default  algorithm  create  get  provider  tls  ssl  context  builder  set  key  manager  factory  algorithm  load  trust  material  load  key  material  set  key  store  type  ssl  context  get  protocol  assert  equals  key  store  get  default  type  key  manager  factory  build  test  build  all  defaults  trust  manager  factory  getname  setprovider  setprotocol  settrustmanagerfactoryalgorithm  provider_sun_jsse  assert  assertnotnull  setsecurerandom  getdefaultalgorithm  create  getprovider  tls  sslcontextbuilder  setkeymanagerfactoryalgorithm  loadtrustmaterial  loadkeymaterial  setkeystoretype  sslcontext  getprotocol  assertequals  keystore  getdefaulttype  keymanagerfactory  build  testbuildalldefaults  trustmanagerfactory
__label__flaky map-reduce  yarn . resourcemanager . address  execute  while  job  tracker  is  shutdown  add  record  to  wf  action  table  make  the  max  number  of  retries  lower  so  the  test  won \  ' t  take  as  long  conf  workflow  instance  it  should  now  continue  and  finish  with  succeeded  get  job  context  wait  for  init  get  status  str  job0  job2  launcher  job2  job1  running  parse  xml  destroy  mapper  id  test  action  check  transient  during  mr  action  execute  job  id  1  max  retries  disable  action  checker  service  so  it  doesn \  ' t  interfere  by  triggering  any  extra  action  check  x  commands  workflow  action  suspended  succeeded  action  id  evaluate  job  id  set  classes  to  be  excluded  now   shutdown  the  job  tracker  to  pretend  it  has  gone  down  during  the  map-reduce  job  launcher  id  start_  manual  assert  false  action  executor  user . name  get  id  original  mapper  id  get  external  id  create  base  hadoop  conf  has  id  swap  action1a  create  job  conf  action1b  sleep  is  successful  add  record  to  wf  job  table  assert  true  launcher  mapper  get  retries  get  when  using  yarn   skip  this  test  because  it  relies  on  shutting  down  the  job  tracker   which  isn \  ' t  used  in  yarn  workflow  job  launcher  job  get  conf  xml  utils  for  name  wf  action  get  cmd  oozie . action . retries . max  org . apache . oozie . service .   action  checker  service  assert  equals  services  mr  job  get  external  status  integer  call  original  launcher  id  services  create  job  client  set  system  property  equals  to  string  action0  job  client  action1  action2  jpa  service  user  action3  action4  is  complete  action5  map-reduce  yarn . resourcemanager . address  executewhilejobtrackerisshutdown  addrecordtowfactiontable   make the max number of retries lower so the test won \  ' t take as long  conf  workflowinstance   it should now continue and finish with succeeded  getjob  context  waitfor  init  getstatusstr  job0  job2  launcherjob2  job1  running  parsexml  destroy  mapperid  testactionchecktransientduringmraction  execute  jobid  1  maxretries   disable actioncheckerservice so it doesn \  ' t interfere by triggering any extra actioncheckxcommands  workflowaction  suspended  succeeded  actionid  evaluate  jobid  setclassestobeexcluded   now  shutdown the job tracker to pretend it has gone down during the map-reduce job  launcherid  start_manual  assertfalse  actionexecutor  user . name  getid  originalmapperid  getexternalid  createbasehadoopconf  hasidswap  action1a  createjobconf  action1b  sleep  issuccessful  addrecordtowfjobtable  asserttrue  launchermapper  getretries  get   when using yarn  skip this test because it relies on shutting down the job tracker  which isn \  ' t used in yarn  workflowjob  launcherjob  getconf  xmlutils  forname  wfactiongetcmd  oozie . action . retries . max  org . apache . oozie . service . actioncheckerservice  assertequals  services  mrjob  getexternalstatus  integer  call  originallauncherid  services  createjobclient  setsystemproperty  equals  tostring  action0  jobclient  action1  action2  jpaservice  user  action3  action4  iscomplete  action5
__label__nflaky get  value  assert  deadline  1969-12-31  t17:00:01 . 000  mst  assert  equals  parse  deadline  test  parse  getvalue  assert  deadline  1969-12-31t17:00:01 . 000 mst  assertequals  parse  deadline  testparse
__label__flaky check  coord  action  test  action  input  check  get  time  tz   / 2009 / 01 / 29 /   get  id  -  test  coord  action  input  check  x  command-  c  date  utils   / 2009 / 01 / 15 /   parse  date  oozie  tz  2009-02-02  t23:59  add  record  to  coord  job  table  call  job  id  @1  2009-02-01  t23:59  get  test  case  dir  create  dir  0000000-  start  time  end  time  job  checkcoordaction  testactioninputcheck  gettime  tz   / 2009 / 01 / 29 /   getid  -testcoordactioninputcheckxcommand-c  dateutils   / 2009 / 01 / 15 /   parsedateoozietz  2009-02-02t23:59  addrecordtocoordjobtable  call  jobid  @1  2009-02-01t23:59  gettestcasedir  createdir  0000000-  starttime  endtime  job
__label__nflaky prim  short  validation  should  work  has  field  violation  then  return  invoke  when  param1  assert  true  context  create  verify  prim  short  param  mock  controller  validation  blah  get  parameter  primshortvalidationshouldwork  hasfieldviolation  thenreturn  invoke  when  param1  asserttrue  context  create  verify  primshortparam  mockcontroller  validation  blah  getparameter
__label__flaky test  permissions  on  files  that  do  not  exist  cluster  data  group_  names  conf  fin  set  owner  wait  active  child_  file1  bar  child_  file2   / foo / bar  file  system  create  write  illegal  file  creation  info  user  group  information  create  user  for  testing  dfs  config  keys  read  child_  dir2  log  this  user  does  not  throw  an  exception .   child_  dir1   /   following  dir / file  creations  are  legal  num  data  nodes  mkdirs  good:  got  can  mkdirs  following  read  is  legal  shutdown  nnfs  illegal  mkdir  assert  false  foo  can  rename  root_  path  test  illegal  file / dir  creation  out  next  bytes  file_  len  assert  true  get  777  test  file  permision  set  permission  close  data  in  dfs  test  util  illegal  file  open  user  group  info  e  bytes  read  assert  equals  user_  name  can  create  userfs  build  get  file  system  as  700  rename_  path  can  open  exists  ran  open  set  boolean   test permissions on files that do not exist  cluster  data  group_names  conf  fin  setowner  waitactive  child_file1  bar  child_file2   / foo / bar  filesystem  create  write   illegal file creation  info  usergroupinformation  createuserfortesting  dfsconfigkeys  read  child_dir2  log   this user does not throw an exception .   child_dir1   /    following dir / file creations are legal  numdatanodes  mkdirs  good: got   canmkdirs   following read is legal  shutdown  nnfs   illegal mkdir  assertfalse  foo  canrename  root_path   test illegal file / dir creation  out  nextbytes  file_len  asserttrue  get  777  testfilepermision  setpermission  close  datain  dfstestutil   illegal file open  usergroupinfo  e  bytesread  assertequals  user_name  cancreate  userfs  build  getfilesystemas  700  rename_path  canopen  exists  ran  open  setboolean
__label__nflaky input_  buffer_  len  read  rw  f  halfway  assert  equals  delete  byte  buffer  seek  output  input  buf  io  utils  rewind  get  channel  raf  exists  test  write  fully  fc  wrap  close  write  fully  test_  file_  name  input_buffer_len  read  rw  f  halfway  assertequals  delete  bytebuffer  seek  output  input  buf  ioutils  rewind  getchannel  raf  exists  testwritefully  fc  wrap  close  writefully  test_file_name
__label__flaky unexpected  exception  add  node  def  j2  seven  f2  three  two  as  list  invoke  fork  join  four  dummy  conf  end  five  six  print  stack  trace  e  f  one  j  k  kill  fail  f-> ( 2 3 )   2->f2  3->j  f2-> ( 4 5 6 )    ( 4 5 6 ) ->j2  j2->7  7->j  parser  test  wf  <worklfow-app / >  test  nested  fork  join  arrays  unexpected exception  addnode  def  j2  seven  f2  three  two  aslist  invokeforkjoin  four  dummyconf  end  five  six  printstacktrace  e  f  one  j  k  kill  fail         f-> ( 2 3 )        2->f2       3->j       f2-> ( 4 5 6 )         ( 4 5 6 ) ->j2       j2->7       7->j        parser  testwf  <worklfow-app / >  testnestedforkjoin  arrays
__label__nflaky process  default  processor  interpretation  context  assert  equals  check  error  tag  name  assert  true  set  value  context  end  no  name  v1  property  action  get  status  manager  value  begin  get  count  atts  top  model  process  defaultprocessor  interpretationcontext  assertequals  checkerror  tagname  asserttrue  setvalue  context  end  noname  v1  propertyaction  getstatusmanager  value  begin  getcount  atts  topmodel
__label__flaky milliseconds  write  lock  ensure  time  for  operations  to  start  blocking  expected  channel  store  executors  futures  new  cached  thread  pool  get  cause  sleep  uninterruptibly  write  read  fail  queue  all  blocking  operations  assert  true  executor  future  get  lock  ensure  all  operations  on  the  channel  will  block  uninterruptibles  close  test  asynchronous  close  milliseconds  writelock   ensure time for operations to start blocking  expected  channel  store  executors  futures  newcachedthreadpool  getcause  sleepuninterruptibly  write  read  fail  queueallblockingoperations  asserttrue  executor  future  get  lock   ensure all operations on the channel will block  uninterruptibles  close  testasynchronousclose
__label__nflaky encode  0  0  1  0  0  1  1  1  0  0  0  1  0  1  0  0  1  0  1  0  0  test  encode  shiftjis  numeric  0  0  0  0  0  0  0  0  1  1  1  1  1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  1  1  0  1  1  1  1  0  0  1  0  1  0  mode:  numeric  mask  pattern:  2  0  1  1  0  1  1  1  1  0  1  1  1  0  1  0  0  1  1  0  1  1  <<  >>  0  0  0  0  0  0  0  0  1  1  0  1  1  1  1  0  0  1  0  0  0  put  1  0  0  0  0  0  1  0  1  1  0  0  1  0  1  0  0  0  0  0  1  1  1  1  1  1  1  1  0  0  1  1  0  1  0  1  1  1  1  1  1  1  1  0  1  1  1  0  1  0  1  1  1  0  1  0  0  1  0  0  1  0  0  1  1  1  1  1  1  1  0  1  1  0  1  0  1  0  0  1  1  1  0  0  encode  hint  type  0123  qr  code  1  0  1  1  1  0  1  0  1  0  0  0  0  0  1  0  1  1  1  0  1  encoder  1  0  1  1  1  1  1  0  0  1  1  0  1  0  1  1  1  1  1  0  0  1  0  0  0  0  0  1  0  0  0  1  0  0  0  0  1  1  0  1  1  0  1  0  1  1  1  0  1  0  1  1  0  1  0  1  0  0  1  1  1  0  0  shift_  jis  1  0  1  1  1  0  1  0  1  1  0  1  1  0  1  0  1  1  1  0  1  matrix:  hints  expected  ec  level:  m  assert  equals  1  0  1  1  1  0  1  0  1  0  1  0  1  0  0  1  0  0  1  0  0  version:  1  1  0  0  0  0  0  1  0  0  1  0  0  1  0  1  0  0  0  0  0  1  1  1  1  1  1  1  1  0  0  0  1  0  1  0  1  1  0  0  0  0  0  1  1  0  0  0  1  0  0  1  0  1  0  1  0  0  1  0  0  1  0  0  to  string  1  1  1  1  1  1  1  0  1  0  1  0  1  0  1  1  1  1  1  1  1  error  correction  level  1  0  1  1  1  0  1  0  1  0  1  1  1  0  1  0  1  1  1  0  1  1  0  1  1  0  1  0  1  0  0  1  0  0  0  0  1  1  0  1  0  0  encode   0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 1 0 0    testencodeshiftjisnumeric   0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0     1 0 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0     mode: numeric     maskpattern: 2     0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1    <<    >>     0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0    put   1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1     1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1     1 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0     1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0    encodehinttype  0123  qrcode   1 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 1    encoder   1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0     1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0     1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0    shift_jis   1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1     matrix:    hints  expected   eclevel: m    assertequals   1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0     version: 1     1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1     1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0     1 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0    tostring   1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1    errorcorrectionlevel   1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1     1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0
__label__flaky <name>a< / name>  expected  b  validate  and  parse  < / prepare>  < / property>  replace  all  <configuration>  <arg> / tmp2 / data . txt< / arg>  <job-tracker>blah< / job-tracker>  < / configuration>  <mkdir  path= \ "" / tmp2 \ ""   / >  <distcp  xmlns= \ ""uri:oozie:distcp-action:0 . 1 \ "">  app  b  <value>  a2< / value>  test  parser  global  extension  actions  local  already  exists  get  conf  <prepare>  <name>b< / name>  assert  equals  wf-schema-valid-global-ext . xml  <value>  b< / value>  <arg> / tmp / data . txt< / arg>  < / distcp>  io  utils  parser  <delete  path= \ "" / tmp2 \ ""   / >  get  resource  as  reader  <property>  get  node  <name-node>meh< / name-node>          <name>a< / name>    expectedb  validateandparse    < / prepare>        < / property>    replaceall    <configuration>      <arg> / tmp2 / data . txt< / arg>      <job-tracker>blah< / job-tracker>      < / configuration>        <mkdir path= \ "" / tmp2 \ ""  / >    <distcp xmlns= \ ""uri:oozie:distcp-action:0 . 1 \ "">    app     b        <value>a2< / value>    testparserglobalextensionactionslocalalreadyexists  getconf    <prepare>          <name>b< / name>    assertequals  wf-schema-valid-global-ext . xml        <value>b< / value>      <arg> / tmp / data . txt< / arg>    < / distcp>  ioutils  parser      <delete path= \ "" / tmp2 \ ""  / >    getresourceasreader      <property>    getnode    <name-node>meh< / name-node>
__label__nflaky get  boolean  with  default  then  return  ninja  constant  invoke  when  param1  long  param  context  create  ninja  properties  mock  controller  get  parameter  long  param  empty  strict  mode  works  getbooleanwithdefault  thenreturn  ninjaconstant  invoke  when  param1  longparam  context  create  ninjaproperties  mockcontroller  getparameter  longparamemptystrictmodeworks
__label__flaky _test  transient  test  end  transient  assert  true  end . transient  end  workflow  action  bean  _testtransient  testendtransient  asserttrue  end . transient  end  workflowactionbean
__label__nflaky get  secret  key  get  current  user  set  check  specific  provider  credentials  credential  provider  factory  get  credentials  conf  our  url  : /  /  /   assert  array  equals  user  provider  pass2  see  if  the  credentials  are  actually  in  the  ugi  test  user  provider  user  group  information  getsecretkey  getcurrentuser  set  checkspecificprovider  credentials  credentialproviderfactory  getcredentials  conf  oururl  : /  /  /   assertarrayequals  userprovider  pass2   see if the credentials are actually in the ugi  testuserprovider  usergroupinformation
__label__flaky cluster  blocks  scanned  get  data  nodes  log  dn  waiting  for  all  blocks  to  be  scanned  for  bpid=  wait  active  thread  sleep  restart  data  node  bpids  get  blocks  scanned  in  last  run  get  ;  scanned  so  far=  set  up  test  block  scanner  after  restart  shutdown  info  cluster  blocksscanned  getdatanodes  log  dn  waiting for all blocks to be scanned for bpid=  waitactive  thread  sleep  restartdatanode  bpids  getblocksscannedinlastrun  get  ; scanned so far=  setup  testblockscannerafterrestart  shutdown  info
__label__nflaky get  bytes  transferred  read  more  stuff;  and  a  lot  more  stuff  dst  standard  charsets  codec  test  utils  assert  false  channel  clear  bytes  read  assert  equals  decoder  convert  byte  buffer  stuff;  assert  allocate  inbuf  assert  true  metrics  more  stuff  test  coding  beyond  content  limit  is  completed  getbytestransferred  read  more stuff; and a lot more stuff  dst  standardcharsets  codectestutils  assertfalse  channel  clear  bytesread  assertequals  decoder  convert  bytebuffer  stuff;  assert  allocate  inbuf  asserttrue  metrics  more stuff  testcodingbeyondcontentlimit  iscompleted
__label__flaky <value>  a< / value>  <name>a< / name>  <job-tracker>foo< / job-tracker>  expected  d  validate  and  parse  < / prepare>  < / property>  replace  all  <archive> / tmp< / archive>  <configuration>  < / configuration>  wf-schema-valid-global-job  xml . xml  app  <file> / tmp< / file>  <mkdir  path= \ "" / tmp \ ""   / >  d  get  conf  <reducer> / mywc . sh< / reducer>  <prepare>  <mapper> / mycat . sh< / mapper>  <name>b< / name>  assert  equals  <job-xml> / spam2< / job-xml>  <job-xml> / spam1< / job-xml>  <value>  b< / value>  < / map-reduce>  io  utils  parser  < / streaming>  test  parser  global  job  xml  <streaming>  get  resource  as  reader  <property>  get  node  <delete  path= \ "" / tmp \ ""   / >  <map-reduce  xmlns= \ ""uri:oozie:workflow:0 . 4 \ "">  <job-xml> / tmp< / job-xml>  <name-node>bar< / name-node>          <value>a< / value>          <name>a< / name>      <job-tracker>foo< / job-tracker>    expectedd  validateandparse    < / prepare>        < / property>    replaceall    <archive> / tmp< / archive>      <configuration>      < / configuration>    wf-schema-valid-global-jobxml . xml  app       <file> / tmp< / file>        <mkdir path= \ "" / tmp \ ""  / >    d  getconf      <reducer> / mywc . sh< / reducer>      <prepare>        <mapper> / mycat . sh< / mapper>          <name>b< / name>    assertequals    <job-xml> / spam2< / job-xml>      <job-xml> / spam1< / job-xml>          <value>b< / value>    < / map-reduce>  ioutils  parser    < / streaming>    testparserglobaljobxml    <streaming>    getresourceasreader      <property>    getnode      <delete path= \ "" / tmp \ ""  / >    <map-reduce xmlns= \ ""uri:oozie:workflow:0 . 4 \ "">      <job-xml> / tmp< / job-xml>      <name-node>bar< / name-node>
__label__nflaky null_  str  test  unescape  string  escaped_  str_  with_  comma  un  escape  string  assert  equals  str_  with_  escape  str_  with_  both2  should  throw  illegal  argument  exception  fail  str_  wo_  special_  chars  str_  with_  comma  escaped_  str_  with_  both2  string  utils  empty_  str  escaped_  str_  with_  escape  null_str  testunescapestring  escaped_str_with_comma  unescapestring  assertequals  str_with_escape  str_with_both2  should throw illegalargumentexception  fail  str_wo_special_chars  str_with_comma  escaped_str_with_both2  stringutils  empty_str  escaped_str_with_escape
__label__flaky  / newfile1  get  name  <fs / >  fs006  fs007  source  dest  fs  create  context  delete  assert  true  get  error  code   / newfile  context  get  path  complex  target  : /  / foo /   test  move  move  get  scheme  ae  to  uri  assert  equals  get  file  system  target   /   fail  ex   / a / b  mkdirs  dest  path  exists  create  new  file  get  fs  test  case  dir   / newfile1  getname  <fs / >  fs006  fs007  source  dest  fs  createcontext  delete  asserttrue  geterrorcode   / newfile  context  getpath  complextarget  : /  / foo /   testmove  move  getscheme  ae  touri  assertequals  getfilesystem  target   /   fail  ex   / a / b  mkdirs  destpath  exists  createnewfile  getfstestcasedir
__label__nflaky no  nested  cause  in  assertion  expected  contains  e  test  assert  exception  contains  wrong  text   ( actual )   assert  exception  contains  to  string  e_  unexpected_  exception  get  cause  no nested cause in assertion  expected  contains  e  testassertexceptioncontainswrongtext   ( actual )   assertexceptioncontains  tostring  e_unexpected_exception  getcause
__label__flaky set  name  get  property  get  name  x  test  case  get  properties  system  testcase  tear  down  test  base  dir  testing  assert  true  set  property  get  test  case  dir  set  up  test  x  test  case  starts  with  setname  getproperty  getname  xtestcase  getproperties  system  testcase  teardown  testbasedir  testing  asserttrue  setproperty  gettestcasedir  setup  testxtestcase  startswith
__label__nflaky chroot  fs  test  acl  methods  path  translation  mockfs: /  / foo / a / b  remove  default  acl  remove  acl  conf  set  acl  uri  get  raw  file  system  raw  path  empty  list  fs . mockfs . impl   / c  chroot  uri   / a / b / c  create  verify  collections  remove  acl  entries  get  acl  status  set  class  entries  chroot  path  modify  acl  entries  mock  fs  chrootfs  testaclmethodspathtranslation  mockfs: /  / foo / a / b  removedefaultacl  removeacl  conf  setacl  uri  getrawfilesystem  rawpath  emptylist  fs . mockfs . impl   / c  chrooturi   / a / b / c  create  verify  collections  removeaclentries  getaclstatus  setclass  entries  chrootpath  modifyaclentries  mockfs
__label__flaky fail  ex  ae  get  error  code  testvalidate  same  nn  fs007  assert  equals  validate  same  nn  hdfs: /  / x / foo  viefs: /  / x / bla  hdfs: /  / y / bla  hdfs: /  / x / bla  fail  ex  ae  geterrorcode  testvalidatesamenn  fs007  assertequals  validatesamenn  hdfs: /  / x / foo  viefs: /  / x / bla  hdfs: /  / y / bla  hdfs: /  / x / bla
__label__nflaky 1  1  1  1  1  1  1  0  0  1  1  1  1  1  1  1  test  embed  basic  patterns2  matrix  util  get  version  for  number  0  0  0  0  0  0  0  0  1  1  0  0  0  1  matrix  1  1  1  1  1  1  1  0  1  0  1  0  1  1  0  0  0  0  0  1  0  version  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  clear  matrix  1  1  1  1  1  1  1  0  0  1  0  0  0  0  0  1  0  1  0  0  0  1  1  1  1  1  1  1  1  0  1  0  1  0  1  0  1  0  1  0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  1  1  1  0  1  0  0  1  0  1  1  1  0  1  1  0  1  1  1  0  1  0  1  1  1  1  1  expected  assert  equals  embed  basic  patterns  1  1  0  1  1  1  0  1  0  bottom  corner .   to  string  1  0  0  0  0  0  1  0  0  1  0  0  0  0  0  1   1 1 1 1 1 1 1 0                   0 1 1 1 1 1 1 1    testembedbasicpatterns2  matrixutil  getversionfornumber   0 0 0 0 0 0 0 0 1               1 0 0 0 1            matrix   1 1 1 1 1 1 1 0                 1 0 1 0 1             1 0 0 0 0 0 1 0                                      version   0 0 0 0 0 0 0 0                   0 0 0 0 0 0 0 0    clearmatrix   1 1 1 1 1 1 1 0                                                   0                                         1 0 0 0 0 0 1 0                 1 0 0 0 1             1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1                 1                   1 1 1 1 1             1 0 1 1 1 0 1 0                   0 1 0 1 1 1 0 1     1 0 1 1 1 0 1 0                 1 1 1 1 1            expected  assertequals  embedbasicpatterns               1                                         1 0 1 1 1 0 1 0                                       bottom corner .   tostring   1 0 0 0 0 0 1 0                   0 1 0 0 0 0 0 1
__label__flaky bundle  job  get  cmd  add  record  to  bundle  job  table  get  id  assert  equals  get  status  execute  call  services  assert  not  null  get  test  bundle  pause  unpause2  job  job  jpa  service  bundlejobgetcmd  addrecordtobundlejobtable  getid  assertequals  getstatus  execute  call  services  assertnotnull  get  testbundlepauseunpause2  job  job  jpaservice
__label__nflaky server  content  type  test  force  http2  listener  core  matchers  not  null  value  equal  to  connect  future  some  stuff  listen  endpoint  assert  get  duration  http  version  policy  get  head  get  get  address  https   / stuff  get  code  http  version  connect  requester  localhost  get  version  address  http  status  start  result  future1  method  assert  that  execute  target  get  time  unit  get  port  future  timeout  response1  message1  server  contenttype  testforcehttp2  listener  corematchers  notnullvalue  equalto  connectfuture  some stuff  listen  endpoint  assert  getduration  httpversionpolicy  gethead  get  getaddress  https   / stuff  getcode  httpversion  connect  requester  localhost  getversion  address  httpstatus  start  resultfuture1  method  assertthat  execute  target  gettimeunit  getport  future  timeout  response1  message1
__label__flaky cluster  renewer  user  group_  names  get  user  run  proxy  ugi  assert  ugi  get  identifier  get  user  name  proxy_  user  user  group  information  identifier  test  delegation  token  with  real  user  token  id  real_  user  assert  equals  get  real  user  get  file  system  create  remote  user  token  dfs  read  fields  do  as  get  delegation  token  create  proxy  user  for  testing  cluster  reneweruser  group_names  getuser  run  proxyugi  assert  ugi  getidentifier  getusername  proxy_user  usergroupinformation  identifier  testdelegationtokenwithrealuser  tokenid  real_user  assertequals  getrealuser  getfilesystem  createremoteuser  token  dfs  readfields  doas  getdelegationtoken  createproxyuserfortesting
__label__nflaky get  inet  address  conn  get  local  port  test  socket  bind  remote  sock  address  when  local  sock  address  get  local  address  bind  assert  assert  true  remote  address  local  port  get  local  socket  address  then  return  remote  port  get  remote  address  assert  equals  get  port  127 . 0 . 0 . 1:8888<->10 . 0 . 0 . 2:80  is  open  mockito  local  address  get  by  address  to  string  socket  inet  address  get  remote  socket  address  getinetaddress  conn  getlocalport  testsocketbind  remotesockaddress  when  localsockaddress  getlocaladdress  bind  assert  asserttrue  remoteaddress  localport  getlocalsocketaddress  thenreturn  remoteport  getremoteaddress  assertequals  getport  127 . 0 . 0 . 1:8888<->10 . 0 . 0 . 2:80  isopen  mockito  localaddress  getbyaddress  tostring  socket  inetaddress  getremotesocketaddress
__label__flaky 2009-02-02  t23:59  z  get  id  run  date  utils  workflow  instance  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  job  sleep  wf  job  add  record  to  wf  job  table  assert  not  null  get  coordinator  action  end  test  coord  action  recovery  service  for  suspended  workflow  job  recovery  runnable  wait  for  ret  running  wf  get  cmd  2009-02-01  t01:00  z  start  assert  equals  execute  add  record  to  coord  job  table  coordinator  job  services  wf  job  id  coord-action-get . xml  jpa  service  evaluate  2009-02-02t23:59z  getid  run  dateutils  workflowinstance  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordjob  sleep  wfjob  addrecordtowfjobtable  assertnotnull  get  coordinatoraction  end  testcoordactionrecoveryserviceforsuspended  workflowjob  recoveryrunnable  waitfor  ret  running  wfgetcmd  2009-02-01t01:00z  start  assertequals  execute  addrecordtocoordjobtable  coordinatorjob  services  wfjobid  coord-action-get . xml  jpaservice  evaluate
__label__nflaky cursor  get  name  test  assert  false  test=stuff  test  =   \ ""  stuff \  \  \ "" \ ""  assert  param  assert  true  get  pos  buffer  test  =  stuff  ;1234  =  stuff  test  at  end  test  nv  parse  length  assert  equals  test  =  stuff  stuff \ ""  get  value  test  =   \ ""stuff \ ""  test   12  parse  name  value  pair  test;  append  stuff  cursor        getname    test  assertfalse  test=stuff  test  =  \ ""  stuff \  \  \ "" \ ""  assert  param  asserttrue  getpos  buffer     test  =   stuff ;1234   = stuff   test  atend  testnvparse  length  assertequals     test  =   stuff     stuff \ ""  getvalue  test  =  \ ""stuff \ ""  test   12  parsenamevaluepair  test;  append  stuff
__label__flaky cluster  ns  racks  conf  dn  to  corrupt   / rack2  wait  for  replication   / rack1  *  test  that  a  block  that  is  re-replicated  because  one  of  its  replicas  *  is  found  to  be  corrupt  and  is  re-replicated  across  racks .   fs  create  file  read  block  on  data  node  restart  data  node  corrupt  replica  create  a  file  with  one  block  with  a  replication  factor  of  2  assert  true  have  been  cleaned  up  yet )  .   wait  corrupt  replicas  wait  for  the  namenode  to  notice  the  corrupt  replica  datanodes  are  spread  across  two  racks  dfs  test  util  b  mini  dfs  cluster  block  is  detected .   get  conf  file  path  assert  equals  test  corrupt  block  rereplicated  across  racks  get  file  system  first  dn  with  block  the  rack  policy  is  still  respected  corrupt  replica  replication_  factor  get  name  node  file  len   / test  file  corrupt  a  replica  of  the  block  build  block  content  num  data  nodes  read  file  get  first  block  shutdown  file  content  get  namesystem  cluster  ns  racks  conf  dntocorrupt   / rack2  waitforreplication   / rack1       * test that a block that is re-replicated because one of its replicas     * is found to be corrupt and is re-replicated across racks .        fs  createfile  readblockondatanode  restartdatanode  corrupt replica   create a file with one block with a replication factor of 2  asserttrue   have been cleaned up yet )  .   waitcorruptreplicas   wait for the namenode to notice the corrupt replica   datanodes are spread across two racks  dfstestutil  b  minidfscluster   block is detected .   getconf  filepath  assertequals  testcorruptblockrereplicatedacrossracks  getfilesystem  firstdnwithblock   the rack policy is still respected  corruptreplica  replication_factor  getnamenode  filelen   / testfile   corrupt a replica of the block  build  blockcontent  numdatanodes  readfile  getfirstblock  shutdown  filecontent  getnamesystem
__label__nflaky random  rand1  rand2  next  double  test  random  double  random  rand1  rand2  nextdouble  testrandomdouble
__label__flaky row_1  qualifier_1  value2  value1  qualifier_2  row_2  test  timerange  result  bytes  set  max  versions  test  get  assert  true  ts_2  assert  not  null  ts_1  get  timestamp  get  @  ts_1  value_1  @  ts_2  test  max  versions  value_2  set  time  range  add  column  count  assert  equals  test  timestamp  kv  list  get  value  assert  null  set  time  stamp  column_2  column_1  add  family  get  family  equals  column_3  remote  table  row_1  qualifier_1  value2  value1  qualifier_2  row_2   test timerange  result  bytes  setmaxversions  testget  asserttrue  ts_2  assertnotnull  ts_1  gettimestamp  get   @ts_1  value_1   @ts_2   test maxversions  value_2  settimerange  addcolumn  count  assertequals   test timestamp  kv  list  getvalue  assertnull  settimestamp  column_2  column_1  addfamily  getfamily  equals  column_3  remotetable
__label__nflaky name:  value  get  name  write  object  in  stream  raw  outbuffer  assert  equals  test  serialization  out  stream  in  buffer  read  object  get  value  buf  assert  orig  to  byte  array  clone  close  append  name: value  getname  writeobject  instream  raw  outbuffer  assertequals  testserialization  outstream  inbuffer  readobject  getvalue  buf  assert  orig  tobytearray  clone  close  append
__label__flaky get  job  tracker  uri  output1  get  name  < / configuration>  _test  submit  <property><name>mapred . reducer . class< / name><value>  fs  action  xml  <property><name>mapred . mapper . class< / name><value>  <map-reduce>  create  write  close  <job-tracker>  get  name  node  uri  output  dir  < / value>< / property>  <property><name>mapred . input . dir< / name><value>  ow  < / job-tracker>  <property><name>mapred . output . dir< / name><value>  dummy  get  file  system  <configuration>  input  dir  <name-node>  < / name-node>  < / map-reduce>  input  test  map  reduce  w  data . txt  get  fs  test  case  dir  getjobtrackeruri  output1  getname  < / configuration>  _testsubmit  <property><name>mapred . reducer . class< / name><value>  fs  actionxml  <property><name>mapred . mapper . class< / name><value>  <map-reduce>  create  write  close  <job-tracker>  getnamenodeuri  outputdir  < / value>< / property>  <property><name>mapred . input . dir< / name><value>  ow  < / job-tracker>  <property><name>mapred . output . dir< / name><value>  dummy    getfilesystem  <configuration>  inputdir  <name-node>  < / name-node>  < / map-reduce>  input  testmapreduce  w  data . txt  getfstestcasedir
__label__nflaky http  headers  process  test  response  content  entity  unknown  content  length  http  status  get  first  header  h1  chunked  interceptor  assert  equals  h2  get  entity  set  entity  get  value  assert  assert  null  empty  input  stream  response  assert  not  null  context  ok  httpheaders  process  testresponsecontententityunknowncontentlength  httpstatus  getfirstheader  h1  chunked  interceptor  assertequals  h2  getentity  setentity  getvalue  assert  assertnull  emptyinputstream  response  assertnotnull  context  ok
__label__flaky fail  io  utils  get  resource  as  string  abcde  test  get  resource  as  string  assert  equals  invalid-resource . txt  test-ioutils . txt  fail  ioutils  getresourceasstring  abcde  testgetresourceasstring  assertequals  invalid-resource . txt  test-ioutils . txt
__label__nflaky test8   . zip  no_  restart  default  test   \ %d{yyyy-  mm-dd   aux} / test8  file_  option_  set  with  missing  target  dir  with  zip  compression  test8   . zip  no_restart  defaulttest   \ %d{yyyy-mm-dd  aux} / test8  file_option_set  withmissingtargetdirwithzipcompression
__label__flaky *  add  2  coordinator  actions  with  status  as  suspended   1  coordinator  action  with  status  failed  and  1  *  with  killed .   then  check  for  expected  number  of  actions  retrieved  action  num  coordinator  job  job  id  coord-action-get . xml  test  coord  actions  suspended  for  size  coordinator  action  get  id  _test  coord  actions  suspended  size  job  add  record  to  coord  action  table  add  record  to  coord  job  table         * add 2 coordinator actions with status as suspended  1 coordinator action with status failed and 1       * with killed .  then check for expected number of actions retrieved         actionnum  coordinatorjob  jobid  coord-action-get . xml  testcoordactionssuspendedforsize  coordinatoraction  getid  _testcoordactionssuspendedsize  job  addrecordtocoordactiontable  addrecordtocoordjobtable
__label__nflaky name  value  pair  test  null  values  equals  assert  name  value  pair2  hash  code  name  assert  equals  namevaluepair  testnullvaluesequals  assert  namevaluepair2  hashcode  name  assertequals
__label__flaky get  job  tracker  uri  get  name  <java>  assert  false  get  status  create  context  action  xml  is  successful  assert  true  context  wait  for  <job-tracker>  killed  is  completed  get  name  node  uri  < / java>  ae  < / main-class>  < / job-tracker>  running  job  get  action  assert  equals  kill  get  external  status  <name-node>  <main-class>  < / name-node>  test  kill  workflow  action  submit  action  evaluate  is  complete  getjobtrackeruri  getname  <java>  assertfalse  getstatus  createcontext  actionxml  issuccessful  asserttrue  context  waitfor  <job-tracker>  killed  iscompleted  getnamenodeuri  < / java>  ae  < / main-class>  < / job-tracker>  runningjob  getaction  assertequals  kill  getexternalstatus  <name-node>  <main-class>  < / name-node>  testkill  workflowaction  submitaction  evaluate  iscomplete
__label__nflaky setting  total  failover  attempts  to   .   p1  p2  test  client  retries  non  idempotent  op  with  io  exception  fails  immediately  p3  get  kms  url  conf  when  times  assert  true  verify  then  throw  test  kp  e  any  string  then  return  get  providers  key  name  create  key  eq  any  set  int  common  configuration  keys  public  fail  mockito  mock  should  fail  since  all  providers  threw  an  io  exception   setting total failover attempts to  .   p1  p2  testclientretriesnonidempotentopwithioexceptionfailsimmediately  p3  getkmsurl  conf  when  times  asserttrue  verify  thenthrow  test  kp  e  anystring  thenreturn  getproviders  keyname  createkey  eq  any  setint  commonconfigurationkeyspublic  fail  mockito  mock  should fail since all providers threw an ioexception
__label__flaky cee  bee  unparseable   \ ""frequency \ ""  value:   \ ""unit \ ""  specified   but   \ ""frequency \ ""  is  not:  empty  string:  null  argument:  parse  filter  no  eq  sign  in  token:  incorrect   \ ""status \ ""  key  value:  winniethepooh  get  error  code  assert  not  null  map  test  parse  filter  negative  ce  fre  quency=foo  unparseable   \ ""unit \ ""  value:  kk=vv=zz  status=foo  foo=moo  assert  equals  fail  unit=minutes  incorrect  k=v:  size  uni  t=foo  unknown  key  in  key=value  pair:  coordinator  engine  exception  expected .   error  code    cee  bee   unparseable  \ ""frequency \ "" value:    \ ""unit \ "" specified  but  \ ""frequency \ "" is not:   empty string:   null argument:  parsefilter   no eq sign in token:   incorrect  \ ""status \ "" key value:  winniethepooh  geterrorcode  assertnotnull  map  testparsefilternegative  ce  frequency=foo   unparseable  \ ""unit \ "" value:  kk=vv=zz  status=foo  foo=moo  assertequals  fail  unit=minutes   incorrect k=v:  size  unit=foo   unknown key in key=value pair:  coordinatorengineexception expected .   errorcode
__label__nflaky store  password  get  resource  to  char  array  aliases  get  name  server  socket  new  single  thread  executor  executors  server  ssl  context  client2  get  server  socket  factory  assert  bind  assert  not  null  nopassword  client  principal  create  time  unit  ssl  context  builder   / test-client . p12  write  get  peer  principal  test  ssl  handshake  client  authenticated  private  key  strategy  localhost  start  handshake  read  local  port  load  trust  material  load  key  material  resource2  input  stream  set  so  timeout  get  input  stream   / test-server . p12  resource1  accept  contains  create  socket  client  ssl  context  timeout  set  need  client  auth  get  local  port  submit  private  key  strategy  session  client  socket  flush  key  password  get  choose  alias  output  stream  key  set  close  connect  cn=  test  client  2   ou=  http  components  project   o=  apache  software  foundation  assert  equals  call  get  socket  factory  build  future  to  milliseconds  int  bound  get  output  stream  socket  get  session  create  server  socket  storepassword  getresource  tochararray  aliases  getname  serversocket  newsinglethreadexecutor  executors  serversslcontext  client2  getserversocketfactory  assert  bind  assertnotnull  nopassword  clientprincipal  create  timeunit  sslcontextbuilder   / test-client . p12  write  getpeerprincipal  testsslhandshakeclientauthenticatedprivatekeystrategy  localhost  starthandshake  read  localport  loadtrustmaterial  loadkeymaterial  resource2  inputstream  setsotimeout  getinputstream   / test-server . p12  resource1  accept  contains  createsocket  clientsslcontext  timeout  setneedclientauth  getlocalport  submit  privatekeystrategy  session  clientsocket  flush  keypassword  get  choosealias  outputstream  keyset  close  connect  cn=test client 2 ou=httpcomponents project o=apache software foundation  assertequals  call  getsocketfactory  build  future  tomillisecondsintbound  getoutputstream  socket  getsession  createserversocket
__label__flaky exec_  order  callable2  callable3  callable1  queue  uniqueness  with  same  key  in  one  composite  queue  serial  queueservice  as  list  services  assert  true  get  test  queue  uniqueness  with  same  key  in  one  composite  arrays  evaluate  wait  for  exec_order  callable2  callable3  callable1  queueuniquenesswithsamekeyinonecomposite  queueserial  queueservice  aslist  services  asserttrue  get  testqueueuniquenesswithsamekeyinonecomposite  arrays  evaluate  waitfor
__label__nflaky 00  reader  make  an  index  entry  for  every  third  insertion .   first_  key  conf  less  than  first  key  in  the  mapfile   that  the  first  key  is  returned .   file  system  90  get  closest  that  falls  before  the  passed  key:  50  the  first  key  in  the  file   we  should  get  null  50  test_  dir  test  get  closest . mapfile  55  assert  that  closest  after  55  is  60  99  log  assert  that  null  is  returned  if  key  is  >  last  entry  in  mapfile .   deprecation  twenty  get  index  interval  test  get  closest  qualified  dir  name  test  get  closest  when  we  pass  explicit  key  i  str  60  now  do  get  closest  on  created  mapfile .   20  dir  name  write  a  mapfile  of  simple  data:  keys  are  add  entries  up  to  100  in  intervals  of  ten .   map  file  fs  cleanup  with  logger  substring  get  closest  if  we  were  looking  for  the  key  before   we  should  get  the  last  key  close  value  key  assert  that  the  index  interval  is  1  length  assert  equals  integer  parse  int  io  utils  set  index  interval  assert  null  t  get  local  make  qualified  to  string  writer  append  closest  00  reader   make an index entry for every third insertion .   first_key  conf   less than first key in the mapfile  that the first key is returned .   filesystem  90   get closest that falls before the passed key: 50   the first key in the file  we should get null  50  test_dir  testgetclosest . mapfile  55   assert that closest after 55 is 60  99  log   assert that null is returned if key is > last entry in mapfile .   deprecation  twenty  getindexinterval  testgetclosest  qualifieddirname   test get closest when we pass explicit key  istr  60   now do getclosest on created mapfile .   20  dirname   write a mapfile of simple data: keys are   add entries up to 100 in intervals of ten .   mapfile  fs  cleanupwithlogger  substring  getclosest   if we were looking for the key before  we should get the last key  close  value  key   assert that the index interval is 1  length  assertequals  integer  parseint  ioutils  setindexinterval  assertnull  t  getlocal  makequalified  tostring  writer  append  closest
__label__flaky <execution>  lifo< / execution>  < / controls>  <datasets>  submit  job  get  missing  dependencies   / workflows / ${  year} / ${  month} / ${  day}< / uri-template>  conf  <data-in  name= \ ""  a \ ""  dataset= \ ""local_a \ "">  <instance>${coord:current ( 0 ) }< / instance>  < / data-in>  get  actions  < / input-events>  get  status  app  path  system  write  to  file  app  xml  action  status  <dataset  name= \ ""local_a \ ""  frequency= \ ""${coord:days ( 1 ) } \ ""  initial-instance= \ ""2009-02-01  t01:00  z \ ""  assert  true  file: /  /   get  test  case  dir  unit_  testing  get  coordinator  action   .  .   missing  deps=  action  missing  deps  <done-flag>consume_me< / done-flag>  < / dataset>  xmlns= \ ""uri:oozie:coordinator:0 . 1 \ "">  <controls>  <timeout>10< / timeout>  <concurrency>2< / concurrency>  wait  for  timezone= \ ""  utc \ "">  <uri-template>file: /  /   get  coord  job  coordinator . xml  ce  set  test  custom  done  flag  <coordinator-app  name= \ ""  name \ ""  frequency= \ ""${coord:days ( 1 ) } \ ""  start= \ ""2009-02-01  t01:00  z \ ""  end= \ ""2009-02-01  t02:00  z \ ""  timezone= \ ""  utc \ ""  <configuration>  <property>  <name>input  a< / name>  <value>${coord:data  in (  \  '   a \  '  ) }< / value>  < / property>  assert  equals  <action>  <workflow>  <app-path>hdfs: /  /  / tmp / workflows2 / < / app-path>  < / configuration>  < / workflow>  < / action>  < / coordinator-app>  oozie  client  job  id  get  test  user  size  < / datasets>  <input-events>  file  actions  evaluate   / workflows / 2009 / 02 / 01 / consume_me  <execution>lifo< / execution> < / controls> <datasets>   submitjob  getmissingdependencies   / workflows / ${year} / ${month} / ${day}< / uri-template>   conf  <data-in name= \ ""a \ "" dataset= \ ""local_a \ ""> <instance>${coord:current ( 0 ) }< / instance> < / data-in>    getactions  < / input-events>   getstatus  apppath  system  writetofile  appxml  actionstatus  <dataset name= \ ""local_a \ "" frequency= \ ""${coord:days ( 1 ) } \ "" initial-instance= \ ""2009-02-01t01:00z \ ""   asserttrue  file: /  /   gettestcasedir  unit_testing  get  coordinatoraction   .  . missing deps=  action  missingdeps  <done-flag>consume_me< / done-flag> < / dataset>  xmlns= \ ""uri:oozie:coordinator:0 . 1 \ ""> <controls> <timeout>10< / timeout> <concurrency>2< / concurrency>   waitfor  timezone= \ ""utc \ ""> <uri-template>file: /  /   getcoordjob  coordinator . xml  ce  set  testcustomdoneflag  <coordinator-app name= \ ""name \ "" frequency= \ ""${coord:days ( 1 ) } \ "" start= \ ""2009-02-01t01:00z \ "" end= \ ""2009-02-01t02:00z \ "" timezone= \ ""utc \ ""   <configuration> <property> <name>inputa< / name> <value>${coord:datain (  \  ' a \  '  ) }< / value> < / property>   assertequals  <action> <workflow> <app-path>hdfs: /  /  / tmp / workflows2 / < / app-path>   < / configuration> < / workflow> < / action> < / coordinator-app>  oozieclient  jobid  gettestuser  size  < / datasets> <input-events>   file  actions  evaluate   / workflows / 2009 / 02 / 01 / consume_me
__label__nflaky actual  count . get  usage  -count  -q  -h  -v  -t  <storage  type>  -u  -x  -e  <path>   .  .  .   expected  count  assert  equals  get  usage  actual  count . getusage  -count -q -h -v -t <storage type> -u -x -e <path>  .  .  .   expected  count  assertequals  getusage
__label__flaky end_  points  -doas  is_  security_  enabled  submit  oozie  url  run  oozie . authentication . simple . anonymous . allowed  app  path  -submit  get  test  user2  -config  create  workflow . xml  servlet_  classes  close  run  test  app  create  config  file  get  context  url  test  submit  do  as  false  mock  dag  engine  service  assert  equals  get  file  system  args  call  -oozie  set  system  property  mkdirs  to  string  job  get  fs  test  case  dir  end_points  -doas  is_security_enabled  submit  oozieurl  run  oozie . authentication . simple . anonymous . allowed  apppath  -submit  gettestuser2  -config  create  workflow . xml  servlet_classes  close  runtest  app  createconfigfile  getcontexturl  testsubmitdoas  false  mockdagengineservice  assertequals  getfilesystem  args  call  -oozie  setsystemproperty  mkdirs  tostring  job  getfstestcasedir
__label__nflaky g3  description  c1  description  description  g2  name  g4  name  g4  description  c2  name  c2  description  add  counter  int  counter  int  gauge  float  gauge  builder  verify  metrics  lists  info  gauge  g3  name  registry  c1  name  test  add  gauge  capture  long  gauge  g1  assert  equals  g2  counter  g3  eq  g4  c1  c2  get  value  double  gauge  g1  name  metric  long  counter  name  test  common  mock  g2  description  metrics  visit  visitor  g1  description  g3 description  c1 description  description  g2 name  g4 name  g4 description  c2 name  c2 description  addcounter  int counter  int gauge  float gauge  builder  verify  metricslists  info  gauge  g3 name  registry  c1 name  test  addgauge  capture  long gauge  g1  assertequals  g2  counter  g3  eq  g4  c1  c2  getvalue  double gauge  g1 name  metric  long counter  name  testcommon  mock  g2 description  metrics  visit  visitor  g1 description
__label__flaky next  delete  topic  kafka  utils  data  log  keys  local  zk  server  test  produce  consume  topic  choose  free  port  sleep  iterator  assert  true  get  first  info  localhost  add  local  kafka  broker  starting  consumer  thread  read  data  producing  data  value  of  kafka  broker  port  start  sleep  for  a  while  before  shutting  down  producer  to  let  both  finish  has  next  assert  equals  zk  port  produce  num_  data  thread  integer  io  utils  contains  get  port  do  run  size  await  scheduling  maybe  create  topic  next  deletetopic  kafkautils  data  log  keys  localzkserver  testproduceconsume  topic  choosefreeport  sleep  iterator  asserttrue  getfirst  info  localhost  add  localkafkabroker  starting consumer thread  readdata  producing data  valueof  kafkabrokerport  start   sleep for a while before shutting down producer to let both finish  hasnext  assertequals  zkport  produce  num_data  thread  integer  ioutils  contains  getport  dorun  size  awaitscheduling  maybecreatetopic
__label__nflaky byte  channel  standard  charsets  test  stream  that  ends  with  error  expected  published  exception  to  be  rethrown  assert  equals  error  byte  buffer  produce  get  cause  fail  assert  ex  assert  true  expected  protocol  exception  concat  array  publisher  producer  12345  dump  wrap  just  stream  channel  flowable    bytechannel  standardcharsets  teststreamthatendswitherror  expected published exception to be rethrown  assertequals  error  bytebuffer  produce  getcause  fail  assert  ex  asserttrue  expected protocolexception  concatarray  publisher  producer  12345  dump  wrap  just  streamchannel  flowable
__label__flaky cluster  create  threads  and  make  them  run  workload  concurrently .   init  buffer  test  files  conf  fs  waiting  for  thread  create  file  system  wait  active  global  status  assert  true  test  complex  append  worker  encountered  exceptions .   retry  num  datanodes  join  close  replication  add  dfs  config  keys  wait  for  all  transactions  to  get  over  start  workload  get  file  system  next  int  test  complex  append  file  contents  stm  num  threads  append  test  util  set  int   /   test  file  number  of  files  dfs . support . append  build  num  data  nodes  complete .   to  complete .  .  .   shutdown  set  boolean   . dat  cluster   create threads and make them run workload concurrently .   initbuffer  testfiles  conf  fs  waiting for thread   createfile  system  waitactive  globalstatus  asserttrue  testcomplexappend worker encountered exceptions .    retry  numdatanodes  join  close  replication  add     dfsconfigkeys   wait for all transactions to get over  start  workload  getfilesystem  nextint  testcomplexappend  filecontents  stm  numthreads  appendtestutil  setint   /   testfile  numberoffiles  dfs . support . append  build  numdatanodes   complete .    to complete .  .  .   shutdown  setboolean   . dat
__label__nflaky next  then  build  route  equal  to  get  filter  chain  when  filter  chain  result  get  context  get  provider  injector  when  test  with  filters  class  given  then  return  dummy  filter  filter  provider  filters  matchers  assert  that   /   with  route  mockito  expected  result  get  mock  route  builder  next   then  buildroute  equalto  getfilterchain  when  filterchain  result  get  context  getprovider  injector   when  testwithfiltersclass   given  thenreturn  dummyfilter  filterprovider  filters  matchers  assertthat   /   with  route  mockito  expectedresult  get  mock  routebuilder
__label__flaky tfs  kills   / 0  clients  common  utils  m  tfs  ls  assert  equals  m  local  tachyon  cluster  multi  master  get  client  k  sleep  ms  create  file   /   fault  test  assert  size  assert  true  get  kill  leader  files  tfs  kills   / 0  clients  commonutils  mtfs  ls  assertequals  mlocaltachyonclustermultimaster  getclient  k  sleepms  createfile   /   faulttest  assert  size  asserttrue  get  killleader  files
__label__nflaky bufentity  standard  charsets  assert  false  get  content  assert  equals  get  content  length  get  bytes  test  wrapping  entity  is  repeatable  httpentity  assert  test  if  we  can  obtain  contain  multiple  times  is  chunked  assert  true  is  streaming  bytes  assert  not  null  message  content  bufentity  standardcharsets  assertfalse  getcontent  assertequals  getcontentlength  getbytes  testwrappingentity  isrepeatable  httpentity  assert   test if we can obtain contain multiple times  ischunked  asserttrue  isstreaming  bytes  assertnotnull  message content
__label__flaky cluster  num_  of_  datanodes  default_  bandwidth  conf  new  bandwidth  fs  datanodes  should  remain  as  it  was .   wait  active  sleep  get  balancer  bandwidth  get  ensure  value  from  the  configuration  is  reflected  in  the  datanodes .   set  balancer  bandwidth  give  it  a  few  seconds  to  propogate  new  the  value  to  the  datanodes .   dfs  config  keys  get  data  nodes  test  balancer  bandwidth  12  m  bps  assert  equals  get  file  system  datanodes  thread  set  long  create  and  start  cluster  set  bandwidth  per  sec  to  a  low  value  of  1  m  bps .   build  num  data  nodes  shutdown  cluster  num_of_datanodes  default_bandwidth  conf  newbandwidth  fs   datanodes should remain as it was .   waitactive  sleep  getbalancerbandwidth  get   ensure value from the configuration is reflected in the datanodes .   setbalancerbandwidth   give it a few seconds to propogate new the value to the datanodes .   dfsconfigkeys  getdatanodes  testbalancerbandwidth   12m bps  assertequals  getfilesystem  datanodes  thread  setlong   create and start cluster    set bandwidthpersec to a low value of 1m bps .    build  numdatanodes  shutdown
__label__nflaky request  p1  adapter  contains  key  query  change  the  request  from  what  is  expected .   unchecked  response  expectations  execute  remove  fail  assert  request  handler  framework  query  assert  true  run  tests  get  new  framework  and  set  adapter  default  uri  add  test  remove  parameter  web  server  testing  framework  exception  should  have  been  thrown  request  p1  adapter  containskey  query   change the request from what is expected .   unchecked  responseexpectations  execute  remove  fail  assert  requesthandler  framework  query  asserttrue  runtests  get  newframeworkandsetadapter  defaulturi  addtest  removeparameter  webservertestingframeworkexception should have been thrown
__label__flaky play  set  variant  and  client  client  pings  server  http2  ping  play  it  back  assert  false  http_20_  draft_09  verify  the  peer  received  what  was  expected  assert  equals  to  nanos  accept  frame  send  frame  assert  true  peer  round  trip  time  ping  frame  time  unit  ping  connection  take  frame  connection . ping (  )   sets  this .   play  setvariantandclient  clientpingsserverhttp2  ping   play it back  assertfalse  http_20_draft_09   verify the peer received what was expected  assertequals  tonanos  acceptframe  sendframe  asserttrue  peer  roundtriptime  pingframe  timeunit   ping  connection  takeframe   connection . ping (  )  sets this . 
__label__nflaky request  assert  nothing  thrown  modify  request  set  request  handler  put  status  assert  headers  modify  request  should  have  been  called .   assert  true  run  tests  make  sure  the  modify  request  method  was  called  by  seeing  if  the  request  was  modified .   content_  type  get  verify  add  test  unlikely_  item  something_unlikely_to_be_in_a_real_request  adapter  contains  key  response  expectations  execute  let  the  adapter  change  the  request  if  needed .   framework  modify  request  called  mockito  response  mock  request  handler  new  framework  and  set  adapter  mock  assert  nothing  thrown (  )   should  have  been  called .   body  request  assertnothingthrown  modifyrequest  setrequesthandler  put  status  assert  headers  modifyrequest should have been called .   asserttrue  runtests   make sure the modifyrequest method was called by seeing if the request was modified .   content_type  get  verify  addtest  unlikely_item  something_unlikely_to_be_in_a_real_request  adapter  containskey  responseexpectations  execute   let the adapter change the request if needed .   framework  modifyrequestcalled  mockito  response  mockrequesthandler  newframeworkandsetadapter  mock   assertnothingthrown (  )  should have been called .   body
__label__flaky  / foo ? bar / foo ? bar  cluster   / foo bar / foo bar   / foo=bar / foo=bar   / foo \ "">bar / foo \ "">bar  wait  active   / foo;bar / foo;bar  p   / foo  bar / foo  bar  test  viewing  file   / foo+bar / foo+bar  build   / test-file   / tmp / test-file  paths  conf   / tmp / test-file \ %with  goofy&characters  test  view  file  jsp  shutdown   / foo ? bar / foo ? bar  cluster   / foo bar / foo bar   / foo=bar / foo=bar   / foo \ "">bar / foo \ "">bar  waitactive   / foo;bar / foo;bar  p   / foo bar / foo bar  testviewingfile   / foo+bar / foo+bar  build   / test-file   / tmp / test-file  paths  conf   / tmp / test-file \ %with goofy&characters  testviewfilejsp  shutdown
__label__nflaky get  class  get  name  test12  test11  test  nested  s211  test0  test1  result  s11  s12  assert  true  context  output  stream  s0  s1  s2  add  +  info  in  test22  status  printer  test21  +  warn  in  |-  warn  in  test2  s22  print  contains  s21  test211  to  string  get  status  manager  getclass  getname  test12  test11  testnested  s211  test0  test1  result  s11  s12  asserttrue  context  outputstream  s0  s1  s2  add  + info in   test22  statusprinter  test21  + warn in       |-warn in   test2  s22  print  contains  s21  test211  tostring  getstatusmanager
__label__flaky inherit  wf  false  parent  libs2  parent  libs3  check  subworkflow  lib  helper  parent  libs1  parent  libs4  parent  libs5  child  libs1  expected  libs1  expected  libs2  expected  libs3  expected  libs4  inherit  child2 . so  expected  libs5  true  test  create  proto  conf  with  sub  workflow  lib5  same . jar  child  libs3  child  libs2  child  libs5  child1 . jar  child  libs4  inheritwf  false  parentlibs2  parentlibs3  checksubworkflowlibhelper  parentlibs1  parentlibs4  parentlibs5  childlibs1  expectedlibs1  expectedlibs2  expectedlibs3  expectedlibs4  inherit  child2 . so  expectedlibs5  true  testcreateprotoconfwithsubworkflowlib5  same . jar  childlibs3  childlibs2  childlibs5  child1 . jar  childlibs4
__label__nflaky num  insertions  digits  hash  hash  id  filter  hash  function  number  remove  scheme  immutable  set  and  of  bit  size  hashes  check  on  absent  false  positive  test  retouched  bloom  filter  specific  numinsertions  digits  hash  hashid  filter  hashfunctionnumber  removescheme  immutableset  and  of  bitsize  hashes  checkonabsentfalsepositive  testretouchedbloomfilterspecific
__label__flaky create  action  default  conf  action . foo  actionx  foo  *  jt  assert  equals  services  create  job  conf  jtx  services  bar  assert  null  action . bar  assert  not  null  get  action  has  test  service  createactiondefaultconf  action . foo  actionx  foo  *  jt  assertequals  services  createjobconf  jtx  services  bar  assertnull  action . bar  assertnotnull  get  action  has  testservice
__label__nflaky to  regex  for  fixed  date  set  get  time  calendar  fnp  assert  equals   / toto / foo-2003 / 05 / 20- (  \  \ d+ )  . txt  foo- \ %d{yyyy .   mm . dd}- \ %i . txt  cal  regex  foo-2003 . 05 . 20- (  \  \ d+ )  . txt  context  as  regex  by  date  get  instance   \  \ toto \  \ foo- \ %d{yyyy \  \   mm \  \ dd}- \ %i . txt  toregexforfixeddate  set  gettime  calendar  fnp  assertequals   / toto / foo-2003 / 05 / 20- (  \  \ d+ )  . txt  foo- \ %d{yyyy . mm . dd}- \ %i . txt  cal  regex  foo-2003 . 05 . 20- (  \  \ d+ )  . txt  context  asregexbydate  getinstance   \  \ toto \  \ foo- \ %d{yyyy \  \ mm \  \ dd}- \ %i . txt
__label__flaky oryx . input-schema . target-feature  start  server  produce  consume  topics  max_  depth  data_  to_  write  gen_  interval_  sec  put  oryx . input-schema . categorical-features   \ ""4 \ ""  oryx . input-schema . num-features  oryx . batch . update-class  model  boolean  target  encoding  get  most  probable  category  encoding  oryx . rdf . hyperparams . max-depth  expected  low  values  like  2  are  deliberately  bad   won \  ' t  work  get  value  encoding  map  *  ml  update  model  instance  dirs:  {}  size   \ ""0 \ ""  no  such  model  file:   \ ""4 \ ""  numeric  feature  forest  pmml  utils  log  expected  positive  rdfpmml  utils  get  temp  dir  assert  true  get  files    model  instance  dirs  oryx . batch . streaming . block-interval-sec  {}  set  model  file  impurity  pmml  assert  equals  get  extensions  get  config  max  depth  oryx . batch . storage . data-dir  io  utils  max_  split_  candidates  get  second  exists  to  string  max  split  candidates  config  no  models ?   impurity  get  name  data  resolve  oryx . rdf . hyperparams . impurity  data  dir  config  utils  oryx . input-schema . id-features  f1  f2  f3  check  intervals  oryx . ml . eval . candidates  get  first  oryx . batch . storage . model-dir  info  read  oryx . ml . eval . parallelism  encoding  latest  model  dir  test  rdf  write_  interval_  msec  prediction  overlay  on  model  dir  oryx . rdf . num-trees  assert  false  start  messaging  forest  encoding  2   for  value  predict  oryx . rdf . hyperparams . max-split-candidates  check  extensions  list  files  num_  trees  int  value  is  empty  oryx . batch . streaming . generation-interval-sec  temp  dir  overlay  config  block_  interval_  sec  oryx . input-schema . target-feature  startserverproduceconsumetopics  max_depth  data_to_write  gen_interval_sec  put  oryx . input-schema . categorical-features   \ ""4 \ ""  oryx . input-schema . num-features  oryx . batch . update-class  model  boolean  targetencoding  getmostprobablecategoryencoding  oryx . rdf . hyperparams . max-depth  expected   low values like 2 are deliberately bad  won \  ' t work  getvalueencodingmap  *  mlupdate  model instance dirs: {}  size   \ ""0 \ ""  no such model file:    \ ""4 \ ""  numericfeature  forest  pmmlutils  log  expectedpositive  rdfpmmlutils  gettempdir  asserttrue  get  files    modelinstancedirs  oryx . batch . streaming . block-interval-sec  {}  set  modelfile  impurity  pmml  assertequals  getextensions  getconfig  maxdepth  oryx . batch . storage . data-dir  ioutils  max_split_candidates  getsecond  exists  tostring  maxsplitcandidates  config  no models ?   impurity  getname  data  resolve  oryx . rdf . hyperparams . impurity  datadir  configutils  oryx . input-schema . id-features  f1  f2  f3  checkintervals  oryx . ml . eval . candidates  getfirst  oryx . batch . storage . model-dir  info  read  oryx . ml . eval . parallelism  encoding  latestmodeldir  testrdf  write_interval_msec  prediction  overlayon  modeldir  oryx . rdf . num-trees  assertfalse  startmessaging  forestencoding  2   forvalue  predict  oryx . rdf . hyperparams . max-split-candidates  checkextensions  listfiles  num_trees  intvalue  isempty  oryx . batch . streaming . generation-interval-sec  tempdir  overlayconfig  block_interval_sec
__label__nflaky test  simple  date  get  yesterdays  millis  test  that  java  util  date  works  test  simpledate  getyesterdaysmillis  testthatjavautildateworks
__label__flaky conn  set  request  method   / version  assert  true  array  get  content-type  run  test  rest  constants  open  connection  test  version  http  servlet  response  assert  equals  parse  params  get  input  stream  url  json  value  call  oozie  client  get  header  field  size  get  get  response  code  create  url  starts  with    conn  setrequestmethod   / version  asserttrue  array  get  content-type  runtest  restconstants  openconnection  testversion  httpservletresponse  assertequals  parse  params  getinputstream  url  jsonvalue  call  oozieclient  getheaderfield  size  get  getresponsecode  createurl  startswith
__label__nflaky get  name  get  process  restart  assert  false  get  our  class  path  multiple  restarts  really  quickly   .   rcsjm  override  output  so  we  can  capture  it  is  alive  get  active  process  assert  true  equals  started  process1  collections  baos1  started  process2  started  process3  set  output  started  process4  fake  daemon  getname  getprocess  restart  assertfalse  getourclasspath  multiplerestartsreallyquickly   .   rcsjm   override output so we can capture it  isalive  getactiveprocess  asserttrue  equals  startedprocess1  collections  baos1  startedprocess2  startedprocess3  setoutput  startedprocess4  fakedaemon
__label__flaky test  feature  loaded  feature  state  enable  disable  is  enabled  saved  feature  state  set  feature  state  test  enabled  state  saving  and  loading  is  state  repository  assert  that  get  feature  state  testfeature  loadedfeaturestate  enable  disable  isenabled  savedfeaturestate  setfeaturestate  testenabledstatesavingandloading  is  staterepository  assertthat  getfeaturestate
__label__nflaky and  check  if  new  umask  is  applied  test  set  umask  in  real  time  default  permission  is  777  assume  not  windows  conf  dir  not  localfs  current  umask  is  {}  assert  true  final  permission  file  system  get  755  get  file  status  715  info  with  umask  062  we  expect  715  since  the  default  permission  is  777  with  umask  062  permission  should  not  be  755  since  the  set  get  permission  get  conf  common  configuration  keys  initial  permission  dir2  assert  equals  is  062  assert  that  test_  path_  prefix  022  with  umask  022  permission  should  be  755  since  the  default  cleanup  get  local  mkdirs  logger  permission  is  777   and check if new umask is applied  testsetumaskinrealtime  default permission is 777  assumenotwindows  conf  dir  not  localfs  current umask is {}  asserttrue  finalpermission  filesystem  get  755  getfilestatus  715  info  with umask 062 we expect 715 since the default permission is 777  with umask 062 permission should not be 755 since the   set  getpermission  getconf  commonconfigurationkeys  initialpermission  dir2  assertequals  is  062  assertthat  test_path_prefix  022  with umask 022 permission should be 755 since the default   cleanup  getlocal  mkdirs  logger  permission is 777
__label__flaky schema  a  race  conditon  in  the  validator .   this  test  is  to  make  sure  we  don \  ' t  accidently  remove  the  dependency .   assert  false  start  threads  error  num  threads  get  schema  services  parser  schema  service  get  test  race  condition  with  old  xerces  all  done  evaluate  wait  for  schema   a race conditon in the validator .   this test is to make sure we don \  ' t accidently remove the dependency .   assertfalse  start  threads  error  numthreads  getschema  services  parser  schemaservice  get  testraceconditionwitholdxerces  alldone  evaluate  waitfor
__label__nflaky retry  policy  curator  framework  factory  working  path  test  ac  ls  conf  get  default  acl  get  acl  for  path  get  bytes  digest  acl  provider  authorization  bla  get  digest  builder  tm1  close  get  secret  conf  ret  add  init  get  connect  string  zk  delegation  token  secret  manager  zk  server  check  acl  user  pass  generate  digest  utf-8  start  destroy   /   acl  provider  myuser:mypass  build  set  curator  digest  acl  verify  acl  connect  string  curator  framework  zoo  defs  digest  authentication  provider  retrypolicy  curatorframeworkfactory  workingpath  testacls  conf  getdefaultacl  getaclforpath  getbytes  digestaclprovider  authorization  bla  get  digest  builder  tm1  close  getsecretconf  ret  add  init  getconnectstring  zkdelegationtokensecretmanager  zkserver   check acl  userpass  generatedigest  utf-8  start  destroy   /   aclprovider  myuser:mypass  build  setcurator  digestacl  verifyacl  connectstring  curatorframework  zoodefs  digestauthenticationprovider
__label__flaky h  constants  conf  session  id  system  sleep  get  connection  password  get  session  password  5  seconds  connection  get  quorum  servers  get  session  id  close  h  connection  manager  empty  watcher  zkw  relocate  region  get  zoo  keeper  wrapper  connection  zk  thread  zoo  keeper  should  have  timed  out  zk  test  client  session  expired  quorum  servers  session  timeout  hconstants  conf  sessionid  system  sleep  getconnection  password  getsessionpassword   5 seconds  connection  getquorumservers  getsessionid  close  hconnectionmanager  emptywatcher  zkw  relocateregion  getzookeeperwrapper  connectionzk  thread  zookeeper should have timed out  zk  testclientsessionexpired  quorumservers  sessiontimeout
__label__nflaky assert  content  type  get  mime  type  text / plain;  charset= \ ""   \ ""  test  parse  empty  charset  assert  equals  parse  get  charset  content  type  text / plain  assert  contenttype  getmimetype  text / plain; charset= \ ""  \ ""  testparseemptycharset  assertequals  parse  getcharset  contenttype  text / plain
__label__flaky cluster  test  count  run  cmd  conf  system  localfs  test_  root_  dir  root  file  system  run  count  close  2 / f1  testcount  get  working  directory  create  tree  localpath  verify  the  counts  count  localstr  assert  equals  get  file  system  set  conf  localstr=  dfs  2  -count  2 / sub  build  shell  num  data  nodes  get  local  make  qualified  mkdirs  to  string  shutdown  get  uri  cluster  testcount  runcmd  conf  system  localfs  test_root_dir  root  filesystem  runcount  close  2 / f1  testcount  getworkingdirectory  createtree  localpath   verify the counts  count  localstr  assertequals  getfilesystem  setconf  localstr=  dfs  2  -count  2 / sub  build  shell  numdatanodes  getlocal  makequalified  mkdirs  tostring  shutdown  geturi
__label__nflaky test  start  when  already  started  start  appender  assert  equals  runner  get  start  count  teststartwhenalreadystarted  start  appender  assertequals  runner  getstartcount
__label__flaky date  set  script  executor  downgrading  consistency  retry  policy  session  with  consistency  level  one  given  update  simple  select  value  from  simple  where  id  =  should_dsl_update_with_options  eq  when  of  with  tracing  where  id  row  value  table  execute  script  template  log  asserter  prepare  log  level  for  driver  connection  is  not  null  random  utils  manager  one  get  string  next  long  assert  that  execute  simple  entity / insert_single_row . cql  immutable  map  assert  consistency  levels  with  retry  policy  then  long  build  date  key  new  value  from  base  table  dsl  is  equal  to  three  date  set  scriptexecutor  downgradingconsistencyretrypolicy  session  withconsistencylevel  one   given  update  simple  select value from simple where id =   should_dsl_update_with_options  eq   when  of  withtracing  where  id  row  value  table  executescripttemplate  logasserter  prepareloglevelfordriverconnection  isnotnull  randomutils  manager  one  getstring  nextlong  assertthat  execute  simpleentity / insert_single_row . cql  immutablemap  assertconsistencylevels  withretrypolicy   then  long  builddatekey  new value  frombasetable  dsl  isequalto  three
__label__nflaky ret  delete  tmp  dir  properly .   assert  false  dangling  symlink  to  file  link  del  assert  equals  list  tmp  dir  assert  assert  true  tmp  should  delete   \  ' y \  '   properly .   dangling  symlink  to  directory  exists  link  setup  dirs  test  fully  delete  dangling  symlinks  file  util  fully  delete  to  make  y  as  a  dangling  link  to  file  tmp / x  link  dir  ret   delete tmpdir properly .   assertfalse   dangling symlink to file  link  del  assertequals  list  tmpdir  assert  asserttrue  tmp   should delete  \  ' y \  '  properly .    dangling symlink to directory  exists  link  setupdirs  testfullydeletedanglingsymlinks  fileutil  fullydelete   to make y as a dangling link to file tmp / x  linkdir
__label__flaky aap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /    /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  q  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaa  this  specially-formatted  frame  has  trailing  deflated  bytes  after  the  name  value  block .   aaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad  a /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9   /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  header  block  has  trailing  compressed  bytes2048  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaa  g  ama  ag  aab / s  aaaa  be  lvjxqf  c  aq  yj  rh  ag  jmx  gx  uqaaaaa /  / 9  kbaaaap /  /   sg  qaaad /  / 0o  eaaaa /  / 9  kbaa  header  block  has  trailing  compressed  bytes  aaad /  / 0o  eaaaa /  / 8=  frame  aap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /    / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgq  kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaa   this specially-formatted frame has trailing deflated bytes after the name value block .   aaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad  a /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9   /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0o  headerblockhastrailingcompressedbytes2048  eaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaa  gamaagaab / saaaabelvjxqfcaqyjrhagjmxgxuqaaaaa /  / 9kbaaaap /  / sgqaaad /  / 0oeaaaa /  / 9kbaa  headerblockhastrailingcompressedbytes  aaad /  / 0oeaaaa /  / 8=  frame
__label__nflaky other_  group_  names  proxy  users  refresh  super  user  groups  configuration  get  proxy  superuser  group  conf  key  assert  authorized  group_  names  default  impersonation  provider  conf  as  list  test  proxy  users  proxy_  ip  string  utils  join  from  bad  ip  user  group  information  first  try  proxying  a  group  that \  ' s  allowed  set  proxy  user  ugi  1 . 2 . 3 . 4  1 . 2 . 3 . 5  now  try  proxying  a  group  that \  ' s  not  allowed     create  remote  user  real_  user_  name  assert  not  authorized  get  test  provider  from  good  ip  arrays  get  proxy  superuser  ip  conf  key  proxy_  user_  name  real  user  ugi  create  proxy  user  for  testing  other_group_names  proxyusers  refreshsuperusergroupsconfiguration  getproxysuperusergroupconfkey  assertauthorized  group_names  defaultimpersonationprovider  conf  aslist  testproxyusers  proxy_ip  stringutils  join   from bad ip  usergroupinformation   first try proxying a group that \  ' s allowed  set  proxyuserugi  1 . 2 . 3 . 4  1 . 2 . 3 . 5   now try proxying a group that \  ' s not allowed     createremoteuser  real_user_name  assertnotauthorized  gettestprovider   from good ip  arrays  getproxysuperuseripconfkey  proxy_user_name  realuserugi  createproxyuserfortesting
__label__flaky location:   /   play  server   / 0  request  add  header  receiver  too  many  redirects:  21  does  not  follow21  redirects  redirecting  to   /   set  response  code  set  body   / 20  url  enqueue  get  url  build  await  client  assert  failure  location:  /   play  server   / 0  request  addheader  receiver  too many redirects: 21  doesnotfollow21redirects  redirecting to  /   setresponsecode  setbody   / 20  url  enqueue  geturl  build  await  client  assertfailure
__label__nflaky test  request  expect  continue  invalid  input  fail  process  assert  interceptor  illegal  argument  exception  should  have  been  thrown  testrequestexpectcontinueinvalidinput  fail  process  assert  interceptor  illegalargumentexception should have been thrown
__label__flaky get  connection  context  get  event  message  conf  parse  date  utc  date  utils  get  status  test  on  workflow  job  started  event  wf-app-name1  ca  id1  2012-07-22  t00:00  z  wf  id1  get  start  time  message  type  init  print  stack  trace  get  text  destroy  wf  event  listener  fail  contains  on  workflow  job  event  wf  start  message  create  consumer  app  type  start  date  get  parent  id  get  app  type  session  assert  false  jms  messaging  utils  get  event  status  get  user  event  status  get  id  create  session  get  topic  workflow  job  jms  context  consumer  user1  get  message  type  receive  get  app  name  e  get  message  assert  equals  message  wfe  end  time  session  getconnectioncontext  geteventmessage  conf  parsedateutc  dateutils  getstatus  testonworkflowjobstartedevent  wf-app-name1  caid1  2012-07-22t00:00z  wfid1  getstarttime  messagetype  init  printstacktrace  gettext  destroy  wfeventlistener  fail  contains  onworkflowjobevent  wfstartmessage  createconsumer  apptype  startdate  getparentid  getapptype  session  assertfalse  jmsmessagingutils  geteventstatus  getuser  eventstatus  getid  createsession  gettopic  workflowjob  jmscontext  consumer  user1  getmessagetype  receive  getappname  e  getmessage  assertequals  message  wfe  endtime  session
__label__nflaky test  sequence  file  deflate  codec  sequence  file  codec  test  conf  org . apache . hadoop . io . compress .   deflate  codec  testsequencefiledeflatecodec  sequencefilecodectest  conf  org . apache . hadoop . io . compress . deflatecodec
__label__flaky set  classes  to  be  excluded  test  coord  kill  for  backward  support  coord  action  get  cmd  get  id  get  status  add  record  to  coord  action  table  assert  not  null  get  coordinator  action  action  init  get  conf  destroy  assert  equals  services  set  app  namespace  execute  add  record  to  coord  job  table  call  services  coordinator  job  coord  job  get  cmd  coord-action-get . xml  excluded  services  schema  service  set  system  property  true  status  transit  service  job  jpa  service  setclassestobeexcluded  testcoordkillforbackwardsupport  coordactiongetcmd  getid  getstatus  addrecordtocoordactiontable  assertnotnull  get  coordinatoraction  action  init  getconf  destroy  assertequals  services  setappnamespace  execute  addrecordtocoordjobtable  call  services  coordinatorjob  coordjobgetcmd  coord-action-get . xml  excludedservices  schemaservice  setsystemproperty  true  statustransitservice  job  jpaservice
__label__nflaky request  http: /  / somehost / stuff  somehost  assert  equals  method  get  method  get  authority  assert  name  get  path  http   / stuff  test  request  with  authority  get  uri  request  http: /  / somehost / stuff  somehost  assertequals  method  getmethod  getauthority  assert  name  getpath  http   / stuff  testrequestwithauthority  geturi
__label__flaky add  record  to  bundle  action  table  add  record  to  wf  action  table  coord  job2  get  cmd  get  status  wf  action5  get  cmd  coordinator  job  4  should  not  have  been  purged  wf  job5  get  cmd  workflow  action  4  should  not  have  been  purged  coordinator  action  5  should  not  have  been  purged  coord  action4  get  cmd  get  end  time  bundle  job  coord  action3  coord  action4  bundle  job  bean  assert  not  null  coord  action5  coordinator  action  wf  job2  get  cmd  coord  action1  coord  action2  workflow  job  4  should  not  have  been  purged  bundle  action4  bundle  action5  bundle  action1  bundle  action2  bundle  action3  execute  workflow  job  3  should  not  have  been  purged  bundle  action1  get  cmd  coordinator  job  1  fail  bundle  action  2  should  not  have  been  purged  succeeded  wf  action2  get  cmd  workflow  action  5  should  not  have  been  purged  coordinator  job  3  should  not  have  been  purged  coordinator  action  4  should  not  have  been  purged  bundle  job  get  cmd  wf  job1  coord  job1  get  cmd  wf  job3  wf  job4  get  cmd  wf  job2  wf  job5  get  wf  job4  bundle  action  4  should  not  have  been  purged  coord  action2  get  cmd  workflow  action  3  should  not  have  been  purged  bundle  action3  get  cmd  get  app  name  set  app  name  coord  action1  get  cmd  bundle  action  3  should  not  have  been  purged  2011-01-01  t01:00  z  add  record  to  bundle  job  table  assert  equals  get  last  modified  time  wf  action1  wf  action2  add  record  to  coord  job  table  wf  action3  wf  action4  wf  action5  call  services  wf  job3  get  cmd  coordinator  job  2  should  not  have  been  purged  jpa  service  workflow  job  2  should  not  have  been  purged  bundle  action2  get  cmd  bundle  action  5  should  not  have  been  purged  get  num  days  to  not  be  purged  date  utils  workflow  instance  add  record  to  coord  action  table  parse  date  oozie  tz  workflow  job  1  should  not  have  been  purged  wf  action1  get  cmd  job  coord2  coord3  coord4  coord5  coordinator  job  1  should  not  have  been  purged  coord  job3  get  cmd  wf  job1  get  cmd  test  purge  bundle  with  coord  child  with  wf  child2  more  than  limit  workflow  action  2  should  not  have  been  purged  coord  job2  bundle  job  should  not  have  been  purged  coord  job3  coord  job1  coordinator  action  3  should  not  have  been  purged  workflow  action  coord  action3  get  cmd  coord  job4  coord  job5  coord  job4  get  cmd  bundle  action4  get  cmd  bundle  action  1  should  not  have  been  purged  get  id  coord  action5  get  cmd  add  record  to  wf  job  table  workflow  job  coordinator  action  1  should  not  have  been  purged  wf  action3  get  cmd  wf  action4  get  cmd  coord  job5  get  cmd  bundle  action5  get  cmd  coordinator  action  2  should  not  have  been  purged  workflow  action  1  should  not  have  been  purged  coord-action-get . xml  workflow  job  5  should  not  have  been  purged  coordinator  job  5  should  not  have  been  purged  addrecordtobundleactiontable  addrecordtowfactiontable  coordjob2getcmd  getstatus  wfaction5getcmd  coordinator job 4 should not have been purged  wfjob5getcmd  workflow action 4 should not have been purged  coordinator action 5 should not have been purged  coordaction4getcmd  getendtime  bundlejob  coordaction3  coordaction4  bundlejobbean  assertnotnull  coordaction5  coordinatoraction  wfjob2getcmd  coordaction1  coordaction2  workflow job 4 should not have been purged  bundleaction4  bundleaction5  bundleaction1  bundleaction2  bundleaction3  execute  workflow job 3 should not have been purged  bundleaction1getcmd  coordinatorjob  1  fail  bundle action 2 should not have been purged  succeeded  wfaction2getcmd  workflow action 5 should not have been purged  coordinator job 3 should not have been purged  coordinator action 4 should not have been purged  bundlejobgetcmd  wfjob1  coordjob1getcmd  wfjob3  wfjob4getcmd  wfjob2  wfjob5  get  wfjob4  bundle action 4 should not have been purged  coordaction2getcmd  workflow action 3 should not have been purged  bundleaction3getcmd  getappname  setappname  coordaction1getcmd  bundle action 3 should not have been purged  2011-01-01t01:00z  addrecordtobundlejobtable  assertequals  getlastmodifiedtime  wfaction1  wfaction2  addrecordtocoordjobtable  wfaction3  wfaction4  wfaction5  call  services  wfjob3getcmd  coordinator job 2 should not have been purged  jpaservice  workflow job 2 should not have been purged  bundleaction2getcmd  bundle action 5 should not have been purged  getnumdaystonotbepurged  dateutils  workflowinstance  addrecordtocoordactiontable  parsedateoozietz  workflow job 1 should not have been purged  wfaction1getcmd  job  coord2  coord3  coord4  coord5  coordinator job 1 should not have been purged  coordjob3getcmd  wfjob1getcmd  testpurgebundlewithcoordchildwithwfchild2morethanlimit  workflow action 2 should not have been purged  coordjob2  bundle job should not have been purged  coordjob3  coordjob1  coordinator action 3 should not have been purged  workflowaction  coordaction3getcmd  coordjob4  coordjob5  coordjob4getcmd  bundleaction4getcmd  bundle action 1 should not have been purged  getid  coordaction5getcmd  addrecordtowfjobtable  workflowjob  coordinator action 1 should not have been purged  wfaction3getcmd  wfaction4getcmd  coordjob5getcmd  bundleaction5getcmd  coordinator action 2 should not have been purged  workflow action 1 should not have been purged  coord-action-get . xml  workflow job 5 should not have been purged  coordinator job 5 should not have been purged
__label__nflaky test  writable  test  short  writable  testwritable  testshortwritable
__label__flaky conn  set  request  method  is_  security_  enabled  test  instrumentation   / v0 / admin / *  assert  true  json  content-type  collections  run  test  json  tags  rest  constants  open  connection  contains  key  http  servlet  response  assert  equals  parse  get  input  stream  url  json  value  call  get  header  field  get  get  response  code  create  url  starts  with  conn  setrequestmethod  is_security_enabled  testinstrumentation   / v0 / admin / *  asserttrue  json  content-type  collections  runtest  jsontags  restconstants  openconnection  containskey  httpservletresponse  assertequals  parse  getinputstream  url  jsonvalue  call  getheaderfield  get  getresponsecode  createurl  startswith
__label__nflaky add  header  keep  alive  assert  false  connection  set  protocol  version  assert  response  keep--alive  context  use  http  1 . 0  reuse  strategy  test  broken  connection  directive1  ok  content-  length  http  version  10  addheader  keepalive  assertfalse  connection  setprotocolversion  assert  response  keep--alive  context   use http 1 . 0  reusestrategy  testbrokenconnectiondirective1  ok  content-length  httpversion  10
__label__flaky cluster  kill  a  datanode  e  file  path  get  message  conf  get  file  system  next  int  fs  append  test  util  out   / test  excluded  nodes  fail  build  num  data  nodes  test  excluded  nodes  create  write  data  node  failure  should  not  result  in  a  block  abort:  close  stop  data  node  cluster   kill a datanode  e  filepath  getmessage  conf  getfilesystem  nextint  fs  appendtestutil  out   / testexcludednodes  fail  build  numdatanodes  testexcludednodes  create  write  datanode failure should not result in a block abort:     close  stopdatanode
__label__nflaky null_  str      a  b  splits  escaped_  str_  with_  comma  b \  \  \  \   assert  equals  str_  with_  escape  str_  with_  both2  a \  \    split  str_  wo_  special_  chars  str_  with_  comma  escaped_  str_  with_  both2  test  split  string  utils  empty_  str  null_str      a  b  splits  escaped_str_with_comma  b \  \  \  \   assertequals  str_with_escape  str_with_both2  a \  \    split  str_wo_special_chars  str_with_comma  escaped_str_with_both2  testsplit  stringutils  empty_str
__label__flaky test  get  sla  events  for  coord  action  id  filter  list  action1  assert  equals  create  filter  list  list  coord  action  id1  execute  jobid  services  sla  events  get  cmd  size  assert  not  null  get  jpa  service  testgetslaeventsforcoordactionid  filterlistaction1  assertequals  createfilterlist  list  coordactionid1  execute  jobid  services  slaeventsgetcmd  size  assertnotnull  get  jpaservice
__label__nflaky then  return  invoke  when  param1  date  param  assert  true  context  create  verify  custom  date  format  validation  should  work  mock  controller  validation  has  violation  blah  get  parameter  thenreturn  invoke  when  param1  dateparam  asserttrue  context  create  verify  customdateformatvalidationshouldwork  mockcontroller  validation  hasviolation  blah  getparameter
__label__flaky next  shutdown  dfs  ccc  compare  startrow  get  log  scan  h  constants  test  stop  row  bytes  assert  true  get  table  desc  get  region_  info  do  simple  test  of  getting  one  row  only  first .   close  results  now  do  something  a  bit  more  imvolved .   abd  bbb  abc  to  bytes  count  assert  equals  kv  we  got  something  back .   add  content  get  row  close  and  delete  create  new  h  region  r  add  family  stoprow  get  scanner  first  next  shutdowndfs  ccc  compare  startrow  getlog  scan  hconstants  teststoprow  bytes  asserttrue  gettabledesc  get  region_info   do simple test of getting one row only first .   close  results   now do something a bit more imvolved .   abd  bbb  abc  tobytes  count  assertequals  kv   we got something back .   addcontent  getrow  closeanddelete  createnewhregion  r  addfamily  stoprow  getscanner  first
__label__nflaky verify  paths  test  ip  authority  with  default  port  myfs: /  / 127 . 0 . 0 . 1:123  fs  ips  authorities  get  verified  fs  verifypaths  testipauthoritywithdefaultport  myfs: /  / 127 . 0 . 0 . 1:123  fs  ips  authorities  getverifiedfs
__label__flaky cluster  assert  false  conf   / tmp / test  block  verification / file1  fs  wait  replication  read  the  file  to  trigger  report  bad  blocks  by  client  create  file  wait  active  rand  random  restart  data  node  its  replicas  assert  true  block  copy  bytes  dfs  test  util  dfs  config  keys  mini  dfs  cluster  and  we  should  get  all  the  replicas  corrupt  random  replica  of  block  restart  the  datanode  hoping  the  corrupt  block  to  be  reported  next  int  get  file  system  corrupt  replica  test  block  corruption  policy  set  long  io  utils  build  num  data  nodes  we  have  2  good  replicas  and  block  is  not  corrupt  all  block  replicas  corrupt  file1  get  first  block  open  shutdown  cluster  assertfalse  conf   / tmp / testblockverification / file1  fs  waitreplication   read the file to trigger reportbadblocks by client  createfile  waitactive  rand  random  restartdatanode   its replicas  asserttrue  block  copybytes  dfstestutil  dfsconfigkeys  minidfscluster   and we should get all the replicas   corrupt random replica of block   restart the datanode hoping the corrupt block to be reported  nextint  getfilesystem  corruptreplica  testblockcorruptionpolicy  setlong  ioutils  build  numdatanodes   we have 2 good replicas and block is not corrupt  allblockreplicascorrupt  file1  getfirstblock  open  shutdown
__label__nflaky handler  add  terse  logging  exceptions  assert  true  assert  false  is  terse  log  test  exceptions  handler  terse  handler  addterseloggingexceptions  asserttrue  assertfalse  isterselog  testexceptionshandlerterse
__label__flaky cluster  start  up  an  empty  node  with  the  same  capacity  and  on  nodegroup2  get  proxy  racks  num  of  datanodes  conf  sum  new  node  group  test  balancer  test  balancer  with  node  group  create  file  wait  active  create  proxy  create  conf  name  node  proxies  mini  dfs  cluster  with  node  group  total  capacity  rack1  nodegroup2  builder  nodegroup1  client  run  balancer  and  validate  results  capacities  rack0  nodegroup0  node  groups  capacity  start  data  nodes  fill  up  the  cluster  to  be  20 \ %  full  file  path  new  capacity  assert  equals  get  file  system  new  rack  run  balancer  simulated  capacities  total  used  space  set  node  groups  num  data  nodes  shutdown  get  uri  cluster   start up an empty node with the same capacity and on nodegroup2  getproxy  racks  numofdatanodes  conf  sum  newnodegroup  testbalancer  testbalancerwithnodegroup  createfile  waitactive  createproxy  createconf  namenodeproxies  minidfsclusterwithnodegroup  totalcapacity  rack1  nodegroup2  builder  nodegroup1  client   run balancer and validate results  capacities  rack0  nodegroup0  nodegroups  capacity  startdatanodes   fill up the cluster to be 20 \ % full  filepath  newcapacity  assertequals  getfilesystem  newrack  runbalancer  simulatedcapacities  totalusedspace  setnodegroups  numdatanodes  shutdown  geturi
__label__nflaky 1 . 1 . 1 . 1  2 . 2 . 2 . 2   3 . 3 . 3 . 3  set  proxy  users  3 . 3 . 3 . 3  refresh  super  user  groups  configuration  assert  false  conf  is  proxy  server  2 . 2 . 2 . 2  proxy  servers  assert  true  test  proxy  server  1 . 1 . 1 . 1  2 . 2 . 2 . 2  3 . 3 . 3 . 3  set  proxyusers  3 . 3 . 3 . 3  refreshsuperusergroupsconfiguration  assertfalse  conf  isproxyserver  2 . 2 . 2 . 2  proxyservers  asserttrue  testproxyserver
__label__flaky java . naming . provider . url#tcp: /  / broker . ${2}:61616  http: /  / unknown:9999 / fs  conf  server2  server1  server3  h  cat  accessor  service  get  get  jndi  properties  string  java . naming . factory . initial#org . apache . activemq . jndi .   active  mq  initial  context  factory;  rules  will  be  applied  hcat: /  / xyz . corp . dummy . com=java . naming . factory . initial#  dummy .   factory;  init  set  hcat: /  / hcatserver . blue . server . com:8020  get  jms  connection  info  get  conf  hcat: /  / xyz . corp . dummy . com  hcat  service  java . naming . provider . url#vm: /  / localhost ? broker . persistent=false  destroy  assert  equals  test  get  jms  connection  info  services  hcat: /  / ${1} . ${2} . server . com:8020=java . naming . factory . initial#  dummy .   factory;     java . naming . provider . url#tcp:localhost:61616  conn  info  java . naming . factory . initial#  dummy .   factory;java . naming . provider . url#tcp:localhost:61616  setup  services  for  h  catalog  jms  connection  url  will  map  to  default  java . naming . factory . initial#  dummy .   factory;java . naming . provider . url#tcp: /  / broker . blue:61616  default=java . naming . factory . initial#org . apache . activemq . jndi .   active  mq  initial  context  factory;  java . naming . provider . url#tcp: /  / broker . ${2}:61616  http: /  / unknown:9999 / fs  conf  server2  server1  server3  hcataccessorservice  get  getjndipropertiesstring  java . naming . factory . initial#org . apache . activemq . jndi . activemqinitialcontextfactory;   rules will be applied  hcat: /  / xyz . corp . dummy . com=java . naming . factory . initial#dummy . factory;  init  set  hcat: /  / hcatserver . blue . server . com:8020  getjmsconnectioninfo  getconf  hcat: /  / xyz . corp . dummy . com  hcatservice  java . naming . provider . url#vm: /  / localhost ? broker . persistent=false  destroy  assertequals  testgetjmsconnectioninfo  services  hcat: /  / ${1} . ${2} . server . com:8020=java . naming . factory . initial#dummy . factory;     java . naming . provider . url#tcp:localhost:61616  conninfo  java . naming . factory . initial#dummy . factory;java . naming . provider . url#tcp:localhost:61616  setupservicesforhcatalog  jmsconnectionurl   will map to default  java . naming . factory . initial#dummy . factory;java . naming . provider . url#tcp: /  / broker . blue:61616  default=java . naming . factory . initial#org . apache . activemq . jndi . activemqinitialcontextfactory;
__label__nflaky get  name  assert  false  get  our  class  path  timeout  rcsjm  override  output  so  we  can  capture  it  wait  or  timeout  fake  daemon  condition  assert  true  started  process1  collections  started  process2  set  output  fake  daemon  get  process  restart  timeout  duration   .   is  alive  get  active  process  equals  baos1  millis  baos2  getname  assertfalse  getourclasspath  timeout  rcsjm   override output so we can capture it  waitortimeout  fakedaemoncondition  asserttrue  startedprocess1  collections  startedprocess2  setoutput  fakedaemon  getprocess  restart  timeout  duration   .   isalive  getactiveprocess  equals  baos1  millis  baos2
__label__flaky cleaned  conts  attempt  set  level  unregister  app  attempt  assert  node  heartbeat  got  get  root  logger  cleaned  apps:  info  get  containers  to  cleanup  cleaned  apps  app  cont  received  conts  to  clean  log  get  app  attempt  id  conts  containers .   waiting  to  get  am  container  state  submit  app  allocate  size  get  applications  to  cleanup  stop  kick  the  scheduler  level  rm  127 . 0 . 0 . 1  root  logger  request  get  application  id  127 . 0 . 0 . 1:1234  register  app  attempt  request  for  containers  get  current  app  attempt  kick  the  scheduling  wait  for  state  sleep  nm1  send  am  launched  get  get  allocated  containers  am  container  is  cleaned  via  container  launcher  apps  resp  start  assert  equals  thread  register  node  waiting  to  get  cleanup  events .  .   cleaned  conts:  test  app  cleanup  rm  app  attempt  state  wait  count  log  manager  cleanedconts  attempt  setlevel  unregisterappattempt  assert  nodeheartbeat  got   getrootlogger   cleanedapps:   info  getcontainerstocleanup  cleanedapps  app  contreceived  contstoclean  log  getappattemptid  conts   containers .  waiting to get   am  containerstate  submitapp  allocate  size  getapplicationstocleanup  stop   kick the scheduler  level  rm  127 . 0 . 0 . 1  rootlogger  request  getapplicationid  127 . 0 . 0 . 1:1234  registerappattempt   request for containers  getcurrentappattempt   kick the scheduling  waitforstate  sleep  nm1  sendamlaunched  get  getallocatedcontainers   am container is cleaned via container launcher  apps  resp  start  assertequals  thread  registernode  waiting to get cleanup events .  .  cleanedconts:   testappcleanup  rmappattemptstate  waitcount  logmanager
__label__nflaky init  get  current  user  verify  token  get  connect  string  renew  token  zk  server  foo  unchecked  conf  create  token  token  test  renew  token  single  manager  verify  destroy  assert  assert  not  null  tm1  test_  retries  connect  string  get  secret  conf  user  group  information  init  getcurrentuser  verifytoken  getconnectstring  renewtoken  zkserver  foo  unchecked  conf  createtoken  token  testrenewtokensinglemanager  verifydestroy  assert  assertnotnull  tm1  test_retries  connectstring  getsecretconf  usergroupinformation
__label__flaky get  job  tracker  uri  get  name  <java>  get  status  create  context  test  exit0  submit  ok  action  xml  is  successful  assert  true  context  end  wait  for  <job-tracker>  get  data  is  completed  get  name  node  uri  <arg>exit0< / arg>  < / java>  ae  < / main-class>  < / job-tracker>  running  job  get  action  assert  equals  check  get  external  status  <name-node>  <main-class>  < / name-node>  assert  null  workflow  action  succeeded  submit  action  evaluate  is  complete  getjobtrackeruri  getname  <java>  getstatus  createcontext  testexit0submitok  actionxml  issuccessful  asserttrue  context  end  waitfor  <job-tracker>  getdata  iscompleted  getnamenodeuri  <arg>exit0< / arg>  < / java>  ae  < / main-class>  < / job-tracker>  runningjob  getaction  assertequals  check  getexternalstatus  <name-node>  <main-class>  < / name-node>  assertnull  workflowaction  succeeded  submitaction  evaluate  iscomplete
__label__nflaky chunk  size  update  data  size  type  crc  bytes  by  chunk  cell  size  assert  array  equals  crc  composer  digest  new  striped  crc  composer  crc  bytes  by  cell  digester  test  striped  byte  array  chunksize  update  datasize  type  crcbytesbychunk  cellsize  assertarrayequals  crccomposer  digest  newstripedcrccomposer  crcbytesbycell  digester  teststripedbytearray
__label__flaky conn  set  request  method  is_  security_  enabled   / v0 / admin / *  assert  true  json  content-type  collections  run  test  rest  constants  java . version  open  connection  contains  key  http  servlet  response  assert  equals  parse  get  input  stream  url  json  value  call  get  header  field  test  java  sys  props  get  get  response  code  create  url  starts  with  conn  setrequestmethod  is_security_enabled   / v0 / admin / *  asserttrue  json  content-type  collections  runtest  restconstants  java . version  openconnection  containskey  httpservletresponse  assertequals  parse  getinputstream  url  jsonvalue  call  getheaderfield  testjavasysprops  get  getresponsecode  createurl  startswith
__label__nflaky add  token  add  token  to  ugi  then  return  service2  unchecked  from  mockito  mocks  get  credentials  create  remote  user  assert  same  when  creds  get  service  check  that  ugi  wasn \  ' t  modified  someone  ugi  service  get  token  mock  check  tokens  test  get  creds  t1  t2  user  group  information  t3  addtoken   add token to ugi  thenreturn  service2  unchecked   from mockito mocks  getcredentials  createremoteuser  assertsame  when  creds  getservice   check that ugi wasn \  ' t modified  someone  ugi  service  gettoken  mock  checktokens  testgetcreds  t1  t2  usergroupinformation  t3
__label__flaky get  job  tracker  uri  get  name  is  main  successful  <java>  assert  false  get  status  create  context  action  xml  failed /   killed  is  successful  assert  true  launcher  mapper  <arg>ex< / arg>  context  end  wait  for  <job-tracker>  get  data  is  completed  get  name  node  uri  < / java>  ae  < / main-class>  < / job-tracker>  running  job  get  action  assert  equals  test  exception  submit  error  check  get  external  status  <name-node>  <main-class>  < / name-node>  assert  null  workflow  action  submit  action  evaluate  is  complete  getjobtrackeruri  getname  ismainsuccessful  <java>  assertfalse  getstatus  createcontext  actionxml  failed / killed  issuccessful  asserttrue  launchermapper  <arg>ex< / arg>  context  end  waitfor  <job-tracker>  getdata  iscompleted  getnamenodeuri  < / java>  ae  < / main-class>  < / job-tracker>  runningjob  getaction  assertequals  testexceptionsubmiterror  check  getexternalstatus  <name-node>  <main-class>  < / name-node>  assertnull  workflowaction  submitaction  evaluate  iscomplete
__label__nflaky a  contains  string  to  list  string  collection  util  assert  true  test  remove  matching  with  no  patterns  values  remove  matching  a  contains  stringtolist  stringcollectionutil  asserttrue  testremovematchingwithnopatterns  values  removematching
__label__flaky @  ::  close  trx  coord  client  get  store  get  time  local  oozie  2009-12-15  t01:00  z  2009-12-16  t01:00  z  could  not  update  db .   get  status  -test  coord  rerun-  c  get  coord  client  rerun  scope  get  begin  trx  coordinator  action  re  run  coord  action  num2  commit  trx  action  num1  coord-rerun-action2 . xml  rest  constants  print  stack  trace  store1  e  test  coord  rerun  date2  store  action  id2  add  record  to  job  table  job  id  action  id1  services  fail  coordinator  job  add  record  to  action  table  assert  not  same  0000000-  action1  action2  coord-rerun-action1 . xml  get  coordinator  action  @  ::  closetrx  coordclient  getstore  gettime  localoozie  2009-12-15t01:00z  2009-12-16t01:00z  could not update db .   getstatus  -testcoordrerun-c  getcoordclient  rerunscope  get  begintrx  coordinatoraction  reruncoord  actionnum2  committrx  actionnum1  coord-rerun-action2 . xml  restconstants  printstacktrace  store1  e  testcoordrerundate2  store  actionid2  addrecordtojobtable  jobid  actionid1  services  fail  coordinatorjob  addrecordtoactiontable  assertnotsame  0000000-  action1  action2  coord-rerun-action1 . xml  getcoordinatoraction
__label__nflaky de  en-  us  ninja  constant  language  when  assert  true  of  get  deutsch  english  lang  test  get  all  with  language  map  key  set  a_property_only_in_the_default  language  tor  -  das  ist  der  platzhalter:  {0}  get  all  optional  message_with_placeholder  then  return  contains  key  en  a_propert_with_commas  assert  equals  size  get  string  array  fr-  fr  ninja  properties  german  locale  testing:  us  locale  testing:  de  en-us  ninjaconstant  language  when  asserttrue  of  get  deutsch  english  lang  testgetallwithlanguage  map  keyset  a_property_only_in_the_defaultlanguage  tor - das ist der platzhalter: {0}  getall  optional  message_with_placeholder  thenreturn  containskey  en  a_propert_with_commas  assertequals  size  getstringarray  fr-fr  ninjaproperties   german locale testing:   us locale testing:
__label__flaky add  record  to  bundle  action  table  add  record  to  bundle  job  table  get  id  run  assert  equals  get  status  execute  services  job  id  runnable  ba1  test  bundle  status  transit  service  succeeded1  assert  not  null  get  equals  action1  job  job  action2  jpa  service  action3  bundle  evaluate  wait  for  addrecordtobundleactiontable  addrecordtobundlejobtable  getid  run  assertequals  getstatus  execute  services  jobid  runnable  ba1  testbundlestatustransitservicesucceeded1  assertnotnull  get  equals  action1  job  job  action2  jpaservice  action3  bundle  evaluate  waitfor
__label__nflaky set  handler  conn  user  foo  user  ok-user  via  proxyuser  foo  run   / bar  http  url  connection  assert   / foo / bar  foo_  user  ugi  of  get  test  http  ugi  context  read  lines  jetty   / *  dispatcher  type  get  jetty  url  user  group  information  ret   / foo  a  url  ok_  user  add  servlet  remoteuser=  open  connection  enum  set  start  :ugi=  set  context  path  assert  equals  create  jetty  server  create  remote  user  get  input  stream  url  realugi=  token  io  utils  do  as  stop  size  get  response  code  add  filter  :remoteuser=  sethandler  conn   user foo   user ok-user via proxyuser foo  run   / bar  httpurlconnection  assert   / foo / bar  foo_user  ugi  of  get  testhttpugi  context  readlines  jetty   / *  dispatchertype  getjettyurl  usergroupinformation  ret   / foo  aurl  ok_user  addservlet  remoteuser=  openconnection  enumset  start  :ugi=  setcontextpath  assertequals  createjettyserver  createremoteuser  getinputstream  url  realugi=  token  ioutils  doas  stop  size  getresponsecode  addfilter  :remoteuser=
__label__flaky 1  2  3  _test  get  actions  test  wf  actions  get  add  record  to  wf  job  table  workflow  action  add  record  to  wf  action  table  get  id  workflow  job  workflow  instance  job  1  2  3  _testgetactions  testwfactionsget  addrecordtowfjobtable  workflowaction  addrecordtowfactiontable  getid  workflowjob  workflowinstance  job
__label__nflaky localhost  localhost  verify  resolve  no  lookup  should  occur  host  verify  inet  address  test  resolver  loopback  addr  127 . 0 . 0 . 1   localhost  localhost  verifyresolve   no lookup should occur  host  verifyinetaddress  testresolverloopback  addr  127 . 0 . 0 . 1
__label__flaky action  num  nominal  time  test  coord  action  get  get  time  get  action  nominal  time  action  nomial  time  get  id  date  utils  clean  up  db  tables  add  record  to  coord  action  table  app  path  d1  add  record  to  coord  job  table  parse  date  oozie  tz  d2  action  xml  coordinator  job  coord  coord-action-get . xml  _test  get  action  for  dates  coordinator  action  job  get  coord  action  xml  get  fs  test  case  dir  actionnum  nominaltime  testcoordactionget  gettime  getactionnominaltime  actionnomialtime  getid  dateutils  cleanupdbtables  addrecordtocoordactiontable  apppath  d1  addrecordtocoordjobtable  parsedateoozietz  d2  actionxml  coordinatorjob  coord  coord-action-get . xml  _testgetactionfordates  coordinatoraction  job  getcoordactionxml  getfstestcasedir
__label__nflaky and  more  stuff  assert  buffer2  test  append  char  array  buffer  buffer1  to  string  assert  equals  append  stuff  stuff  and  more  stuff   and more stuff  assert  buffer2  testappendchararraybuffer  buffer1  tostring  assertequals  append  stuff  stuff and more stuff
__label__flaky add  operator  rows_  one  regular  expression  and  substring  filters  f  one  clear  kvs  filters  set  filter  use  must  pass  all  test  filter  list  qualifiers_  one  verify  scan  full  add  family  families   . +-2  values   . +  two . +  compare  op  verify  scan  no  early  out  add  operator  rows_one   regular expression and substring filters  f  one  clear  kvs  filters  setfilter   use must pass all  testfilterlist  qualifiers_one  verifyscanfull  addfamily  families   . +-2  values   . +two . +  compareop  verifyscannoearlyout
__label__nflaky  ? op=  renewdelegationtoken&token=  set  handler  unauthenticated  access  to  url  authenticated  access  to  url  conn  url  string  token   ? delegation=  dt   / bar  assert   / foo / bar  assert  not  null  context  dispatcher  type   / foo  delegation  token  access  to  url  cancel  delegation  token   nonauthenticated  access  to  url  open  connection  &op=  canceldelegationtoken&token=  set  context  path  create  jetty  server  get  input  stream  &delegation=  non  auth  url  to  external  form  stop   ? op=  canceldelegationtoken&token=  add  filter  &op=  renewdelegationtoken&token=  unauthenticated  access  to  get  delegation  token  set  request  method   / foo / bar ? authenticated=bar&op=  renewdelegationtoken&token=  mapper  auth  url  renewew  delegation  token   authenticated  access  to  url  http  url  connection  of  get  jetty   / *   / foo / bar ? authenticated=foo  cancel  delegation  token   authenticated  access  to  url  map  get  jetty  url  get  new  delegation  token  read  value  cancel  canceled  delegation  token   nonauthenticated  access  to  url  test  raw  http  calls  add  servlet   ? op=  getdelegationtoken  enum  set  renewew  delegation  token   authenticated  access  to  url   not  renewer  start  assert  equals  url  renewew  delegation  token   unauthenticated  access  to  url  put  get  response  code  &op=  getdelegationtoken&renewer=foo  delegation  token  and  authenticated  access  to  url  authenticated  access  to  get  delegation  token   ? op=renewdelegationtoken&token=  sethandler   unauthenticated access to url   authenticated access to url  conn  urlstring  token   ? delegation=  dt   / bar  assert   / foo / bar  assertnotnull  context  dispatchertype   / foo   delegation token access to url   cancel delegation token  nonauthenticated access to url  openconnection  &op=canceldelegationtoken&token=  setcontextpath  createjettyserver  getinputstream  &delegation=  nonauthurl  toexternalform  stop   ? op=canceldelegationtoken&token=  addfilter  &op=renewdelegationtoken&token=   unauthenticated access to get delegation token  setrequestmethod   / foo / bar ? authenticated=bar&op=renewdelegationtoken&token=  mapper  authurl   renewew delegation token  authenticated access to url  httpurlconnection  of  get  jetty   / *   / foo / bar ? authenticated=foo   cancel delegation token  authenticated access to url  map  getjettyurl   get new delegation token  readvalue   cancel canceled delegation token  nonauthenticated access to url  testrawhttpcalls  addservlet   ? op=getdelegationtoken  enumset   renewew delegation token  authenticated access to url  not renewer  start  assertequals  url   renewew delegation token  unauthenticated access to url  put  getresponsecode  &op=getdelegationtoken&renewer=foo   delegation token and authenticated access to url   authenticated access to get delegation token
__label__flaky get  service  component  hosts  cluster  handler  hi  set  last  heartbeat  time  set  hardware  profile  hm  set  hostname  set  node  status  get  cluster  map  hosts  to  cluster  centos5  set  component  name  iterator  get  service  component  name  handle  registration  reg  set  response  id  host  sch  get  clusters  for  host  get  host  add  add  cluster  host  state  get  server  version  am  heartbeat  will  expire  and  action  queue  will  be  flushed  test  heartbeat  loss  with  component  role  aq  set  component  status  set  agent  version  size  state  name  mock  statuses  add  service  component  hdp-0 . 1  shutdown  set  desired  stack  version  next  set  os  host  names  get  service  name  try  to  flip  statuses  back  set  cluster  name  system  sleep  sc  hostname1  add  service  centos5  set  service  name  cluster  name  host  status  persist  injector  clusters  set  timestamp  get  service  component  handle  heart  beat  cool  ambari  meta  info  start  service  assert  equals  add  service  component  host  service  name  add  host  get  service  set  status  thread  cs  integer  enqueue  set  os  type  get  state  current  time  millis  hdfs  is  client  component  set  state  hb  get  instance  don \  ' t  keep  marking  the  host  as  down  getservicecomponenthosts  cluster  handler  hi  setlastheartbeattime  sethardwareprofile  hm  sethostname  setnodestatus  getcluster  maphoststocluster  centos5  setcomponentname  iterator  getservicecomponentname  handleregistration  reg  setresponseid  host  sch  getclustersforhost  gethost  add  addcluster  hoststate  getserverversion  am   heartbeat will expire and action queue will be flushed  testheartbeatlosswithcomponent  role  aq  setcomponentstatus  setagentversion  size  state  name  mock  statuses  addservicecomponent  hdp-0 . 1  shutdown  setdesiredstackversion  next  setos  hostnames  getservicename   try to flip statuses back  setclustername  system  sleep  sc  hostname1  addservice  centos5  setservicename  clustername  hoststatus  persist  injector  clusters  settimestamp  getservicecomponent  handleheartbeat  cool  ambarimetainfo  start  service  assertequals  addservicecomponenthost  servicename  addhost  getservice  setstatus  thread  cs  integer  enqueue  setostype  getstate  currenttimemillis  hdfs  isclientcomponent  setstate  hb  getinstance   don \  ' t keep marking the host as down
__label__nflaky viewfs: /  /  /   vfs  get  child  file  system  test  list  located  file  status  conf  uri  mockfs: /  / foo /   get  raw  file  system  fs . mockfs . impl  mockfs: /  / foo / user  file  system  get  get  path  create  verify  list  located  status  mock  path  config  util  set  class  to  uri  mock  mount  to  string  mock  fs   / usermock  add  link  viewfs: /  /  /   vfs  getchildfilesystem  testlistlocatedfilestatus  conf  uri  mockfs: /  / foo /   getrawfilesystem  fs . mockfs . impl  mockfs: /  / foo / user  filesystem  get  getpath  create  verify  listlocatedstatus  mockpath  configutil  setclass  touri  mockmount  tostring  mockfs   / usermock  addlink
__label__flaky check  whether  transactions  are  rolled  back  or  not  expected  exception  due  to  commit  failure  but  didn \  ' t  get  any  prep  get  id  workflow  instance  action  get  cmd  deactivate  test  bulk  insert  updates  rollback  wf  bean  add  record  to  wf  job  table  get  error  code  assert  not  null  wf  update  cmd1  get  workflow  job  update  list  add  get  status  str  insert  list  expected  exception  but  didnt  get  any  wf  get  cmd  assert  equals  skip  commit  fault  injection  add  two  actions  to  insert  list  execute  set  status  fault  injection  1  services  fail  jpaee  2  workflow  action  org . apache . oozie . command .   skip  commit  fault  injection  set  system  property  true  create  workflow  action  action1  set  fault  injection  to  true   so  transaction  is  roll  backed  error  code  job  action2  add  to  update  list  status  should  not  be  running  jpa  service   check whether transactions are rolled back or not  expected exception due to commit failure but didn \  ' t get any  prep  getid  workflowinstance  actiongetcmd  deactivate  testbulkinsertupdatesrollback  wfbean  addrecordtowfjobtable  geterrorcode  assertnotnull  wfupdatecmd1  get  workflowjob  updatelist  add  getstatusstr  insertlist  expected exception but didnt get any  wfgetcmd  assertequals  skipcommitfaultinjection   add two actions to insert list  execute  setstatus  faultinjection  1  services  fail  jpaee  2  workflowaction  org . apache . oozie . command . skipcommitfaultinjection  setsystemproperty  true  createworkflowaction  action1   set fault injection to true  so transaction is roll backed  errorcode  job  action2   add to update list   status should not be running  jpaservice
__label__nflaky test  compressor  stream  assert  file  cleanup  after  test  case  assert  true  closed  shoud  be  true  test  close  close  delete  expected  io  exception  system  testcompressorstream  assert  file   cleanup after test case  asserttrue  closed shoud be true  testclose  close  delete  expected ioexception  system
__label__flaky sub  workflow  job  4  should  not  have  been  purged  subwf  job3  get  cmd  add  record  to  wf  action  table  workflow  instance  get  status  wf  action5  get  cmd  workflow  action  4  should  not  have  been  purged  wf  action1  get  cmd  assert  not  null  sub  workflow  action  1  should  not  have  been  purged  subwf  action3  get  cmd  wf  job  get  cmd  subwf  job2  get  cmd  subwf  action4  get  cmd  sub  workflow  job  2  should  not  have  been  purged  execute  workflow  action  2  should  not  have  been  purged  1  fail  2  3  4  workflow  action  5  sub  workflow  action  3  should  not  have  been  purged  wf  action2  get  cmd  workflow  action  5  should  not  have  been  purged  subwf  action5  subwf  job1  get  cmd  sub  workflow  action  2  should  not  have  been  purged  get  id  sub  workflow  job  5  should  not  have  been  purged  add  record  to  wf  job  table  for  neg  case  subwf  action5  get  cmd  subwf  job5  get  cmd  wf  job  subwf  action1  get  cmd  sub  workflow  action  5  should  not  have  been  purged  add  record  to  wf  job  table  sub  workflow  job  3  should  not  have  been  purged  get  workflow  job  should  not  have  been  purged  subwf  job1  workflow  job  subwf  job5  subwf  action1  workflow  action  3  should  not  have  been  purged  subwf  job4  subwf  action2  subwf  job3  subwf  action3  subwf  job2  subwf  action4  wf  action3  get  cmd  wf  action4  get  cmd  sub  workflow  action  4  should  not  have  been  purged  assert  equals  wf  action1  wf  action2  wf  action3  wf  action4  wf  action5  call  services  workflow  action  1  should  not  have  been  purged  test  purge  wf  with  sub  wf2  more  than  limit  sub  workflow  job  1  should  not  have  been  purged  subwf  action2  get  cmd  jpa  service  subwf  job4  get  cmd  subworkflow job 4 should not have been purged  subwfjob3getcmd  addrecordtowfactiontable  workflowinstance  getstatus  wfaction5getcmd  workflow action 4 should not have been purged  wfaction1getcmd  assertnotnull  subworkflow action 1 should not have been purged  subwfaction3getcmd  wfjobgetcmd  subwfjob2getcmd  subwfaction4getcmd  subworkflow job 2 should not have been purged  execute  workflow action 2 should not have been purged  1  fail  2  3  4  workflowaction  5  subworkflow action 3 should not have been purged  wfaction2getcmd  workflow action 5 should not have been purged  subwfaction5  subwfjob1getcmd  subworkflow action 2 should not have been purged  getid  subworkflow job 5 should not have been purged  addrecordtowfjobtablefornegcase  subwfaction5getcmd  subwfjob5getcmd  wfjob  subwfaction1getcmd  subworkflow action 5 should not have been purged  addrecordtowfjobtable  subworkflow job 3 should not have been purged  get  workflow job should not have been purged  subwfjob1  workflowjob  subwfjob5  subwfaction1  workflow action 3 should not have been purged  subwfjob4  subwfaction2  subwfjob3  subwfaction3  subwfjob2  subwfaction4  wfaction3getcmd  wfaction4getcmd  subworkflow action 4 should not have been purged  assertequals  wfaction1  wfaction2  wfaction3  wfaction4  wfaction5  call  services  workflow action 1 should not have been purged  testpurgewfwithsubwf2morethanlimit  subworkflow job 1 should not have been purged  subwfaction2getcmd  jpaservice  subwfjob4getcmd
__label__nflaky arg_  nofail  kdiag  test  k  diag  standalone  nofail  keylen  arg_  keylen  arg_nofail  kdiag  testkdiagstandalonenofail  keylen  arg_keylen
__label__flaky filepaths  cluster  write  something  to  file3  write  something  to  file2  write  something  to  file1  conf  dir  out2  check  to  see  if  opening  a  non-existent  file  triggers  a  fnf  out3  path   / wrwelkj  read  fully  out1  file  system  close  create  did  not  get  a  file  not  found  exception  for  non-existing  write  passed  previous  grace  period   should  still  running  set  grace  sleep  period  in  create  file2  create  file3  passed  grace  period  get  file  system  create  file1  write  something  dfs  num  data  nodes  get  name  node  port  millis  shutdown  test  dfs  client  is  listening  on .   in  this  case   it  is  localhost .   assert  false  hdfs: /  / 127 . 0 . 0 . 1:  fs  file  should  not  exist  for  test .   system  filepathstring  out  sleep  get  test  configuration  write  long  is  running  assert  true  within  grace  period  get  grace   / test / ip  address / file  close  file3  close  close  file2  close  file1  to  uri  assert  equals  uri  thread  buf  read  long  build  open  and  check  the  file  current  time  millis  create  a  file  exists   / test /   lease  checker / foo  file .   open  filepaths  cluster   write something to file3   write something to file2   write something to file1  conf  dir  out2   check to see if opening a non-existent file triggers a fnf  out3  path   / wrwelkj  readfully  out1  filesystem   close  create  did not get a filenotfoundexception for non-existing  write   passed previous grace period  should still running  setgracesleepperiod  in   create file2   create file3   passed grace period  getfilesystem   create file1   write something  dfs  numdatanodes  getnamenodeport  millis  shutdown  testdfsclient   is listening on .  in this case  it is localhost .   assertfalse  hdfs: /  / 127 . 0 . 0 . 1:  fs  file should not exist for test .   system  filepathstring  out  sleep  gettestconfiguration  writelong  isrunning  asserttrue   within grace period  get  grace   / test / ipaddress / file   close file3  close   close file2   close file1  touri  assertequals  uri  thread  buf  readlong  build   open and check the file  currenttimemillis   create a file  exists   / test / leasechecker / foo   file .   open
__label__nflaky encode  a  data  size  get  assert  equals  decode  in  map  put  out  map  bake_in_a_header_an_empty_value    encode  a  data  size  get  assertequals  decode  inmap  put  outmap  bake_in_a_header_an_empty_value
__label__flaky init  res   . dataout .   abc . unresolved  20120230  hcat: /  / hcat . server . com:5080 / mydb / clicks / datastamp=20120230;region=  us  coord  el  functions  ${coord:data  out  partition  value (  \  '   abc \  '   \  ' region \  '  ) }  test  data  out  partition  value  set  variable  coord-action-start  eval  eval  and  wrap  assert  true   . dataout .   abc  ${coord:data  out  partition  value (  \  '   abc \  '   \  ' datastamp \  '  ) }  equals  expr  boolean  us  init  res   . dataout . abc . unresolved  20120230  hcat: /  / hcat . server . com:5080 / mydb / clicks / datastamp=20120230;region=us  coordelfunctions  ${coord:dataoutpartitionvalue (  \  ' abc \  '   \  ' region \  '  ) }  testdataoutpartitionvalue  setvariable  coord-action-start  eval  evalandwrap  asserttrue   . dataout . abc  ${coord:dataoutpartitionvalue (  \  ' abc \  '   \  ' datastamp \  '  ) }  equals  expr  boolean  us
__label__nflaky  \ %bar \ %  begin   \ %foo \ %_ \ %bar \ %_ \ %baz \ %  end   \ %foo \ %_ \ %bar \ %_ \ %baz \ %  test  replace  tokens  win  env  vars  foo  pattern  assert  equals  zoo__zaz  put  zaz  begin  zoo__zaz  end  string  utils  replace  tokens   \ %baz \ %  baz  replacements  zoo   \ %foo \ %     \ %bar \ %  begin  \ %foo \ %_ \ %bar \ %_ \ %baz \ % end   \ %foo \ %_ \ %bar \ %_ \ %baz \ %  testreplacetokenswinenvvars  foo  pattern  assertequals  zoo__zaz  put  zaz  begin zoo__zaz end  stringutils  replacetokens   \ %baz \ %  baz  replacements  zoo   \ %foo \ %
__label__flaky conn  set  request  method  is_  security_  enabled   / v0 / admin / *  assert  true  get  json  content-type  collections  run  test  get  build  info  json  tags  rest  constants  get  property  open  connection  test  version  http  servlet  response  assert  equals  parse  get  input  stream  url  json  value  call  get  header  field  get  get  response  code  build  info  create  url  starts  with  conn  setrequestmethod  is_security_enabled   / v0 / admin / *  asserttrue  get  json  content-type  collections  runtest  getbuildinfo  jsontags  restconstants  getproperty  openconnection  testversion  httpservletresponse  assertequals  parse  getinputstream  url  jsonvalue  call  getheaderfield  get  getresponsecode  buildinfo  createurl  startswith
__label__nflaky try  to  add  the  same  token  through  configuration  and  file  expected  token1  token  path1  test  token  kind1  cred0  test  token  kind0  cred1  get  bytes  found1  found0  assert  array  equals  password  ugi  encode  to  url  string  expected  token0  user  group  information  copy  token  password  import  config  service1  generic  test  utils  write  token  storage  file  token  base64     service0   badtoken  common  configuration  keys  public  expected  token  test  token  service0  not  found:  test  token  import  service0  size  identity  import  config  reset  check  if  the  tokens  were  loaded  test  token  import  service1  get  randomized  test  dir  out  cred  dt . token  get  all  tokens  out  cred1  get  credentials  ugi1  expected  token  test  token  service1  not  found:  assert  true  identity  get  identifier  badfile  set  kind  test  import  tokens  from  config  work  dir  set  configuration  add  token  set  get  absolute  path  assert  equals  get  login  user  get  service  tokens:  token  add  a  token  from  a  file  set  service  equals  add  a  base64  token  to  string  config   try to add the same token through configuration and file  expectedtoken1  tokenpath1  testtokenkind1  cred0  testtokenkind0  cred1  getbytes  found1  found0  assertarrayequals  password  ugi  encodetourlstring  expectedtoken0  usergroupinformation  copytoken  passwordimportconfig  service1  generictestutils  writetokenstoragefile  tokenbase64     service0   badtoken  commonconfigurationkeyspublic  expected token testtokenservice0 not found:   testtokenimportservice0  size  identityimportconfig  reset   check if the tokens were loaded  testtokenimportservice1  getrandomizedtestdir  outcred  dt . token  getalltokens  outcred1  getcredentials  ugi1  expected token testtokenservice1 not found:   asserttrue  identity  getidentifier  badfile  setkind  testimporttokensfromconfig  workdir  setconfiguration  addtoken  set  getabsolutepath  assertequals  getloginuser  getservice  tokens:   token   add a token from a file  setservice  equals   add a base64 token  tostring  config
__label__flaky <execution>  lifo< / execution>  < / controls>  <datasets>  <coordinator-app  name= \ ""  name \ ""  frequency= \ ""${coord:days ( 1 ) } \ ""  start= \ ""2010-02-01  t01:00  z \ ""  end= \ ""2009-02-03  t23:59  z \ ""  timezone= \ ""  utc \ ""  conf  < / input-events>  get  status  app  path  xmlns= \ ""uri:oozie:coordinator:0 . 2 \ "">  <controls>  get  job  sc  < / property>< / configuration>  < / workflow>  < / action>  < / coordinator-app>  write  to  file  app  xml  get  error  code  assert  true  <property>  <name>input  b< / name>  <value>${coord:data  out (  \  '   local_  a \  '  ) }< / value>  file: /  /   get  test  case  dir  unit_  testing  test  basic  submit  with  start  time  after  end  time  <output-events>  <data-out  name= \ ""  local_  a \ ""  dataset= \ ""local_a \ "">  job  timezone= \ ""  utc \ "">  <uri-template>file: /  /  / tmp / coord / workflows / ${  year} / ${  day}< / uri-template>  < / dataset>  coordinator . xml  expected  to  catch  errors  due  to  incorrectly  specified  start  and  end  time  set  coordinator  start  time  cannot  be  greater  than  end  time .   <configuration>  <property>  <name>input  a< / name>  <value>${coord:data  in (  \  '   a \  '  ) }< / value>  < / property>  e  get  message  <dataset  name= \ ""local_a \ ""  frequency= \ ""${coord:days ( 7 ) } \ ""  initial-instance= \ ""2009-02-01  t01:00  z \ ""  assert  equals  call  oozie  client  fail  contains  get  test  user  < / datasets>  <input-events>  <instance>${coord:current ( -1 ) }< / instance>  < / data-out>  < / output-events>  <action>  <workflow>  <app-path>hdfs: /  /  / tmp / workflows / < / app-path>  <data-in  name= \ ""  a \ ""  dataset= \ ""a \ "">  <instance>${coord:latest ( 0 ) }< / instance>  < / data-in>  <dataset  name= \ ""a \ ""  frequency= \ ""${coord:days ( 7 ) } \ ""  initial-instance= \ ""2009-02-01  t01:00  z \ ""  error  code  file  <execution>lifo< / execution> < / controls> <datasets>   <coordinator-app name= \ ""name \ "" frequency= \ ""${coord:days ( 1 ) } \ "" start= \ ""2010-02-01t01:00z \ "" end= \ ""2009-02-03t23:59z \ "" timezone= \ ""utc \ ""   conf  < / input-events>   getstatus  apppath  xmlns= \ ""uri:oozie:coordinator:0 . 2 \ ""> <controls>   getjob  sc  < / property>< / configuration> < / workflow> < / action> < / coordinator-app>  writetofile  appxml  geterrorcode  asserttrue  <property> <name>inputb< / name> <value>${coord:dataout (  \  ' local_a \  '  ) }< / value>   file: /  /   gettestcasedir  unit_testing  testbasicsubmitwithstarttimeafterendtime  <output-events> <data-out name= \ ""local_a \ "" dataset= \ ""local_a \ "">   job  timezone= \ ""utc \ ""> <uri-template>file: /  /  / tmp / coord / workflows / ${year} / ${day}< / uri-template> < / dataset>   coordinator . xml  expected to catch errors due to incorrectly specified start and end time  set  coordinator start time cannot be greater than end time .   <configuration> <property> <name>inputa< / name> <value>${coord:datain (  \  ' a \  '  ) }< / value> < / property>   e  getmessage  <dataset name= \ ""local_a \ "" frequency= \ ""${coord:days ( 7 ) } \ "" initial-instance= \ ""2009-02-01t01:00z \ ""   assertequals  call  oozieclient  fail  contains  gettestuser  < / datasets> <input-events>   <instance>${coord:current ( -1 ) }< / instance> < / data-out> < / output-events> <action> <workflow> <app-path>hdfs: /  /  / tmp / workflows / < / app-path>   <data-in name= \ ""a \ "" dataset= \ ""a \ ""> <instance>${coord:latest ( 0 ) }< / instance> < / data-in>    <dataset name= \ ""a \ "" frequency= \ ""${coord:days ( 7 ) } \ "" initial-instance= \ ""2009-02-01t01:00z \ ""   errorcode  file
__label__nflaky testing  sequence  file  with  default  codec  log  successfully  tested  sequence  file  with  default  codec  test  zlib  sequence  file  compressed  seq  file  test  info  testing sequencefile with defaultcodec  log  successfully tested sequencefile with defaultcodec  testzlibsequencefile  compressedseqfiletest  info
__label__flaky get  failovers  occurred  proxy  provider  impl2  start  set  latch  enabled  assert  equals  impl1  retry  proxy  getting  a  proxy  will  now  wait  on  a  latch .   type  of  exception  to  fail  with  retry  policies  unreliable  create  failover  on  network  exception  join  t1  test  concurrent  method  failures  t2  getfailoversoccurred  proxyprovider  impl2  start  setlatchenabled  assertequals  impl1  retryproxy   getting a proxy will now wait on a latch .   typeofexceptiontofailwith  retrypolicies  unreliable  create  failoveronnetworkexception  join  t1  testconcurrentmethodfailures  t2
__label__nflaky dst  compact  codec  test  utils  channel  convert  put  assert  inbuf  assert  true  tmp  flip  s1  s2  is  completed  read  test  decoding  with  small  buffer  standard  charsets  has  remaining  clear  bytes  read  assert  equals  decoder  0123456789abcdef  byte  buffer  9  6  abcdef  0  allocate  5  01234  5  5678  metrics  dst  compact  codectestutils  channel  convert  put  assert  inbuf  asserttrue  tmp  flip  s1  s2  iscompleted  read  testdecodingwithsmallbuffer  standardcharsets  hasremaining  clear  bytesread  assertequals  decoder  0123456789abcdef  bytebuffer  9  6  abcdef  0      allocate  5  01234  5  5678  metrics
__label__flaky write  lock  got  async  close  exception  channel  executors  handler  latch  get  cause  sleep  uninterruptibly  write  exc  cause  another  thread  trying  to  write  to  block  assert  true  executor  get  await  lock  count  down  write  close  milliseconds  set  new  fixed  thread  pool  expected  give  enough  time  to  ensure  both  writes  start  blocking  store  completed  failed  byte  buffer  read  fail  allocate  test  async  close_write  future  uninterruptibles  shutdown  writelock  gotasynccloseexception  channel  executors  handlerlatch  getcause  sleepuninterruptibly  write  exc   cause another thread trying to write to block  asserttrue  executor  get  await  lock  countdown  write  close  milliseconds  set  newfixedthreadpool  expected   give enough time to ensure both writes start blocking  store  completed  failed  bytebuffer  read  fail  allocate  testasyncclose_write  future  uninterruptibles  shutdown
__label__nflaky set  future  ms  assert  false  source  executors  src  updater  sleep  updater  future  test  jmx  cache  update  race  condition  hit  error  get  reader  executor  time  unit  await  termination  injected  tags  shutdown  now  new  source  builder  jmx  cache .   schedule  at  fixed  rate  test  source  builder  new  scheduled  thread  pool  called .   set  jmx  info  cache  at  the  beginning  test  metric  cache  update  race  get  jmx  cache  ttl  thread  src  reader  cleanup  create  test  source  with  a  single  metric  counter  of  value  1 .   build  let  the  threads  do  their  work .   metrics  annotations  reader  future  source  adapter  has  error  jmx_  cache_  ttl  race_  test_  runtime  updater  executor  setfuture   ms  assertfalse  source  executors  srcupdater  sleep  updaterfuture  test jmx cache update race condition  hit error  get  readerexecutor  timeunit  awaittermination  injectedtags  shutdownnow  newsourcebuilder   jmx cache .   scheduleatfixedrate  test  sourcebuilder  newscheduledthreadpool   called .    set jmx info cache at the beginning  testmetriccacheupdaterace  getjmxcachettl  thread  srcreader   cleanup   create test source with a single metric counter of value 1 .   build   let the threads do their work .   metricsannotations  readerfuture  sourceadapter  haserror  jmx_cache_ttl  race_test_runtime  updaterexecutor
__label__flaky cancel  play  server  b  dispatch  next  response  has  nothing  left  to  wait  for .   force  requests  to  be  executed  serially .   assert  no  response  assert  body   / a  client .    / b  get  path  await  client  tag  request  b  request  a  character  receiver  take  request  get  dispatcher  assert  equals  set  max  requests  request  a  set  body  request  b  canceled  before  response  read  is  never  delivered  url  get  url  enqueue  build  set  dispatcher  to  string  yet  it  never  will .   cancel  play  server  b  dispatch  nextresponse   has nothing left to wait for .    force requests to be executed serially .   assertnoresponse  assertbody   / a   client .    / b  getpath  await  client  tag  requestb  requesta  character  receiver  takerequest  getdispatcher  assertequals  setmaxrequests  request a  setbody  request b  canceledbeforeresponsereadisneverdelivered  url  geturl  enqueue  build  setdispatcher  tostring   yet it never will . 
__label__nflaky slow  rpc  server  create  a  client  down  slow  rpc  testing  ping  second  fast  ping  slowrpc  conf  slow  rpc  should  not  have  finished1 .   waiting  for  slow  rpc  to  get  done .   system  sleep  now  the  slow  ping  should  be  able  to  be  executed  assert  true  test  slow  rpc  addr  testing  slow  rpc  first  fast  ping  start  slow  rpc  should  not  have  finished2 .   get  client  thread  is  done  thread  proxy  send  a  slow  rpc   which  won \  ' t  return  until  two  fast  pings  stop  verify  that  the  first  rpc  is  still  stuck  setup  test  server  create  a  server  with  two  handlers  slowrpc  server   create a client  down slow rpc testing  ping   second fast ping  slowrpc  conf  slow rpc should not have finished1 .   waiting for slow rpc to get done .   system  sleep   now the slow ping should be able to be executed  asserttrue  testslowrpc  addr  testing slow rpc   first fast ping  start  slow rpc should not have finished2 .   getclient  thread  isdone  thread  proxy   send a slow rpc  which won \  ' t return until two fast pings  stop   verify that the first rpc is still stuck  setuptestserver   create a server with two handlers
__label__flaky mock  task  get  job  updated  node  events  conf  when  allocator  assert  node  heartbeat  new  job  id  get  attempt  am  node  manager  get  the  assignment  dispatcher  attempt  id  app  get  node  id  get  container  get  app  attempt  id  then  return  create  req  mock  task  attempt  get  task  attempt  id  submit  app  mr  builder  utils  job  id  size  get  task  attempt  kill  events  get  attempt  id  mock  assigned  mark  nodes  bad  rm  test  updated  nodes  h1:1234  add  resources  to  scheduler  create  the  map  container  request  updated  nodes  are  reported  get  application  id  mock  job  submit  the  application  h1  get  current  app  attempt  get  rm  context  am  nm:1234  h2:1234  nm2  nm1  send  am  launched  assert  true  get  await  event  get  task  id  get  dispatcher  start  is  empty  clear  schedule  response  returns  updated  nodes  assert  equals  this  tells  the  scheduler  about  the  requests  app  attempt  id  no  updated  nodes  reported  schedule  register  node  send  request  get  updated  nodes  get  task  mocktask  getjobupdatednodeevents  conf  when  allocator  assert  nodeheartbeat  newjobid  getattempt  amnodemanager   get the assignment  dispatcher  attemptid  app  getnodeid  getcontainer  getappattemptid  thenreturn  createreq  mocktaskattempt  gettaskattemptid  submitapp  mrbuilderutils  jobid  size  gettaskattemptkillevents  getattemptid  mock  assigned   mark nodes bad  rm  testupdatednodes  h1:1234   add resources to scheduler   create the map container request   updated nodes are reported  getapplicationid  mockjob   submit the application  h1  getcurrentappattempt  getrmcontext  amnm:1234  h2:1234  nm2  nm1  sendamlaunched  asserttrue  get  await  event  gettaskid  getdispatcher  start  isempty  clear   schedule response returns updated nodes  assertequals   this tells the scheduler about the requests  appattemptid   no updated nodes reported  schedule  registernode  sendrequest  getupdatednodes  gettask
__label__nflaky not  a  service  init  incorrect  number  of  services  test  service  test  remove  service  assert  false  added  an  integer  as  a  service  service2  service1  assert  equals  service3  service  init  service3  service2  service1  remove  service  size  add  if  service  get  services  test  service  notaservice  init  incorrect number of services  testservice  testremoveservice  assertfalse  added an integer as a service  service2  service1  assertequals  service3  serviceinit  service3  service2  service1  removeservice  size  addifservice  getservices  testservice
__label__flaky play  http: /  / google . com /   server  path= \ "" / path \ "";  get  name  get  discard  domain= \ ""  android  80 443   set-  cookie2:  a= \ ""android \ "";  accept_  original_  server  cookies  get  max  age  get  get  cookies   / path / foo  get  path  get  comment  get  portlist  cookie  manager  get  cookie  store  get  comment  url   / path  get  version  a  add  header  cookie  test  quoted  attribute  values   \ "";  comment= \ ""this  cookie  is  delicious \ "";  assert  equals  set  default  secure;  get  domain  enqueue  get  value  discard;  get  port  size  get  cookie  domain  this  cookie  is  delicious  max-  age= \ ""60 \ "";  comment  url= \ ""http: /  / google . com /  \ "";  version= \ ""1 \ ""  cookie  handler  port= \ ""80 443   get  secure  play  http: /  / google . com /   server  path= \ "" / path \ "";   getname  getdiscard  domain= \ ""  android  80 443   set-cookie2: a= \ ""android \ "";   accept_original_server  cookies  getmaxage  get  getcookies   / path / foo  getpath  getcomment  getportlist  cookiemanager  getcookiestore  getcommenturl   / path  getversion  a  addheader  cookie  testquotedattributevalues   \ "";   comment= \ ""this cookie is delicious \ "";   assertequals  setdefault  secure;   getdomain  enqueue  getvalue  discard;   getport  size  getcookiedomain  this cookie is delicious  max-age= \ ""60 \ "";   commenturl= \ ""http: /  / google . com /  \ "";   version= \ ""1 \ ""  cookiehandler  port= \ ""80 443   getsecure
__label__nflaky gethgegwge  wg  aw  ib  ba  en  gwt  b  qk  neruzh  lk9  sr6  ic  m  bqg  aw  ibaketmb  eb  b  eh  u  z002p  hn  gzu / pur  z5m  oya  qt12v  hx  j2  t+  cwi8  k  test  service  principal  decode  g  ahamg9  o  qpu  reik0p  ck3  zs  hh  jz8q  mwduz  rz  hc4v  n  cg==  spnego  other  gri0sp9w3hc4  i  vm8afb3  ggm6  pg  r  iyy  g  nd  tz  k / p03v+z  a01  m  jh3htu  og  lkuov  gethgegwge  wg  aw  ib  ba  en  gwt  fwefnu  ex  f  lk  np  ta  ic  m  bqg  aw  ibaketmb  eb  b  eh  u  vf  ab  cw90a  g  vya  g9zd  ko  bs  dc  bra  ad  ag  e  ro  qmcaq  giga  a  eg  z23  qs  t1+16  t23ni  z002p  hn  gzu / pur  z5m  oya  qt12v  hx  j2  t+  cwi8=  krb5  default  tji  qw  k  jcke  z837m  xqau  rbf  jp  fc3  vlax  gf  nk  mfcr7  zk  wp  ga1  vzc3  pe  u  nczn2  d  vf  ab  c  wxv  y2  fsa  g9zd  ko  bs  dc  bra  ad  ag  e  ro  qmcaq  giga  a  eg  z23  qs  t1+16  t23ni  get  principal  yiiccqyg  kw  ybbqu  co  iib /   tcc  afmg  dtal  bgkqhki  g9x  ib  ag  kh  bamca  xaigg  hg  fgh5  dgg  hv  yf1  cw  x  pp2l1  jq373v  slq1k  bl6  t  xl+a  k  ls  z  yh  v  uj  kv  e7  auippclb  2t  o  vzgpj  fv  au /   de  tp  ig /   mig8o  amcar  gigb  q  egb  g  wnb  kl  v1oo7 / gz  t4hi /   q41  iqb7  wu  piw3  r  tk  ftwj  u9  p / o  f  abuj  g  pd8h / qk  cszro  ndv  hh  uk  pntu  oqh  f  bnt  mo  ji1u  fru0  fn13hh  psl  al4+o  aqp  v5s1  z6  e+  g2  vk  gx2+r  uf21ut  odlw  uk /   j5  ckf  biib3  gcc  adg  gc  sq  gs  ib3  eg  ec  ag  e  abo  i  bxz  cc  ac  og  aw  ib  ba  ed  ag  e  oogc  dbq  ag  ff2lu  dn  sx  ad  emo6  m8  lc42scs  yml  ng  u4i  l  jhuf4  y  lb7ueh790  hrb  b6  kdes71 /   gw  rivfrq  gwlvd  ghlcmhvc3  sjgb  awga2g  aw  ib  ea  ed  ag  e  boo  gg  bi  gd  b  wbzv  v1  r  gw  rivfrq  gwlsb2  nhb  ghvc3  sjgb  awga2g  aw  ib  ea  ed  ag  e  boo  gg  bi  gd  b  wbzv  v1  r  bilg  tq  n  ed  du  gv  bbfk  ja  rkl  n  gq  t /   iaouv6tl  gp  buc  xqu  r5  ud  pz  pp  uv  g  zi  vr  uu  g  ahamg9  o  qpu  reik0p  ck3  zs  hh  jz8q  mwduz  rz  hc4v  n  g  s  bi  li2 / mn3  bq  ne43gt94d  q8  vf  bix4n  j  cs  ynu  or  yx  l  jj  rsje+3  im  j  ns  sjqaf  di  pfj  pipf  olc7  v9  gl  wv  z  fyr5  nmjs  fwsp  kjx  yh /   fs  np  sv  tecf  gskjded9  t  zz  r  http / otherhost@  abcdefg .   org  yiib2  ayj  ko  z  ihvc  saqicaq  bugg  hhmii  bw6  ad  ag  e  fo  qmcaq6i  bw  mfacaaaa  cj  assert  equals  http / localhost@  example .   com  aaa  ao4  hr  yy  ho  mi  hlo  amcaq  wh  d  rs  lr  vh  btvbmrs5  dt02i  hd  aao  amcaq  ch  ez  ar  spnego  default  krb5  other  lpu8sme55  hffq  di / 0ak  w6  lwv / i  crpw  ik  z  py  z  pja  emw  lva  lu4  e8m0  ka3f  jk  pv  yl+35r2762j+  o  ew  z  rfcj4x  ck7j0m  u  tcx  lty  v  gxy  y9  ax+ljl5g  twz  rh  xc  jq0  t  aaa  ao4  hr  yy  ho  mi  hlo  amcaq  wh  d  rs  lqujdrevg  ry5  p  ukei  hd  aao  amcaq  ch  ez  ar  for  principals  with  the  default  realm   and  a  non-default  realm .   hx  m4zf  nsmz  r  fhdk5mo  jw6  aw  hu  rq  gj9hr  zg  tx  a2v  ob  in / tju+n / v  jv  ec  uv  w0f  hv /   gg  gex /   tcj  nh48k47  o  qa  s  bvz  c  bv  kad  ag  e  roo  g0  bi  gxe  chp3  tm  vt  wb  cd  f  go  gethgegwgewgawibbaengwtbqkneruzhlk9sr6icmbqgawibaketmbebbehu  z002phngzu / purz5moyaqt12vhxj2t+cwi8k  testserviceprincipaldecode  gahamg9oqpureik0pck3zshhjz8qmwduzrzhc4vncg==  spnegoother  gri0sp9w3hc4ivm8afb3ggm6pgriyygndtzk / p03v+za01mjh3htuoglkuov  gethgegwgewgawibbaengwtfwefnuexflknptaicmbqgawibaketmbebbehu  vfabcw90agvyag9zdkobsdcbraadageroqmcaqgigaaegz23qst1+16t23ni  z002phngzu / purz5moyaqt12vhxj2t+cwi8=  krb5default  tjiqwkjckez837mxqaurbfjpfc3vlaxgfnkmfcr7zkwpga1vzc3peunczn2d  vfabcwxvy2fsag9zdkobsdcbraadageroqmcaqgigaaegz23qst1+16t23ni  getprincipal  yiiccqygkwybbqucoiib / tccafmgdtalbgkqhkig9xibagkhbamcaxaigghg  fgh5dgghvyf1cwxpp2l1jq373vslq1kbl6txl+aklszyhvujkve7auippclb  2tovzgpjfvau / detpig / mig8oamcargigbqegbgwnbklv1oo7 / gzt4hi / q41  iqb7wupiw3rtkftwju9p / ofabujgpd8h / qkcszrondvhhukpntuoqhfbntmo  ji1ufru0fn13hhpslal4+oaqpv5s1z6e+g2vkgx2+ruf21utodlwuk / j5ckf  biib3gccadggcsqgsib3egecageaboibxzccacogawibbaedageoogcdbqag  ff2ludnsxademo6m8lc42scsymlngu4iljhuf4ylb7ueh790hrbb6kdes71 /   gwrivfrqgwlvdghlcmhvc3sjgbawga2gawibeaedagebooggbigdbwbzvv1r  gwrivfrqgwlsb2nhbghvc3sjgbawga2gawibeaedagebooggbigdbwbzvv1r  bilgtqneddugvbbfkjarklngqt / iaouv6tlgpbucxqur5udpzppuvgzivruu  gahamg9oqpureik0pck3zshhjz8qmwduzrzhc4vn  gsbili2 / mn3bqne43gt94dq8vfbix4njcsynuoryxljjrsje+3imjnssjqaf  dipfjpipfolc7v9glwvzfyr5nmjsfwspkjxyh / fsnpsvtecfgskjded9tzzr  http / otherhost@abcdefg . org  yiib2ayjkozihvcsaqicaqbugghhmiibw6adagefoqmcaq6ibwmfacaaaacj  assertequals  http / localhost@example . com  aaaao4hryyhomihloamcaqwhdrslrvhbtvbmrs5dt02ihdaaoamcaqchezar  spnegodefault  krb5other  lpu8sme55hffqdi / 0akw6lwv / icrpwikzpyzpjaemwlvalu4e8m0ka3fjkpv  yl+35r2762j+oewzrfcj4xck7j0mutcxltyvgxyy9ax+ljl5gtwzrhxcjq0t  aaaao4hryyhomihloamcaqwhdrslqujdrevgry5pukeihdaaoamcaqchezar   for principals with the default realm  and a non-default realm .   hxm4zfnsmzrfhdk5mojw6awhurqgj9hrzgtxa2vobin / tju+n / vjvecuvw0f  hv / gggex / tcjnh48k47oqasbvzcbvkadageroog0bigxechp3tmvtwbcdfgo
__label__flaky check  coord  actions  get  time  date  utils  parse  date  oozie  tz  2009-03-06  t10:00  z  add  record  to  job  table  call  job  id  pause  time  -test  action  mater-  c  0000000-  start  time  end  time  2009-03-06  t10:04  z  test  action  mater  with  pause  time1  2009-03-06  t10:14  z  checkcoordactions  gettime  dateutils  parsedateoozietz  2009-03-06t10:00z  addrecordtojobtable  call  jobid  pausetime  -testactionmater-c  0000000-  starttime  endtime  2009-03-06t10:04z  testactionmaterwithpausetime1  2009-03-06t10:14z
__label__nflaky handler  request  get  time  jwt  alternate  authentication  should  not  have  thrown  a  servlet  exception:  public  key  set  public  key  jwt  redirect  authentication  handler  when  put  alternate  authentication  should  not  have  thrown  a  authentication  exception  se  jowt  service_  url  assert  get  cookies  get  jwt  get  user  name  get  request  url  test  custom  cookie  name  jwt  init  cookie  then  return  get  properties  encode  redirect  url  get  message  alternate  authenticate  assert  equals  props  token  fail  private  key  serialize  bob  mockito  response  mock  handler  request  gettime  jwt  alternateauthentication should not have thrown a servletexception:   publickey  setpublickey  jwtredirectauthenticationhandler  when  put  alternateauthentication should not have thrown a authenticationexception  se  jowt  service_url  assert  getcookies  getjwt  getusername  getrequesturl  testcustomcookienamejwt  init  cookie  thenreturn  getproperties  encoderedirecturl  getmessage  alternateauthenticate  assertequals  props  token  fail  privatekey  serialize  bob  mockito  response  mock
__label__flaky test  coord  re  run2  end_  points  is_  security_  enabled  oozie  url  run  app  path  assert  true  get  create  servlet_  classes  close  run  test  app  mock  coordinator  engine  service  coordinator . xml  rest  constants  get  context  url  assert  equals  get  file  system  -rerun  args  call  1  -date  -oozie  2009-12-15  t01:00  z::2009-12-16  t01:00  z  mkdirs  job  get  fs  test  case  dir  testcoordrerun2  end_points  is_security_enabled  oozieurl  run  apppath  asserttrue  get  create  servlet_classes  close  runtest  app  mockcoordinatorengineservice  coordinator . xml  restconstants  getcontexturl  assertequals  getfilesystem  -rerun  args  call  1  -date  -oozie  2009-12-15t01:00z::2009-12-16t01:00z  mkdirs  job  getfstestcasedir
__label__nflaky get  bytes  transferred  codec  test  utils  channel  times  assert  flush  verify  dump  write  argument  matchers  standard  charsets  length  assert  equals  encoder  -  any  stuff--m  mockito  outbuf  much  more  stuff  test  coding  fragment  buffering  channel  saturated2  metrics  spy  wrap  stuff  getbytestransferred  codectestutils  channel  times  assert  flush  verify  dump  write  argumentmatchers  standardcharsets  length  assertequals  encoder  -  any  stuff--m  mockito  outbuf  much more stuff  testcodingfragmentbufferingchannelsaturated2  metrics  spy  wrap  stuff
__label__flaky a  l1  a:1-  l  a:2-  l  a:1-  u  a:2-  u  l2  start  test  read  lock  assert  equals  sb  thread  sleep  trim  finish  to  string    a  l1  a:1-l a:2-l a:1-u a:2-u  l2  start  testreadlock  assertequals  sb  thread  sleep  trim  finish  tostring
__label__nflaky test  negative  cache  entries  expire  put  user1  in  negative  cache .   assert  false  conf  as  list  advance  advance  fake  timer  timer  cache  groups  add  assert  true  get  negative  cache  did  not  throw  io  exception  :  failed  to  obtain  groups  get  groups  user1  can  be  added  to  negative  cache  user2  no  groups  found  for  user  common  configuration  keys  e  check  if  user2  exists  in  negative  cache  advance  timer .   only  user2  should  be  present  in  negative  cache .   groups  refresh  generic  test  utils  fake  group  mapping  put  user2  in  negative  cache  check  if  user1  exists  in  negative  cache  fail  set  long  ensure  that  stale  entries  are  removed  from  negative  cache  every  2  seconds  contains  advance  timer .   even  user2  should  not  be  present  in  negative  cache .   my  groups  add  to  black  list  assert  exception  contains  arrays  from  fake  group  mapping .   testnegativecacheentriesexpire   put user1 in negative cache .   assertfalse  conf  aslist  advance   advance fake timer  timer  cachegroupsadd  asserttrue  getnegativecache  did not throw ioexception : failed to obtain groups  getgroups  user1   can be added to negative cache  user2  no groups found for user  commonconfigurationkeys  e   check if user2 exists in negative cache   advance timer .  only user2 should be present in negative cache .   groups  refresh  generictestutils  fakegroupmapping   put user2 in negative cache   check if user1 exists in negative cache  fail  setlong   ensure that stale entries are removed from negative cache every 2 seconds  contains   advance timer .  even user2 should not be present in negative cache .   mygroups  addtoblacklist  assertexceptioncontains  arrays   from fakegroupmapping . 
__label__flaky request  test  client  status  content  type  post  pattern  set  max  total  get  status  remove  set  entity  n  string  entity  io  reactor  status  assert  assert  not  null  expected  pattern  get  create  buffer  http  version  localhost  add  address  set  default  max  per  route  start  count  is  empty  assert  equals  generate  text  get  entity  execute  target  entity  utils  rnd  test  pattern  generator  generate  count  get  port  future  response  to  string  test  http  posts  http10  append  queue  entity  request  test client status  contenttype  post  pattern  setmaxtotal  getstatus  remove  setentity  nstringentity  ioreactorstatus  assert  assertnotnull  expectedpattern  get  create  buffer  httpversion  localhost  add  address  setdefaultmaxperroute  start  count  isempty  assertequals  generatetext  getentity  execute  target  entityutils  rndtestpatterngenerator  generatecount  getport  future  response  tostring  testhttppostshttp10  append  queue  entity
__label__nflaky server  make  a  really  slow  call .   sleep  sleeps  for  1000ms  before  get  client2  new  empty  request  sleep_  duration  make  sure  we  never  called  into  log  slow  rpc  routine .   ensure  rpc  metrics  are  updated  sleep  get  rpc  slow  calls  client  ping2  make  10  k  fast  calls  after  set  log  slow  rpc  is  greater  than  assert  that  disable  slow  rpc  logging  new  sleep  request  get  processing  sample  count  rpc  metrics  test  ensure  no  log  if  disabled  is  equal  to  get  rpc  metrics  server   make a really slow call .  sleep sleeps for 1000ms  before  getclient2  newemptyrequest  sleep_duration   make sure we never called into log slow rpc routine .    ensure rpc metrics are updated  sleep  getrpcslowcalls  client  ping2   make 10 k fast calls  after  setlogslowrpc  isgreaterthan  assertthat   disable slow rpc  logging  newsleeprequest  getprocessingsamplecount  rpcmetrics  testensurenologifdisabled  isequalto  getrpcmetrics
__label__flaky cluster  sub  run  cmd  get  localized  message  destination  files  conf  run  f1  f2  fs  f3  delete  system  f4  f5  copy  to  local2  f6  exception  raised  from  dfs  shell . run  -copy  to  local  assert  true  test_  root_  dir  root  close  is  file  e  create  tree  *  assert  equals  get  file  system  set  conf  not  a  hdfs:  dfs  nosuchfile  args  build  shell  num  data  nodes  verify  copying  the  tree  test  copy  to  local  copying  failed .   exists  localroot  copy  to  local  localroot2  get  uri  shutdown  is  directory  cluster  sub  runcmd  getlocalizedmessage   destination files  conf  run  f1  f2  fs  f3  delete  system  f4  f5  copytolocal2  f6  exception raised from dfsshell . run   -copytolocal  asserttrue  test_root_dir  root  close  isfile  e  createtree  *  assertequals  getfilesystem  setconf  not a hdfs:   dfs  nosuchfile  args  build  shell  numdatanodes   verify copying the tree  testcopytolocal  copying failed .   exists  localroot  copytolocal  localroot2  geturi  shutdown  isdirectory
__label__nflaky get  name  get  checksum  file  fsdos  the  data  file  should  be  moved:  data  file  length  check  that  the  files  exist  in  the  new  location  where  they  were  moved:  bad  files  dir  get  file  status  create  checksum  fsdis  check  the  the  checksum  file  is  created  and  not  empty:  set  writable  path  to  file  pathname  accept  data  file  name  contains  mkdirs  file  sys  write  utf  dir1files  file  util  is  directory  checksum  file  length  foo  data  path  data  file  found  bad  files  assert  true  get  len  retry  is  necessary  checksum  file  found  test  report  checksum  failure  close  list  files  the  checksum  file  should  be  moved:  corrupted  data  data  fsdis  to  uri  report  checksum  failure  length  dir2  can  write  bad  file  dir1  checksum  path   . crc  equals  corrupted  files  storage:  exists  open  base  starts  with  getname  getchecksumfile  fsdos   the data file should be moved:  datafilelength   check that the files exist in the new location where they were moved:  badfilesdir  getfilestatus  create  checksumfsdis   check the the checksum file is created and not empty:  setwritable  pathtofile  pathname  accept  datafilename  contains  mkdirs  filesys  writeutf  dir1files  fileutil  isdirectory  checksumfilelength  foo  datapath  datafilefound  badfiles  asserttrue  getlen  retryisnecessary  checksumfilefound  testreportchecksumfailure  close  listfiles   the checksum file should be moved:  corrupteddata  datafsdis  touri  reportchecksumfailure  length  dir2  canwrite  badfile  dir1  checksumpath   . crc  equals   corrupted files storage:  exists  open  base  startswith
__label__flaky 1  2  3  _test  get  actions  test  wf  actions  get  add  record  to  wf  job  table  workflow  action  add  record  to  wf  action  table  get  id  workflow  job  workflow  instance  job  1  2  3  _testgetactions  testwfactionsget  addrecordtowfjobtable  workflowaction  addrecordtowfactiontable  getid  workflowjob  workflowinstance  job
__label__nflaky file  system  test  helper  file: /  /  / tmp / dir  foo  bar  test  rename  across  fs   / new  dir / dir  foo  rename  mkdirs   / tmp / dir  foo  bar  f  sys  is  dir  filesystemtesthelper  file: /  /  / tmp / dirfoobar  testrenameacrossfs   / newdir / dirfoo  rename  mkdirs   / tmp / dirfoobar  fsys  isdir
__label__flaky cluster  delete  on  exit  successful .   conf  fs  create  file  system  simulated  storage  set  delete  on  exit  flag  on  files .   localfs  assert  true  file  system  close  stream  write  file  close  delete  on  exit  filestatus2 . dat  still  exists  inspite  of  delet  on  exit  set .   write  to  files  and  close .   purposely   do  not  close  file2 .   filestatus . dat  get  file  system  delete  on  exit:  created  files .   reopen  file  system  and  verify  that  file  does  not  exist .   stm2  stm3  test  delete  on  exit  io  utils  stm1  build  get  local  file2  filestatus3 . dat  file3  exists  simulated  fs  dataset  file1  shutdown  set  boolean  disappear .   cluster  deleteonexit successful .   conf  fs  createfile  system  simulatedstorage   set delete on exit flag on files .   localfs  asserttrue  filesystem  closestream  writefile  close  deleteonexit     filestatus2 . dat   still exists inspite of deletonexit set .    write to files and close .  purposely  do not close file2 .   filestatus . dat  getfilesystem  deleteonexit: created files .    reopen file system and verify that file does not exist .   stm2  stm3  testdeleteonexit  ioutils  stm1  build  getlocal  file2  filestatus3 . dat  file3  exists  simulatedfsdataset  file1  shutdown  setboolean   disappear . 
__label__nflaky prepare  test  coding  direct  buffer_10x4_erasure_of_d2_d4_p0  test  coding  prepare  testcodingdirectbuffer_10x4_erasure_of_d2_d4_p0  testcoding
__label__flaky cluster  the  block  now  has  sufficient  #  replicas   across  racks  test  reduce  repl  factor  due  to  rejoin  respects  rack  policy  ns  racks  not  on  the  restarted  datanode  as  that  would  violate  the  rack  policy .   dm  conf   / rack2  get  block  manager  wait  for  replication   / rack1  fs  create  file  rack2  wait  active  *  test  that  when  the  excess  replicas  of  a  block  are  reduced  due  to  *  a  node  re-joining  the  cluster  the  rack  policy  is  not  violated .   get  datanode  manager  get  stop  data  node  dfs  test  util  b  get  data  nodes  start  data  nodes  get  conf  file  path  to  heartbeat  by  stopping  it  and  calling  remove  datanode .   assert  equals  dn  id  get  file  system  data  node  available  and  only  2  replicas  required )  .   replication_  factor  get  name  node  datanodes   / test  file  last  datanode  is  on  a  different  rack  size  build  remove  datanode  num  data  nodes  create  a  file  with  one  block  get  first  block  shutdown  get  datanode  id  get  namesystem  cluster   the block now has sufficient # replicas  across racks  testreducereplfactorduetorejoinrespectsrackpolicy  ns  racks   not on the restarted datanode as that would violate the rack policy .   dm  conf   / rack2  getblockmanager  waitforreplication   / rack1  fs  createfile  rack2  waitactive       * test that when the excess replicas of a block are reduced due to     * a node re-joining the cluster the rack policy is not violated .        getdatanodemanager  get  stopdatanode  dfstestutil  b  getdatanodes  startdatanodes  getconf  filepath   to heartbeat by stopping it and calling removedatanode .   assertequals  dnid  getfilesystem  datanode   available and only 2 replicas required )  .   replication_factor  getnamenode  datanodes   / testfile   last datanode is on a different rack  size  build  removedatanode  numdatanodes   create a file with one block  getfirstblock  shutdown  getdatanodeid  getnamesystem
__label__nflaky  .  .  .   x .    .  .  .   xx   .  .   x .  .   xxxxx   .  .  .  .   x   .   xx .  .   x .  .    .  .   xx .    .  .   xxx   .   x .  .  .   lo .   test  123 .   test  high  level  encode  string   .   xx .   x  xxx .  .   x .  .  .  .   xxxx .   xx .   x  xx .   x  xx .   x  xxx .   xxx .  .   xx .  .   x  lo .  .  . x  test  high  level  encode  a .   b .   ab  cd  efg   .  .  .  .  .    .  .  .   xx  xxx .  .   xx .  .   x   .  .  .  .  .   x .   x .   x   .  .  .  .  .   x .   x .  .    .  .  .  .  .   x .   x .  .    .  .  .   x .    .  .  .   xx   .  .   x .  .    .  .  .  .  .   x .   x .  .   xxxx .   xx .   x  09  uag  ^160  meuciqc0s  ys /   hp  kxn  belr1u  b85  r20  ooqqw  f  ga0q2u  ei  lorem  ipsum .    \  '   l \  '   l /   l   \  ' o \  '   p /   s   \  '  .    \  '   u /   s   \  '   t \  '    \  ' e \  '    \  ' s \  '    \  ' t \  '   d /   l   \  '    \  '    \  ' 1 \  '    \  ' 2 \  '    \  ' 3 \  '    \  '  .  \  '    \  '   a \  '   p /   s   \  '  .    \  '   l /   l  b  d /   l   \  '  .  \  '   uses  binary /   shift  rather  than  lower /   shift  to  save  two  bits .   ygh6ut  a  ig  ll1a  bvm4  eot  qt  mqqyh9  m2  z3  dp4qn  a / fw  wu  q+  m8  l3  v8  u=  necessary  to  keep  the  bitcount  so  low .    .  .  .   x .    .  .  .  .  .    .  .  .   xx  xxx .  .    .  .  .   xx  xxxx .   xx .   x   \  '   l \  '   l /   l   \  ' o \  '    \  ' r \  '    \  ' e \  '    \  ' m \  '    \  '    \  '    \  ' i \  '    \  ' p \  '    \  ' s \  '    \  ' u \  '    \  ' m \  '   d /   l   \  '  .  \  '    \  '   a \  '    \  '   b \  '    \  '   c \  '   b /   s  =1   \  ' d \  '    \  '   e \  '    \  '   f \  '    \  '   g \  '    .   xx .   x  xxx .  .   x .  .  .  .    .  .  .  .  .    .  .  .   xx  xxx .  .   x .   x .   x   .  .   xx .   x .   x .  .   x .   x .   x  xxxx .    .  .  .   x   .  .   xx   .   x .  .    .   x .   x  xx .   x  p /   s   \  '  .    \  '   l /   l   \  ' x \  '   p /   s   \  ' : \  '   p /   s   \  '  /  \  '   p /   s   \  '  /  \  '    \  ' a \  '    \  ' b \  '    \  ' c \  '   p /   s   \  '  /  \  '   d /   l   \  '  .  \  '    \  '   l \  '   l /   l   \  ' o \  '   d /   l   \  '  .  \  '    \  '  .  \  '    \  '  .  \  '   u /   l  l /   l   \  ' x \  '    .   xx .   x  xxx .  .   x .  .  .  .   x .  .   xx   .  .   xx .    .   xxx .    .  .  .  .   x   .   x .   x .   x .  .  .   x  x .   x .  .   x .   xx .    .   xxx .   xxxx .   xx .   x   .   x: /  / abc /  .   found  on  an  airline  boarding  pass .   several  stretches  of  binary  shift  are   .  .  . x .   .  .  . xx  .  . x .  .  xxxxx  .  .  .  . x  . xx .  . x .  .   .  . xx .   .  . xxx  . x .  .  .   lo .  test 123 .   testhighlevelencodestring   . xx . x xxx .  .  x .  .  .  .  xxxx .  xx . x xx . x xx . x xxx .  xxx .  .  xx .  . x  lo .  .  . x  testhighlevelencode  a .  b .   abcdefg   .  .  .  .  .   .  .  . xx xxx .  .  xx .  . x  .  .  .  .  .  x . x . x  .  .  .  .  .  x . x .  .   .  .  .  .  .  x . x .  .   .  .  . x .   .  .  . xx  .  . x .  .   .  .  .  .  .  x . x .  .  xxxx .  xx . x  09  uag    ^160meuciqc0sys / hpkxnbelr1ub85r20ooqqwfga0q2uei  lorem ipsum .     \  ' l \  '   l / l    \  ' o \  '    p / s    \  '  .   \  '   u / s    \  ' t \  '     \  ' e \  '     \  ' s \  '     \  ' t \  '     d / l    \  '   \  '    \  ' 1 \  '    \  ' 2 \  '    \  ' 3 \  '    \  '  .  \  '     \  ' a \  '   p / s    \  '  .   \  '  l / l    b    d / l     \  '  .  \  '    uses binary / shift rather than lower / shift to save two bits .   ygh6utaigll1abvm4eotqtmqqyh9m2z3dp4qna / fwwuq+m8l3v8u=   necessary to keep the bitcount so low .    .  .  . x .   .  .  .  .  .   .  .  . xx xxx .  .   .  .  . xx xxxx .  xx . x    \  ' l \  '   l / l    \  ' o \  '     \  ' r \  '     \  ' e \  '     \  ' m \  '     \  '   \  '     \  ' i \  '     \  ' p \  '     \  ' s \  '     \  ' u \  '     \  ' m \  '    d / l    \  '  .  \  '     \  ' a \  '     \  ' b \  '     \  ' c \  '    b / s    =1     \  ' d \  '       \  ' e \  '     \  ' f \  '     \  ' g \  '    . xx . x xxx .  .  x .  .  .  .   .  .  .  .  .   .  .  . xx xxx .  .  x . x . x  .  . xx .  x . x .  .  x . x . x  xxxx .   .  .  . x  .  . xx  . x .  .   . x . x xx . x   p / s    \  '  .   \  '   l / l    \  ' x \  '    p / s    \  ' : \  '    p / s    \  '  /  \  '    p / s    \  '  /  \  '     \  ' a \  '     \  ' b \  '     \  ' c \  '    p / s    \  '  /  \  '    d / l    \  '  .  \  '     \  ' l \  '   l / l    \  ' o \  '    d / l    \  '  .  \  '    \  '  .  \  '    \  '  .  \  '   u / l  l / l    \  ' x \  '    . xx . x xxx .  .  x .  .  .  .  x .  . xx  .  . xx .   . xxx .   .  .  .  . x  . x . x .  x .  .  . x x . x .  .  x . xx .   . xxx .  xxxx .  xx . x   .  x: /  / abc /  .    found on an airline boarding pass .   several stretches of binary shift are
__label__flaky cluster  recent  opcode  offsets:   (  \  \ d+ \  \ s* ) {4}$  conf  get  file  wait  active  error  message  contains  opcodes  message  get  fs  image  num_  data_  nodes  write  expected  error  message  fs  edit  log  op  codes  format  get  file  system  matches  get  op  code  fail  namesystem  should  exist:  num  data  nodes  start  a  cluster  mkdirs  file  sys  get  storage  shutdown  next  rwf  name  node  dir  type  rw  seek  find  latest  edits  log  edit  file  sd  should  not  be  able  to  start  assert  true  fsimage  close  dir  iterator  e  test  display  recent  edit  log  op  codes  length  get  message  ^  error  replaying  edit  log  at  offset   \  \ d+  file  len  build  exists   / tmp / tmp  corrupt  the  edits  file .   fs  image  test  util  get  namesystem  cluster  recent opcode offsets:  (  \  \ d+ \  \ s* ) {4}$  conf  getfile  waitactive  error message contains opcodes message  getfsimage  num_data_nodes  write  expectederrormessage  fseditlogopcodes  format  getfilesystem  matches  getopcode  fail  namesystem  should exist:   numdatanodes   start a cluster  mkdirs  filesys  getstorage  shutdown  next  rwf  namenodedirtype  rw  seek  findlatesteditslog  editfile  sd  should not be able to start  asserttrue  fsimage  close  diriterator  e  testdisplayrecenteditlogopcodes  length  getmessage  ^error replaying edit log at offset  \  \ d+    filelen  build  exists   / tmp / tmp   corrupt the edits file .   fsimagetestutil  getnamesystem
__label__nflaky checksum  file  checksum  stream  get  checksum  file  now  reading  the  file  should  fail  with  a  checksum  exception  get  bytes  get  raw  file  system  testtruncatedcrc  telling  it  not  to  verify  checksums   should  avoid  issue .   assert  true  test_  root_  dir  fout  create  did  not  throw  a  checksum  exception  when  reading  truncated  write  close  replace  stream  raw  fs  read  in  the  checksum  testing  truncation  read  set  verify  checksum  str  now  rewrite  the  checksum  file  with  the  last  byte  missing  fail  buf  local  fs  test  path  crc  file  read  file  test  truncated  checksum  equals  to  string  open  checksumfile  checksumstream  getchecksumfile   now reading the file should fail with a checksumexception  getbytes  getrawfilesystem  testtruncatedcrc   telling it not to verify checksums  should avoid issue .   asserttrue  test_root_dir  fout  create  did not throw a checksumexception when reading truncated   write  close  replacestream  rawfs   read in the checksum  testing truncation  read  setverifychecksum  str   now rewrite the checksum file with the last byte missing  fail  buf  localfs  testpath  crc file  readfile  testtruncatedchecksum  equals  tostring  open
__label__flaky loader  wait  finish  new  file  invalidate  staging  task  latch  callback  latch  file  cache  executor  f2  start  the  original  uploads  copy  to  file  random  stream  file  get  staging  cache  stats  assert  true  executor  uploader  finished  invalidate  staging  root  count  down  id_  prefix  create  executor  get  if  present  info  cache  log  get  absolute  path  bytes  f  threads  accepted  assert  cache  stats  scheduled  executor  invalidate  closer  after  execute  latch  folder  assert  null  staging   \ %  stage  stats  provider  assert  file  starting  invalidate  staging  register  loader  waitfinish  newfile  invalidatestaging  tasklatch  callbacklatch  filecacheexecutor  f2   start the original uploads  copytofile  randomstream  file  getstagingcachestats  asserttrue  executor  uploader  finished invalidatestaging  root  countdown  id_prefix   create executor  getifpresent  info  cache  log  getabsolutepath            bytes   f  threads  accepted  assertcachestats  scheduledexecutor  invalidate  closer  afterexecutelatch  folder  assertnull   staging  \ %   stage  statsprovider  assertfile  starting invalidatestaging  register
__label__nflaky thread  add  appender  check  that  start  method  is  idempotent  start  lossy  async  appender  async  appender  base   thread  addappender  checkthatstartmethodisidempotent  start  lossyasyncappender  asyncappenderbase
__label__flaky test  basic  submit  <execution>  lifo< / execution>  < / controls>  <datasets>  var-app-name  check  coord  jobs  conf  < / input-events>  <coordinator-app  name= \ ""${app  name}-foo \ ""  frequency= \ ""${coord:days ( 1 ) } \ ""  start= \ ""2009-02-01  t01:00  z \ ""  end= \ ""2009-02-03  t23:59  z \ ""  timezone= \ ""  utc \ ""  get  concurrency  xmlns= \ ""uri:oozie:coordinator:0 . 2 \ "">  <controls>  < / property>< / configuration>  < / workflow>  < / action>  < / coordinator-app>  assert  not  null  file: /  /   get  test  case  dir  unit_  testing  <output-events>  <data-out  name= \ ""  local_  a \ ""  dataset= \ ""local_a \ "">  timezone= \ ""  utc \ "">  <uri-template>file: /  /  / tmp / coord / workflows / ${  year} / ${  day}< / uri-template>  < / dataset>  oozie . service . coord . default . concurrency  oozie . service . coord . normal . default . timeout  <configuration>  <property>  <name>input  a< / name>  <value>${coord:data  in (  \  '   a \  '  ) }< / value>  < / property>  <dataset  name= \ ""local_a \ ""  frequency= \ ""${coord:days ( 7 ) } \ ""  initial-instance= \ ""2009-02-01  t01:00  z \ ""  oozie  client  job  id  get  int  < / datasets>  <input-events>  -  c  <dataset  name= \ ""a \ ""  frequency= \ ""${coord:days ( 7 ) } \ ""  initial-instance= \ ""2009-02-01  t01:00  z \ ""  job  file  var-app-name-foo  app  path  substring  sc  write  to  file  app  xml  <property>  <name>input  b< / name>  <value>${coord:data  out (  \  '   local_  a \  '  ) }< / value>  get  timeout  get  coordinator . xml  get  app  name  set  get  conf  app  name  length  assert  equals  call  services  get  test  user  <instance>${coord:current ( -1 ) }< / instance>  < / data-out>  < / output-events>  <action>  <workflow>  <app-path>hdfs: /  /  / tmp / workflows / < / app-path>  <data-in  name= \ ""  a \ ""  dataset= \ ""a \ "">  <instance>${coord:latest ( 0 ) }< / instance>  < / data-in>  testbasicsubmit  <execution>lifo< / execution> < / controls> <datasets>   var-app-name  checkcoordjobs  conf  < / input-events>   <coordinator-app name= \ ""${appname}-foo \ "" frequency= \ ""${coord:days ( 1 ) } \ "" start= \ ""2009-02-01t01:00z \ "" end= \ ""2009-02-03t23:59z \ "" timezone= \ ""utc \ ""   getconcurrency  xmlns= \ ""uri:oozie:coordinator:0 . 2 \ ""> <controls>   < / property>< / configuration> < / workflow> < / action> < / coordinator-app>  assertnotnull  file: /  /   gettestcasedir  unit_testing  <output-events> <data-out name= \ ""local_a \ "" dataset= \ ""local_a \ "">   timezone= \ ""utc \ ""> <uri-template>file: /  /  / tmp / coord / workflows / ${year} / ${day}< / uri-template> < / dataset>   oozie . service . coord . default . concurrency  oozie . service . coord . normal . default . timeout  <configuration> <property> <name>inputa< / name> <value>${coord:datain (  \  ' a \  '  ) }< / value> < / property>   <dataset name= \ ""local_a \ "" frequency= \ ""${coord:days ( 7 ) } \ "" initial-instance= \ ""2009-02-01t01:00z \ ""   oozieclient  jobid  getint  < / datasets> <input-events>   -c  <dataset name= \ ""a \ "" frequency= \ ""${coord:days ( 7 ) } \ "" initial-instance= \ ""2009-02-01t01:00z \ ""   job  file  var-app-name-foo  apppath  substring  sc  writetofile  appxml  <property> <name>inputb< / name> <value>${coord:dataout (  \  ' local_a \  '  ) }< / value>   gettimeout  get  coordinator . xml  getappname  set  getconf  appname  length  assertequals  call  services  gettestuser  <instance>${coord:current ( -1 ) }< / instance> < / data-out> < / output-events> <action> <workflow> <app-path>hdfs: /  /  / tmp / workflows / < / app-path>   <data-in name= \ ""a \ "" dataset= \ ""a \ ""> <instance>${coord:latest ( 0 ) }< / instance> < / data-in>
__label__nflaky get  failovers  occurred  proxy  provider  impl2  start  assert  equals  impl1  retry  proxy  type  of  exception  to  fail  with  retry  policies  unreliable  create  failover  on  network  exception  join  t1  test  concurrent  method  failures  t2  getfailoversoccurred  proxyprovider  impl2  start  assertequals  impl1  retryproxy  typeofexceptiontofailwith  retrypolicies  unreliable  create  failoveronnetworkexception  join  t1  testconcurrentmethodfailures  t2
__label__flaky location:   /   play  server   / 0  request  add  header  receiver  redirecting  to   /   assert  code  set  response  code  set  body   / 20  url  enqueue  get  url  assert  body  success !   build  await  client  follow20  redirects  location:  /   play  server   / 0  request  addheader  receiver  redirecting to  /   assertcode  setresponsecode  setbody   / 20  url  enqueue  geturl  assertbody  success !   build  await  client  follow20redirects
__label__nflaky get_  all_  groups_  cmd  test  static  mapping  assume  not  windows  put  hash  bi  map  u  map  |  cut  -d:  -f1 3  echo   \ ""hdfs:*:11501:hrt_hdfs  uid  static  map  mapred:x:497  get  create  g  map  atm  hdfs:x:11501:10787:  grid  distributed  file  system: / home / hdfs: / bin / bash \ ""  group  inverse  mapred2:x:498 \ ""  get_  all_  users_  cmd  assert  equals  mapred2  shell  based  id  mapping  hdfs  :  maps  for  id  to  name  map  echo   \ ""atm:x:1000:1000:  aaron  t .   myers   : / home / atm: / bin / bash  user  mapred  gid  static  map  update  map  internal  get_all_groups_cmd  teststaticmapping  assumenotwindows  put  hashbimap  umap   | cut -d: -f1 3  echo  \ ""hdfs:*:11501:hrt_hdfs    uidstaticmap  mapred:x:497    get  create  gmap  atm  hdfs:x:11501:10787:grid distributed file system: / home / hdfs: / bin / bash \ ""  group  inverse  mapred2:x:498 \ ""  get_all_users_cmd  assertequals  mapred2  shellbasedidmapping  hdfs  :   maps for id to name map  echo  \ ""atm:x:1000:1000:aaron t .  myers   : / home / atm: / bin / bash    user  mapred  gidstaticmap  updatemapinternal
__label__flaky format  date  expires:  last-  modified:  headers  add  header  get  headers  last  modified  date  if-  modified-  since:  contains  assert  true  time  unit  cache  control  no  cache  and  expiration  date  in  the  future  assert  conditionally  cached  conditional  request  cache-  control:  no-cache  formatdate  expires:   last-modified:   headers  addheader  getheaders  lastmodifieddate  if-modified-since:   contains  asserttrue  timeunit  cachecontrolnocacheandexpirationdateinthefuture  assertconditionallycached  conditionalrequest  cache-control: no-cache
__label__nflaky interval  is  1  hours   so  we  just  test  if  these  metrics  exist .   read  write  disk  validator  write  latency3600s  num  ops  write  latency3600s50th  percentile  latency  micros  get  file  read  quantiles  get  metrics  get  estimator  source  write  latency864000s  num  ops  last  failure  time  metrics  of  file  read  is  not  right  system  get  file  write  quantiles  collector  read  latency3600s50th  percentile  latency  micros  check  status  assert  read  write  disk  validator  metrics  get  get  records  read  latency864000s  num  ops  assert  metric  test  read  write  disk  validator  test . build . data  get  count  write  latency86400s  num  ops  get  property  failure  count  metrics  records  ms  count  read  write  disk  validator  assert  equals  read  latency3600s  num  ops  test  dir  the  count  number  of  estimator  in  mutable  quantiles  metric  disk  validator  factory  get  source  to  string  get  instance  get  metric  source  name  read  latency86400s  num  ops  assert  metric  not  null  metrics  of  file  write  is  not  right   interval is 1 hours  so we just test if these metrics exist .   readwritediskvalidator  writelatency3600snumops  writelatency3600s50thpercentilelatencymicros  getfilereadquantiles  getmetrics  getestimator  source  writelatency864000snumops  lastfailuretime  metrics of file read is not right  system  getfilewritequantiles  collector  readlatency3600s50thpercentilelatencymicros  checkstatus  assert  readwritediskvalidatormetrics  get  getrecords  readlatency864000snumops  assertmetric  testreadwritediskvalidator  test . build . data  getcount  writelatency86400snumops  getproperty  failurecount  metricsrecords  ms  count  readwritediskvalidator  assertequals  readlatency3600snumops  testdir  the count number of estimator in mutablequantiles  metric  diskvalidatorfactory  getsource  tostring  getinstance  getmetric  sourcename  readlatency86400snumops  assertmetricnotnull  metrics of file write is not right
__label__flaky bb  kills  a  b  add  node  def  get  transient  var  enters  workflow  instance  get  status  as  list  wf  exits  test  node  context  end  fails  aa  a  b  one  set  var  start  assert  equals  ta  tb  1  size  <worklfow-app / >  get  var  arrays  job  set  transient  var  bb  kills  a  b  addnode  def  gettransientvar  enters  workflowinstance  getstatus  aslist  wf  exits  testnodecontext  end  fails  aa  a  b  one  setvar  start  assertequals  ta  tb  1  size  <worklfow-app / >  getvar  arrays  job  settransientvar
__label__nflaky test  get  valid  indexes  check  valid  indexes  num  inputs  chunk  size  coder  util  inputs  get  valid  indexes  assert  equals  valid  indexes  testgetvalidindexes   check valid indexes  numinputs  chunksize  coderutil  inputs  getvalidindexes  assertequals  validindexes
__label__flaky init  ${coord:date  offset (  \ ""2009-09-08  t23:59  z \ ""   2    \ ""  day \ "" ) }  2009-09-10  t23:59  z  coord  el  functions  assert  equals  coord-action-start  ${coord:date  offset (  \ ""2009-09-08  t23:59  z \ ""   1    \ ""  year \ "" ) }  coord-job-submit-data  eval  eval  and  wrap  2010-09-08  t23:59  z  ${coord:date  offset (  \ ""2009-09-08  t23:59  z \ ""   -1    \ ""  day \ "" ) }  2009-09-07  t23:59  z  expr  test  date  offset  init  ${coord:dateoffset (  \ ""2009-09-08t23:59z \ ""  2   \ ""day \ "" ) }  2009-09-10t23:59z  coordelfunctions  assertequals  coord-action-start  ${coord:dateoffset (  \ ""2009-09-08t23:59z \ ""  1   \ ""year \ "" ) }  coord-job-submit-data  eval  evalandwrap  2010-09-08t23:59z  ${coord:dateoffset (  \ ""2009-09-08t23:59z \ ""  -1   \ ""day \ "" ) }  2009-09-07t23:59z  expr  testdateoffset
__label__nflaky assert  null  test  get  non  existing  produces  no  npe  manager  create  template  engine  manager  non / existing  get  template  engine  for  content  type  assertnull  testgetnonexistingproducesnonpe  manager  createtemplateenginemanager  non / existing  gettemplateengineforcontenttype
__label__flaky cluster  dfs  config  keys  seed  num_  of_  datanodes  write  file1  expected  write  file2  block_  size  write  file3  conf  get  file  system  test  fs  output  summer  set  int  next  bytes  rand  set  long  file  build  num  data  nodes  file  sys  close  bytes_  per_  checksum  shutdown  try . dat  cluster  dfsconfigkeys  seed  num_of_datanodes  writefile1  expected  writefile2  block_size  writefile3  conf  getfilesystem  testfsoutputsummer  setint  nextbytes  rand  setlong  file  build  numdatanodes  filesys  close  bytes_per_checksum  shutdown  try . dat
__label__nflaky value  x  write  a  key / value  first  compression  get  name  key  y  skip  key  x  value  y  get  bytes  cannot  add  key / value  after  start  adding  meta  blocks .   add  more  key / value  dummy  fail  out  meta  close  output  assert  test  x  prepare  meta  block  create  a  new  metablock  writer  test  failure  write  record  after  meta  block  write  close  append  valuex   write a key / value first  compression  getname  keyy  skip  keyx  valuey  getbytes  cannot add key / value after start adding meta blocks .    add more key / value  dummy  fail  outmeta  closeoutput  assert  testx  preparemetablock   create a new metablock  writer  testfailurewriterecordaftermetablock  write  close  append
__label__flaky jms  topic  service  bab  add  record  to  bundle  action  table  cab  get  user  add  record  to  wf  action  table  =  workflow   get  id  workflow  instance  get  topic  add  record  to  coord  action  table  setup  services  for  topic  coord  coord-action-for-action-input-check . xml  add  record  to  wf  job  table  as  no  default  is  specified   user  will  be  considered  as  topic  get  coordinator  action  wab  cjb  bjb  workflow  job  job  init  set  get  bundle  action  id  print  stack  trace  get  conf  workflow  e  =coord  add  record  to  bundle  job  table  get  message  destroy  jms  topic  service  assert  equals  services  add  record  to  coord  job  table  fail  get  value  services  1  coordinator  job  workflow  action  wfj  test  mixed  topic2  jmstopicservice  bab  addrecordtobundleactiontable  cab  getuser  addrecordtowfactiontable   = workflow   getid  workflowinstance  gettopic  addrecordtocoordactiontable  setupservicesfortopic  coord  coord-action-for-action-input-check . xml  addrecordtowfjobtable   as no default is specified  user will be considered as topic  get  coordinatoraction  wab  cjb  bjb  workflowjob  job  init  set  getbundleactionid  printstacktrace  getconf  workflow  e  =coord  addrecordtobundlejobtable  getmessage  destroy  jmstopicservice  assertequals  services  addrecordtocoordjobtable  fail  getvalue  services  1  coordinatorjob  workflowaction  wfj  testmixedtopic2
__label__nflaky list  keys  glarch  =baz  clean  up  to  be  a  good  citizen  list  out  run  abc=def  attributes:  foo=bar  foo  =  bar  test  attributes  simple  creation  test  keyattr2  create  keyattr3  keyattr1  keyattr4  foo=bar  delete  key  =bar  abc=def  glarch=baz  legal:  attribute  is  a   value  is  b=c  negative  test  -  repeated  attributes  should  fail  rc  contains  -provider  -attr  reset  not  in  attribute  =  value  form  =  test  several  attrs  together .  .  .   foo  attributes:  a=b=c   .  .  . and  list  to  see  that  we  have  the  attr  keyattr1  has  been  assert  true  a=b=c  jceks  provider   .  .  . and  list  to  ensure  they \  ' re  there .   negative  tests:  no  attribute  out  content  foo=glarch  ks  assert  equals  no  attribute  or  value  set  conf  foo=bar  args1  args2  to  string  args3  successfully  created  args4  listkeys   glarch =baz     clean up to be a good citizen   listout  run  abc=def  attributes: foo=bar  foo = bar  testattributes   simple creation test   keyattr2  create  keyattr3  keyattr1  keyattr4  foo=bar  deletekey  =bar  abc=def  glarch=baz   legal: attribute is a  value is b=c    negative test - repeated attributes should fail   rc  contains  -provider  -attr  reset   not in attribute = value form   =   test several attrs together .  .  .    foo  attributes: a=b=c    .  .  . and list to see that we have the attr   keyattr1 has been   asserttrue  a=b=c  jceksprovider    .  .  . and list to ensure they \  ' re there .     negative tests: no attribute   outcontent  foo=glarch  ks  assertequals   no attribute or value   setconf  foo=bar  args1  args2  tostring  args3  successfully created  args4
__label__flaky get  definition  submit  job  def  reader  end . error  conf  error  job  id1  engine  assert  not  null  get  test  case  dir   / workflow . xml  file: /  /   workflow . xml  ok  ok  test  job  definition  a  external-status  set  wf-ext-schema-valid . xml  oozie  client  io  utils  get  test  user  t  signal-value  copy  char  stream  get  resource  as  reader  writer  file  getdefinition  submitjob  def  reader  end . error  conf  error  jobid1  engine  assertnotnull  gettestcasedir   / workflow . xml  file: /  /   workflow . xml  ok  ok  testjobdefinition  a  external-status  set  wf-ext-schema-valid . xml  oozieclient  ioutils  gettestuser  t  signal-value  copycharstream  getresourceasreader  writer  file
__label__nflaky compare  ret2  get  test  string  ret1  compare  to  num_  iterations  compare  two  strings  by  looking  at  their  binary  formats  out2  reset  output  buffer  equvalence  of  data  output  buffers  out3  equivalence  of  different  txt  objects   same  content  str1  out1  str2  write  get  data  get  long  string  assert  equals  convert  to  texts  compare  two  strings  comparator  test  compare  txt2  txt3  txt1  reset  get  length  generate  two  random  strings  serialize  them  compare  ret2  getteststring  ret1  compareto  num_iterations   compare two strings by looking at their binary formats  out2   reset output buffer  equvalence of data output buffers  out3  equivalence of different txt objects  same content  str1  out1  str2  write  getdata  getlongstring  assertequals   convert to texts   compare two strings  comparator  testcompare  txt2  txt3  txt1  reset  getlength   generate two random strings   serialize them
__label__flaky coord  action  get  cmd  get  current  dateafter  incrementing  in  months  get  id  date  utils  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  assert  not  null  get  coordinator  action  action  end  current  date  plus  month  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  call  coordinator  job  services  coord  job  get  cmd  coord-action-get . xml  test  coord  kill  success1  job  jpa  service  coordactiongetcmd  getcurrentdateafterincrementinginmonths  getid  dateutils  getstatus  addrecordtocoordactiontable  parsedateoozietz  assertnotnull  get  coordinatoraction  action  end  currentdateplusmonth  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  call  coordinatorjob  services  coordjobgetcmd  coord-action-get . xml  testcoordkillsuccess1  job  jpaservice
__label__nflaky creation  expiration  test  light  weight  cache  check  size  limit  test  size  limit  data  size  next  int  check  size  limit  test  randomized  creation  expiration  with  zero  access  expiration  access  expiration  test  randomized  creation / access  expiration  periods  ran  modulus  creationexpiration  testlightweightcache  checksizelimit   test size limit  datasize  nextint  check  sizelimit   test randomized creation expiration with zero access expiration  accessexpiration   test randomized creation / access expiration periods  ran  modulus
__label__flaky app  name2  assert  equals  create  filter  list  list  execute  test  get  sla  events  for  app  name  filter  list  app2  services  sla  events  get  cmd  appname  size  assert  not  null  get  jpa  service  appname2  assertequals  createfilterlist  list  execute  testgetslaeventsforappname  filterlistapp2  services  slaeventsgetcmd  appname  size  assertnotnull  get  jpaservice
__label__nflaky cookie  yummy  argument  argument  captor  do  nothing  cookie  set  domain  capture  is  assert  that  when  unset  cookie  get  value  abstract  context  add  cookie  get  max  age  build  domain  context  builder  for  class  unset  cookie  adds  cookie  with  max  age  zero  spy  cookie  yummy  argument  argumentcaptor  donothing  cookie  setdomain  capture  is  assertthat  when  unsetcookie  getvalue  abstractcontext  addcookie  getmaxage  build  domain  context  builder  forclass  unsetcookieaddscookiewithmaxagezero  spy
__label__flaky de  conn   / app  post  put  get  job  set  request  property  create  workflow . xml   / v0 / jobs  run  test (  \ "" / jobs \ ""   base  jobs  servlet . class   is_  security_  enabled   new  callable<  void> (  )   {  open  connection  conf1  get  file  system  params  get  input  stream  get  dag  engine  json  value  oozie  client  size  reset  set  do  output  job  conf  set  request  method  is_  security_  enabled  assert  false  write  xml  test  submit  app  path  fs  assert  true  get  content-type  job  xml  path  run  test  sr  json  tags  set  rest  constants  get  conf  undef  mock  dag  engine  service  http  servlet  response  assert  equals  parse  services  url  call  services  get  test  user  obj  get  response  code  wf  count  create  url  to  string  get  output  stream  get  fs  test  case  dir    de  conn   / app  post  put  getjob  setrequestproperty  create  workflow . xml   / v0 / jobs   runtest (  \ "" / jobs \ ""  basejobsservlet . class  is_security_enabled  new callable<void> (  )  {  openconnection  conf1  getfilesystem  params  getinputstream  getdagengine  jsonvalue  oozieclient  size  reset  setdooutput  jobconf  setrequestmethod  is_security_enabled  assertfalse  writexml  testsubmit  apppath  fs  asserttrue  get  content-type  jobxmlpath  runtest  sr  jsontags  set  restconstants  getconf  undef  mockdagengineservice  httpservletresponse  assertequals  parse  services  url  call  services  gettestuser  obj  getresponsecode  wfcount  createurl  tostring  getoutputstream  getfstestcasedir
__label__nflaky current  har  block  b  get  offset  do  some  tests  where  start  ==  0  assert  that  case  4:  range  starts  and  ends  in  current  har  block  case  5:  range  starts  before  current  har  block  and  ends  after  case  2:  range  starts  in  current  har  block  and  ends  after  case  6:  range  starts  in  current  har  block  and  ends  after  fix  block  locations  case  8:  range  starts  and  ends  in  current  har  block  test  fix  block  locations  har  file  system  get  length  is  zero  test  case  from  jira  mapreduce-1752  case  1:  range  starts  before  current  har  block  and  ends  after  is  equal  to  now  try  a  range  where  start  ==  3   current har block  b  getoffset   do some tests where start == 0  assertthat   case 4: range starts and ends in current har block   case 5: range starts before current har block and ends after   case 2: range starts in current har block and ends after   case 6: range starts in current har block and ends after  fixblocklocations   case 8: range starts and ends in current har block  testfixblocklocations  harfilesystem  getlength  iszero   test case from jira mapreduce-1752   case 1: range starts before current har block and ends after  isequalto   now try a range where start == 3
__label__flaky play  play  it  back  header  entries  verify  the  peer  received  what  was  expected  type_  rst_  stream  timeout  system  accept  frame  elapsed  nanos  stream  open  stream  count  type_  headers  peer  nano  time  get  response  headers  time  unit  connection  to  millis  get  response  headers  times  out  take  frame  banana  b  assert  equals  rst_  stream  fail  syn_  stream  spdy3  read  timeout  new  stream  start  nanos  play   play it back  headerentries   verify the peer received what was expected  type_rst_stream  timeout  system  acceptframe  elapsednanos  stream  openstreamcount  type_headers  peer  nanotime  getresponseheaders  timeunit  connection  tomillis  getresponseheaderstimesout  takeframe  banana  b  assertequals   rst_stream  fail   syn_stream  spdy3  readtimeout  newstream  startnanos
__label__nflaky test0132021  data  compressed15bit  weight1750  expected  compressed  gtin900123456798908  header   ( 01 ) 90012345678908 ( 3202 ) 001750  assert  correct  binary  string  test0132021  data  compressed15bitweight1750  expected  compressedgtin900123456798908  header   ( 01 ) 90012345678908 ( 3202 ) 001750  assertcorrectbinarystring
__label__flaky execute  script  template  all  script  executor  manager  delete  by  partition  keys  session  given  is  empty  should_delete_by_partition  rows  assert  that  execute  select  *  from  simple  where  id  =  immutable  map  crud  simple  entity / insert_2_rows_same_partition . cql  when  of  then  id  executescripttemplate  all  scriptexecutor  manager  deletebypartitionkeys  session   given  isempty  should_delete_by_partition  rows  assertthat  execute  select * from simple where id =   immutablemap  crud  simpleentity / insert_2_rows_same_partition . cql   when  of   then  id
__label__nflaky 1  x  0  e:  y:  z  e  standard  charsets  test  chunked  output  stream  with  trailers  outbuffer  assert  equals  as  list  content  out  assert  get  to  byte  array  y  z  finish  output  stream  arrays  write  close    1  x  0  e:   y: z      e  standardcharsets  testchunkedoutputstreamwithtrailers  outbuffer  assertequals  aslist  content  out  assert  get  tobytearray  y  z  finish  outputstream  arrays  write  close
__label__flaky server  get  name  get  hdfs  conf  h06 . *  conf  dir  as  list  test  dir  helper  create  hadoop  conf  server . services  string  utils  get  join  get  file  system  configuration  fs  access  file  system  executor  no  name  node  init  hdfs  conf  set  get  absolute  path  test  hdfs  helper  get  test  dir  hadoop  conf  services     execute  common  configuration  keys  public  u  arrays    server  getname  gethdfsconf  h06 . *  conf  dir  aslist  testdirhelper  createhadoopconf  server . services  stringutils  get  join  getfilesystemconfiguration  fsaccess  filesystemexecutornonamenode  init  hdfsconf  set  getabsolutepath  testhdfshelper  gettestdir  hadoopconf  services     execute  commonconfigurationkeyspublic  u  arrays
__label__nflaky optional  then  return  invoke  when  param1  get  header  empty  optional  header  empty  context  create  verify  optional  header  mock  controller  optional  thenreturn  invoke  when  param1  getheader  empty  optionalheaderempty  context  create  verify  optionalheader  mockcontroller
__label__flaky _test  is  main  successful  action  dir  has  output  data  assert  false  test  exception  running  job  is  main  done  get  file  system  fs  has  id  swap  get  id  swap  path  ex  is  successful  assert  true  launcher  mapper  get  error  path  exists  get  output  data  path  evaluate  wait  for  get  fs  test  case  dir  is  complete  _test  ismainsuccessful  actiondir  hasoutputdata  assertfalse  testexception  runningjob  ismaindone  getfilesystem  fs  hasidswap  getidswappath  ex  issuccessful  asserttrue  launchermapper  geterrorpath  exists  getoutputdatapath  evaluate  waitfor  getfstestcasedir  iscomplete
__label__nflaky stuff;  fail  assert  inbuf  standard  charsets  channel  test  invalid  constructor  more  stuff  metrics  illegal  argument  exception  should  have  been  thrown  stuff;  fail  assert  inbuf  standardcharsets  channel  testinvalidconstructor  more stuff  metrics  illegalargumentexception should have been thrown
__label__flaky test  fs  failover  reader  local  oozie  conf  source  is  active  get  status  get  test  group  get  path  create  action  workflow . xml  wait  for  wf  client  get  file  system  action  start  command  failover-fs-wf . xml  fault  injection  oozie  client  size  workflow  action  start  action  executor  get  type  copy  char  stream  set  property  mkdirs  get  resource  as  reader  true  create  configuration  evaluate  actions  submit  fsfailover-source  fsfailover-target  get  job  info  assert  false  get  id  wf  job  id2  job  id1  get  workflow  job  get  actions  for  workflow  to  uri  start  false  assert  equals  get  client  store  skip  commit  fault  injection  target  call  services  io  utils  get  test  user  org . apache . oozie . command .   skip  commit  fault  injection  set  system  property  exists  to  string  writer  get  fs  test  case  dir  testfsfailover  reader  localoozie  conf  source  isactive  getstatus  gettestgroup  getpath  create  action  workflow . xml  waitfor  wfclient  getfilesystem  actionstartcommand  failover-fs-wf . xml  faultinjection  oozieclient  size  workflowaction  startactionexecutor  gettype  copycharstream  setproperty  mkdirs  getresourceasreader  true  createconfiguration  evaluate  actions  submit  fsfailover-source  fsfailover-target  getjobinfo  assertfalse  getid  wf  jobid2  jobid1  get  workflowjob  getactionsforworkflow  touri  start  false  assertequals  getclient  store  skipcommitfaultinjection  target  call  services  ioutils  gettestuser  org . apache . oozie . command . skipcommitfaultinjection  setsystemproperty  exists  tostring  writer  getfstestcasedir
__label__nflaky encode  1  0  1  1  1  0  1  0  1  0  0  1  1  0  1  0  1  1  1  0  1  1  1  1  1  1  1  1  0  0  0  1  1  0  0  1  1  1  1  1  1  1  1  0  1  1  1  0  1  0  1  0  0  0  1  0  1  0  1  1  1  0  1  1  0  1  1  1  0  1  0  0  1  1  1  0  0  1  0  0  1  0  1  1  1  0  0  0  0  0  1  0  0  0  0  1  0  0  1  0  0  0  0  0  1  0  0  0  0  1  1  0  0  1  0  0  0  0  0  1  0  1  1  0  0  0  <<  >>  1  1  1  1  1  1  1  0  0  0  0  1  0  1  0  0  1  0  1  0  0  ec  level:  h  0  0  0  0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0  0  0  put  1  0  0  0  0  0  1  0  0  1  0  0  0  1  0  0  0  1  1  0  0  1  0  1  1  1  0  1  0  1  0  0  0  1  0  1  0  0  0  1  0  0  encode  hint  type  qr  code  encoder  0  0  0  1  1  0  1  1  0  0  0  0  1  0  0  0  0  1  1  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  1  1  0  1  1  0  0  0  1  0  1  1  1  0  1  0  1  1  1  1  0  1  0  0  1  0  1  1  0  0  0  0  0  0  0  0  0  1  1  1  0  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  1  0  0  0  1  1  0  0  1  0  0  0  0  0  1  matrix:  hints  1  0  1  1  1  0  1  0  0  1  1  0  0  0  1  0  1  1  1  0  1  expected  assert  equals  0  0  0  0  0  0  0  0  1  1  0  1  0  0  1  0  1  1  1  1  1  version:  1  mask  pattern:  6  utf8  mode:  byte  1  1  0  0  0  1  1  1  0  0  0  1  1  0  0  1  0  1  0  1  1  test  simple  utf8  eci  to  string  1  1  1  1  1  1  1  0  1  0  1  0  1  0  1  1  1  1  1  1  1  0  1  1  0  0  1  1  0  0  1  1  1  0  1  1  1  1  1  1  1  1  error  correction  level  1  1  1  1  1  1  1  0  1  0  1  0  0  0  1  0  0  0  0  0  0  encode   1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 1 1 1 0 1     1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1     1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1     1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1     1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1     0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0    <<    >>     1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0     eclevel: h     0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0    put   1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0     1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0    encodehinttype  qrcode  encoder   0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0     1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0     1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 1 0     0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1     1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1     matrix:    hints   1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1    expected  assertequals   0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1     version: 1     maskpattern: 6    utf8   mode: byte     1 1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1    testsimpleutf8eci  tostring   1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1     0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1    errorcorrectionlevel   1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0
__label__flaky action  id  get  missing  dependencies  data  should  have  been  in  missing  dependency  list !   current  list:  dependency  should  be  available !   current  list:  get  time  tz   / 2009 / 01 / 29 /   get  id  2009-02-16  t23:59  date  utils   / 2009 / 02 / 05  parse  date  oozie  tz  missing  dependencies  recorded  by  the  coordinator  action  after  input  check   / 2009 / 02 / 12 /   get  test  case  dir  get  test  action  input  missing  dependencies  create  dir  action  start  time  index  of  2009-02-15  t23:59   / 2009 / 02 / 12  expected  missing  dependencies  are   / 2009 / 02 / 05    / 2009 / 01 / 29   and   / 2009 / 01 / 22 .   miss  deps  order  specification  -   / 2009 / 02 / 12    / 2009 / 02 / 05    / 2009 / 01 / 29    / 2009 / 01 / 22   / 2009 / 01 / 29  index  -  test  coord  action  input  check  x  command-  c  execute  add  record  to  coord  job  table  call  job  id  @1  was  not  stored  properly  in  db  fail  services  case  when   / 2009 / 01 / 29  exists  but  checking  stops  since  dataset  synchronously  expected  before  i . e .    / 2009 / 02 / 05  is  missing  0000000-  end  time  job  jpa  service  action id   getmissingdependencies  data should have been in missing dependency list !  current list:   dependency should be available !  current list:   gettime  tz   / 2009 / 01 / 29 /   getid  2009-02-16t23:59  dateutils   / 2009 / 02 / 05  parsedateoozietz   missing dependencies recorded by the coordinator action after input check   / 2009 / 02 / 12 /   gettestcasedir  get  testactioninputmissingdependencies  createdir  action  starttime  indexof  2009-02-15t23:59   / 2009 / 02 / 12   expected missing dependencies are  / 2009 / 02 / 05   / 2009 / 01 / 29  and  / 2009 / 01 / 22 .   missdepsorder   specification -  / 2009 / 02 / 12   / 2009 / 02 / 05   / 2009 / 01 / 29   / 2009 / 01 / 22   / 2009 / 01 / 29  index  -testcoordactioninputcheckxcommand-c  execute  addrecordtocoordjobtable  call  jobid  @1   was not stored properly in db  fail  services   case when  / 2009 / 01 / 29 exists but checking stops since dataset synchronously expected before i . e .   / 2009 / 02 / 05 is missing  0000000-  endtime  job  jpaservice
__label__nflaky expected  contents  inputs  l  barcode  contents  as  list  result  assert  not  null  result  metadata  type  process  structured  append  test  process  structured  append  results  sa1  sa2  sa3  qr  code  multi  reader  add  sa1  sa1  sa3  sa3  sa2  sa2  barcode  format  get  text  assert  equals  size  put  metadata  arrays  nsa  not  sa  expectedcontents  inputs  l  barcodecontents  aslist  result  assertnotnull  resultmetadatatype  processstructuredappend  testprocessstructuredappend  results  sa1sa2sa3  qrcodemultireader  add  sa1  sa1  sa3  sa3  sa2  sa2  barcodeformat  gettext  assertequals  size  putmetadata  arrays  nsa  notsa
__label__flaky cluster  create  table  test  timestamps  t  timestamp  test  base  do  test  delete  not  pollute  this  latter ?   or  put  into  separate  tests .   incommon  do  test  timestamp  scanning  flushcache  cluster  createtable  testtimestamps  t  timestamptestbase  dotestdelete   not pollute this latter ?   or put into separate tests .   incommon  dotesttimestampscanning  flushcache
__label__nflaky fruit  context  print  simple  configurator  status  listener  with  prefix . xml  status  printer  implcit_  dir  assert  is  error  free  do  configure  je  checker  status  listener  with  prefix  fruitcontext  print  simpleconfigurator  statuslistenerwithprefix . xml  statusprinter  implcit_dir  assertiserrorfree  doconfigure  je  checker  statuslistenerwithprefix
__label__flaky assert  false  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  get  status  is  pending  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  test  coord  status  transit  service  running2  assert  not  null  get  coordinator  action  end  current  date  plus  month  job  wait  for  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  coordinator  job  job  id  services  runnable  coord-action-get . xml  job  jpa  service  evaluate  assertfalse  getcurrentdateafterincrementinginmonths  getid  run  dateutils  getstatus  ispending  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  testcoordstatustransitservicerunning2  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  job  waitfor  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  coordinatorjob  jobid  services  runnable  coord-action-get . xml  job  jpaservice  evaluate
__label__nflaky apply  glob  mixed  case  item  get  conf  apply  n*e  name  setup   / directory / path /   na  me  assert  equals  mock  fs  result  test  a  glob  pattern  with  different  case  applyglobmixedcase  item  getconf  apply  n*e  name  setup   / directory / path / name  assertequals  mockfs  result   test a glob pattern with different case
__label__flaky date  script  executor  session  given  insert  simple  select  value  from  simple  where  id  =  0  am  crud  when  of  should_insert_with_insert_strategy_non_null_fields  with  insert  strategy  id  row  value  table  insert  strategy  execute  script  template  is  not  null  random  utils  manager  one  get  string  next  long  assert  that  execute  simple  entity / insert_single_row . cql  immutable  map  then  long  build  date  key  is  equal  to  entity  date  scriptexecutor  session   given  insert  simple  select value from simple where id =   0 am  crud   when  of  should_insert_with_insert_strategy_non_null_fields  withinsertstrategy  id  row  value  table  insertstrategy  executescripttemplate  isnotnull  randomutils  manager  one  getstring  nextlong  assertthat  execute  simpleentity / insert_single_row . cql  immutablemap   then  long  builddatekey  isequalto  entity
__label__nflaky assume  false  test  env  helper  windows  assume  test  env  vars  with  inheritance  assumefalse  testenvhelper  windows  assume  testenvvarswithinheritance
__label__flaky context  set  resource  watcher  update  period  try  async  check  then  return  assert  false  resource  type  should  not  watch  for  change  unless  check  completed  eq  when  get  config  group_  name  was  checked  for  change  mockito  assert  true  get  mock  resource  watcher  victim  key  context  setresourcewatcherupdateperiod  tryasynccheck  thenreturn  assertfalse  resourcetype  shouldnotwatchforchangeunlesscheckcompleted  eq  when  getconfig  group_name  wascheckedforchange  mockito  asserttrue  get  mockresourcewatcher  victim  key
__label__nflaky erasure  code  constants  coder  xor  raw  erasure  coder  factory  native  xor  raw  erasure  coder  factory  rs  legacy  raw  erasure  coder  factory  get  coder  by  name  assert  true  rs  raw  erasure  coder  factory  get  instance  native  rs  raw  erasure  coder  factory  codec  registry  test  get  coder  by  name  erasurecodeconstants  coder  xorrawerasurecoderfactory  nativexorrawerasurecoderfactory  rslegacyrawerasurecoderfactory  getcoderbyname  asserttrue  rsrawerasurecoderfactory  getinstance  nativersrawerasurecoderfactory  codecregistry  testgetcoderbyname
__label__flaky add  qualifier_1  value2  qualifier_2  value1  row_3  delete  put  result  get  value  bytes  test  delete  assert  null  column_2  column_1  add  family  assert  true  assert  not  null  get  equals  remote  table  value_1  value_2  delete  column  add  qualifier_1  value2  qualifier_2  value1  row_3  delete  put  result  getvalue  bytes  testdelete  assertnull  column_2  column_1  addfamily  asserttrue  assertnotnull  get  equals  remotetable  value_1  value_2  deletecolumn
__label__nflaky next  bad  request  then  return  get  filter  chain  filter  chain  when  get  bad  request  result  ninja  default  route  mockito  that \  ' s  a  bad  request  that  should  be  handled  by  on  bad  request  context  impl  mock  verify  test  on  route  request  when  on  bad  request  on  route  request  then  throw  next  badrequest  thenreturn  getfilterchain  filterchain  when  getbadrequestresult  ninjadefault  route  mockito  that \  ' s a badrequest that should be handled by onbadrequest  contextimpl  mock  verify  testonrouterequestwhenonbadrequest  onrouterequest  thenthrow
__label__flaky a  a  b  b  aa  bb  x  log  create  prefix  a-  b-  assert  equals  log  info  aa  b-  test  info  parameters  a-  define  parameter  set  parameter    a  a  b  b  aa bb  xlog  createprefix  a- b-  assertequals  loginfo  aa b-  testinfoparameters  a-  defineparameter  setparameter
__label__nflaky is  static  get  name  log  get  declared  method  get  parameter  types  is  private  get  method  error  m  exc2  filter  file  system  doesn \  ' t  implement  get  declared  methods  testing  skipping  get  modifiers  is  final  modifier  info  test  filter  file  system  isstatic  getname  log  getdeclaredmethod  getparametertypes  isprivate  getmethod  error  m  exc2  filterfilesystem doesn \  ' t implement   getdeclaredmethods  testing   skipping   getmodifiers  isfinal  modifier  info  testfilterfilesystem
__label__flaky check  ownership  case  6:  user2   ( non-owner )   changes  file_  dir_  path \  ' s  group  to  be  group3  case  3:  user1  changes  file_  dir_  path \  ' s  owner  to  be  user2  case  2:  superuser  changes  file_  dir_  path \  ' s  owner  to  be  <user1   group3>  conf  default_  umask  login  fs  delete  default_  permission  set  owner  file_  dir_  path  user1  user2  file  system  get  which  it  does  not  belong  to  group3_  name  create  delete  the  file / directory  test  directory  creation  to  case  7:  user2   ( non-owner )   changes  file_  dir_  path \  ' s  user  to  be  user2  case  1:  superuser  create  a  file / directory  get  short  user  name  op  get  parent  check  if  the  ownership  of  a  file / directory  is  set  correctly  superuser  get  group  test  file  creation  op  type  check  ownership  is  set  correctly  for  a  file  or  directory  test  ownership  group1_  name  checkownership   case 6: user2  ( non-owner )  changes file_dir_path \  ' s group to be group3   case 3: user1 changes file_dir_path \  ' s owner to be user2   case 2: superuser changes file_dir_path \  ' s owner to be <user1  group3>  conf  default_umask  login  fs  delete  default_permission  setowner  file_dir_path  user1  user2  filesystem  get   which it does not belong to  group3_name  create   delete the file / directory   test directory creation   to   case 7: user2  ( non-owner )  changes file_dir_path \  ' s user to be user2   case 1: superuser create a file / directory  getshortusername  op  getparent   check if the ownership of a file / directory is set correctly   superuser  getgroup   test file creation  optype   check ownership is set correctly for a file or directory   testownership  group1_name
__label__nflaky 240  shifts  to  edifact  encodation   .   a .   c1 . 3 .   x .   x2 .  .   240  184  27  131  198  236  238  89  240  184  27  131  198  236  238  98  230  31  97  139  152  97  139  152  97  139  152  97  139  152  97  139  152  97  139  152  89  89  <--  this  is  the  temporary  unlatch   .   a .   c1 . 3 .   x  test  edifact  encodation   .   a .   c1 . 3 .   x .   x2 .   240  184  27  131  198  236  238  98  230  50   .   a .   c1 . 3 .   x .   x   .   xxx .   xxx .   xxx .   xxx .   xxx .   xxx .   xx .   xxx .   xxx .   xxx .   xxx .   xxx .   xxx  124  47  235  125  240   .   a .   c1 . 3 .   x .   x2  240  184  27  131  198  236  238  16  21  1  187  28  179  16  21  1  187  28  179  16  21  1  240  184  27  131  198  236  238  98  230  50  47  47  240  185  134  24  185  134  24  185  134  24  185  134  24  185  134  24  185  134  24  visualized   .   a .   c1 . 3 .   data . 123  data . 123  data  assert  equals  240  184  27  131  198  236  238  98  230  50  47  129  240  184  27  131  198  236  238  98  231  192  checking  temporary  unlatch  from  edifact   .   a .   c1 . 3 .   x .   encode  high  level   240 shifts to edifact encodation   . a . c1 . 3 . x . x2 .  .   240 184 27 131 198 236 238 89  240 184 27 131 198 236 238 98 230 31   97 139 152 97 139 152 97 139 152 97 139 152 97 139 152 97 139 152 89 89   <-- this is the temporary unlatch   . a . c1 . 3 . x  testedifactencodation   . a . c1 . 3 . x . x2 .   240 184 27 131 198 236 238 98 230 50   . a . c1 . 3 . x . x   . xxx . xxx . xxx . xxx . xxx . xxx . xx . xxx . xxx . xxx . xxx . xxx . xxx   124 47 235 125 240   . a . c1 . 3 . x . x2  240 184 27 131 198 236 238 16 21 1 187 28 179 16 21 1 187 28 179 16 21 1  240 184 27 131 198 236 238 98 230 50 47 47  240 185 134 24 185 134 24 185 134 24 185 134 24 185 134 24 185 134 24  visualized   . a . c1 . 3 . data . 123data . 123data  assertequals  240 184 27 131 198 236 238 98 230 50 47 129  240 184 27 131 198 236 238 98 231 192   checking temporary unlatch from edifact   . a . c1 . 3 . x .   encodehighlevel
__label__flaky get  time  get  expected  start  test  sla  registration  get  current  assert  not  null  get  -  test  sla  reg  get  jpa  executor-  w  bean  get  alert  events  read  cmd  get  job  id  get  sla  config  map  _add  record  to  sla  registration  table  assert  equals  execute  job  id  services  get  alert  contact  size  0000000-  app  type  alert@example . com  jpa  service  end_  miss  get  app  type  gettime  getexpectedstart  testslaregistrationget  current  assertnotnull  get  -testslareggetjpaexecutor-w  bean  getalertevents  readcmd  getjobid  getslaconfigmap  _addrecordtoslaregistrationtable  assertequals  execute  jobid  services  getalertcontact  size  0000000-  apptype  alert@example . com  jpaservice  end_miss  getapptype
__label__nflaky 10 . 119 . 103 . 112  10 . 113 . 221 . 222  10 . 222 . 103 . 121  is  in  the  list  10 . 113 . 221 . 221  assert  false  10 . 222 . 103 . 121  is  not  in  the  list  refresh  10 . 221 . 102 . 0 / 23  cipl  ips  10 . 222 . 103 . 121  create  file  with  entries  test  add  with  refresh  remove  file  assert  true  ips . txt  test  file  based  ip  list  ips2  10 . 113 . 221 . 222  is  in  the  list  10 . 222 . 0 . 0 / 16  is  in  10 . 113 . 221 . 222  is  not  in  the  list  10 . 119 . 103 . 112  10 . 113 . 221 . 222  10 . 222 . 103 . 121 is  in the list  10 . 113 . 221 . 221  assertfalse  10 . 222 . 103 . 121 is not in the list  refresh  10 . 221 . 102 . 0 / 23  cipl  ips  10 . 222 . 103 . 121  createfilewithentries  testaddwithrefresh  removefile  asserttrue  ips . txt  testfilebasediplist  ips2  10 . 113 . 221 . 222 is in the list  10 . 222 . 0 . 0 / 16  isin  10 . 113 . 221 . 222 is not in the list
__label__flaky date  set  script  executor  table  name  for  session  given  update_dsl_with_schema_name  update  eq  table  name  should_dsl_update_with_schema_name  when  of  from  where  id  row  value  table  select  value  from  simple  entity / create_simple_mirror_table . cql  execute  script  template  random  utils  manager  one  where  id  =  get  string  next  long  assert  that  execute  immutable  map  simple  entity / insert_single_row . cql  keyspace  for  then  long  build  date  key  new  value  dsl  is  equal  to  default_  cassandra_  embedded_  keyspace_  name  date  set  scriptexecutor  tablenamefor  session   given  update_dsl_with_schema_name  update  eq  tablename  should_dsl_update_with_schema_name   when  of  from  where  id  row  value  table  select value from   simpleentity / create_simple_mirror_table . cql  executescripttemplate  randomutils  manager  one   where id =   getstring  nextlong  assertthat  execute  immutablemap  simpleentity / insert_single_row . cql  keyspacefor   then  long  builddatekey  new value  dsl  isequalto  default_cassandra_embedded_keyspace_name
__label__nflaky server  get  default  socket  factory  test  rte  during  connection  setup  conf  when  do  answer  assert  true  string  utils  client  info  address  e  log  random  expected  an  exception  to  have  been  thrown  start  call  should  fail  due  to  injected  exception .   stringify  exception  caught  expected  exception   ( i . e .   it  should  not  have  cached  a  half-constructed  connection )   next  long  spy  factory  get  connect  address  call  fail  contains  net  utils  create  socket  answer  stop  mockito  reset  injected  fault  spy  throw  an  rte  when  set  so  timeout  is  called .   server  getdefaultsocketfactory  testrteduringconnectionsetup  conf  when  doanswer  asserttrue  stringutils  client  info  address  e  log  random  expected an exception to have been thrown  start   call should fail due to injected exception .   stringifyexception  caught expected exception    ( i . e .  it should not have cached a half-constructed connection )   nextlong  spyfactory  getconnectaddress  call  fail  contains  netutils  createsocket  answer  stop  mockito  reset  injected fault  spy   throw an rte when setsotimeout is called . 
__label__flaky check  coord  actions  get  time  date  utils  parse  date  oozie  tz  2009-03-06  t10:00  z  add  record  to  job  table  call  job  id  pause  time  2009-03-06  t10:08  z  -test  action  mater-  c  0000000-  start  time  end  time  test  action  mater  with  pause  time2  2009-03-06  t10:14  z  checkcoordactions  gettime  dateutils  parsedateoozietz  2009-03-06t10:00z  addrecordtojobtable  call  jobid  pausetime  2009-03-06t10:08z  -testactionmater-c  0000000-  starttime  endtime  testactionmaterwithpausetime2  2009-03-06t10:14z
__label__nflaky other-user4  conf  user5 / cron@  other .   realm  user7@example . com@  default .   realm  hadoop_  security_  auth_  to_  local  test  constructor  success  failure  test  mit  hadoop  security  off   but  use  rules  if  explicitly  set  user6@example . com@  other .   realm  set  configuration  user3 / cron@  default .   realm  with  mit  failures  test  constructor  with  rules  user  group  information  user1  rule:1:$1@$0 (  . *@  other .   realm ) s /  (  . * ) @ . * / other-$1 /   set  user2@  default .   realm  test  constructor  failures  hadoop_  security_  auth_  to_  local_  mechanism  user4@  other .   realm    other-user4  conf  user5 / cron@other . realm  user7@example . com@default . realm  hadoop_security_auth_to_local  testconstructorsuccess   failure test  mit  hadoop   security off  but use rules if explicitly set  user6@example . com@other . realm  setconfiguration  user3 / cron@default . realm   with mit   failures  testconstructorwithrules  usergroupinformation  user1  rule:1:$1@$0 (  . *@other . realm ) s /  (  . * ) @ . * / other-$1 /   set  user2@default . realm  testconstructorfailures  hadoop_security_auth_to_local_mechanism  user4@other . realm
__label__flaky get  recovery  path  <chmod  path= \  '  \  ' {5} \  '  \  '   permissions= \  '  \  ' -rwxrwxrwx \  '  \  '  / >  chmod1  chmod2  <chmod  path= \  '  \  ' {6} \  '  \  '   permissions= \  '  \  ' -rwxrwx--- \  '  \  '   dir-files= \  '  \  ' false \  '  \  '  / >  source  get  status  create  context  new  file2  x  chmod2  x  get  path  context  get  file  status  action  mkdir  x  mkdir  <touchz  path= \  '  \  ' {8} \  '  \  '  / >  <move  source= \  '  \  ' {3} \  '  \  '   target= \  '  \  ' {4} \  '  \  '  / >  get  permission  ae  format  <mkdir  path= \  '  \  ' {1} \  '  \  '  / >  get  file  system  check  <fs><name-node>{0}< / name-node>  chmod1  x  rwxrwx---  new  file1  x  workflow  action  mkdirs  new  file2  new  file1  assert  false  <touchz  path= \  '  \  ' {7} \  '  \  '  / >  child2  fs  delete  child1  action  xml  <delete  path= \  '  \  ' {2} \  '  \  '  / >  test  submit  with  name  node  assert  true  < / fs>  end  ok  get  data  get  name  node  uri  source  x  message  format  to  uri  delete  x  start  get  action  assert  equals  get  external  status  rwxrwxrwx  target  assert  null  assert  not  same  exists  to  string  create  new  file  get  fs  test  case  dir  getrecoverypath  <chmod path= \  '  \  ' {5} \  '  \  '  permissions= \  '  \  ' -rwxrwxrwx \  '  \  '  / >  chmod1  chmod2  <chmod path= \  '  \  ' {6} \  '  \  '  permissions= \  '  \  ' -rwxrwx--- \  '  \  '  dir-files= \  '  \  ' false \  '  \  '  / >  source  getstatus  createcontext  newfile2x  chmod2x  getpath  context  getfilestatus  action  mkdirx  mkdir  <touchz path= \  '  \  ' {8} \  '  \  '  / >  <move source= \  '  \  ' {3} \  '  \  '  target= \  '  \  ' {4} \  '  \  '  / >  getpermission  ae  format  <mkdir path= \  '  \  ' {1} \  '  \  '  / >  getfilesystem  check  <fs><name-node>{0}< / name-node>  chmod1x  rwxrwx---  newfile1x  workflowaction  mkdirs  newfile2  newfile1  assertfalse  <touchz path= \  '  \  ' {7} \  '  \  '  / >  child2  fs  delete  child1  actionxml  <delete path= \  '  \  ' {2} \  '  \  '  / >  testsubmitwithnamenode  asserttrue  < / fs>  end  ok  getdata  getnamenodeuri  sourcex  messageformat  touri  deletex  start  getaction  assertequals  getexternalstatus  rwxrwxrwx  target  assertnull  assertnotsame  exists  tostring  createnewfile  getfstestcasedir
__label__nflaky  / storage  policy  storage  policy  path  chroot  fs  set  class  mockfs: /  / foo / a / b   / a / b / storage  policy  conf  uri  ch  rooted  storage  policy  path  get  raw  file  system  get  storage  policy  fs . mockfs . impl  test  get  storage  policy  chroot  uri  create  verify  mock  fs   / storagepolicy  storagepolicypath  chrootfs  setclass  mockfs: /  / foo / a / b   / a / b / storagepolicy  conf  uri  chrootedstoragepolicypath  getrawfilesystem  getstoragepolicy  fs . mockfs . impl  testgetstoragepolicy  chrooturi  create  verify  mockfs
__label__flaky kills  a  b  add  node  def  f  enters  start  j  assert  equals  test  kill  with  running  nodes  workflow  instance  get  status  kill  as  list  wf  1  exits  size  <worklfow-app / >  end  arrays  job  fails  kills  a  b  addnode  def  f  enters  start  j  assertequals  testkillwithrunningnodes  workflowinstance  getstatus  kill  aslist  wf  1  exits  size  <worklfow-app / >  end  arrays  job  fails
__label__nflaky json  document  test  invalid  json  body  then  return  format  body  parser  engine  json  is  invoke  string  json  obj  mapper  get  input  stream  when  get  bytes  mockito  assert  true  { \ ""first  name \ "": \ "" \ %s \ ""    \ ""last  name \ "": \ "" \ %s \ ""    \ ""birth  year \ "": \ %d    \ ""last  seen \ "": \ "" \ %s \ ""  context  body  parser  engine  json  test  bad  request  thrown  close  jsondocument  testinvalidjsonbody  thenreturn  format  bodyparserenginejson  is  invoke  string  jsonobjmapper  getinputstream  when  getbytes  mockito  asserttrue  { \ ""firstname \ "": \ "" \ %s \ ""   \ ""lastname \ "": \ "" \ %s \ ""   \ ""birthyear \ "": \ %d   \ ""lastseen \ "": \ "" \ %s \ ""  context  bodyparserenginejsontest  badrequestthrown  close
__label__flaky cluster  create  cluster  assert  false  t=  conf  error  system  create  file  wait  active  sleep  lease  period   / foo3  set  lease  period  create  a  new  file .    / foo2  test  lease  expire  empty  files   / foo  dfs  config  keys  e  set  default  uncaught  exception  handler  wait  for  the  lease  to  expire  get  file  system  test  file  creation  thread  set  int  dfs  get  default  uncaught  exception  handler  lease  manager  t  is  concurrent  modification  exception  build  num  data  nodes  datanode_  num  test  lease  expire  empty  files  start  uncaught  exception  old  ueh  namenode  triggers  lease  recovery  shutdown  cluster   create cluster  assertfalse  t=  conf  error  system  createfile  waitactive  sleep  leaseperiod   / foo3  setleaseperiod   create a new file .    / foo2  testleaseexpireemptyfiles   / foo  dfsconfigkeys  e  setdefaultuncaughtexceptionhandler   wait for the lease to expire  getfilesystem  testfilecreation  thread  setint  dfs  getdefaultuncaughtexceptionhandler  leasemanager  t  isconcurrentmodificationexception  build  numdatanodes  datanode_num  testleaseexpireemptyfiles start  uncaughtexception  oldueh   namenode triggers lease recovery  shutdown
__label__nflaky test  fields  number  of  ops  for  rs1  average  time  for  s1  number  of  ops  for  r1  get  metrics  r1  avg  time  g1  source  g2  g3  s1  avg  time  g4  c1  add  counter  rs1  counter2  desc  verify  average  time  for  rs1  info  g3  desc  add  add  gauge  r1  num  ops  number  of  ops  for  s1  incr  average  time  for  r1  g4  desc  rs1  avg  time  rb  make  source  metrics  annotations  s1  num  ops  metrics  counter2  rs1  num  ops  testfields  number of ops for rs1  average time for s1  number of ops for r1  getmetrics  r1avgtime  g1  source  g2  g3  s1avgtime  g4  c1  addcounter  rs1  counter2 desc  verify  average time for rs1  info  g3 desc  add  addgauge  r1numops  number of ops for s1  incr  average time for r1  g4 desc  rs1avgtime  rb  makesource  metricsannotations  s1numops  metrics  counter2  rs1numops
__label__flaky wf  action  get  cmd  get  workflow  instance  add  record  to  wf  action  table  test  wf  kill  success2  get  id  assert  equals  workflow  instance  get  status  execute  call  1  services  add  record  to  wf  job  table  workflow  action  assert  not  null  get  action  workflow  job  job  wf  instance  jpa  service  wf  job  get  cmd  wfactiongetcmd  getworkflowinstance  addrecordtowfactiontable  testwfkillsuccess2  getid  assertequals  workflowinstance  getstatus  execute  call  1  services  addrecordtowfjobtable  workflowaction  assertnotnull  get  action  workflowjob  job  wfinstance  jpaservice  wfjobgetcmd
__label__nflaky cluster  a  chance  to  take  the  lock   if  it  is  ever  going  to .   log  health  monitor  start  wait  for  health  state  allowing  svc0 \  ' s  elector  to  re-establish  its  connection  wait  for  active  lock  holder  svc0  should  get  the  lock  again  allow  session  reestablishment  for  tests  expire  active  lock  holder  thread  make  svc1  unhealthy   and  wait  for  its  fc  to  notice  the  bad  health .   get  elector  sleep  set  healthy  expired  svc0 \  ' s  zk  session .   waiting  a  second  to  give  svc1  prevent  session  reestablishment  for  tests  expire  svc0  test  dont  failover  to  unhealthy  node  info  ensure  that  no  one  holds  the  lock .   cluster   a chance to take the lock  if it is ever going to .   log  healthmonitor  start  waitforhealthstate  allowing svc0 \  ' s elector to re-establish its connection  waitforactivelockholder   svc0 should get the lock again  allowsessionreestablishmentfortests  expireactivelockholder  thread   make svc1 unhealthy  and wait for its fc to notice the bad health .   getelector  sleep  sethealthy  expired svc0 \  ' s zk session .  waiting a second to give svc1  preventsessionreestablishmentfortests   expire svc0  testdontfailovertounhealthynode  info   ensure that no one holds the lock . 
__label__flaky coord  action  event  waiting  coord  action  event  success  _test  event  handler  service  *  coordinator  action  events  run  myapp  parentid  output  jobid  coord  action  event  started  assert  true  test  event  listener  queue  event  coordinator  action  workflow  job  event  event2  workflow  job  event  success  workflow  job  event  failure  workflow  job  event  started  coord  action  event  suspend  *  workflow  job  events  set  status  ehs  workflow  job  event  suspend  contains  set  length  get  test  user  to  string  coord  action  event  failure  coord action event waiting  coord action event success  _testeventhandlerservice             * coordinator action events             run  myapp  parentid  output  jobid  coord action event started  asserttrue  testeventlistener  queueevent  coordinatoraction  workflowjob  event  event2  workflow job event success  workflow job event failure  workflow job event started  coord action event suspend             * workflow job events             setstatus  ehs  workflow job event suspend  contains  setlength  gettestuser  tostring  coord action event failure
__label__nflaky p1  p2  get  kms  url  conf  should  fail  since  provider  p1  threw  runtime  exception  when  times  test  client  retries  with  runtime  exception  assert  true  verify  then  throw  kp  e  any  string  then  return  create  key  eq  any  set  int  common  configuration  keys  public  fail  never  test3  mockito  mock  p1  p2  getkmsurl  conf  should fail since provider p1 threw runtimeexception  when  times  testclientretrieswithruntimeexception  asserttrue  verify  thenthrow  kp  e  anystring  thenreturn  createkey  eq  any  setint  commonconfigurationkeyspublic  fail  never  test3  mockito  mock
__label__flaky hdfs: /  /  /  /  / tmp / file  get  authority  with  scheme   / tmp / file  uri  service  assert  equals  hdfs: /  / nn1:8020  uri   /   hdfs: /  / nn1:8020 / dataset / ${  year} / ${  month}  hdfs: /  / nn1:8020 /   test  get  authority  with  scheme  hdfs: /  /  /   to  string  hdfs: /  /  / tmp / file  hdfs: /  /  /  /  / tmp / file  getauthoritywithscheme   / tmp / file  uriservice  assertequals  hdfs: /  / nn1:8020  uri   /   hdfs: /  / nn1:8020 / dataset / ${year} / ${month}  hdfs: /  / nn1:8020 /   testgetauthoritywithscheme  hdfs: /  /  /   tostring  hdfs: /  /  / tmp / file
__label__nflaky full  crc  test  unstriped  incorrect  chunk  size  chunk  size  the  full  crc .   update  assert  equals  type  crc  bytes  by  chunk  new  crc  composer  crc  composer  crc  util  digest  calculated  crc  read  int  digester  assert  not  equals  fullcrc  testunstripedincorrectchunksize  chunksize   the fullcrc .   update  assertequals  type  crcbytesbychunk  newcrccomposer  crccomposer  crcutil  digest  calculatedcrc  readint  digester  assertnotequals
__label__flaky job  conf  conn  set  request  method  is_  security_  enabled   / app  post  write  xml  app  path  fs  set  request  property  get  test  user2  create  workflow . xml  content-type   / v0 / jobs  job  xml  path  run  test (  \ "" / jobs \ ""   base  jobs  servlet . class   is_  security_  enabled   new  callable<  void> (  )   {  run  test  set  rest  constants  open  connection  mock  dag  engine  service  http  servlet  response  test  diff  user  assert  equals  get  file  system  params  url  call  oozie  client  get  test  user  get  response  code  reset  create  url  to  string  get  output  stream  get  fs  test  case  dir  set  do  output    jobconf  conn  setrequestmethod  is_security_enabled   / app  post  writexml  apppath  fs  setrequestproperty  gettestuser2  create  workflow . xml  content-type   / v0 / jobs  jobxmlpath   runtest (  \ "" / jobs \ ""  basejobsservlet . class  is_security_enabled  new callable<void> (  )  {  runtest  set  restconstants  openconnection  mockdagengineservice  httpservletresponse  testdiffuser  assertequals  getfilesystem  params  url  call  oozieclient  gettestuser  getresponsecode  reset  createurl  tostring  getoutputstream  getfstestcasedir  setdooutput
__label__nflaky russian= \ %  d0 \ %92 \ %  d1 \ %81 \ %  d0 \ %  b5 \ %  d0 \ %  bc_ \ %  d0 \ %  bf \ %  d1 \ %80 \ %  d0 \ %  b8 \ %  d0 \ %  b2 \ %  d0 \ %  b5 \ %  d1 \ %82  content  type  result  ru_hello  assert  construct  string  russian_  hello  with  charset  get  ch_hello  &swiss=  gr \ %  c3 \ %  b  cezi_z \ %  c3 \ %  a4m \ %  c3 \ %  a4  add  russian  url  encoded  utils  standard  charsets  swiss_  german_  hello  format  swiss  assert  equals  parse  entity  utils  assert  name  value  pair  size  test  parse  utf8  entity  parameters  entity  russian= \ %d0 \ %92 \ %d1 \ %81 \ %d0 \ %b5 \ %d0 \ %bc_ \ %d0 \ %bf \ %d1 \ %80 \ %d0 \ %b8 \ %d0 \ %b2 \ %d0 \ %b5 \ %d1 \ %82  contenttype  result  ru_hello  assert  constructstring  russian_hello  withcharset  get  ch_hello  &swiss=gr \ %c3 \ %bcezi_z \ %c3 \ %a4m \ %c3 \ %a4  add  russian  urlencodedutils  standardcharsets  swiss_german_hello  format  swiss  assertequals  parse  entityutils  assertnamevaluepair  size  testparseutf8entity  parameters  entity
__label__flaky kills  add  node  def  enters  one  start  test  synch  simple  assert  equals  workflow  instance  get  status  as  list  wf  1  exits  size  <worklfow-app / >  end  arrays  job  fails  kills  addnode  def  enters  one  start  testsynchsimple  assertequals  workflowinstance  getstatus  aslist  wf  1  exits  size  <worklfow-app / >  end  arrays  job  fails
__label__nflaky add  a  b  c  set  get  string  collection  assert  equals  a   b     c  check  that  the  result  is  mutable  assert  array  equals  strs  size  does-not-exist  make  sure  same  is  true  for  missing  config  to  array  get  trimmed  string  collection  z  test  get  string  collection  add  a  b  c  set  getstringcollection  assertequals   a  b     c    check that the result is mutable  assertarrayequals  strs  size  does-not-exist   make sure same is true for missing config  toarray  gettrimmedstringcollection  z  testgetstringcollection
__label__flaky get  conf  string  2010-10-01  t00:00  z  conf  date  utils  parse  date  oozie  tz  create  instances  el  evaluator  time  unit  expr  event  coord  el  evaluator  set  nominal  time  xml  utils  system . out . println (  \ ""  output  : \ ""  +  eval . evaluate ( expr   string . class )  ) ;  parse  xml  <uri-template>file: /  /  / tmp / coord /   us / ${  year} / ${  month} / ${  day}< / uri-template>< / dataset>< / data-in>  ${coord:current ( 0 ) }  assert  equals  <dataset  name= \ ""a \ ""  frequency= \ ""1440 \ ""  initial-instance= \ ""2009-01-01  t00:00  z \ ""  freq_timeunit= \ ""  minute \ ""  timezone= \ ""  utc \ ""  end_of_duration= \ ""  none \ "">  2009-09-08  t00:00  z  set  actual  time  app  inst  set  time  unit  eval  -1 )  ) ;  <data-in  name= \ ""  a \ ""  dataset= \ ""a \ ""><uris>file: /  /  / tmp / coord /   us / 2009 / 1 / 30|file: /  /  / tmp / coord /   us / 2009 / 1 / 31< / uris>  test  create  instances  el  evaluator  data  evnt  xml  evaluate  2009-09-08  t01:00  z  getconfstring  2010-10-01t00:00z  conf  dateutils  parsedateoozietz  createinstanceselevaluator  timeunit  expr  event  coordelevaluator  setnominaltime  xmlutils   system . out . println (  \ ""output : \ "" + eval . evaluate ( expr  string . class )  ) ;  parsexml  <uri-template>file: /  /  / tmp / coord / us / ${year} / ${month} / ${day}< / uri-template>< / dataset>< / data-in>  ${coord:current ( 0 ) }  assertequals  <dataset name= \ ""a \ "" frequency= \ ""1440 \ "" initial-instance= \ ""2009-01-01t00:00z \ "" freq_timeunit= \ ""minute \ "" timezone= \ ""utc \ "" end_of_duration= \ ""none \ "">  2009-09-08t00:00z  setactualtime  appinst  settimeunit  eval   -1 )  ) ;  <data-in name= \ ""a \ "" dataset= \ ""a \ ""><uris>file: /  /  / tmp / coord / us / 2009 / 1 / 30|file: /  /  / tmp / coord / us / 2009 / 1 / 31< / uris>  testcreateinstanceselevaluator  dataevntxml  evaluate  2009-09-08t01:00z
__label__nflaky pp  get  current  user  fake  user  run  runtime  split  trim  get  the  user  name  get  runtime  user  group  information  add  to  lower  case  get  win  utils  path  create  remote  user  get  input  stream  login  user  name  contains  do  as  groups  -  f  foo . bar  size  :  exec  whoami  user  names  are  case  insensitive  on  windows .   make  consistent  line  get  group  names  assert  false  login  substring  system  br  shell  extract  only  the  user  name  current  assert  true  string  utils  tokens  sp  get  short  user  name  gi  test  get  server  side  groups  groups  assert  equals  read  line  user  name  get  the  groups  last  index  of  equals  id  -  gn  pp  getcurrentuser  fakeuser  run  runtime  split  trim   get the user name  getruntime  usergroupinformation  add  tolowercase  getwinutilspath  createremoteuser  getinputstream  loginusername  contains  doas   groups -f  foo . bar  size  :  exec  whoami   user names are case insensitive on windows .  make consistent  line  getgroupnames  assertfalse  login  substring  system  br  shell   extract only the user name  current  asserttrue  stringutils  tokens  sp  getshortusername  gi  testgetserversidegroups  groups  assertequals  readline  username   get the groups  lastindexof  equals  id -gn
__label__flaky end_  points  is_  security_  enabled  oozie  url  conf  run  wc  app  path  assert  true  get  create  workflow . xml  servlet_  classes  close  run  test  app  get  context  url  mock  dag  engine  service  assert  equals  get  file  system  test  run  call  oozie  client  mkdirs  set  property  wf  count  create  configuration  to  string  get  fs  test  case  dir  end_points  is_security_enabled  oozieurl  conf  run  wc  apppath  asserttrue  get  create  workflow . xml  servlet_classes  close  runtest  app  getcontexturl  mockdagengineservice  assertequals  getfilesystem  testrun  call  oozieclient  mkdirs  setproperty  wfcount  createconfiguration  tostring  getfstestcasedir
__label__nflaky drwho  test  default  blocked  machine  list  conf  test  without  setting  a  default  blocked  machine  list  drwho@  example .   com  set  a  default  blocked  machine  list  and  a  blocked  machine  list  for  test  protocol  test  protocol1  can  be  accessed  from   \ ""1 . 2 . 3 . 4 \ ""  because  it  uses  default  block  list  get  by  name  because   \ ""10 . 222 . 0 . 0 \ ""  is  in  default  block  list  authorize  10 . 222 . 0 . 0  user  group  information  create  user  for  testing  ip_  range  set  test  protocol  can  be  accessed  from   \ ""10 . 222 . 0 . 0 \ ""  because  it  blocks  only   \ ""1 . 2 . 3 . 4 \ ""  1 . 2 . 3 . 4  security . service . authorization . default . hosts . blocked  refresh  blocked_  host_  config  group2  group1  service  authorization  manager  fail  test  protocol  cannot  be  accessed  from   \ ""1 . 2 . 3 . 4 \ ""  inet  address  drwho  testdefaultblockedmachinelist  conf   test without setting a default blocked machinelist  drwho@example . com   set a  default blocked machinelist and a blocked machinelist for testprotocol   testprotocol1 can be accessed from  \ ""1 . 2 . 3 . 4 \ "" because it uses default block list  getbyname   because  \ ""10 . 222 . 0 . 0 \ "" is in default block list  authorize  10 . 222 . 0 . 0  usergroupinformation  createuserfortesting  ip_range  set   testprotocol can be accessed from  \ ""10 . 222 . 0 . 0 \ "" because it blocks only  \ ""1 . 2 . 3 . 4 \ ""  1 . 2 . 3 . 4  security . service . authorization . default . hosts . blocked  refresh  blocked_host_config  group2  group1  serviceauthorizationmanager  fail   testprotocol cannot be accessed from   \ ""1 . 2 . 3 . 4 \ ""  inetaddress
__label__flaky bulk  insert  cmd  create  workflow  add  node  auth  get  app  path  prep  conf  get  id  test  token  workflow  instance  action  get  cmd  set  insert  list  assert  not  null  get  test  app  <workflow-app / >  end  workflow . xml  workflow  job  app  add  get  status  str  set  check  for  expected  status  after  running  bulk  update  jpa  insert  list  wf  get  cmd  test  inserts  assert  equals  execute  app  uri  oozie  client  1  services  2  get  test  user  workflow  action  to  string  create  workflow  action  action1  insert  one  workflow  job  and  two  actions  job  action2  jpa  service  bulkinsertcmd  createworkflow  addnode  auth  getapppath  prep  conf  getid  testtoken  workflowinstance  actiongetcmd  setinsertlist  assertnotnull  get  testapp  <workflow-app / >  end  workflow . xml  workflowjob  app  add  getstatusstr  set   check for expected status after running bulkupdatejpa  insertlist  wfgetcmd  testinserts  assertequals  execute  appuri  oozieclient  1  services  2  gettestuser  workflowaction  tostring  createworkflowaction  action1   insert one workflow job and two actions  job  action2  jpaservice
__label__nflaky server  cleanup  interval  call  barrier  conf  run  first  call  barrier  call  returned  max  idle  start  client  interrupt  join  client  conf  current  thread  wake  up  call  and  ensure  connection  times  out  set  log  level  log  generic  test  utils  close  max  connections  on  every  cleanup  interval  kill  max  all  call  latch  set  int  get  connect  address  common  configuration  keys  public  stop  compare  and  set  level  server  clients  assert  false  get  id  error  connection  for  the  first  blocked  call  should  still  be  open  sleep  all  calls  blocked  in  handler  so  all  connections  made  get  await  client  connections  should  have  closed  count  down  block  first  call  addr  1  to  block   2  batches  to  kill  set  common  configuration  keys  e  start  threads  assert  equals  thread  call  net  utils  t  test  connection  idle  timeouts  get  num  open  connections  to  string  stagger  cleanups  first  server  cleanupinterval  callbarrier  conf  run  firstcallbarrier  callreturned  maxidle   start client  interrupt  join  clientconf  currentthread   wake up call and ensure connection times out  setloglevel  log  generictestutils   close max connections on every cleanupinterval  killmax  allcalllatch  setint  getconnectaddress  commonconfigurationkeyspublic  stop  compareandset  level  server  clients  assertfalse  getid  error   connection for the first blocked call should still be open  sleep   all calls blocked in handler so all connections made  get  await  client   connections should have closed  countdown   block first call  addr   1 to block  2 batches to kill  set  commonconfigurationkeys  e  start  threads  assertequals  thread  call  netutils  t  testconnectionidletimeouts  getnumopenconnections  tostring   stagger cleanups  first
__label__flaky add  node  one  assert  equals  as  list  wf  fail  ex  get  error  code  <worklfow-app / >  test  self  transition  end  error  code  arrays  addnode  one  assertequals  aslist  wf  fail  ex  geterrorcode  <worklfow-app / >  testselftransition  end  errorcode  arrays
__label__nflaky test  set  key  value  expiration  ninja  cache  parse  duration  cache  set  10s  time  util  verify  expiration  value  key  testsetkeyvalueexpiration  ninjacache  parseduration  cache  set  10s  timeutil  verify  expiration  value  key
__label__flaky start . non-transient  _test  non  transient  assert  true  test  start  non  transient  start  workflow  action  bean  start . non-transient  _testnontransient  asserttrue  teststartnontransient  start  workflowactionbean
__label__nflaky g2  desc  c1  found  new  gauge  run  num  metrics  in  registry  metric  name  c1  already  exists  assert  true  get  c1  desc  g1  found  s1  g3  desc  test  s1  found  c2  found  test  new  metrics  g1  assert  equals  g2  g3  g3  found  c1  c2  c2  desc  s1  desc  new  stat  g2  found  expect  metrics  exception  r  ops  size  new  counter  g1  desc  time  metrics  test  dup  g2 desc  c1 found  newgauge  run  num metrics in registry  metric name c1 already exists  asserttrue  get  c1 desc  g1 found  s1  g3 desc  test  s1 found  c2 found  testnewmetrics  g1  assertequals  g2  g3  g3 found  c1  c2  c2 desc  s1 desc  newstat  g2 found  expectmetricsexception  r  ops  size  newcounter  g1 desc  time  metrics  test dup
__label__flaky cluster  0 . 0 . 0 . 0:0  conf  dn  get  self  addr  unset  dfs . datanode . ipc . address  system  wait  active  assert  that  default  self  socket  address  is  127 . 0 . 0 . 1  dn  self  socket  addr  ==  assert  true  assert  not  null  get  startup  option   / 0 . 0 . 0 . 0:  stop  data  node  -------------------------------------------------------------------------  *  by  default   the  data  node  socket  address  should  be  localhost   ( 127 . 0 . 0 . 1 )  .   *------------------------------------------------------------------------  get  data  nodes   / 127 . 0 . 0 . 1:  start  data  nodes  set  -------------------------------------------------------------------------  *  shut  down  the  datanodes   reconfigure   and  bring  them  back  up .   *  even  if  told  to  use  the  configuration  properties  for  dfs . datanode   *  mini  dfs  cluster . start  data  nodes (  )   should  use  localhost  as  the  default  if  *  the  dfs . datanode  properties  are  not  set .   *------------------------------------------------------------------------  assert  that  default  self  socket  address  is  0 . 0 . 0 . 0  dnp  dfs . datanode . address  dns  -------------------------------------------------------------------------  *  shut  down  the  datanodes   reconfigure   and  bring  them  back  up .   *  this  time   modify  the  dfs . datanode  properties  and  make  sure  that  they  *  are  used  to  configure  sockets  by  mini  dfs  cluster . start  data  nodes (  )  .   *------------------------------------------------------------------------  should  have  been  able  to  stop  simulated  datanode  size  build  test  dfs  address  config  to  string  self  socket  addr  dfs . datanode . http . address  shutdown  starts  with  cluster  0 . 0 . 0 . 0:0  conf  dn  getselfaddr  unset  dfs . datanode . ipc . address  system  waitactive   assert that default self socket address is 127 . 0 . 0 . 1  dn self socket addr ==   asserttrue  assertnotnull  get  startupoption   / 0 . 0 . 0 . 0:  stopdatanode  -------------------------------------------------------------------------       * by default  the datanode socket address should be localhost  ( 127 . 0 . 0 . 1 )  .        *------------------------------------------------------------------------  getdatanodes   / 127 . 0 . 0 . 1:  startdatanodes  set  -------------------------------------------------------------------------       * shut down the datanodes  reconfigure  and bring them back up .        * even if told to use the configuration properties for dfs . datanode        * minidfscluster . startdatanodes (  )  should use localhost as the default if       * the dfs . datanode properties are not set .        *------------------------------------------------------------------------   assert that default self socket address is 0 . 0 . 0 . 0  dnp  dfs . datanode . address  dns  -------------------------------------------------------------------------       * shut down the datanodes  reconfigure  and bring them back up .        * this time  modify the dfs . datanode properties and make sure that they       * are used to configure sockets by minidfscluster . startdatanodes (  )  .        *------------------------------------------------------------------------  should have been able to stop simulated datanode  size  build  testdfsaddressconfig  tostring  selfsocketaddr  dfs . datanode . http . address  shutdown  startswith
__label__nflaky the  test  is  kinit \  ' ed  because  the  test  renews  _their  tgt_ .   relogin  every  1  second  foo  keytab  hadoop_  kerberos_  min_  seconds_  before_  relogin  conf  principals  bogus-kinit-cmd  hadoop . kerberos . kinit . command  system  set  authentication  method  principal  logout  ugi  get  path  await  test  auto  renewal  thread  retry  with  kdc  work  dir  test  user  group  information#test  get  next  retry  time  set  configuration  value  user  group  information  info  add  set  get  property  set  log  level  test . dir  no  ticket  cache   so  force  the  thread  to  test  for  failures .   count  generic  test  utils  kdc  login  user  from  keytab  get  renewal  failures  login  context  get  login  user  spawn  auto  renewal  thread  for  user  creds  target  foo . keytab  set  long  renew  failure  count  is  {}  lambda  test  utils  create  principal  level  security  util  setup  kdc   the test is kinit \  ' ed because the test renews _their tgt_ .    relogin every 1 second  foo  keytab  hadoop_kerberos_min_seconds_before_relogin  conf  principals  bogus-kinit-cmd  hadoop . kerberos . kinit . command  system  setauthenticationmethod  principal  logout  ugi  getpath  await  testautorenewalthreadretrywithkdc  workdir   testusergroupinformation#testgetnextretrytime  setconfiguration  value  usergroupinformation  info  add  set  getproperty  setloglevel  test . dir   no ticket cache  so force the thread to test for failures .   count  generictestutils  kdc  loginuserfromkeytab  getrenewalfailures  logincontext  getloginuser  spawnautorenewalthreadforusercreds  target  foo . keytab  setlong  renew failure count is {}  lambdatestutils  createprincipal  level  securityutil  setupkdc
__label__flaky <event>  set  pretty  print  <job-data>jd< / job-data>  xml  utils  < / event>  <job-status>  started< / job-status>  el  to  xml  <user>u< / user>  assert  equals  actual  xml  <sequence-id>1< / sequence-id>  <sla-id>si< / sla-id>  <status>  < / status>  <app-name>an< / app-name>  <group>gn< / group>  <status-timestamp>1970-01-01  t00:00  z< / status-timestamp>  to  string  test  to  xml  status  event  bean  <event>    set  prettyprint      <job-data>jd< / job-data>    xmlutils  < / event>      <job-status>started< / job-status>    el  toxml      <user>u< / user>    assertequals  actualxml    <sequence-id>1< / sequence-id>        <sla-id>si< / sla-id>      <status>      < / status>        <app-name>an< / app-name>        <group>gn< / group>        <status-timestamp>1970-01-01t00:00z< / status-timestamp>    tostring  testtoxmlstatusevent  bean
__label__nflaky regex  validation  with  optional  passed  validate  jsr303  with  optional  length  build  dto  context  do  check  validation  passed  regex  validationwithoptionalpassed  validatejsr303withoptional  length  builddto  context  docheckvalidationpassed
__label__flaky recovery  service  get  name  coord  el  functions   / nodb / notable / dt=20120430;country=usa  callable  queue  service  coordinator  action  action  coord-job-for-action-input-check . xml  add  record  to  coord  action  table  for  waiting  new  h  cat  dependency  test  timeout  when  table  containing  missing  dependencies  is  dropped  in  between  info  delay  should  be  something  like  delay=599999 .   ignore  last  three  digits  should  be  requeued  at  the  recovery  service  interval  delay=5990-9{3}    . *  matches  set  int  coordinator  job  fail  contains  size  action  id  job   / nodb / notable / dt=20120430;country=brazil  server  add  record  to  coord  job  table  for  waiting  queue  dump  is  check  coord  action  but  only  push  missing  deps  are  there  log  get  id  coord-action-for-action-input-check . xml  assert  true  get  get  queue  dump  z  test  requeue  on  exception  get  conf  new  h  cat  dependency2  new  h  cat  dependency1  e  nothing  should  be  queued  as  there  are  no  pull  dependencies  hcat: /  /   get  message  assert  equals  set  missing  dependencies  queue  dump  call  services  no  such  object  exception  to  string  recoveryservice  getname  coordelfunctions   / nodb / notable / dt=20120430;country=usa  callablequeueservice  coordinatoraction  action  coord-job-for-action-input-check . xml  addrecordtocoordactiontableforwaiting  newhcatdependency   test timeout when table containing missing dependencies is dropped in between  info   delay should be something like delay=599999 .  ignore last three digits   should be requeued at the recovery service interval  delay=5990-9{3}   . *  matches  setint  coordinatorjob  fail  contains  size  actionid  job   / nodb / notable / dt=20120430;country=brazil  server  addrecordtocoordjobtableforwaiting  queue dump is   checkcoordaction   but only push missing deps are there  log  getid  coord-action-for-action-input-check . xml  asserttrue  get  getqueuedump  z  testrequeueonexception  getconf  newhcatdependency2  newhcatdependency1  e   nothing should be queued as there are no pull dependencies  hcat: /  /   getmessage  assertequals  setmissingdependencies  queuedump  call  services  nosuchobjectexception  tostring
__label__nflaky test  file01  get  path  data  testfile01  add  contents  -  s  ls  format  line  mtime  out  check  reverse  length  order   ( -  s  -r  options )   testfile03  set  file  length  in  different  order  to  file  names  options  compute  line  format  in  order  testfile02  process  options  verify  testfile05  test  file06  testfile04  test  file04  test  file05  testfile06  test  file02  test  file03  add  found  6  items  path  data  line  format  -r  length  set  is  dir  process  arguments  test  dir  test  directory  set  length  verify  no  more  interactions  process  path  dir  order  length  reverse  test  file  mock    testfile01  getpathdata  testfile01  addcontents  -s  ls  formatlinemtime  out   check reverse length order  ( -s -r options )   testfile03   set file length in different order to file names  options  computelineformat  inorder  testfile02  processoptions  verify  testfile05  testfile06  testfile04  testfile04  testfile05  testfile06  testfile02  testfile03  add  found 6 items  pathdata  lineformat  -r  length  setisdir  processarguments  testdir  testdirectory  setlength  verifynomoreinteractions  processpathdirorderlengthreverse  testfile  mock
__label__flaky cluster   / test / mkdirs /   testchunk  size  to  view  get  file  system  fs  datanode  jsp  helper  at  least  once  test  file  writer  mock  print  req  mock  <input  type= \ ""hidden \ ""  name= \ ""genstamp \ ""  value= \ ""987654321 \ "">  build  mockito  num  data  nodes  mock  generate  file  details  verify  test  gen  stamp  conf  set  the  mock  expectations  from  req  write  file  shutdown  cluster   / test / mkdirs / testchunksizetoview  getfilesystem  fs  datanodejsphelper  atleastonce  testfile  writermock  print  reqmock  <input type= \ ""hidden \ "" name= \ ""genstamp \ "" value= \ ""987654321 \ "">  build  mockito  numdatanodes  mock  generatefiledetails  verify  testgenstamp  conf  setthemockexpectationsfromreq  writefile  shutdown
__label__nflaky request  conn  test  execution  head  when  flush  executor  context  create  verify  ok  post  process  process  then  return  method  get  entity  execute   /   never  mockito  response  http  core  context  httprocessor  mock  pre  process  receive  response  header  send  request  header  receive  response  entity  request  conn  testexecutionhead  when  flush  executor  context  create  verify  ok  postprocess  process  thenreturn  method  getentity  execute   /   never  mockito  response  httpcorecontext  httprocessor  mock  preprocess  receiveresponseheader  sendrequestheader  receiveresponseentity
__label__flaky get  job  tracker  uri  get  name  <java>  test  id  swap  submit  ok  create  context  action  xml  is  successful  assert  true  context  idswap  wait  for  <job-tracker>  get  name  node  uri  < / java>  ae  < / main-class>  <capture-output / >  < / job-tracker>  get  message  running  job  get  action  check  <name-node>  <main-class>  < / name-node>  fail  contains  ex  <arg>id< / arg>  submit  action  evaluate  is  complete  getjobtrackeruri  getname  <java>  testidswapsubmitok  createcontext  actionxml  issuccessful  asserttrue  context  idswap  waitfor  <job-tracker>  getnamenodeuri  < / java>  ae  < / main-class>  <capture-output / >  < / job-tracker>  getmessage  runningjob  getaction  check  <name-node>  <main-class>  < / name-node>  fail  contains  ex  <arg>id< / arg>  submitaction  evaluate  iscomplete
__label__nflaky add  result  basic  to  array  typed  as  typed  array  cowa  list  assert  array  equals  add  result  basictoarraytyped  astypedarray  cowalist  assertarrayequals
__label__flaky jms  topic  service  bab  add  record  to  bundle  action  table  cab  add  record  to  wf  action  table  =  workflow   get  id  workflow  instance  get  topic  add  record  to  coord  action  table  setup  services  for  topic  coord  coord-action-for-action-input-check . xml  add  record  to  wf  job  table  =coord   default  =  get  coordinator  action  wab  cjb  bjb  workflow  job  job  init  set  get  bundle  action  id  print  stack  trace  get  conf  workflow  e  add  record  to  bundle  job  table  get  message  destroy  jms  topic  service  assert  equals  services  add  record  to  coord  job  table  fail  get  value  services  1  coordinator  job  workflow  action  test  mixed  topic1  wfj  jmstopicservice  bab  addrecordtobundleactiontable  cab  addrecordtowfactiontable   = workflow   getid  workflowinstance  gettopic  addrecordtocoordactiontable  setupservicesfortopic  coord  coord-action-for-action-input-check . xml  addrecordtowfjobtable  =coord  default =   get  coordinatoraction  wab  cjb  bjb  workflowjob  job  init  set  getbundleactionid  printstacktrace  getconf  workflow  e  addrecordtobundlejobtable  getmessage  destroy  jmstopicservice  assertequals  services  addrecordtocoordjobtable  fail  getvalue  services  1  coordinatorjob  workflowaction  testmixedtopic1  wfj
__label__nflaky next  joe  drwho joe  tardis users  drwho  add  user  assert  false  acl  get  acl  string  iterator  drwho  remove  user  get  users  is  zero  add  group  get  groups  is  one  groups  iter  test  add  remove  api  assert  that  drwho  tardis  users  contains  size  remove  group  tardis  is  equal  to  next  joe  drwho joe tardis users  drwho  adduser  assertfalse  acl  getaclstring  iterator  drwho   removeuser  getusers  iszero  addgroup  getgroups     isone  groups  iter  testaddremoveapi  assertthat  drwho tardis  users  contains  size  removegroup  tardis  isequalto
__label__flaky new_val  script  executor  select  *  from  entitywithstaticcolumn  where  id  =  entity  with  static  column / insert_single_row . cql  session  given  update  uui  ds  uuid  crud  should_update  new_static  when  of  id  value  static_col  execute  script  template  is  not  null  actual  random  utils  manager  one  time  based  get  string  next  long  assert  that  execute  immutable  map  and  uuid  =  then  long  is  equal  to  entity  new_val  scriptexecutor  select * from entitywithstaticcolumn where id =   entitywithstaticcolumn / insert_single_row . cql  session   given  update  uuids  uuid  crud  should_update  new_static   when  of  id  value  static_col  executescripttemplate  isnotnull  actual  randomutils  manager  one  timebased  getstring  nextlong  assertthat  execute  immutablemap   and uuid =    then  long  isequalto  entity
__label__nflaky add  token  then  return  service2  add  token  unchecked  from  mockito  mocks  service1  get  credentials  create  remote  user  assert  same  when  get  service  someone  ugi  add  token  with  another  name  get  token  mock  t1  t2  user  group  information  test  add  named  token  addtoken  thenreturn  service2   add token  unchecked   from mockito mocks  service1  getcredentials  createremoteuser  assertsame  when  getservice  someone  ugi   add token with another name  gettoken  mock  t1  t2  usergroupinformation  testaddnamedtoken
__label__flaky get  job  tracker  uri  get  name  <exec>sh< / exec>  create  context  submit  the  action  <capture-output   / >  context  create  action  <argument>script . sh< / argument>  write  wait  for  <job-tracker>  #  ae  ls  -ltr  echo  var1=$var1  echo  var2=$var2  < / job-tracker>  get  file  system  check  script  <name-node>  < / name-node>  string  to  properties  <file>  submit  action  checking  action  data  from  shell  script  output  script . sh  evaluate  properties  utils  <argument>  a< / argument>  wait  for  the  external  job  to  get  app  path  create  the  script  file  with  canned  shell  command  fs  <env-var>var2=  <env-var>var1=val1< / env-var>  action  xml  < / env-var>  <shell>  < / file>  end  var2  close  get  data  a=b;c=d  get  name  node  uri  launcher  job  finish  get  property  shell  script  <argument>-c< / argument>  test  env  var  get  action  assert  equals  < / shell>  w  <argument>  b< / argument>  env  value  having  equal  sign  create  sample  shell  action  xml  to  string  is  complete  getjobtrackeruri  getname  <exec>sh< / exec>  createcontext   submit the action  <capture-output  / >  context  create  action  <argument>script . sh< / argument>  write  waitfor  <job-tracker>  #  ae  ls -ltr  echo var1=$var1  echo var2=$var2  < / job-tracker>  getfilesystem  check  script  <name-node>  < / name-node>  stringtoproperties  <file>  submitaction   checking action data from shell script output  script . sh  evaluate  propertiesutils  <argument>a< / argument>   wait for the external job to  getapppath   create the script file with canned shell command  fs  <env-var>var2=  <env-var>var1=val1< / env-var>  actionxml  < / env-var>  <shell>  < / file>  end  var2  close  getdata  a=b;c=d  getnamenodeuri  launcherjob   finish  getproperty  shellscript  <argument>-c< / argument>  testenvvar  getaction  assertequals  < / shell>  w  <argument>b< / argument>  envvaluehavingequalsign   create sample shell action xml  tostring  iscomplete
__label__nflaky tt  wait  for  consumers  to  wake  up   then  consume  pt  create  putters  and  takers  conf  put  swap  queue  sleep  scheduler  class  total  calls  created  get  interrupt  total  calls  consumed  queue  class  consumers  join  stop  the  producers  add  manager  start  threads  assert  equals  producers  thread  p  t  stop  size  ensure  no  calls  were  dropped  test  swap  under  contention    tt   wait for consumers to wake up  then consume  pt   create putters and takers  conf  put  swapqueue  sleep  schedulerclass  totalcallscreated  get  interrupt  totalcallsconsumed  queueclass  consumers  join   stop the producers  add  manager  start  threads  assertequals  producers  thread  p  t  stop  size   ensure no calls were dropped  testswapundercontention
__label__flaky node  is  not  decommisioned .   write  to  hosts  file  get  metrics  conf  host  file  nm2  nm1  node  action  assert  node  heartbeat  get  node  action  yarn  configuration  nm3  assert  true  metric  count  refresh  nodes  test  decommission  with  include  hosts  localhost  get  nodes  list  manager  check  decommissioned  nm  count  set  host1  get  absolute  path  host2  ip  start  localhost:4433  host2:5678  assert  equals  host1:1234  normalize  host  name  net  utils  cluster  metrics  register  node  equals  get  num  decommisioned  n  ms  rm  metrics  to  test  that  i  ps  also  work  node is not decommisioned .   writetohostsfile  getmetrics  conf  hostfile  nm2  nm1  nodeaction  assert  nodeheartbeat  getnodeaction  yarnconfiguration  nm3  asserttrue  metriccount  refreshnodes  testdecommissionwithincludehosts  localhost  getnodeslistmanager  checkdecommissionednmcount  set  host1  getabsolutepath  host2  ip  start  localhost:4433  host2:5678  assertequals  host1:1234  normalizehostname  netutils  clustermetrics  registernode  equals  getnumdecommisionednms  rm  metrics   to test that ips also work
__label__nflaky bais  < / configuration>  conf  conf  test  assert  equals  get  bytes  line  2:  <property>  has  no  <name>  size  check  conf  get  < / property>  <property>  <configuration>  <value>foo< / value>  errors  test  property  has  no  name  bais  < / configuration>  conf  conftest  assertequals  getbytes  line 2: <property> has no <name>  size  checkconf  get  < / property>    <property>    <configuration>    <value>foo< / value>    errors  testpropertyhasnoname
__label__flaky assert  false  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  is  pending  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  assert  not  null  get  coordinator  action  end  current  date  plus  month  wait  for  start  x  data  test  case  execute  add  record  to  coord  job  table  coordinator  job  job  id  services  runnable  coord-action-get . xml  test  coord  status  transit  service  killed  by  user2  job  jpa  service  evaluate  assertfalse  getcurrentdateafterincrementinginmonths  getid  run  dateutils  ispending  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  waitfor  start  xdatatestcase  execute  addrecordtocoordjobtable  coordinatorjob  jobid  services  runnable  coord-action-get . xml  testcoordstatustransitservicekilledbyuser2  job  jpaservice  evaluate
__label__nflaky c  test  fair  call  queue  mx  bean  assert  equals  management  factory  put  queue  sizes  mock  call  hadoop:service=ns name=  fair  call  queue  call  take  get  attribute  fcq  get  platform  m  bean  server  mxbean  name  mbs  queue  sizes  c  testfaircallqueuemxbean  assertequals  managementfactory  put  queuesizes  mockcall  hadoop:service=ns name=faircallqueue  call  take  getattribute  fcq  getplatformmbeanserver  mxbeanname  mbs  queuesizes
__label__flaky @  fail  test  valid  token  validate  action  name  az  az09_-  param  checker    @  fail  testvalidtoken  validateactionname  azaz09_-  paramchecker
__label__nflaky 123-value-via-system-property  verify  system  property  overrides  it   \ %dev . unit . test . 123  unit . test . 123  is  assert  that  123-value-via-external-conf  system  clear  property  system  properties  ninja  mode  verify  property  in  external  conf  is  set  123-value-via-prefixed-system-property  conf / system_property . conf  get  set  property  ninja  properties  verify  prefixed  system  property  overrides  both  123-value-via-system-property   verify system property overrides it   \ %dev . unit . test . 123  unit . test . 123  is  assertthat  123-value-via-external-conf  system  clearproperty  systemproperties  ninjamode   verify property in external conf is set  123-value-via-prefixed-system-property  conf / system_property . conf  get  setproperty  ninjaproperties   verify prefixed system property overrides both
__label__flaky get  job  tracker  uri  < / name-node>  <configuration>  case:  launcher  specific  ac  ls  not  configured  -  set  defaults  <java>  < / configuration>  get  app  path  get  actions  conf  setup  action  conf  create  base  hadoop  conf  action  xml  wf  bean  add  record  to  wf  job  table  get  context  action  java  action  executor  test1-acl  <job-tracker>  get  name  node  uri  e  action  xml  test  acl  defaults_launcher  ac  ls  set  to  default  modifier  action  conf  < / java>  ae  xml  utils  parse  xml  < / job-tracker>  create  launcher  conf  assert  equals  <main-class>  main-  class< / main-class>  get  file  system  set  type  <name-node>  viewer  get  type  <property><name>mapreduce . job . acl-view-job< / name><value>  viewer< / value>< / property>  <property><name>mapreduce . job . acl-modify-job< / name><value>  modifier< / value>< / property>  getjobtrackeruri  < / name-node> <configuration>   case: launcher specific acls not configured - set defaults  <java>  < / configuration>  getapppath  getactions  conf  setupactionconf  createbasehadoopconf  actionxml  wfbean  addrecordtowfjobtable  get  context  action  javaactionexecutor  test1-acl  <job-tracker>  getnamenodeuri  eactionxml  testacldefaults_launcheraclssettodefault  modifier  actionconf  < / java>  ae  xmlutils  parsexml  < / job-tracker>  createlauncherconf  assertequals  <main-class>main-class< / main-class>  getfilesystem  settype  <name-node>  viewer  gettype  <property><name>mapreduce . job . acl-view-job< / name><value>viewer< / value>< / property>  <property><name>mapreduce . job . acl-modify-job< / name><value>modifier< / value>< / property>
__label__nflaky unknown: /  /  /   set  e  get  providers  credential  provider  factory  get  message  conf  assert  equals  test  factory  errors  assert  true  should  throw !   no  credential  provider  factory  for  unknown: /  /  /   in  providers  unknown: /  /  /   set  e  getproviders  credentialproviderfactory  getmessage  conf  assertequals  testfactoryerrors  asserttrue  should throw !   no credentialproviderfactory for unknown: /  /  /  in   providers
__label__flaky get  job  tracker  uri  map-reduce  map-reduce-launcher . jar  oozie . streaming . mapper  oozie . streaming . reducer  <pipes>  < / configuration>  conf  setup  action  conf  proto  conf  create  base  workflow  <reduce>  r< / reduce>  <map-reduce>  context  action  mapred . input . dir  test  setup  methods  if  <job-tracker>  oozie . pipes . writer  add  ae  in  <record-reader-mapping>  rrm1=1< / record-reader-mapping>  oozie . pipes . inputformat  parse  xml  oozie . pipes . partitioner  < / job-tracker>  < / pipes>  oozie . pipes . program  <name-node>  < / name-node>  2  <streaming>  get  type  <env>ee=  ee< / env>  <map>  m< / map>  < / streaming>  <writer>  w< / writer>  oozie . streaming . record-reader  rr  <record-reader>  rr< / record-reader>  get  classes  for  launcher  classes  get  actions  <reducer>  r< / reducer>  <inputformat>  if< / inputformat>  m  oozie . pipes . reduce  create  base  hadoop  conf  mr-action  wf  action  xml  p  <partitioner>  p< / partitioner>  r  get  w  <program>  pp< / program>  <mapper>  m< / mapper>  get  name  node  uri  <record-reader-mapping>  rrm2=2< / record-reader-mapping>  <property><name>mapred . output . dir< / name><value>  out< / value>< / property>  set  xml  utils  workflow  app  service  get  launcher  classes  oozie . streaming . env . size  oozie . pipes . map  assert  equals  <configuration>  set  type  get  launcher  jar  name   /   pp  < / map-reduce>  services  get  test  user  add  all  <property><name>mapred . input . dir< / name><value>  in< / value>< / property>  <env>e=  e< / env>  oozie . streaming . record-reader-mapping . size  get  fs  test  case  dir  getjobtrackeruri  map-reduce  map-reduce-launcher . jar  oozie . streaming . mapper  oozie . streaming . reducer  <pipes>  < / configuration>  conf  setupactionconf  protoconf  createbaseworkflow  <reduce>r< / reduce>  <map-reduce>  context  action  mapred . input . dir  testsetupmethods  if  <job-tracker>  oozie . pipes . writer  add  ae  in  <record-reader-mapping>rrm1=1< / record-reader-mapping>  oozie . pipes . inputformat  parsexml  oozie . pipes . partitioner  < / job-tracker>  < / pipes>  oozie . pipes . program  <name-node>  < / name-node>  2  <streaming>  gettype  <env>ee=ee< / env>  <map>m< / map>  < / streaming>  <writer>w< / writer>  oozie . streaming . record-reader  rr  <record-reader>rr< / record-reader>  getclassesforlauncher  classes  getactions  <reducer>r< / reducer>  <inputformat>if< / inputformat>  m  oozie . pipes . reduce  createbasehadoopconf  mr-action  wf  actionxml  p  <partitioner>p< / partitioner>  r  get  w  <program>pp< / program>  <mapper>m< / mapper>  getnamenodeuri  <record-reader-mapping>rrm2=2< / record-reader-mapping>  <property><name>mapred . output . dir< / name><value>out< / value>< / property>  set  xmlutils  workflowappservice  getlauncherclasses  oozie . streaming . env . size  oozie . pipes . map  assertequals  <configuration>  settype  getlauncherjarname   / pp  < / map-reduce>  services  gettestuser  addall  <property><name>mapred . input . dir< / name><value>in< / value>< / property>  <env>e=e< / env>  oozie . streaming . record-reader-mapping . size  getfstestcasedir
__label__nflaky create  keys  and  put  it  in  wrong  number  of  keys  in  the  storage  get  secret  key  map  tmp  file  name  compare  secret  keys  put  dis  get  the  tokens  and  compare  the  services  get  token  map  token  map  assert  not  null  token1  token2  secret  key  map  write  add  get  key  not  found  entry  set  default_  hmac_  algorithm  get  encoded  contains  key  service2  unchecked  service1  test  read  write  storage  read  fields  entry  size  open  and  read  it  back  get  token  map  should  return  collection  of  size  2  arrays  alias1  dos  alias2  token  for  service  delete  tmp  dir  sometoken2  sometoken1  keys  don \  ' t  match  for  alias  assert  true  secret  key  for  alias  get  alias  token  for  alias  kg  add  secret  key  key  generator  close  key  add  token  create  file  to  store  number  of  secret  keys  create  token  storage  object  assert  equals  services  m  get  service  generate  key  set  service  get  value  must  be  present  equals  get  instance  ts  token  storage  test   create keys and put it in  wrong number of keys in the storage  getsecretkeymap  tmpfilename   compare secret keys  put  dis   get the tokens and compare the services  gettokenmap  tokenmap  assertnotnull  token1  token2  secretkeymap  write  add  getkey   not found  entryset  default_hmac_algorithm  getencoded  containskey  service2  unchecked  service1  testreadwritestorage  readfields  entry  size   open and read it back  gettokenmap should return collection of size 2  arrays  alias1  dos  alias2  token for service   delete  tmpdir  sometoken2  sometoken1  keys don \  ' t match for alias   asserttrue  secret key for alias   get  alias  token for alias   kg  addsecretkey  keygenerator  close  key  addtoken   create file to store  numberofsecretkeys   create tokenstorage object  assertequals  services  m  getservice  generatekey  setservice  getvalue   must be present  equals  getinstance  ts  tokenstoragetest
__label__flaky coord  id1  app  name1  assert  equals  create  filter  list  list  coord  action  id1  execute  as  list  put  jobid  services  sla  events  get  cmd  appname  last  seq  id  size  assert  not  null  get  filter  list  arrays  jpa  service  test  get  sla  events  for  combined  coordid1  appname1  assertequals  createfilterlist  list  coordactionid1  execute  aslist  put  jobid  services  slaeventsgetcmd  appname  lastseqid  size  assertnotnull  get  filterlist  arrays  jpaservice  testgetslaeventsforcombined
__label__nflaky defaults  vary  by  number  of  queues  set  get  thresholds  ns  decay  rpc  scheduler  ns .   conf  deprecation  1   10   20   50   85  scheduler  assert  equal  decimal  arrays  custom  test  parse  thresholds     defaults vary by number of queues  set  getthresholds  ns  decayrpcscheduler  ns .   conf  deprecation  1  10  20  50  85  scheduler  assertequaldecimalarrays   custom  testparsethresholds
__label__flaky unexpected  exception  def  add  node  print  stack  trace  test  wf  no  fork  join  e  one  three  two  fail  invoke  fork  join  parser  name  dummy  conf  end  *  1->ok->2  *  2->ok->end  unexpected exception  def  addnode  printstacktrace  testwfnoforkjoin  e  one  three  two  fail  invokeforkjoin  parser  name  dummyconf  end         * 1->ok->2       * 2->ok->end
__label__nflaky p1  p2  get  kms  url  conf  when  get  cause  times  assert  true  should  fail  since  provider  p1  threw  authentication  exception  verify  then  throw  test  client  retries  with  authentication  exception  wrappedin  io  exception  kp  e  any  string  then  return  create  key  eq  any  set  int  common  configuration  keys  public  fail  test3  mockito  mock  p1  p2  getkmsurl  conf  when  getcause  times  asserttrue  should fail since provider p1 threw authenticationexception  verify  thenthrow  testclientretrieswithauthenticationexceptionwrappedinioexception  kp  e  anystring  thenreturn  createkey  eq  any  setint  commonconfigurationkeyspublic  fail  test3  mockito  mock
__label__flaky <controls>  <timeout>10< / timeout>  <concurrency>2< / concurrency>  <execution>  lifo< / execution>  <throttle>3< / throttle>< / controls>  <datasets>  <dataset  name= \  ' a \  '   frequency= \  ' ${coord:days ( 7 ) } \  '   initial-instance= \  ' 2009-02-01  t01:00  z \  '   timezone= \  '   utc \  ' >  <uri-template>file: /  /  / tmp / coord / workflows / ${  year} / ${  day}< / uri-template>  < / dataset>  <dataset  name= \  ' local_a \  '   frequency= \  ' ${coord:days ( 7 ) } \  '   initial-instance= \  ' 2009-02-01  t01:00  z \  '   timezone= \  '   utc \  ' >  <uri-template>file: /  /  / tmp / coord / workflows / ${  year} / ${  day}< / uri-template>  < / dataset>  < / datasets>  <input-events>  <data-in  name= \  '   a \  '   dataset= \  ' a \  ' >  <instance>${coord:latest ( 0 ) }< / instance>  < / data-in>  < / input-events>  <output-events>  <data-out  name= \  '   local_  a \  '   dataset= \  ' local_a \  ' >  <instance>${coord:current ( -1 ) }< / instance>  < / data-out>  < / output-events>  <action>  <workflow>  <app-path>hdfs: /  /  / tmp / workflows / < / app-path>  <configuration>  <property>  <name>input  a< / name>  <value>${coord:data  in (  \  '   a \  '  ) }< / value>  < / property>  <property>  <name>input  b< / name>  <value>${coord:data  out (  \  '   local_  a \  '  ) }< / value>  < / property>< / configuration>  < / workflow>  <coordinator-app  name= \  '   name \  '   frequency= \  ' ${coord:days ( 1 ) } \  '   start= \  ' 2009-02-01  t01:00  z \  '   end= \  ' 2009-02-03  t23:59  z \  '   timezone= \  '   utc \  '   xmlns:xsi= \  ' http: /  / www . w3 . org / 2001 /   xml  schema-instance \  '   xmlns= \  ' uri:oozie:coordinator:0 . 2 \  '   xmlns:sla= \  ' uri:oozie:sla:0 . 1 \  ' >  xml  utils  e  validator  parse  xml  < / action>  < / coordinator-app>  new  validator  get  schema  coord_  app1  services  wss  get  test  coord  schema2  schema  name  validate  system . out . println (  \ ""  xml  : \ ""+  xml  utils . pretty  print ( e )  ) ;  <controls> <timeout>10< / timeout> <concurrency>2< / concurrency> <execution>lifo< / execution>  <throttle>3< / throttle>< / controls> <datasets> <dataset name= \  ' a \  '  frequency= \  ' ${coord:days ( 7 ) } \  '  initial-instance= \  ' 2009-02-01t01:00z \  '  timezone= \  ' utc \  ' > <uri-template>file: /  /  / tmp / coord / workflows / ${year} / ${day}< / uri-template> < / dataset> <dataset name= \  ' local_a \  '  frequency= \  ' ${coord:days ( 7 ) } \  '  initial-instance= \  ' 2009-02-01t01:00z \  '  timezone= \  ' utc \  ' > <uri-template>file: /  /  / tmp / coord / workflows / ${year} / ${day}< / uri-template> < / dataset> < / datasets> <input-events> <data-in name= \  ' a \  '  dataset= \  ' a \  ' > <instance>${coord:latest ( 0 ) }< / instance> < / data-in>  < / input-events> <output-events> <data-out name= \  ' local_a \  '  dataset= \  ' local_a \  ' > <instance>${coord:current ( -1 ) }< / instance> < / data-out> < / output-events> <action> <workflow> <app-path>hdfs: /  /  / tmp / workflows / < / app-path> <configuration> <property> <name>inputa< / name> <value>${coord:datain (  \  ' a \  '  ) }< / value> < / property> <property> <name>inputb< / name> <value>${coord:dataout (  \  ' local_a \  '  ) }< / value> < / property>< / configuration> < / workflow>    <coordinator-app name= \  ' name \  '  frequency= \  ' ${coord:days ( 1 ) } \  '  start= \  ' 2009-02-01t01:00z \  '  end= \  ' 2009-02-03t23:59z \  '  timezone= \  ' utc \  '  xmlns:xsi= \  ' http: /  / www . w3 . org / 2001 / xmlschema-instance \  '  xmlns= \  ' uri:oozie:coordinator:0 . 2 \  '  xmlns:sla= \  ' uri:oozie:sla:0 . 1 \  ' >   xmlutils  e  validator  parsexml  < / action> < / coordinator-app>  newvalidator  getschema  coord_app1  services  wss  get  testcoordschema2  schemaname  validate   system . out . println (  \ ""xml : \ ""+ xmlutils . prettyprint ( e )  ) ;
__label__nflaky request  assert  nothing  thrown  set  request  handler  put  modify  response  expectations  status  assert  headers  assert  true  run  tests  make  sure  the  modify  request  method  was  called  by  seeing  if  the  request  was  modified .   content_  type  get  verify  add  test  something_unlikely_to_be_in_a_real_response  unlikely_  item  modify  response  expectations  should  have  been  called .   adapter  contains  key  response  expectations  execute  modify  response  expectations  called  let  the  adapter  change  the  request  if  needed .   framework  mockito  response  mock  request  handler  new  framework  and  set  adapter  mock  assert  nothing  thrown (  )   should  have  been  called .   body  request  assertnothingthrown  setrequesthandler  put  modifyresponseexpectations  status  assert  headers  asserttrue  runtests   make sure the modifyrequest method was called by seeing if the request was modified .   content_type  get  verify  addtest  something_unlikely_to_be_in_a_real_response  unlikely_item  modifyresponseexpectations should have been called .   adapter  containskey  responseexpectations  execute  modifyresponseexpectationscalled   let the adapter change the request if needed .   framework  mockito  response  mockrequesthandler  newframeworkandsetadapter  mock   assertnothingthrown (  )  should have been called .   body
__label__flaky job  conf  < / configuration>  assert  array  equals  get  default  share  lib  name  oozie . action . sharelib . for . java  wf  bean  assert  get  context  action  action  conf  set  ae  get  conf  java-action-executor  java-oozie-conf  <property>  <configuration>  set  conf  services  java-action-conf  get  share  lib  names  <configuration / >  < / property>  java-job-conf  test  action  sharelib  resolution  <name>oozie . action . sharelib . for . java< / name>  <value>java-job-conf< / value>  jobconf  < / configuration>  assertarrayequals  getdefaultsharelibname  oozie . action . sharelib . for . java  wfbean  assert  get  context  action  actionconf  set  ae  getconf  java-action-executor  java-oozie-conf  <property>  <configuration>  setconf  services  java-action-conf  getsharelibnames  <configuration / >  < / property>  java-job-conf  testactionsharelibresolution  <name>oozie . action . sharelib . for . java< / name>  <value>java-job-conf< / value>
__label__nflaky get  bytes  transferred  rw  codec  test  utils  assert  false  channel  transferred  from  buffer  stuff;  more  stuff;  assert  inbuf  get  channel  pos  assert  true  stuff;  more  stuff;  a  lot  more  stuff !   a  lot  more  stuff !  !  !   close  fchannel  is  completed  transferred  from  channel  testfile  standard  charsets  bytes  read  assert  equals  create  temp  file  decoder  fill  transfer  read  from  file  metrics  test  decoding  file  with  limit  getbytestransferred  rw  codectestutils  assertfalse  channel   transferred from buffer  stuff; more stuff;   assert  inbuf  getchannel  pos  asserttrue  stuff; more stuff; a lot more stuff !   a lot more stuff !  !  !   close  fchannel  iscompleted   transferred from channel  testfile  standardcharsets  bytesread  assertequals  createtempfile  decoder  fill  transfer  readfromfile  metrics  testdecodingfilewithlimit
__label__flaky play  handler  increment  and  get  android  play  it  back  header  entries  verify  the  peer  received  what  was  expected  type_  rst_  stream  cola  accept  frame  stream  get  error  code  type_  headers  peer  receive  count  reply  protocol_  error  syn_  reply  take  frame  rst  stream  banana  a  receive  b  c  open  socket  int  value  remote  double  syn  stream  assert  equals  rst_  stream  headers  mode  get  request  headers  send  frame  build  write  the  mocking  script  syn  stream  play  handler  incrementandget  android   play it back  headerentries   verify the peer received what was expected  type_rst_stream  cola  acceptframe  stream  geterrorcode  type_headers  peer  receivecount  reply  protocol_error   syn_reply  takeframe  rststream  banana  a  receive  b  c  opensocket  intvalue  remotedoublesynstream  assertequals   rst_stream  headersmode  getrequestheaders  sendframe  build   write the mocking script  synstream
__label__nflaky fail  process  assert  interceptor  test  request  content  invalid  input  illegal  argument  exception  should  have  been  thrown  fail  process  assert  interceptor  testrequestcontentinvalidinput  illegalargumentexception should have been thrown
__label__flaky test  get  jobs  submit  job  reader  end . error  conf  error  job  id2  job  id1  engine  get  test  case  dir   / workflow . xml  file: /  /   workflow . xml  ok  ok  a  external-status  set  wf-ext-schema-valid . xml  oozie  client  io  utils  get  test  user  t  signal-value  copy  char  stream  get  resource  as  reader  writer  file  testgetjobs  submitjob  reader  end . error  conf  error  jobid2  jobid1  engine  gettestcasedir   / workflow . xml  file: /  /   workflow . xml  ok  ok  a  external-status  set  wf-ext-schema-valid . xml  oozieclient  ioutils  gettestuser  t  signal-value  copycharstream  getresourceasreader  writer  file
__label__nflaky exception  should  specify  parsing  error  and  invalid  umask:  22  99  b  set  foo  get  message  conf  iae  shouldn \  ' t  have  been  able  to  parse  bad  umask  fail  1777  assert  true  is  correct  exception  message  get  u  mask  fs  permission  test  bad  umasks  exception should specify parsing error and invalid umask:   22  99    b  set  foo  getmessage  conf  iae  shouldn \  ' t have been able to parse bad umask  fail  1777  asserttrue  iscorrectexceptionmessage  getumask  fspermission  testbadumasks
__label__flaky test  feature  reflection  equals   /   feature  modify  data  in  zk  setup  test  with  empty  datastore  run  get  bytes  sleep  externally  set  state  wrapper  set  parameter  set  feature  state  await  json  time  unit  latch  count  down  server  client  pair  externally  set  state  for  path  test_  znode  print  stack  trace  e  set  data  test  zk  node  changes  update  feature  state  utf-8  start  set  strategy  id  user1   user2   user3  is  assert  that  get  feature  state  thread  loaded  feature  state  object  mapper  saved  feature  state  username  activation  strategy  state  repository  write  value  as  string  testfeature  reflectionequals   / feature   modify data in zk  setuptestwithemptydatastore  run  getbytes  sleep  externallysetstatewrapper  setparameter  setfeaturestate  await  json  timeunit  latch  countdown  serverclientpair  externallysetstate  forpath  test_znode  printstacktrace  e  setdata  testzknodechangesupdatefeaturestate  utf-8  start  setstrategyid  user1  user2  user3  is  assertthat  getfeaturestate  thread  loadedfeaturestate  objectmapper  savedfeaturestate  usernameactivationstrategy  staterepository  writevalueasstring
__label__nflaky request  conn  in  stream  post   / stuff  http / 1 . 1  user-  agent:  test  transfer-  encoding:  get  endpoint  details  get  content  user-  agent  get  method  when  test  read  request  entity  chunck  coded  get  bytes  content  receive  request  header  chunked  3  123  0  receive  request  entity  bind  assert  is  chunked  assert  true  assert  not  null  get  path   / stuff  get  request  count  standard  charsets  then  return  assert  equals  method  get  entity  get  content  length  get  input  stream  assert  null  mockito  name  socket  contains  header  entity  request  conn  instream  post  / stuff http / 1 . 1  user-agent: test  transfer-encoding:   getendpointdetails  getcontent  user-agent  getmethod  when  testreadrequestentitychunckcoded  getbytes  content  receiverequestheader  chunked    3  123  0      receiverequestentity  bind  assert  ischunked  asserttrue  assertnotnull  getpath   / stuff  getrequestcount  standardcharsets  thenreturn  assertequals  method  getentity  getcontentlength  getinputstream  assertnull  mockito  name  socket  containsheader  entity
__label__flaky add  record  to  wf  action  table  get  id  workflow  instance  get  status  update  the  list  for  doing  bulk  writes  coord  job  wf  job  add  record  to  wf  job  table  assert  not  null  get  action  workflow  job  update  list  add  get  status  str  update  the  status  check  for  expected  status  after  running  bulk  update  jpa  running  assert  equals  execute  add  record  to  coord  job  table  set  status  coordinator  job  1  services  set  update  list  workflow  action  bulk  update  cmd  succeeded  test  updates  action2  jpa  service  addrecordtowfactiontable  getid  workflowinstance  getstatus   update the list for doing bulk writes  coordjob  wfjob  addrecordtowfjobtable  assertnotnull  get  action  workflowjob  updatelist  add  getstatusstr   update the status   check for expected status after running bulkupdatejpa  running  assertequals  execute  addrecordtocoordjobtable  setstatus  coordinatorjob  1  services  setupdatelist  workflowaction  bulkupdatecmd  succeeded  testupdates  action2  jpaservice
__label__nflaky delegation  token  authentication  handler  request  foo  assert  false  conf  get  method  when  put  test  writer  not  closed  no  auth  close  handler  assert  kerberos  delegation  token  authentication  handler  get  user  name  close  write  init  json  factory  print  writer  close  count  getdelegationtoken  op  then  return  auto_  close_  target  false  delegation  token  authenticator  get  query  string  destroy  token  str  already  closed !   management  operation  mockito  response  get  writer  set  value  mock  closed  to  string  get  http  method  boolean  value  =  user  init  token  manager  delegationtokenauthenticationhandler  request  foo  assertfalse  conf  getmethod  when  put  testwriternotclosed  noauthclosehandler  assert  kerberosdelegationtokenauthenticationhandler  getusername  close  write  initjsonfactory  printwriterclosecount  getdelegationtoken  op  thenreturn  auto_close_target  false  delegationtokenauthenticator  getquerystring  destroy  token  str  already closed !   managementoperation  mockito  response  getwriter  setvalue  mock  closed  tostring  gethttpmethod  booleanvalue  =  user  inittokenmanager
__label__flaky test  coord  re  run3  end_  points  is_  security_  enabled  -action  oozie  url  -refresh  run  app  path  assert  true  get  create  servlet_  classes  close  run  test  app  mock  coordinator  engine  service  coordinator . xml  rest  constants  get  context  url  assert  equals  get  file  system  -rerun  0  args  call  -oozie  mkdirs  job  get  fs  test  case  dir  testcoordrerun3  end_points  is_security_enabled  -action  oozieurl  -refresh  run  apppath  asserttrue  get  create  servlet_classes  close  runtest  app  mockcoordinatorengineservice  coordinator . xml  restconstants  getcontexturl  assertequals  getfilesystem  -rerun  0  args  call  -oozie  mkdirs  job  getfstestcasedir
__label__nflaky {hello:{world:yay}}  option  helper  curly  braces_  logback_1101  {world:{yay}}  {foo{ \ ""bar \ ""}}  assert  equals  { \ ""hello \ "":{ \ ""world \ "": \ ""yay \ ""}}  input  r  a:{y}  foo{bar}  context  subst  vars  {hello:{world:yay}}  optionhelper  curlybraces_logback_1101  {world:{yay}}  {foo{ \ ""bar \ ""}}  assertequals  { \ ""hello \ "":{ \ ""world \ "": \ ""yay \ ""}}  input  r  a:{y}  foo{bar}  context  substvars
__label__flaky play  ping  play  it  back  this  ping  will  not  be  returned .   verify  the  peer  received  what  was  expected  assert  equals  accept  frame  send  frame  peer  spdy3  write  the  mocking  script  ping4  unexpected  ping  is  not  returned  ping  connection  ping2  take  frame  play  ping   play it back   this ping will not be returned .    verify the peer received what was expected  assertequals  acceptframe  sendframe  peer  spdy3   write the mocking script  ping4  unexpectedpingisnotreturned   ping  connection  ping2  takeframe
__label__nflaky wait  for  the  async  task  to  finish  test  sync  generation  policy  k1  assert  equals  get  next  test  drain  drain  drain  completely   no  further  refills  triggered  the  prefill  to  the  low  watermark   1  consumed  by  get  next (  )  )   wait  for  refill  assert  assert  null  trigger  a  prefill   ( 1 )   and  an  async  refill   ( 10 )   wait  a  while  to  make  sure  that  no  async  refills  are  triggered  get  top  filler  vq  shutdown   wait for the async task to finish  test  syncgenerationpolicy  k1  assertequals  getnext  testdrain  drain   drain completely  no further refills triggered   the prefill to the low watermark  1 consumed by getnext (  )  )   waitforrefill  assert  assertnull   trigger a prefill  ( 1 )  and an async refill  ( 10 )    wait a while to make sure that no async refills are triggered  gettop  filler  vq  shutdown
__label__flaky fail  vfs  dfs_  block_  size_  default  test  should  still  pass  get  server  defaults  on  view  fs  did  not  throw  excetion !   test  file  path  test  get  default  block  size  assert  equals  get  default  block  size  fail  vfs  dfs_block_size_default   test should still pass  getserverdefaults on viewfs did not throw excetion !   testfilepath  testgetdefaultblocksize  assertequals  getdefaultblocksize
__label__nflaky assume  false  ex  assert  ex  contains  get  win  utils  file  e_  not_  a_  windows_  system  get  win  utils  path  windows  assume  test  no  winutils  on  unix  get  cause  assumefalse  ex  assertexcontains  getwinutilsfile  e_not_a_windows_system  getwinutilspath  windows  assume  testnowinutilsonunix  getcause
__label__flaky end_  points  rest  constants  is_  security_  enabled  get  context  url  oozie  url  start  mock  dag  engine  service  conf  assert  equals  wc  test  start  call  oozie  client  1  set  property  create  configuration  servlet_  classes  run  test  end_points  restconstants  is_security_enabled  getcontexturl  oozieurl  start  mockdagengineservice  conf  assertequals  wc  teststart  call  oozieclient  1  setproperty  createconfiguration  servlet_classes  runtest
__label__nflaky server  connectors  get  default  socket  factory  conf  run  sleep  server  should  drop  the  other  4  connections  join  addr  close  connect  test  max  connections  start  assert  equals  server  should  only  accept  up  to  6  connections  set  int  get  connect  address  thread  sock  net  utils  create  socket  stop  get  num  open  connections  get  num  dropped  connections  ipc . server . max . connections  server  connectors  getdefaultsocketfactory  conf  run  sleep   server should drop the other 4 connections  join  addr  close  connect  testmaxconnections  start  assertequals   server should only accept up to 6 connections  setint  getconnectaddress  thread  sock  netutils  createsocket  stop  getnumopenconnections  getnumdroppedconnections  ipc . server . max . connections
__label__flaky container   / ping / *  conn  open  connection  reader  ping  ping  servlet  start  assert  equals  read  line  add  servlet  endpoint  get  input  stream  url  http  url  connection  stop  get  servlet  url  assert  true  bla  get  response  code  add  filter  test  embedded  servlet  container  connect  blah  container   / ping / *  conn  openconnection  reader  ping  pingservlet  start  assertequals  readline  addservletendpoint  getinputstream  url  httpurlconnection  stop  getservleturl  asserttrue  bla  getresponsecode  addfilter  testembeddedservletcontainer  connect  blah
__label__nflaky assert  null  is  textual  context  type  assert  false  get  sub  type  null  context  content  type  util  assertnull  istextual  contexttype  assertfalse  getsubtype  nullcontext  contenttypeutil
__label__flaky a  a:1-  l  a:2-  n  a:1-  u  l1  l2  start  assert  equals  sb  thread  sleep  trim  test  no  wait  write  lock  finish  to  string    a  a:1-l a:2-n a:1-u  l1  l2  start  assertequals  sb  thread  sleep  trim  testnowaitwritelock  finish  tostring
__label__nflaky b  to  bytes  storage  unit  is  get  default  assert  that  test  byte  conversions  get  long  name  bytes  get  short  name  from  bytes  to  string  get  suffix  char  b  tobytes  storageunit  is  getdefault  assertthat  testbyteconversions  getlongname  bytes  getshortname  frombytes  tostring  getsuffixchar
__label__flaky test  coord  re  run4  end_  points  is_  security_  enabled  -action  oozie  url  run  app  path  assert  true  get  create  servlet_  classes  close  run  test  app  mock  coordinator  engine  service  coordinator . xml  rest  constants  get  context  url  assert  equals  get  file  system  -rerun  0  args  call  -nocleanup  -oozie  mkdirs  job  get  fs  test  case  dir  testcoordrerun4  end_points  is_security_enabled  -action  oozieurl  run  apppath  asserttrue  get  create  servlet_classes  close  runtest  app  mockcoordinatorengineservice  coordinator . xml  restconstants  getcontexturl  assertequals  getfilesystem  -rerun  0  args  call  -nocleanup  -oozie  mkdirs  job  getfstestcasedir
__label__nflaky cursor  get  name  assert  false  test;  test1  =  stuff  ;  test2  =   \ ""stuff;  stuff \ "";  test3= \ ""stuff  test  nv  parse  all  test1  assert  assert  true  get  pos  buffer  test;  test1  =  stuff  ;  test2  =   \ ""stuff;  stuff \ "";  test3= \ ""stuff \ "" 123  test  at  end  length  assert  equals  stuff;  stuff  params  parse  parameters  get  value  test2  test3  append  stuff  cursor      getname  assertfalse  test; test1 =  stuff   ; test2 =   \ ""stuff; stuff \ ""; test3= \ ""stuff  testnvparseall  test1  assert  asserttrue  getpos  buffer  test; test1 =  stuff   ; test2 =   \ ""stuff; stuff \ ""; test3= \ ""stuff \ "" 123  test  atend  length  assertequals  stuff; stuff  params  parseparameters  getvalue  test2  test3  append  stuff
__label__flaky end_  points  -file  is_  security_  enabled  oozie  url  run  app  path  pig  submit  pig  assert  true  test  submit  pig  get  -config  servlet_  classes  run  test  app  get  context  url  mock  dag  engine  service  assert  equals  get  file  system  args  call  create  pig  properties  file  -oozie  mkdirs  wf  count  create  pig  script  to  string  get  fs  test  case  dir  end_points  -file  is_security_enabled  oozieurl  run  apppath  pig  submitpig  asserttrue  testsubmitpig  get  -config  servlet_classes  runtest  app  getcontexturl  mockdagengineservice  assertequals  getfilesystem  args  call  createpigpropertiesfile  -oozie  mkdirs  wfcount  createpigscript  tostring  getfstestcasedir
__label__nflaky test  any  ai  decoder3  data  numeric10  isoiec6462alpha  expected  numeric2alpha  alpha2isoiec646  alpha  a  alpha2numeric  i646  b   ( 10 )   bca10  i646  c  header  assert  correct  binary  string  testanyaidecoder3  data  numeric10  isoiec6462alpha  expected  numeric2alpha  alpha2isoiec646  alphaa  alpha2numeric  i646b   ( 10 ) bca10  i646c  header  assertcorrectbinarystring
__label__flaky child_value  session  given  insert  crud  when  id  row  value  val  random  utils  manager  child_val  one  get  string  next  long  assert  that  execute  select  *  from  entity_child  get  long  should_insert  then  long  is  equal  to  entity  child_value  session   given  insert  crud   when  id  row  value  val  randomutils  manager  child_val  one  getstring  nextlong  assertthat  execute  select * from entity_child  getlong  should_insert   then  long  isequalto  entity
__label__nflaky get  bytes  transferred  codec  test  utils  channel  times  assert  flush  verify  write  line  dump  chbuffer  write  argument  matchers  standard  charsets  assert  equals  encoder  any  never  header  stuff  test  coding  fragment  buffering  large  fragment  mockito  outbuf  header  metrics  spy  wrap  append  stuff  getbytestransferred  codectestutils  channel  times  assert  flush  verify  writeline  dump  chbuffer  write  argumentmatchers  standardcharsets  assertequals  encoder  any  never  header  stuff  testcodingfragmentbufferinglargefragment  mockito  outbuf  header  metrics  spy  wrap  append  stuff
__label__flaky <sla:should-start>5< / sla:should-start>  <sla:should-end>50< / sla:should-end>  <coordinator-app  name= \  '   name \  '   frequency= \  ' ${coord:days ( 1 ) } \  '   start= \  ' 2009-02-01  t01:00  z \  '   end= \  ' 2009-02-03  t23:59  z \  '   timezone= \  '   utc \  '   xmlns:xsi= \  ' http: /  / www . w3 . org / 2001 /   xml  schema-instance \  '   xmlns= \  ' uri:oozie:coordinator:0 . 2 \  '   xmlns:sla= \  ' uri:oozie:sla:0 . 1 \  ' >  xml  utils  e  test  coord  sla  schema  validator  < / sla:info>  parse  xml  < / action>  < / coordinator-app>  new  validator  get  schema  coord_  app1  services  <sla:info>  <sla:app-name>5< / sla:app-name>  <sla:nominal-time>2009-03-06  t010:00  z< / sla:nominal-time>  <controls>  <timeout>10< / timeout>  <concurrency>2< / concurrency>  <execution>  lifo< / execution>  < / controls>  <datasets>  <dataset  name= \  ' a \  '   frequency= \  ' ${coord:days ( 7 ) } \  '   initial-instance= \  ' 2009-02-01  t01:00  z \  '   timezone= \  '   utc \  ' >  <uri-template>file: /  /  / tmp / coord / workflows / ${  year} / ${  day}< / uri-template>  < / dataset>  <dataset  name= \  ' local_a \  '   frequency= \  ' ${coord:days ( 7 ) } \  '   initial-instance= \  ' 2009-02-01  t01:00  z \  '   timezone= \  '   utc \  ' >  <uri-template>file: /  /  / tmp / coord / workflows / ${  year} / ${  day}< / uri-template>  < / dataset>  < / datasets>  <input-events>  <data-in  name= \  '   a \  '   dataset= \  ' a \  ' >  <instance>${coord:latest ( 0 ) }< / instance>  < / data-in>  < / input-events>  <output-events>  <data-out  name= \  '   local_  a \  '   dataset= \  ' local_a \  ' >  <instance>${coord:current ( -1 ) }< / instance>  < / data-out>  < / output-events>  <action>  <workflow>  <app-path>hdfs: /  /  / tmp / workflows / < / app-path>  <configuration>  <property>  <name>input  a< / name>  <value>${coord:data  in (  \  '   a \  '  ) }< / value>  < / property>  <property>  <name>input  b< / name>  <value>${coord:data  out (  \  '   local_  a \  '  ) }< / value>  < / property>< / configuration>  < / workflow>  wss  <sla:alert-contact>abc@example . com< / sla:alert-contact>  <sla:dev-contact>abc@example . com< / sla:dev-contact>  get  <sla:qa-contact>abc@example . com< / sla:qa-contact>  <sla:se-contact>abc@example . com< / sla:se-contact>  schema  name  validate  system . out . println (  \ ""  xml  : \ ""+  xml  utils . pretty  print ( e )  ) ;  <sla:should-start>5< / sla:should-start> <sla:should-end>50< / sla:should-end>   <coordinator-app name= \  ' name \  '  frequency= \  ' ${coord:days ( 1 ) } \  '  start= \  ' 2009-02-01t01:00z \  '  end= \  ' 2009-02-03t23:59z \  '  timezone= \  ' utc \  '  xmlns:xsi= \  ' http: /  / www . w3 . org / 2001 / xmlschema-instance \  '  xmlns= \  ' uri:oozie:coordinator:0 . 2 \  '  xmlns:sla= \  ' uri:oozie:sla:0 . 1 \  ' >   xmlutils  e  testcoordslaschema  validator  < / sla:info>  parsexml  < / action> < / coordinator-app>  newvalidator  getschema  coord_app1  services  <sla:info> <sla:app-name>5< / sla:app-name> <sla:nominal-time>2009-03-06t010:00z< / sla:nominal-time>   <controls> <timeout>10< / timeout> <concurrency>2< / concurrency> <execution>lifo< / execution> < / controls> <datasets> <dataset name= \  ' a \  '  frequency= \  ' ${coord:days ( 7 ) } \  '  initial-instance= \  ' 2009-02-01t01:00z \  '  timezone= \  ' utc \  ' > <uri-template>file: /  /  / tmp / coord / workflows / ${year} / ${day}< / uri-template> < / dataset> <dataset name= \  ' local_a \  '  frequency= \  ' ${coord:days ( 7 ) } \  '  initial-instance= \  ' 2009-02-01t01:00z \  '  timezone= \  ' utc \  ' > <uri-template>file: /  /  / tmp / coord / workflows / ${year} / ${day}< / uri-template> < / dataset> < / datasets> <input-events> <data-in name= \  ' a \  '  dataset= \  ' a \  ' > <instance>${coord:latest ( 0 ) }< / instance> < / data-in>  < / input-events> <output-events> <data-out name= \  ' local_a \  '  dataset= \  ' local_a \  ' > <instance>${coord:current ( -1 ) }< / instance> < / data-out> < / output-events> <action> <workflow> <app-path>hdfs: /  /  / tmp / workflows / < / app-path> <configuration> <property> <name>inputa< / name> <value>${coord:datain (  \  ' a \  '  ) }< / value> < / property> <property> <name>inputb< / name> <value>${coord:dataout (  \  ' local_a \  '  ) }< / value> < / property>< / configuration> < / workflow>    wss  <sla:alert-contact>abc@example . com< / sla:alert-contact> <sla:dev-contact>abc@example . com< / sla:dev-contact>  get   <sla:qa-contact>abc@example . com< / sla:qa-contact> <sla:se-contact>abc@example . com< / sla:se-contact>  schemaname  validate   system . out . println (  \ ""xml : \ ""+ xmlutils . prettyprint ( e )  ) ;
__label__nflaky pt  quadrilateral  to  quadrilateral  assert  point  equals  perspective  transform  test  quadrilateral  to  quadrilateral  pt  quadrilateraltoquadrilateral  assertpointequals  perspectivetransform  testquadrilateraltoquadrilateral
__label__flaky get  element  by  id  disabled  div  get  page  assert  false  text  for  enabled  feature !   index . jsf  url  enabled  div  this  part  is  disabled  contains  assert  null  assert  true  this  part  of  the  page  is  rendered  text  for  disabled  feature !   assert  not  null  one  div  can  be  found  the  other  not  client  page  as  text  test  jsf  feature  map  getelementbyid  disableddiv  getpage  assertfalse  text for enabled feature !   index . jsf  url  enableddiv   this part is disabled  contains  assertnull  asserttrue   this part of the page is rendered  text for disabled feature !   assertnotnull   one div can be found the other not  client  page  astext  testjsffeaturemap
__label__nflaky request  process  set  version  context  interceptor  method  get  entity  test  request  http10  host  header  absent  http  version   /   request  process  setversion  context  interceptor  method  getentity  testrequesthttp10hostheaderabsent  httpversion   / 
__label__flaky get  job  tracker  uri  get  name  <argument>  a< / argument>  <exec>sh< / exec>  get  app  path  create  the  script  file  with  canned  shell  command  _test  submit  fs  shell_  script_  content_  error  action  xml  <shell>  < / file>  create  test  shell  script  error  <argument>script . sh< / argument>  write  close  <job-tracker>  get  name  node  uri  submit  and  verify  the  job \  ' s  status  #  <argument>-c< / argument>  < / job-tracker>  get  file  system  script  <name-node>  < / name-node>  < / shell>  w  <file>  <argument>  b< / argument>  create  sample  shell  action  xml  to  string  script . sh  getjobtrackeruri    getname  <argument>a< / argument>  <exec>sh< / exec>  getapppath   create the script file with canned shell command  _testsubmit  fs  shell_script_content_error  actionxml  <shell>  < / file>  create  testshellscripterror  <argument>script . sh< / argument>  write  close  <job-tracker>  getnamenodeuri   submit and verify the job \  ' s status  #  <argument>-c< / argument>  < / job-tracker>  getfilesystem  script  <name-node>  < / name-node>  < / shell>  w  <file>  <argument>b< / argument>   create sample shell action xml  tostring  script . sh
__label__nflaky init  assert  assert  true  servlet  context  context  test  is  multipart  is  multipart  http  servlet  request  http  servlet  response  init  assert  asserttrue  servletcontext  context  testismultipart  ismultipart  httpservletrequest  httpservletresponse
__label__flaky conn  set  request  method  is_  security_  enabled   / v0 / admin / *  assert  true  get  test  status  json  content-type  collections  run  test  json  tags  rest  constants  open  connection  http  servlet  response  assert  equals  parse  get  input  stream  url  json  value  call  get  header  field  get  get  response  code  create  url  starts  with  conn  setrequestmethod  is_security_enabled   / v0 / admin / *  asserttrue  get  teststatus  json  content-type  collections  runtest  jsontags  restconstants  openconnection  httpservletresponse  assertequals  parse  getinputstream  url  jsonvalue  call  getheaderfield  get  getresponsecode  createurl  startswith
__label__nflaky this  contains  a  comment  test  comments  in  value  my . comment  end  config  start  config  conf  assert  equals  append  property  out  config  this  < ! --comment  here-->  contains  a  comment  add  resource  get  two  spaces  one  after   \ ""this \ ""   one  before   \ ""contains \ ""  file  resource  this  contains a comment  testcommentsinvalue  my . comment  endconfig  startconfig  conf  assertequals  appendproperty  out  config  this < ! --comment here--> contains a comment  addresource  get   two spaces one after  \ ""this \ ""  one before  \ ""contains \ ""  fileresource
__label__flaky verify  the  peer \  ' s  settings  were  read  and  applied .   settings  set  get  header  table  size  max  header  table  byte  count  persist_  value  assert  equals  peer  is  server   so  we  are  client .   frame  reader  peer  http2  server  zeros  compression  table  client  connection  send  http2  settings  and  check  for  ack  settings   verify the peer \  ' s settings were read and applied .   settings  set  getheadertablesize  maxheadertablebytecount  persist_value  assertequals   peer is server  so we are client .   framereader  peerhttp2serverzeroscompressiontable  client  connection  sendhttp2settingsandcheckforack  settings
__label__nflaky set  get  property  common  configuration  keys  log  test  netgroup  shell  generic  test  utils  groups  user . name  conf  group  list  set  root  log  level  system  has  groups:  size  assert  true  level  to  string  org . apache . hadoop . security .   shell  based  unix  groups  netgroup  mapping  get  groups  username  info  set  getproperty  commonconfigurationkeys  log  testnetgroupshell  generictestutils  groups  user . name  conf  grouplist  setrootloglevel  system   has groups:   size  asserttrue  level  tostring  org . apache . hadoop . security . shellbasedunixgroupsnetgroupmapping  getgroups  username  info
__label__flaky cluster  conf  test  file  creation  delete  parent:  create  file2 .   create  file  wait  active  this  ensures  that  leases  are  persisted  in  fsimage .   rename  file3  to  some  bad  name  test  while  open  rename  parent  ipc . client . connection . maxidletime  move  dir1  while  file1  is  open  newfile  2s  dfs  config  keys  print  stack  trace  format  create  file3  create  file1 .   get  file  system  set  int  persistent  leases  from  fsimage .   stm2  stm3  max_  idle_  time  stm1  nnport   / user / dir2   / user / dir3  mkdirs  get  name  node  port  shutdown  name  node  port  create  cluster   / user / dir3 / dir1  fs  system  sleep   / user / a+b / dir1  hflush  assert  true  test  1*****************************  close  write  file  e  dir3  created  file  dir2  dir1  test  file  creation  thread  check  full  file  dfs . support . append  build  rename  file2  file3  exists  file1  $  set  boolean  cluster  conf  testfilecreationdeleteparent:    create file2 .   createfile  waitactive   this ensures that leases are persisted in fsimage .    rename file3 to some bad name  testwhileopenrenameparent  ipc . client . connection . maxidletime   move dir1 while file1 is open  newfile   2s  dfsconfigkeys  printstacktrace  format   create file3   create file1 .   getfilesystem  setint   persistent leases from fsimage .   stm2  stm3  max_idle_time  stm1  nnport   / user / dir2   / user / dir3  mkdirs  getnamenodeport  shutdown  namenodeport   create cluster   / user / dir3 / dir1  fs  system  sleep   / user / a+b / dir1  hflush  asserttrue  test 1*****************************  close  writefile  e  dir3  created file   dir2  dir1  testfilecreation  thread  checkfullfile  dfs . support . append  build  rename  file2  file3  exists  file1  $   setboolean
__label__nflaky get  boolean  with  default  not  in  prod  =>  no-cache  is  prod  date  util  if  cache  time  =  0  =>  set  to  no-cache:  important:  etag  added  ninja  constant  no-cache  get  method  when  get  header  result  result  add  etag  1234  max-age=1234  context  format  for  http  header  test  add  e  tag  verify  if  not  in  production  =>  no  cache:  in  production  =>  make  sure  cache  header  is  set  accordingly:  important:  etag  not  added  add  header  then  return  any  string  get  with  default  add  etag  when  configured:  eq  set  regular  header  with  request  to  http  cache  control  constant:   \ ""12___34 \ ""  0   \ ""1234 \ ""  http  cache  toolkit  never  test  lastmodified  is  added  when  etags  match:  =>  but  last-  modified  header  is  added  get  reset  do  not  add  etag  when  not  configured:  ninja  properties  http  header  constants  status  getbooleanwithdefault   not in prod => no-cache  isprod  dateutil   if cache time = 0 => set to no-cache:   important: etag added  ninjaconstant  no-cache  getmethod  when  getheader  result  result  addetag  1234  max-age=1234  context  formatforhttpheader  testaddetag  verify   if not in production => no cache:   in production => make sure cache header is set accordingly:   important: etag not added  addheader  thenreturn  anystring  getwithdefault   add etag when configured:  eq   set regular header with request to http cache control constant:   \ ""12___34 \ ""  0   \ ""1234 \ ""  httpcachetoolkit  never   test lastmodified is added when etags match:   => but last-modified header is added  get  reset   do not add etag when not configured:  ninjaproperties  httpheaderconstants  status
__label__flaky rr  next  table_  name  are  running .   there  are  5  cases  we  have  to  test .   each  is  described  below .   scan  h  constants  conf  system  result  cell  count  assert  true  test  scan  multiple  versions  get  timestamps  should  get  2  rows .   close  set  time  range   ( in  this  case  ==  1000 .   should  get  2  rows .   count   ( in  this  case  >  1000  and  <  latest_  timestamp .   should  get  2  rows .   j  number  of  rows  should  be  2  assert  equals  kv  second  timestamp   ( 100  <  timestamp  <  1000 )  .   should  get  2  rows .   sorted  set  time  stamp  t  add  family  long  unused  to  string  get  scanner  rows  case  1:  scan  with  latest_  timestamp .   should  get  two  rows  rr  next  table_name   are running .  there are 5 cases we have to test .  each is described below .   scan  hconstants  conf  system  result  cellcount  asserttrue  testscanmultipleversions  get  timestamps   should get 2 rows .   close  settimerange    ( in this case == 1000 .  should get 2 rows .   count    ( in this case > 1000 and < latest_timestamp .  should get 2 rows .   j  number of rows should be 2  assertequals  kv   second timestamp  ( 100 < timestamp < 1000 )  .  should get 2 rows .   sorted  settimestamp  t  addfamily  long  unused  tostring  getscanner  rows   case 1: scan with latest_timestamp .  should get two rows
__label__nflaky check  har  home  path:  ========  positive  tests:  check  har  version:  get  scheme  get  working  directory  har  path  to  uri  home  path  work  dir  path0  assert  equals  check  working  directory:  get  har  version  set  working  directory   / foo / bar  check  har  uri:  get  home  directory  har  uri  get  path  har  har  file  system  har  file  system  get  uri   ( #set  working  directory  should  have  no  effect ) :  test  positive  har  file  system  basics   check har home path:   ======== positive tests:   check har version:  getscheme  getworkingdirectory  harpath  touri  homepath  workdirpath0  assertequals   check working directory:  getharversion  setworkingdirectory   / foo / bar   check har uri:  gethomedirectory  haruri  getpath  har  harfilesystem  harfilesystem  geturi    ( #setworkingdirectory should have no effect ) :  testpositiveharfilesystembasics
__label__flaky handler  get  uri  handler  test  exists  to  uri  assert  false  uri  service  conf  get  file  system  get  test  user  path1  path2  assert  true  mkdirs  try  without  the  scheme .   get  path  exists   / 2012 / 12 / 02 /    / 2012 / 12 / 12 /   get  fs  test  case  dir  handler  geturihandler  testexists  touri  assertfalse  uriservice  conf  getfilesystem  gettestuser  path1  path2  asserttrue  mkdirs   try without the scheme .   getpath  exists   / 2012 / 12 / 02 /    / 2012 / 12 / 12 /   getfstestcasedir
__label__nflaky de  accept-language  do  return  language  assert  equals  when  get  header  abstract  context  assert  null  context  da   en-gb;q=0 . 8   en;q=0 . 7  get  accept  language  spy  de  accept-language  doreturn  language  assertequals  when  getheader  abstractcontext  assertnull  context  da  en-gb;q=0 . 8  en;q=0 . 7  getacceptlanguage  spy
__label__flaky do  an  edit  make  sure  runtime . exit (  .  .  .  )   hasn \  ' t  been  called  at  all  yet .   have  halted  the  nn .   invalidate  both  edits  journals .   assert  true  assert  exit  invocations  test  all  edits  dir  fail  on  write  invalidate  edits  dir  at  index  doanedit   make sure runtime . exit (  .  .  .  )  hasn \  ' t been called at all yet .    have halted the nn .    invalidate both edits journals .   asserttrue  assertexitinvocations  testalleditsdirfailonwrite  invalidateeditsdiratindex
__label__nflaky test_  jar_  name  make  a  simple  zip  jstream  manifest-  version:  1 . 0  created-  by:  1 . 8 . 0_1   (   manual )   data  get  bytes  unjar  dir  set  size  test_  root_  dir  unjar-path  test  un  jar2  write  close  meta-  inf /   manifest .   mf  get  unjar  dir  run  jar  un  jar  put  next  entry  un  jar  should  throw  io  exception .   e  standard  charsets  any  data  here  generic  test  utils  would  create  file  outside  of  fail  close  entry  jar  file  match_  any  assert  exception  contains   .  .  / outside . path  je  unjar  everything  test_jar_name   make a simple zip  jstream  manifest-version: 1 . 0  created-by: 1 . 8 . 0_1  ( manual )   data  getbytes  unjardir  setsize  test_root_dir  unjar-path  testunjar2  write  close  meta-inf / manifest . mf  getunjardir  runjar  unjar  putnextentry  unjar should throw ioexception .   e  standardcharsets  any data here  generictestutils  would create file outside of  fail  closeentry  jarfile  match_any  assertexceptioncontains   .  .  / outside . path  je   unjar everything
__label__flaky headers  get  server  address  ninja  test  browser  new  hash  map  assert  equals  assets / js / google-code-prettify / prettify . css  some  empty  headers  for  now .  .  .   make  request  and  get  response  maps   / redirect  will  send  a  location:  redirect  in  the  headers  get  status  code  get  status  line  http  response  test  that  assets  work  headers  getserveraddress  ninjatestbrowser  newhashmap  assertequals  assets / js / google-code-prettify / prettify . css   some empty headers for now .  .  .   makerequestandgetresponse  maps    / redirect will send a location: redirect in the headers  getstatuscode  getstatusline  httpresponse  testthatassetswork
__label__nflaky test  to  string  data  checksum ( type=  crc32   chunk  size=512 )   to  string  assert  equals  data  checksum  new  data  checksum  testtostring  datachecksum ( type=crc32  chunksize=512 )   tostring  assertequals  datachecksum  newdatachecksum
__label__flaky conn  set  request  method  is_  security_  enabled  jo   / v1 / jobs  get  id  put  total  bundle  job  bean  assert  true  array  get  json  content-type  job  bundle  run  test  rest  constants  open  connection  value  of  add  record  to  bundle  job  table  mock  dag  engine  service  http  servlet  response  assert  equals  parse  params  get  input  stream  bundle  job  id  url  =  bundle-  test;  json  value  call  oozie  client  get  header  field  get  test  user  x  data  test  case  =  prep;  get  get  response  code  long  bundlejobs  reset  create  url  test  get  bundle  jobs  =  starts  with    conn  setrequestmethod  is_security_enabled  jo   / v1 / jobs  getid  put  total  bundlejobbean  asserttrue  array  get  json  content-type  job  bundle  runtest  restconstants  openconnection  valueof  addrecordtobundlejobtable  mockdagengineservice  httpservletresponse  assertequals  parse  params  getinputstream  bundlejobid  url  =bundle-test;  jsonvalue  call  oozieclient  getheaderfield  gettestuser  xdatatestcase  =prep;  get  getresponsecode  long  bundlejobs  reset  createurl  testgetbundlejobs  =  startswith
__label__nflaky local  path  file  access  time2  read  attributes  access  time1  get  file  status  to  millis  get  connection  pool  files  last  access  time  get  method  name  sftp  file  system  doesn \  ' t  have  milliseconds .   excluding  it .   to  lower  case  path  to  file  touch  get  access  time  assert  equals  is  assert  that  sftp  fs  local  fs  to  path  test  get  access  time  name  get  live  conn  count  local  path  file  accesstime2  readattributes  accesstime1  getfilestatus  tomillis  getconnectionpool  files  lastaccesstime  getmethodname   sftpfilesystem doesn \  ' t have milliseconds .  excluding it .   tolowercase  pathtofile  touch  getaccesstime  assertequals  is  assertthat  sftpfs  localfs  topath  testgetaccesstime  name  getliveconncount
__label__flaky os  read  timed  out  expected  timeout  e  log  get  message  test_  timeout  assert  equals   / file  fs  fail  io  utils  cleanup  test  two  step  write  read  timeout  start  single  temporary  redirect  response  thread  create  must  close  stream  to  force  reading  the  http  response  close  os  read timed out  expected timeout  e  log  getmessage  test_timeout  assertequals   / file  fs  fail  ioutils  cleanup  testtwostepwritereadtimeout  startsingletemporaryredirectresponsethread  create   must close stream to force reading the http response  close
__label__nflaky key1  test  equals  and  hash  code  key2  value2  sanity  checks  value1  keys  assert  false  values  two  sorted  map  writables  with  different  data  are  now  equal  two  sorted  map  writables  with  same  entry  sets  formed  in  different  order  are  now  different  entry  sets  are  now  same  get  bytes  put  map  b  assert  true  map  a  assert  not  null  hash  code  when  entry  set  is  empty   they  should  be  equal  sorted  map  writable  couldn \  ' t  be  initialized .   got  null  reference  setup  equals  method  returns  true  when  passed  null  assert  equals  entry  sets  are  different  failure  reason  equals  basic  null  check  two  sorted  map  writables  with  different  content  are  now  equal  let \  ' s  check  if  entry  sets  of  same  keys  but  different  values  two  empty  sorted  map  writables  are  no  longer  equal  key1  testequalsandhashcode  key2  value2   sanity checks  value1  keys  assertfalse  values  two sortedmapwritables with different data are now equal  two sortedmapwritables with same entry sets formed in different order are now different   entrysets are now same  getbytes  put  mapb  asserttrue  mapa  assertnotnull  hashcode   when entry set is empty  they should be equal  sortedmapwritable couldn \  ' t be initialized .  got null reference   setup  equals method returns true when passed null  assertequals   entrysets are different  failurereason  equals   basic null check  two sortedmapwritables with different content are now equal   let \  ' s check if entry sets of same keys but different values  two empty sortedmapwritables are no longer equal
__label__flaky suspend  resume  test  workflow  states  add  node  def  one  start  assert  equals  workflow  instance  get  status  kill  as  list  wf  1  fail  <worklfow-app / >  end  arrays  job  suspend  resume  testworkflowstates  addnode  def  one  start  assertequals  workflowinstance  getstatus  kill  aslist  wf  1  fail  <worklfow-app / >  end  arrays  job
__label__nflaky content  type  set  ssl  context  ssl_  rsa_  export_  with_  rc2_  cbc_40_  md5  cipher  suite  request1  set  entity  weak  ciphers  suites  set  protocols  assert  ssl_  dh_anon_  export_  with_  rc4_40_  md5  set  socket  config  context  create  https   / stuff  tls_  dh_anon_  with_  aes_128_  cbc_  sha  requester  localhost  socket  config  set  stream  listener  logging  http1  stream  listener  set  so  timeout  method  execute  server  bootstrap  entity  utils  test  weak  ciphers  disabled  by  default  logging  conn  pool  listener  tls_  ecdhe_  ecdsa_  with_  rc4_128_  sha  fail  close  mode  requester  bootstrap  timeout  response1  tls_  rsa_  with_  null_  sha256  server  ssl_  rsa_  with_3  des_  ede_  cbc_  sha  get  local  port  tls_  krb5_  export_  with_  rc4_40_  sha  create  client  ssl  context  ssl_  rsa_  export_  with_  des40_  cbc_  sha  consume  bootstrap  set  conn  pool  listener  tls_  ecdh_anon_  with_  aes_256_  cbc_  sha  some  stuff  ssl_  rsa_  export_  with_  rc4_40_  md5  create  server  ssl  context  ssl  parameters  ssl_  rsa_  with_  rc4_128_  sha  tls_  ecdh_  ecdsa_  with_3  des_  ede_  cbc_  sha  close  io  exception  expected  ssl  test  contexts  ssl_  rsa_  with_  null_  sha  custom  start  get  entity  set  ssl  setup  handler  target  build  tls_  dh_anon_  with_  aes_256_  gcm_  sha384  contenttype  setsslcontext  ssl_rsa_export_with_rc2_cbc_40_md5  ciphersuite  request1  setentity  weakcipherssuites  setprotocols  assert  ssl_dh_anon_export_with_rc4_40_md5  setsocketconfig  context  create  https   / stuff  tls_dh_anon_with_aes_128_cbc_sha  requester  localhost  socketconfig  setstreamlistener  logginghttp1streamlistener  setsotimeout  method  execute  serverbootstrap  entityutils  testweakciphersdisabledbydefault  loggingconnpoollistener  tls_ecdhe_ecdsa_with_rc4_128_sha  fail  closemode  requesterbootstrap  timeout  response1  tls_rsa_with_null_sha256  server  ssl_rsa_with_3des_ede_cbc_sha  getlocalport  tls_krb5_export_with_rc4_40_sha  createclientsslcontext  ssl_rsa_export_with_des40_cbc_sha  consume  bootstrap  setconnpoollistener  tls_ecdh_anon_with_aes_256_cbc_sha  some stuff  ssl_rsa_export_with_rc4_40_md5  createserversslcontext  sslparameters  ssl_rsa_with_rc4_128_sha  tls_ecdh_ecdsa_with_3des_ede_cbc_sha  close  ioexception expected  ssltestcontexts  ssl_rsa_with_null_sha  custom  start  getentity  setsslsetuphandler  target  build  tls_dh_anon_with_aes_256_gcm_sha384
__label__flaky init  coordinator  job  as  get  test  user  test  authorization  service  for  coord  assert  not  null  get  get  id  services  job  add  record  to  coord  job  table  authorize  for  job  init  coordinatorjob  as  gettestuser  testauthorizationserviceforcoord  assertnotnull  get  getid  services  job  addrecordtocoordjobtable  authorizeforjob
__label__nflaky current  time  get  mask  closely  repeated  calls  should  cause  mask  to  increase  min  delay  threshold  is  too  soon  assert  true  default_  mask  assert  false  gate  max  delay  threshold  currenttime  getmask  closelyrepeatedcallsshouldcausemasktoincrease  mindelaythreshold  istoosoon  asserttrue  default_mask  assertfalse  gate  maxdelaythreshold
__label__flaky cluster  test  seek  bug  dfs  conf  get  file  system  seek  read  file  small  read  seek  build  file  sys  file1  seektest . dat  close  write  file  shutdown  cleanup  file  cluster  testseekbugdfs  conf  getfilesystem  seekreadfile  smallreadseek  build  filesys  file1  seektest . dat  close  writefile  shutdown  cleanupfile
__label__nflaky  / jmx ? qry=java . lang:type=  memory  conn   \ ""committed \ "" \  \ s*:   \ ""name \ "" \  \ s*: \  \ s* \ ""java . lang:type=  runtime \ ""  negative  test  to  get  an  attribute  of  a  mbean  test  to  get  an  attribute  of  a  mbean   \ ""modeler  type \ ""  result   / jmx   / jmx ? get=java . lang:type=  memory::  assert  not  null  read  output   / jmx ? qry=java . lang:type=  runtime  test  to  cors  headers   \ ""  error \ ""  open  connection   \ ""name \ "" \  \ s*: \  \ s* \ ""java . lang:type=  memory \ ""  assert  equals  access_  control_  allow_  origin  base  url  assert  re  find  get  header  field  test  query  get  access_  control_  allow_  methods   / jmx ? get=java . lang:type=  memory::  heap  memory  usage   / jmx ? qry=java . lang:type=memory  conn   \ ""committed \ "" \  \ s*:   \ ""name \ "" \  \ s*: \  \ s* \ ""java . lang:type=runtime \ ""   negative test to get an attribute of a mbean   test to get an attribute of a mbean   \ ""modelertype \ ""  result   / jmx   / jmx ? get=java . lang:type=memory::  assertnotnull  readoutput   / jmx ? qry=java . lang:type=runtime   test to cors headers   \ ""error \ ""  openconnection   \ ""name \ "" \  \ s*: \  \ s* \ ""java . lang:type=memory \ ""  assertequals  access_control_allow_origin  baseurl  assertrefind  getheaderfield  testquery  get  access_control_allow_methods   / jmx ? get=java . lang:type=memory::heapmemoryusage
__label__flaky test  coord  re  run  neg1  end_  points  is_  security_  enabled  -action  oozie  url  assert  false  2009-12-15  t01:00  z  run  app  path  get  create  servlet_  classes  close  run  test  app  mock  coordinator  engine  service  coordinator . xml  get  context  url  mock  dag  engine  service  assert  equals  get  file  system  -rerun  args  call  1  -date  -oozie  assert  null  mkdirs  job  get  fs  test  case  dir  testcoordrerunneg1  end_points  is_security_enabled  -action  oozieurl  assertfalse  2009-12-15t01:00z  run  apppath  get  create  servlet_classes  close  runtest  app  mockcoordinatorengineservice  coordinator . xml  getcontexturl  mockdagengineservice  assertequals  getfilesystem  -rerun  args  call  1  -date  -oozie  assertnull  mkdirs  job  getfstestcasedir
__label__nflaky +rwrt  test  fs  symbolic  constructor  with  normal  input  +r  added  both  octal  and  short  representation  to  show  with  sticky  bit  assert  equals  +w  +wx  +x  -rt  +rw  -rwx  +rx  repeated  value  in  input  will  be  ignored  as  duplicate .   to  octal  -rwr  +rwr  -rwrt  +rwx  to  short  +rwxt  +rwrt  testfssymbolicconstructorwithnormalinput  +r   added both octal and short representation to show with sticky bit  assertequals  +w  +wx  +x  -rt  +rw  -rwx  +rx   repeated value in input will be ignored as duplicate .   tooctal  -rwr  +rwr  -rwrt  +rwx  toshort  +rwxt
__label__flaky cache  generate  fixed  blocks  blocks  room  for  9   will  evict  get  eviction  count  max  size  assert  equals  block  size  n  system  thread  sleep  a  single  eviction  run  should  have  occurred  test  background  eviction  thread  let  the  eviction  run  cache  block  background  evictions  run:  calculate  block  size  default  assert  true  add  all  the  blocks  block  cache  generatefixedblocks  blocks   room for 9  will evict  getevictioncount  maxsize  assertequals  blocksize  n  system  thread  sleep   a single eviction run should have occurred  testbackgroundevictionthread   let the eviction run  cacheblock  background evictions run:   calculateblocksizedefault  asserttrue   add all the blocks  block
__label__nflaky get  class  unknown_junk  e  assert  true   . *unknown_junk . *  test  bad  name  writable  name  get  message  conf  matches  getclass  unknown_junk  e  asserttrue   . *unknown_junk . *  testbadname  writablename  getmessage  conf  matches
__label__flaky server  hcat . mydb . mytable  get  jms  connection  info  print  stack  trace  e  hcat  service  hcat . server . com:5080  jms  service  assert  equals  services  hcat: /  / hcat . server . com:8020  fail  get  message  receiver  receiver2  receiver1  conn  info  get  topic  register  for  notification  exception  encountered  :  test  register  single  consumer  per  topic  server  hcat . mydb . mytable  getjmsconnectioninfo  printstacktrace  e  hcatservice  hcat . server . com:5080  jmsservice  assertequals  services  hcat: /  / hcat . server . com:8020  fail  getmessagereceiver  receiver2  receiver1  conninfo  get  topic  registerfornotification  exception encountered :   testregistersingleconsumerpertopic
__label__nflaky credential1  credential1  has  been  successfully  created .   assert  false  run  delete  -value  assert  true  create  jceks  provider  -f  out  content  p@ssw0rd  assert  equals  list  set  conf  deleted .   test  credential  successful  lifecycle  cs  rc  contains  args5  -provider  args1  reset  args2  to  string  provider  utils  args4  credential1  credential1 has been successfully   created .   assertfalse  run  delete  -value  asserttrue  create  jceksprovider  -f  outcontent  p@ssw0rd  assertequals  list  setconf  deleted .   testcredentialsuccessfullifecycle  cs  rc  contains  args5  -provider  args1  reset  args2  tostring  providerutils  args4
__label__flaky i  nodes  in  path  resolve  inodes  call  get  existing  path  i  nodes  and  request  2  i  nodes .   snapshot  root  index  should  be  3:  {root   testsnapshot   sub1   s1   file1}  test  snapshot  path  i  nodes  invalid  path  bar  assert  create  snapshot  get  file  status   /  . snapshot / s1 / file1  nodes  in  path  s1  get  path  names  assert  i  node  file  allow  snapshot  last  pointing  to  a  snapshot  file  fail   . snapshot  the  exception  is  expected:  invalid  path  component  fnfe  snapshot  file  node  check  the  i  node  for  file1   ( snapshot  file )   snapshot  the  last  i  node  should  be  the  i  node  for  sub1  i  node  get  path  components  components  sub1  assert  false  foo  system  assert  snapshot   \ "" . snapshot \ ""  assert  true  invalid  dir  no  snapshot  root  dir  is  included  in  the  resolved  inodes   /  . snapshot  get  parent  assert  equals  get  snapshot  snapshot  root  index  should  be  0 .   dot  snapshot  path  get  full  path  name  snapshot  path  call  get  existing  path  i  nodes  and  request  only  one  i  node .   names  fsdir  hdfs  get  last  i  node  to  string  resolve  the  path   \ "" /   test  snapshot / sub1 /  . snapshot \ ""  file1  will  ignore   \ "" . snapshot \ ""  get  i  nodes  snapshot  root  index  should  be  -1 .    /   test  snapshot / sub1 /  . snapshot / s1 / file1  inodesinpath  resolve  inodes   call getexistingpathinodes and request 2 inodes .    snapshotrootindex should be 3: {root  testsnapshot  sub1  s1  file1}  testsnapshotpathinodes  invalidpath  bar  assert  createsnapshot  getfilestatus   /  . snapshot / s1 / file1  nodesinpath  s1  getpathnames  assertinodefile  allowsnapshot  last   pointing to a snapshot file  fail   . snapshot  the exception is expected:   invalidpathcomponent  fnfe  snapshotfilenode   check the inode for file1  ( snapshot file )   snapshot   the last inode should be the inode for sub1  inode  getpathcomponents  components  sub1  assertfalse  foo  system  assertsnapshot    \ "" . snapshot \ ""  asserttrue  invaliddir   no snapshotroot dir is included in the resolved inodes   /  . snapshot  getparent  assertequals  getsnapshot   snapshotrootindex should be 0 .   dotsnapshotpath  getfullpathname  snapshotpath   call getexistingpathinodes and request only one inode .   names  fsdir  hdfs  getlastinode  tostring   resolve the path  \ "" / testsnapshot / sub1 /  . snapshot \ ""  file1   will ignore  \ "" . snapshot \ ""  getinodes   snapshotrootindex should be -1 .     / testsnapshot / sub1 /  . snapshot / s1 / file1
__label__nflaky request  the  request  should  be  equal  to  the  default  request .   assert  nothing  thrown  set  request  handler  default  request  put  status  assert  request  handler  headers  run  tests  assert  not  null  content_  type  get  default  uri  verify  add  test  the  response  expectations  do  not  match  the  defaults  init  response  expectations  matches  default  uri  init  request  adapter  the  request  handler  should  have  been  passed  to  the  adapter  default  response  expectations  assert  equals  assert  that  assert  same  response  expectations  execute  the  response  expectations  should  be  equal  to  the  default .   the  request  does  not  match  the  default  request  should  not  be  null  framework  mockito  response  mock  request  handler  new  framework  and  set  adapter  mock  assert  nothing  thrown (  )   should  have  been  called .   body  request   the request should be equal to the default request .   assertnothingthrown  setrequesthandler  defaultrequest  put  status  assert  requesthandler  headers  runtests  assertnotnull  content_type  get  defaulturi  verify  addtest  the responseexpectations do not match the defaults  initresponseexpectations  matchesdefaulturi  initrequest  adapter  the request handler should have been passed to the adapter  defaultresponseexpectations  assertequals  assertthat  assertsame  responseexpectations  execute   the responseexpectations should be equal to the default .   the request does not match the default  request should not be null  framework  mockito  response  mockrequesthandler  newframeworkandsetadapter  mock   assertnothingthrown (  )  should have been called .   body
__label__flaky job1  get  time  pause  start  runnable  add  record  to  bundle  job  table  run  get  id  assert  equals  get  status  execute  services  job  id  test  start2  assert  not  null  get  set  kickoff  time  job  job  jpa  service  evaluate  wait  for  job1  gettime  pausestartrunnable  addrecordtobundlejobtable  run  getid  assertequals  getstatus  execute  services  jobid  teststart2  assertnotnull  get  setkickofftime  job  job  jpaservice  evaluate  waitfor
__label__nflaky rw  channel  header  stuff;more  stuff  test  coding  from  file  flush  buffer  get  bytes  stuff;  assert  get  channel  assert  true  write  line  more  stuff  dump  chbuffer  close  write  fchannel  is  completed  testfile  standard  charsets  create  temp  file  assert  equals  encoder  transfer  outbuf  header  metrics  append  rw  channel  header  stuff;more stuff  testcodingfromfileflushbuffer  getbytes  stuff;  assert  getchannel  asserttrue  writeline  more stuff  dump  chbuffer  close  write  fchannel  iscompleted  testfile  standardcharsets  createtempfile  assertequals  encoder  transfer  outbuf  header  metrics  append
__label__flaky script  executor  session  given  simple  crud  when  of  id  entity  as  child / insert_single_row . cql  select  *  from  entity_child  where  id  =  table  should_delete_by_id  execute  script  template  all  random  utils  manager  is  empty  next  long  rows  assert  that  execute  immutable  map  then  long  delete  by  id  scriptexecutor  session   given  simple  crud   when  of  id  entityaschild / insert_single_row . cql  select * from entity_child where id =   table  should_delete_by_id  executescripttemplate  all  randomutils  manager  isempty  nextlong  rows  assertthat  execute  immutablemap   then  long  deletebyid
__label__nflaky get  instances  set  get  name  test  get  instances  empty . property  no . such .   class  does  not  exist  classes  is  empty  conf  assert  equals  no . such .   class  fail  size  assert  true  set  strings  java . lang .   string  does  not  implement  sample  interface  no . such . property  some . classes    getinstances  set  getname  testgetinstances  empty . property  no . such . class does not exist  classes  isempty  conf  assertequals  no . such . class  fail  size  asserttrue  setstrings  java . lang . string does not implement sampleinterface  no . such . property  some . classes
__label__flaky request  _exec  query  get  status  add  record  to  coord  action  table  as  list  failed  test  default  status  get  coordinator  action  coord3  adding  coordinator  action  #4  to  coord#3  killed  add  assert  equals  get  action  br  list  result  status  coord-action-get . xml  size  bundle  name  possible  status  4  actions  satisfy  the  conditions  to  string  ;  arrays  bundle=  request  _execquery  getstatus  addrecordtocoordactiontable  aslist  failed  testdefaultstatus  get  coordinatoraction  coord3   adding coordinator action #4 to coord#3  killed  add  assertequals  getaction  brlist  resultstatus  coord-action-get . xml  size  bundlename  possiblestatus   4 actions satisfy the conditions  tostring  ;  arrays  bundle=
__label__nflaky add  get  stats  dummy  test  metric  collect  thread  local  states  get  metrics  test  metric  generic  test  utils  the  rolling  average  of  metric2  is  not  as  expected  test  mutable  rolling  averages  metric  rb  the  rolling  average  of  metric1  is  not  as  expected    metric2  rolling  avg  testing  assert  size  assert  true  get    metric1  rolling  avg  testing  create  metric1  metric2  metric1  avg  metric2  avg  get  double  gauge  wait  for  add  getstats  dummytestmetric  collectthreadlocalstates  getmetrics  testmetric  generictestutils  the rolling average of metric2 is not as expected  testmutablerollingaveragesmetric  rb  the rolling average of metric1 is not as expected  metric2rollingavgtesting  assert  size  asserttrue  get  metric1rollingavgtesting  create  metric1  metric2  metric1avg  metric2avg  getdoublegauge  waitfor
__label__flaky add  record  to  wf  action  table  coord  action  get  cmd  get  id  get  num  days  to  not  be  purged  workflow  instance  get  status  add  record  to  coord  action  table  coord  job  wf  job  get  end  time  add  record  to  wf  job  table  assert  not  null  get  workflow  job  should  not  have  been  purged  coordinator  action  workflow  job  wf  action  wf  job  get  cmd  wf  action  get  cmd  coordinator  action  should  not  have  been  purged  assert  equals  execute  add  record  to  coord  job  table  coordinator  job  should  not  have  been  purged  call  services  coordinator  job  1  coord  job  get  cmd  fail  coord-action-get . xml  workflow  action  coord  action  succeeded  jpa  service  workflow  action  should  not  have  been  purged  test  purge  coord  with  wf  child2  addrecordtowfactiontable  coordactiongetcmd  getid  getnumdaystonotbepurged  workflowinstance  getstatus  addrecordtocoordactiontable  coordjob  wfjob  getendtime  addrecordtowfjobtable  assertnotnull  get  workflow job should not have been purged  coordinatoraction  workflowjob  wfaction  wfjobgetcmd  wfactiongetcmd  coordinator action should not have been purged  assertequals  execute  addrecordtocoordjobtable  coordinator job should not have been purged  call  services  coordinatorjob  1  coordjobgetcmd  fail  coord-action-get . xml  workflowaction  coordaction  succeeded  jpaservice  workflow action should not have been purged  testpurgecoordwithwfchild2
__label__nflaky x ( 123 ) y  test  escape  both  parentheses  plb  context  set  context  start  set  pattern  assert  equals  get  pattern  layout  base  do  layout  x \  \  (  \ %  ott \  \  ) y  x ( 123 ) y  testescapebothparentheses  plb  context  setcontext  start  setpattern  assertequals  getpatternlayoutbase  dolayout  x \  \  (  \ %ott \  \  ) y
__label__flaky restore  events  count  to  10  run  test  queue  operations  repetition  myapp  1234-  c  get  current  size  get  queue  event  n ( events )   -  n ( batch ) *n ( threads )   n ( events )   -  n ( batch )   i . e .   workflow  job  wf  event  test  two  threads  polling  concurrently  from  queue  test  single  threads  polling  from  queue  is  empty  get  event  queue  assert  equals  thread  num  threads  create  some  events  to  enqueue  event  q  get  batch  size  services  ehs  r  get  test  user  enqueue  events  again  1234-  w  from  queue   restore events count to 10  run  testqueueoperations  repetition  myapp  1234-c  getcurrentsize  get  queueevent   n ( events )  - n ( batch ) *n ( threads )    n ( events )  - n ( batch )  i . e .   workflowjob  wfevent   test two threads polling concurrently from queue   test single threads polling from queue  isempty  geteventqueue  assertequals  thread  numthreads   create some events to enqueue  eventq  getbatchsize  services  ehs  r  gettestuser   enqueue events again  1234-w   from queue
__label__nflaky assert  is  set  assert  true  assert  false  foo  to  string  assert  equals  test  token  token  assert  isset  asserttrue  assertfalse  foo  tostring  assertequals  testtoken  token
__label__flaky log4j  file  get  test  case  conf  dir  get  log  ls  assert  false  test  log4j  reload  sleep  assert  true  is  trace  enabled  wait  for  test-custom-log4j . properties  init  a  current  thread  x  test  case  x  log  service  get  resource  as  stream  cl  destroy  is  original  ratio  thread  log  factory  1  io  utils  test-oozie-log4j . properties  get  context  class  loader  copy  stream  set  system  property  evaluate  log4jfile  gettestcaseconfdir  getlog  ls  assertfalse  testlog4jreload  sleep  asserttrue  istraceenabled  waitfor  test-custom-log4j . properties  init  a  currentthread  xtestcase  xlogservice  getresourceasstream  cl  destroy  is  originalratio  thread  logfactory  1  ioutils  test-oozie-log4j . properties  getcontextclassloader  copystream  setsystemproperty  evaluate
__label__nflaky fail  assert  test  shutdown  release  close  mode  somehost  pool  illegal  state  exception  should  have  been  thrown  ignored  if  shut  down  lease  close  fail  assert  testshutdown  release  closemode  somehost  pool  illegalstateexception should have been thrown   ignored if shut down  lease  close
__label__flaky <coordinator-app  name= \  '   name \  '   frequency= \  ' ${coord:days ( 1 ) } \  '   start= \  ' 2009-02-01  t01:00  z \  '   end= \  ' 2009-02-03  t23:59  z \  '   timezone= \  '   utc \  '   xmlns:xsi= \  ' http: /  / www . w3 . org / 2001 /   xml  schema-instance \  '   xmlns= \  ' uri:oozie:coordinator:0 . 1 \  '   xmlns:sla= \  ' uri:oozie:sla:0 . 1 \  ' >  xml  utils  e  test  coord  schema  validator  parse  xml  < / action>  < / coordinator-app>  new  validator  get  schema  coord_  app1  services  <controls>  <timeout>10< / timeout>  <concurrency>2< / concurrency>  <execution>  lifo< / execution>  < / controls>  <datasets>  <dataset  name= \  ' a \  '   frequency= \  ' ${coord:days ( 7 ) } \  '   initial-instance= \  ' 2009-02-01  t01:00  z \  '   timezone= \  '   utc \  ' >  <uri-template>file: /  /  / tmp / coord / workflows / ${  year} / ${  day}< / uri-template>  < / dataset>  <dataset  name= \  ' local_a \  '   frequency= \  ' ${coord:days ( 7 ) } \  '   initial-instance= \  ' 2009-02-01  t01:00  z \  '   timezone= \  '   utc \  ' >  <uri-template>file: /  /  / tmp / coord / workflows / ${  year} / ${  day}< / uri-template>  < / dataset>  < / datasets>  <input-events>  <data-in  name= \  '   a \  '   dataset= \  ' a \  ' >  <instance>${coord:latest ( 0 ) }< / instance>  < / data-in>  < / input-events>  <output-events>  <data-out  name= \  '   local_  a \  '   dataset= \  ' local_a \  ' >  <instance>${coord:current ( -1 ) }< / instance>  < / data-out>  < / output-events>  <action>  <workflow>  <app-path>hdfs: /  /  / tmp / workflows / < / app-path>  <configuration>  <property>  <name>input  a< / name>  <value>${coord:data  in (  \  '   a \  '  ) }< / value>  < / property>  <property>  <name>input  b< / name>  <value>${coord:data  out (  \  '   local_  a \  '  ) }< / value>  < / property>< / configuration>  < / workflow>  wss  get  schema  name  validate  system . out . println (  \ ""  xml  : \ ""+  xml  utils . pretty  print ( e )  ) ;  <coordinator-app name= \  ' name \  '  frequency= \  ' ${coord:days ( 1 ) } \  '  start= \  ' 2009-02-01t01:00z \  '  end= \  ' 2009-02-03t23:59z \  '  timezone= \  ' utc \  '  xmlns:xsi= \  ' http: /  / www . w3 . org / 2001 / xmlschema-instance \  '  xmlns= \  ' uri:oozie:coordinator:0 . 1 \  '  xmlns:sla= \  ' uri:oozie:sla:0 . 1 \  ' >   xmlutils  e  testcoordschema  validator  parsexml  < / action> < / coordinator-app>  newvalidator  getschema  coord_app1  services  <controls> <timeout>10< / timeout> <concurrency>2< / concurrency> <execution>lifo< / execution> < / controls> <datasets> <dataset name= \  ' a \  '  frequency= \  ' ${coord:days ( 7 ) } \  '  initial-instance= \  ' 2009-02-01t01:00z \  '  timezone= \  ' utc \  ' > <uri-template>file: /  /  / tmp / coord / workflows / ${year} / ${day}< / uri-template> < / dataset> <dataset name= \  ' local_a \  '  frequency= \  ' ${coord:days ( 7 ) } \  '  initial-instance= \  ' 2009-02-01t01:00z \  '  timezone= \  ' utc \  ' > <uri-template>file: /  /  / tmp / coord / workflows / ${year} / ${day}< / uri-template> < / dataset> < / datasets> <input-events> <data-in name= \  ' a \  '  dataset= \  ' a \  ' > <instance>${coord:latest ( 0 ) }< / instance> < / data-in>  < / input-events> <output-events> <data-out name= \  ' local_a \  '  dataset= \  ' local_a \  ' > <instance>${coord:current ( -1 ) }< / instance> < / data-out> < / output-events> <action> <workflow> <app-path>hdfs: /  /  / tmp / workflows / < / app-path> <configuration> <property> <name>inputa< / name> <value>${coord:datain (  \  ' a \  '  ) }< / value> < / property> <property> <name>inputb< / name> <value>${coord:dataout (  \  ' local_a \  '  ) }< / value> < / property>< / configuration> < / workflow>    wss  get  schemaname  validate   system . out . println (  \ ""xml : \ ""+ xmlutils . prettyprint ( e )  ) ;
__label__nflaky svc  log  hm  health  monitor  assert  false  wait  for  state  is  alive  mocking  rte  in  health  monitor   waiting  for  failed  test  health  monitor  dies  join  throw  oome  on  create  shutdown  info  svc  log  hm  healthmonitor  assertfalse  waitforstate  isalive  mocking rte in health monitor  waiting for failed  testhealthmonitordies  join  throwoomeoncreate  shutdown  info
__label__flaky get  job  tracker  uri  test3-acl  < / name-node>  <configuration>  <java>  < / configuration>  get  app  path  get  actions  conf  setup  action  conf  create  base  hadoop  conf  case:  launcher  specific  ac  ls  configured   as  well  as  mr  job  ac  ls  configured .   check  that  no  overriding  with  defaults  action  xml  wf  bean  <property><name>oozie . launcher . mapreduce . job . acl-modify-job< / name><value>  m< / value>< / property>  add  record  to  wf  job  table  get  context  action  java  action  executor  test  acl  defaults_explicit  launcher  and  action  settings  <job-tracker>  get  name  node  uri  e  action  xml  <property><name>oozie . launcher . mapreduce . job . acl-view-job< / name><value>  v< / value>< / property>  action  conf  < / java>  ae  xml  utils  parse  xml  < / job-tracker>  create  launcher  conf  <main-class>  main-  class< / main-class>  get  file  system  set  type  <name-node>  get  type  <property><name>mapreduce . job . acl-view-job< / name><value>  viewer< / value>< / property>  <property><name>mapreduce . job . acl-modify-job< / name><value>  modifier< / value>< / property>  assert  not  same  getjobtrackeruri  test3-acl  < / name-node> <configuration>  <java>  < / configuration>  getapppath  getactions  conf  setupactionconf  createbasehadoopconf   case: launcher specific acls configured  as well as mr job acls configured .  check that no overriding with defaults  actionxml  wfbean  <property><name>oozie . launcher . mapreduce . job . acl-modify-job< / name><value>m< / value>< / property>  addrecordtowfjobtable  get  context  action  javaactionexecutor  testacldefaults_explicitlauncherandactionsettings  <job-tracker>  getnamenodeuri  eactionxml  <property><name>oozie . launcher . mapreduce . job . acl-view-job< / name><value>v< / value>< / property>  actionconf  < / java>  ae  xmlutils  parsexml  < / job-tracker>  createlauncherconf  <main-class>main-class< / main-class>  getfilesystem  settype  <name-node>  gettype  <property><name>mapreduce . job . acl-view-job< / name><value>viewer< / value>< / property>  <property><name>mapreduce . job . acl-modify-job< / name><value>modifier< / value>< / property>  assertnotsame
__label__nflaky pair1  get  name  rss  expanded  reader  retrieve  next  pair  get  black  row  read  image  pair3  pair2  get  height  assert  not  null  finder  pattern  the  previous  was  the  last  pair  binary  map  row  row  number  test  find  finder  patterns  previous  pairs  add  image  get  finder  pattern  assert  equals  get  value  fail  expected  2 . png  pair1  getname  rssexpandedreader  retrievenextpair  getblackrow  readimage  pair3  pair2  getheight  assertnotnull  finderpattern   the previous was the last pair  binarymap  row  rownumber  testfindfinderpatterns  previouspairs  add  image  getfinderpattern  assertequals  getvalue  fail   expected  2 . png
__label__flaky get  job  tracker  uri  get  name  test  shell  script  <argument>  a< / argument>  <exec>sh< / exec>  get  app  path  create  the  script  file  with  canned  shell  command  _test  submit  fs  <env-var>var1=val1< / env-var>  action  xml  create  sample  shell  action  xml  <shell>  < / file>  create  <argument>script . sh< / argument>  shell_  script_  content  write  close  <job-tracker>  get  name  node  uri  submit  and  verify  the  job \  ' s  status  #  <argument>-c< / argument>  < / job-tracker>  get  file  system  script  <name-node>  < / name-node>  < / shell>  <env-var>var2=val2< / env-var>  w  <file>  <argument>  b< / argument>  to  string  script . sh  getjobtrackeruri    getname  testshellscript  <argument>a< / argument>  <exec>sh< / exec>  getapppath   create the script file with canned shell command  _testsubmit  fs  <env-var>var1=val1< / env-var>  actionxml   create sample shell action xml  <shell>  < / file>  create  <argument>script . sh< / argument>  shell_script_content  write  close  <job-tracker>  getnamenodeuri   submit and verify the job \  ' s status  #  <argument>-c< / argument>  < / job-tracker>  getfilesystem  script  <name-node>  < / name-node>  < / shell>  <env-var>var2=val2< / env-var>  w  <file>  <argument>b< / argument>  tostring  script . sh
__label__nflaky expected  no  groups  to  be  returned  given  a  shell  command  timeout  default  timeout  the  groups  framework  call  should  test  the  no-timeout   ( default )   configuration  assert  false  ran  longer  than  the  configured  timeout  limit  conf  expected  the  logs  to  carry  shell  mapping  log  test  a  1  second  max-runtime  timeout  expected  the  group  id  executor  to  carry  the  configured  timeout  assert  true  clear  output  executor  expected  the  group  id  executor  to  carry  the  default  timeout  test  also  the  parent  groups  framework  for  expected  behaviour  create  group  executor  create  group  id  executor  a  message  about  command  timeout  but  was:  test  finite  group  resolution  time  have  failed  with  a  command  timeout  get  groups  get  output  expected  the  group  names  executor  to  carry  the  configured  timeout  mapping  common  configuration  keys  test  timeout  set  class  groups  foobarnonexistinguser  new  instance  assert  equals  user  name  get  timeout  interval  fail  set  long  contains  size  command  timeout  message  reflection  utils  expected  the  group  names  executor  to  carry  the  default  timeout  didn \  ' t  expect  a  timeout  of  command  in  execution  but  logs  carry  it:  expected no groups to be returned given a shell command timeout  defaulttimeout  the groups framework call should    test the no-timeout  ( default )  configuration  assertfalse  ran longer than the configured timeout limit  conf  expected the logs to carry   shellmappinglog   test a 1 second max-runtime timeout  expected the group id executor to carry the configured timeout  asserttrue  clearoutput  executor  expected the group id executor to carry the default timeout   test also the parent groups framework for expected behaviour  creategroupexecutor  creategroupidexecutor  a message about command timeout but was:   testfinitegroupresolutiontime  have failed with a command timeout  getgroups  getoutput  expected the group names executor to carry the configured timeout  mapping  commonconfigurationkeys  testtimeout  setclass  groups  foobarnonexistinguser  newinstance  assertequals  username  gettimeoutinterval  fail  setlong  contains  size  commandtimeoutmessage  reflectionutils  expected the group names executor to carry the default timeout  didn \  ' t expect a timeout of command in execution but logs carry it:
__label__flaky file_  size  cluster  dn  r  dn  rand  get  all  blocks  dn_  n0  block  report  block  th  block  is  incorrect  get  data  nodes  get  block  pool  id  get  method  name  blocks  after  report  log  get  block  list  as  longs  generic  test  utils   /   prepare  for  ride  get  generation  stamp  size  old  lengths  pool  id  before  is  debug  enabled  number  of  blocks  allocated   . dat  temp  len  block_  size  fs  get  num  bytes  get  block  id  get  size  dfs  test  util  b  get  block  debug  set  length  of  all  blocks  belong  to  the  same  file   hence  same  bp  block  report_01  blocks  file  path  get  block  name  assert  equals  next  int  get  name  node  rpc  setting  new  length  after  after  mods:  number  of  blocks  allocated  method_  name  open  get  namesystem  get  dn  registration  for  bp  file_size  cluster  dnr  dn  rand  getallblocks  dn_n0  blockreport  block   th block is incorrect  getdatanodes  getblockpoolid  getmethodname  blocksafterreport  log  getblocklistaslongs  generictestutils   /   prepareforride  getgenerationstamp  size  oldlengths  poolid   before \ t  isdebugenabled  number of blocks allocated    . dat  templen  block_size  fs  getnumbytes  getblockid  get  size   dfstestutil  b  getblock  debug  set  length of    all blocks belong to the same file  hence same bp  blockreport_01  blocks  filepath  getblockname  assertequals  nextint  getnamenoderpc  setting new length   after \ t   after mods: number of blocks allocated   method_name  open  getnamesystem  getdnregistrationforbp
__label__nflaky 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  embed  data  bits  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  matrix  util  get  version  for  number  expected  bits  test  embed  data  bits  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  assert  equals  matrix  embed  basic  patterns  1  1  1  1  1  1  1  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  0  1  1  1  0  1  0  0  0  0  0  0  0  1  0  1  1  1  0  1  version  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  1  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  cells  other  than  basic  patterns  should  be  filled  with  zero .   clear  matrix  1  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  to  string  1  1  1  1  1  1  1  0  1  0  1  0  1  0  1  1  1  1  1  1  1   0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0    embeddatabits   1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0    matrixutil  getversionfornumber  expected  bits  testembeddatabits   1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0    assertequals  matrix  embedbasicpatterns   1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1     1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 1    version   0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0     1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0     cells other than basic patterns should be filled with zero .   clearmatrix   1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1     0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0    tostring   1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1
__label__flaky fail  a  add  function  ${a:a (  ) }  function  error  test  function  el  evaluation  error  support  evaluate  evaluator  fail  a  addfunction  ${a:a (  ) }  functionerror  testfunctionelevaluationerror  support  evaluate  evaluator
__label__nflaky get  encrypted  key  version  get  name  generate  another  eek  and  make  sure  it \  ' s  different  from  the  first  be  the  same  ek1  encryption  key  key  provider  crypto  extension  name  of  eek  should  be  encryption  key  name  ek2  assert  array  equals  decrypt  encrypted  key  generate  a  new  eek  and  check  it  assert  not  null  get  encrypted  key  iv  test  generate  encrypted  key  generated  ee  ks  should  have  different  i  vs !   generate  encrypted  key  get  encryption  key  name  generated  ee  ks  should  have  different  material !   k1  k2  assert  equals  kp  ext  get  version  name  expected  encrypted  key  material  decrypt  it  again  and  it  should  be  the  same  encryption_  key_  name  get  material  fail  decrypt  eek  into  an  ek  and  check  it  equals  k1a  arrays  version  name  of  eek  should  be  eek  length  of  encryption  key  material  and  eek  material  should  getencryptedkeyversion  getname   generate another eek and make sure it \  ' s different from the first  be the same  ek1  encryptionkey  keyprovidercryptoextension  name of eek should be encryption key name  ek2  assertarrayequals  decryptencryptedkey   generate a new eek and check it  assertnotnull  getencryptedkeyiv  testgenerateencryptedkey  generated eeks should have different ivs !   generateencryptedkey  getencryptionkeyname  generated eeks should have different material !   k1  k2  assertequals  kpext  getversionname  expected encrypted key material   decrypt it again and it should be the same  encryption_key_name  getmaterial  fail   decrypt eek into an ek and check it  equals  k1a  arrays  version name of eek should be eek  length of encryption key material and eek material should
__label__flaky date  value_tenant3  script  executor  table  name  for  session  given  insert  table  name  crud  select  *  from  provider  when  of  id  row  simple_insert_with_schema_name  value  table  simple  entity / create_simple_mirror_table . cql  execute  script  template  with  schema  name  provider  is  not  null  random  utils  manager  should_insert_with_schema_name_provider  one  where  id  =  get  string  next  long  assert  that  execute  immutable  map  keyspace  for  then  long  build  date  key  is  equal  to  entity  default_  cassandra_  embedded_  keyspace_  name  date  value_tenant3  scriptexecutor  tablenamefor  session   given  insert  tablename  crud  select * from   provider   when  of  id  row  simple_insert_with_schema_name  value  table  simpleentity / create_simple_mirror_table . cql  executescripttemplate  withschemanameprovider  isnotnull  randomutils  manager  should_insert_with_schema_name_provider  one   where id =   getstring  nextlong  assertthat  execute  immutablemap  keyspacefor   then  long  builddatekey  isequalto  entity  default_cassandra_embedded_keyspace_name
__label__nflaky key1  list  keys  rolled .   assert  false  list  out  roll  description  key1  has  been  successfully  run  invalidated .   test  key  successful  key  lifecycle  assert  true  create  jceks  provider  out  content  jceks  provider \  ' s  invalidate  is  a  no-op .   created  has  been  key  name  ks  assert  equals  delete  key  set  conf  rc  contains  -provider  invalidate  cache  args1  reset  args2  to  string  provider  utils  args3  successfully  created  key1  listkeys  rolled .   assertfalse  listout  roll  description  key1 has been successfully   run  invalidated .   testkeysuccessfulkeylifecycle  asserttrue  create  jceksprovider  outcontent   jceks provider \  ' s invalidate is a no-op .   created   has been   keyname  ks  assertequals  deletekey  setconf  rc  contains  -provider  invalidatecache  args1  reset  args2  tostring  providerutils  args3  successfully created
__label__flaky server  rpc  get  default  socket  factory  conf  block  key  update  interval  all  of  generate  token  get  block  id  get  replica  visible  length  stop  proxy  sm  addr  user  group  information  create  mock  datanode  add  token  ticket  block3  enum  set  dfs  util  start  assert  equals  create  remote  user  token  get  connect  address  test  block  token  rpc  proxy  block  token  lifetime  create  client  datanode  protocol  proxy  net  utils  stop  to  string  server  rpc  getdefaultsocketfactory  conf  blockkeyupdateinterval  allof  generatetoken  getblockid  getreplicavisiblelength  stopproxy  sm  addr  usergroupinformation  createmockdatanode  addtoken  ticket  block3  enumset  dfsutil  start  assertequals  createremoteuser  token  getconnectaddress  testblocktokenrpc  proxy  blocktokenlifetime  createclientdatanodeprotocolproxy  netutils  stop  tostring
__label__nflaky get  class  get  package  get  name  set  before  avro  reflect  serialization  conf  assert  equals  serialization  test  util  test  serialization  after  test  reflect  inner  class  getclass  getpackage  getname  set  before  avroreflectserialization  conf  assertequals  serializationtestutil  testserialization  after  testreflectinnerclass
__label__flaky b_out  cluster  a  b  conf  get  file  system  dir  fs  delete  something  has  lease  assert  a_out  write  bytes  build  assert  true  num  data  nodes  mkdirs  create  close  shutdown  test  lease  b_out  cluster  a  b  conf  getfilesystem  dir  fs  delete  something  haslease  assert  a_out  writebytes  build  asserttrue  numdatanodes  mkdirs  create  close  shutdown  testlease
__label__nflaky ninja  mode  is  available  get  ssl  keystore  uri  conf / jetty . minimal . conf  get  context  path  null  value  ssl  ninja  mode  not  get  server  urls  assert  not  null  get  ssl  truststore  uri  get  standalone  get  host  random_  port  is  stopped  external  configuration  path  https: /  / localhost:  standalone  start  is  get  ssl  truststore  password  is  started  ssl  port  assert  that  get  ninja  mode  get  port  port  get  ssl  port  get  ssl  keystore  password  shutdown  ninjamode    isavailable  getsslkeystoreuri  conf / jetty . minimal . conf  getcontextpath  nullvalue  ssl  ninjamode  not  getserverurls  assertnotnull  getssltruststoreuri  get  standalone  gethost  random_port  isstopped  externalconfigurationpath  https: /  / localhost:  standalone  start  is  getssltruststorepassword  isstarted  sslport  assertthat  getninjamode  getport  port  getsslport  getsslkeystorepassword  shutdown
__label__flaky add  record  to  bundle  action  table  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  assert  not  null  get  coordinator  action  end  current  date  plus  month  job  bundle  wait  for  add  record  to  bundle  job  table  bundle  id  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  with  bundle  services  coordinator  job  runnable  coord-action-get . xml  test  bundle  status  transit  service  succeeded2  equals  action1  job  action2  jpa  service  evaluate  addrecordtobundleactiontable  getcurrentdateafterincrementinginmonths  getid  run  dateutils  getstatus  addrecordtocoordactiontable  parsedateoozietz  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  job  bundle  waitfor  addrecordtobundlejobtable  bundleid  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtablewithbundle  services  coordinatorjob  runnable  coord-action-get . xml  testbundlestatustransitservicesucceeded2  equals  action1  job  action2  jpaservice  evaluate
__label__nflaky test  4:  exit  code  for  chgrp  on  existing  path  with  globbed  input  is  0  p1  p4  p5  p6  test  1:  exit  code  for  chgrp  on  existing  file  is  0  admin  f1  f2  f3  test  chgrp / file*  test  2:  exit  code  for  chgrp  on  non  existing  path  is  1  f7  test  chgrp / file3  assert  true  test_  root_  dir  test  chgrp / file2  create  and  write  test  file  test  chgrp / file1  get  path  test  chgrp / non  existingfiles*  exit  code  used  to  be  for  last  item  write  file  test  chgrp / file  exists  to  uri  change  test  3:  exit  code  for  chgrp  on  non-existing  path  with  globbed  input  is  1  test  chgrp / file  does  not  exist  create  required  files  test  chgrp  file  sys  exists   test 4: exit code for chgrp on existing path with globbed input is 0  p1  p4  p5  p6   test 1: exit code for chgrp on existing file is 0  admin  f1  f2  f3  testchgrp / file*   test 2: exit code for chgrp on non existing path is 1  f7  testchgrp / file3  asserttrue  test_root_dir  testchgrp / file2   create and write test file  testchgrp / file1  getpath  testchgrp / nonexistingfiles*   exit code used to be for last item  writefile  testchgrp / fileexists  touri  change   test 3: exit code for chgrp on non-existing path with globbed input is 1  testchgrp / filedoesnotexist   create required files  testchgrp  filesys  exists
__label__flaky format  date  request  headers  add  header  get  headers  client  supplied  if  modified  since  with  cached  result  assert  false  assert  client  supplied  condition  if-  modified-  since:  e  tag:  v3  cache-  control:  max-age=0  contains  assert  true  response  if  modified  since  date  time  unit  if-  modified-  since  if-  none-  match:  v3  formatdate  request  headers  addheader  getheaders  clientsuppliedifmodifiedsincewithcachedresult  assertfalse  assertclientsuppliedcondition  if-modified-since:   etag: v3  cache-control: max-age=0  contains  asserttrue  response  ifmodifiedsincedate  timeunit  if-modified-since  if-none-match: v3
__label__nflaky test . sink . test2 . period  test . sink . test1 . class  test . sink . test1 . period  get  name  save  test1  get  test  filename  get  get  sink  adapter  wait  for  hadoop-metrics2-test  add  init  give  some  time  for  the  publish  event  to  go  through  on  timer  event  test  ms  sink  get  metric  values  generic  test  utils  assert  equals  test2  size  test  metrics  config  test  register  sinks  multiple  periods  test . sink . test2 . class  sink2  sink1  shutdown  test . sink . test2 . period  test . sink . test1 . class  test . sink . test1 . period  getname  save  test1  gettestfilename  get  getsinkadapter  waitfor  hadoop-metrics2-test  add  init   give some time for the publish event to go through  ontimerevent  test  ms  sink  getmetricvalues  generictestutils  assertequals  test2  size  testmetricsconfig  testregistersinksmultipleperiods  test . sink . test2 . class  sink2  sink1  shutdown
__label__flaky initial  callable  callables  type  key  int  queueservice  initial  key  assert  true  get  test  interrupt  initial  type  lock  key  wait  for  key  exec_  order  add  init  c  initial  lock  key  ret  value  callable  queue  service  destroy  services  1  test  kill  int  callable  set  system  property  evaluate  queue  initialcallable  callables  type  keyint  queueservice  initialkey  asserttrue  get  testinterrupt  initialtype  lockkey  waitfor  key  exec_order  add  init  c  initiallockkey  retvalue  callablequeueservice  destroy  services  1  testkill  intcallable  setsystemproperty  evaluate  queue
__label__nflaky test  read  correctly  restricted  with  security  open  for  read  test  file  path  fadis  r  real  group  test  file  path  raf  open  for  random  read  test  file  path  is  secure  io  utils  open  fs  data  input  stream  real  owner  close  testreadcorrectlyrestrictedwithsecurity  openforread  testfilepathfadis  r  realgroup  testfilepathraf  openforrandomread  testfilepathis  secureioutils  openfsdatainputstream  realowner  close
__label__flaky aa  bb  a  a  b  set  variables  c  resolve  variable  set  variable  assert  equals  get  variable  put  fail  test  vars  vars  support  get  context  evaluator  aa  bb  a  a  b  setvariables  c  resolvevariable  setvariable  assertequals  getvariable  put  fail  testvars  vars  support  getcontext  evaluator
__label__nflaky test . txt  watch  dir  new  txt  file  add  a  new  file  windows  may  mod  a  file  more  than  once  watcher  thread  run   (  . * ) included . txt  default_  exclude_  patterns  delete  new  included  txt  file  as  list  timeout  get  bytes  included . txt  modify  the  file  assets  indicates  exclusion  rule  for  modified  files  didn \  ' t  work  interrupt  test . png  verify  trigger  should  have  been  called  soon  at  most  after  close  write  watcher  indicates  exclusion  rule  for  new  files  didn \  ' t  work  windows  may  do  2  mods  so  we  need  to  check  range  file  that  would  be  excluded  in  assets  directory   but  we \  ' ll  include  a  rule  to  include  it  os  target / fake-watch-dir  start  new  png  file  trigger  restart  trigger  hello !   never  to  path  mockito  mkdirs  assets  dir  mock  reset  at  least  arrays  shutdown  make  sure  file  does  not  yet  exist  test . txt  watchdir  newtxtfile   add a new file   windows may mod a file more than once  watcherthread  run   (  . * ) included . txt  default_exclude_patterns  delete  newincludedtxtfile  aslist  timeout  getbytes  included . txt   modify the file  assets   indicates exclusion rule for modified files didn \  ' t work  interrupt  test . png  verify   trigger should have been called soon  atmost  after  close  write  watcher   indicates exclusion rule for new files didn \  ' t work   windows may do 2 mods so we need to check range   file that would be excluded in assets directory  but we \  ' ll include a rule to include it  os  target / fake-watch-dir  start  newpngfile  trigger  restarttrigger  hello !   never  topath  mockito  mkdirs  assetsdir  mock  reset  atleast  arrays  shutdown   make sure file does not yet exist
__label__flaky cluster  new  array  list  ha  test  util  assert  parallel  files  are  identical  immutable  list  get  most  recent  checkpoint  tx  id  dirs  do  edits  assert  equals  nn1  nn0  get  name  node  current  dirs  immutable  set  lists  add  all  test  both  nodes  in  standby  state  transition  to  standby  of  wait  for  checkpoint  get  fs  image  will  each  try  to  take  a  checkpoint  and  upload  to  each  other .   fs  image  test  util  get  namesystem  cluster  newarraylist  hatestutil  assertparallelfilesareidentical  immutablelist  getmostrecentcheckpointtxid  dirs  doedits  assertequals  nn1  nn0  getnamenodecurrentdirs  immutableset  lists  addall  testbothnodesinstandbystate  transitiontostandby  of  waitforcheckpoint  getfsimage   will each try to take a checkpoint and upload to each other .   fsimagetestutil  getnamesystem
__label__nflaky setfacl  should  fail  without  options  -b   -k   -m   -x  or  --set  -m  setfacl  should  fail  with  extra  arguments  default:user::rwx  -  r  setfacl  should  fail  without  path  test  setfacl  validations  assert  false  -x  setfacl  should  fail  with  permissions  for  -x  path  --set  setfacl  should  fail  acl  spec  missing  setfacl  should  fail  without  options  -setfacl  user:user1:rwx  extra  run  command  setfacl  should  fail  without  acl  spec  setfacl  should  fail  with  conflicting  options  setfacl should fail without options -b  -k  -m  -x or --set  -m  setfacl should fail with extra arguments    default:user::rwx  -r  setfacl should fail without path  testsetfaclvalidations  assertfalse  -x  setfacl should fail with permissions for -x  path  --set  setfacl should fail acl spec missing  setfacl should fail without options  -setfacl  user:user1:rwx  extra  runcommand  setfacl should fail without aclspec  setfacl should fail with conflicting options
__label__flaky get  waiting  actions  dep  evicted  to  uri  string  assert  true  first  500  should  have  been  evicted .   but  it  is  lru  and  the  last  200  removed  is  between  300  and  700 .   assert  not  null  get  setup  services  action  id  max  elements  in  memory= \ ""500 \ ""  overflow  to  disk= \ ""false \ ""  testmaxelementsinmemory  add  missing  dependency  waiting  actions  assert  equals  test  max  elements  in  memory  pdms  hcat: /  / hcat . server . com:5080 / mydb / mytbl / id=  is  missing  in  cache  num  items  services  contains  assert  null    getwaitingactions  dep  evicted  touristring  asserttrue   first 500 should have been evicted .  but it is lru and the last 200 removed is between 300 and 700 .   assertnotnull  get  setupservices  actionid   maxelementsinmemory= \ ""500 \ "" overflowtodisk= \ ""false \ ""  testmaxelementsinmemory  addmissingdependency  waitingactions  assertequals  testmaxelementsinmemory  pdms  hcat: /  / hcat . server . com:5080 / mydb / mytbl / id=   is missing in cache  numitems  services  contains  assertnull
__label__nflaky exception  get  localized  message  ninja  constant  equal  to  when  result  result  get  renderable  assert  true  verify  get  not  found  result  not  important  get  template  argument  matchers  then  return  get  with  default  get  message  test  get  on  not  found  exception  result  works  eq  real  test:  assert  that  any  ninja  default  get  status  code  context  impl  messages  ninja  properties  exception  getlocalizedmessage  ninjaconstant  equalto  when  result  result  getrenderable  asserttrue  verify  getnotfoundresult  not important  gettemplate  argumentmatchers  thenreturn  getwithdefault  getmessage  testgetonnotfoundexceptionresultworks  eq   real test:  assertthat  any  ninjadefault  getstatuscode  contextimpl  messages  ninjaproperties
__label__flaky cluster  get  proxy  racks  num  of  datanodes  conf  sum  test  balancer  run  balancer  can  finish  create  file  wait  active  run  balancer  which  can  finish  in  5  iterations  with  no  block  movement .   create  proxy  create  conf  name  node  proxies  mini  dfs  cluster  with  node  group  total  capacity  rack1  nodegroup2  builder  nodegroup1  client  capacities  rack0  nodegroup0  node  groups  test  balancer  end  in  no  move  progress  capacity  fill  up  the  cluster  to  be  60 \ %  full  file  path  assert  equals  get  file  system  simulated  capacities  total  used  space  set  node  groups  num  data  nodes  shutdown  get  uri  cluster  getproxy  racks  numofdatanodes  conf  sum  testbalancer  runbalancercanfinish  createfile  waitactive   run balancer which can finish in 5 iterations with no block movement .   createproxy  createconf  namenodeproxies  minidfsclusterwithnodegroup  totalcapacity  rack1  nodegroup2  builder  nodegroup1  client  capacities  rack0  nodegroup0  nodegroups  testbalancerendinnomoveprogress  capacity   fill up the cluster to be 60 \ % full  filepath  assertequals  getfilesystem  simulatedcapacities  totalusedspace  setnodegroups  numdatanodes  shutdown  geturi
__label__nflaky set  character  encoding  test  get  input  stream  enforcing  of  correct  encoding  init  this  proofs  that  the  encoding  has  been  set:  servlet  context  any  string  context  verify  http  servlet  request  http  servlet  response  get  input  stream  setcharacterencoding  testgetinputstreamenforcingofcorrectencoding  init   this proofs that the encoding has been set:  servletcontext  anystring  context  verify  httpservletrequest  httpservletresponse  getinputstream
__label__flaky conn  set  request  method  is_  security_  enabled  get  reader  as  string  get  id  put  bundle  job  bean  assert  true   / v1 / job / *  content-type  id  job  run  test  mock  coordinator  engine  service  rest  constants  open  connection  add  record  to  bundle  job  table  length  http  servlet  response  assert  equals  params  get  input  stream  url  call  ct  get  header  field  io  utils  test  bundle  engine  get  definition  x  data  test  case  response  get  get  response  code  reset  create  url  starts  with  conn  setrequestmethod  is_security_enabled  getreaderasstring  getid  put  bundlejobbean  asserttrue   / v1 / job / *  content-type  id  job  runtest  mockcoordinatorengineservice  restconstants  openconnection  addrecordtobundlejobtable  length  httpservletresponse  assertequals  params  getinputstream  url  call  ct  getheaderfield  ioutils  testbundleenginegetdefinition  xdatatestcase  response  get  getresponsecode  reset  createurl  startswith
__label__nflaky < ! --  yarn . nodes . exclude  -->  excludes  len  excludes  get  excluded  hosts  <host><name>host1< / name>< / host>  assert  true  <host><name>10001< / name><timeout>123< / timeout>< / host>  get  <hosts>  < / hosts>  #  hosts-in-  dfs  <host><name>host2< / name><timeout>123< / timeout>< / host>  write  close  get  hosts  somehost  somehost2  somehost4  host5  host4  host  details  excludes  xml  file  < ? xml  version= \ ""1 . 0 \ "" ? >  host6  host1  contains  key  host3  host2  includes  file  <host><name>10000< / name>< / host>  assert  equals  get  host  details  *  test  if  timeout  values  are  provided  in  host  file  <host><name>host4 host5   host6< / name>  hfp  get  excluded  map  size  efw  <timeout>1800< / timeout>< / host>  somehost3  #  somehost5  10000  <host><name>10002< / name><timeout>-1< / timeout>< / host>  test  host  file  reader  with  timeout  10002  ifw  10001  <host><name>host3< / name><timeout>-1< / timeout>< / host>  includes  len  < ! -- yarn . nodes . exclude -->    excludeslen  excludes           getexcludedhosts  <host><name>host1< / name>< / host>    asserttrue  <host><name>10001< / name><timeout>123< / timeout>< / host>    get  <hosts>    < / hosts>    #hosts-in-dfs    <host><name>host2< / name><timeout>123< / timeout>< / host>    write  close  gethosts     somehost  \ t  somehost2    somehost4  host5  host4  hostdetails  excludesxmlfile  < ? xml version= \ ""1 . 0 \ "" ? >    host6  host1  containskey  host3  host2  includesfile  <host><name>10000< / name>< / host>    assertequals  gethostdetails       * test if timeout values are provided in hostfile       <host><name>host4 host5  host6< / name>  hfp  getexcludedmap  size  efw  <timeout>1800< / timeout>< / host>       somehost3  \ t # somehost5  10000  <host><name>10002< / name><timeout>-1< / timeout>< / host>    testhostfilereaderwithtimeout  10002  ifw  10001  <host><name>host3< / name><timeout>-1< / timeout>< / host>    includeslen
__label__flaky action  num  nominal  time  test  coord  action  get  get  time  get  action  nominal  time  action  nomial  time  get  id  date  utils  clean  up  db  tables  add  record  to  coord  action  table  app  path  d1  add  record  to  coord  job  table  parse  date  oozie  tz  d2  action  xml  coordinator  job  coord  coord-action-get . xml  _test  get  action  for  dates  coordinator  action  job  get  coord  action  xml  get  fs  test  case  dir  actionnum  nominaltime  testcoordactionget  gettime  getactionnominaltime  actionnomialtime  getid  dateutils  cleanupdbtables  addrecordtocoordactiontable  apppath  d1  addrecordtocoordjobtable  parsedateoozietz  d2  actionxml  coordinatorjob  coord  coord-action-get . xml  _testgetactionfordates  coordinatoraction  job  getcoordactionxml  getfstestcasedir
__label__nflaky to  char  array  hr  conf  allowed  flush  interval  with  bad  units:  property  every  time .   test  get  roll  interval  min  do  test  get  roll  interval  hour  builder  abcefgijklnopqrtuvwxyz  day  add  init  hours  c  d  minutes  sink  h  90  assert  equals  m  minute  1  fail  get  roll  interval  sink . roll-interval  days  subset  tochararray  hr  conf  allowed flush interval with bad units:    property every time .   testgetrollinterval  min  dotestgetrollinterval  hour  builder  abcefgijklnopqrtuvwxyz  day  add  init  hours  c  d  minutes  sink  h  90   assertequals  m  minute  1  fail  getrollinterval  sink . roll-interval  days  subset
__label__flaky lib  local  oozie  <end  name= \  ' end \  '  / >  conf  compare  to  get  status  test  workflow  run  last  mod  time  input-data  get  end  time  < / workflow-app>  get  test  group  assert  not  null  create  workflow . xml  write  wait  for  app  suspend  get  file  system  input  writer  oozie  client  job  id  stop  hello .   this  is  my  input  data  set .   mkdirs  set  property  create  configuration  <start  to= \  ' end \  '  / >  date  test  file  get  created  time  evaluate  <workflow-app  xmlns= \  ' uri:oozie:workflow:0 . 1 \  '   name= \  ' test-wf \  ' >  submit  get  job  info  wc  fs  app  path  wf  sleep  input-data / data1 . txt  workflow  job  close  resume  start  assert  equals  get  last  modified  time  get  client  wf  app  get  test  user  to  string  writer  get  fs  test  case  dir  lib  localoozie      <end name= \  ' end \  '  / >  conf  compareto  getstatus  testworkflowrun  lastmodtime  input-data  getendtime  < / workflow-app>  gettestgroup  assertnotnull  create  workflow . xml  write  waitfor  app  suspend  getfilesystem  inputwriter  oozieclient  jobid  stop  hello .  this is my input data set .   mkdirs  setproperty  createconfiguration      <start to= \  ' end \  '  / >  datetest  file  getcreatedtime  evaluate  <workflow-app xmlns= \  ' uri:oozie:workflow:0 . 1 \  '  name= \  ' test-wf \  ' >  submit  getjobinfo  wc  fs  apppath  wf  sleep  input-data / data1 . txt  workflowjob  close  resume  start  assertequals  getlastmodifiedtime  getclient  wfapp  gettestuser  tostring  writer  getfstestcasedir
__label__nflaky get  subject   /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /   set  subject  make  sure  that  mocked  mailer  did  not  send  email  previously  get  last  sent  mail  first  mail  second  mail  from@localhost  send  simple  mail  via  mocked  postoffice  assert  true   /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /   get  from  postoffice  simple  body  text  and  test  that  mail  has  been  sent .   set  from  assert  equals  get  tos  first  mail  contains  get  body  text  second  mail  test  sending  equals  to@localhost  add  to  send  set  body  text  getsubject    /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /   setsubject   make sure that mocked mailer did not send email previously  getlastsentmail  first mail  secondmail  from@localhost   send simple mail via mocked postoffice  asserttrue    /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /  /   getfrom  postoffice  simple body text   and test that mail has been sent .   setfrom  assertequals  gettos  firstmail  contains  getbodytext  second mail  testsending  equals  to@localhost  addto  send  setbodytext
__label__flaky create  flag  cluster  create  non  recursive (  )   should  throw  file  not  found  exception  overwrite  a  file  in  root  dir   should  succeed  test  file  creation  non  recursive  conf   / test  create  non  recursive  fs  expected  exception  delete  system  simulated  storage  out  create  a  new  file  in  root  dir   should  succeed  create  a  file  in  a  non-exist  dir  using  overwrite  flag  path   / non-exist-  assert  true  create  of  -test  file  creation  non  recursive  non  exist  dir  close  create  a  file  in  a  non-exist  directory   should  fail  create  flag  create  a  file  when  parent  directory  exists  as  a  file  overwrite  e  enum  set  overwrite  a  file  in  a  non-exist  directory   should  fail  get  file  system   / test  overwrite  non  recursive  overwrite  a  file  when  parent  dir  exists  as  file   should  fail   /   overwrite  a  file  when  parent  directory  exists  as  a  file  create  a  file  when  parent  dir  exists  as  file   should  fail  build  should  throw  parent  not  directory  exception  path2  create  non  recursive  path3  overwrite  a  file  in  a  non-exist  dir  using  current  time  millis  simulated  fs  dataset  shutdown  set  boolean  createflag  cluster   createnonrecursive (  )  should throw filenotfoundexception    overwrite a file in root dir  should succeed  testfilecreationnonrecursive  conf   / testcreatenonrecursive  fs  expectedexception  delete  system  simulatedstorage  out   create a new file in root dir  should succeed  create a file in a non-exist dir using  overwriteflag  path   / non-exist-  asserttrue  create  of  -testfilecreationnonrecursive  nonexistdir  close   create a file in a non-exist directory  should fail  createflag  create a file when parent directory exists as a file  overwrite  e  enumset   overwrite a file in a non-exist directory  should fail  getfilesystem   / testoverwritenonrecursive   overwrite a file when parent dir exists as file  should fail   /   overwrite a file when parent directory exists as a file   create a file when parent dir exists as file  should fail  build   should throw parentnotdirectoryexception   path2  createnonrecursive  path3  overwrite a file in a non-exist dir using  currenttimemillis  simulatedfsdataset  shutdown  setboolean
__label__nflaky encode  executors  decode  mark  end  stream  assert  1234567890  get  duration  tmp  boolean  capacity  channel  read  standard  charsets  argument  matchers  rnd  fill  any  int  mock  reset  timeout  12345678901234567890123456789012345678901234567890  test  multithreading  read  stream  charset  submit  executor  service  update  system  sleep  get  verify  task1  task2  input  buffer  new  fixed  thread  pool  assert  equals  next  int  l  byte  buffer  thread  get  time  unit  call  update  capacity  buf  mockito  current  time  millis  to  string  at  least  wrap  append  encode  executors  decode  markendstream  assert  1234567890  getduration  tmp  boolean  capacitychannel  read  standardcharsets  argumentmatchers  rnd  fill  anyint  mock  reset  timeout  12345678901234567890123456789012345678901234567890  testmultithreadingreadstream  charset  submit  executorservice  update  system  sleep  get  verify  task1  task2  inputbuffer  newfixedthreadpool  assertequals  nextint  l  bytebuffer  thread  gettimeunit  call  updatecapacity  buf  mockito  currenttimemillis  tostring  atleast  wrap  append
__label__flaky a  conn  set  request  method  post  error  put  set  request  property  content-type  id  collections  ok  run  test  a  rest  constants  test  callback  post  open  connection  utf-8  unchecked  mock  dag  engine  service  http  servlet  response  assert  equals  store  params  url  props  call  get  response  code  set  property   / callback  reset  create  url  get  output  stream  status  set  do  output    a  conn  setrequestmethod  post  error  put  setrequestproperty  content-type  id  collections  ok  runtest  a  restconstants  testcallbackpost  openconnection  utf-8  unchecked  mockdagengineservice  httpservletresponse  assertequals  store  params  url  props  call  getresponsecode  setproperty   / callback  reset  createurl  getoutputstream  status  setdooutput
__label__nflaky assume  false  get  process  shell  cmd  destroy  all  shell  processes  start  generic  test  utils  run  sleep  200  execute  sleep  command  shexc1  shexc2  shell  thread1  test  destroy  all  shell  processes  shell  -c  get  windows  assume  bash  to  string  wait  for  append  shell  thread2  assumefalse  getprocess  shellcmd  destroyallshellprocesses  start  generictestutils  run  sleep 200  execute  sleepcommand  shexc1  shexc2  shellthread1  testdestroyallshellprocesses  shell  -c  get  windows  assume  bash  tostring  waitfor  append  shellthread2
__label__flaky exec_  order  callable2  callable3  callable1  queue  serial  queue  uniqueness  with  diff  key  in  one  composite  queueservice  as  list  services  test  queue  uniqueness  with  diff  key  in  one  composite  assert  true  get  queue  uniqueness  with  diff  key  in  one  composite2  queue  uniqueness  with  diff  key  in  one  composite1  queue  uniqueness  with  diff  key  in  one  composite3  arrays  evaluate  wait  for  exec_order  callable2  callable3  callable1  queueserial  queueuniquenesswithdiffkeyinonecomposite  queueservice  aslist  services  testqueueuniquenesswithdiffkeyinonecomposite  asserttrue  get  queueuniquenesswithdiffkeyinonecomposite2  queueuniquenesswithdiffkeyinonecomposite1  queueuniquenesswithdiffkeyinonecomposite3  arrays  evaluate  waitfor
__label__nflaky a  a-  inside  include  b  start  include  b-  outside  include  end  config  start  config  conf  assert  equals  config2  tear  down  property   \ ""a \ ""  is  set  to  different  values  inside  and  outside  of  includes .   append  property  out  config  end  include  add  resource  a-  outside  include  get  file  resource  b-  inside  include  test  order  of  duplicate  properties  with  include  a  a-insideinclude  b  startinclude  b-outsideinclude  endconfig  startconfig  conf  assertequals  config2  teardown   property  \ ""a \ "" is set to different values inside and outside of includes .   appendproperty  out  config  endinclude  addresource  a-outsideinclude  get  fileresource  b-insideinclude  testorderofduplicatepropertieswithinclude
__label__flaky be  bee  status=foo  foo=moo  assert  equals  parse  filter  no  eq  sign  in  token:  incorrect   \ ""status \ ""  key  value:  fail  xx=yy=zz  winniethepooh  bundle  engine  exception  expected .   get  error  code  incorrect  key=value  pair  syntax:  unknown  key  in  key=value  pair:  error  code  test  parse  filter  negative  be  bee  status=foo  foo=moo  assertequals  parsefilter   no eq sign in token:   incorrect  \ ""status \ "" key value:  fail  xx=yy=zz  winniethepooh  bundleengineexception expected .   geterrorcode   incorrect key=value pair syntax:   unknown key in key=value pair:  errorcode  testparsefilternegative
__label__nflaky in  e  premature  eof  from  input  stream  get  message  assert  equals  fail  io  utils  skip  fully  after  skipping  0  byte ( s )  .   in  array  after  skipping  1  byte ( s )  .   reset  close  test  skip  fully  mark  expected  to  get  a  premature  eof  exception  after  skipping  5  byte ( s )  .   in  e  premature eof from inputstream   getmessage  assertequals  fail  ioutils  skipfully  after skipping 0 byte ( s )  .   inarray  after skipping 1 byte ( s )  .   reset  close  testskipfully  mark  expected to get a prematureeofexception  after skipping 5 byte ( s )  . 
__label__flaky bundle  job  get  executor  add  record  to  bundle  action  table  test  bundle  rerun  in  suspended  add  record  to  bundle  job  table  get  id  assert  equals  get  status  execute  add  record  to  coord  job  table  call  coordinator  job  services  assert  not  null  get  action1  job  job  action2  jpa  service  bundlejobgetexecutor  addrecordtobundleactiontable  testbundlereruninsuspended  addrecordtobundlejobtable  getid  assertequals  getstatus  execute  addrecordtocoordjobtable  call  coordinatorjob  services  assertnotnull  get  action1  job  job  action2  jpaservice
__label__nflaky exit_  connectivity_  problem  service  assert  in  state  service  set  exit  code  launch  service  assert  equals  test  access  launched  service  execute  get  service  launcher  exit_connectivity_problem  service  assertinstate  service  setexitcode  launchservice  assertequals  testaccesslaunchedservice  execute  getservice  launcher
__label__flaky add  add  column  create  table  to  bytes  test  that  table  is  enabled  h  constants  assert  equals  test_  util  ht  put  bytes  test  that  table  is  disabled  qualifier  get  test  disable  and  enable  table  enable  table  row  ok  value  table  disable  table  add  addcolumn  createtable  tobytes   test that table is enabled  hconstants  assertequals  test_util  ht  put  bytes   test that table is disabled  qualifier  get  testdisableandenabletable  enabletable  row  ok  value  table  disabletable
__label__nflaky @  abcdefghijklmnopqrstuvwxyz \  \ ^_  do  test  test  decode  extended  mode  000001001011011010101001001001011001010101101001001001010110101001011010010010010101011010010110100100100101011011010010101001001001010101011001011010010010010101101011001010100100100101010110110010101001001001010101010011011010010010010101101010011010100100100101010110100110101001001001010101011001101010010010010101101010100110100100100101010110101001101001001001010110110101001010010010010101010110100110100100100101011010110100101001001001010101101101001010010010010101010101100110100100100101011010101100101001001001010101101011001010010010010101010110110010100100100101011001010101101001001001010100110101011010010010010101100110101010100100100101010010110101101001001001010110010110101010010010010101001101101010101001001001011010100101101010010010010101101001011010100100100101101101001010101001001001010101100101101010010010010110101100101010010110110100000  00000100101101101010011010110101001001010010110101001011010010010100101011010010110100100101001011011010010101001001010010101011001011010010010100101101011001010100100101001010110110010101001001010010101010011011010010010100101101010011010100100101001010110100110101001001010010101011001101010010010100101101010100110100100101001010110101001101001010110110110010101101010010010100101101011010010101001101101011010010101101011001010110110110010101010100110101101101001101010101100110101010100101101101101001011010101100101101010010010100101001101101010101001001001010110110010101010010010010101010011011010100100100101101010011010101001001001010110100110101010010010010101011001101010010110110100000   !  \ ""#$ \ %& \  '  (  ) *+ - .  / 0123456789:;<=> ?   `abcdefghijklmnopqrstuvwxyz{|}~  000010010110110101010010010010100110101011011010100101101011010010110110110100101010101100101101101011001010101101100101010101001101101101010011010101101001101010101100110101101010100110101101010011011011010100101010110100110110101101001010110110100101010101100110110101011001010110101100101010110110010110010101011010011010101101100110101010100101101011011001011010101001101101010101001001001011010101001101010010010010101101010011010100100100101101101010010101001001001010101101001101010010010010110101101001010010110110100000  000001001011011010101001001001011001101010101001010010010110101001011010010100100101011010010110100101001001011011010010101001010010010101011001011010010100100101101011001010100101001001010110110010101001010010010101010011011010010100100101101010011010100101001001010110100110101001010010010101011001101010010100100101101010100110100101001001010110101001101001010010010110110101001010010100100101010110100110100101001001011010110100101001010010010101101101001010010100100101010101100110100101001001011010101100101001010010010101101011001010010100100101010110110010100101001001011001010101101001010010010100110101011010010100100101100110101010100101001001010010110101101001010010010110010110101010010100100101001101101010101001001001010110110100101010010010010101010110011010100100100101101010110010101001001001010110101100101010010010010101011011001010010110110100000  "
__label__flaky dag  el  functions  drop  database  def  year month dt country  conf  create  evaluator  ${hcat:exists ( wf:conf (  \  ' partition2 \  '  )  ) }  proto  conf  get  test  case  dir  ${hcat:exists ( wf:conf (  \  ' partition1 \  '  )  ) }  set  id  action  set  user  group  test  h  cat  exists  workflow  test . dir     create  database  oozie  client  set  group  eval  name  action  id  job  evaluate  get  h  cat  uri  action  name  set  name  create  table  dt=05  add  node  write  xml  add  partition  get  id  app  path  set  app  path  baos  year=2012;month=12;dt=02;country=us  wf  table1  configure  evaluator  get  dt=02  <workflow-app / >  end  hadoop . job . ugi  drop  table  set  proto  action  conf  set  workflow  instance  partition2  set  app  name  set  assert  equals  partition1  services  db1  get  test  user  to  string  wf  id  dagelfunctions  dropdatabase  def  year month dt country  conf  createevaluator  ${hcat:exists ( wf:conf (  \  ' partition2 \  '  )  ) }  protoconf  gettestcasedir  ${hcat:exists ( wf:conf (  \  ' partition1 \  '  )  ) }  setid  action  setuser  group  testhcatexists  workflow  test . dir     createdatabase  oozieclient  setgroup  eval  name  actionid  job  evaluate  gethcaturi  actionname  setname  createtable  dt=05  addnode  writexml  addpartition  getid  apppath  setapppath  baos  year=2012;month=12;dt=02;country=us  wf  table1  configureevaluator  get  dt=02  <workflow-app / >  end  hadoop . job . ugi  droptable  setprotoactionconf  setworkflowinstance  partition2  setappname  set  assertequals  partition1  services  db1  gettestuser  tostring  wfid
__label__nflaky body  parser  engine  xml  then  return  is  invoke  get  input  stream  when  test  empty  xml  body  get  bytes  mockito  assert  true  xml  obj  mapper  context  xml  document  bad  request  thrown  close    bodyparserenginexml  thenreturn  is  invoke  getinputstream  when  testemptyxmlbody  getbytes  mockito  asserttrue  xmlobjmapper  context  xmldocument  badrequestthrown  close
__label__flaky end_  points  is_  security_  enabled  submit  oozie  url  assert  false  test  submit  conf  wc  app  path  get  create  workflow . xml  servlet_  classes  close  run  test  app  get  context  url  mock  dag  engine  service  assert  equals  get  file  system  call  oozie  client  mkdirs  set  property  wf  count  reset  create  configuration  to  string  get  fs  test  case  dir  end_points  is_security_enabled  submit  oozieurl  assertfalse  testsubmit  conf  wc  apppath  get  create  workflow . xml  servlet_classes  close  runtest  app  getcontexturl  mockdagengineservice  assertequals  getfilesystem  call  oozieclient  mkdirs  setproperty  wfcount  reset  createconfiguration  tostring  getfstestcasedir
__label__nflaky payload1  payload2  payload3  in  buffer  readable  channel  assert  assert  not  null  frame  type  get  of  test  read  frame  multiple  small  buffer  get  payload  content  read  frame3  frame1  value  of  frame2  get  stream  id  assert  equals  byte  buffer  remaining  frame  flag  allocate  get  type  get  flags  payload1  payload2  payload3  inbuffer  readablechannel  assert  assertnotnull  frametype  get  of  testreadframemultiplesmallbuffer  getpayloadcontent  read  frame3  frame1  valueof  frame2  getstreamid  assertequals  bytebuffer  remaining  frameflag  allocate  gettype  getflags
__label__flaky encode  iso-8859-1  data  barcode  format  standard  charsets  expected  matrix  utf-8  aztec  assert  equals  test  writer  matrix  iso-8859-15  get  bytes  test  aztec  writer  test  aztec  writer  defaults  get  matrix    1  sample  data .   encoder  in  ut  magna  vel  mauris  malesuada  writer  encode  iso-8859-1  data  barcodeformat  standardcharsets  expectedmatrix  utf-8  aztec  assertequals  testwriter  matrix  iso-8859-15  getbytes  testaztecwriter   test aztecwriter defaults  getmatrix   1 sample data .   encoder  in ut magna vel mauris malesuada  writer
__label__nflaky test  all  constants  configuration  ninja  constant  assert  equals  get  string  languages  name  get  int  prefix  swiss  knife  get  boolean  server_  name  load  configuration  in  utf8  conf / all_constants . conf  secret  testallconstants  configuration  ninjaconstant  assertequals  getstring  languages  name  getint  prefix  swissknife  getboolean  server_name  loadconfigurationinutf8  conf / all_constants . conf  secret
__label__flaky format  date  play  a  server  read  ascii  date:  add  header  open  connection  assert  equals  source  set  body  set  response  code   /   cache-  control:  max-age=0  enqueue  get  url  get  header  field  response  source  header  conditional  cache  not  fetched  response  source  ok  headers  304  time  unit  connection  formatdate  play  a  server  readascii  date:   addheader  openconnection  assertequals  source  setbody  setresponsecode   /   cache-control: max-age=0  enqueue  geturl  getheaderfield  responsesourceheaderconditionalcachenotfetched  responsesource  okheaders   304  timeunit  connection
__label__nflaky mock  res  init  mock  req  verify  zero  interactions  object  under  test  then  return  browser_  agent  csrf  has  not  been  sent  objects  to  verify  interactions  based  on  request  setup  the  configuration  settings  of  the  server  get  method  when  test  missing  header  multiple  ignore  methods  config  bad  request  filter  config  put  get  header  filter  mock  chain  get  init  parameter  mockito  do  filter  mock  get   options  rest  csrf  prevention  filter  mockres  init  mockreq  verifyzerointeractions   object under test  thenreturn  browser_agent   csrf has not been sent   objects to verify interactions based on request   setup the configuration settings of the server  getmethod  when  testmissingheadermultipleignoremethodsconfigbadrequest  filterconfig  put  getheader  filter  mockchain  getinitparameter  mockito  dofilter  mock  get options  restcsrfpreventionfilter
__label__flaky job  conf  lib   / libx / maputilx . jar  reader  auth  token   / libx   / lib / reduceutil . so  create  proto  action  conf  found  proto  conf  get  test  case  dir   / workflow . xml  get  file: /  /   create  test  case  sub  dir  bla  bla  collections  write  close   / lib / maputil . jar  test  createproto  conf  with  lib  path  add  init  libx  set  wf-schema-valid . xml  workflow  app  service  expected  destroy  assert  equals  services  sort  get  strings  services  oozie  client  io  utils  get  test  user  copy  char  stream  get  resource  as  reader  writer  wps  jobconf  lib   / libx / maputilx . jar  reader  authtoken   / libx   / lib / reduceutil . so  createprotoactionconf  found  protoconf  gettestcasedir   / workflow . xml  get  file: /  /   createtestcasesubdir  bla bla  collections  write  close   / lib / maputil . jar  testcreateprotoconfwithlibpath  add  init  libx  set  wf-schema-valid . xml  workflowappservice  expected  destroy  assertequals  services  sort  getstrings  services  oozieclient  ioutils  gettestuser  copycharstream  getresourceasreader  writer  wps
__label__nflaky append  bits  010  1010  1111  1110  101  0101  xor  assert  equals  v1  v2  get  unsigned  int  test  xor2  appendbits   010 1010   1111 1110   101 0101  xor  assertequals  v1  v2  getunsignedint  testxor2
__label__flaky add  record  to  coord  job  table  for  waiting  configuration   / 2009 / 01 / 29 /   ca  bean  get  id   / 2009 / 01 / 15 /   coord  get  cmd  sleep  e  action  coord-action-for-action-input-check . xml  get  test  case  dir  get  coordinator  action  create  dir  property  action  coord-job-for-action-input-check . xml  test  resolve  coord  configuration  add  record  to  coord  action  table  for  waiting  element  list  value   / 2009 / 01 / 22 /   print  stack  trace  xml  utils  workflow  e  get  child  parse  xml   / 2009 / 01 / 08 /   assert  equals  e1  execute  e2  unexpected  exception  call  fail  coordinator  job  services  get  children  get  value  get  action  xml  get  namespace  file: /  /  test  dir / 2009 / 29  config  elem  file: /  /  test  dir / 2009 / 29 file: /  /  test  dir / 2009 / 22 file: /  /  test  dir / 2009 / 15 file: /  /  test  dir / 2009 / 08  job  jpa  service  addrecordtocoordjobtableforwaiting  configuration   / 2009 / 01 / 29 /   cabean  getid   / 2009 / 01 / 15 /   coordgetcmd  sleep  eaction  coord-action-for-action-input-check . xml  gettestcasedir  get  coordinatoraction  createdir  property  action  coord-job-for-action-input-check . xml  testresolvecoordconfiguration  addrecordtocoordactiontableforwaiting  elementlist  value   / 2009 / 01 / 22 /   printstacktrace  xmlutils  workflow  e  getchild  parsexml   / 2009 / 01 / 08 /   assertequals  e1  execute  e2  unexpected exception  call  fail  coordinatorjob  services  getchildren  getvalue  getactionxml  getnamespace  file: /  /  testdir / 2009 / 29  configelem  file: /  /  testdir / 2009 / 29 file: /  /  testdir / 2009 / 22 file: /  /  testdir / 2009 / 15 file: /  /  testdir / 2009 / 08  job  jpaservice
__label__nflaky verify  zero  interactions  object  under  test  conf  origin  is  not  specified  for  same  origin  requests  when  put  filter  config  get  header  mock  chain  do  filter  verify  example . com  mock  res  init  mock  req  then  return  objects  to  verify  interactions  based  on  request  setup  the  configuration  settings  of  the  server  cross  origin  filter  filter  mockito  get  mock  disallowed-  header  test  disallowed  header  verifyzerointeractions   object under test  conf   origin is not specified for same origin requests  when  put  filterconfig  getheader  mockchain  dofilter  verify  example . com  mockres  init  mockreq  thenreturn   objects to verify interactions based on request   setup the configuration settings of the server  crossoriginfilter  filter  mockito  get  mock  disallowed-header  testdisallowedheader
__label__flaky read  value  get  server  address  ninja  test  browser  assert  equals  system  test  post  person  json  result  j:  post  json  person  response  zeeess  name  -  and  some  utf8  =>    api / person . json  readvalue  getserveraddress  ninjatestbrowser  assertequals  system  testpostpersonjson  result  j:   postjson  person  response  zeeess name - and some utf8 =>   api / person . json
__label__nflaky new  matcher  assert  assert  true  matcher  uri  pattern  type  test  uri  pattern  newmatcher  assert  asserttrue  matcher  uripatterntype  testuripattern
__label__flaky cluster  conf  get  file  system  test  file  not  found  fs  simulated  storage   / nonexistingfile . dat  build  simulated  fs  dataset  file1  close  shutdown  append  set  boolean  cluster  conf  getfilesystem  testfilenotfound  fs  simulatedstorage   / nonexistingfile . dat  build  simulatedfsdataset  file1  close  shutdown  append  setboolean
__label__nflaky then  return  context  path  is  get  context  path  assert  that  when  get  reverse  route  with  method  reference  ref  router  route2  route   / ref  get  reverse  route  ninja  properties    thenreturn  contextpath  is  getcontextpath  assertthat  when  getreverseroutewithmethodreference  ref  router  route2  route   / ref  getreverseroute  ninjaproperties
__label__flaky launcher  id  add  record  to  wf  action  table  action  executor  user . name  get  id  run  conf  workflow  instance  get  external  id  get  status  create  base  hadoop  conf  has  id  swap  get  job  sleep  is  successful  add  record  to  wf  job  table  assert  true  launcher  mapper  assert  not  null  get  context  action  test  workflow  action  recovery  user  retry  workflow  job  recovery  runnable  wait  for  group  a  group . name  launcher  job  get  conf  xml  utils  for  name  wf  action  get  cmd  parse  xml  assert  equals  execute  services  1  create  job  client  workflow  action  job  client  job  jpa  service  evaluate  user  job  id  is  complete  launcherid  addrecordtowfactiontable  actionexecutor  user . name  getid  run  conf  workflowinstance  getexternalid  getstatus  createbasehadoopconf  hasidswap  getjob  sleep  issuccessful  addrecordtowfjobtable  asserttrue  launchermapper  assertnotnull  get  context  action  testworkflowactionrecoveryuserretry  workflowjob  recoveryrunnable  waitfor  group  a  group . name  launcherjob  getconf  xmlutils  forname  wfactiongetcmd  parsexml  assertequals  execute  services  1  createjobclient  workflowaction  jobclient  job  jpaservice  evaluate  user  jobid  iscomplete
__label__nflaky get  client  id  operation  proto  rpc  constants  uuid  rpc  kind  make  rpc  request  header  assert  true  to  byte  array  equals  client  id  proto  util  header  test  rpc  client  id  arrays  getclientid  operationproto  rpcconstants  uuid  rpckind  makerpcrequestheader  asserttrue  tobytearray  equals  clientid  protoutil  header  testrpcclientid  arrays
__label__flaky request  init  chain  set  get  remote  addr  then  return  destroy  when  test  missing  hostname  filter  contains  assert  assert  null  mockito  hostname  filter  assert  true  do  filter  response  get  mock  invoked   ?  ?  ?   request  init  chain  set  getremoteaddr  thenreturn  destroy  when  testmissinghostname  filter  contains  assert  assertnull  mockito  hostnamefilter  asserttrue  dofilter  response  get  mock  invoked   ?  ?  ? 
__label__nflaky  \ %d  percentile  latency  with  5  second  interval  for  stat  foo  foo \ %dth  percentile  latency  insert  the  values  test  mutable  quantiles  rollover  string  system  number  of  ops  for  stat  with  5s  interval  sleep  times  ops  mb  verify  that  the  window  reset   check  it  has  the  values  we  pushed  in  verify  the  metrics  were  added  the  right  number  of  times  nano  time  verify  roll  over  new  quantiles  info  add  registry  stat  quants  test  d  add  gauge  use  a  5s  rollover  period  start  format  j  eq  n  latency  thread  quantiles  q  percentile  mutable  quantiles  any  long  mock  metrics  record  builder  name  foo  num  ops  push  values  for  three  intervals  snapshot  desc   \ %d percentile latency with 5 second interval for stat  foo  foo \ %dthpercentilelatency   insert the values  testmutablequantilesrollover  string  system  number of ops for stat with 5s interval  sleep  times  ops  mb   verify that the window reset  check it has the values we pushed in   verify the metrics were added the right number of times  nanotime  verify   roll over  newquantiles  info  add  registry  stat  quants  test  d  addgauge   use a 5s rollover period  start  format  j  eq  n  latency  thread  quantiles  q  percentile  mutablequantiles  anylong  mockmetricsrecordbuilder  name  foonumops   push values for three intervals  snapshot  desc
__label__flaky bb  data  out  seed  key  interval  alloc  bloom  we  assume  only  2  blooms  in  this  test   so  exit  before  a  3rd  is  made  get  key  count  hash  system  valid  seed  =  bytes  add  assert  true  new  bf1  check  get  bloom  count  next  boolean  write  false  positives:  add  test  serialization / deserialization  get  data  writer  set  err  to  bytes  false  positives  allow  some  tolerance  bf1  byte  buffer  keys  added  =  r  contains  test  dynamic  bloom  get  meta  writer  current  time  millis  to  byte  array  meta  out  wrap  bb  dataout  seed  keyinterval  allocbloom   we assume only 2 blooms in this test  so exit before a 3rd is made  getkeycount  hash  system  valid  seed =   bytes   add  asserttrue  newbf1   check  get  bloomcount  nextboolean  write  false positives:   add   test serialization / deserialization  getdatawriter  set  err  tobytes  falsepositives   allow some tolerance  bf1  bytebuffer  keys added =   r  contains  testdynamicbloom  getmetawriter  currenttimemillis  tobytearray  metaout  wrap
__label__nflaky q1  val  type  c3  desc  new  gauge  withtab5  metric  name   \  ' badcount  2 \  '   contains  run  num  metrics  in  registry  c5  desc  c4  desc  metric  name   \  ' withnewline6   \  '   contains  c1  desc  new  quantiles  final  validation  fill  up  with  some  basics  metric  name   \  ' withtab5   \  '   contains  q1  test  badcount  2  withnewline6  add  some  illegal  names  badcount3  metric  name   \  '   badcount4 \  '   contains  g1  assert  equals  c1  c2  desc  expect  metrics  exception  badcount4  r  test  metrics  registry  illegal  metric  names  illegal  whitespace  character  size  new  counter  g1  desc  metrics  q1  desc  c6  desc  q1  name  metric  name   \  ' badcount3   \  '   contains  q1 val type  c3 desc  newgauge  withtab5 \ t  metric name  \  ' badcount 2 \  '  contains   run  num metrics in registry  c5 desc  c4 desc  metric name  \  ' withnewline6   \  '  contains   c1 desc  newquantiles   final validation   fill up with some basics  metric name  \  ' withtab5 \ t \  '  contains   q1  test  badcount 2  withnewline6     add some illegal names  badcount3    metric name  \  '   badcount4 \  '  contains   g1  assertequals  c1  c2 desc  expectmetricsexception    badcount4  r  testmetricsregistryillegalmetricnames  illegal whitespace character  size  newcounter  g1 desc  metrics  q1 desc  c6 desc  q1 name  metric name  \  ' badcount3   \  '  contains
__label__flaky get  conf  todo:  delete  these  two  lines  once  uber  mode  is  set  back  to  the  default   (   oozie-1385 )   default  --  should  set  to  true  assert  false  false  action  conf  set  to  true  --  should  keep  at  true  conf  assert  equals  jae  mapreduce . job . ubertask . enable  test  inject  launcher  use  uber  mode  services  assert  null  inject  launcher  use  uber  mode  action  conf  set  to  false  --  should  keep  at  false  oozie . action . launcher . mapreduce . job . ubertask . enable  get  true  default  --  should  not  set  get  boolean  disable  at  oozie-site  level   ( default  is  to  be  enabled )   --  redo  above  tests  set  boolean  getconf   todo: delete these two lines once uber mode is set back to the default  ( oozie-1385 )    default -- should set to true  assertfalse  false   action conf set to true -- should keep at true  conf  assertequals  jae  mapreduce . job . ubertask . enable  testinjectlauncheruseubermode  services  assertnull  injectlauncheruseubermode   action conf set to false -- should keep at false  oozie . action . launcher . mapreduce . job . ubertask . enable  get  true   default -- should not set  getboolean   disable at oozie-site level  ( default is to be enabled )  -- redo above tests  setboolean
__label__nflaky file  test  cr  cwith  create7  create / 7  test_  root_  dir  file  sys  assert  writes  crc  get  file  default  create  fs  permission  write  data  file  testcrcwithcreate7  create / 7  test_root_dir  filesys  assertwritescrc  getfiledefault  create  fspermission  writedata
__label__flaky allow  assert  false  generate  id  save  principals  get  user  manager  remove  create  glob  restriction  group2_  path  get  principal  ac  mgr  get  test  group   / *  add  has  privileges  create  group  deny  read  privs  group3  group2  test  glob  restriction2  privileges  from  name  modify  child  n  path  group3_  privilege  superuser  allow  assertfalse  generateid  save  principals  getusermanager  remove  createglobrestriction  group2_  path  getprincipal  acmgr  gettestgroup   / *  add  hasprivileges  creategroup  deny  readprivs  group3  group2  testglobrestriction2  privilegesfromname  modify  childnpath  group3_  privilege  superuser
__label__nflaky format  name  value  pair  param= \ ""this that \ ""  this \  \ that  param= \ ""regular_stuff \ ""  quote  marks   (  \ "" )   must  be  escaped  assert  param  param7  param5  param=regular_stuff  param6  param= \ ""back  slash   (  \  \  \  \  )   must  be  escaped  too \ ""  clear  test  nvp  formatting  param= \ ""quote  marks   (  \  \  \ "" )   must  be  escaped \ ""  assert  equals  param3  param4  param1  param= \ ""this \  \  \  \ that \ ""  param2  buf  regular_stuff  to  string  param= \ ""values  with  blanks  must  always  be  quoted \ ""  this that  back  slash   (  \  \  )   must  be  escaped  too  values  with  blanks  must  always  be  quoted  formatnamevaluepair  param= \ ""this that \ ""  this \  \ that  param= \ ""regular_stuff \ ""  quote marks  (  \ "" )  must be escaped  assert  param  param7  param5  param=regular_stuff  param6  param= \ ""back slash  (  \  \  \  \  )  must be escaped too \ ""  clear  testnvpformatting  param= \ ""quote marks  (  \  \  \ "" )  must be escaped \ ""  assertequals  param3  param4  param1  param= \ ""this \  \  \  \ that \ ""  param2  buf  regular_stuff  tostring  param= \ ""values with \ tblanks must always be quoted \ ""  this that  back slash  (  \  \  )  must be escaped too  values with \ tblanks must always be quoted
__label__flaky exec_  order  callable2  callable3  callable1  test  queue  serial  assert  equals  queue  serial  queueservice  as  list  services  get  arrays  evaluate  wait  for  exec_order  callable2  callable3  callable1  testqueueserial  assertequals  queueserial  queueservice  aslist  services  get  arrays  evaluate  waitfor
__label__nflaky get  class  get  name  secret  value  simple  when  get  cookie  path  as  list  get  init  parameter  names   / bar  assert  context  custom  secret  by  file  management . operation . return  test . build . data  write  init   . foo . com  then  return  is  custom  signer  secret  provider  destroy  custom  cookie  domain  and  cookie  path  is  random  secret  test  dir  custom  secret  as  inline  get  authentication  handler  get  init  parameter  mkdirs  true  mock  secret  file  reset  arrays  authentication  handler  lifecycle   and  custom  impl  get  all  secrets  get  servlet  context  assert  false  kerberos  system  http-secret . txt  sc  get  attribute  assert  true  dummy  authentication  handler  hadoop  close  test  init  get  property  authentication  filter  get  absolute  path  kerberos  auth  handler  get  current  secret  assert  equals  filter  get  mocked  servlet  context  with  string  signer  mockito  get  cookie  domain  elements  writer  config  target / test-dir  getclass  getname  secretvalue  simple  when  getcookiepath  aslist  getinitparameternames   / bar  assert  context   custom secret by file  management . operation . return  test . build . data  write  init   . foo . com  thenreturn  iscustomsignersecretprovider  destroy   custom cookie domain and cookie path  israndomsecret  testdir   custom secret as inline  getauthenticationhandler  getinitparameter  mkdirs  true  mock  secretfile  reset  arrays   authentication handler lifecycle  and custom impl  getallsecrets  getservletcontext  assertfalse  kerberos  system  http-secret . txt  sc  getattribute  asserttrue  dummyauthenticationhandler  hadoop  close  testinit  getproperty  authenticationfilter  getabsolutepath   kerberos auth handler  getcurrentsecret  assertequals  filter  getmockedservletcontextwithstringsigner  mockito  getcookiedomain  elements  writer  config  target / test-dir
__label__flaky get  job  tracker  uri  < / name-node>  <configuration>  <java>  < / configuration>  get  app  path  get  actions  conf  setup  action  conf  create  base  hadoop  conf  test  acl  defaults_no  false  change  action  xml  wf  bean  test2-acl  <property><name>oozie . launcher . mapreduce . job . acl-modify-job< / name><value>  m< / value>< / property>  add  record  to  wf  job  table  assert  not  null  get  context  action  java  action  executor  <job-tracker>  get  name  node  uri  case:  launcher  specific  ac  ls  configured   but  mr  job  ac  ls  not  configured  i . e .   null .   check  for  no  false  changes  to  null  e  action  xml  <property><name>oozie . launcher . mapreduce . job . acl-view-job< / name><value>  v< / value>< / property>  action  conf  < / java>  ae  xml  utils  parse  xml  < / job-tracker>  create  launcher  conf  <main-class>  main-  class< / main-class>  get  file  system  set  type  <name-node>  get  type  getjobtrackeruri  < / name-node> <configuration>  <java>  < / configuration>  getapppath  getactions  conf  setupactionconf  createbasehadoopconf  testacldefaults_nofalsechange  actionxml  wfbean  test2-acl  <property><name>oozie . launcher . mapreduce . job . acl-modify-job< / name><value>m< / value>< / property>  addrecordtowfjobtable  assertnotnull  get  context  action  javaactionexecutor  <job-tracker>  getnamenodeuri   case: launcher specific acls configured  but mr job acls not configured i . e .  null .  check for no false changes to null  eactionxml  <property><name>oozie . launcher . mapreduce . job . acl-view-job< / name><value>v< / value>< / property>  actionconf  < / java>  ae  xmlutils  parsexml  < / job-tracker>  createlauncherconf  <main-class>main-class< / main-class>  getfilesystem  settype  <name-node>  gettype
__label__nflaky assert  false  channel  out  stream  get  bytes  assert  flush  inbuf  buffer  write  chbuffer  s1  s2  s3  a  standard  charsets  clear  assert  equals  fill  read  line  byte  buffer  set  length  outbuf  to  byte  array  to  string  test  complex  read  write  line  wrap  new  channel  append  out  channel    assertfalse  channel  outstream    getbytes  assert  flush  inbuf  buffer  write      chbuffer  s1  s2  s3  a  standardcharsets  clear  assertequals  fill  readline  bytebuffer  setlength  outbuf  tobytearray  tostring  testcomplexreadwriteline  wrap  newchannel  append  outchannel
__label__flaky new_val  script  executor  session   \ ""over  riden \ ""  local_  one  given  insert  select  *  from  entity_static_annotations  where  partition_key  =  crud  entity  with  static  annotations / insert_single_row . cql  when  of  id  value  should_insert_using_static_strategy_an_consistency_level  execute  script  template  log  asserter  prepare  log  level  for  driver  connection  is  not  null  actual  random  utils  manager  one  get  string  next  long  assert  that  execute  immutable  map  assert  consistency  levels  using  time  to  live  then  long  is  equal  to  overriden_val  entity  new_val  scriptexecutor  session   \ ""overriden \ ""  local_one   given  insert  select * from entity_static_annotations where partition_key =   crud  entitywithstaticannotations / insert_single_row . cql   when  of  id  value  should_insert_using_static_strategy_an_consistency_level  executescripttemplate  logasserter  prepareloglevelfordriverconnection  isnotnull  actual  randomutils  manager  one  getstring  nextlong  assertthat  execute  immutablemap  assertconsistencylevels  usingtimetolive   then  long  isequalto  overriden_val  entity
__label__nflaky date  https: /  / www . example . com  private  get  dynamic  entry  foo=  asdjkhqkbzxoqweopiuaxqweoiu;  max-age=3600;  version=1  content-encoding  assert  header  equals  dynamic  table  set  max  size  get  current  size  set-cookie  assert  get  :status  cache-control  test  response  decoding  without  huffman  rfc7541  examples  standard  charsets  mon   21  oct  2013  20:13:22  gmt  create  byte  buffer  mon   21  oct  2013  20:13:21  gmt  assert  equals  headers2  gzip  decoder  headers3  headers1  200  size  302  src1  decode  headers  location  307  src3  src2  dynamic  length  date  https: /  / www . example . com  private  getdynamicentry  foo=asdjkhqkbzxoqweopiuaxqweoiu; max-age=3600; version=1  content-encoding  assertheaderequals  dynamictable  setmaxsize  getcurrentsize  set-cookie  assert  get  :status  cache-control  testresponsedecodingwithouthuffmanrfc7541examples  standardcharsets  mon  21 oct 2013 20:13:22 gmt  createbytebuffer  mon  21 oct 2013 20:13:21 gmt  assertequals  headers2  gzip  decoder  headers3  headers1  200  size  302  src1  decodeheaders  location  307  src3  src2  dynamiclength
__label__flaky reader  auth  token  conf  an  exception  should  be  thrown  as  the  definition  exceeds  the  given  maximum  get  error  code  get  test  case  dir   / workflow . xml  get  file: /  /   workflow . xml  init  test  max  wf  definition  workflow  app  service  wf-schema-valid . xml  destroy  assert  equals  services  100  fail  io  utils  get  test  user  copy  char  stream  set  system  property  wfe  get  resource  as  reader  error  code  writer  wps  read  definition  file  reader  authtoken  conf  an exception should be thrown as the definition exceeds the given maximum  geterrorcode  gettestcasedir   / workflow . xml  get  file: /  /   workflow . xml  init  testmaxwfdefinition  workflowappservice  wf-schema-valid . xml  destroy  assertequals  services  100  fail  ioutils  gettestuser  copycharstream  setsystemproperty  wfe  getresourceasreader  errorcode  writer  wps  readdefinition  file
__label__nflaky payload1  payload2  payload3  in  buffer  readable  channel  assert  assert  not  null  frame  type  get  of  test  read  frame  multiple  small  buffer  get  payload  content  read  frame3  frame1  value  of  frame2  get  stream  id  assert  equals  byte  buffer  remaining  frame  flag  allocate  get  type  get  flags  payload1  payload2  payload3  inbuffer  readablechannel  assert  assertnotnull  frametype  get  of  testreadframemultiplesmallbuffer  getpayloadcontent  read  frame3  frame1  valueof  frame2  getstreamid  assertequals  bytebuffer  remaining  frameflag  allocate  gettype  getflags
__label__flaky end_  points  is_  security_  enabled  oozie  url  run  create  mr  properties  app  path  test  submit  map  reduce2  assert  true  get  -config  servlet_  classes  run  test  app  get  context  url  mock  dag  engine  service  assert  equals  get  file  system  args  call  submit  mr  -oozie  mapreduce  mkdirs  wf  count  to  string  get  fs  test  case  dir  end_points  is_security_enabled  oozieurl  run  createmrproperties  apppath  testsubmitmapreduce2  asserttrue  get  -config  servlet_classes  runtest  app  getcontexturl  mockdagengineservice  assertequals  getfilesystem  args  call  submitmr  -oozie  mapreduce  mkdirs  wfcount  tostring  getfstestcasedir
__label__nflaky p1  test  chown / non  existingfiles*  p4  p5  p6  test  5:  test  for  set  owner  invocation  on  fs  from  command  handler .   admin  f1  f2  f3  test  chown / file  exists  f7  assert  true  test  test_  root_  dir  create  and  write  test  file  test  2:  exit  code  for  chown  on  non-existing  path  is  1  test  chown  get  path  write  file  test  3:  exit  code  for  chown  on  non-existing  path  with  globbed  input  is  1  test  4:  exit  code  for  chown  on  existing  path  with  globbed  input  is  0  to  uri  change  test  chown / file*  test  chown / file  does  not  exist  create  required  files  test  chown / file1  test  chown / file2  test  chown / file3  file  sys  exists  test  1:  exit  code  for  chown  on  existing  file  is  0    p1  testchown / nonexistingfiles*  p4  p5  p6   test 5: test for setowner invocation on fs from command handler .   admin  f1  f2  f3  testchown / fileexists  f7  asserttrue  test  test_root_dir   create and write test file   test 2: exit code for chown on non-existing path is 1  testchown  getpath  writefile   test 3: exit code for chown on non-existing path with globbed input is 1   test 4: exit code for chown on existing path with globbed input is 0  touri  change  testchown / file*  testchown / filedoesnotexist   create required files  testchown / file1  testchown / file2  testchown / file3  filesys  exists   test 1: exit code for chown on existing file is 0
__label__flaky a  b  add  sampler  test  samplers  assert  equals  counter  1  get  value  2  size  set  scheduler  inst  get  shutdown  now  get  samplers  scheduled  executor  service  evaluate  wait  for    a  b  addsampler  testsamplers  assertequals  counter  1  getvalue  2  size  setscheduler  inst  get  shutdownnow  getsamplers  scheduledexecutorservice  evaluate  waitfor
__label__nflaky verify  no  more  interactions  test  test  that  set  options  method  is  called  options  mock  set  options  verify  expr  verifynomoreinteractions  test   test that setoptions method is called  options  mock  setoptions  verify  expr
__label__flaky actual  test  naming  strategy  that  worked  in  one  dot  oh  continues  to  work  spring . jpa . hibernate . namingstrategy:  get  jpa  property  map  org . hibernate . cfg .   ejb3  naming  strategy  equal  to  refresh  assert  that  hibernate . ejb . naming_strategy  environment  test  utils  add  environment  get  setup  test  configuration  get  bean  bean  actual  testnamingstrategythatworkedinonedotohcontinuestowork  spring . jpa . hibernate . namingstrategy:  getjpapropertymap  org . hibernate . cfg . ejb3namingstrategy  equalto  refresh  assertthat  hibernate . ejb . naming_strategy  environmenttestutils  addenvironment  get  setuptestconfiguration  getbean  bean
__label__nflaky auth  exception  error  while  test  wrap  exception  with  message  get  message  assert  equals  get  cause  redirect  the  log  to  and  check  log  message  ex  assert  error  while  authenticating  with  endpoint:  localhost  kerberos  authenticator  assert  true  equals  authenticating  with  endpoint:  localhost  wrap  exception  with  message  induced  exception  ex2  auth exception  error while   testwrapexceptionwithmessage  getmessage  assertequals  getcause   redirect the log to and check log message  ex  assert  error while authenticating with endpoint: localhost  kerberosauthenticator  asserttrue  equals  authenticating with endpoint: localhost  wrapexceptionwithmessage  induced exception  ex2
__label__flaky test  client  without  anonymous  get  context  url  oozie  url  false  admin  run  assert  equals  oozie . authentication . simple . anonymous . allowed  args  call  -oozie  set  system  property  -status  run  test  testclientwithoutanonymous  getcontexturl  oozieurl  false  admin  run  assertequals  oozie . authentication . simple . anonymous . allowed  args  call  -oozie  setsystemproperty  -status  runtest
