__label__nflaky test  partial  frame  write  assert  false  is  empty  outbuffer  byte  buffer  assert  array  equals  frame  flag  get  value  assert  flush  frame  type  to  byte  array  frame  consts  wrap  write  writable  channel  frame  testpartialframewrite  assertfalse  isempty  outbuffer  bytebuffer  assertarrayequals  frameflag  getvalue  assert  flush  frametype  tobytearray  frameconsts  wrap  write  writablechannel  frame
__label__flaky inherit  wf  false  parent  libs2  parent  libs3  check  subworkflow  lib  helper  parent  libs1  parent  libs4  parent  libs5  child  libs1  expected  libs1  expected  libs2  expected  libs3  expected  libs4  inherit  child2.so  expected  libs5  same.jar  test  create  proto  conf  with  sub  workflow  lib2  child  libs3  child  libs2  child  libs5  child1.jar  child  libs4  inheritwf  false  parentlibs2  parentlibs3  checksubworkflowlibhelper  parentlibs1  parentlibs4  parentlibs5  childlibs1  expectedlibs1  expectedlibs2  expectedlibs3  expectedlibs4  inherit  child2.so  expectedlibs5  same.jar  testcreateprotoconfwithsubworkflowlib2  childlibs3  childlibs2  childlibs5  child1.jar  childlibs4
__label__nflaky nn_host/  get  default  uri  set  tet  get  default  uri  no  scheme  trailing  slash  intercept  file  system  conf  no  scheme  in  default  fs  fs_  default_  name_  key  nn_host/  getdefaulturi  set  tetgetdefaulturinoschemetrailingslash  intercept  filesystem  conf  no scheme in default fs  fs_default_name_key
__label__flaky end_  points  is_  security_  enabled  get  context  url  test  admin  queue  dump  oozie  url  header  testing  version  servlet  clear  admin  run  assert  equals  args  call  -oozie  -queuedump  servlet_  classes  run  test  end_points  is_security_enabled  getcontexturl  testadminqueuedump  oozieurl  headertestingversionservlet  clear  admin  run  assertequals  args  call  -oozie  -queuedump  servlet_classes  runtest
__label__nflaky p1  p2  should  fail  test  client  retries  if  max  attempts  not  set  get  kms  url  kp  e  any  string  then  return  create  key  conf  eq  any  when  fail  times  test3  mockito  mock  verify  then  throw  p1  p2  should fail  testclientretriesifmaxattemptsnotset  getkmsurl  kp  e  anystring  thenreturn  createkey  conf  eq  any  when  fail  times  test3  mockito  mock  verify  thenthrow
__label__flaky action  num  test  coord  action  get  pretty  print  xml  utils  pass  expected  values  get  coord  conf  get  id  conf  app  path  add  record  to  coord  job  table  resource  xml  name  coordinator  job  create  coord  action  coord  coord-action-get.xml  _test  get  for  input  check  x  insert  the  action  coordinator  action  action  insert  record  coord  action  to  string  job  get  fs  test  case  dir  actionnum  testcoordactionget  prettyprint  xmlutils   pass expected values  getcoordconf  getid  conf  apppath  addrecordtocoordjobtable  resourcexmlname  coordinatorjob  createcoordaction  coord  coord-action-get.xml  _testgetforinputcheckx   insert the action  coordinatoraction  action  insertrecordcoordaction  tostring  job  getfstestcasedir
__label__nflaky standard  charsets  get  content  assert  false  assert  equals  get  content  length  byte  buffer  get  bytes  capacity  is  repeatable  httpentity  assert  is  streaming  bytes  assert  not  null  message  content  test  basics  wrap  standardcharsets  getcontent  assertfalse  assertequals  getcontentlength  bytebuffer  getbytes  capacity  isrepeatable  httpentity  assert  isstreaming  bytes  assertnotnull  message content  testbasics  wrap
__label__flaky get  id  assert  equals  get  status  execute  add  record  to  coord  job  table  call  coordinator  job  services  coord  job  get  cmd  assert  not  null  get  test  coord  suspend  with  error  postive  job  jpa  service  getid  assertequals  getstatus  execute  addrecordtocoordjobtable  call  coordinatorjob  services  coordjobgetcmd  assertnotnull  get  testcoordsuspendwitherrorpostive  job  jpaservice
__label__nflaky byte  param  should  handle  null  byte  param  assert  false  context  create  verify  has  violations  invoke  mock  controller  validation  byteparamshouldhandlenull  byteparam  assertfalse  context  create  verify  hasviolations  invoke  mockcontroller  validation
__label__flaky <property><name>hello</name><value>world</value></property>  foo  assert  false  conf  hello   meh  bar  world  get  error  code  assert  true  get  verify  parameters  </parameters></root>  xml  utils  <property><name>foo</name><value>bar</value></property>  parse  xml  get  message  assert  equals  <root  xmlns=\""uri:oozie:workflow:0.4\""><parameters>  str  1  fail  contains  2  ex  size  <property><name>hello</name></property>  ends  with  parameter  verifier  error  code  <property><name>meh</name></property>  test  verify  parameters  missing  <property><name>hello</name><value>world</value></property>  foo  assertfalse  conf  hello  meh  bar  world  geterrorcode  asserttrue  get  verifyparameters  </parameters></root>  xmlutils  <property><name>foo</name><value>bar</value></property>  parsexml  getmessage  assertequals  <root xmlns=\""uri:oozie:workflow:0.4\""><parameters>  str  1  fail  contains  2  ex  size  <property><name>hello</name></property>  endswith  parameterverifier  errorcode  <property><name>meh</name></property>  testverifyparametersmissing
__label__nflaky cookie  de  get  name  cookie  then  return  ninja  constant  return  cookie  get  or  die  assert  equals  when  get  cookie  result  get  value  get  max  age  build  results  test  clear  language  clear  language  builder  ninja  properties  lang  ok  ninja_  test  cookie    de  getname  cookie  thenreturn  ninjaconstant  returncookie  getordie  assertequals  when  getcookie  result  getvalue  getmaxage  build  results  testclearlanguage  clearlanguage  builder  ninjaproperties  lang  ok  ninja_test
__label__flaky kills  add  node  def  enters  j2  seven  f2  workflow  instance  get  status  three  two  as  list  exits  assert  true  four  get  end  five  fails  six  f  one  abcde  start  j  assert  equals  size  test  wf  <worklfow-app/>  arrays  job  test  nested  fork  kills  addnode  def  enters  j2  seven  f2  workflowinstance  getstatus  three  two  aslist  exits  asserttrue  four  get  end  five  fails  six  f  one  abcde  start  j  assertequals  size  testwf  <worklfow-app/>  arrays  job  testnestedfork
__label__nflaky the  server  shall  authorize  the  access   but  should  not  drop  a  new  cookie  expires  token_  max_  inactive_  interval  new  cookie  _test  do  filter  authentication  max  inactive  interval  token_  validity_  sec  current  time  millis  authorized  max  inactives  with  renewed  activity  interval  system  test  token  with  valid  activity  interval   the server shall authorize the access  but should not drop a new cookie  expires  token_max_inactive_interval   newcookie  _testdofilterauthenticationmaxinactiveinterval  token_validity_sec  currenttimemillis   authorized  maxinactives   with renewed activity interval  system  testtokenwithvalidactivityinterval
__label__flaky call  test  action  start  command  check  coord  action  mytoken  get  time  add  record  to  action  table  me  action  id  myjob  -  coord-  action  start  command-  c@1  myapp  call  testactionstartcommand  checkcoordaction  mytoken  gettime  addrecordtoactiontable  me  actionid  myjob  -coord-actionstartcommand-c@1  myapp
__label__nflaky reason  adapter  assert  assert  null  check  request  support  assert  request  supported  reason  should  be  null  a  reason  this  request  is  not  supported.  reason  adapter  assert  assertnull  checkrequestsupport  assertrequestsupported  reason should be null  a reason this request is not supported.
__label__flaky add  record  to  coord  job  table  for  waiting  coord-job-for-matd-relative.xml  get  id  date  utils  parse  date  oozie  tz  call  test  action  mater  for  hcatalog  relative  path  coordinator  job  2009-03-06  t010:00  z  2009-03-11  t10:00  z  start  time  end  time  job  addrecordtocoordjobtableforwaiting  coord-job-for-matd-relative.xml  getid  dateutils  parsedateoozietz  call  testactionmaterforhcatalogrelativepath  coordinatorjob  2009-03-06t010:00z  2009-03-11t10:00z  starttime  endtime  job
__label__nflaky fail  assert  buffer  index  out  of  bounds  exception  should  have  been  thrown  append  substring  stuff  substring  trimmed  test  substring  index  of  out  bound  fail  assert  buffer  indexoutofboundsexception should have been thrown  append  substring  stuff  substringtrimmed  testsubstringindexofoutbound
__label__flaky cluster  mtime  on  close  file  after  writing  stat  before  close  get  modification  time  (  conf  wait  active  get  file  status  ipc.client.connection.maxidletime  create  a  new  file  and  write  to  it  info  localhost  2s  closed  file.  dfs  config  keys  datanode  report  format  )  get  file  system  stm  set  int  before  close  is  max_  idle_  time  num  data  nodes  parameter  initialization  file  sys  get  name  node  port  print  datanode  report  shutdown  date  form  system  stat  after  close  assert  true  mdate  after  close  client  num  datanodes  addr  close  /simple.dat  write  file  cleanup  file  e  replicas  test  times  at  close  mtime  before  close  assert  equals  mtime  after  close  after  close  is  build  mdate  before  close  number  of  datanodes  file1  created  and  wrote  file  simple.dat  datanode  report  type  cluster  mtime on    close file after writing  statbeforeclose  getmodificationtime   (  conf  waitactive  getfilestatus  ipc.client.connection.maxidletime   create a new file and write to it  info  localhost   2s  closed file.  dfsconfigkeys  datanodereport  format  )  getfilesystem  stm  setint   before close is   max_idle_time  numdatanodes   parameter initialization  filesys  getnamenodeport  printdatanodereport  shutdown  dateform  system  statafterclose  asserttrue  mdateafterclose  client  numdatanodes  addr  close  /simple.dat  writefile  cleanupfile  e  replicas  testtimesatclose  mtimebeforeclose  assertequals  mtimeafterclose   after close is   build  mdatebeforeclose  number of datanodes   file1  created and wrote file simple.dat  datanodereporttype
__label__nflaky host5  host4  host7  host11  host6  host1  host3  somehost  host2  test  hash  code  someotherhost  host10  myhttp  assert  assert  true  hash  code  http  get  by  address  some  host  host9  inet  address  host8  127.0.0.1  host5  host4  host7  host11  host6  host1  host3  somehost  host2  testhashcode  someotherhost  host10  myhttp  assert  asserttrue  hashcode  http  getbyaddress  somehost  host9  inetaddress  host8  127.0.0.1
__label__flaky coordinator.xml  test  submit  no  username  set  <coordinator-app  name=\""  name\""  frequency=\""10\""  start=\""2009-02-01  t01:00  z\""  end=\""2009-02-03  t23:59  z\""  timezone=\""  utc\""  conf  exception  expected  if  user.name  is  not  set!  app  path  </configuration>  </workflow>  </action>  </coordinator-app>  sc  call  write  to  file  oozie  client  fail  app  xml  file://  get  test  case  dir  unit_  testing  <action>  <workflow>  <app-path>hdfs:///tmp/workflows/</app-path>  <controls>  <timeout>10</timeout>  <concurrency>2</concurrency>  conf.set(  oozie  client.  user_  name   get  test  user());  file  xmlns=\""uri:oozie:coordinator:0.2\"">  <execution>  lifo</execution>  </controls>  <configuration>  <property>  <name>input  a</name>  <value>blah</value>  </property>  coordinator.xml  testsubmitnousername  set  <coordinator-app name=\""name\"" frequency=\""10\"" start=\""2009-02-01t01:00z\"" end=\""2009-02-03t23:59z\"" timezone=\""utc\""   conf  exception expected if user.name is not set!  apppath  </configuration> </workflow> </action> </coordinator-app>  sc  call  writetofile  oozieclient  fail  appxml  file://  gettestcasedir  unit_testing  <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>   <controls> <timeout>10</timeout> <concurrency>2</concurrency>    conf.set(oozieclient.user_name  gettestuser());  file  xmlns=\""uri:oozie:coordinator:0.2\"">   <execution>lifo</execution> </controls>   <configuration> <property> <name>inputa</name> <value>blah</value> </property>
__label__nflaky get  buffer  size  test  fs  output  stream  builder  create  file  get  bytes  assert  array  equals  path  assert  io_  file_  buffer_  size_  default  get  replication  get  block  size  read  fully  get  default  replication  get  file  status  buffer  write  get  permission  should  be  default  replication  factor  assert  that  get  default  block  size  block  size  input  get  int  test  set  0  to  replication   block  size  and  buffer  size  utf8  file  sys  should  be  default  buffer  size  and  permission  buffer  size  should  be  0  replication  factor  should  be  0  should  be  default  block  size  io_  file_  buffer_  size_  key  recursive  content  out  data  written.  stream  test_  root_  dir  block  size  should  be  0  get  len  builder  is  zero  fs  permission  close  replication  get  conf  e  content  origin  should  be  default  permission  the  data  be  read  should  equals  with  the  with  fail  message  test  builder  build  create  with  a  generic  type  of  create  file!  get  file  default  is  equal  to  open  buffer  size  getbuffersize  testfsoutputstreambuilder  createfile  getbytes  assertarrayequals  path  assert  io_file_buffer_size_default  getreplication  getblocksize  readfully  getdefaultreplication  getfilestatus  buffer  write  getpermission  should be default replication factor  assertthat  getdefaultblocksize  blocksize  input  getint   test set 0 to replication  block size and buffer size  utf8  filesys  should be default buffer size   and permission  buffer size should be 0  replication factor should be 0  should be default block size  io_file_buffer_size_key  recursive  content  out  data written.  stream  test_root_dir  block size should be 0  getlen  builder  iszero  fspermission  close  replication  getconf  e  contentorigin  should be default permission  the data be read should equals with the   withfailmessage  testbuilder  build  create with a generic type of createfile!  getfiledefault  isequalto  open  buffersize
__label__flaky -start  end_  points  rest  constants  is_  security_  enabled  get  context  url  oozie  url  mock  dag  engine  service  run  assert  equals  test  start  args  call  1  -oozie  size  assert  true  get  job  servlet_  classes  run  test  -start  end_points  restconstants  is_security_enabled  getcontexturl  oozieurl  mockdagengineservice  run  assertequals  teststart  args  call  1  -oozie  size  asserttrue  get  job  servlet_classes  runtest
__label__nflaky has  field  violation  then  return  invoke  double  param  double  validation  should  work  when  param1  assert  true  context  create  verify  mock  controller  validation  blah  get  parameter  hasfieldviolation  thenreturn  invoke  doubleparam  doublevalidationshouldwork  when  param1  asserttrue  context  create  verify  mockcontroller  validation  blah  getparameter
__label__flaky timestamp2  test  3  failed   but  relax.  time  spent:  something  wrong!  test  4  got  exception  with  maxmum  retries!  something  wrong!  test  2  got  exception  with  maxmum  retries!  test  4  succeeded!  time  spent:  system  busy  test  assert  true  testing  dfs  client  random  waiting  on  busy  blocks.  timestamp  info  test  3  succeeded!  time  spent:  time  win  pass  sec.  log  threads  test  2  succeeded!  time  spent:  file  len  test  dfs  client  retries  on  busy  blocks  retries  warn  current  time  millis  test  1  failed   but  relax.  time  spent:  test  1  succeeded!  time  spent:  xcievers  timestamp2  test 3 failed  but relax. time spent:   something wrong! test 4 got exception with maxmum retries!  something wrong! test 2 got exception with maxmum retries!  test 4 succeeded! time spent:   system  busytest  asserttrue  testing dfsclient random waiting on busy blocks.  timestamp  info  test 3 succeeded! time spent:      timewin  pass   sec.  log  threads  test 2 succeeded! time spent:   filelen  testdfsclientretriesonbusyblocks  retries  warn  currenttimemillis  test 1 failed  but relax. time spent:   test 1 succeeded! time spent:   xcievers
__label__nflaky assert  false  context  prim  boolean  param  create  verify  has  violations  invoke  prim  boolean  param  should  handle  null  mock  controller  validation  assertfalse  context  primbooleanparam  create  verify  hasviolations  invoke  primbooleanparamshouldhandlenull  mockcontroller  validation
__label__flaky get  job  tracker  uri  root  archive  root  so  so  file.so.1  create  context  setup  action  conf  files  in  cache  test  lib  file  archives  context  get  path  create  jar  root  jar  get  cache  files  <main-class>  class</main-class>  <job-tracker>  e  action  xml  <file>  ae  </file>  parse  xml  </job-tracker>  archive  get  file  system  archive  </name-node>  set  lib  files  archives  found  in  classpath  so  file.so  root  so  file.so  not  found  in  cache  job  conf  archive.tar  <archive>  <java>  assert  false  get  app  path  app  path  create  base  hadoop  conf  action  xml  root  so1  root  jar.jar  file  found  so1  distributed  cache  assert  true  root  so  files  in  classpath  close  get  name  node  uri  get  file  class  paths  root  archive.tar  c  </java>  xml  utils  root  so  file.so.1  to  uri  archives  in  cache  file  get  symlink  not  found  in  classpath  p  </archive>  get  cache  archives  equals  root  file  to  string  <name-node>  get  fs  test  case  dir  jar.jar  getjobtrackeruri  rootarchive  rootso  sofile.so.1  createcontext  setupactionconf  filesincache  testlibfilearchives  context  getpath  create  jar  rootjar  getcachefiles        <main-class>class</main-class>        <job-tracker>  eactionxml        <file>  ae  </file>    parsexml  </job-tracker>  archive  getfilesystem  archive   </name-node>  setlibfilesarchives   found in classpath  sofile.so  rootsofile.so   not found in cache  jobconf  archive.tar        <archive>  <java>  assertfalse  getapppath  apppath  createbasehadoopconf  actionxml  rootso1  rootjar.jar  file  found  so1  distributedcache  asserttrue  root  so  filesinclasspath  close  getnamenodeuri  getfileclasspaths  rootarchive.tar  c  </java>  xmlutils  rootsofile.so.1  touri  archivesincache  file   getsymlink   not found in classpath  p  </archive>    getcachearchives  equals  rootfile  tostring        <name-node>  getfstestcasedir  jar.jar
__label__nflaky server  server  assert  false  check  response  conf  run  assert  client  get  call  retry  count  attach  a  listener  that  tracks  every  call  received  by  the  server.  addr  info  get  call  id  get  retry  count  rpc  kind  start  rpc  request  assert  equals  create  call  get  connect  address  call  caller  test  call  id  and  retry  net  utils  override  client  to  store  the  call  info  and  check  response  stop  header  server  server  assertfalse  checkresponse  conf  run  assert  client  getcallretrycount   attach a listener that tracks every call received by the server.  addr  info  getcallid  getretrycount  rpckind  start  rpcrequest  assertequals  createcall  getconnectaddress  call  caller  testcallidandretry  netutils   override client to store the call info and check response  stop  header
__label__flaky get  alert  percentage  workflow_  action  get  notification  msg  get  sla  id  ua  date  utils  get  parent  sla  id  get  upstream  apps  qc  bean  ee  ac  af  get  parent  client  id  an  es  ap  et  get  expected  end  get  alert  contact  get  alert  frequency  jd  get  event_id  get  app  type  nm  get  job  data  get  app  type  str  psi  get  user  get  se  contact  get  expected  start  get  job  status  str  sc  assert  true  si  started  pci  convert  date  to  timestamp  get  status  timestamp  get  expected  end  ts  get  qa  contact  get  app  name  st  set  gn  assert  equals  get  dev  contact  test  set  get  get  expected  start  ts  get  group  name  get  event  type  u  get  status  timestamp  ts  dc  getalertpercentage  workflow_action  getnotificationmsg  getslaid  ua  dateutils  getparentslaid  getupstreamapps  qc  bean  ee  ac  af  getparentclientid  an  es  ap  et  getexpectedend  getalertcontact  getalertfrequency  jd  getevent_id  getapptype  nm  getjobdata  getapptypestr  psi  getuser  getsecontact  getexpectedstart  getjobstatusstr  sc  asserttrue  si  started  pci  convertdatetotimestamp  getstatustimestamp  getexpectedendts  getqacontact  getappname  st  set  gn  assertequals  getdevcontact  testsetget  getexpectedstartts  getgroupname  geteventtype  u  getstatustimestampts  dc
__label__nflaky do  nothing  get  name  get  proxy  could  not  connect  to  host  ha  service  state  error  throwing  proxy  when  test  failover  from  non  existant  service  with  fencer  not  on  creation  of  the  proxy.  verify  with  settings  close  default  answer  do  failover  svc2  common  configuration  keys  svc1  addr  svc1  do  return  don\'t  check  svc1  because  we  can\'t  reach  it   but  that\'s  ok   it\'s  been  fenced.  assert  equals  eq  any  non-existant  active  prevented  failover  gracefully  used  the  right  rpc  timeout  any  int  setup  fencer  fail  mockito  svc2  addr  extra  interfaces  mock  spy  donothing  getname  getproxy  could not connect to host  haservicestate  errorthrowingproxy  when  testfailoverfromnonexistantservicewithfencer   not on creation of the proxy.  verify  withsettings  close  defaultanswer  dofailover  svc2  commonconfigurationkeys  svc1addr  svc1  doreturn   don\'t check svc1 because we can\'t reach it  but that\'s ok  it\'s been fenced.  assertequals  eq  any  non-existant active prevented failover   gracefully used the right rpc timeout  anyint  setupfencer  fail  mockito  svc2addr  extrainterfaces  mock  spy
__label__flaky action  num  coordinator  job  test  coord  action  get  coord-action-get.xml  coordinator  action  get  id  job  clean  up  db  tables  add  record  to  coord  action  table  add  record  to  coord  job  table  _test  get  running  actions  count  actionnum  coordinatorjob  testcoordactionget  coord-action-get.xml  coordinatoraction  getid  job  cleanupdbtables  addrecordtocoordactiontable  addrecordtocoordjobtable  _testgetrunningactionscount
__label__nflaky filter  test  no  remote  host  1.1.1.1  test  request  destroy  http  servlet  response  init  filter  filter  testnoremotehost  1.1.1.1  testrequest  destroy  httpservletresponse  initfilter
__label__flaky should_dsl_update_codec_counter  codec_count  session  given  update  eq  uui  ds  uuid  when  select  codec_count  from  entity_complex_counters  where  id  =  where  id  is  not  null  actual  counter  with  codec_  incr  random  utils  manager  one  time  based  codec  count  next  long  assert  that  execute  and  uuid  =  get  long  then  long  from  base  table  counter  with  codec  dsl  is  equal  to    should_dsl_update_codec_counter  codec_count  session   given  update  eq  uuids  uuid   when  select codec_count from entity_complex_counters where id =   where  id  isnotnull  actual  counterwithcodec_incr  randomutils  manager  one  timebased  codeccount  nextlong  assertthat  execute   and uuid =   getlong   then  long  frombasetable  counterwithcodec  dsl  isequalto
__label__nflaky content  transferred:  50000000  bytes  failed  requests:  0  document  path:  /index.html  replace  core  matchers  equal  to  result  formatter  server  software:  test  server/1.1  protocol  version:  http/1.1  total  transferred:  62640000  bytes  transfer  rate:  17 997.02    kbytes/sec  received  assert  requests  per  second:  5 884.08  #/sec  (mean)  test  basics  server  port:  8080  http  version  results  localhost  time  per  request:  0.170  ms  (mean   across  all  concurrent  requests)  server  hostname:  localhost  standard  charsets  test  server/1.1  time  taken  for  tests:  3.399000  seconds  assert  that  buf  print  concurrency  level:  5  complete  requests:  20000  to  byte  array  kept  alive:  20000  name  document  length:  2924  bytes  /index.html  time  per  request:  0.850  ms  (mean)  content transferred:\t50000000 bytes    failed requests:\t\t0    document path:\t\t\t/index.html    replace  corematchers  equalto  resultformatter      server software:\t\ttestserver/1.1    protocol version:\t\thttp/1.1    total transferred:\t\t62640000 bytes    transfer rate:\t\t\t17 997.02 kbytes/sec received    assert  requests per second:\t5 884.08 #/sec (mean)    testbasics  server port:\t\t\t8080    httpversion  results      localhost  time per request:\t\t0.170 ms (mean  across all concurrent requests)    server hostname:\t\tlocalhost    standardcharsets  testserver/1.1  time taken for tests:\t3.399000 seconds    assertthat  buf  print  concurrency level:\t\t5    complete requests:\t\t20000    tobytearray  kept alive:\t\t\t\t20000    name  document length:\t\t2924 bytes    /index.html  time per request:\t\t0.850 ms (mean)
__label__flaky play  a  server  read  ascii  request  get  /?query  http/1.1  get  host  name  take  request  http://b/4361656  assert  equals  set  body  get  input  stream  url  url  contains  query  but  no  path  integer  enqueue  get  request  line  get  port  http  ?query  client  open  play  a  server  readascii  request  get /?query http/1.1  gethostname  takerequest   http://b/4361656  assertequals  setbody  getinputstream  url  urlcontainsquerybutnopath  integer  enqueue  getrequestline  getport  http  ?query  client  open
__label__nflaky 100110110110101001010101101001101101011010010101101101001010101011001101101010110010  010011010010101101101100101011010100100101001011010110100101010011011010110100101011  011011001010010110110100000  010110101011001011010100100101001010011011010101010010010010101101100101010100100100  101001010010110110100000  101010100110110101001001001011010100110101010010010010101101001101010100100100101010  001001010110010110101010010010010101001101101010101001001001011010100101101010010010  001010100101001001010110110010101001010010010101010011011010010100100101101010011010  100101010110101001101001001001010110110101001010010010010101010110100110100100100101  011011001010101010011011011010100110101011010011010101011001101011010101001101011010  011010010110100101001001011011010010101001010010010101011001011010010100100101101011  010110010101101101100101010101001101011011010011010101011001101010101001011011011010  101010100101101011011001011010101001101101010101001001001011010101001101010010010010  01101001101010101100110101010100101101101101001011010101100101101010010110110100000  000001001011011010110101001011010110100101101101101001010101011001011011010110010101  110101010011011010101010011011010110100101011010110010101101101100101010101001101011  101101011001010101101100101100101010110100110101011011001101010101001011010110110010  11001101010010110110100000  001001010010110110100101010010010100101010110010110100100101001011010110010101001001  100101001001010110100110101001010010010101011001101010010100100101101010100110100101  011010110100101001001001010101101101001010010010010101010101100110100100100101011010  001010100100100101010110110010101001001001010101010011011010010010010101101010011010  010101010110011010100100100101101010110010101001001001010110101100101010010010010101  abcdefghijklmnopqrstuvwxyz0123456789  000001001011011010101001001001011001101010101001010010010110101001011010010100100101  101001001001010100110101011010010010010101100110101010100100100101010010110101101001  010101101001011010100100100101101101001010101001001001010101100101101010010010010110  "
__label__flaky test  coord  action  get  _  e  get  coord  conf  error  code  get  id  conf  app  path  set  error  code  resource  xml  name  action  xml  set  error  message  coord  pass  the  expected  values  coordinator  action  action  add  extra  attributes  for  action  action  num  pretty  print  xml  utils  error  message  x  data  test  case  add  record  to  coord  job  table  000  coordinator  job  _test  get  for  start  x  create  coord  action  coord-action-get.xml  insert  the  action  set  sla  xml  insert  record  coord  action  to  string  job  get  coord  action  xml  dummy  get  fs  test  case  dir  testcoordactionget  _e  getcoordconf  errorcode  getid  conf  apppath  seterrorcode  resourcexmlname  actionxml  seterrormessage  coord   pass the expected values  coordinatoraction  action   add extra attributes for action  actionnum  prettyprint  xmlutils  errormessage  xdatatestcase  addrecordtocoordjobtable  000  coordinatorjob  _testgetforstartx  createcoordaction  coord-action-get.xml   insert the action  setslaxml  insertrecordcoordaction  tostring  job  getcoordactionxml  dummy  getfstestcasedir
__label__nflaky mock  res  init  mock  req  object  under  test  then  return  browser_  agent  csrf  has  not  been  sent  objects  to  verify  interactions  based  on  request  setup  the  configuration  settings  of  the  server  get  method  options  when  filter  config  get  header  filter  mock  chain  get  init  parameter  mockito  do  filter  test  missing  header  multiple  ignore  methods  config  good  request  mock  verify  get   options  rest  csrf  prevention  filter  mockres  init  mockreq   object under test  thenreturn  browser_agent   csrf has not been sent   objects to verify interactions based on request   setup the configuration settings of the server  getmethod  options  when  filterconfig  getheader  filter  mockchain  getinitparameter  mockito  dofilter  testmissingheadermultipleignoremethodsconfiggoodrequest  mock  verify  get options  restcsrfpreventionfilter
__label__flaky cluster  table_  name  create  table  assert  false  reach  in  and  set  minimum  server  count  admin  conf  create  and  disable  table  now  try  to  enable  the  table  thread  now  start  another  region  server  sleep  create  table  descriptor  assert  true  set  minimum  server  count  enable  table  sleep  a  bit  for  assignment  start  region  server  get  master  test  minimum  server  count  is  table  enabled  disable  table  get  server  manager  is  table  available  cluster  table_name  createtable  assertfalse   reach in and set minimum server count  admin  conf   create and disable table   now try to enable the table  thread   now start another region server  sleep  createtabledescriptor  asserttrue  setminimumservercount  enabletable   sleep a bit for assignment  startregionserver  getmaster  testminimumservercount  istableenabled  disabletable  getservermanager  istableavailable
__label__nflaky reader  skip  conf  key  x  create  scanner  error  on  handling  negative  length.  fs  get  bytes  test  failure  negative  length_2  path  fail  close  output  assert  get  len  get  file  status  scanner  lower  bound  close  open  reader  skip  conf  keyx  createscanner  error on handling negative length.  fs  getbytes  testfailurenegativelength_2  path  fail  closeoutput  assert  getlen  getfilestatus  scanner  lowerbound  close  open
__label__flaky test  parser  wf-loop1-invalid.xml  wf-transition-invalid.xml  wf-schema-valid.xml  wf-loop2-invalid.xml  validate  and  parse  assert  equals  fail  io  utils  ex  wf-unsupported-action.xml  parser  get  error  code  get  resource  as  reader  error  code  testparser  wf-loop1-invalid.xml  wf-transition-invalid.xml  wf-schema-valid.xml  wf-loop2-invalid.xml  validateandparse  assertequals  fail  ioutils  ex  wf-unsupported-action.xml  parser  geterrorcode  getresourceasreader  errorcode
__label__nflaky postpone  response  get  and  increment  increasing  server  conf  send  response  executors  trigger  last  waiting  call  was  consumed  assert  make  sure  it  blocked  assert  not  null  time  unit  val  make  sure  it\'s  still  blocked  count  trigger  responses  get  connect  address  fail  future1  ex  future2  stop  address  exec  server  wait  submit  assert  false  waiting  calls  the  background  calls  should  still  be  blocked  get  client  use  only  1  handler  to  prove  it\'s  freed  after  every  call  unexpected  exception:  wait0  set  address  do  a  call  in  the  background  that  will  have  a  deferred  response  call  4:  send  response   expect  it  to  return  wait1  wait2  start  assert  equals  get  cur  call  new  cached  thread  pool  is  done  call  net  utils  deferred  call  wait  count  test  ipc  server  responder  ipc  shouldn\'t  have  responded  another  call  with  wait  count  of  2  test  defer  response  call  should  return  immediately  postponeresponse  getandincrement   increasing  server  conf  sendresponse  executors   trigger last waiting call   was consumed  assert   make sure it blocked  assertnotnull  timeunit  val   make sure it\'s still blocked  count   trigger responses  getconnectaddress  fail  future1  ex  future2  stop  address  exec  server  wait  submit  assertfalse  waitingcalls   the background calls should still be blocked  get  client   use only 1 handler to prove it\'s freed after every call  unexpected exception:  wait0  set  address   do a call in the background that will have a deferred response   call 4: sendresponse  expect it to return  wait1  wait2  start  assertequals  getcurcall  newcachedthreadpool  isdone  call  netutils  deferredcall  waitcount  testipcserverresponder  ipc shouldn\'t have responded   another call with wait count of 2  testdeferresponse   call should return immediately
__label__flaky parent  default  works  for  cat  cp  is  working  run  cmd  default  works  for  ls  run  bak  check  cp  :reptiles  check  put  du  works  on  remote  uri  path  tool  runner  -chown  -cat  test.build.data  /tmp  src  conf  name  dir  ret  hdfs:///furi  /tmp/chown  test  create  local  file  dst  conf  get  file  system  /  /furi  shell  put  is  working  herbivores  num  data  nodes  set  property  mkdirs  /hadoopdir  -chgrp  shutdown  get  uri  dfs_tmp_uri/  check  chown  check  for  rm  -r  dst  fs  -  r  check  for  ls  check  cat  reptiles  default  works  for  rm/rmr  src  cluster  argv  delete  system  file  -put  assert  true  test_  root_  dir  root  src  fs  -cp  /*  check  if  default  hdfs:///  works  -rmr  write  file  dst  cluster  check  du  get  property  -rmr  works  on  remote  uri  ls  works  on  remote  uri  assert  equals  set  conf  confirm  owner  cat  is  working  -ls  build  furi  test  uri  paths  exists  hdfs:///  to  string  test  dfs  shell  -du  parent   default works for cat   cp is working   runcmd  default works for ls   run  bak   check cp  :reptiles   check put  du works on remote uri   path  toolrunner  -chown  -cat  test.build.data  /tmp  srcconf  namedir  ret  hdfs:///furi  /tmp/chowntest  createlocalfile  dstconf  getfilesystem  /  /furi  shell   put is working   herbivores  numdatanodes  setproperty  mkdirs  /hadoopdir  -chgrp  shutdown  geturi  dfs_tmp_uri/   check chown   check for rm -r  dstfs  -r   check for ls   check cat  reptiles  default works for rm/rmr  srccluster  argv  delete  system  file  -put  asserttrue  test_root_dir  root  srcfs  -cp  /*   check if default hdfs:/// works  -rmr  writefile  dstcluster   check du  getproperty  -rmr works on remote uri   ls works on remote uri   assertequals  setconf  confirmowner   cat is working   -ls  build  furi  testuripaths  exists  hdfs:///  tostring  testdfsshell  -du
__label__nflaky get  parsed  type  parse  parameter  asdfasdf  is  matchers  assert  that  null  value  param1  0  000  -123  test  integer  param  parser  123  integer  param  parser  validation    getparsedtype  parseparameter  asdfasdf  is  matchers  assertthat  nullvalue  param1  0  000  -123  testintegerparamparser  123  integerparamparser  validation
__label__flaky init  get  name  set  oozie.service.  proxy  user  service.proxyuser.foo.hosts  get  conf  oozie.service.  proxy  user  service.proxyuser.foo.groups  destroy  conf  *  services     as  list  services  fail  test  wrong  host  otherhost  string  utils  join  arrays  init  getname  set  oozie.service.proxyuserservice.proxyuser.foo.hosts  getconf  oozie.service.proxyuserservice.proxyuser.foo.groups  destroy  conf  *  services     aslist  services  fail  testwronghost  otherhost  stringutils  join  arrays
__label__nflaky cache  no  implementation  for  ninja.cache.  cache  was  bound  e  then  return  ninja  constant  contains  string  get  injector  get  message  bootstrap  assert  that  cache  should  not  have  been  found  when  fail  ninja  mode  com.example.frameworkmodule  framework  module  skips  ninja  classic  module  ninja  properties  impl  mockito  get  get  instance  boot  spy  cache  no implementation for ninja.cache.cache was bound  e  thenreturn  ninjaconstant  containsstring  getinjector  getmessage  bootstrap  assertthat  cache should not have been found  when  fail  ninjamode  com.example.frameworkmodule  frameworkmoduleskipsninjaclassicmodule  ninjapropertiesimpl  mockito  get  getinstance  boot  spy
__label__flaky add  record  to  bundle  action  table  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  get  status  parse  date  oozie  tz  bundle  job  assert  not  null  get  end  current  date  plus  month  job  bundle  wait  for  test  bundle  status  transit  service  killed1  add  record  to  bundle  job  table  bundle  id  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  with  bundle  call  services  coordinator  job  runnable  action1  action2  jpa  service  evaluate  addrecordtobundleactiontable  getcurrentdateafterincrementinginmonths  getid  run  dateutils  getstatus  parsedateoozietz  bundlejob  assertnotnull  get  end  currentdateplusmonth  job  bundle  waitfor  testbundlestatustransitservicekilled1  addrecordtobundlejobtable  bundleid  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtablewithbundle  call  services  coordinatorjob  runnable  action1  action2  jpaservice  evaluate
__label__nflaky localhost  localhost:123  compare  net  utils  create  socket  addr  for  host  localhost:  run  good  cases  test  good  hosts  and  ports  localhost  localhost:123  compare  netutils  createsocketaddrforhost  localhost:  rungoodcases  testgoodhostsandports
__label__flaky date  not  eq  all  should_delete_with_not_equal_condition  script  executor  session  given  simple  with  lwt  result  listener  eq  delete  select  *  from  simple  where  id  =  as  list  lwt  result  listener  when  of  get  where  id  get  and  set  row  table  execute  script  template  on  error  random  utils  manager  all  columns_  from  base  table  one  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  if_  consistency  list  is  true  success  then  is  null  long  build  date  key  arrays  dsl  on  success  date  noteq  all  should_delete_with_not_equal_condition  scriptexecutor  session   given  simple  withlwtresultlistener  eq  delete  select * from simple where id =   aslist  lwtresultlistener   when  of  get  where  id  getandset  row  table  executescripttemplate  onerror  randomutils  manager  allcolumns_frombasetable  one  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  if_consistencylist  istrue  success   then  isnull  long  builddatekey  arrays  dsl  onsuccess
__label__nflaky uri  authority  assert  somehost:1234  user@somehost  somehost  somehost:8080  create  some  host:8080  assert  equals  test  create  from  string  user  uriauthority  assert  somehost:1234  user@somehost  somehost  somehost:8080  create  somehost:8080  assertequals  testcreatefromstring  user
__label__flaky upload  file  get  server  address  upload  finish  ninja  test  browser  let\'s  upload  a  simple  txt  file...  result  test  that  upload  works  contains  file  assert  true  let\'s  see  if  that  has  worked...  test_for_upload.txt  src/test/resources/test_for_upload.txt  uploadfile  getserveraddress  uploadfinish  ninjatestbrowser   let\'s upload a simple txt file...  result  testthatuploadworks  contains  file  asserttrue   let\'s see if that has worked...  test_for_upload.txt  src/test/resources/test_for_upload.txt
__label__nflaky test  root  dir  http://  conn  proxy  users  user  a  cannot  impersonate  user  c   it  fails.  servlet  test  authentication  with  proxy  user  conf  hadoop.proxyuser.user  a.groups  create  http  server  to  test.  setup  logs  dir  assert  jmx  server  url  group  c  get  spengo  conf  logs  group  b  group  a  user  group  information  signer  create  user  for  testing  open  connection  stacks  *  setup  auth  token  for  user  a  /  stop  set  property  get  encrypted  auth  token  user  a  group  a  spengo  conf  user  a  impersonates  user  b   it\'s  allowed.  hadoop.log.dir  setup  user  group  get  signer  to  encrypt  refresh  super  user  groups  configuration  only  user  a  has  the  access.  set  acl  user  b  cannot  access  these  servlets.  system  make  user  a  impersonate  users  in  group  b  auth  url  get  host  port  string  get  connector  address  http  url  connection  log  level  get  signer  to  encrypt  token  get  common  builder  setup  token  for  user  b  hadoop.proxyuser.user  a.hosts  set  get  absolute  path  the  default  authenticator  is  kerberos.  start  http  server  assert  equals  ?do  as=user  c  ?do  as=user  b  set  conf  token  user  a  user  b  net  utils  build  get  response  code  user  c  testrootdir  http://  conn  proxyusers   usera cannot impersonate userc  it fails.  servlet  testauthenticationwithproxyuser  conf  hadoop.proxyuser.usera.groups   create http server to test.   setup logs dir  assert  jmx  serverurl  groupc  getspengoconf  logs  groupb  groupa  usergroupinformation  signer  createuserfortesting  openconnection  stacks  *   setup auth token for usera  /  stop  setproperty  getencryptedauthtoken  usera groupa  spengoconf   usera impersonates userb  it\'s allowed.  hadoop.log.dir   setup user group  getsignertoencrypt  refreshsuperusergroupsconfiguration   only usera has the access.  setacl   userb cannot access these servlets.  system   make usera impersonate users in groupb  authurl  gethostportstring  getconnectoraddress  httpurlconnection  loglevel   get signer to encrypt token  getcommonbuilder   setup token for userb  hadoop.proxyuser.usera.hosts  set  getabsolutepath   the default authenticator is kerberos.  start  httpserver  assertequals  ?doas=userc  ?doas=userb  setconf  token  usera  userb  netutils  build  getresponsecode  userc
__label__flaky cluster  file_  size  test  multiple  files  smaller  than  one  block  conf  dir  /test  create  file  wait  active  webhdfsuri=  check  content  summary  get  ns  quota  exceeded  quota  ://  web  hdfs  file  system  /test/test  dfs  config  keys  invalid  space  consumed  192kb  quota  now  check  that  trying  to  create  another  file  violates  the  quota  get  file  system  get  default  block  size  set  int  get  name  node  nn  addr  default  namespace  quota  expected  as  long  max.  but  the  value  is  :  num  data  nodes  mkdirs  -set  space  quota  long  should  account  for  all  59  files  (almost  quota_  size)  shutdown  /test/test59  quota_  size  test  for  deafult  name  space  quota  block_  size  admin  fs  wait  replication  system  file  assert  true  get  run  command  get  space  consumed  dfs  test  util  the  last  block:  (58  *  3  *  1024)  (3  *  6  *  1024)  =  192kb  c  ns  quota  get  content  summary  webhdfs  assert  equals  quota  not  exceeded  integer  build  webhdfsuri  amount  used  as  calculated  by  i  node#space  consumed  in  tree.  to  string  fs  image  test  util  set  boolean  get  namesystem  cluster  file_size  testmultiplefilessmallerthanoneblock  conf  dir  /test  createfile  waitactive  webhdfsuri=  checkcontentsummary  getnsquota  exceededquota  ://  webhdfsfilesystem  /test/test  dfsconfigkeys  invalid space consumed   192kb quota   now check that trying to create another file violates the quota  getfilesystem  getdefaultblocksize  setint  getnamenode  nnaddr  default namespace quota expected as long max. but the value is :  numdatanodes  mkdirs  -setspacequota  long   should account for all 59 files (almost quota_size)  shutdown  /test/test59  quota_size   test for deafult namespace quota  block_size  admin  fs  waitreplication  system  file  asserttrue  get  runcommand  getspaceconsumed  dfstestutil   the last block: (58 * 3 * 1024) (3 * 6 * 1024) = 192kb  c  nsquota  getcontentsummary  webhdfs  assertequals  quota not exceeded  integer  build  webhdfsuri   amount used as calculated by inode#spaceconsumedintree.  tostring  fsimagetestutil  setboolean  getnamesystem
__label__nflaky yak  dingo  get  name  dst  src  conf  delete  fail  assert  true  test_  root_  dir  tmp  mkdirs  file  sys  exists  test  copy  copy  failed  to  detect  existing  dir  write  file  file  util  yak  dingo  getname  dst  src  conf  delete  fail  asserttrue  test_root_dir  tmp  mkdirs  filesys  exists  testcopy  copy  failed to detect existing dir  writefile  fileutil
__label__flaky call  h3#heading  {  font-size:  modular-scale(14px   1   1.618);  }  process  task  e  should  be  thread  safe  wro  test  utils  run  concurrently  processor  call  h3#heading {  font-size: modular-scale(14px  1  1.618); }  process  task  e  shouldbethreadsafe  wrotestutils  runconcurrently  processor
__label__nflaky set  key  manager  factory  is  factory  created  set  key  store  factory  bean  create  context  set  trust  manager  factory  verifying  that  ssl  is  configured  properly  key_  store_  message_  pattern  trust_  store_  message_  pattern  secure  random  key  manager  factory  assert  true  assert  not  null  set  secure  random  context  trust  manager  factory  set  trust  store  ssl_  configuration_  message_  pattern  is  key  store  created  secure_  random_  message_  pattern  test  create  context  has  info  matching  key  store  trust_  manager_  factory_  message_  pattern  trust  store  is  secure  random  created  key_  manager_  factory_  message_  pattern  setkeymanagerfactory  isfactorycreated  setkeystore  factorybean  createcontext  settrustmanagerfactory   verifying that ssl is configured properly  key_store_message_pattern  trust_store_message_pattern  securerandom  keymanagerfactory  asserttrue  assertnotnull  setsecurerandom  context  trustmanagerfactory  settruststore  ssl_configuration_message_pattern  iskeystorecreated  secure_random_message_pattern  testcreatecontext  hasinfomatching  keystore  trust_manager_factory_message_pattern  truststore  issecurerandomcreated  key_manager_factory_message_pattern
__label__flaky src/test/resources/tmp2.png  f1  f2  delete  src/test/resources/graph  wf.xml  image  io  not  a  valid  png:  my  test  app  assert  assert  true  assert  not  null  src/test/resources/tmp1.png  set  id  test  write  png1  png2  write  set  app  name  read  e  io  g  length  get  message  fail  src/test/resources/invalid  graph  wf.xml  json  wf  job  my  test  id  read  file  write  png  failed  for  invalid  graph  wf.xml:  write  png  failed  for  graph  wf.xml:  check  if  a  valid  file  was  written  src/test/resources/invalid.png  src/test/resources/tmp2.png  f1  f2  delete  src/test/resources/graphwf.xml  imageio  not a valid png:   my test app  assert  asserttrue  assertnotnull  src/test/resources/tmp1.png  setid  testwrite  png1  png2  write  setappname  read  e  io  g  length  getmessage  fail  src/test/resources/invalidgraphwf.xml  jsonwfjob  my test id  readfile  write png failed for invalidgraphwf.xml:   write png failed for graphwf.xml:    check if a valid file was written  src/test/resources/invalid.png
__label__nflaky mock  res  init  mock  req  verify  zero  interactions  object  under  test  then  return  browser_  agent  test  missing  header  no  methods  to  ignore  config  bad  request  csrf  has  not  been  sent  objects  to  verify  interactions  based  on  request  setup  the  configuration  settings  of  the  server  get  method  when  filter  config  get  header  filter  mock  chain  get  init  parameter  mockito  do  filter  get  mock  rest  csrf  prevention  filter    mockres  init  mockreq  verifyzerointeractions   object under test  thenreturn  browser_agent  testmissingheadernomethodstoignoreconfigbadrequest   csrf has not been sent   objects to verify interactions based on request   setup the configuration settings of the server  getmethod  when  filterconfig  getheader  filter  mockchain  getinitparameter  mockito  dofilter  get  mock  restcsrfpreventionfilter
__label__flaky be  equal  assert  false  equal  assert  true  get  join  jms  context  jms  props  session4  session3  session2  get  conf  print  stack  trace  session1  e  create  connection  context  create  thread  local  session  start  assert  equals  services  services  conn  info  th  equals  test  thread  local  session  jms  job  event  listener  session   be equal  assertfalse   equal  asserttrue  get  join  jmscontext  jmsprops  session4  session3  session2  getconf  printstacktrace  session1  e  createconnectioncontext  createthreadlocalsession  start  assertequals  services  services  conninfo  th  equals  testthreadlocalsession  jmsjobeventlistener  session
__label__nflaky get  and  advance  current  index  is  one  test  default  pattern  mux  of  size  2:  0  0  1  0  0  1  0  0  1   etc  mux  of  size  1:  0  0  0  0  0   etc  size  3:  4x0  2x1  1x2   etc  assert  that  mux  size  4:  8x0  4x1  2x2  1x3  is  zero  is  equal  to    getandadvancecurrentindex  isone  testdefaultpattern   mux of size 2: 0 0 1 0 0 1 0 0 1  etc   mux of size 1: 0 0 0 0 0  etc   size 3: 4x0 2x1 1x2  etc  assertthat  mux   size 4: 8x0 4x1 2x2 1x3  iszero  isequalto
__label__flaky fail  expected  timeout  e  test  redirect  connect  timeout  connect  timed  out  start  single  temporary  redirect  response  thread  get  message  test_  timeout  assert  equals  get  file  checksum  /file  fs  fail  expected timeout  e  testredirectconnecttimeout  connect timed out  startsingletemporaryredirectresponsethread  getmessage  test_timeout  assertequals  getfilechecksum  /file  fs
__label__nflaky test  class  loader  other  assert  true  conf  get  class  loader  set  quiet  mode  set  class  loader  testclassloader  other  asserttrue  conf  getclassloader  setquietmode  setclassloader
__label__flaky <execution>  lifo</execution>  </controls>  <datasets>  test  job  methods  local  oozie  conf  xmlns=\""uri:oozie:coordinator:0.1\"">  <controls>  <timeout>10</timeout>  <concurrency>1</concurrency>  run  </input-events>  <app-path>hdfs:///tmp/workflows/</app-path>  </property></configuration>  </workflow>  </action>  </coordinator-app>  get  coord  client  file://  get  test  case  dir  <coordinator-app  name=\""  name\""  frequency=\""${coord:minutes(20)}\""  <output-events>  <data-out  name=\""  local_  a\""  dataset=\""local_a\"">  timezone=\""  utc\"">  <uri-template>file:///tmp/coord/workflows/${  year}/${  day}</uri-template>  </dataset>  suspend  <configuration>  <property>  <name>input  a</name>  <value>${coord:data  in(\'  a\')}</value>  </property>  list  name  oozie  client  job  id  size  </datasets>  <input-events>  set  property  create  configuration  job  file  start=\""2009-02-01  t01:00  z\""  end=\""2009-02-03  t23:59  z\""  timezone=\""  utc\""  submit  get  coord  jobs  info  app  path  write  to  file  app  xml  job  id0  just  in  case   check  that  there  are  no  coord  job  records  left  by  previous  tests:  <property>  <name>input  b</name>  <value>${coord:data  out(\'  local_  a\')}</value>  get  coord  job  info  client  <instance>${coord:current(-1)}</instance>  </data-out>  </output-events>  <action>  <workflow>  <dataset  name=\""local_a\""  frequency=\""${coord:minutes(20)}\""  initial-instance=\""2009-02-01  t01:00  z\""  <dataset  name=\""a\""  frequency=\""${coord:minutes(20)}\""  initial-instance=\""2009-02-01  t01:00  z\""  resume  coordinator.xml  get  app  name  app  name  assert  equals  kill  list0  <data-in  name=\""  a\""  dataset=\""a\"">  <instance>${coord:latest(0)}</instance>  </data-in>    <execution>lifo</execution> </controls> <datasets>   testjobmethods  localoozie  conf  xmlns=\""uri:oozie:coordinator:0.1\""> <controls> <timeout>10</timeout> <concurrency>1</concurrency>   run  </input-events>   <app-path>hdfs:///tmp/workflows/</app-path>   </property></configuration> </workflow> </action> </coordinator-app>  getcoordclient  file://  gettestcasedir  <coordinator-app name=\""name\"" frequency=\""${coord:minutes(20)}\""   <output-events> <data-out name=\""local_a\"" dataset=\""local_a\"">   timezone=\""utc\""> <uri-template>file:///tmp/coord/workflows/${year}/${day}</uri-template> </dataset>   suspend  <configuration> <property> <name>inputa</name> <value>${coord:datain(\'a\')}</value> </property>   list  name  oozieclient  jobid  size  </datasets> <input-events>   setproperty  createconfiguration  job  file  start=\""2009-02-01t01:00z\"" end=\""2009-02-03t23:59z\"" timezone=\""utc\""   submit  getcoordjobsinfo  apppath  writetofile  appxml  jobid0   just in case  check that there are no coord job records left by previous tests:  <property> <name>inputb</name> <value>${coord:dataout(\'local_a\')}</value>   getcoordjobinfo  client  <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow>   <dataset name=\""local_a\"" frequency=\""${coord:minutes(20)}\"" initial-instance=\""2009-02-01t01:00z\""   <dataset name=\""a\"" frequency=\""${coord:minutes(20)}\"" initial-instance=\""2009-02-01t01:00z\""   resume  coordinator.xml  getappname  appname  assertequals  kill  list0  <data-in name=\""a\"" dataset=\""a\""> <instance>${coord:latest(0)}</instance> </data-in>
__label__nflaky get  bytes  transferred  testfile  more  stuff;  and  a  lot  more  stuff  rw  standard  charsets  assert  false  channel  bytes  read  create  temp  file  assert  equals  decoder  test  coding  beyond  content  limit  file  stuff;  transfer  assert  inbuf  get  channel  assert  true  metrics  close  fchannel  is  completed  getbytestransferred  testfile  more stuff; and a lot more stuff  rw  standardcharsets  assertfalse  channel  bytesread  createtempfile  assertequals  decoder  testcodingbeyondcontentlimitfile  stuff;  transfer  assert  inbuf  getchannel  asserttrue  metrics  close  fchannel  iscompleted
__label__flaky var-app-name  check  coord  jobs  </dataset>  </configuration>  test  basic  submit  with  include  file  include  path  conf  <action>  file:///tmp/include_xml/workflows/${  year}/${  day}  end=\""2009-02-03  t23:59  z\""  timezone=\""  utc\""  xmlns=\""uri:oozie:coordinator:0.2\"">  <controls>  </input-events>  <app-path>hdfs:///tmp/workflows/</app-path>  uri_  template_  include_  xml  </datasets>  <data-in>  should  be  2.  one  from  coordinator.xml  and  the  other  from  the  include  file  assert  not  null  file://  get  test  case  dir  unit_  testing  processed  job  xml  </include>  <dataset  name=\""  b\""  frequency=\""${coord:days(7)}\""  initial-instance=\""2009-02-01  t01:00  z\""  timezone=\""  utc\"">  </uri-template>  get  child  parse  xml  unchecked  <execution>  lifo</execution>  data-in  uri_  template_  coord_  xml  oozie  client  job  id  get  children  size  <property>  <name>input  a</name>  <value>${coord:data  in(\'input  b\')}</value>  </property>  get  namespace  <workflow>  -  c  <input-events>  datain  elements  </workflow>  <include>  </coordinator-app>  </controls>  job  file  <data-in  name=\""input  b\""  dataset=\""  b\"">  <instance>${coord:latest(0)}</instance>  </data-in>  <dataset  name=\""  a\""  frequency=\""${coord:days(7)}\""  initial-instance=\""2009-02-01  t01:00  z\""  timezone=\""  utc\"">  <coordinator-app  name=\""${app  name}-foo\""  frequency=\""${coord:days(1)}\""  start=\""2009-02-01  t01:00  z\""  app  path  substring  include1.xml  sc  write  to  file  app  xml  get  job  xml  uri-template  </action>  assert  true  get  include  xml  coordinator.xml  set  xml  utils  <datasets>  <data-in  name=\""input  a\""  dataset=\""  a\"">  <instance>${coord:latest(0)}</instance>  </data-in>  app  name  length  <uri-template>  assert  equals  <configuration>  file:///tmp/coord_xml/workflows/${  year}/${  day}  input-events  call  get  child  text  get  test  user  namespace  dataset  var-app-name  checkcoordjobs  </dataset>   </configuration>  testbasicsubmitwithincludefile  includepath  conf  <action>  file:///tmp/include_xml/workflows/${year}/${day}  end=\""2009-02-03t23:59z\"" timezone=\""utc\"" xmlns=\""uri:oozie:coordinator:0.2\"">  <controls>   </input-events>   <app-path>hdfs:///tmp/workflows/</app-path>   uri_template_include_xml  </datasets>  <data-in> should be 2. one from coordinator.xml and the other from the include file  assertnotnull  file://  gettestcasedir  unit_testing  processedjobxml  </include>  <dataset name=\""b\"" frequency=\""${coord:days(7)}\"" initial-instance=\""2009-02-01t01:00z\"" timezone=\""utc\"">  </uri-template>  getchild  parsexml  unchecked  <execution>lifo</execution>  data-in  uri_template_coord_xml  oozieclient  jobid  getchildren  size  <property> <name>inputa</name> <value>${coord:datain(\'inputb\')}</value> </property>   getnamespace  <workflow>  -c   <input-events>   datainelements  </workflow>  <include>   </coordinator-app>  </controls>  job  file  <data-in name=\""inputb\"" dataset=\""b\""> <instance>${coord:latest(0)}</instance> </data-in>    <dataset name=\""a\"" frequency=\""${coord:days(7)}\"" initial-instance=\""2009-02-01t01:00z\"" timezone=\""utc\"">  <coordinator-app name=\""${appname}-foo\"" frequency=\""${coord:days(1)}\"" start=\""2009-02-01t01:00z\""   apppath  substring  include1.xml  sc  writetofile  appxml  getjobxml  uri-template  </action>  asserttrue  get  includexml  coordinator.xml  set  xmlutils  <datasets>   <data-in name=\""inputa\"" dataset=\""a\""> <instance>${coord:latest(0)}</instance> </data-in>    appname  length  <uri-template>  assertequals  <configuration>  file:///tmp/coord_xml/workflows/${year}/${day}  input-events  call  getchildtext  gettestuser  namespace  dataset
__label__nflaky docheck  validation  failed  regex  validate  jsr303  with  optional  validation  with  optional  failed  regex  length  build  dto  context  regex!!!  docheckvalidationfailedregex  validatejsr303withoptional  validationwithoptionalfailedregex  length  builddto  context  regex!!!
__label__flaky get  build  info  end_  points  get  property  is_  security_  enabled  get  context  url  oozie  url  assert  equals  wc  call  test  client  build  version  build  info  servlet_  classes  run  test  get  client  build  version  getbuildinfo  end_points  getproperty  is_security_enabled  getcontexturl  oozieurl  assertequals  wc  call  testclientbuildversion  buildinfo  servlet_classes  runtest  getclientbuildversion
__label__nflaky test  sub  package  controller  get  request  core  matchers  equal  to  assert  that  make  request  url  sub  get  works.  path  assert  response  get  test  server  url  /sub/get  testsubpackagecontrollerget  request  corematchers  equalto  assertthat  makerequest  url  sub get works.  path  assert  response  get  testserverurl  /sub/get
__label__flaky test  pause  unpause2  job1  get  time  pause  start  runnable  add  record  to  bundle  job  table  run  get  id  assert  equals  get  status  execute  set  pause  time  services  job  id  assert  not  null  get  set  kickoff  time  job  job  jpa  service  evaluate  wait  for  testpauseunpause2  job1  gettime  pausestartrunnable  addrecordtobundlejobtable  run  getid  assertequals  getstatus  execute  setpausetime  services  jobid  assertnotnull  get  setkickofftime  job  job  jpaservice  evaluate  waitfor
__label__nflaky contains  go  to  $  assert  true  /notauthenticate  page  source  #login  only  visible  with  valid  authentication  token  login  click  test  authenticity  fails  contains  goto  $  asserttrue  /notauthenticate  pagesource  #login  only visible with valid authenticationtoken  login  click  testauthenticityfails
__label__flaky server  hcatalog.mydb.mytable  get  jms  connection  info  print  stack  trace  e  hcat  service  hcat.server.com:5080  jms  service  assert  equals  services  hcat://hcat.server.com:8020  fail  get  message  receiver  receiver1  conn  info  assert  not  null  get  topic  register  for  notification  test  un  register  topic  exception  encountered  :  unregister  from  notification  server  hcatalog.mydb.mytable  getjmsconnectioninfo  printstacktrace  e  hcatservice  hcat.server.com:5080  jmsservice  assertequals  services  hcat://hcat.server.com:8020  fail  getmessagereceiver  receiver1  conninfo  assertnotnull  get  topic  registerfornotification  testunregistertopic  exception encountered :   unregisterfromnotification
__label__nflaky directory  count  expected  length  11110  33333  22222  11111  assert  equals  space  consumed  file  count  check  the  to  string  method  (defaults  to  with  quotas)  test  to  string  build  quota  44444  -11111  66665  to  string  space  quota  content  summary  directorycount  expected  length             11110        33333        22222              11111   assertequals  spaceconsumed  filecount   check the tostring method (defaults to with quotas)  testtostring  build  quota         44444          -11111           66665  tostring  spacequota  contentsummary
__label__flaky ::  end  date  get  time  stream  log  date  utils  dag  x  log  info  service  assert  true  middle  date  get  action  cjb  after  get  coord  job  ce  middle  rest  constants  create  coordinator  engine  get  filter  params  (  assert  equals  services  @1|     run  jobs  impl  filter  job  id  created  date  format  date  oozie  tz  service  @2)  test  stream  log4  job  log  date  get  created  time  ::  enddate  gettime  streamlog  dateutils  dagxloginfoservice  asserttrue  middledate  get  action  cjb  after  getcoordjob  ce  middle  restconstants  createcoordinatorengine  getfilterparams  (  assertequals  services  @1|     runjobsimpl  filter  jobid  createddate  formatdateoozietz  service  @2)  teststreamlog4joblogdate  getcreatedtime
__label__nflaky mockds30  check  metrics  mockds31  gsink31  publish  the  metrics  .sink.gsink30.context  save  setup  test  for  ganglia  sink31  we  manually  publish  metrics  by  metics  system#publish  metrics  now  here.  gsink30  ganglia  metrics  test  helper  filter  out  only  \""test\""  check  ganflia  sink30  data  get  test  filename  check  ganflia  sink31  data  test  ganglia  metrics2  .sink.gsink31.context  s1  s1rec  gsink31  desc  get  captured  send  cb  set  datagram  socket  add  init  set  expected  metrics  incr  ms  start  gsink30  desc  s1  desc  register  the  sinks  test  name  prefix  stop  *.period  setup  test  for  ganglia  sink30  hadoop-metrics2-  test  metrics  config  expected  count  from  ganglia30  expected  count  from  ganglia31  publish  metrics  now  subset  register  mockds30  checkmetrics  mockds31  gsink31   publish the metrics  .sink.gsink30.context  save   setup test for gangliasink31   we manually publish metrics by meticssystem#publishmetricsnow here.  gsink30  gangliametricstesthelper   filter out only \""test\""   check ganfliasink30 data  gettestfilename   check ganfliasink31 data  testgangliametrics2  .sink.gsink31.context  s1  s1rec  gsink31 desc  getcapturedsend  cb  setdatagramsocket  add  init  set  expectedmetrics  incr  ms  start  gsink30 desc  s1 desc   register the sinks  testnameprefix  stop  *.period   setup test for gangliasink30  hadoop-metrics2-  testmetricsconfig  expectedcountfromganglia30  expectedcountfromganglia31  publishmetricsnow  subset  register
__label__flaky cluster  get  first  tx  id  restart  cluster  conf  run  wait  active  assert  in-progress  log  could  not  renew  or  cancel  the  token  token1  get  user  name  token2  get  fs  image  saving  image  in  safe  mode  should  succeed  token3  token4  token5  is  in  progress  should  only  have  start  txn  user  group  information  restart  cluster  again  verify  that  the  edits  file  is  empty  except  for  the  start  txn  format  cancel  token  get  file  system  get  name  node  validate  log  fail  namesystem  test  save  namespace  num  data  nodes  get  last  tx  id  saving  image  without  safe  mode  should  fail  get  storage  should  be  able  to  renew  &  cancel  the  delegation  token  after  cluster  restart  shutdown  nn  renew  token  log  num  transactions  admin  fs  find  latest  edits  log  sd  assert  true  get  delegation  token  secret  manager  start  threads  num  datanodes  dir  iterable  close  should  have  5  transactions  e  renewer  get  message  assert  equals  set  safe  mode  get  login  user  -save  namespace  args  safe  mode  action  build  verify  that  the  edits  file  is  not  empty  get  delegation  token  fs  image  test  util  get  namesystem  cluster  getfirsttxid   restart cluster  conf  run  waitactive  assert  in-progress log   could not renew or cancel the token  token1  getusername  token2  getfsimage   saving image in safe mode should succeed  token3  token4  token5  isinprogress   should only have start txn  usergroupinformation   restart cluster again   verify that the edits file is empty except for the start txn  format  canceltoken  getfilesystem  getnamenode  validatelog  fail  namesystem  testsavenamespace  numdatanodes  getlasttxid   saving image without safe mode should fail  getstorage   should be able to renew & cancel the delegation token after cluster restart  shutdown  nn  renewtoken  log  numtransactions  admin  fs  findlatesteditslog  sd  asserttrue  getdelegationtokensecretmanager  startthreads  numdatanodes  diriterable  close   should have 5 transactions  e  renewer  getmessage  assertequals  setsafemode  getloginuser  -savenamespace  args  safemodeaction  build   verify that the edits file is not empty  getdelegationtoken  fsimagetestutil  getnamesystem
__label__nflaky result  test  results  redirect  temporary  http://example.com  get  status  code  get  headers  get  renderable  results  assert  true  get  assert  equals  redirect  temporary  result  result  testresultsredirecttemporary  http://example.com  getstatuscode  getheaders  getrenderable  results  asserttrue  get  assertequals  redirecttemporary  result
__label__flaky add  record  to  wf  action  table  get  id  workflow  instance  get  status  update  the  list  for  doing  bulk  writes  coord  job  wf  job  add  record  to  wf  job  table  assert  not  null  get  action  workflow  job  update  list  add  get  status  str  update  the  status  check  for  expected  status  after  running  bulk  update  jpa  running  assert  equals  execute  add  record  to  coord  job  table  set  status  coordinator  job  1  services  set  update  list  workflow  action  bulk  update  cmd  succeeded  test  updates  action2  jpa  service  addrecordtowfactiontable  getid  workflowinstance  getstatus   update the list for doing bulk writes  coordjob  wfjob  addrecordtowfjobtable  assertnotnull  get  action  workflowjob  updatelist  add  getstatusstr   update the status   check for expected status after running bulkupdatejpa  running  assertequals  execute  addrecordtocoordjobtable  setstatus  coordinatorjob  1  services  setupdatelist  workflowaction  bulkupdatecmd  succeeded  testupdates  action2  jpaservice
__label__nflaky sub  not  created  in  src  dir  contract  test  utils  test  rename  with  non  empty  sub  dir  posix  rename  test  dir  dest  handle  empty  dst  directory  on  windows  fs  assert  path  does  not  exist  path  write  text  file  final  dir  not  created  in  src/sub  dir  accept  only  posix  rename  behavior  in  this  test  not  deleted  assert  path  exists  sub/subfile.txt  path  to  file  subfile.txt  get  file  system  this  is  the  file  in  src  dir  source.txt  rlfs  not  renamed  into  dest/sub  dir  mkdirs  src1  src  dir  this  is  the  file  in  src/sub  dir  rm  src  sub  dir  not  renamed  into  dest  dir  test  rename  with  non  empty  sub  dir  sub  not created in src dir  contracttestutils  testrenamewithnonemptysubdirposix  renametestdir  dest  handleemptydstdirectoryonwindows  fs  assertpathdoesnotexist  path  writetextfile  finaldir  not created in src/sub dir   accept only posix rename behavior in this test  not deleted  assertpathexists  sub/subfile.txt  pathtofile  subfile.txt  getfilesystem  this is the file in src dir  source.txt  rlfs  not renamed into dest/sub dir  mkdirs  src1  srcdir  this is the file in src/sub dir  rm  srcsubdir  not renamed into dest dir  testrenamewithnonemptysubdir
__label__flaky row_1  row_2  check  value  pb  add  row  put  table  path  bytes  yield  get  client  value_1  value_3  value_2  get  code  make  sure  the  fake  row  was  not  actually  created  value_4  add  cell  to  bytes  assert  equals  cell  set  model  check  that  all  of  the  values  were  created  /  thread  delete  row  mimetype_  protobuf  row  model  column_2  column_1  response  create  protobuf  output  /fakerow  deliberate  nonexistent  row  test  multi  cell  get  put  pb  row_1  row_2  checkvaluepb  addrow  put  table  path  bytes  yield  get  client  value_1  value_3  value_2  getcode   make sure the fake row was not actually created  value_4  addcell  tobytes  assertequals  cellsetmodel   check that all of the values were created  /  thread  deleterow  mimetype_protobuf  rowmodel  column_2  column_1  response  createprotobufoutput  /fakerow   deliberate nonexistent row  testmulticellgetputpb
__label__nflaky has  field  violation  get  field  violations  invoke  assert  equals  validation  should  be  applied  in  correct  order  pre  fail  validation.required.violation  param1  required  int  size  get  message  key  assert  true  get  context  create  verify  mock  controller  validation  hasfieldviolation  getfieldviolations  invoke  assertequals  validationshouldbeappliedincorrectorderprefail  validation.required.violation  param1  requiredint  size  getmessagekey  asserttrue  get  context  create  verify  mockcontroller  validation
__label__flaky uri:oozie:workflow:0.3  uri:oozie:coordinator:0.3  uri:oozie:bundle:0.3  uri:oozie:workflow:0.4  uri:oozie:bundle:0.2  uri:oozie:workflow:0.5  uri:oozie:coordinator:0.5  uri:oozie:bundle:0.1  assert  false  uri:oozie:coordinator:0.4  foo  supports  parameters  assert  true  parameter  verifier  uri:oozie:foo:0.4  test  supports  parameters  uri:oozie:workflow:0.3  uri:oozie:coordinator:0.3  uri:oozie:bundle:0.3  uri:oozie:workflow:0.4  uri:oozie:bundle:0.2  uri:oozie:workflow:0.5  uri:oozie:coordinator:0.5  uri:oozie:bundle:0.1  assertfalse  uri:oozie:coordinator:0.4  foo  supportsparameters  asserttrue  parameterverifier  uri:oozie:foo:0.4  testsupportsparameters
__label__nflaky trash  shell  get  home  directory  .  trash/  current  test  trash  fs  view  fs  target  conf  test  trash  file  system  test  helper  get  test  root  path  trashshell  gethomedirectory  .trash/current  testtrash  fsview  fstarget  conf  testtrash  filesystemtesthelper  gettestrootpath
__label__flaky conn  set  request  method  is_  security_  enabled  test  instrumentation  assert  true  json  content-type  /v1/admin/*  collections  run  test  json  tags  rest  constants  open  connection  contains  key  http  servlet  response  assert  equals  parse  get  input  stream  url  json  value  call  get  header  field  get  get  response  code  create  url  starts  with  conn  setrequestmethod  is_security_enabled  testinstrumentation  asserttrue  json  content-type  /v1/admin/*  collections  runtest  jsontags  restconstants  openconnection  containskey  httpservletresponse  assertequals  parse  getinputstream  url  jsonvalue  call  getheaderfield  get  getresponsecode  createurl  startswith
__label__nflaky max  time  should  fail  retry  up  to  maximum  time  with  fixed  sleep  real  policy  retry  decision  construct  reason  string  times  should  retry  other  exception  other  than  unreliable  exception  should  also  get  time  unit  create  verify  retry  up  to  maximum  time  with  fixed  sleep  unreliable  impl  policy  any  boolean  fails  once  then  succeeds  fails  ten  times  then  succeeds  setup  mock  policy  assert  equals  failed.  test  retry  up  to  maximum  time  with  fixed  sleep  retry  proxy  always  succeeds  any  any  int  fail  expected  unreliable  mock  caught  retry  action  maxtime  should fail  retryuptomaximumtimewithfixedsleep  realpolicy  retrydecision  constructreasonstring  times  shouldretry  other exception other than unreliableexception should also get   timeunit  create  verify  retryuptomaximumtimewithfixedsleep  unreliableimpl  policy  anyboolean  failsoncethensucceeds  failstentimesthensucceeds  setupmockpolicy  assertequals  failed.  testretryuptomaximumtimewithfixedsleep  retryproxy  alwayssucceeds  any  anyint  fail   expected  unreliable  mock  caughtretryaction
__label__flaky <app-path>  <configuration>  get  job  info  <name>a</name>  </property>  get  actions  get  id  get  external  id  get  status  fs  app1  <value>  a</value>  sub  workflow  action  executor  proto  conf  create  base  workflow  get  workflow  client  w  get  create  action  </app-path>  workflow.xml  end  workflow  job  write  close  get  base  proto  conf  wait  for  workflow  <sub-workflow  xmlns=\'uri:oozie:workflow:0.1\'>  oozie  client  <property>  start  sub  workflow  app  path  sub  workflow  assert  equals  get  file  system  job_  timeout  check  set  conf  </configuration>  workflow  action  </sub-workflow>  test  sub  workflow  start  writer  evaluate  get  parent  id  get  fs  test  case  dir        <app-path>        <configuration>  getjobinfo            <name>a</name>          </property>  getactions  getid  getexternalid  getstatus  fs  app1            <value>a</value>  subworkflowactionexecutor  protoconf  createbaseworkflow  getworkflowclient  w  get  create  action  </app-path>  workflow.xml  end  workflowjob  write  close  getbaseprotoconf  waitfor  workflow  <sub-workflow xmlns=\'uri:oozie:workflow:0.1\'>  oozieclient          <property>  start  subworkflowapppath  subworkflow  assertequals  getfilesystem  job_timeout  check  setconf        </configuration>  workflowaction  </sub-workflow>  testsubworkflowstart  writer  evaluate  getparentid  getfstestcasedir
__label__nflaky fail  assert  ae  java  assert  does  not  work.  log  good!  java  assert  is  on.  test  java  assert  the  assertion  error  is  expected.  info  fail  assert  ae  java assert does not work.  log  good! java assert is on.  testjavaassert  the assertionerror is expected.  info
__label__flaky <execution>  lifo</execution>  </controls>  <datasets>  add  record  to  bundle  action  table  conf  </input-events>  app  path  sc  </property></configuration>  </workflow>  </action>  </coordinator-app>  write  to  file  app  xml  <property>  <name>input  b</name>  <value>${coord:data  out(\'  local_  a\')}</value>  file://  get  test  case  dir  unit_  testing  <output-events>  <data-out  name=\""  local_  a\""  dataset=\""local_a\"">  exception  expected  because  namespace  is  too  old  when  submit  coordinator  through  bundle!  job  timezone=\""  utc\"">  <uri-template>file:///tmp/coord/workflows/${  year}/${  day}</uri-template>  </dataset>  coordinator.xml  xmlns=\""uri:oozie:coordinator:0.1\"">  <controls>  <concurrency>2</concurrency>  set  <configuration>  <property>  <name>input  a</name>  <value>${coord:data  in(\'  a\')}</value>  </property>  <dataset  name=\""local_a\""  frequency=\""${coord:days(7)}\""  initial-instance=\""2009-02-01  t01:00  z\""  call  <coordinator-app  name=\""  name\""  frequency=\""${coord:days(1)}\""  start=\""2009-02-01  t01:00  z\""  end=\""2009-02-03  t23:59  z\""  timezone=\""  utc\""  oozie  client  fail  get  test  user  </datasets>  <input-events>  <instance>${coord:current(-1)}</instance>  </data-out>  </output-events>  <action>  <workflow>  <app-path>hdfs:///tmp/workflows/</app-path>  <data-in  name=\""  a\""  dataset=\""a\"">  <instance>${coord:latest(0)}</instance>  </data-in>  coord-  name  oozie-  b  <dataset  name=\""a\""  frequency=\""${coord:days(7)}\""  initial-instance=\""2009-02-01  t01:00  z\""  file  test  basic  submit  with  wrong  namespace  <execution>lifo</execution> </controls> <datasets>   addrecordtobundleactiontable  conf  </input-events>   apppath  sc  </property></configuration> </workflow> </action> </coordinator-app>  writetofile  appxml  <property> <name>inputb</name> <value>${coord:dataout(\'local_a\')}</value>   file://  gettestcasedir  unit_testing  <output-events> <data-out name=\""local_a\"" dataset=\""local_a\"">   exception expected because namespace is too old when submit coordinator through bundle!  job  timezone=\""utc\""> <uri-template>file:///tmp/coord/workflows/${year}/${day}</uri-template> </dataset>   coordinator.xml  xmlns=\""uri:oozie:coordinator:0.1\""> <controls> <concurrency>2</concurrency>   set  <configuration> <property> <name>inputa</name> <value>${coord:datain(\'a\')}</value> </property>   <dataset name=\""local_a\"" frequency=\""${coord:days(7)}\"" initial-instance=\""2009-02-01t01:00z\""   call  <coordinator-app name=\""name\"" frequency=\""${coord:days(1)}\"" start=\""2009-02-01t01:00z\"" end=\""2009-02-03t23:59z\"" timezone=\""utc\""   oozieclient  fail  gettestuser  </datasets> <input-events>   <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>   <data-in name=\""a\"" dataset=\""a\""> <instance>${coord:latest(0)}</instance> </data-in>    coord-name  oozie-b  <dataset name=\""a\"" frequency=\""${coord:days(7)}\"" initial-instance=\""2009-02-01t01:00z\""   file  testbasicsubmitwithwrongnamespace
__label__nflaky cancel  conf  time  file  system  not  removed  from  delegation  token  renewer  when  fs  get  renew  queue  length  sleep  do  answer  get  renew  token  file  system  not  added  to  delegation  token  renewer  now  verify  at  most  myservice  get  conf  do  return  renewer  remove  renew  action  assert  equals  eq  any  add  renew  action  get  service  token  thread  never  set  delegation  token  answer  test  add  remove  renew  action  service  mock  at  least  renew  get  delegation  token  renew_  cycle  cancel  conf  time  filesystem not removed from delegationtokenrenewer  when  fs  getrenewqueuelength  sleep  doanswer  getrenewtoken  filesystem not added to delegationtokenrenewer  now  verify  atmost  myservice  getconf  doreturn  renewer  removerenewaction  assertequals  eq  any  addrenewaction  getservice  token  thread  never  setdelegationtoken  answer  testaddremoverenewaction  service  mock  atleast  renew  getdelegationtoken  renew_cycle
__label__flaky exec_  order  callable2  callable3  callables  callable1  c  as  list  queueservice  queue  uniqueness  with  same  key  services  assert  true  get  arrays  test  queue  uniqueness  with  same  key  evaluate  wait  for  queue  exec_order  callable2  callable3  callables  callable1  c  aslist  queueservice  queueuniquenesswithsamekey  services  asserttrue  get  arrays  testqueueuniquenesswithsamekey  evaluate  waitfor  queue
__label__nflaky path  request  add  request.  test  method  nulls  )  put  status  testing  framework  framework  headers  request  query  run  tests  content_  type  response  method  add  test  response  body  response  path  request   add request.  test  method  nulls   )  put  status  testingframework  framework  headers  request  query  runtests  content_type  response  method  addtest  response  body   response
__label__flaky aee  oozie.action.mapreduce.uber.jar.enable  serv  get  conf  e  action  executor  exception  get  message  assert  equals  mr003  test  map  reduce  with  uber  jar  disabled  services  contains  original  uber  jar  disabled  get  error  code  assert  true  this  test  is  excluded  by  default)  get  _test  map  reduce  with  uber  jar  get  boolean  oozie.mapreduce.uber.jar  get  error  type  set  boolean  aee  oozie.action.mapreduce.uber.jar.enable  serv  getconf  e  actionexecutorexception  getmessage  assertequals  mr003  testmapreducewithuberjardisabled  services  contains  originaluberjardisabled  geterrorcode  asserttrue   this test is excluded by default)  get  _testmapreducewithuberjar  getboolean  oozie.mapreduce.uber.jar  geterrortype  setboolean
__label__nflaky add  a  (  h  )  token  assert  equals  tokenize  (x  witness  x)  test  escaped  paranteheses  \%a(x\\)  tl  \%a\\(x)  (\%h\\)  \\(\%h\\)  add  a  (  h  )  token  assertequals  tokenize  (x  witness  x)  testescapedparanteheses  \%a(x\\)  tl  \%a\\(x)  (\%h\\)  \\(\%h\\)
__label__flaky read  fields  set  _test  get  bean2  to  byte  array  dos  test  serialization  baos  write  close  bean  readfields  set  _testget  bean2  tobytearray  dos  testserialization  baos  write  close  bean
__label__nflaky input  node  lone  colon  should  read  like  any  other  character  transform  node  to  string  transformer  property  container0  make  node  assert  equals  java:comp/env/jdbc/datasource  input  node  lonecolonshouldreadlikeanyothercharacter  transform  nodetostringtransformer  propertycontainer0  makenode  assertequals  java:comp/env/jdbc/datasource
__label__flaky cluster  test2.dat  test1.dat  get  modification  time  conf  create  file  wait  active  creating  testdir2  get  file  status  mdir2  mdir1  info  newfile  localhost  deleting  testdir2/testnew.dat.  mtime1  datanode  report  get  file  system  moving  block  size  creating  testdir1  and  testdir1/test1.dat.  file  size  num  data  nodes  mkdirs  file  sys  get  name  node  port  testnew.dat  print  datanode  report  shutdown  seed  delete  system  creating  testdir1/test2.dat.  test  mod  time  testdir2/  assert  true  client  num  datanodes  addr  close  cleanup  file  dfs  test  util  stat  e  replicas  assert  equals  dir2  dir1  build  to  rename  make  qualified  file2  testdir1  number  of  datanodes  file1  datanode  report  type  cluster  test2.dat  test1.dat  getmodificationtime  conf  createfile  waitactive  creating testdir2   getfilestatus  mdir2  mdir1  info  newfile  localhost     deleting testdir2/testnew.dat.  mtime1  datanodereport  getfilesystem  moving   blocksize  creating testdir1 and testdir1/test1.dat.  filesize  numdatanodes  mkdirs  filesys  getnamenodeport  testnew.dat  printdatanodereport  shutdown  seed  delete  system  creating testdir1/test2.dat.  testmodtime  testdir2/  asserttrue  client  numdatanodes  addr  close  cleanupfile  dfstestutil  stat  e  replicas  assertequals  dir2  dir1  build   to   rename  makequalified  file2  testdir1  number of datanodes   file1  datanodereporttype
__label__nflaky set  user  info  result  http://stuff@localhost:80/stuff?param=stuff#fragment  http://localhost:80/stuff?param=stuff#fragment  assert  build  test  mutation  remove  user  info  assert  equals  uri  setuserinfo  result  http://stuff@localhost:80/stuff?param=stuff#fragment  http://localhost:80/stuff?param=stuff#fragment  assert  build  testmutationremoveuserinfo  assertequals  uri
__label__flaky set  name  a  b  get  name  get  property  c  get  properties  assert  equals  system  remove  testcase  tear  down  test  unset  sys  property  assert  null  set  property  set  up  sys_  prop  test  sys  prop  setting  test  set  sys  property  setname  a  b  getname  getproperty  c  getproperties  assertequals  system  remove  testcase  teardown  testunsetsysproperty  assertnull  setproperty  setup  sys_prop  testsyspropsetting  testsetsysproperty
__label__nflaky test  future  get  with  timeout  server  generic  test  utils.set  log  level(  async  get  future.  log   level.  all);  assert  return  values  start  conf  run  get  connect  address  caller  net  utils  stop  client  time  unit  addr  testfuturegetwithtimeout  server   generictestutils.setloglevel(asyncgetfuture.log  level.all);  assertreturnvalues  start  conf  run  getconnectaddress  caller  netutils  stop  client  timeunit  addr
__label__flaky init  ae  destroy  wildcard  indicates  all  schemes  will  be  allowed.  this  should  pass  *  validate  path  hadoop  accessor  service  anyfs://bla  services  fail  get  set  system  property  test  file  scheme  wildcard  init  ae  destroy  wildcard indicates all schemes will be allowed. this should pass  *  validatepath  hadoopaccessorservice  anyfs://bla  services  fail  get  setsystemproperty  testfileschemewildcard
__label__nflaky write  records  get  value  length  reader  test  failure  read  value  many  times  vlen  skip  conf  vbuf  assert  equals  value  create  scanner  fs  cannot  get  the  value  mlutiple  times.  path  entry  get  value  fail  assert  get  len  get  file  status  scanner  buf_  size  close  open  writerecords  getvaluelength  reader  testfailurereadvaluemanytimes  vlen  skip  conf  vbuf  assertequals  value  createscanner  fs  cannot get the value mlutiple times.  path  entry  getvalue  fail  assert  getlen  getfilestatus  scanner  buf_size  close  open
__label__flaky container  conf  get  id  get  status  when  system  coord  assert  get  servlet  url  run  conf  assert  true  coordinator  action  end  set  then  return  start  command  test  coord  notification  timeout  call  oozie  client  1  get  run  conf  mockito  to  xml  string  current  time  millis  mock  /hang/*  container  conf  getid  getstatus  when  system  coord  assert  getservleturl  runconf  asserttrue  coordinatoraction  end  set  thenreturn  start  command  testcoordnotificationtimeout  call  oozieclient  1  getrunconf  mockito  toxmlstring  currenttimemillis  mock  /hang/*
__label__nflaky server  call  started  conf  run  when  mock  factory  sleep  do  answer  min_  sleep_  time  create  socket  called  get  client  addr  wait  for  set  random  start  generic  test  utils  track  how  many  times  we  retried  to  set  up  the  connection  assert  equals  next  long  get  connect  address  thread  call  net  utils  create  socket  stop()  should  stop  the  client  immediately  without  any  more  retries  answer  stop  mockito  start  server  mock  add  and  get  fake  call  a  random  function  asynchronously  so  that  we  can  call  stop()  test  setup  connection  should  not  block  shutdown  server  callstarted  conf  run  when  mockfactory  sleep  doanswer  min_sleep_time  createsocketcalled  get  client  addr  waitfor  set  random  start  generictestutils   track how many times we retried to set up the connection  assertequals  nextlong  getconnectaddress  thread  call  netutils  createsocket   stop() should stop the client immediately without any more retries  answer  stop  mockito   start server  mock  addandget  fake   call a random function asynchronously so that we can call stop()  testsetupconnectionshouldnotblockshutdown
__label__flaky <execution>  lifo</execution>  </controls>  <datasets>  check  coord  jobs  xmlns=\""uri:oozie:coordinator:0.2\"">  <controls>  <timeout>10</timeout>  <concurrency>2</concurrency>  conf  </input-events>  app  path  substring  sc  </property></configuration>  </workflow>  </action>  </coordinator-app>  write  to  file  app  xml  timezone=\""  utc\"">  <uri-template>file:///tmp/coord/workflows/${  year}/${  day}</uri-template>  <property>  <name>input  b</name>  <value>${coord:data  out(\'  local_  a\')}</value>  file://  get  test  case  dir  unit_  testing  <done-flag>consume_me</done-flag>  </dataset>  <output-events>  <data-out  name=\""  local_  a\""  dataset=\""local_a\"">  timezone=\""  utc\"">  <uri-template>file:///tmp/coord/workflows/${  year}/${  day}</uri-template>  </dataset>  timezone=\""  utc\"">  <uri-template>file:///tmp/coord/workflowsb/${  year}/${  day}</uri-template>  coordinator.xml  set  <configuration>  <property>  <name>input  a</name>  <value>${coord:data  in(\'  a\')}</value>  </property>  length  <dataset  name=\""local_a\""  frequency=\""${coord:days(7)}\""  initial-instance=\""2009-02-01  t01:00  z\""  my_  done_  flag  assert  equals  <done-flag>${  my_  done_  flag}</done-flag>  </dataset>  <data-in  name=\""  b\""  dataset=\""local_b\"">  <instance>${coord:latest(0)}</instance>  </data-in>  call  <coordinator-app  name=\""  name\""  frequency=\""${coord:days(1)}\""  start=\""2009-02-01  t01:00  z\""  end=\""2009-02-03  t23:59  z\""  timezone=\""  utc\""  oozie  client  job  id  get  test  user  <dataset  name=\""local_b\""  frequency=\""${coord:days(7)}\""  initial-instance=\""2009-02-01  t01:00  z\""  </datasets>  <input-events>  <instance>${coord:current(-1)}</instance>  </data-out>  </output-events>  <action>  <workflow>  <app-path>hdfs:///tmp/workflows/</app-path>  test  submit  with  done  flag  -  c  <data-in  name=\""  a\""  dataset=\""a\"">  <instance>${coord:latest(0)}</instance>  </data-in>  <dataset  name=\""a\""  frequency=\""${coord:days(7)}\""  initial-instance=\""2009-02-01  t01:00  z\""  complete  file  <execution>lifo</execution> </controls> <datasets>   checkcoordjobs  xmlns=\""uri:oozie:coordinator:0.2\""> <controls> <timeout>10</timeout> <concurrency>2</concurrency>   conf  </input-events>   apppath  substring  sc  </property></configuration> </workflow> </action> </coordinator-app>  writetofile  appxml  timezone=\""utc\""> <uri-template>file:///tmp/coord/workflows/${year}/${day}</uri-template>   <property> <name>inputb</name> <value>${coord:dataout(\'local_a\')}</value>   file://  gettestcasedir  unit_testing  <done-flag>consume_me</done-flag> </dataset>  <output-events> <data-out name=\""local_a\"" dataset=\""local_a\"">   timezone=\""utc\""> <uri-template>file:///tmp/coord/workflows/${year}/${day}</uri-template> </dataset>   timezone=\""utc\""> <uri-template>file:///tmp/coord/workflowsb/${year}/${day}</uri-template>   coordinator.xml  set  <configuration> <property> <name>inputa</name> <value>${coord:datain(\'a\')}</value> </property>   length  <dataset name=\""local_a\"" frequency=\""${coord:days(7)}\"" initial-instance=\""2009-02-01t01:00z\""   my_done_flag  assertequals  <done-flag>${my_done_flag}</done-flag> </dataset>  <data-in name=\""b\"" dataset=\""local_b\""> <instance>${coord:latest(0)}</instance> </data-in>    call  <coordinator-app name=\""name\"" frequency=\""${coord:days(1)}\"" start=\""2009-02-01t01:00z\"" end=\""2009-02-03t23:59z\"" timezone=\""utc\""   oozieclient  jobid  gettestuser  <dataset name=\""local_b\"" frequency=\""${coord:days(7)}\"" initial-instance=\""2009-02-01t01:00z\""   </datasets> <input-events>   <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>   testsubmitwithdoneflag  -c  <data-in name=\""a\"" dataset=\""a\""> <instance>${coord:latest(0)}</instance> </data-in>    <dataset name=\""a\"" frequency=\""${coord:days(7)}\"" initial-instance=\""2009-02-01t01:00z\""   complete  file
__label__nflaky get  dynamic  entry  assert  header  equals  no-cache  dynamic  table  custom-value  get  current  size  assert  :scheme  get  test  request  decoding  without  huffman  rfc7541  examples  https  cache-control  :authority  custom-key  standard  charsets  create  byte  buffer  assert  equals  headers2  decoder  headers3  headers1  www.example.com  /  size  :method  get  src1  decode  headers  http  :path  src3  src2  /index.html  dynamic  length  getdynamicentry  assertheaderequals  no-cache  dynamictable  custom-value  getcurrentsize  assert  :scheme  get  testrequestdecodingwithouthuffmanrfc7541examples  https  cache-control  :authority  custom-key  standardcharsets  createbytebuffer  assertequals  headers2  decoder  headers3  headers1  www.example.com  /  size  :method  get  src1  decodeheaders  http  :path  src3  src2  /index.html  dynamiclength
__label__flaky create  stage  poll  system  counting  4  observer  counting  3  counting  2  counting  1  start  countdown  assert  true  assert  not  null  get  time  unit  join  timer  test  get  reference  counting  5  create  client  counting  start  some  timer  must  have  elapsed!  1  get  right  assert  null  ensures  no  new  messages  are  received  current  time  millis  i  actor  stage1  frontend  chat  room  createstage  poll  system  counting 4  observer  counting 3  counting 2  counting 1  startcountdown  asserttrue  assertnotnull  get  timeunit  join  timertest  getreference  counting 5  createclient  counting  start   some timer must have elapsed!  1  getright  assertnull   ensures no new messages are received  currenttimemillis  iactor  stage1  frontend  chatroom
__label__nflaky test  file01  get  path  data  testfile01  add  contents  -  s  ls  format  line  mtime  out  testfile03  set  file  length  in  different  order  to  file  names  options  compute  line  format  in  order  testfile02  process  options  verify  testfile05  test  file06  testfile04  test  file04  test  file05  testfile06  test  file02  test  file03  add  found  6  items  path  data  line  format  check  length  order  (-  s  option)  length  set  is  dir  process  arguments  test  dir  test  directory  set  length  verify  no  more  interactions  test  file  mock  process  path  dir  order  length    testfile01  getpathdata  testfile01  addcontents  -s  ls  formatlinemtime  out  testfile03   set file length in different order to file names  options  computelineformat  inorder  testfile02  processoptions  verify  testfile05  testfile06  testfile04  testfile04  testfile05  testfile06  testfile02  testfile03  add  found 6 items  pathdata  lineformat   check length order (-s option)  length  setisdir  processarguments  testdir  testdirectory  setlength  verifynomoreinteractions  testfile  mock  processpathdirorderlength
__label__flaky allow  assert  false  generate  id  save  principals  get  user  manager  remove  create  glob  restriction  group2_  path  get  principal  ac  mgr  get  test  group  assert  true  /*  add  has  privileges  create  group  deny  read  privs  group3  group2  privileges  from  name  modify  test  glob  restriction3  child  n  path  group3_  privilege  superuser  allow  assertfalse  generateid  save  principals  getusermanager  remove  createglobrestriction  group2_  path  getprincipal  acmgr  gettestgroup  asserttrue  /*  add  hasprivileges  creategroup  deny  readprivs  group3  group2  privilegesfromname  modify  testglobrestriction3  childnpath  group3_  privilege  superuser
__label__nflaky regex  to  regex  context  fnp  foo-\\d{4}\\.\\d{2}\\.\\d{2}-\\d+.txt  as  regex  assert  equals  foo-\\d{4}\\.\\d{2}\\.\\d{2}  t-\\d+.txt  foo-\%d{yyyy.  mm.dd}-\%i.txt  foo-\%d{yyyy.  mm.dd\'  t\'}-\%i.txt  regex  toregex  context  fnp  foo-\\d{4}\\.\\d{2}\\.\\d{2}-\\d+.txt  asregex  assertequals  foo-\\d{4}\\.\\d{2}\\.\\d{2}t-\\d+.txt  foo-\%d{yyyy.mm.dd}-\%i.txt  foo-\%d{yyyy.mm.dd\'t\'}-\%i.txt
__label__flaky ${coord:table  in(\'  abcd\')}  init  -ve  test  coord  el  functions  set  variable  test  table  ph1  +ve  test  assert  equals  ${coord:table  out(\'  abcd\')}  data-in  coord-job-submit-data  *  table  out  fail  should  throw  exception  because  data-in  abcd  is  not  defiend  ${coord:table  in(\'  abc\')}  *  table  in  eval  eval  and  wrap  should  throw  exception  because  data-out  abcd  is  not  defiend  expr  oozie.dataname.  abc  ${coord:table  out(\'  abc\')}  data-out  ${coord:tablein(\'abcd\')}  init   -ve test  coordelfunctions  setvariable  testtableph1   +ve test  assertequals  ${coord:tableout(\'abcd\')}  data-in  coord-job-submit-data             * tableout             fail  should throw exception because data-in abcd is not defiend  ${coord:tablein(\'abc\')}             * tablein             eval  evalandwrap  should throw exception because data-out abcd is not defiend  expr  oozie.dataname.abc  ${coord:tableout(\'abc\')}  data-out
__label__nflaky get  class  test  auth  local  jceks  zk  auths  credential  provider  factory  zk  auth  info  conf  delete  get  bytes  assert  array  equals  local  jceks  file  get  zk  auth  infos  assert  true  get  a_scheme  set  get  scheme  get  auth  common  configuration  keys  get  absolute  path  local  jceks  uri  create  temp  file  assert  equals  deleted  size  populate  local  jceks  test  file  .test  auth  local  jceks-  .localjceks  get  simple  name  security  util  localjceks://file/  a_password  file  getclass  testauthlocaljceks  zkauths  credentialproviderfactory  zkauthinfo  conf  delete  getbytes  assertarrayequals  localjceksfile  getzkauthinfos  asserttrue  get  a_scheme  set  getscheme  getauth  commonconfigurationkeys  getabsolutepath  localjceksuri  createtempfile  assertequals  deleted  size  populatelocaljcekstestfile  .testauthlocaljceks-  .localjceks  getsimplename  securityutil  localjceks://file/  a_password  file
__label__flaky cluster  write  to  file  conf  does  not  exist.  fs  system  dfsclient  create  file  simulated  storage  testing  adbornal  client  death.  assert  true  test  dfs  client  death  this  should  close  all  existing  file.  write  file  close  /clienttest.dat  reopen  file  system  and  verify  that  file  exists.  get  file  system  created  file  clienttest.dat  stm  append  test  util  dfs  build  create  hdfs  with  different  username  exists  simulated  fs  dataset  file1  shutdown  set  boolean  cluster   write to file  conf   does not exist.  fs  system  dfsclient  createfile  simulatedstorage  testing adbornal client death.  asserttrue  testdfsclientdeath   this should close all existing file.  writefile  close     /clienttest.dat   reopen file system and verify that file exists.  getfilesystem  created file clienttest.dat  stm  appendtestutil  dfs  build  createhdfswithdifferentusername  exists  simulatedfsdataset  file1  shutdown  setboolean
__label__nflaky test  resolver  unqualified  .a.b.  1.1.1.1  verify  resolve  host  verify  inet  address  host.a.b  addr  testresolverunqualified  .a.b.  1.1.1.1  verifyresolve  host  verifyinetaddress  host.a.b  addr
__label__flaky cluster  foofs  create  cluster  conf  test  fs  close  system  create  file  get  bytes  wait  active  out  fpath  create  a  new  file.  write  close  test  fs  close  successful  f  get  file  system  test  file  creation  dir  test  closing  file  system  before  all  file  handles  are  closed.  test  file  system  close  start  something  dfs  close  file  system  without  closing  file  build  num  data  nodes  datanode_  num  shutdown  cluster  foofs   create cluster  conf  testfsclose  system  createfile  getbytes  waitactive  out  fpath   create a new file.  write  close  testfsclose successful  f  getfilesystem  testfilecreation  dir   test closing file system before all file handles are closed.  test file system close start  something  dfs   close file system without closing file  build  numdatanodes  datanode_num  shutdown
__label__nflaky new  mod  time  test  set  times  support  millisecond  timestamps  get  modification  time  get  access  time  check  times  status  check  we\'re  actually  changing  something  path  assert  true  test_  root_  dir  new  acc  time  file  sys  get  file  status  set  times  write  file  set-times  status  newmodtime  testsettimes   support millisecond timestamps  getmodificationtime  getaccesstime  checktimesstatus  check we\'re actually changing something  path  asserttrue  test_root_dir  newacctime  filesys  getfilestatus  settimes  writefile  set-times  status
__label__flaky init  coord  el  functions  ${coord:hours(1)}  assert  equals  timeunit  get  variable  eval  eval  and  wrap  ${coord:hours(coord:hours(1))}  3600  time  unit  expr  60  coord-job-submit-freq  test  hours  init  coordelfunctions  ${coord:hours(1)}  assertequals  timeunit  getvariable  eval  evalandwrap  ${coord:hours(coord:hours(1))}  3600  timeunit  expr  60  coord-job-submit-freq  testhours
__label__nflaky humanoids  drwho  get  group  names  barbara@  example.  com  acl  drwho  humanoids  drwho@  example.  com  humanoids  assert  user  allowed  drwho  ian@  example.  com  assert  user  not  allowed  teachers  ian  verify  barbara  user  group  information  create  user  for  testing  aliens  drwho ian  aliens teachers  never  susan  susan@  example.  com  is  user  allowed  test  is  user  allowed  timelord  spy  user  humans  spy     humanoids  drwho  getgroupnames  barbara@example.com  acl  drwho humanoids  drwho@example.com  humanoids  assertuserallowed  drwho   ian@example.com  assertusernotallowed  teachers  ian  verify  barbara  usergroupinformation  createuserfortesting  aliens  drwho ian aliens teachers  never  susan  susan@example.com  isuserallowed  testisuserallowed  timelord  spyuser  humans  spy
__label__flaky date  script  executor  session  given  update  simple  eq  consistencylist  as  list  consistency  list_  set  contains  exactly  should_dsl_update_list_set  when  get  list  of  where  id  row  table  execute  script  template  random  utils  manager  one  next  long  assert  that  two  execute  simple  entity/insert_single_row.cql  immutable  map  select  consistencylist  from  simple  where  id  =  then  long  build  date  key  from  base  table  consistency  list  dsl  three  date  scriptexecutor  session   given  update  simple  eq  consistencylist  aslist  consistencylist_set  containsexactly  should_dsl_update_list_set   when  getlist  of  where  id  row  table  executescripttemplate  randomutils  manager  one  nextlong  assertthat  two  execute  simpleentity/insert_single_row.cql  immutablemap  select consistencylist from simple where id =    then  long  builddatekey  frombasetable  consistencylist  dsl  three
__label__nflaky ldap  server  is  down   no  groups  should  be  retrieved  any  string  any  when  as  list  this  mocks  the  case  where  ldap  server  is  down   and  always  throws  communication  exception  search  do  test  get  groups  connection  is  closed  arrays  get  context  test  get  groups  with  ldap  down  then  throw   ldap server is down  no groups should be retrieved  anystring  any  when  aslist   this mocks the case where ldap server is down  and always throws communicationexception  search  dotestgetgroups  connection is closed  arrays  getcontext  testgetgroupswithldapdown  thenthrow
__label__flaky cluster  write  timeout  conf  set  a  very  short  write  timeout  for  datanode   so  that  tests  runs  fast.  write  data  fs  wait  active  out  sleep  read  fully  milliseconds.  create  test  write  timeout  at  data  node  set  a  smaller  block  size  close  enough  to  empty  tcp  buffers.  first  read  a  few  bytes  dfs  config  keys  write  a  2  block  file.  in  file  path  /test  write  timeout  at  data  node  get  file  system  io.file.buffer.size  block  size  set  int  thread  set  a  small  buffer  size  buf  io  utils  build  force  write  timeout  at  the  datanode.  num  data  nodes  successfully  read  with  write  timeout  on  datanodes.  read  enough  to  empty  out  socket  buffers.  now  read  few  more  chunks  of  data  by  sleeping  in  between  :  shutdown  open  buffer  size  cluster  writetimeout  conf   set a very short write timeout for datanode  so that tests runs fast.  writedata  fs  waitactive  out  sleep  readfully   milliseconds.  create  testwritetimeoutatdatanode   set a smaller block size  close   enough to empty tcp buffers.   first read a few bytes  dfsconfigkeys   write a 2 block file.  in  filepath  /testwritetimeoutatdatanode  getfilesystem  io.file.buffer.size  blocksize  setint  thread   set a small buffer size  buf  ioutils  build   force write timeout at the datanode.  numdatanodes   successfully read with write timeout on datanodes.   read enough to empty out socket buffers.   now read few more chunks of data by sleeping in between :  shutdown  open  buffersize
__label__nflaky get  short  user  name  somerandomuser  then  return  get  real  user  when  dummy  user  fakeuser  test.user  2.2.2.2  provider  proxy  user  user  group  information  user  authorize  real  user  ugi  test  authorization  success  getshortusername  somerandomuser  thenreturn  getrealuser  when  dummyuser  fakeuser  test.user  2.2.2.2  provider  proxyuser  usergroupinformation  user  authorize  realuserugi  testauthorizationsuccess
__label__flaky cs1  cluster  get  located  blocks  get  name  cs2  conf  fs  create  file  wait  active  assert  true  test  get  file  checksum  get  stop  data  node  dfs  client  dfs  test  util  locatedblocks  stop  the  first  datanode  f  get  checksum  assert  equals  get  file  system  get  name  node  rpc  get  file  checksum  p  build  num  data  nodes  create  a  file  long  call  get  block  locations  get  locations  shutdown  first  /test  get  file  checksum  get  checksum  again  cs1  cluster  getlocatedblocks  getname  cs2  conf  fs  createfile  waitactive  asserttrue  testgetfilechecksum  get  stopdatanode  dfsclient  dfstestutil  locatedblocks   stop the first datanode  f   get checksum  assertequals  getfilesystem  getnamenoderpc  getfilechecksum  p  build  numdatanodes   create a file  long  callgetblocklocations  getlocations  shutdown  first  /testgetfilechecksum   get checksum again
__label__nflaky fill  in  jar  file  assert  false  rules  map  delete  url  tc  as  url  make  random  jar  file  buzz.xml  jar  file  assert  true  jar  entry  do  configure  context  set  context  deleting  an  open  file  fails  lbcore105  exists  fillinjarfile  assertfalse  rulesmap  delete  url  tc  asurl  makerandomjarfile  buzz.xml  jarfile  asserttrue  jarentry  doconfigure  context  setcontext   deleting an open file fails  lbcore105  exists
__label__flaky allow  snapshot  before  sub1  assert  false  before  a  directory  is  snapshottable  after  a  directory  is  snapshottable  path  fsdir  assert  assert  true  disallow  snapshot  test  allow  snapshot  hdfs  to  string  after  path  str  get  i  node  allowsnapshot  before  sub1  assertfalse   before a directory is snapshottable   after a directory is snapshottable  path  fsdir  assert  asserttrue  disallowsnapshot  testallowsnapshot  hdfs  tostring  after  pathstr  getinode
__label__nflaky a  b  c  d  set  included  protocols  get  enabled  protocols  a   b     c   d  configuration  set  supported  protocols  test  set  included  protocols  configure  assert  true  equals  arrays  configurable  a  b  c  d  setincludedprotocols  getenabledprotocols  a b  c  d  configuration  setsupportedprotocols  testsetincludedprotocols  configure  asserttrue  equals  arrays  configurable
__label__flaky a  http://  get  action  id  replace  create  call  back  url  assert  equals  get  external  status  id=a  test  callbacks  cs  status=@  status  services  contains  assert  true  assert  not  null  get  callback  ok  @  status  a  http://  getactionid  replace  createcallbackurl  assertequals  getexternalstatus  id=a  testcallbacks  cs  status=@status  services  contains  asserttrue  assertnotnull  get  callback  ok  @status
__label__nflaky 20080504  t123456  z  do  test  test  geo  begin:  vcalendar  begin:  vevent  geo:-12.345;-45.678  dtstart:20080504  t123456  z  end:  vevent  end:  vcalendar  20080504t123456z  dotest  testgeo  begin:vcalendar  begin:vevent    geo:-12.345;-45.678    dtstart:20080504t123456z    end:vevent  end:vcalendar
__label__flaky get  timers  interval  a  b  start  assert  equals  test  instrumentation  timer  cron1  cron2  add  cron  cron3  thread  sleep  1  get  value  2  size  stop  inst  get  get  own  gettimers  interval  a  b  start  assertequals  testinstrumentationtimer  cron1  cron2  addcron  cron3  thread  sleep  1  getvalue  2  size  stop  inst  get  getown
__label__nflaky get  name  content  type  listener  core  matchers  equal  to  set  exception  callback  async  server  bootstrap  listen  io  reactor  config  assert  get  duration  create  https  /stuff  set  lookup  registry  get  code  cn=localhost   ou=  apache  http  components   o=  apache  software  foundation  get  peer  principal  requester  localhost  set  stream  listener  http  status  logging  exception  callback  tls  version  logging  http1  stream  listener  set  io  session  listener  result  future1  ssl  session  *  set  so  timeout  method  assert  that  execute  logging  conn  pool  listener  secure  all  ports  strategy  greater  equals  timeout  response1  server  test  tls  success  set  io  reactor  config  create  client  ssl  context  not  null  value  bootstrap  h2  requester  bootstrap  set  conn  pool  listener  set  tls  strategy  ssl  session  ref  some  stuff  set  io  session  decorator  create  server  ssl  context  get  head  get  body1  verify  get  address  tls  get  and  set  ssl  test  contexts  set  address  get  body  custom  start  get  protocol  parse  ssl  engine  target  get  time  unit  logging  io  session  decorator  get  port  build  future  logging  io  session  listener  get  session  register  message1  getname  contenttype  listener  corematchers  equalto  setexceptioncallback  asyncserverbootstrap  listen  ioreactorconfig  assert  getduration  create  https  /stuff  setlookupregistry  getcode  cn=localhost ou=apache httpcomponents o=apache software foundation  getpeerprincipal  requester  localhost  setstreamlistener  httpstatus  loggingexceptioncallback  tlsversion  logginghttp1streamlistener  setiosessionlistener  resultfuture1  sslsession  *  setsotimeout  method  assertthat  execute  loggingconnpoollistener  secureallportsstrategy  greaterequals  timeout  response1  server  testtlssuccess  setioreactorconfig  createclientsslcontext  notnullvalue  bootstrap  h2requesterbootstrap  setconnpoollistener  settlsstrategy  sslsessionref  some stuff  setiosessiondecorator  createserversslcontext  gethead  get  body1  verify  getaddress  tls  getandset  ssltestcontexts  set  address  getbody  custom  start  getprotocol  parse  sslengine  target  gettimeunit  loggingiosessiondecorator  getport  build  future  loggingiosessionlistener  getsession  register  message1
__label__flaky get  connection  context  get  event  message  error  code  conf  parse  date  utc  date  utils  get  status  wf-app-name1  ca  job  id1  ca  id1  coordinator  action  2012-07-22  t00:00  z  get  start  time  message  type  2011-07-11  t00:00  z  init  print  stack  trace  get  text  fail  contains  create  consumer  app  type  start  date  get  parent  id  test  on  coordinator  action  start  event  get  app  type  cae  session  coord  event  listener  assert  false  jms  messaging  utils  get  event  status  get  user  event  status  get  id  create  session  get  topic  on  coordinator  action  event  jms  context  consumer  user1  missing  dependency  get  message  type  nominal  time  receive  get  app  name  e  error  message  coord  action  start  message  get  message  assert  equals  message  end  time  session  getconnectioncontext  geteventmessage  errorcode  conf  parsedateutc  dateutils  getstatus  wf-app-name1  cajobid1  caid1  coordinatoraction  2012-07-22t00:00z  getstarttime  messagetype  2011-07-11t00:00z  init  printstacktrace  gettext  fail  contains  createconsumer  apptype  startdate  getparentid  testoncoordinatoractionstartevent  getapptype  cae  session  coordeventlistener  assertfalse  jmsmessagingutils  geteventstatus  getuser  eventstatus  getid  createsession  gettopic  oncoordinatoractionevent  jmscontext  consumer  user1  missingdependency  getmessagetype  nominaltime  receive  getappname  e  errormessage  coordactionstartmessage  getmessage  assertequals  message  endtime  session
__label__nflaky test  that  the  get  help  method  is  called  test  then  return  help  3  help  1  help  2  when  assert  array  equals  help  verify  no  more  interactions  get  help  verify  expr   test that the gethelp method is called  test  thenreturn  help 3  help 1  help 2  when  assertarrayequals  help  verifynomoreinteractions  gethelp  verify  expr
__label__flaky play  verify  the  peer  received  what  was  expected.  data  okio  type_  data  assert  flush  blocks  http_20_  draft_09  header  entries  receiving  a  window  update  on  the  connection  isn\'t  enough.  get  sink  out  accept  frame  flush  check  that  we\'ve  filled  the  window  for  both  the  stream  and  also  the  connection.  stream  type_  headers  default_  initial_  window_  size  peer  connection  get  stream  frames  that  fill  window  buffer  round  up  write  write  awaits  window  update  take  frame  banana  window  update  b  write  byte  data  we  won\'t  be  able  to  flush  until  a  window  update.  data  assert  equals  max  frame  size  syn_  stream  spdy3  play  it  back.  syn  stream  new  stream  receiving  a  window  update  on  the  stream  will  unblock  the  stream.  play   verify the peer received what was expected.  data  okio  type_data  assertflushblocks  http_20_draft_09  headerentries   receiving a window update on the connection isn\'t enough.  getsink  out  acceptframe  flush   check that we\'ve filled the window for both the stream and also the connection.  stream  type_headers  default_initial_window_size  peer  connection  getstream  framesthatfillwindow  buffer  roundup  write  writeawaitswindowupdate  takeframe  banana  windowupdate  b  writebyte   data we won\'t be able to flush until a window update.   data  assertequals  maxframesize   syn_stream  spdy3   play it back.  synstream  newstream   receiving a window update on the stream will unblock the stream.
__label__nflaky should  work  when  metrics  system  is  not  started  ms  ts2  ts1  assert  null  get  source  assert  not  null  unregister  source  test  unregister  source  s1  shutdown  register  s2     should work when metrics system is not started  ms  ts2  ts1  assertnull  getsource  assertnotnull  unregistersource  testunregistersource  s1  shutdown  register  s2
__label__flaky request  normal  i2  assert  equals  get  id  test  consider  known  items  with  consider  i7  target  accept  get  value  consider  known  items  list_  id_  value_  type  assert  size  float_  epsilon  /recommend/  u4  get  true  media  type  query  param  request  normal  i2  assertequals  getid  testconsiderknownitems  withconsider  i7  target  accept  getvalue  considerknownitems  list_id_value_type  assert  size  float_epsilon  /recommend/u4  get  true  mediatype  queryparam
__label__nflaky actual  get  replacement  command  ls  expected  ls.get  replacement  command  assert  equals  check  there\'s  no  replacement  command  actual  getreplacementcommand  ls  expected  ls.getreplacementcommand  assertequals   check there\'s no replacement command
__label__flaky get  recovery  path  chmod1  chmod2  source  get  status  create  context  get  path  context  get  file  status  set  id  action  id  id  mkdir  get  permission  ae  format  <chmod  path=\'\'{4}\'\'  permissions=\'\'-rwxrwxrwx\'\'/>  get  file  system  check  rwxrwx---  ex  workflow  action  test  recovery  mkdirs  -  fs  <chmod  path=\'\'{5}\'\'  permissions=\'\'-rwxrwx---\'\'  dir-files=\'\'false\'\'/>  <mkdir  path=\'\'{0}\'\'/>  <chmod  path=\'\'{5}\'\'  permissions=\'\'222\'\'  dir-files=\'\'false\'\'/>  get  workflow  set  job  id  fs001  assert  false  <fs>  get  actions  child2  fs  delete  system  child1  action  xml  get  error  code  assert  true  <move  source=\'\'{2}\'\'  target=\'\'{3}\'\'/>  get  </fs>  end  ok  get  data  message  format  <delete  path=\'\'{1}\'\'/>  to  uri  <chmod  path=\'\'{4}\'\'  permissions=\'\'111\'\'/>  start  get  action  assert  equals  get  external  status  rwxrwxrwx  target  assert  null  current  time  millis  equals  assert  not  same  exists  to  string  get  fs  test  case  dir  getrecoverypath  chmod1  chmod2  source  getstatus  createcontext  getpath  context  getfilestatus  setid  action  id  id  mkdir  getpermission  ae  format  <chmod path=\'\'{4}\'\' permissions=\'\'-rwxrwxrwx\'\'/>  getfilesystem  check  rwxrwx---  ex  workflowaction  testrecovery  mkdirs  -fs  <chmod path=\'\'{5}\'\' permissions=\'\'-rwxrwx---\'\' dir-files=\'\'false\'\'/>  <mkdir path=\'\'{0}\'\'/>  <chmod path=\'\'{5}\'\' permissions=\'\'222\'\' dir-files=\'\'false\'\'/>  getworkflow  setjobid  fs001  assertfalse  <fs>  getactions  child2  fs  delete  system  child1  actionxml  geterrorcode  asserttrue  <move source=\'\'{2}\'\' target=\'\'{3}\'\'/>  get  </fs>  end  ok  getdata  messageformat  <delete path=\'\'{1}\'\'/>  touri  <chmod path=\'\'{4}\'\' permissions=\'\'111\'\'/>  start  getaction  assertequals  getexternalstatus  rwxrwxrwx  target  assertnull  currenttimemillis  equals  assertnotsame  exists  tostring  getfstestcasedir
__label__nflaky set  run  mini  benchmark  hadoop.security.authentication  mb  conf  simple  level  test  simple  set  runminibenchmark  hadoop.security.authentication  mb  conf  simple  level  testsimple
__label__flaky get  connection  context  get  event  message  wf  succ  message  end  date  session  jms  messaging  utils  get  event  status  get  user  event  status  conf  get  id  parse  date  utc  date  utils  get  status  create  session  get  topic  wf-app-name1  get  end  time  ca  id1  2012-07-22  t00:00  z  wf  id1  get  start  time  workflow  job  jms  context  consumer  message  type  user1  get  message  type  init  receive  get  app  name  print  stack  trace  e  get  message  destroy  assert  equals  message  wf  event  listener  fail  on  workflow  job  event  wfe  create  consumer  test  on  workflow  job  success  event  app  type  start  date  get  parent  id  session  get  app  type  getconnectioncontext  geteventmessage  wfsuccmessage  enddate  session  jmsmessagingutils  geteventstatus  getuser  eventstatus  conf  getid  parsedateutc  dateutils  getstatus  createsession  gettopic  wf-app-name1  getendtime  caid1  2012-07-22t00:00z  wfid1  getstarttime  workflowjob  jmscontext  consumer  messagetype  user1  getmessagetype  init  receive  getappname  printstacktrace  e  getmessage  destroy  assertequals  message  wfeventlistener  fail  onworkflowjobevent  wfe  createconsumer  testonworkflowjobsuccessevent  apptype  startdate  getparentid  session  getapptype
__label__nflaky store  password  get  resource  to  char  array  server  socket  new  single  thread  executor  executors  server  ssl  context  as  list  get  server  socket  factory  assert  bind  assert  not  null  nopassword  is  windows  create  boolean  ssl  context  builder  /test-client.p12  localhost  start  handshake  local  port  load  key  material  load  trust  material  resource2  thrown  set  so  timeout  /test-server.p12  resource1  accept  contains  test  ssl  handshake  protocol  mismatch1  create  socket  client  ssl  context  timeout  arrays  supported  server  protocols  get  supported  protocols  get  local  port  submit  supported  client  protocols  client  socket  ss  lv3  tl  sv1  assert  true  key  password  close  connect  set  enabled  protocols  call  get  socket  factory  expect  build  to  milliseconds  int  bound  socket  get  session  create  server  socket  storepassword  getresource  tochararray  serversocket  newsinglethreadexecutor  executors  serversslcontext  aslist  getserversocketfactory  assert  bind  assertnotnull  nopassword  iswindows  create  boolean  sslcontextbuilder  /test-client.p12  localhost  starthandshake  localport  loadkeymaterial  loadtrustmaterial  resource2  thrown  setsotimeout  /test-server.p12  resource1  accept  contains  testsslhandshakeprotocolmismatch1  createsocket  clientsslcontext  timeout  arrays  supportedserverprotocols  getsupportedprotocols  getlocalport  submit  supportedclientprotocols  clientsocket  sslv3  tlsv1  asserttrue  keypassword  close  connect  setenabledprotocols  call  getsocketfactory  expect  build  tomillisecondsintbound  socket  getsession  createserversocket
__label__flaky add  record  to  bundle  action  table  get  current  dateafter  incrementing  in  months  run  date  utils  workflow  instance  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  bundle  job  assert  not  null  coordinator  action  current  date  plus  month  job  wait  for  bundle  action1  bundle  action2  x  data  test  case  test  bundle  status  transit  service  killed  execute  add  record  to  coord  job  table  with  bundle  coord  job2  coordinator  job  coord  job1  evaluate  assert  false  get  id  get  external  id  is  pending  wf  job  add  record  to  wf  job  table  get  end  coord  action1_3  workflow  job  coord  action1_4  bundle  coord  action1_1  coord  action1_2  add  record  to  bundle  job  table  bundle  id  start  assert  equals  call  services  runnable  coord-action-get.xml  equals  action1  action2  jpa  service  addrecordtobundleactiontable  getcurrentdateafterincrementinginmonths  run  dateutils  workflowinstance  getstatus  addrecordtocoordactiontable  parsedateoozietz  bundlejob  assertnotnull  coordinatoraction  currentdateplusmonth  job  waitfor  bundleaction1  bundleaction2  xdatatestcase  testbundlestatustransitservicekilled  execute  addrecordtocoordjobtablewithbundle  coordjob2  coordinatorjob  coordjob1  evaluate  assertfalse  getid  getexternalid  ispending  wfjob  addrecordtowfjobtable  get  end  coordaction1_3  workflowjob  coordaction1_4  bundle  coordaction1_1  coordaction1_2  addrecordtobundlejobtable  bundleid  start  assertequals  call  services  runnable  coord-action-get.xml  equals  action1  action2  jpaservice
__label__nflaky init  service  assert  service  in  state  listener  service  register  service  listener  assert  event  count  test  stop  in  init  service  init  service  assertserviceinstate  listener  service  registerservicelistener  asserteventcount  teststopininitservice
__label__flaky job14-200904160239--example-forkjoinwf  action-  use  generic  options  parser  for  parsing  2009-06-24  02:43:19 344  debug  _  l6_:323  -  useroozie  groupoozie  token  m  ytoken  app-  app  the  arguments.  lr  org.apache.oozie.core.command.  workflow  runner  callable  job-  action-  number  of  pending  signals  to  check  0  2009-06-24  02:43:14 505  info  _  l5_:317  -  useroozie  groupoozie  token-  app-  job-  split  get  test  case  dir  action-  _  l3  a_  job  token  2009-06-24  02:43:29 151  debug  _  l7_:323  -  user-  group-  token-  app-  job-  action-  write  test  process  log  see  job  conf(  class)  or  job  conf#set  jar(  string).  set  log  level  job14-200904160239--example-forkjoinwf  action-  end  workflow  state  change  contains  /test.log  _  l3_  debug|  warn  reset  _  l3  b_  released  lock  job14-200904160239--example-forkjoinwf  action-  sb  out  2009-06-24  02:43:13 958  debug  _  l1_:323  -  useroozie  group-  token-  appexample-forkjoinwf  group  fw  2009-06-24  02:43:13 961  info  _  l2_:317  -  user-  group-  token-  appexample-forkjoinwf  14-200904160239--example-forkjoinwf  released  lock  define  parameter  set  parameter  _  l3  a_  applications  should  implement  tool  for  the  same.  _  l3  b_  multi  line  test  close  2009-06-24  02:43:14 431  warn  _  l4_:661  -  no  job  jar  file  set.  user  classes  may  not  be  found.  sw  x  log  streamer  number  of  pending  actions  0  assert  equals  user  xf  2009-06-24  02:43:13 986  warn  _  l3_:539  -  user-  group-  token-  appexample-forkjoinwf  action  _  l1_  to  string  process  log  append  job14-200904160239--example-forkjoinwf action- use genericoptionsparser for parsing     2009-06-24 02:43:19 344 debug _l6_:323 - useroozie groupoozie tokenmytoken app-   app  the arguments.   lr  org.apache.oozie.core.command.workflowrunnercallable   job- action- number of pending signals to check 0        2009-06-24 02:43:14 505  info _l5_:317 - useroozie groupoozie token- app- job-   split  gettestcasedir  action-   _l3a_  job  token    2009-06-24 02:43:29 151 debug _l7_:323 - user- group- token- app- job- action-   write  testprocesslog  see jobconf(class) or jobconf#setjar(string).  setloglevel  job14-200904160239--example-forkjoinwf action- end workflow state change  contains  /test.log  _l3_  debug|warn  reset  _l3b_  released lock  job14-200904160239--example-forkjoinwf action-   sb  out  2009-06-24 02:43:13 958 debug _l1_:323 - useroozie group- token- appexample-forkjoinwf   group  fw    2009-06-24 02:43:13 961  info _l2_:317 - user- group- token- appexample-forkjoinwf   14-200904160239--example-forkjoinwf  released lock  defineparameter  setparameter    _l3a_applications should implement tool for the same.   _l3b_multi line test  close    2009-06-24 02:43:14 431  warn _l4_:661 - no job jar file set.  user classes may not be found.   sw  xlogstreamer  number of pending actions 0   assertequals  user  xf    2009-06-24 02:43:13 986  warn _l3_:539 - user- group- token- appexample-forkjoinwf   action  _l1_  tostring  processlog  append
__label__nflaky set  socket  timeout  conn  argument  matchers  timeout  set  so  timeout  when  any  int  do  throw  times  bind  test  set  socket  timeout  exception  mockito  of  milliseconds  verify  socket  setsockettimeout  conn  argumentmatchers  timeout  setsotimeout  when  anyint  dothrow  times  bind  testsetsockettimeoutexception  mockito  ofmilliseconds  verify  socket
__label__flaky date  session  given  insert  select  *  from  simple  where  id  =  crud  sleep  should_insert_with_ttl  when  id  row  value  random  utils  manager  one  next  long  assert  that  execute  using  time  to  live  thread  then  is  null  long  build  date  key  entity  date  session   given  insert  select * from simple where id =   crud  sleep  should_insert_with_ttl   when  id  row  value  randomutils  manager  one  nextlong  assertthat  execute  usingtimetolive  thread   then  isnull  long  builddatekey  entity
__label__nflaky enum  param  then  return  invoke  when  param1  red  rainbow  context  create  verify  mock  controller  enum  param  should  be  parsed  to  enum  case  insensitive  get  parameter  enumparam  thenreturn  invoke  when  param1  red  rainbow  context  create  verify  mockcontroller  enumparamshouldbeparsedtoenumcaseinsensitive  getparameter
__label__flaky add  request  ;actionstatus=  failed   killed;  _exec  query  assert  equals  get  action  br  list  get  status  3  actions  satisfy  the  conditions  as  list  test  multiple  records  result  status  startcreatedtime=2012-07-21  t00:00  z;endcreatedtime=2012-07-22  t02:00  z  size  failed  get  bundle  name  possible  status  to  string  arrays  bundle=  killed  add  request  ;actionstatus=failed killed;  _execquery  assertequals  getaction  brlist  getstatus   3 actions satisfy the conditions  aslist  testmultiplerecords  resultstatus  startcreatedtime=2012-07-21t00:00z;endcreatedtime=2012-07-22t02:00z  size  failed  get  bundlename  possiblestatus  tostring  arrays  bundle=  killed
__label__nflaky of  seconds  of  nanoseconds  hours1  of  days  assert  equals  nanos1  seconds1  millis1  min  assert  of  hours  days1  test  min  of  milliseconds  of  microseconds  minutes1  of  minutes  time  value  micros1     ofseconds  ofnanoseconds  hours1  ofdays  assertequals  nanos1  seconds1  millis1  min  assert  ofhours  days1  testmin  ofmilliseconds  ofmicroseconds  minutes1  ofminutes  timevalue  micros1
__label__flaky coord  id1  filter  list  job1  assert  equals  create  filter  list  list  execute  jobid  services  sla  events  get  cmd  test  get  sla  events  for  coord  job  id  size  assert  not  null  get  jpa  service  coordid1  filterlistjob1  assertequals  createfilterlist  list  execute  jobid  services  slaeventsgetcmd  testgetslaeventsforcoordjobid  size  assertnotnull  get  jpaservice
__label__nflaky proxy  users  refresh  super  user  groups  configuration  assert  authorized  group_  names  default  impersonation  provider  now  try  proxying  a  user  that\'s  not  allowed  get  proxy  superuser  user  conf  key  conf  as  list  proxy_  ip  string  utils  join  from  bad  ip  user  group  information  set  proxy  user  ugi  1.2.3.4  1.2.3.5  test  proxy  users  with  user  conf  authorized_  proxy_  user_  name     create  remote  user  real_  user_  name  assert  not  authorized  get  test  provider  from  good  ip  first  try  proxying  a  user  that\'s  allowed  arrays  get  proxy  superuser  ip  conf  key  proxy_  user_  name  real  user  ugi  create  proxy  user  for  testing  proxyusers  refreshsuperusergroupsconfiguration  assertauthorized  group_names  defaultimpersonationprovider   now try proxying a user that\'s not allowed  getproxysuperuseruserconfkey  conf  aslist  proxy_ip  stringutils  join   from bad ip  usergroupinformation  set  proxyuserugi  1.2.3.4  1.2.3.5  testproxyuserswithuserconf  authorized_proxy_user_name     createremoteuser  real_user_name  assertnotauthorized  gettestprovider   from good ip   first try proxying a user that\'s allowed  arrays  getproxysuperuseripconfkey  proxy_user_name  realuserugi  createproxyuserfortesting
__label__flaky call  a=  a  test  no  resource  no  params  my  json  rest  servlet  get  http  servlet  response  invoke  assert  equals  run  test  /  /hello    call  a=a  testnoresourcenoparams  myjsonrestservlet  get  httpservletresponse  invoke  assertequals  runtest  /  /hello
__label__nflaky get  key  version  cache  mock  key  asserting  no  caching  when  key  is  not  known  get  conf  then  return  k2@0  k1@0  assert  equals  eq  when  thread  sleep  times  assert  test  key  version  mockito  mock  verify  asserting  caching  mock  prov  getkeyversion  cache  mockkey   asserting no caching when key is not known  getconf  thenreturn  k2@0  k1@0  assertequals  eq  when  thread  sleep  times  assert  testkeyversion  mockito  mock  verify   asserting caching  mockprov
__label__flaky cluster  address  test  file  system  close  all  conf  close  all  get  test  configuration  get  default  uri  build  set  default  uri  num  data  nodes  file  system  get  shutdown  cluster  address  testfilesystemcloseall  conf  closeall  gettestconfiguration  getdefaulturi  build  setdefaulturi  numdatanodes  filesystem  get  shutdown
__label__nflaky request  get  name  converter  convert  assert  :scheme  assert  not  null  get  host  :authority  header4  headers  header3  add  header  header2  header1  assert  equals  custom123  /  header5  get  value  test  convert  from  message  basic  size  :method  get  value  http  :path  request  getname  converter  convert  assert  :scheme  assertnotnull  get  host  :authority  header4  headers  header3  addheader  header2  header1  assertequals  custom123  /  header5  getvalue  testconvertfrommessagebasic  size  :method  get  value  http  :path
__label__flaky headers  get  server  address  get  headers  ninja  test  browser  new  hash  map  assert  equals  test  that  setting  of  mime  type  works  some  empty  headers  for  now...  get  value  make  request  and  get  response  maps  /redirect  will  send  a  location:  redirect  in  the  headers  default  charset  is  always  utf-8  by  convention.  assets/files/test_for_mimetypes.dxf  application/dxf;  charset=  utf-8  http  response  content-  type  headers  getserveraddress  getheaders  ninjatestbrowser  newhashmap  assertequals  testthatsettingofmimetypeworks   some empty headers for now...  getvalue  makerequestandgetresponse  maps   /redirect will send a location: redirect in the headers   default charset is always utf-8 by convention.  assets/files/test_for_mimetypes.dxf  application/dxf; charset=utf-8  httpresponse  content-type
__label__nflaky 0  footer1:  looooooooooooooooooooooooooooooooooooooooooooooooooooooog  dst  codec  test  utils  10  1234567890123456  convert  metrics2  metrics1  assert  message  constraint  exception  expected  assert  not  null  test  too  long  footer  read  1234567890123456  standard  charsets  \""0\\r   footer1:  looooooooooooooooooooooooooooooooooooooooog\\r   \\r   fghij\\r \\r \"";  decoder1  clear  bytes  read  channel1  inbuf1  assert  equals  channel2  decoder2  byte  buffer  inbuf2  trailers  fail  allocate  size  get  trailers  0  footer1: looooooooooooooooooooooooooooooooooooooooooooooooooooooog      dst  codectestutils  10  1234567890123456    convert  metrics2  metrics1  assert  messageconstraintexception expected  assertnotnull  testtoolongfooter  read  1234567890123456  standardcharsets   \""0\\r footer1: looooooooooooooooooooooooooooooooooooooooog\\r    \\r   fghij\\r \\r \"";  decoder1  clear  bytesread  channel1  inbuf1  assertequals  channel2  decoder2  bytebuffer  inbuf2  trailers  fail  allocate  size  gettrailers
__label__flaky request  normal  i2  assert  equals  get  id  test  consider  known  items  with  consider  i7  target  accept  get  value  consider  known  items  list_  id_  value_  type  /recommend  to  many/  u4  assert  size  float_  epsilon  get  true  media  type  query  param  request  normal  i2  assertequals  getid  testconsiderknownitems  withconsider  i7  target  accept  getvalue  considerknownitems  list_id_value_type  /recommendtomany/u4  assert  size  float_epsilon  get  true  mediatype  queryparam
__label__nflaky open  file  write  data  create  file  recursive  crc_  size  file  stats  test_  root_  dir  bytes  read  in  open  file()  call  with  stats  get  assert  writes  crc  overwrite  close  write  get  bytes  read  now  read  back  the  data   again  with  the  builder  api  create  file()  create  file  non  recursive()  assert  equals  bytes  read0  now  write  with  overwrite  =  true  test  read  includes  cr  cwith  builders  build  data  file  sys  get  file  statistics  write  the  file  using  the  builder  api  openfile  writedata  createfile  recursive  crc_size  file  stats  test_root_dir  bytes read in openfile() call with stats   get  assertwritescrc  overwrite  close  write  getbytesread   now read back the data  again with the builder api  createfile()  createfilenonrecursive()  assertequals  bytesread0   now write with overwrite = true  testreadincludescrcwithbuilders  build  data  filesys  getfilestatistics   write the file using the builder api
__label__flaky init  jms  topic  service  set  get  conf  =coord  get  message  destroy  =  workflow   services  setup  services  for  topic  expected  service  exception  get  value  fail  se  contains  test  incorrect  configuration  job  type  assert  true  incorrect  job  type  invalid  job  type  init  jmstopicservice  set  getconf  =coord  getmessage  destroy   = workflow   services  setupservicesfortopic  expected service exception  getvalue  fail  se  contains  testincorrectconfigurationjobtype  asserttrue  incorrect job type  invalidjobtype
__label__nflaky conn  in  stream  get  content  assert  equals  create  incoming  entity  message  get  content  length  content  content  length  strategy  assert  is  chunked  mockito  assert  true  assert  not  null  mock  test  create  entity  input  chunked  ok  entity  conn  instream  getcontent  assertequals  createincomingentity  message  getcontentlength  content  contentlengthstrategy  assert  ischunked  mockito  asserttrue  assertnotnull  mock  testcreateentityinputchunked  ok  entity
__label__flaky get  the  first  3  job2  job1  job4  check  workflows  job3  job5  assert  equals  get  id  workflow  instance  list  execute  services  test  wf  jobs  get  for  purge  too  many  size  add  record  to  wf  job  table  add  all  assert  not  null  get  get  the  next  3  (though  there\'s  only  2  more)  workflow  job  jpa  service   get the first 3  job2  job1  job4  checkworkflows  job3  job5  assertequals  getid  workflowinstance  list  execute  services  testwfjobsgetforpurgetoomany  size  addrecordtowfjobtable  addall  assertnotnull  get   get the next 3 (though there\'s only 2 more)  workflowjob  jpaservice
__label__nflaky values  insert  string  error  system  as  list  estimator  get  estimate  collections  test  quantile  error  actual  do  10  shuffle/insert/check  cycles  count  clear  format  starting  run  j  assert  that  quantiles  q  is  true  r  expected  \%d  with  error  \%d   estimated  \%d  arrays  shuffle  snapshot  values  insert  string  error  system  aslist  estimator  get  estimate  collections  testquantileerror  actual   do 10 shuffle/insert/check cycles  count  clear  format  starting run   j  assertthat  quantiles  q  istrue  r  expected \%d with error \%d  estimated \%d  arrays  shuffle  snapshot
__label__flaky aa  bb  a  a  b  set  variables  c  resolve  variable  set  variable  assert  equals  get  variable  put  fail  assert  null  test  context  vars  vars  support  aa  bb  a  a  b  setvariables  c  resolvevariable  setvariable  assertequals  getvariable  put  fail  assertnull  testcontextvars  vars  support
__label__nflaky data  common  configuration  keys  value  of  conf  string  test  du  get  used  will  not  return  negative  du  size  du  set  long  file  assert  true  get  used  long  du_  dir  create  new  file  inc  dfs  used  data  commonconfigurationkeys  valueof  conf  string  testdugetusedwillnotreturnnegative  dusize  du  setlong  file  asserttrue  getused  long  du_dir  createnewfile  incdfsused
__label__flaky end_  points  is_  security_  enabled  oozie  url  conf  wc  test  re  run  app  path  assert  true  get  create  workflow.xml  servlet_  classes  close  run  test  app  rest  constants  get  context  url  mock  dag  engine  service  assert  equals  get  file  system  re  run  call  oozie  client  1  get  test  user  set  property  mkdirs  create  configuration  to  string  get  fs  test  case  dir  end_points  is_security_enabled  oozieurl  conf  wc  testrerun  apppath  asserttrue  get  create  workflow.xml  servlet_classes  close  runtest  app  restconstants  getcontexturl  mockdagengineservice  assertequals  getfilesystem  rerun  call  oozieclient  1  gettestuser  setproperty  mkdirs  createconfiguration  tostring  getfstestcasedir
__label__nflaky calendar  add  rfs  sink  set  get  time  calendar  get  time  in  millis  assert  equals  test  update  roll  time  get  instance  the  next  roll  time  should  have  been  1  second  in  the  future  update  flush  time  set  time  the  next  roll  time  should  have  been  990  ms  in  the  future  calendar  add  rfssink  set  gettime  calendar  gettimeinmillis  assertequals  testupdaterolltime  getinstance  the next roll time should have been 1 second in the future  updateflushtime  settime  the next roll time should have been 990 ms in the future
__label__flaky date  script  executor  and  date  =  \'2015-10-01  00:00:00+0000\'  session  local_  one  given  update  simple  eq  consistency  list_  remove  from  consistencylist  contains  exactly  quorum  should_dsl_update_list_remove_single  when  get  list  of  where  id  row  table  execute  script  template  random  utils  manager  one  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  update  simple  set  consistencylist  =  consistencylist  +  \'  quorum\'   \'  quorum\'  where  id  =  select  consistencylist  from  simple  where  id  =  then  long  build  date  key  from  base  table  consistency  list  dsl  date  scriptexecutor  and date = \'2015-10-01 00:00:00+0000\'  session  local_one   given  update  simple  eq  consistencylist_removefrom  consistencylist  containsexactly  quorum  should_dsl_update_list_remove_single   when  getlist  of  where  id  row  table  executescripttemplate  randomutils  manager  one  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  update simple set consistencylist = consistencylist + \'quorum\'  \'quorum\' where id =   select consistencylist from simple where id =    then  long  builddatekey  frombasetable  consistencylist  dsl
__label__nflaky should  log  helper  test  logging  with  inconsistent  values  assert  true  record  shouldlog  helper  testloggingwithinconsistentvalues  asserttrue  record
__label__flaky next  cluster  meta  index  listener  test_  util  assert  region  is  back  online  figure  the  index  of  the  server  that  is  not  server  the  .  meta.  get  region  server  sleep  iterator  other  server  index  meta  hrs  get  h  server  info  assert  true  unregister  region  server  operation  listener  abort  region  server  test  region  close  when  no  meta  h  base2428  hri  add  our  region  server  operations  listener  info  get  server  address  log  get  online  regions  get  region  server  threads  now  close  the  server  carrying  meta.  get  region  server  operation  queue  get  server  with  meta  is  done  register  region  server  operation  listener  master  get  region  info  threads  other  server  get  a  region  out  on  the  other  server.  h  base2428  listener  running  test  region  close  when  no  meta  h  base2428  size  first  wait  on  receipt  of  meta  server  shutdown  message.  get  h  base  cluster  (  multiple  by  two  to  add  in  some  slop  in  case  of  gc  or  something).  get  master  assert  the  closed  region  came  back  online  get  close  count  next  cluster  metaindex  listener  test_util  assertregionisbackonline   figure the index of the server that is not server the .meta.  getregionserver  sleep  iterator  otherserverindex  metahrs  gethserverinfo  asserttrue  unregisterregionserveroperationlistener  abortregionserver  testregionclosewhennometahbase2428  hri   add our regionserveroperationslistener  info  getserveraddress  log  getonlineregions  getregionserverthreads   now close the server carrying meta.  getregionserveroperationqueue  getserverwithmeta  isdone  registerregionserveroperationlistener  master  getregioninfo  threads  otherserver   get a region out on the otherserver.  hbase2428listener  running testregionclosewhennometahbase2428  size   first wait on receipt of meta server shutdown message.  gethbasecluster   (multiple by two to add in some slop in case of gc or something).  getmaster   assert the closed region came back online  getclosecount
__label__nflaky get  name  defaultfs://host2  conf  //host2  uri  has  scheme   same  auth  fs.defaultfs.impl  file  system  get  test  default  fs  uris  default  uri  create  default  fs  no  scheme   no  auth  set  defaultfs://host  assert  equals  assert  same  defaultfs:///  /  sanity  check  default  fs  //host  no  scheme   same  auth  set  default  uri  intercept  assert  not  same  has  scheme   no  auth  has  scheme   different  auth  get  uri  defaultfs:/  getname  defaultfs://host2  conf  //host2  uri   has scheme  same auth  fs.defaultfs.impl  filesystem  get  testdefaultfsuris  defaulturi  create  defaultfs   no scheme  no auth  set  defaultfs://host  assertequals  assertsame  defaultfs:///  /   sanity check default fs  //host   no scheme  same auth  setdefaulturi  intercept  assertnotsame   has scheme  no auth   has scheme  different auth  geturi  defaultfs:/
__label__flaky test  jobs  status  end_  points  is_  security_  enabled  get  context  url  oozie  url  get  jobs  info  get  app  path  mock  dag  engine  service  assert  equals  get  id  wc  list  call  size  assert  not  null  get  reset  name=x  servlet_  classes  run  test  testjobsstatus  end_points  is_security_enabled  getcontexturl  oozieurl  getjobsinfo  getapppath  mockdagengineservice  assertequals  getid  wc  list  call  size  assertnotnull  get  reset  name=x  servlet_classes  runtest
__label__nflaky server  get  current  user  rpc  get  proxy  superuser  group  conf  key  group_  names  default  impersonation  provider  get  user  new  empty  request  conf  run  ret  val  assert  set  strings  real_  user_  short_  name  test  real  user  ip  authorization  failure  refresh  conf  20.20.20.20  client  *  tests  authorization  of  superuser\'s  ip.  set  protocol  engine  addr  set  configuration  user  group  information  proxy  user  ugi  print  stack  trace  e  authorized  ip  address  get  client  create  remote  user  group1  real_  user_  name  fail  do  as  get  test  provider  stop  setup  test  server  get  proxy  superuser  ip  conf  key  proxy_  user_  name  the  rpc  must  have  failed  real  user  ugi  create  proxy  user  for  testing  server  getcurrentuser  rpc  getproxysuperusergroupconfkey  group_names  defaultimpersonationprovider  getuser  newemptyrequest  conf  run  retval  assert  setstrings  real_user_short_name  testrealuseripauthorizationfailure  refreshconf  20.20.20.20  client       * tests authorization of superuser\'s ip.       setprotocolengine  addr  setconfiguration  usergroupinformation  proxyuserugi  printstacktrace  e   authorized ip address  getclient  createremoteuser  group1  real_user_name  fail  doas  gettestprovider  stop  setuptestserver  getproxysuperuseripconfkey  proxy_user_name  the rpc must have failed   realuserugi  createproxyuserfortesting
__label__flaky get  name  oozie.service.  proxy  user  service.proxyuser.foo.groups  foo  conf  as  list  bar  assert  string  utils  assert  not  null  get  join  validate  localhost  init  set  oozie.service.  proxy  user  service.proxyuser.foo.hosts  get  conf  destroy  *  services     services  test  validate  host  proxy  user  arrays  getname  oozie.service.proxyuserservice.proxyuser.foo.groups  foo  conf  aslist  bar  assert  stringutils  assertnotnull  get  join  validate  localhost  init  set  oozie.service.proxyuserservice.proxyuser.foo.hosts  getconf  destroy  *  services     services  testvalidatehost  proxyuser  arrays
__label__nflaky get  value  class  reader  conf  fs  test  deprecated  constructors  cleanup  with  logger  path  sequence  file  assert  not  null  file  system  get  writes.mapfile  close  test_  dir  default  codec  e  log  get  key  class  writable  comparator  get  message  deprecation  reader  key  is  null  !!!  reader  value  in  null  fail  io  utils  get  local  default  progressable  to  string  writer  compression  type  getvalueclass  reader  conf  fs  testdeprecatedconstructors  cleanupwithlogger  path  sequencefile  assertnotnull  filesystem  get  writes.mapfile  close  test_dir  defaultcodec  e  log  getkeyclass  writablecomparator  getmessage  deprecation  reader key is null !!!  reader value in null  fail  ioutils  getlocal  defaultprogressable  tostring  writer  compressiontype
__label__flaky wait  until  has  some  regions  before  proceeding.  balancer  will  give  it  some.  cluster  this  test  to  succeed.  start  new  regionserver.  listener  running  test  kill  rs  with  opening  region2482  test_  util  assert  region  is  back  online  add  a  listener  on  the  server.  make  sure  the  abort  server  message  was  sent.  get  region  server  sleep  count  of  meta  regions  past  close  now  wait  for  regions  to  come  back  online.  unregister  region  server  operation  listener  close  all  non  catalog  regions  go  close  all  non-catalog  regions  on  this  new  server  past  abort  send;  waiting  on  all  regions  to  redeploy  info  minimum  regions  log  get  online  regions  started  new  regionserver:  get  region  server  threads  hrs  get  region  server  operation  queue  need  at  least  two  servers.  set  the  listener  only  after  some  regions  have  been  opened  on  new  server.  m  register  region  server  operation  listener  threads  get  live  region  server  threads  wait  on  all  regions  back  online.  test  kill  rs  with  opening  region2482  size  get  h  base  cluster  h  msg  come  in.  start  region  server  to  string  get  master  add  message  to  send  region  server   wait until has some regions before proceeding.  balancer will give it some.  cluster   this test to succeed.   start new regionserver.  listener  running testkillrswithopeningregion2482  test_util  assertregionisbackonline   add a listener on the server.   make sure the abort server message was sent.  getregionserver  sleep  countofmetaregions  past close   now wait for regions to come back online.  unregisterregionserveroperationlistener  closeallnoncatalogregions   go close all non-catalog regions on this new server  past abort send; waiting on all regions to redeploy  info  minimumregions  log  getonlineregions  started new regionserver:   getregionserverthreads  hrs  getregionserveroperationqueue   need at least two servers.   set the listener only after some regions have been opened on new server.  m  registerregionserveroperationlistener  threads  getliveregionserverthreads   wait on all regions back online.  testkillrswithopeningregion2482  size  gethbasecluster  hmsg   come in.  startregionserver  tostring  getmaster  addmessagetosendregionserver
__label__nflaky base  url  a:b  c&lt;:d  e:&gt;  servlet_  path_  echo  ?a=b&c<=d&e=>  test  echo  assert  equals  ?a=b&c=d  a:b  c:d  read  from  url  baseurl  a:b  c&lt;:d  e:&gt;    servlet_path_echo  ?a=b&c<=d&e=>  testecho  assertequals  ?a=b&c=d  a:b  c:d    readfromurl
__label__flaky get  job  tracker  uri  map-reduce  assert  mapred  job  name  has  been  set  conf  get  status  create  context  get  job  hadoop.counters  will  always  be  set  in  case  of  mr  action.  output  counter  mapred.job.name  get  execution  stats  assert  not  null  <map-reduce>  context  create  write  wait  for  <job-tracker>  mapred  job  name  map  reduce  launcher  test  ae  counters  get  job  name  parse  xml  </job-tracker>  dummy  get  file  system  check  <name-node>  assert  for  stats  info  stored  in  the  context.  </name-node>  input  contains  workflow  action  succeeded  submit  action  test  set  mapred  job  name  get  external  child  i  ds  data.txt  evaluate  job  id  launcher  id  launcher  job  name:  mapred  job  name:  external  child  i  ds  will  always  be  null  in  case  of  mr  action.  assert  false  user.name  get  external  id  fs  mr  config  has  id  swap  system  create  base  hadoop  conf  sb  action  xml  is  successful  assert  true  launcher  mapper  map  reduce  test  get  end  assert  launcher  job  name  has  been  set  close  get  map  reduce  config  get  data  get  name  node  uri  output  dir  launcher  job  set  xml  utils  for  name  get  action  assert  equals  mr  job  hadoop.counters  input  dir  get  external  status  </map-reduce>  oozie.launcher.mapred.job.name  services  create  job  client  assert  null  launcher  job  name  w  to  xml  string  equals  get  var  to  string  job  client  user  append  get  fs  test  case  dir  is  complete  getjobtrackeruri  map-reduce   assert mapred job name has been set  conf  getstatus  createcontext  getjob   hadoop.counters will always be set in case of mr action.  output  counter  mapred.job.name  getexecutionstats  assertnotnull  <map-reduce>  context  create  write  waitfor  <job-tracker>  mapredjobname  mapreducelaunchertest  ae  counters  getjobname  parsexml  </job-tracker>  dummy    getfilesystem  check  <name-node>   assert for stats info stored in the context.  </name-node>  input  contains  workflowaction  succeeded  submitaction  testsetmapredjobname  getexternalchildids  data.txt  evaluate  jobid  launcherid  launcher job name:   mapred job name:    external child ids will always be null in case of mr action.  assertfalse  user.name  getexternalid  fs  mrconfig  hasidswap  system  createbasehadoopconf  sb  actionxml  issuccessful  asserttrue  launchermapper  mapreducetest  get  end   assert launcher job name has been set  close  getmapreduceconfig  getdata  getnamenodeuri  outputdir  launcherjob  set  xmlutils  forname  getaction  assertequals  mrjob  hadoop.counters  inputdir  getexternalstatus  </map-reduce>  oozie.launcher.mapred.job.name  services  createjobclient  assertnull  launcherjobname  w  toxmlstring  equals  getvar  tostring  jobclient  user  append  getfstestcasedir  iscomplete
__label__nflaky svc  test  monitor  log  hm  health  monitor  returning  an  io  exception   as  if  node  went  down  assert  false  create  proxy  count  returning  to  healthy  state   waiting  for  healthy  count  before  should  retry  several  times  wait  for  state  thread  sleep  is  alive  get  mocking  bad  health  check   waiting  for  unhealthy  join  should  expect  many  rapid  retries  shutdown  info  svc  testmonitor  log  hm  healthmonitor  returning an ioexception  as if node went down  assertfalse  createproxycount  returning to healthy state  waiting for healthy  countbefore   should retry several times  waitforstate  thread  sleep  isalive  get  mocking bad health check  waiting for unhealthy  join   should expect many rapid retries  shutdown  info
__label__flaky cluster  create  table  admin  test_  util  get  region  name  register  listener  bytes  split  about  to  open  get  first  get  table  region  from  name  await  time  unit  count  down  proceed  tablename  cde  get  table  regions  load  table  to  bytes  list  m  pair  test  master  ops  while  splitting  get  table  region  closest  get  h  base  cluster  h  base  event  handler  get  h  base  admin  get  master  familyname  cluster  createtable  admin  test_util  getregionname  registerlistener  bytes  split  abouttoopen  getfirst  gettableregionfromname  await  timeunit  countdown  proceed  tablename  cde  gettableregions  loadtable  tobytes  list  m  pair  testmasteropswhilesplitting  gettableregionclosest  gethbasecluster  hbaseeventhandler  gethbaseadmin  getmaster  familyname
__label__nflaky prepare  append  key  out  key  fail  key0  key  is  shorter  than  expected.  skip  writer  test  failure  value  too  short  write  close  get  bytes  prepareappendkey  outkey  fail  key0  key is shorter than expected.  skip  writer  testfailurevaluetooshort  write  close  getbytes
__label__flaky fail  expected  timeout  test  auth  url  connect  timeout  e  renewer  connect  timed  out  consume  connection  backlog  get  message  test_  timeout  assert  equals  fs  get  delegation  token  fail  expected timeout  testauthurlconnecttimeout  e  renewer  connect timed out  consumeconnectionbacklog  getmessage  test_timeout  assertequals  fs  getdelegationtoken
__label__nflaky test  get  index  fifo  linked  list  get  index  h  h1  h2  assert  equals  h3  h4  assert  same  node1  remove  last  node4  1  2  node2  3  node3  assert  4  size  get  add  first  testgetindex  fifolinkedlist  getindex  h  h1  h2  assertequals  h3  h4  assertsame  node1  removelast  node4  1  2  node2  3  node3  assert  4  size  get  addfirst
__label__flaky drop  database  create  table  year=2013;month=1;dt=01;country=us  part1  part2  assert  false  </prepare>  do  operations  add  partition  <delete  path=\'  year month dt country  conf  fs  year=2012;month=12;dt=02;country=us  create  job  conf  test  delete  table1  /db1/table1/year=2013;dt=01  launcher  mapper  get  partitions  <prepare>  \'/>  prepare  block  that  contains  delete  action  /db1/table1/year=2012;month=12  drop  table  country=us  get  metastore  authority  hcat://  assert  equals  get  file  system  uri2  create  database  db1  uri1  size  prepare  xml  part3  exists  year=2012;month=12;dt=03;country=us  setup  launcher  uri  handler  conf  prepare  actions  driver  dropdatabase  createtable  year=2013;month=1;dt=01;country=us  part1  part2  assertfalse  </prepare>  dooperations  addpartition  <delete path=\'  year month dt country  conf  fs  year=2012;month=12;dt=02;country=us  createjobconf  testdelete  table1  /db1/table1/year=2013;dt=01  launchermapper  getpartitions  <prepare>  \'/>   prepare block that contains delete action  /db1/table1/year=2012;month=12  droptable  country=us  getmetastoreauthority  hcat://  assertequals  getfilesystem  uri2  createdatabase  db1  uri1  size  preparexml  part3  exists  year=2012;month=12;dt=03;country=us  setuplauncherurihandlerconf  prepareactionsdriver
__label__nflaky test  basic  read  input  read  assert  in  tmp  input  stream  assert  equals  in  buffer  close  testbasicread  input  read  assert  in  tmp  inputstream  assertequals  inbuffer  close
__label__flaky next  parent  init  file  system  non_  existent_  path  case  4:  set  permission  assert  false  generator  default_  umask  create  and  check  permission  fs  default_  permission  case  3:  use  permission  0643  and  umask  0222  file_  dir_  path  check  permission  u  mask  test  directory  creation  set  permission  case  1:  use  default  permission  but  all  possible  umasks  close  file  system  op  get  parent  case  2:  use  permission  0643  and  the  default  umask  get  permission  case  5:  test  non-existent  parent  directory  permission  check  permission  setting  works  correctly  for  file  or  directory  expected  permission  test  permission  setting  r  num_  test_  permissions  file  shouldn\'t  exists  test  file  creation  exists  op  type  next  parent  initfilesystem  non_existent_path   case 4: set permission  assertfalse  generator  default_umask  createandcheckpermission  fs  default_permission   case 3: use permission 0643 and umask 0222  file_dir_path  checkpermission  umask   test directory creation  setpermission   case 1: use default permission but all possible umasks  closefilesystem  op  getparent   case 2: use permission 0643 and the default umask  getpermission   case 5: test non-existent parent directory  permission   check permission setting works correctly for file or directory   expectedpermission  testpermissionsetting  r  num_test_permissions  file shouldn\'t exists   test file creation  exists  optype
__label__nflaky key1  key2  arg_  conf_  prefixed  bind  command  options  extracted  as  list  name  args  list  extract  command  options  assert  true  new  conf  config  file  get  get  boolean  is  empty  conf2  test  dual  conf  args  conf1  assert  equals  args  get  int  running  service  size  7  args  beginning  with  true  file2  launcher  key1  key2  arg_conf_prefixed  bindcommandoptions  extracted  aslist  name  argslist  extractcommandoptions  asserttrue  newconf  configfile  get  getboolean  isempty  conf2  testdualconfargs  conf1  assertequals  args  getint  runningservice  size  7  args beginning with   true  file2  launcher
__label__flaky get  build  info  end_  points  get  property  is_  security_  enabled  get  context  url  oozie  url  assert  equals  wc  get  server  build  version  call  test  server  build  version  build  info  servlet_  classes  run  test  getbuildinfo  end_points  getproperty  is_security_enabled  getcontexturl  oozieurl  assertequals  wc  getserverbuildversion  call  testserverbuildversion  buildinfo  servlet_classes  runtest
__label__nflaky other_  group_  names  proxy  users  refresh  super  user  groups  configuration  assert  authorized  group_  names  default  impersonation  provider  from  the  other  test  case!)  get  proxy  superuser  user  conf  key  conf  proxy_  ip  from  bad  ip  user  group  information  set  proxy  user  ugi  1.2.3.4  1.2.3.5  test  wildcard  user  authorized_  proxy_  user_  name  *  create  remote  user  real_  user_  name  assert  not  authorized  get  test  provider  from  good  ip  first  try  proxying  a  user  that\'s  allowed  get  proxy  superuser  ip  conf  key  proxy_  user_  name  real  user  ugi  create  proxy  user  for  testing  other_group_names  proxyusers  refreshsuperusergroupsconfiguration  assertauthorized  group_names  defaultimpersonationprovider   from the other test case!)  getproxysuperuseruserconfkey  conf  proxy_ip   from bad ip  usergroupinformation  set  proxyuserugi  1.2.3.4  1.2.3.5  testwildcarduser  authorized_proxy_user_name  *  createremoteuser  real_user_name  assertnotauthorized  gettestprovider   from good ip   first try proxying a user that\'s allowed  getproxysuperuseripconfkey  proxy_user_name  realuserugi  createproxyuserfortesting
__label__flaky play  a  server  read  ascii  cache  can  use  criteria  besides  variant  obeyed  add  header  b  get  request  count  open  connection  assert  equals  set  body  url  add  request  property  /  enqueue  get  url  in  memory  response  cache  cache-  control:  max-age=60  connection1  connection4  connection3  connection2  play  a  server  readascii  cachecanusecriteriabesidesvariantobeyed  addheader  b  getrequestcount  openconnection  assertequals  setbody  url  addrequestproperty  /  enqueue  geturl  inmemoryresponsecache  cache-control: max-age=60  connection1  connection4  connection3  connection2
__label__nflaky channel  out  stream  assert  construct  string  like  hello  and  stuff  flush  russian_  hello  inbuf  tmp  write  line  chbuffer  s1  s2  s3  standard  charsets  new  decoder  swiss_  german_  hello  clear  assert  equals  fill  read  line  outbuf  to  byte  array  new  encoder  to  string  new  channel  test  multibyte  coded  read  write  line  append  out  channel  channel  outstream  assert  constructstring  like hello and stuff  flush  russian_hello  inbuf  tmp  writeline  chbuffer  s1  s2  s3  standardcharsets  newdecoder  swiss_german_hello  clear  assertequals  fill  readline  outbuf  tobytearray  newencoder  tostring  newchannel  testmultibytecodedreadwriteline  append  outchannel
__label__flaky banana  play  a  b  syn  reply  android  header  entries  assert  equals  accept  frame  syn_  stream  send  frame  stream  open  stream  count  peer  spdy3  get  response  headers  connection  headers  only  stream  is  closed  after  reply  headers  new  stream  banana  play  a  b  synreply  android  headerentries  assertequals  acceptframe   syn_stream  sendframe  stream  openstreamcount  peer  spdy3  getresponseheaders  connection  headersonlystreamisclosedafterreplyheaders  newstream
__label__nflaky renderable  test  serve  static  normal  operation  modified  no  caching  make  sure  we  get  the  correct  result...  assets  controller  when  result  captor  result  result  check  etag  has  been  called  mime  types  get  renderable  add  etag  response  streams  make  sure  the  content  is  okay...  verify  testasset  ok  render  result2  serve  static  finalize  headers  without  flash  and  session  cookie  byte  array  output  stream  then  return  any  string  capture  we  mocked  this  one:  assert  equals  context  renderable  eq  /assets/testasset.txt  http  cache  toolkit  get  value  get  status  code  results  mockito  any  long  get  content  type  mimetype  get  output  stream  to  string  get  request  path  renderable  testservestaticnormaloperationmodifiednocaching   make sure we get the correct result...  assetscontroller  when  resultcaptor  result  result   check etag has been called  mimetypes  getrenderable  addetag  responsestreams   make sure the content is okay...  verify  testasset  ok  render  result2  servestatic  finalizeheaderswithoutflashandsessioncookie  bytearrayoutputstream  thenreturn  anystring  capture   we mocked this one:  assertequals  contextrenderable  eq  /assets/testasset.txt  httpcachetoolkit  getvalue  getstatuscode  results  mockito  anylong  getcontenttype  mimetype  getoutputstream  tostring  getrequestpath
__label__flaky test  add  x  include  from  reader  abc  print  stack  trace  def  e  foo  prepare  xml  with  include  conf  assert  equals  parent  xml  x  include  failed  fail  bar  oozie.dummy  get  test  case  dir  get  verify  the  properties  from  include  file  default  testaddxincludefromreader  abc  printstacktrace  def  e  foo  preparexmlwithinclude  conf  assertequals  parentxml  xinclude failed  fail  bar  oozie.dummy  gettestcasedir  get   verify the properties from include file  default
__label__nflaky ninja  mode  test  ninja  mode  helper  works  with  prod  set  determine  mode  from  system  properties  set  property  get  ninja  constant  ninja  mode  helper  assert  equals  determine  mode  from  system  properties  or  prod  if  not  set  system  clear  property  ninjamode  testninjamodehelperworkswithprodset  determinemodefromsystemproperties  setproperty  get  ninjaconstant  ninjamodehelper  assertequals  determinemodefromsystempropertiesorprodifnotset  system  clearproperty
__label__flaky cookie  headers  get  server  address  ninja_  flash=\""success=  this+is+a+flashed+success+-+with+placeholder\%3  a+  placeholder\"";  path=/  get  first  header  test  that  static  assets  do  not  set  ninja  cookies  ...  and  static  assets  should  not  set  any  flash  information  ninja  test  browser  new  hash  map  assert  equals  some  empty  headers  for  now...  put  make  request  and  get  response  maps  /redirect  will  send  a  location:  redirect  in  the  headers  assets/files/test_for_mimetypes.dxf  set-  cookie  http  response  cookie  headers  getserveraddress  ninja_flash=\""success=this+is+a+flashed+success+-+with+placeholder\%3a+placeholder\"";path=/  getfirstheader  testthatstaticassetsdonotsetninjacookies   ... and static assets should not set any flash information  ninjatestbrowser  newhashmap  assertequals   some empty headers for now...  put  makerequestandgetresponse  maps   /redirect will send a location: redirect in the headers  assets/files/test_for_mimetypes.dxf  set-cookie  httpresponse
__label__nflaky _mkdirs  default  perm  test  mkdirs_no  dir_bad  umask  invalid  perm  _mkdirs  defaultperm  testmkdirs_nodir_badumask  invalidperm
__label__flaky oryx.input-schema.target-feature  start  server  produce  consume  topics  get  name  oryx.input-schema.feature-names  config  utils  dist  put  num  updates  red  not  testing  the  model  much  here:  get  first  up  node  id  count  map  info  contains  key  oryx.speed.streaming.block-interval-sec  unchecked  count  get  value  encoding  map  get  data  dictionary  \""color\"" \""fruit\""  num_  input  size  should  be  about  9x  more  yellow  oryx.input-schema.numeric-features  overlay  on  is  debug  enabled  fields  yellow  count  pmml  utils  log  fruit  yellow  update  build  categorical  value  encodings  updates  start  messaging  tree  id  should  be  about  9x  more  red  assert  true  fruit  encoding  get  red  count  mapper  read  value    {}  debug  encodings  pmml  app  pmml  utils  assert  equals  model  model   and  then  pairs  of  positive  /  negative  get  config  integer  oryx.speed.streaming.generation-interval-sec  equals  get  second  check  probability  r+  overlay  config  to  string  from  string  r-  oryx.speed.model-manager-class  config  test  rdf  speed  classification  oryx.input-schema.target-feature  startserverproduceconsumetopics  getname  oryx.input-schema.feature-names  configutils  dist  put  numupdates  red   not testing the model much here:  getfirst  up  nodeid  countmap  info  containskey  oryx.speed.streaming.block-interval-sec  unchecked  count  getvalueencodingmap  getdatadictionary  \""color\"" \""fruit\""  num_input  size   should be about 9x more yellow  oryx.input-schema.numeric-features  overlayon  isdebugenabled  fields  yellowcount  pmmlutils  log  fruit  yellow  update  buildcategoricalvalueencodings  updates  startmessaging  treeid   should be about 9x more red  asserttrue  fruitencoding  get  redcount  mapper  readvalue    {}  debug  encodings  pmml  apppmmlutils  assertequals  model   model  and then pairs of positive / negative  getconfig  integer  oryx.speed.streaming.generation-interval-sec  equals  getsecond  checkprobability  r+  overlayconfig  tostring  fromstring  r-  oryx.speed.model-manager-class  config  testrdfspeedclassification
__label__nflaky de  en-  us  optional  then  return  ninja  constant  en  a_propert_with_commas  assert  equals  when  test  correct  parsing  of  delimiters  in  properties  files  prop1   prop2   prop3  of  get  messages  get  string  array  fr-  fr  ninja  properties  lang  de  en-us  optional  thenreturn  ninjaconstant  en  a_propert_with_commas  assertequals  when  testcorrectparsingofdelimitersinpropertiesfiles  prop1  prop2  prop3  of  get  messages  getstringarray  fr-fr  ninjaproperties  lang
__label__flaky get  conf  string  <property><name>  name</name><value>${coord:name()}</value></property>  <configuration><property><name>input  a</name><value>${coord:data  in(\'  a\')}</value></property>  coord  el  functions  </configuration></workflow></action>  <property><name>  actionid</name><value>${coord:action  id()}</value></property>  conf  <coordinator-app  name=\""mycoordinator-app\""  start=\""2009-02-01  t01:00  gmt\""  end=\""2009-02-03  t23:59  gmt\""  timezone=\""  utc\""  create  data  evaluator  <property><name>  actionid</name><value>00000-oozie-  c@1</value></property>  eval  and  wrap  test  create  data  evaluator  <uri-template>file:///tmp/coord/  us/${  year}/${  month}/${  day}</uri-template></dataset></data-in></input-events>  <property><name>  name</name><value>mycoordinator-app</value></property>  frequency=\""720\""  freq_timeunit=\""  minute\""  action  reply  <dataset  name=\""a\""  frequency=\""1440\""  initial-instance=\""2009-01-01  t00:00  z\"">  coord  el  evaluator  pretty  print  xml  utils  get  child  parse  xml  assert  equals  <property><name>  actualtime</name><value>${coord:actual  time()}</value></property>  <configuration><property><name>input  a</name><value>file:///tmp/coord/  us/2009/1/30|file:///tmp/coord/  us/2009/1/31</value></property>  str  job  xml  action-nominal-time=\'2009-09-01  t00:00  z\'  action-actual-time=\'2010-10-01  t00:00  z\'>  </configuration></workflow></action></coordinator-app>  eval  <property><name>  actualtime</name><value>2010-10-01  t00:00  z</value></property>  get  namespace  <input-events><data-in  name=\""  a\""  dataset=\""a\""><uris>file:///tmp/coord/  us/2009/1/30|file:///tmp/coord/  us/2009/1/31</uris>  e  job  to  string  <property><name>  nominaltime</name><value>2009-09-01  t00:00  z</value></property>  <action><workflow><url>http://foobar.com:8080/oozie</url><app-path>hdfs://foobarfoobar.com:9000/usr/tucu/mywf</app-path>  <property><name>  nominaltime</name><value>${coord:nominal  time()}</value></property>  00000-oozie-  c@1  getconfstring  <property><name>name</name><value>${coord:name()}</value></property>  <configuration><property><name>inputa</name><value>${coord:datain(\'a\')}</value></property>  coordelfunctions  </configuration></workflow></action>  <property><name>actionid</name><value>${coord:actionid()}</value></property>  conf  <coordinator-app name=\""mycoordinator-app\"" start=\""2009-02-01t01:00gmt\"" end=\""2009-02-03t23:59gmt\"" timezone=\""utc\""  createdataevaluator  <property><name>actionid</name><value>00000-oozie-c@1</value></property>  evalandwrap  testcreatedataevaluator  <uri-template>file:///tmp/coord/us/${year}/${month}/${day}</uri-template></dataset></data-in></input-events>  <property><name>name</name><value>mycoordinator-app</value></property>   frequency=\""720\"" freq_timeunit=\""minute\""  action  reply  <dataset name=\""a\"" frequency=\""1440\"" initial-instance=\""2009-01-01t00:00z\"">  coordelevaluator  prettyprint  xmlutils  getchild  parsexml  assertequals  <property><name>actualtime</name><value>${coord:actualtime()}</value></property>  <configuration><property><name>inputa</name><value>file:///tmp/coord/us/2009/1/30|file:///tmp/coord/us/2009/1/31</value></property>  str  jobxml   action-nominal-time=\'2009-09-01t00:00z\' action-actual-time=\'2010-10-01t00:00z\'>  </configuration></workflow></action></coordinator-app>  eval  <property><name>actualtime</name><value>2010-10-01t00:00z</value></property>  getnamespace  <input-events><data-in name=\""a\"" dataset=\""a\""><uris>file:///tmp/coord/us/2009/1/30|file:///tmp/coord/us/2009/1/31</uris>  ejob  tostring  <property><name>nominaltime</name><value>2009-09-01t00:00z</value></property>  <action><workflow><url>http://foobar.com:8080/oozie</url><app-path>hdfs://foobarfoobar.com:9000/usr/tucu/mywf</app-path>  <property><name>nominaltime</name><value>${coord:nominaltime()}</value></property>  00000-oozie-c@1
__label__nflaky snippet  resolve  read  from  relative  file  path  to  uri  get  source  location  get  line  number  to  get  lines  assert  equals  first  line  base  dir  assert  size  graceful  w/  bad  from/to  requested?  get  second  line  to  file  source  snippet  helper  to  string  expected  source  location  get  line  number  from  third  line  relative  source  path  snippet  resolve  readfromrelativefilepath  touri  getsourcelocation  getlinenumberto  getlines  assertequals  first line  basedir  assert  size   graceful w/ bad from/to requested?  get  second line  tofile  sourcesnippethelper  tostring  expectedsourcelocation  getlinenumberfrom  third line  relativesourcepath
__label__flaky play  def  okio  go  away  util  header  entries  stream  was  reset:  refused_  stream  get  sink  get  bytes  type_  headers  type_  ping  connection  buffer  protocol_  error  banana  expected  utf-8  fail  is  open  arrays  new  stream  shutdown  ping  play  it  back  android  assert  false  type_  data  verify  the  peer  received  what  was  expected  syn_  stream  3  syn_  stream  1  cola  accept  frame  flush  assert  true  open  stream  count  peer  receive  go  away  round  trip  time  write  utf8  close  take  frame  a  data  stream  1  b  abc  c  set  variant  and  client  stream1  stream2  data1  get  message  assert  equals  syn  stream1  syn  stream2  ensure  the  go_  away  that  resets  stream2  has  been  received.  send  frame  spdy3  equals  ping  sink2  abcdef  sink1  play  def  okio  goaway  util  headerentries  stream was reset: refused_stream  getsink  getbytes  type_headers  type_ping  connection  buffer  protocol_error  banana  expected  utf-8  fail  isopen  arrays  newstream  shutdown  ping   play it back  android  assertfalse  type_data   verify the peer received what was expected   syn_stream 3   syn_stream 1  cola  acceptframe  flush  asserttrue  openstreamcount  peer  receivegoaway  roundtriptime  writeutf8  close  takeframe  a   data stream 1  b  abc  c  setvariantandclient  stream1  stream2  data1  getmessage  assertequals  synstream1  synstream2   ensure the go_away that resets stream2 has been received.  sendframe  spdy3  equals   ping  sink2  abcdef  sink1
__label__nflaky val  set  a+rw  value  of  conf  symbolic  assert  equals  test  some  symbolic  to  octal  settings  get  u  mask  fs  permission  test  symbolic  umasks  short  to  short  val  set  a+rw  valueof  conf  symbolic  assertequals   test some symbolic to octal settings  getumask  fspermission  testsymbolicumasks  short  toshort
__label__flaky end_  points  is_  security_  enabled  submit  oozie  url  run  app  path  assert  true  get  -config  create  workflow.xml  servlet_  classes  close  run  test  app  create  config  file  get  context  url  -run  mock  dag  engine  service  assert  equals  get  file  system  test  run  with  debug  args  call  -oozie  mkdirs  wf  count  to  string  job  -debug  get  fs  test  case  dir  end_points  is_security_enabled  submit  oozieurl  run  apppath  asserttrue  get  -config  create  workflow.xml  servlet_classes  close  runtest  app  createconfigfile  getcontexturl  -run  mockdagengineservice  assertequals  getfilesystem  testrunwithdebug  args  call  -oozie  mkdirs  wfcount  tostring  job  -debug  getfstestcasedir
__label__nflaky still  works   but  leaves  the  breadcrumb  in  place.  cluster  get  zkfc  proxy  start  set  fail  to  fence  generic  test  utils  conf  wait  for  active  lock  holder  set  fail  to  become  standby  get  service  test  graceful  failover  fail  becoming  standby  and  fail  fence  fail  sfe  failover  should  have  failed  when  old  node  wont  fence  graceful  failover  unable  to  fence  assert  exception  contains   still works  but leaves the breadcrumb in place.  cluster  getzkfcproxy  start  setfailtofence  generictestutils  conf  waitforactivelockholder  setfailtobecomestandby  getservice  testgracefulfailoverfailbecomingstandbyandfailfence  fail  sfe  failover should have failed when old node wont fence  gracefulfailover  unable to fence   assertexceptioncontains
__label__flaky coordinator  job  bean  job  conf  bundle  job  get  cmd  log  submit  cmd  get  id  get  status  is  pending  app  path  configuration  parse  error.  read  from  db  :  get  job  sleep  test  bundle  suspend2  bundle  actions  get  cmd  assert  not  null  get  get  auth  token  job  wait  for  coord  get  cmd1  set  coord  get  cmd2  get  conf  job2  job1  add  record  to  bundle  job  table  assert  equals  get  coord  id  execute  bundle.xml  call  services  warn  oozie  client  size  equals  to  string  error  code  job  jpa  service  actions  evaluate  ioe  coordinatorjobbean  jobconf  bundlejobgetcmd  log  submitcmd  getid  getstatus  ispending  apppath  configuration parse error. read from db :  getjob  sleep  testbundlesuspend2  bundleactionsgetcmd  assertnotnull  get  getauthtoken  job  waitfor  coordgetcmd1  set  coordgetcmd2  getconf  job2  job1  addrecordtobundlejobtable  assertequals  getcoordid  execute  bundle.xml  call  services  warn  oozieclient  size  equals  tostring  errorcode  job  jpaservice  actions  evaluate  ioe
__label__nflaky server  content  type  java  version  listener  core  matchers  not  null  value  equal  to  connect  future  some  stuff  listen  endpoint  assert  get  duration  http  version  policy  get  head  get  test  negotiate  protocol  get  address  https  /stuff  get  code  http  version  connect  requester  localhost  get  version  address  http  status  start  result  future1  method  assert  that  execute  target  get  time  unit  get  port  future  timeout  response1  message1  server  contenttype  javaversion  listener  corematchers  notnullvalue  equalto  connectfuture  some stuff  listen  endpoint  assert  getduration  httpversionpolicy  gethead  get  testnegotiateprotocol  getaddress  https  /stuff  getcode  httpversion  connect  requester  localhost  getversion  address  httpstatus  start  resultfuture1  method  assertthat  execute  target  gettimeunit  getport  future  timeout  response1  message1
__label__flaky date  all  script  executor  should_dsl_update_list_prepend  session  local_  one  given  update  simple  eq  consistencylist  consistency  list_  prepend  to  contains  exactly  quorum  when  get  list  of  where  id  row  table  execute  script  template  random  utils  manager  one  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  select  consistencylist  from  simple  where  id  =  then  long  build  date  key  from  base  table  consistency  list  dsl  date  all  scriptexecutor  should_dsl_update_list_prepend  session  local_one   given  update  simple  eq  consistencylist  consistencylist_prependto  containsexactly  quorum   when  getlist  of  where  id  row  table  executescripttemplate  randomutils  manager  one  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  select consistencylist from simple where id =    then  long  builddatekey  frombasetable  consistencylist  dsl
__label__nflaky de  franÃ§ais  en-  us  en-  ca  ninja  constant  language  test  get  with  context  and  result  when  get  cookie  result  of  get  deutsch  context  english  test  that  result  overwrites  context  accept  header  builder  lang  ok  cookie  de-  de  optional  then  return  any  string  en  assert  equals  and  the  result  overwrites  it  again...  results  build  mockito  test  with  context  accept  header  name  messages  get  string  array  en-  uk  fr-  fr  ninja  properties  get  accept  language  that  forced  language  from  context  works  with  empty  result  set  language  de  franÃ§ais  en-us  en-ca  ninjaconstant  language  testgetwithcontextandresult  when  getcookie  result  of  get  deutsch  context  english   test that result overwrites context acceptheader  builder  lang  ok  cookie  de-de  optional  thenreturn  anystring  en  assertequals   and the result overwrites it again...  results  build  mockito   test with context accept header  name  messages  getstringarray  en-uk  fr-fr  ninjaproperties  getacceptlanguage   that forced language from context works with empty result  setlanguage
__label__flaky now  use  start  row  with  inclusive  stop  filter  expected  rows  to  bytes  test  row  one-0  test  row  one-3  set  filter  bytes  test  row  two-0  test  inclusive  stop  filter  verify  scan  if  we  just  use  start/stop  row   we  get  total/2  -  1  rows  expected  keys  test  row  two-3   now use start row with inclusive stop filter  expectedrows  tobytes  testrowone-0  testrowone-3  setfilter  bytes  testrowtwo-0  testinclusivestopfilter  verifyscan   if we just use start/stop row  we get total/2 - 1 rows  expectedkeys  testrowtwo-3
__label__nflaky test  file01  get  path  data  testfile01  get  time  set  file  mtime  in  different  order  to  atime  add  contents  ls  out  set  atime  check  reverse  access  time  order  (-u  -t  -r  options)  testfile03  options  compute  line  format  in  order  testfile02  process  options  verify  testfile05  test  file06  set  mtime  testfile04  test  file04  format  line  atime  test  file05  testfile06  test  file02  test  file03  add  process  path  dir  order  atime  reverse  found  6  items  path  data  line  format  -r  -t  -u  set  is  dir  process  arguments  test  dir  test  directory  set  file  atime  in  different  order  to  file  names  verify  no  more  interactions  now  test  file  mock    testfile01  getpathdata  testfile01  gettime   set file mtime in different order to atime  addcontents  ls  out  setatime   check reverse access time order (-u -t -r options)  testfile03  options  computelineformat  inorder  testfile02  processoptions  verify  testfile05  testfile06  setmtime  testfile04  testfile04  formatlineatime  testfile05  testfile06  testfile02  testfile03  add  processpathdirorderatimereverse  found 6 items  pathdata  lineformat  -r  -t  -u  setisdir  processarguments  testdir  testdirectory   set file atime in different order to file names  verifynomoreinteractions  now  testfile  mock
__label__flaky get  connection  context  session  conf  create  session  get  topic  wf-app-name1  ca  id1  selector  wf  id1  workflow  job  jms  context  =\'  non_matching_user\'  consumer  user1  init  receive  print  stack  trace  e  pass  a  selector  which  wont  match  and  assert  for  null  message  test  workflow  job  selectors  negative  get  message  destroy  message  wf  event  listener  fail  assert  null  on  workflow  job  event  jms  header  constants  wfe  create  consumer  session  getconnectioncontext  session  conf  createsession  gettopic  wf-app-name1  caid1  selector  wfid1  workflowjob  jmscontext  =\'non_matching_user\'  consumer  user1  init  receive  printstacktrace  e   pass a selector which wont match and assert for null message  testworkflowjobselectorsnegative  getmessage  destroy  message  wfeventlistener  fail  assertnull  onworkflowjobevent  jmsheaderconstants  wfe  createconsumer  session
__label__nflaky always  fails  with  fatal  exception  get  class  retry  up  to  maximum  time  with  fixed  sleep  submit  new  single  thread  executor  executors  time  to  fail  and  sleep  get  cause  sleep  future  thread  assert  true  assert  not  null  get  await  interrupt  time  unit  create  latch  count  down  retry  interrupted  unreliable  impl  current  thread  set  sleep  interrupted  e  ute  get  message  assert  equals  retry  proxy  test  retry  interruptible  thread  call  is  alive  future  unreliable  should  return  immediately  exec  alwaysfailswithfatalexception  getclass  retryuptomaximumtimewithfixedsleep  submit  newsinglethreadexecutor  executors   time to fail and sleep  getcause  sleep  futurethread  asserttrue  assertnotnull  get  await  interrupt  timeunit  create  latch  countdown  retry interrupted  unreliableimpl  currentthread  set  sleep interrupted  e  ute  getmessage  assertequals  retryproxy  testretryinterruptible  thread  call  isalive  future  unreliable   should return immediately  exec
__label__flaky get  job  tracker  uri  get  workflow  </name-node>  <configuration>  <java>  \'  modifier\'  assert  false  </configuration>  create  context  fs  action  xml  get  app  file  system  assert  true  get  context  java  action  executor  then  it  equals  group  name  get  acl  user  group  <job-tracker>  get  name  node  uri  job  xml  conf  user  modify  acl  </java>  </job-tracker>  <main-class>  main-  class</main-class>  <name-node>  then  it  should  not  be  overridden  by  group  name  \'  users\'  get  job  file  <property><name>mapreduce.job.acl-modify-job</name><value>  modifier</value></property>  equals  submit  action  users  job  test  acl  modify  job  open  getjobtrackeruri  getworkflow  </name-node> <configuration>  <java>   \'modifier\'  assertfalse  </configuration>  createcontext  fs  actionxml  getappfilesystem  asserttrue  get  context  javaactionexecutor   then it equals group name  getacl  usergroup  <job-tracker>  getnamenodeuri  jobxmlconf  usermodifyacl  </java>  </job-tracker>  <main-class>main-class</main-class>  <name-node>   then it should not be overridden by group name   \'users\'  getjobfile  <property><name>mapreduce.job.acl-modify-job</name><value>modifier</value></property>  equals  submitaction  users  job  testaclmodifyjob  open
__label__nflaky get  all  secrets  seed  system  timeout  assert  array  equals  at  least  once  rand  assert  use  the  same  seed  and  a  \""plain\""  random  so  we  can  predict  the  rng  current  secret  secret  provider  verify  init  rollover  frequency  get  current  secret  destroy  assert  equals  secret2  secret3  roll  secret  secret1  test  get  and  roll  secrets  assert  null  current  time  millis  real  roll  secret  all  secrets  at  least  generate  new  secret  spy  getallsecrets  seed  system  timeout  assertarrayequals  atleastonce  rand  assert   use the same seed and a \""plain\"" random so we can predict the rng  currentsecret  secretprovider  verify  init  rolloverfrequency  getcurrentsecret  destroy  assertequals  secret2  secret3  rollsecret  secret1  testgetandrollsecrets  assertnull  currenttimemillis  realrollsecret  allsecrets  atleast  generatenewsecret  spy
__label__flaky shexec  assert  equals  count  timer  threads  timers  after  before:  execute  system  timers  before  thread  sleep  100  fail  /bin/sleep  bad  command  should  throw  exception  test  shell  command  timer  leak  quick  command  after:  shexec  assertequals  counttimerthreads  timersafter  before:   execute  system  timersbefore  thread  sleep  100  fail  /bin/sleep  bad command should throw exception  testshellcommandtimerleak  quickcommand  after:
__label__nflaky test  constructor  with  quota  check  the  full  constructor  with  quota  information  get  file  and  directory  count  get  space  quota  file  and  directory  count  assert  equals  space  consumed  get  quota  build  quota  quota  usage  file  and  dir  count  space  quota  get  space  consumed  testconstructorwithquota   check the full constructor with quota information  getfileanddirectorycount  getspacequota  fileanddirectorycount  assertequals  spaceconsumed  getquota  build  quota  quotausage  fileanddircount  spacequota  getspaceconsumed
__label__flaky session  given  insert  get  tuple  value  as  list  crud  tuple  when  of  id  map  10  is  not  null  actual  contains  entry  random  utils  manager  one  next  long  assert  that  execute  immutable  map  get  map  get  int  should_insert  tuple2  then  long  select  *  from  complex_tuple  where  id  =  tuple  value  is  equal  to  20  entity  session   given  insert  gettuplevalue  aslist  crud  tuple   when  of  id  map  10  isnotnull  actual  containsentry  randomutils  manager  one  nextlong  assertthat  execute  immutablemap  getmap  getint  should_insert  tuple2   then  long  select * from complex_tuple where id =   tuplevalue  isequalto  20  entity
__label__nflaky verify  paths  test  full  authority  with  other  port  myfs://host.a.b:456  fs  ips  authorities  get  verified  fs  verifypaths  testfullauthoritywithotherport  myfs://host.a.b:456  fs  ips  authorities  getverifiedfs
__label__flaky init  get  name  set  get  conf  test  invalid  groups  mapping  destroy  conf  services     as  list  oozie.service.  groups  service.hadoop.security.group.mapping  services  fail  ex  string  utils  to  string  join  arrays  init  getname  set  getconf  testinvalidgroupsmapping  destroy  conf  services     aslist  oozie.service.groupsservice.hadoop.security.group.mapping  services  fail  ex  stringutils  tostring  join  arrays
__label__nflaky get  class  get  name  make  class  loader  test  jar  test  client  class  loader  it  should  not  throw  an  exception  create  the  test  jar  run  when  test_  jar_2_  name  jar  finder  form  the  args  times  test_  root_  dir  verify  buff_  size  test  jar  un  jar  get  absolute  path  then  return  enable  the  client  classloader  third  class  so  they  can  be  loaded  by  the  application  classloader  system  classes     -  any  application  class  loader  run  run  jar  args  third  cls  get  system  classes  use  client  class  loader  main  cls  run  jar  spy  getclass  getname  makeclassloadertestjar  testclientclassloader   it should not throw an exception   create the test jar  run  when  test_jar_2_name  jarfinder   form the args  times  test_root_dir  verify  buff_size  testjar  unjar  getabsolutepath  thenreturn   enable the client classloader   third class so they can be loaded by the application classloader  systemclasses     -  any  applicationclassloader   run runjar  args  thirdcls  getsystemclasses  useclientclassloader  maincls  runjar  spy
__label__flaky cluster  test  failover  on  connect  timeout  injecting  socket  factory  ha  test  util  successfully.  set  class  conf  when  connecting  to  the  first  nn.  fs  configure  failover  fs  make  the  second  nn  the  active  one.  shutdown  name  node  common  configuration  keys  public  io  utils  transition  to  active  test_  file  close  stream  get  name  node  port  create  cluster  testfailoveronconnecttimeout  injectingsocketfactory  hatestutil   successfully.  setclass  conf   when connecting to the first nn.  fs  configurefailoverfs   make the second nn the active one.  shutdownnamenode  commonconfigurationkeyspublic  ioutils  transitiontoactive  test_file  closestream  getnamenodeport  create
__label__nflaky r2  get  name  output  test.*.source.filter.exclude  get  test  filename  test  put  metrics  when  we  call  stop   at  most  two  sources  will  be  consumed  by  each  sink  thread.  s0  s1  test  init  first  verify  call  backs  add  check  metrics  records  ms  get  all  values  capture  test.sink.test.class  mr2  mr1  s1  desc  stop  *.period  test  metrics  config  test.sink.sink1.metric.filter.exclude  mock  shutdown  s0rec  publish  the  metrics  test.sink.sink2.metric.filter.exclude  save  test.source.s1.metric.filter.exclude  timeout  x*  times  verify  sink2  desc  hadoop-metrics2-test  s1rec  set  register  sink  default  metrics  system  incr  start  sink1  desc  assert  equals  y*  s0  desc  sink2  sink1  publish  metrics  now  register  r1  r2  getname  output  test.*.source.filter.exclude  gettestfilename  test  putmetrics   when we call stop  at most two sources will be consumed by each sink thread.  s0  s1  testinitfirstverifycallbacks  add  checkmetricsrecords  ms  getallvalues  capture  test.sink.test.class  mr2  mr1  s1 desc  stop  *.period  testmetricsconfig  test.sink.sink1.metric.filter.exclude  mock  shutdown  s0rec   publish the metrics  test.sink.sink2.metric.filter.exclude  save  test.source.s1.metric.filter.exclude  timeout  x*  times  verify  sink2 desc  hadoop-metrics2-test  s1rec  set  registersink  defaultmetricssystem  incr  start  sink1 desc  assertequals  y*  s0 desc  sink2  sink1  publishmetricsnow  register  r1
__label__flaky cluster  test  repl  due  to  node  fail  respects  rack  policy  ns  only  1  rack  for  all  the  replicas  racks  dm  conf  /rack2  get  block  manager  wait  for  replication  /rack1  fs  create  file  short  one  rack  and  therefore  need  one  replica  *  test  that  when  a  block  is  replicated  because  a  replica  is  lost  due  *  to  host  failure  the  the  rack  policy  is  preserved.  get  datanode  manager  create  a  file  with  one  block  with  a  replication  factor  of  2  get  it  should  have  been  replicated  within  the  same  rack.  stop  data  node  dfs  test  util  b  get  data  nodes  get  conf  file  path  dn  id  get  file  system  data  node  replication_  factor  get  name  node  datanodes  /test  file  last  datanode  is  on  a  different  rack  size  build  remove  datanode  num  data  nodes  calling  remove  datanode  and  stopping  it.  idx  get  first  block  shutdown  get  datanode  id  get  namesystem  cluster  testreplduetonodefailrespectsrackpolicy  ns   only 1 rack for all the replicas  racks  dm  conf  /rack2  getblockmanager  waitforreplication  /rack1  fs  createfile   short one rack and therefore need one replica       * test that when a block is replicated because a replica is lost due     * to host failure the the rack policy is preserved.       getdatanodemanager   create a file with one block with a replication factor of 2  get   it should have been replicated within the same rack.  stopdatanode  dfstestutil  b  getdatanodes  getconf  filepath  dnid  getfilesystem  datanode  replication_factor  getnamenode  datanodes  /testfile   last datanode is on a different rack  size  build  removedatanode  numdatanodes   calling removedatanode and stopping it.  idx  getfirstblock  shutdown  getdatanodeid  getnamesystem
__label__nflaky have  to  sleep  to  allow  time  for  the  clients  to  reconnect.  stop  server  connection_  timeout  wait  for  elector  state  check  fatals  and  reset  active  standby  elector  test  util  thread  sleep  never  start  server  cbs  mockito  become  active  state  ensure  parent  z  node  verify  host  port  electors  test  dont  join  election  on  disconnect  and  reconnect  wait  for  server  up   have to sleep to allow time for the clients to reconnect.  stopserver  connection_timeout  waitforelectorstate  checkfatalsandreset  activestandbyelectortestutil  thread  sleep  never  startserver  cbs  mockito  becomeactive  state  ensureparentznode  verify  hostport  electors  testdontjoinelectionondisconnectandreconnect  waitforserverup
__label__flaky ce  foo  assert  equals  test  parse  filter  positive  parse  filter  frequency  unit  300  size  failed  get  minute  map  user  frequency=5;unit=hours;user=foo;status=  failed  status  ce  foo  assertequals  testparsefilterpositive  parsefilter  frequency  unit  300  size  failed  get  minute  map  user  frequency=5;unit=hours;user=foo;status=failed  status
__label__nflaky add  a  b  \%  \\\%\\(\\t\\)\\r   \\\%  )  token  assert  equals  \%x\\_a  tokenize  witness  test  escape  \%x\\)  tl  \\\\\%x  \%x\\_\%b  \%(  )  \\  add  a  b  \%  \\\%\\(\\t\\)\\r   \\\%  )  token  assertequals  \%x\\_a  tokenize  witness  testescape  \%x\\)  tl  \\\\\%x  \%x\\_\%b  \%(\t)    \\
__label__flaky m  executor  service  open  close  test  user_create  file  assert  false  is  connected  constants  master  client  /file  get  master  address  assert  assert  true  get  file  status  m  master  info  close  connect  mexecutorservice    openclosetest  user_createfile  assertfalse  isconnected  constants  masterclient  /file  getmasteraddress  assert  asserttrue  getfilestatus  mmasterinfo  close  connect
__label__nflaky test  do  s  a  b  c  after  one  interval   should  still  have  enough  hits  to  be  banned  test  d  assert  false  timer  time  ms  after  building  up  a  ban  again   and  letting  plenty  of  time  elapse   should  un-ban  thread  sleep  timer  max  access  per  time  2  requests  allowed  per  time;  3rd  should  be  banned  assert  true  build  up  a  lot  of  hits  tracker  is  banned  after  max  3  others  are  tracked   a  should  be  reset/evicted  and  un-ban  testdos  a  b  c   after one interval  should still have enough hits to be banned  test  d  assertfalse  timertimems   after building up a ban again  and letting plenty of time elapse  should un-ban  thread  sleep  timer  maxaccesspertime   2 requests allowed per time; 3rd should be banned  asserttrue   build up a lot of hits  tracker  isbanned   after max 3 others are tracked  a should be reset/evicted and un-ban
__label__flaky receive  message  get  observer  reference  observer  garbage  collection  create  stage  ref1  this  fails  because  the  garbage  collector  will  have  disposed  of  the  observer  system  observer1  join  gc  expect  exception  stage1  receivemessage  getobserverreference  observergarbagecollection  createstage  ref1   this fails because the garbage collector will have disposed of the observer  system  observer1  join  gc  expectexception  stage1
__label__nflaky fs.default  fs  my  file  get  localized  message  val2  assert  false  val1  conf  run  fs  second   create  a  file  in  that  directory.  system  assert  true  file  system  10  minute  test  existing  file  trash  mkdir  write  file  test_  dir  set  fs_  trash_  interval_  key  e  test/mkdirs/my  existing  file  set  class  disabled  -rm  set  conf  second  rm  a  file  which  parent  path  is  the  same  as  above  first  rm  a  file  set  long  exception  raised  from  trash.run  my  sub  file  shell  get  local  first  create  a  new  directory  with  mkdirs  is  enabled  args1  test/mkdirs  args2  to  string  fs.file.impl  get  uri  my  path  fs.defaultfs  myfile  getlocalizedmessage  val2  assertfalse  val1  conf  run  fs   second  create a file in that directory.  system  asserttrue  filesystem   10 minute  testexistingfiletrash  mkdir  writefile  test_dir  set  fs_trash_interval_key  e  test/mkdirs/myexistingfile  setclass   disabled  -rm  setconf   second  rm a file which parent path is the same as above   first rm a file  setlong  exception raised from trash.run   mysubfile  shell  getlocal   first create a new directory with mkdirs  isenabled  args1  test/mkdirs  args2  tostring  fs.file.impl  geturi  mypath
__label__flaky init  -ve  test  coord  el  functions  ${coord:database  in(\'  abcd\')}  ${coord:database  in(\'  abc\')}  *  database  out  set  variable  ${coord:database  out(\'  abc\')}  ${coord:database  out(\'  abcd\')}  +ve  test  assert  equals  data-in  coord-job-submit-data  fail  should  throw  exception  because  data-in  abcd  is  not  defiend  eval  eval  and  wrap  should  throw  exception  because  data-out  abcd  is  not  defiend  *  database  in  test  database  ph1  expr  oozie.dataname.  abc  data-out  init   -ve test  coordelfunctions  ${coord:databasein(\'abcd\')}  ${coord:databasein(\'abc\')}             * databaseout             setvariable  ${coord:databaseout(\'abc\')}  ${coord:databaseout(\'abcd\')}   +ve test  assertequals  data-in  coord-job-submit-data  fail  should throw exception because data-in abcd is not defiend  eval  evalandwrap  should throw exception because data-out abcd is not defiend             * databasein             testdatabaseph1  expr  oozie.dataname.abc  data-out
__label__nflaky test  clear  underlying  byte  array  length  must  be  zero  clear  actual  string  on  an  empty  text  object  must  be  an  empty  string  assert  equals  test  if  clear  works  as  intended  abcdâ‚¬bdcdâ‚¬  get  bytes  length  of  the  string  must  be  reset  to  0  after  clear()  len  assert  true  string\'s  length  must  be  zero  get  length  to  string  string  must  be  empty  after  clear()  length  of  the  byte  array  must  not  decrease  after  clear()  text  test  lengths  on  an  empty  text  object    testclear  underlying byte array length must be zero  clear  actual string on an empty text object must be an empty string  assertequals   test if clear works as intended  abcdâ‚¬bdcdâ‚¬  getbytes  length of the string must be reset to 0 after clear()  len  asserttrue  string\'s length must be zero  getlength  tostring  string must be empty after clear()  length of the byte array must not decrease after clear()  text   test lengths on an empty text object
__label__flaky test  case  where  dir-files=false   recursive=false  chgrp  <fs/>  dir  fs  create  context  set  owner  path  get  test  group  test  group  get  file  status  context  test  user  grandchild  get  test  group2  revert  to  testgroup  ae  test  group2  assert  equals  get  file  system  get  test  user  test  chgrp  mkdirs  get  group  to  string  get  fs  test  case  dir  child   test case where dir-files=false  recursive=false  chgrp  <fs/>  dir  fs  createcontext  setowner  path  gettestgroup  testgroup  getfilestatus  context  testuser  grandchild  gettestgroup2   revert to testgroup  ae  testgroup2  assertequals  getfilesystem  gettestuser  testchgrp  mkdirs  getgroup  tostring  getfstestcasedir  child
__label__nflaky data  bytes  ec  bytes  generate  ec  bytes  bytes  encoder  expected  high-order  zero  coefficient  case.  assert  equals  http://www.swetake.com/qr/qr9.html  test  generate  ec  bytes  databytes  ecbytes  generateecbytes  bytes  encoder  expected   high-order zero coefficient case.  assertequals   http://www.swetake.com/qr/qr9.html  testgenerateecbytes
__label__flaky test  kill  coord  purge  x  command  get  id  coord  job  get  executor  get  status  add  record  to  coord  action  table  coord  action  get  executor  get  error  code  assert  not  null  coordinator  action  should  have  been  purged  get  coordinator  action  action  coordinator  job  should  have  been  purged  assert  equals  execute  add  record  to  coord  job  table  call  coordinator  job  services  fail  coord-action-get.xml  error  code  je  job  jpa  service  testkillcoordpurgexcommand  getid  coordjobgetexecutor  getstatus  addrecordtocoordactiontable  coordactiongetexecutor  geterrorcode  assertnotnull  coordinator action should have been purged  get  coordinatoraction  action  coordinator job should have been purged  assertequals  execute  addrecordtocoordjobtable  call  coordinatorjob  services  fail  coord-action-get.xml  errorcode  je  job  jpaservice
__label__nflaky bind  create  injector  start  equal  to  mock  service  configure  injector  assert  that  service  should  not  be  started  if  explicitly  bound  and  not  singleton  bind  createinjector  start  equalto  mockservice  configure  injector  assertthat  serviceshouldnotbestartedifexplicitlyboundandnotsingleton
__label__flaky cluster  conf  test  file  creation  delete  parent:  create  file2.  create  file  wait  active  this  ensures  that  leases  are  persisted  in  fsimage.  ipc.client.connection.maxidletime  move  dir1  while  file1  is  open  newfile  test  while  open  rename  parent  to  nonexistent  dir  2s  dfs  config  keys  format  create  file1.  get  file  system  test  2************************************  set  int  persistent  leases  from  fsimage.  stm2  max_  idle_  time  stm1  /user/dir1  nnport  /user/dir2  /user/dir3  get  name  node  port  shutdown  name  node  port  create  cluster  fs  system  sleep  hflush  assert  true  close  write  file  dir3  created  file  dir2  dir1  test  file  creation  thread  check  full  file  dfs.support.append  build  rename  file2  exists  file1  set  boolean  cluster  conf  testfilecreationdeleteparent:    create file2.  createfile  waitactive   this ensures that leases are persisted in fsimage.  ipc.client.connection.maxidletime   move dir1 while file1 is open  newfile  testwhileopenrenameparenttononexistentdir   2s  dfsconfigkeys  format   create file1.  getfilesystem  test 2************************************  setint   persistent leases from fsimage.  stm2  max_idle_time  stm1  /user/dir1  nnport  /user/dir2  /user/dir3  getnamenodeport  shutdown  namenodeport   create cluster  fs  system  sleep  hflush  asserttrue  close  writefile  dir3  created file   dir2  dir1  testfilecreation  thread  checkfullfile  dfs.support.append  build  rename  file2  exists  file1  setboolean
__label__nflaky integer  fail  assert  tmp  test  invalid  append  buffer  index  out  of  bounds  exception  should  have  been  thrown  append  integer  fail  assert  tmp  testinvalidappend  buffer  indexoutofboundsexception should have been thrown  append
__label__flaky 2009-12-15  t01:00  z  get  id  coord  job  get  executor  get  status  add  record  to  coord  action  table  assert  not  null  get  coordinator  action  job  init  rest  constants  false  destroy  assert  equals  services  execute  add  record  to  coord  job  table  call  services  set  system  property  test  coord  rerun  in  done  with  error  status  transit  service  job  jpa  service  coord-rerun-action1.xml  2009-12-15t01:00z  getid  coordjobgetexecutor  getstatus  addrecordtocoordactiontable  assertnotnull  get  coordinatoraction  job  init  restconstants  false  destroy  assertequals  services  execute  addrecordtocoordjobtable  call  services  setsystemproperty  testcoordrerunindonewitherror  statustransitservice  job  jpaservice  coord-rerun-action1.xml
__label__nflaky calendar  last  flush  time  should  have  been  null  prior  to  calling  init()  rfs  sink  set  now  try  pathological  settings  get  time  calendar  get  time  in  millis  diff  assert  equals  test  set  initial  flush  time  assert  null  try  again  with  a  random  offset  assert  true  the  initial  flush  time  was  calculated  incorrectly  get  instance  set  initial  flush  time  the  initial  flush  time  was  calculated  incorrectly:  calendar  last flush time should have been null prior to calling init()  rfssink  set   now try pathological settings  gettime  calendar  gettimeinmillis  diff  assertequals  testsetinitialflushtime  assertnull   try again with a random offset  asserttrue  the initial flush time was calculated incorrectly  getinstance  setinitialflushtime  the initial flush time was calculated incorrectly:
__label__flaky add  get  buffer  pool  return  buffer  clear  assert  equals  test  weak  ref  clearing  bufs  system  buf  gc.  weak  refs  should  get  cleared.  references  from  the  pool.  lists  allocate  and  return  10  buffers.  new  linked  list  gc  count  buffers  of  size  add  getbuffer  pool  returnbuffer  clear  assertequals  testweakrefclearing  bufs  system  buf   gc. weak refs should get cleared.   references from the pool.  lists   allocate and return 10 buffers.  newlinkedlist  gc  countbuffersofsize
__label__nflaky args  get  property  test  args  parsing  foo  user.name  12345  assert  equals  :12345  foo:2222  system  args    getproperty  testargsparsing  foo  user.name  12345  assertequals  :12345  foo:2222  system
__label__flaky wf  job  a  wf  job  b  add  record  to  wf  action  table  get  id  workflow  instance  subwf  action  b  subwf  job  b  test  get  workflow  parent  add  record  to  wf  job  table  subwf  action  a2  children  assert  not  null  subwf  action  a1  get  workflow  job  subwf  job  a1  subwf  job  a2  execute  check  children  services  1  workflow  action  add  all  wf  action  a  jpa  service  wf  action  b  wfjoba  wfjobb  addrecordtowfactiontable  getid  workflowinstance  subwfactionb  subwfjobb  testgetworkflowparent  addrecordtowfjobtable  subwfactiona2  children  assertnotnull  subwfactiona1  get  workflowjob  subwfjoba1  subwfjoba2  execute  checkchildren  services  1  workflowaction  addall  wfactiona  jpaservice  wfactionb
__label__nflaky request  conn  illegal  argument  exception  expected  method  test  invalid  input  execute  /  fail  assert  mockito  response  executor  http  core  context  context  httprocessor  create  mock  pre  process  ok  post  process  request  conn  illegalargumentexception expected  method  testinvalidinput  execute  /  fail  assert  mockito  response  executor  httpcorecontext  context  httprocessor  create  mock  preprocess  ok  postprocess
__label__flaky file_  size  cluster  after  sequence  of  calls  append()/write()/hflush()  shouldn\'t  be  null  some  more  stuff  to  write  dn  create  file  rand  hdfs  server  constants  should  be  rbw  replica  on  get  block  pool  id  get  data  nodes  get  method  name  log  generic  test  utils  running  /  get  wrapped  stream  write  bytes  replica  on  dn  is  debug  enabled  pipeline_01  .dat  repl_  factor  get  block  locations  get  located  blocks  bpid  invoking  append  but  doing  nothing  otherwise...  fs  hflush  get  block  id  assert  true  get  close  dfs  test  util  get  block  debug  file  path  assert  equals  get  name  node  rpc  fetch  replica  info  next  long  r  get  state  lb  method_  name  to  string  ofs  data  node  adapter  append  get  namesystem  file_size  cluster   after sequence of calls append()/write()/hflush()   shouldn\'t be null  some more stuff to write  dn  createfile  rand  hdfsserverconstants  should be rbw replica on   getblockpoolid  getdatanodes  getmethodname  log  generictestutils  running   /  getwrappedstream  writebytes  replica on dn   isdebugenabled  pipeline_01  .dat  repl_factor  getblocklocations  getlocatedblocks  bpid  invoking append but doing nothing otherwise...  fs  hflush  getblockid  asserttrue  get  close  dfstestutil  getblock  debug  filepath  assertequals  getnamenoderpc  fetchreplicainfo  nextlong  r  getstate  lb  method_name  tostring  ofs  datanodeadapter  append  getnamesystem
__label__nflaky key1  key2  value2  value1  key3  keys  value3  values  compare  to  b  value  in  map  get  bytes  put  assert  true  get  last  key  key  set  key  this  will  work  because  we  know  what  we  put  into  each  set  get  key  a  b  maps  e  entry  set  map2  contains  key  map1  copy  of  map  of  maps  unchecked  assert  equals  test  sorted  map  writable  get  value  size  map  of  maps  first  key  now  for  something  a  little  harder...  out  map  a  value  key1  key2  value2  value1  key3  keys  value3  values  compareto  bvalue  inmap  getbytes  put  asserttrue  get  lastkey  keyset  key   this will work because we know what we put into each set  getkey  a  b  maps  e  entryset  map2  containskey  map1  copyofmapofmaps  unchecked  assertequals  testsortedmapwritable  getvalue  size  mapofmaps  firstkey   now for something a little harder...  outmap  avalue
__label__flaky date  with  serial  consistency  level  given  simple  0  am  when  id  log  asserter  is  not  null  should_dsl_update_value_if_equal  random  utils  with  result  set  async  listener  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  if_  value  success  then  long  build  date  key  from  base  table  dsl  rs  set  script  executor  session  update  select  value  from  simple  where  id  =  with  lwt  result  listener  eq  of  get  where  get  and  set  row  value  table  execute  script  template  prepare  log  level  for  driver  connection  serial  on  error  manager  one  get  string  next  long  assert  serial  consistency  levels  is  true  new  value  was  applied  is  equal  to  on  success  date  withserialconsistencylevel   given  simple  0 am   when  id  logasserter  isnotnull  should_dsl_update_value_if_equal  randomutils  withresultsetasynclistener  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  if_value  success   then  long  builddatekey  frombasetable  dsl  rs  set  scriptexecutor  session  update  select value from simple where id =   withlwtresultlistener  eq  of  get  where  getandset  row  value  table  executescripttemplate  prepareloglevelfordriverconnection  serial  onerror  manager  one  getstring  nextlong  assertserialconsistencylevels  istrue  new value  wasapplied  isequalto  onsuccess
__label__nflaky selection  key  verify  no  more  interactions  get  window  test  window  update  update  verify  assert  equals  set  event  window  eq  io  session  selectionkey  verifynomoreinteractions  getwindow  testwindowupdate  update  verify  assertequals  setevent  window  eq  iosession
__label__flaky get  block  locations  b  get  block  start  writing  a  file  but  do  not  close  it  src  blocks  foo  test  abandon  block  dfs  client  adapter  fs  dfsclient  abandon  block  and  close  the  file  now  abandon  the  last  block  hflush  file_  name_  prefix  fout  get  namenode  create  write  close  get  dfs  client  get  last  located  block  getblocklocations  b  getblock   start writing a file but do not close it  src  blocks  foo  testabandonblock  dfsclientadapter  fs  dfsclient  abandonblock   and close the file   now abandon the last block  hflush  file_name_prefix  fout  getnamenode  create  write  close  getdfsclient  getlastlocatedblock
__label__nflaky next  get  block  locations  dir1  assert  false  file1  file2  file3  fs  test  empty  directory  delete  remove  file_  len  assert  true  get  len  get  path  list  files  write  file  files  to  find  test_  dir  unexpected  add  stat  is  file  test  more  complicated  directory  is  empty  has  next  assert  equals  path  test  directory  testing  directory  with  1  file  mkdirs  make  qualified  itor  next  getblocklocations  dir1  assertfalse  file1  file2  file3  fs   test empty directory  delete  remove  file_len  asserttrue  getlen  getpath  listfiles  writefile  filestofind  test_dir   unexpected  add  stat  isfile   test more complicated directory  isempty  hasnext  assertequals  path   testdirectory   testing directory with 1 file  mkdirs  makequalified  itor
__label__flaky reinitialize  new  application  id  handle  assert  equals  app  attempt  id  assert  test  app  attempt  metrics  schedular  app  id  get  root  queue  metrics  get  apps  submitted  new  application  attempt  id  metrics  event  dispatcher  rm  context  user  builder  utils  queue  reinitialize  newapplicationid  handle  assertequals  appattemptid  assert  testappattemptmetrics  schedular  appid  getrootqueuemetrics  getappssubmitted  newapplicationattemptid  metrics  event  dispatcher  rmcontext  user  builderutils  queue
__label__nflaky fencer  mock_  target  test  short  name  ssh  with  user  port  assert  false  sshfence(user:123)  fence  setup  fencer  fencer  mock_target  testshortnamesshwithuserport  assertfalse  sshfence(user:123)  fence  setupfencer
__label__flaky get  time  check  coord  jobs  assert  false  test  coord  change  end  time  get  id  date  utils  get  status  parse  date  oozie  tz  coord  get  cmd  coord  job  pause  time  get  start  time  job  ;pausetime=  print  stack  trace  endtime=  assert  equals  convert  date  to  string  execute  add  record  to  coord  job  table  new  end  time  invalid  date  call  coordinator  job  fail  services  ex  is  done  materialization  end  time  job  jpa  service  gettime  checkcoordjobs  assertfalse  testcoordchangeendtime  getid  dateutils  getstatus  parsedateoozietz  coordgetcmd  coordjob  pausetime  get  starttime  job  ;pausetime=  printstacktrace  endtime=  assertequals  convertdatetostring  execute  addrecordtocoordjobtable  newendtime  invalid date  call  coordinatorjob  fail  services  ex  isdonematerialization  endtime  job  jpaservice
__label__nflaky http://host3:9600/kms/foo/v1/  test  creation  kp  get  kms  url  get  providers  kms://http@host1;host2;host3:9600/kms/foo  http://host1:9600/kms/foo/v1/  conf  assert  equals  create  provider  new  hash  set  assert  true  sets  http://host2:9600/kms/foo/v1/  kms://http@host1:9600/kms/foo  providers  http://host3:9600/kms/foo/v1/  testcreation  kp  getkmsurl  getproviders  kms://http@host1;host2;host3:9600/kms/foo  http://host1:9600/kms/foo/v1/  conf  assertequals  createprovider  newhashset  asserttrue  sets  http://host2:9600/kms/foo/v1/  kms://http@host1:9600/kms/foo  providers
__label__flaky get  runtime  dir  init  get  system  id  get  property  test  default  services  oozie-  destroy  user.name  should  be  services  system  oozie-dummy.xml  services  assert  true  assert  not  null  set  system  property  get  exists  configuration  service  starts  with    getruntimedir  init  getsystemid  getproperty  testdefaultservices  oozie-  destroy  user.name  shouldbe  services  system  oozie-dummy.xml  services  asserttrue  assertnotnull  setsystemproperty  get  exists  configurationservice  startswith
__label__nflaky get  key  version  get  metadata  cache  mock  key  c  get  current  key  get  conf  k1  then  return  k1@0  assert  equals  delete  key  asserting  the  cache  is  purged  test  delete  key  eq  l  when  times  assert  mockito  mock  verify  mock  prov  getkeyversion  getmetadata  cache  mockkey  c  getcurrentkey  getconf  k1  thenreturn  k1@0  assertequals  deletekey   asserting the cache is purged  testdeletekey  eq  l  when  times  assert  mockito  mock  verify  mockprov
__label__flaky uri  handler  factory  dt=09  get  launcher  config  handler  get  uri  handler  dt=03  assert  false  uri  service  get  partition  dir  conf  delete  year=2012;month=12;dt=02;country=us  test  delete  assert  true  get  partitions  month=12;country=us  uri  handler  hcat  uri  table  country=us  drop  test  table  assert  equals  get  file  system  year=2012;month=12  create  test  table  create  partition  for  test  delete  get  test  user  size  location1  location2  exists  db  year=2012;month=12;dt=03;country=us  get  h  cat  uri  urihandlerfactory  dt=09  getlauncherconfig  handler  geturihandler  dt=03  assertfalse  uriservice  getpartitiondir  conf  delete  year=2012;month=12;dt=02;country=us  testdelete  asserttrue  getpartitions  month=12;country=us  urihandler  hcaturi  table  country=us  droptesttable  assertequals  getfilesystem  year=2012;month=12  createtesttable  createpartitionfortestdelete  gettestuser  size  location1  location2  exists  db  year=2012;month=12;dt=03;country=us  gethcaturi
__label__nflaky we  still  can  scan  records  in  an  unsorted  t  file  reader  conf  vbuf  test  scan  get  key  length  now  try  get  value  first  fs  advance  path  get  len  get  file  status  scanner  value  m  kbuf  get  key  get  value  length  vlen  key  z  is  false  assert  that  create  scanner  value  z  entry  get  value  klen  buf_  size  is  sorted  get  entry  count  key  m  is  equal  to  open  read  key  and  value   we still can scan records in an unsorted tfile  reader  conf  vbuf  testscan  getkeylength   now try get value first  fs  advance  path  getlen  getfilestatus  scanner  valuem  kbuf  getkey  getvaluelength  vlen  keyz  isfalse  assertthat  createscanner  valuez  entry  getvalue  klen  buf_size  issorted  getentrycount  keym  isequalto  open   read key and value
__label__flaky @  close  trx  coord  client  get  store  get  time  local  oozie  2009-12-15  t01:00  z  could  not  update  db.  get  status  -test  coord  rerun-  c  get  coord  client  get  begin  trx  coordinator  action  re  run  coord  commit  trx  action  num  rest  constants  print  stack  trace  store1  e  store2  test  coord  rerun  date1  assert  equals  store  add  record  to  job  table  job  id  services  fail  coordinator  job  add  record  to  action  table  assert  not  same  action  id  0000000-  action1  action2  coord-rerun-action1.xml  get  coordinator  action  @  closetrx  coordclient  getstore  gettime  localoozie  2009-12-15t01:00z  could not update db.  getstatus  -testcoordrerun-c  getcoordclient  get  begintrx  coordinatoraction  reruncoord  committrx  actionnum  restconstants  printstacktrace  store1  e  store2  testcoordrerundate1  assertequals  store  addrecordtojobtable  jobid  services  fail  coordinatorjob  addrecordtoactiontable  assertnotsame  actionid  0000000-  action1  action2  coord-rerun-action1.xml  getcoordinatoraction
__label__nflaky 123456789  teststrs  assert  false  channel  out  stream  which  is  only  16  bytes  for  this  test  assert  hello  flush  inbuf  this  string  should  be  much  longer  than  the  size  of  the  line  buffer  write  line  buffer  chbuffer  clear  teststr  this  write  operation  should  have  no  effect  assert  equals  fill  read  line  outbuf  to  byte  array  and  stuff  like  that  to  string  new  channel  append  out  channel  and  goodbye  test  basic  read  write  line    123456789   teststrs  assertfalse  channel  outstream  which is only 16 bytes for this test  assert  hello  flush  inbuf  this string should be much longer than the size of the line buffer   writeline  buffer  chbuffer  clear  teststr   this write operation should have no effect  assertequals  fill  readline  outbuf  tobytearray  and stuff like that  tostring  newchannel  append  outchannel  and goodbye  testbasicreadwriteline
__label__flaky set  push  missing  dependencies  coord  el  functions  get  user  get  id  poll  add  record  to  coord  action  table  coord  coordinator  x  command  my  cmd  assert  not  null  case  3:  both  types  get  coordinator  action  action  event  test  coordinator  action  event  dependencies  get  app  name  generate  event  assert  equals  execute  set  missing  dependencies  case  2:  only  hcat  (push)  missing  deps  add  record  to  coord  job  table  push  call  coordinator  job  services  pull  coord-action-get.xml  case  1:  only  pull  missing  deps  jpa  service  queue  get  missing  deps  setpushmissingdependencies  coordelfunctions  getuser  getid  poll  addrecordtocoordactiontable  coord  coordinatorxcommand  mycmd  assertnotnull   case 3: both types  get  coordinatoraction  action  event  testcoordinatoractioneventdependencies  getappname  generateevent  assertequals  execute  setmissingdependencies   case 2: only hcat (push) missing deps  addrecordtocoordjobtable  push  call  coordinatorjob  services  pull  coord-action-get.xml   case 1: only pull missing deps  jpaservice  queue  getmissingdeps
__label__nflaky normal  script  create  node  health  script  timer  task  node  health  status  reported  healthy  even  after  timeout  assert  false  @echo  off  ping  -n  4  127.0.0.1  >nul  echo  \""  i  am  fine\""  write  node  health  script  file  conf  run  timeout  script.  node  health  script  runner  normal  script  runs  successfully  is  healthy  sleep  4  echo  \""  i  am  fine\""  shell  healthy  script.  node  health  status  reported  unhealthy  exit  127  assert  true  time  out  script  exit  code  127  error  init  error  script.  error  script  is  empty  get  health  report  assert  equals  get  timer  task  test  node  health  script  echo  \""  i  am  all  fine\""  run  timer  contains  exit  code  script  node  health  script  runner  node  health  status  reported  healthy  echo  error  echo  \""  tracker  not  healthy\""    normalscript  createnodehealthscript  timertask  node health status reported healthy even after timeout  assertfalse  @echo off  ping -n 4 127.0.0.1 >nul  echo \""i am fine\""  writenodehealthscriptfile  conf  run   timeout script.  nodehealthscriptrunner   normal script runs successfully  ishealthy  sleep 4  echo \""i am fine\""  shell   healthy script.  node health status reported unhealthy  exit 127  asserttrue  timeoutscript   exit code 127  error  init   error script.  errorscript  isempty  gethealthreport  assertequals  gettimertask  testnodehealthscript  echo \""i am all fine\""   run timer  contains  exitcodescript  nodehealthscriptrunner  node health status reported healthy  echo error   echo \""tracker not healthy\""
__label__flaky given  .installed  resolve  alpha.jar  will  return  assert  that  as  list  bravo  charlie.jar  get  names  of  files  in  lib  bravo.jar  uninstall  install  alpha  install  and  uninstall  with  common  dependencies  create  temporary  file  contains  in  any  order  arrays  charlie  given  .installed  resolve  alpha.jar  willreturn  assertthat  aslist  bravo  charlie.jar  getnamesoffilesinlib  bravo.jar  uninstall  install  alpha  installanduninstallwithcommondependencies  createtemporaryfile  containsinanyorder  arrays  charlie
__label__nflaky test  too  long  chunk  header  dst  codec  test  utils  convert  metrics2  metrics1  assert  assert  true  message  constraint  exception  expected  is  completed  read  standard  charsets  has  remaining  5;  and  some  very  looooong  comment  12345  0  decoder1  clear  channel1  inbuf1  assert  equals  channel2  decoder2  byte  buffer  inbuf2  fail  allocate  12345  testtoolongchunkheader  dst  codectestutils  convert  metrics2  metrics1  assert  asserttrue  messageconstraintexception expected  iscompleted  read  standardcharsets  hasremaining  5; and some very looooong comment  12345  0    decoder1  clear  channel1  inbuf1  assertequals  channel2  decoder2  bytebuffer  inbuf2  fail  allocate  12345
__label__flaky coord  el  functions  tz  action-actual-time=\""  date  utils  sleep  for  sometime  as  it  gets  requeued  with  10ms  delay  on  failure  to  acquire  write  lock  ${coord:latest  range(-3 0)}  before  and  after  action  creation  time  parse  date  oozie  tz  datasets  should  be  picked  up  based  on  current  time  and  not  action  creation/actual  time.  get  test  case  dir  file://  action  set  created  time  index  of  /2009/01/08/  resolved  list  execute  set  action  xml  /2009/03/05  job  id  contains  coord  command  utils  /2009/02/19/  job  get  missing  dependencies  get  time  get  id  2009-02-16  t23:59  </uris>  replace  all  /2009/02/05  substring  test  action  input  check  latest  current  time  action  xml  sleep  /2009/02/12/  <uris>  assert  true  get  create  dir  start  time  update  action  creation  time  \"">  latest  2009-02-15  t23:59  action-actual-time=\""2009-02-15  t01:00  /2009/03/05/  /2009/01/22/  /2009/02/12  get  conf  action-actual-time=\"".*\"">  /2009/02/19  assert  equals  -  test  coord  action  input  check  x  command-  c  add  record  to  coord  job  table  thread  call  services  @1  get  action  xml  0000000-  end  time  2009-02-15  t01:00  action  creation  time  jpa  service  set  boolean  /2009/02/05/    coordelfunctions  tz  action-actual-time=\""  dateutils   sleep for sometime as it gets requeued with 10ms delay on failure to acquire write lock  ${coord:latestrange(-3 0)}   before and after action creation time  parsedateoozietz   datasets should be picked up based on current time and not action creation/actual time.  gettestcasedir  file://  action  setcreatedtime  indexof  /2009/01/08/  resolvedlist  execute  setactionxml  /2009/03/05  jobid  contains  coordcommandutils  /2009/02/19/  job  getmissingdependencies  gettime  getid  2009-02-16t23:59  </uris>  replaceall  /2009/02/05  substring  testactioninputchecklatestcurrenttime  actionxml  sleep  /2009/02/12/  <uris>  asserttrue  get  createdir  starttime   update action creation time  \"">  latest  2009-02-15t23:59  action-actual-time=\""2009-02-15t01:00  /2009/03/05/  /2009/01/22/  /2009/02/12  getconf  action-actual-time=\"".*\"">  /2009/02/19  assertequals  -testcoordactioninputcheckxcommand-c  addrecordtocoordjobtable  thread  call  services  @1  getactionxml  0000000-  endtime  2009-02-15t01:00  actioncreationtime  jpaservice  setboolean  /2009/02/05/
__label__nflaky yyyy-  mm  yyyy-ww  yyyy-  ww  yyyy-  mm-dd_  hh_mm  assert  equals  yyyy-  mm-dd_  hh_mm_ss  yyyy-  mm-dd_  hh  yyyy-  mm-dd_hh  get  periodicity  type  rc  periodicity  type  yyyy-  mm-dd  test  periodicity  yyyy-mm  yyyy-ww  yyyy-ww  yyyy-mm-dd_hh_mm  assertequals  yyyy-mm-dd_hh_mm_ss  yyyy-mm-dd_hh  yyyy-mm-dd_hh  getperiodicitytype  rc  periodicitytype  yyyy-mm-dd  testperiodicity
__label__flaky coordinator  job  bean  job  conf  bundle  job  get  cmd  log  submit  cmd  get  id  get  status  is  pending  app  path  configuration  parse  error.  read  from  db  :  get  job  sleep  bundle  actions  get  cmd  assert  not  null  get  get  auth  token  job  wait  for  coord  get  cmd1  set  coord  get  cmd2  get  conf  job2  job1  add  record  to  bundle  job  table  assert  equals  get  coord  id  execute  bundle.xml  call  services  warn  oozie  client  size  equals  test  bundle  kill2  to  string  error  code  job  jpa  service  actions  evaluate  ioe  coordinatorjobbean  jobconf  bundlejobgetcmd  log  submitcmd  getid  getstatus  ispending  apppath  configuration parse error. read from db :  getjob  sleep  bundleactionsgetcmd  assertnotnull  get  getauthtoken  job  waitfor  coordgetcmd1  set  coordgetcmd2  getconf  job2  job1  addrecordtobundlejobtable  assertequals  getcoordid  execute  bundle.xml  call  services  warn  oozieclient  size  equals  testbundlekill2  tostring  errorcode  job  jpaservice  actions  evaluate  ioe
__label__nflaky set  name  failed  to  delete  status  checker  status  printer.print(context);  delete  get  copy  of  status  list  fat-test  prudent  mode  logical  implications.txt  file  assert  true  core  test  constants  get  do  append  context  set  context  set  prudent  got  message    sm    status  msg1  get  absolute  path  expecting  status  list  size  to  be  2  or  larger   but  was  start  get  message  diff  appender  set  encoder  assert  equals  set  append  get  highest  level  filename  set  file  status  list  size  stop  is  append  exists  test  prudent  mode  logical  implications  get  status  manager  setting  \""  append\""  property  starts  with  setname  failed to delete   statuschecker   statusprinter.print(context);  delete  getcopyofstatuslist  fat-testprudentmodelogicalimplications.txt  file  asserttrue  coretestconstants  get  doappend  context  setcontext  setprudent  got message   sm    status  msg1  getabsolutepath  expecting status list size to be 2 or larger  but was   start  getmessage  diff  appender  setencoder  assertequals  setappend  gethighestlevel  filename  setfile  statuslist  size  stop  isappend  exists  testprudentmodelogicalimplications  getstatusmanager  setting \""append\"" property  startswith
__label__flaky add  record  to  wf  action  table  coord  action  get  cmd  get  id  workflow  instance  get  status  add  record  to  coord  action  table  coord  job  wf  job  workflow  job  should  have  been  purged  add  record  to  wf  job  table  get  error  code  assert  not  null  coordinator  action  should  have  been  purged  get  coordinator  action  workflow  job  wf  action  wf  job  get  cmd  coordinator  job  should  have  been  purged  workflow  action  should  have  been  purged  wf  action  get  cmd  assert  equals  execute  add  record  to  coord  job  table  call  test  purge  coord  with  wf  child3  services  coordinator  job  1  coord  job  get  cmd  fail  coord-action-get.xml  workflow  action  coord  action  succeeded  error  code  je  jpa  service  addrecordtowfactiontable  coordactiongetcmd  getid  workflowinstance  getstatus  addrecordtocoordactiontable  coordjob  wfjob  workflow job should have been purged  addrecordtowfjobtable  geterrorcode  assertnotnull  coordinator action should have been purged  get  coordinatoraction  workflowjob  wfaction  wfjobgetcmd  coordinator job should have been purged  workflow action should have been purged  wfactiongetcmd  assertequals  execute  addrecordtocoordjobtable  call  testpurgecoordwithwfchild3  services  coordinatorjob  1  coordjobgetcmd  fail  coord-action-get.xml  workflowaction  coordaction  succeeded  errorcode  je  jpaservice
__label__nflaky server  debug  expected  exception  log  close  the  server  expected  create  server  server  description  expected  an  exception   got  fail  stop  test  missing  server  resource  no  such  webapp  to  string  server  debug  expected exception   log   close the server  expected  createserver  serverdescription  expected an exception  got   fail  stop  testmissingserverresource  nosuchwebapp  tostring
__label__flaky get  id  run  assert  equals  get  status  add  record  to  coord  action  table  execute  add  record  to  coord  job  table  coord  get  cmd  test  coord  status  transit  service  transition  to  done  with  error  coord  job  sleep  coordinator  job  services  runnable  coord-action-get.xml  get  coordinator  action  job  jpa  service  getid  run  assertequals  getstatus  addrecordtocoordactiontable  execute  addrecordtocoordjobtable  coordgetcmd  testcoordstatustransitservicetransitiontodonewitherror  coordjob  sleep  coordinatorjob  services  runnable  coord-action-get.xml  get  coordinatoraction  job  jpaservice
__label__nflaky mask5  assert  true  mask4  test  get  data  mask  bit  internal  mask7  mask6  see  mask  patterns  on  the  page  43  of  jisx0510:2004.  mask1  mask0  mask3  test  get  data  mask  bit  mask2  mask5  asserttrue  mask4  testgetdatamaskbitinternal  mask7  mask6   see mask patterns on the page 43 of jisx0510:2004.  mask1  mask0  mask3  testgetdatamaskbit  mask2
__label__flaky conn  set  request  method  is_  security_  enabled  get  id  put  bundle  job  bean  endtime=2011-12-01  t05:00  z  /v1/job/*  id  job  run  test  mock  coordinator  engine  service  rest  constants  open  connection  add  record  to  bundle  job  table  http  servlet  response  assert  equals  params  url  put  call  test  bundle  engine  change  x  data  test  case  get  response  code  reset  create  url  change  value  conn  setrequestmethod  is_security_enabled  getid  put  bundlejobbean  endtime=2011-12-01t05:00z  /v1/job/*  id  job  runtest  mockcoordinatorengineservice  restconstants  openconnection  addrecordtobundlejobtable  httpservletresponse  assertequals  params  url  put  call  testbundleenginechange  xdatatestcase  getresponsecode  reset  createurl  changevalue
__label__nflaky test  socket  io  with  timeout  interrupted  source  timeout  sleep  add  thread  assert  true  do  work  interrupted  io  exception.  interrupt  pipe  start  threads  total  string  read  in  ste  ctx  get  message  millis  timeout  left  pipe  total  timeout  mills  is  thread  thread  fail  contains  stop  left  string  did  not  fail  with  interrupt  timeout  detail  open  testsocketiowithtimeoutinterrupted  source  timeout  sleep  addthread  asserttrue  dowork   interruptedioexception.  interrupt  pipe  startthreads  totalstring  read  in  ste  ctx  getmessage  millis timeout left  pipe  total timeout mills is   thread  thread  fail  contains  stop  leftstring  did not fail with interrupt  timeout  detail  open
__label__flaky check  coord  actions  get  id  date  utils  parse  date  oozie  tz  add  record  to  coord  job  table  2009-03-06  t10:00  z  call  coordinator  job  pause  time  start  time  end  time  2009-03-06  t10:04  z  job  test  action  mater  with  pause  time1  2009-03-06  t10:14  z  checkcoordactions  getid  dateutils  parsedateoozietz  addrecordtocoordjobtable  2009-03-06t10:00z  call  coordinatorjob  pausetime  starttime  endtime  2009-03-06t10:04z  job  testactionmaterwithpausetime1  2009-03-06t10:14z
__label__nflaky future  oops  test  intercept  future  not  an  exception2  intercept  future  complete  exceptionally  verify  cause    future  oops  testinterceptfuturenotanexception2  interceptfuture  completeexceptionally  verifycause
__label__flaky end_  points  rest  constants  is_  security_  enabled  get  context  url  oozie  url  mock  dag  engine  service  conf  assert  equals  wc  kill  call  oozie  client  1  test  kill  set  property  create  configuration  servlet_  classes  run  test  end_points  restconstants  is_security_enabled  getcontexturl  oozieurl  mockdagengineservice  conf  assertequals  wc  kill  call  oozieclient  1  testkill  setproperty  createconfiguration  servlet_classes  runtest
__label__nflaky buf  assert  format  protocol  version  http/1.1  to  string  assert  equals  http  version  test  http  version  formatting  buf  assert  formatprotocolversion  http/1.1  tostring  assertequals  httpversion  testhttpversionformatting
__label__flaky subwf  job  get  cmd  add  record  to  wf  action  table  coord  action  get  cmd  get  id  get  num  days  to  not  be  purged  workflow  instance  get  status  add  record  to  coord  action  table  sub  workflow  job  should  not  have  been  purged  coord  job  sub  workflow  action  should  not  have  been  purged  wf  job  get  end  time  add  record  to  wf  job  table  assert  not  null  get  workflow  job  should  not  have  been  purged  coordinator  action  workflow  job  wf  action  subwf  action  wf  job  get  cmd  wf  action  get  cmd  coordinator  action  should  not  have  been  purged  assert  equals  execute  add  record  to  coord  job  table  subwf  action  get  cmd  coordinator  job  should  not  have  been  purged  call  services  coordinator  job  1  coord  job  get  cmd  fail  coord-action-get.xml  test  purge  coord  with  wf  child  with  sub  wf2  workflow  action  coord  action  succeeded  subwf  job  jpa  service  workflow  action  should  not  have  been  purged  subwfjobgetcmd  addrecordtowfactiontable  coordactiongetcmd  getid  getnumdaystonotbepurged  workflowinstance  getstatus  addrecordtocoordactiontable  subworkflow job should not have been purged  coordjob  subworkflow action should not have been purged  wfjob  getendtime  addrecordtowfjobtable  assertnotnull  get  workflow job should not have been purged  coordinatoraction  workflowjob  wfaction  subwfaction  wfjobgetcmd  wfactiongetcmd  coordinator action should not have been purged  assertequals  execute  addrecordtocoordjobtable  subwfactiongetcmd  coordinator job should not have been purged  call  services  coordinatorjob  1  coordjobgetcmd  fail  coord-action-get.xml  testpurgecoordwithwfchildwithsubwf2  workflowaction  coordaction  succeeded  subwfjob  jpaservice  workflow action should not have been purged
__label__nflaky next  headers  assert  false  has  next  assert  equals  name  value2=whatever  value3;tag=nil  test  all  same  0  1  hit  without  filter  2  assert  3  assert  true  n  ame  na  me  nam  e  name  value1   value1.1  value0  with  filter  next  headers  assertfalse  hasnext  assertequals  name  value2=whatever  value3;tag=nil  testallsame  0  1  hit   without filter  2  assert  3  asserttrue  name  name  name  name  value1  value1.1  value0   with filter
__label__flaky conn  set  request  method  is_  security_  enabled  test  graph  put  assert  true  /v1/job/*  content-type  run  test  mock  coordinator  engine  service  rest  constants  open  connection  clear  mock  dag  engine  service  http  servlet  response  assert  equals  params  url  call  get  header  field  get  get  response  code  name  reset  create  url  error  code  starts  with  negative  test..  should  fail  conn  setrequestmethod  is_security_enabled  testgraph  put  asserttrue  /v1/job/*  content-type  runtest  mockcoordinatorengineservice  restconstants  openconnection  clear  mockdagengineservice  httpservletresponse  assertequals  params  url  call  getheaderfield  get  getresponsecode  name  reset  createurl  errorcode  startswith   negative test..  should fail
__label__nflaky skip  get  bytes  test  failure  out  of  order  keys  key  a  fail  close  output  assert  error  on  handling  out  of  order  keys.  value  a  value  m  writer  key  m  append  skip  getbytes  testfailureoutoforderkeys  keya  fail  closeoutput  assert  error on handling out of order keys.  valuea  valuem  writer  keym  append
__label__flaky /2009/01/01/  coord  el  functions  tz  action-actual-time=\""  date  utils  sleep  for  sometime  as  it  gets  requeued  with  10ms  delay  on  failure  to  acquire  write  lock  ${coord:latest  range(-3 0)}  before  and  after  action  creation  time  parse  date  oozie  tz  actual:  file://  get  test  case  dir  coordinator  action  action  set  created  time  index  of  /2009/01/22  /2009/01/08/  resolved  list  execute  set  action  xml  job  id  contains  test  action  input  check  latest  action  creation  time  with  push  dependency  coord  command  utils  /2009/02/19/  job  get  missing  dependencies  check  coord  action  expected:  set  push  missing  dependencies  get  time  get  id  2009-02-16  t23:59  </uris>  /2009/02/05  replace  all  system  substring  action  xml  sleep  /2009/02/12/  <uris>  assert  true  get  create  dir  start  time  update  action  creation  time  \"">  latest  2009-02-15  t23:59  action-actual-time=\""2009-02-15  t01:00  /2009/03/05/  /2009/01/22/  run  input  check  after  making  push  dependencies  available  /2009/02/12  get  conf  action-actual-time=\"".*\"">  /2009/01/08  assert  equals  -  test  coord  action  input  check  x  command-  c  add  record  to  coord  job  table  thread  datasets  only  before  action  creation/actual  time  should  be  picked  up.  call  services  @1  push  missing  dependency  get  action  xml  run  input  check  after  making  latest  available  get  push  missing  dependencies  0000000-  end  time  2009-02-15  t01:00  action  creation  time  jpa  service  set  boolean  set  push  missing  dependency    /2009/01/01/  coordelfunctions  tz  action-actual-time=\""  dateutils   sleep for sometime as it gets requeued with 10ms delay on failure to acquire write lock  ${coord:latestrange(-3 0)}   before and after action creation time  parsedateoozietz  actual:   file://  gettestcasedir  coordinatoraction  action  setcreatedtime  indexof  /2009/01/22  /2009/01/08/  resolvedlist  execute  setactionxml  jobid  contains  testactioninputchecklatestactioncreationtimewithpushdependency  coordcommandutils  /2009/02/19/  job  getmissingdependencies  checkcoordaction  expected:   setpushmissingdependencies  gettime  getid  2009-02-16t23:59  </uris>  /2009/02/05  replaceall  system  substring  actionxml  sleep  /2009/02/12/  <uris>  asserttrue  get  createdir  starttime   update action creation time  \"">  latest  2009-02-15t23:59  action-actual-time=\""2009-02-15t01:00  /2009/03/05/  /2009/01/22/   run input check after making push dependencies available  /2009/02/12  getconf  action-actual-time=\"".*\"">  /2009/01/08  assertequals  -testcoordactioninputcheckxcommand-c  addrecordtocoordjobtable  thread   datasets only before action creation/actual time should be picked up.  call  services  @1  pushmissingdependency  getactionxml   run input check after making latest available  getpushmissingdependencies  0000000-  endtime  2009-02-15t01:00  actioncreationtime  jpaservice  setboolean   set push missing dependency
__label__nflaky content  type  byte  channel  standard  charsets  assert  false  test  produce  data  with  buffering2  assert  equals  produce  is  open  assert  assert  true  producer  12345  dump  67890  stream  channel    contenttype  bytechannel  standardcharsets  assertfalse  testproducedatawithbuffering2  assertequals  produce  isopen  assert  asserttrue  producer  12345  dump  67890  streamchannel
__label__flaky rest  constants  get  time  2009-12-15  t01:00  z  get  id  assert  equals  coord  job  get  executor  get  status  add  record  to  coord  action  table  execute  call  get  pause  time  test  coord  rerun  in  paused  services  pause  time  assert  not  null  get  coordinator  action  curr  job  job  jpa  service  coord-rerun-action1.xml  add  record  to  coord  job  table  with  paused  time  restconstants  gettime  2009-12-15t01:00z  getid  assertequals  coordjobgetexecutor  getstatus  addrecordtocoordactiontable  execute  call  getpausetime  testcoordreruninpaused  services  pausetime  assertnotnull  get  coordinatoraction  curr  job  job  jpaservice  coord-rerun-action1.xml  addrecordtocoordjobtablewithpausedtime
__label__nflaky get  current  user  conf  run  echo  test  rpc  metrics  assert  quantile  gauges  lock  and  sleep  assert  gauge  rpc  lock  wait  time  num  ops  proxy2  rpc  queue  time  num  ops  user  group  information  \""  get  string  metric  print  stack  trace  rpc  queue  time  create  remote  user  rpc  processing  time  new  sleep  request  proxy  do  as  rpc  processing  time  num  ops  contains  stop  name  rpc  lock  wait  time  avg  time  interval  expected  correct  rpc  lock  wait  count  get  rpc  metrics  server  rpc  get  proxy  ping  actual  user  vs  con  get  metrics  new  empty  request  get  listener  address  get  long  counter  num  open  connections  per  user  another  user  expected  zero  rpc  lock  wait  time  assert  true  stop  proxy  \"":1  test  user  addr  get  short  user  name  expected  correct  rpc  processing  count  set  common  configuration  keys  e  expected  correct  rpc  queue  count  assert  equals  get  client  rpc  metrics  proxy  user  setup  test  server  metrics  asserts  get  double  gauge  new  echo  request  set  boolean    getcurrentuser  conf  run  echo  testrpcmetrics  assertquantilegauges  lockandsleep  assertgauge  rpclockwaittimenumops  proxy2  rpcqueuetimenumops  usergroupinformation  \""  getstringmetric  printstacktrace  rpcqueuetime  createremoteuser  rpcprocessingtime  newsleeprequest  proxy  doas  rpcprocessingtimenumops  contains  stop  name  rpclockwaittimeavgtime  interval  expected correct rpc lock wait count  getrpcmetrics  server  rpc  getproxy  ping  actualuservscon  getmetrics  newemptyrequest  getlisteneraddress  getlongcounter  numopenconnectionsperuser  anotheruser  expected zero rpc lock wait time  asserttrue  stopproxy  \"":1  testuser  addr  getshortusername  expected correct rpc processing count  set  commonconfigurationkeys  e  expected correct rpc queue count  assertequals  getclient  rpcmetrics  proxyuser  setuptestserver  metricsasserts  getdoublegauge  newechorequest  setboolean
__label__flaky next  rs  conn  schema  test  generate  create  script  pkey  test  values(1   \'abcd\')  test  table  prepare  statement  db  type  drop  table  insert  into  will  throw  an  exception  if  index  cant  be  created  test  columns  close  test  index  index  stmt  (  )  select  count(*)  from  assert  equals  get  direct  connection  execute  execute  query  get  int  prepare  db     generate  create  index  script  drop  schema  execute  update  next  rs  conn  schema  testgeneratecreatescript  pkeytest   values(1  \'abcd\')  testtable  preparestatement  dbtype  drop table   insert into    will throw an exception if   index cant be created  testcolumns  close  testindex  indexstmt  (  )  select count(*) from   assertequals  getdirectconnection  execute  executequery  getint  preparedb      generatecreateindexscript  dropschema  executeupdate
__label__nflaky rather  than  do  this  by  doing  unregister  checks   a  new  service  is  created  assert  listener  state  l0  not  the  final  one  l3  listener  stop  the  service  listeners  are  all  updated  create  and  register  the  listeners  set  failing  state  listeners  has  incremented  by  one  test  listener  chain  init  assert  listener  event  count  start  unregister  service  log  listener  assert  service  state  inited  can  all  be  unregistered  in  any  order  this  service  is  initialized  this  is  the  listener  that  is  not  expected  to  have  been  invoked  stop  service  create  and  init  a  service.  assert  service  state  started  register   rather than do this by doing unregister checks  a new service is created  assertlistenerstate  l0   not the final one  l3  listener   stop the service   listeners are all updated   create and register the listeners  setfailingstate   listeners   has incremented by one  testlistenerchain  init  assertlistenereventcount  start  unregister  service  loglistener  assertservicestateinited   can all be unregistered in any order   this service is initialized   this is the listener that is not expected to have been invoked  stop  service   create and init a service.  assertservicestatestarted  register
__label__flaky callable2  callable3  callables  callable1  get  current  dateafter  incrementing  in  months  get  id  date  utils  parse  date  oozie  tz  as  list  queueservice  assert  true  get  end  current  date  plus  month  wait  for  c  start  x  data  test  case  services  test  coord  kill  x  command  uniqueness  add  record  to  coord  job  table  coordinator  job  job  arrays  evaluate  queue  callable2  callable3  callables  callable1  getcurrentdateafterincrementinginmonths  getid  dateutils  parsedateoozietz  aslist  queueservice  asserttrue  get  end  currentdateplusmonth  waitfor  c  start  xdatatestcase  services  testcoordkillxcommanduniqueness  addrecordtocoordjobtable  coordinatorjob  job  arrays  evaluate  queue
__label__nflaky test  default  ur  iwith  out  port  test  default  uri  internal  hdfs://dummyhost  testdefaulturiwithoutport  testdefaulturiinternal  hdfs://dummyhost
__label__flaky get  name  splits  log  system  table  name  bytes  hflush  test  split  add  edits  for  three  regions.  verify  splits  howmany  add  ii  split  log  edit  :  to  bytes  row  name  column  j  close  and  delete  integer  qualifier  current  time  millis  region  to  string  family  roll  writer  h  log  infos  append  column:    getname  splits  log  system  tablename  bytes  hflush  testsplit   add edits for three regions.  verifysplits  howmany  add  ii  splitlog  edit  :   tobytes  rowname  column  j  closeanddelete  integer  qualifier  currenttimemillis  region   tostring  family  rollwriter  hlog  infos  append  column:
__label__nflaky build  matrix  get  version  for  number  matrix  util  mask  pattern  3  1  0  1  1  1  0  1  0  1  1  1  1  0  0  0  0  1  1  1  0  0  matrix  1  1  1  1  0  1  1  0  1  0  1  1  1  0  0  1  1  1  0  1  0  0  0  1  0  0  1  1  1  0  0  0  0  0  0  1  0  1  1  1  1  1  version  1  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  1  1  0  1  1  1  0  1  0  1  1  0  1  0  0  0  0  0  1  1  1  0  test  build  matrix  1  0  1  1  1  0  1  0  1  1  0  0  1  0  1  0  1  1  1  0  1  1  0  0  0  0  0  1  0  0  0  0  1  0  1  1  1  0  0  0  0  0  1  1  1  1  1  1  1  0  0  1  1  0  0  0  1  1  1  1  1  1  1  c  from  http://www.swetake.com/qr/qr7.html  0  0  1  1  0  0  1  1  1  0  0  1  1  1  1  0  1  0  0  0  0  1  0  1  1  1  0  1  0  0  1  1  0  0  0  1  0  1  1  1  0  1  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  1  0  0  expected  bits  version  1  1  1  1  1  1  1  1  0  0  0  1  1  1  1  1  0  1  0  0  1  0  1  0  1  0  1  0  0  0  0  0  1  1  1  0  0  1  0  1  1  1  0  0  0  0  0  0  0  0  0  1  1  0  1  0  0  0  0  0  1  0  1  1  assert  equals  1  0  1  1  1  0  1  0  0  0  0  1  0  0  1  0  1  1  1  0  1  append  bits  bytes  0  0  0  0  0  0  0  0  1  1  0  1  1  0  0  0  0  0  0  0  0  1  0  1  0  1  1  0  1  1  1  0  0  1  1  1  0  0  1  0  1  0  1  0  0  0  0  0  1  0  0  0  1  1  1  0  1  0  0  0  0  0  1  to  string  1  1  1  1  1  1  1  0  1  0  1  0  1  0  1  1  1  1  1  1  1  error  correction  level  1  0  1  1  1  0  1  0  0  1  0  0  1  1  0  0  1  0  0  1  1  1  1  1  1  1  1  1  0  1  1  1  1  0  0  0  0  1  0  1  1  0  buildmatrix  getversionfornumber  matrixutil   mask pattern 3   1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 0    matrix   1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 0     0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1    version   1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1     1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 1 1 1 0    testbuildmatrix   1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1     1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0     1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1    c   from http://www.swetake.com/qr/qr7.html   0 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0     1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1     1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0    expected  bits   version 1   1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 0     1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0     0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 1    assertequals   1 0 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 1    appendbits  bytes   0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0     1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0     1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1    tostring   1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1    errorcorrectionlevel   1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 1 1     1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0
__label__flaky cluster  1.x1  script  args  dg  script  file2  script  file1  dir_  structure_  first_  line  -max  delay  between  ops  run  /test  wait  active  max_  delay_  between_  ops  script_  test_  dir  script2  -read  probability  elapsed_  time  write  10  -root  read_  probability  2  .22  .33  -1  old  arg  dir_  structure_  file  -script  file  loadgenscript  script  /  0  1  1.1  num  data  nodes  out_  dir  long  conf  -start  time  shutdown  test_  space_  root  start_  time  test  with  good  script  file_  structure_  second_  line  num_  of_  threads  -write  probability  time  delete  -elapsed  time  fw  now  6  0  .7  file_  structure_  first_  line  close  -in  dir  test  with  bad  script  get  absolute  path  file_  structure_  file  assert  equals  set  conf  -num  of  threads  args  -1.1  loadgenscript2  build  0.3  3  .10  .6  3  blah  blah  blah  .6  dir_  structure_  second_  line  write_  probability  to  string  writer  lg  0.9  test  load  generator  cluster  1.x1  scriptargs  dg  scriptfile2  scriptfile1  dir_structure_first_line  -maxdelaybetweenops      run  /test  waitactive  max_delay_between_ops  script_test_dir  script2  -readprobability  elapsed_time  write  10  -root  read_probability  2 .22 .33    -1  oldarg  dir_structure_file  -scriptfile  loadgenscript  script  /  0  1  1.1  numdatanodes  out_dir  long  conf  -starttime  shutdown  test_space_root  start_time   test with good script  file_structure_second_line  num_of_threads  -writeprobability  time  delete  -elapsedtime  fw  now  6 0 .7    file_structure_first_line  close  -indir   test with bad script  getabsolutepath  file_structure_file  assertequals  setconf  -numofthreads  args  -1.1  loadgenscript2  build  0.3  3 .10 .6    3 blah blah blah .6    dir_structure_second_line  write_probability  tostring  writer  lg  0.9  testloadgenerator
__label__nflaky num  components  created  the  other  appenders  should  be  in  the  tracker  assert  false  timeout  the  first  appender  should  have  been  removed  assert  true  find  assert  not  null  now  get  appender  tracker  remove  stale  components  key  add  a  all  keys  cleaning  only  happens  in  remove  stale  components.  the  first  appender  should  timeout  assert  equals  is  started  -  set  timeout  assert  null  size  appender  list  get  or  create  tracker  should  honor  timeout  parameter  numcomponentscreated   the other appenders should be in the tracker  assertfalse  timeout   the first appender should have been removed  asserttrue  find  assertnotnull  now  get  appendertracker  removestalecomponents  key  add  a  allkeys   cleaning only happens in removestalecomponents. the first appender should timeout  assertequals  isstarted  -  settimeout  assertnull  size  appenderlist  getorcreate  trackershouldhonortimeoutparameter
__label__flaky cc  email-action  ctx  multiple  <to>s  subject  body  create  normal  context  fail  multiple  <cc>s  test  validation  multiple  <subject>s  prepare  bad  element  multiple  <body>s  validate  and  mail  to  email  cc  email-action  ctx   multiple <to>s  subject  body  createnormalcontext  fail   multiple <cc>s  testvalidation   multiple <subject>s  preparebadelement   multiple <body>s  validateandmail  to  email
__label__nflaky set  name  other  parsed  list  default:user:user1:: default:mask::  parsed  acl  not  correct  parse  acl  spec  user:: user:user1: group:: group:group1: mask:: other::   default  user  group  mask  owner  user1  add  test  multiple  acl  spec  parsing  without  permissions  acl  entry  scope  acl  entry  type  named  user  expected  list  acl  entry  assert  equals  set  type  group1  named  group  build  set  scope  default  mask  setname  other  parsedlist  default:user:user1:: default:mask::  parsed acl not correct  parseaclspec  user:: user:user1: group:: group:group1: mask:: other::   defaultuser  group  mask  owner  user1  add  testmultipleaclspecparsingwithoutpermissions  aclentryscope  aclentrytype  nameduser  expectedlist  aclentry  assertequals  settype  group1  namedgroup  build  setscope  defaultmask
__label__flaky date  coord  el  functions  coord-action-create  coord-action-start  utc  date  2009  eval  and  wrap  expr3_eval  coord-action-create-inst  expr3  expr2  expr1  2009-09-08  t23:59  z  \'     init  ${coord:format  time(\""2009-09-08  t23:59  z\""   \""yyyy\"")}  ${coord:format  time(\""2009-09-08  t23:59  z\""   \""yyyy  m  mdd_  h  hmmss\"")}  20090908_235900  ${coord:format  time(\'  yyyy)}  coord-job-submit-instances  set  variable  assert  equals  test  format  time  ${coord:format  time(date   \""yyyy\"")}  coord-job-submit-data  eval  date  coordelfunctions  coord-action-create  coord-action-start  utcdate  2009  evalandwrap  expr3_eval  coord-action-create-inst  expr3  expr2  expr1  2009-09-08t23:59z  \'     init  ${coord:formattime(\""2009-09-08t23:59z\""  \""yyyy\"")}  ${coord:formattime(\""2009-09-08t23:59z\""  \""yyyymmdd_hhmmss\"")}  20090908_235900  ${coord:formattime(\'  yyyy)}  coord-job-submit-instances  setvariable  assertequals  testformattime  ${coord:formattime(date  \""yyyy\"")}  coord-job-submit-data  eval
__label__nflaky http://localhost/foo  bar  localhost  /foo  bar  to  url  to  uri  assert  equals  /foo+bar  uri  encodes  the  path  uri#get  path  decodes  the  path  uri#to  string  returns  an  encoded  path  test  reserved  characters  /foo\%20bar  get  path  uri#get  path  decodes  the  path  part  (and  url#get  path  does  not  decode)  http  to  string  /foo;bar  get  raw  path  /foo\%3  fbar  /foo?bar  reserved  chars  are  not  encoded  http://localhost/foo bar  localhost  /foo bar  tourl  touri  assertequals  /foo+bar   uri encodes the path   uri#getpath decodes the path   uri#tostring returns an encoded path  testreservedcharacters  /foo\%20bar  getpath   uri#getpath decodes the path part (and url#getpath does not decode)  http  tostring  /foo;bar  getrawpath  /foo\%3fbar  /foo?bar   reserved chars are not encoded
__label__flaky set  classes  to  be  excluded  c  job1  get  time  pause  start  runnable  get  current  dateafter  incrementing  in  months  run  get  id  date  utils  get  status  parse  date  oozie  tz  test  pause  coordinator  for  backward  support  set  pause  time  pause  time  assert  not  null  get  end  current  date  plus  month  job  wait  for  init  get  conf  start  destroy  assert  equals  services  x  data  test  case  set  app  namespace  execute  add  record  to  coord  job  table  coord  job2  services  coordinator  job  coord  job1  excluded  services  coord  job  id1  schema  service  coord  job  id2  set  system  property  true  status  transit  service  action1  action2  jpa  service  evaluate  setclassestobeexcluded  cjob1  gettime  pausestartrunnable  getcurrentdateafterincrementinginmonths  run  getid  dateutils  getstatus  parsedateoozietz  testpausecoordinatorforbackwardsupport  setpausetime  pausetime  assertnotnull  get  end  currentdateplusmonth  job  waitfor  init  getconf  start  destroy  assertequals  services  xdatatestcase  setappnamespace  execute  addrecordtocoordjobtable  coordjob2  services  coordinatorjob  coordjob1  excludedservices  coordjobid1  schemaservice  coordjobid2  setsystemproperty  true  statustransitservice  action1  action2  jpaservice  evaluate
__label__nflaky fail  should  fail  exponential  backoff  retry  unreliable  fails  once  then  succeeds  fails  ten  times  then  succeeds  time  unit  create  unreliable  impl  retry  proxy  always  succeeds  test  exponential  retry  fail  should fail  exponentialbackoffretry  unreliable  failsoncethensucceeds  failstentimesthensucceeds  timeunit  create  unreliableimpl  retryproxy  alwayssucceeds  testexponentialretry
__label__flaky exec_  order  callable2  callable3  callables  test  queue  uniqueness  with  same  key  in  composite  callable1  c  type  queue  serial  as  list  queueservice  services  assert  true  get  queue  uniqueness  with  same  key  in  composite  arrays  evaluate  wait  for  exec_order  callable2  callable3  callables  testqueueuniquenesswithsamekeyincomposite  callable1  c  type  queueserial  aslist  queueservice  services  asserttrue  get  queueuniquenesswithsamekeyincomposite  arrays  evaluate  waitfor
__label__nflaky parse  body  abstract  context  assert  null  do  return  context  test  parse  body  with  unkown  content  type  works  spy  when  get  request  content  type  o  parsebody  abstractcontext  assertnull  doreturn  context  testparsebodywithunkowncontenttypeworks  spy  when  getrequestcontenttype  o
__label__flaky initial  callable  callables  test  interrupts  with  distinguished  lock  keys  type  key  int  queueservice  initial  key  assert  true  get  initial  type  *  introducing  an  interrupt  with  different  keys  and  assure  it  will  be  *  executed  in  order  regardless  of  the  existence  of  an  interrupt  command  in  *  the  mix.  lock  key  wait  for  key  exec_  order  add  init  c  initial  lock  key  ret  value  callable  queue  service  destroy  services  1  test  kill  int  callable  set  system  property  evaluate  queue  initialcallable  callables  testinterruptswithdistinguishedlockkeys  type  keyint  queueservice  initialkey  asserttrue  get  initialtype         * introducing an interrupt with different keys and assure it will be       * executed in order regardless of the existence of an interrupt command in       * the mix.         lockkey  waitfor  key  exec_order  add  init  c  initiallockkey  retvalue  callablequeueservice  destroy  services  1  testkill  intcallable  setsystemproperty  evaluate  queue
__label__nflaky get  bytes  transferred  codec  test  utils  channel  times  assert  flush  verify  more  stuff  dump  stuff---more  stuff  write  test  coding  fragment  buffering  tiny  fragments  argument  matchers  standard  charsets  assert  equals  encoder  -  any  mockito  outbuf  metrics  spy  wrap  stuff  getbytestransferred  codectestutils  channel  times  assert  flush  verify  more stuff  dump  stuff---more stuff  write  testcodingfragmentbufferingtinyfragments  argumentmatchers  standardcharsets  assertequals  encoder  -  any  mockito  outbuf  metrics  spy  wrap  stuff
__label__flaky hdfs://x  fs001  fs002  hdfs://z  hdfs://x/ha  get  error  code  assert  true  bla  get  test  resolve  to  full  path  /bla  hdfs://x/bla  init  fs011  ae  destroy  get  message  assert  equals  hadoop  accessor  service  fail  services  e0904  contains  ex  file://bla  set  system  property  resolve  to  full  path  hdfs://x  fs001  fs002  hdfs://z  hdfs://x/ha  geterrorcode  asserttrue  bla  get  testresolvetofullpath  /bla  hdfs://x/bla  init  fs011  ae  destroy  getmessage  assertequals  hadoopaccessorservice  fail  services  e0904  contains  ex  file://bla  setsystemproperty  resolvetofullpath
__label__nflaky current  context  assert  equals  param3  param4  param1  param2  1  set  attribute  2  3  get  attribute  assert  4  parent  context  test  context  operations  remove  attribute  currentcontext  assertequals  param3  param4  param1  param2  1  setattribute  2  3  getattribute  assert  4  parentcontext  testcontextoperations  removeattribute
__label__flaky add  qualifier_1  qualifier_2  row_3  row_4  test  put  put  result  puts  multiput  get  value  bytes  column_2  column_1  add  family  assert  true  assert  not  null  get  equals  remote  table  value_1  value  value_2  add  qualifier_1  qualifier_2  row_3  row_4  testput  put  result  puts   multiput  getvalue  bytes  column_2  column_1  addfamily  asserttrue  assertnotnull  get  equals  remotetable  value_1  value  value_2
__label__nflaky refill  task  should  add  10  values  to  get  to  a  full  queue  failed  to  get  all  19.  sync  call  filler  got  wrong  number.  drain  assert  trigger  a  prefill  (1)  and  an  async  refill  (10)  wait  a  while  to  make  sure  that  no  async  refills  are  triggered  synchronous  call  get  top  2.  start  another  async  task  to  fill  the  queue  in  the  cache  wait  for  the  async  task  to  finish  drain  completely  after  filled  by  the  async  thread  test  sync  generation  policy  k1  get  at  most  failed  in  async  call.  assert  equals  get  next  failed  in  sync  call.  drain  completely   no  further  refills  triggered  the  prefill  to  the  low  watermark   1  consumed  by  get  next())  wait  for  refill  get  size  assert  null  size  filler  vq  testget  at  most  policy  all  shutdown  failed  to  drain  completely  after  async.   refill task should add 10 values to get to a full queue  failed to get all 19.  sync call filler got wrong number.  drain  assert   trigger a prefill (1) and an async refill (10)   wait a while to make sure that no async refills are triggered   synchronous call  gettop   2. start another async task to fill the queue in the cache   wait for the async task to finish   drain completely after filled by the async thread  test  syncgenerationpolicy  k1  getatmost  failed in async call.  assertequals  getnext  failed in sync call.   drain completely  no further refills triggered   the prefill to the low watermark  1 consumed by getnext())  waitforrefill  getsize  assertnull  size  filler  vq  testgetatmostpolicyall  shutdown  failed to drain completely after async.
__label__flaky hcat  uri2  check  coord  action  coord  el  functions  hcat  uri1  test  update  coord  table  advanced  add  init  records  get  available  dependency  ur  is  partition  available  available  ur  is  assert  true  get  coordinator  action  mydb  src=search;datastamp=11;region=us  add  missing  dependency  new  h  cat  dependency2  second  partition  available  hcat://hcat.server.com:5080/mydb/clicks/datastamp=11;region=us  new  h  cat  dependency1  hcat.server.com:5080  assert  equals  pdms  call  services  contains  src=search;datastamp=12;region=us  assert  null  size  action  id  clicks  get  partition  map  full  deps  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us  hcaturi2    checkcoordaction  coordelfunctions  hcaturi1  testupdatecoordtableadvanced  addinitrecords  getavailabledependencyuris  partitionavailable  availableuris  asserttrue  get  coordinatoraction  mydb  src=search;datastamp=11;region=us  addmissingdependency  newhcatdependency2   second partition available  hcat://hcat.server.com:5080/mydb/clicks/datastamp=11;region=us  newhcatdependency1  hcat.server.com:5080  assertequals  pdms  call  services  contains  src=search;datastamp=12;region=us  assertnull  size  actionid  clicks  getpartitionmap  fulldeps  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us
__label__nflaky get  class  test  clearing  cached  mappings  resolve  /rack2  conf  reload  cached  mappings  /rack2  /rack1  result  .txt  get  .test  clearing  cached  mappings  files  write  delete  on  exit  add  map  file  mapping  get  canonical  path  set  /rack1  as  char  sink  create  temp  file  assert  equals  set  conf  net_  topology_  table_  mapping_  file_  key  names  size  network  topology  host  name2  host  name1  get  simple  name  file  charsets    getclass  testclearingcachedmappings  resolve  \t/rack2    conf  reloadcachedmappings  /rack2  /rack1  result  .txt  get  .testclearingcachedmappings  files  write  deleteonexit  add  mapfile  mapping  getcanonicalpath  set   /rack1    ascharsink  createtempfile  assertequals  setconf  net_topology_table_mapping_file_key  names  size  networktopology  hostname2  hostname1  getsimplename  file  charsets
__label__flaky play  server  connect  via  http  proxy  to  https  using  bad  proxy  and  http  response  cache  init  response  cache  connect  line  failure  on  proxy  for  the  backwards-compatible  ss  lv3  retry  to  proxy  address  todo:  use  the  fake  dns  implementation  instead  of  a  loop  for  the  first  tls  tolerant  connection  client  socket  policy  connection  bogus  proxy  connect  response  content  host:  android.com  connect  https://android.com/foo  set  ssl  socket  factory  get  host  name  get  all  by  name  get  headers  take  request  set  proxy  set  socket  policy  ssl  context  assert  equals  set  body  url  assert  contains  get  socket  factory  enqueue  fail  get  request  line  connect  android.com:443  http/1.1  inet  address  response  get  response  code  use  https  key  to  reproducing  b/6754912  inet  address  open  play  server  connectviahttpproxytohttpsusingbadproxyandhttpresponsecache  initresponsecache  connect line failure on proxy   for the backwards-compatible sslv3 retry  toproxyaddress   todo: use the fake dns implementation instead of a loop   for the first tls tolerant connection  client  socketpolicy  connection  bogus proxy connect response content  host: android.com  connect  https://android.com/foo  setsslsocketfactory  gethostname  getallbyname  getheaders  takerequest  setproxy  setsocketpolicy  sslcontext  assertequals  setbody  url  assertcontains  getsocketfactory  enqueue  fail  getrequestline  connect android.com:443 http/1.1  inetaddress  response  getresponsecode  usehttps   key to reproducing b/6754912  inetaddress  open
__label__nflaky test  file01  get  path  data  testfile01  add  contents  ls  format  line  mtime  out  testfile03  options  compute  line  format  in  order  testfile02  process  options  verify  testfile05  test  file06  testfile04  test  file04  test  file05  testfile06  test  file02  test  file03  add  found  6  items  path  data  line  format  set  is  dir  process  arguments  test  dir  check  listing  of  a  single  directory  test  directory  process  path  directory  verify  no  more  interactions  test  file  mock    testfile01  getpathdata  testfile01  addcontents  ls  formatlinemtime  out  testfile03  options  computelineformat  inorder  testfile02  processoptions  verify  testfile05  testfile06  testfile04  testfile04  testfile05  testfile06  testfile02  testfile03  add  found 6 items  pathdata  lineformat  setisdir  processarguments  testdir   check listing of a single directory  testdirectory  processpathdirectory  verifynomoreinteractions  testfile  mock
__label__flaky wf  update  cmd2  get  id  workflow  instance  first  update;  wf  bean  add  record  to  wf  job  table  second  update;  assert  not  null  wf  update  cmd1  wf  bean2  get  wf  bean1  workflow  job  test  workflow  job  update  get  status  str  set  app  name  test  running  wf  get  cmd  assert  equals  execute  set  status  services  succeeded  job  jpa  service  wfupdatecmd2  getid  workflowinstance   first update;  wfbean  addrecordtowfjobtable   second update;  assertnotnull  wfupdatecmd1  wfbean2  get  wfbean1  workflowjob  testworkflowjobupdate  getstatusstr  setappname  test  running  wfgetcmd  assertequals  execute  setstatus  services  succeeded  job  jpaservice
__label__nflaky host5  host4  host7  host6  host1  host3  somehost  host2  assert  false  someotherhost  assert  assert  true  equals  some  host  user  test  equals  host5  host4  host7  host6  host1  host3  somehost  host2  assertfalse  someotherhost  assert  asserttrue  equals  somehost  user  testequals
__label__flaky start.error  assert  true  based_on_action_status  test  start  error  with  user  retry  error  _test  error  with  user  retry  start.error  asserttrue  based_on_action_status  teststarterrorwithuserretry  error  _testerrorwithuserretry
__label__nflaky garbage  strings  max  gc  time  percentage  alerter  gc  time  percentage  get  latest  gc  data  system  alerter  should  be  called  if  gc  takes  >=  10\%  assert  alert  alerter  is  invoked  at  least  once.  assert  true  long  string  prefix  just  to  fill  memory  with  garbage  num  alerts  run  this  for  at  least  1  sec  for  our  monitor  to  collect  enough  data  start  time  gc  get  gc  time  percentage  add  alert  gc  perc  gc  time  monitor  gc  count  start  clear  j  gc  data  test  gc  time  monitor  current  time  millis  get  accumulated  gc  count  garbagestrings  maxgctimepercentage  alerter  gctimepercentage  getlatestgcdata  system   alerter should be called if gc takes >= 10\%  assert  alert   alerter is invoked at least once.  asserttrue  long string prefix just to fill memory with garbage   numalerts   run this for at least 1 sec for our monitor to collect enough data  starttime  gc  getgctimepercentage  add  alertgcperc  gctimemonitor  gccount  start  clear  j  gcdata  testgctimemonitor  currenttimemillis  getaccumulatedgccount
__label__flaky push  promise  play  push  observer  play  it  back  squareup.com  http_20_  draft_09  verify  the  peer  received  what  was  expected  type_  rst_  stream  as  list  connection  builder  accept  frame  peer  https  take  frame  rst  stream  syn  reply  set  variant  and  client  assert  equals  /cached  rst_  stream  push  promise  streams  automatically  cancel  200  send  frame  header  build  get  write  the  mocking  script  cancel  push  observer  arrays  pushpromise  play  pushobserver   play it back  squareup.com  http_20_draft_09   verify the peer received what was expected  type_rst_stream  aslist  connectionbuilder  acceptframe  peer  https  takeframe  rststream  synreply  setvariantandclient  assertequals  /cached   rst_stream  pushpromisestreamsautomaticallycancel  200  sendframe  header  build  get   write the mocking script  cancel  pushobserver  arrays
__label__nflaky expected  num  sectors  read  get  storage  bytes  written  get  storage  bytes  read  string  f  writer  parsing  proc  disks  file  disk  sector  size  temp  file  write  close  delete  on  exit  num  sectors  readsdf  format  num  sectors  readsda  assert  equals  expected  num  sectors  written  num  sectors  readsdc  num  sectors  readsde  use  non-default  sector  size  disksinfo_  format  fake  linux  resource  calculator  plugin  plugin  fake_  disksfile  num  sectors  writtensda  num  sectors  writtensdc  num  sectors  writtensdf  num  sectors  writtensde  expectednumsectorsread  getstoragebyteswritten  getstoragebytesread  string  fwriter  parsingprocdisksfile  disksectorsize  tempfile  write  close  deleteonexit  numsectorsreadsdf  format  numsectorsreadsda  assertequals  expectednumsectorswritten  numsectorsreadsdc  numsectorsreadsde   use non-default sector size  disksinfo_format  fakelinuxresourcecalculatorplugin  plugin  fake_disksfile  numsectorswrittensda  numsectorswrittensdc  numsectorswrittensdf  numsectorswrittensde
__label__flaky fail  test  parallel  read  run  parallel  read  check  log  for  errors  fail  testparallelread  runparallelread  check log for errors
__label__nflaky msg  conn  get  name  test  validate  response  json  error  known  exception  http  exception  utils  get  response  message  when  put  get  bytes  get  error  stream  http  url  connection  assert  json  validate  response  then  return  get  message  is  assert  equals  json  mapper  fail  ex  ex  mockito  response  get  response  code  mock  get  simple  name  write  value  as  string  msg  conn  getname  testvalidateresponsejsonerrorknownexception  httpexceptionutils  getresponsemessage  when  put  getbytes  geterrorstream  httpurlconnection  assert  json  validateresponse  thenreturn  getmessage  is  assertequals  jsonmapper  fail  ex  ex  mockito  response  getresponsecode  mock  getsimplename  writevalueasstring
__label__flaky set  script  executor  updated_static  entity  with  static  column/insert_single_row.cql  session  given  select  static_col  from  entitywithstaticcolumn  where  id  =  eq  uui  ds  uuid  when  of  static  col  should_dsl_update_static  where  id  static_col  execute  script  template  is  not  null  static_val  actual  random  utils  manager  one  time  based  if_  static  col  get  string  next  long  assert  that  execute  immutable  map  then  long  update  static  from  base  table  dsl  is  equal  to  set  scriptexecutor  updated_static  entitywithstaticcolumn/insert_single_row.cql  session   given  select static_col from entitywithstaticcolumn where id =   eq  uuids  uuid   when  of  staticcol  should_dsl_update_static  where  id  static_col  executescripttemplate  isnotnull  static_val  actual  randomutils  manager  one  timebased  if_staticcol  getstring  nextlong  assertthat  execute  immutablemap   then  long  updatestatic  frombasetable  dsl  isequalto
__label__nflaky test  file01  get  path  data  check  path  only  display  (-  c  option)  testfile01  add  contents  ls  out  process  path  directory  path  only  testfile03  options  in  order  get  path  testfile02  process  options  verify  testfile05  test  file06  testfile04  test  file04  test  file05  testfile06  test  file02  test  file03  add  path  data  set  is  dir  process  arguments  test  dir  test  directory  verify  no  more  interactions  -  c  mock  to  string    testfile01  getpathdata   check path only display (-c option)  testfile01  addcontents  ls  out  processpathdirectorypathonly  testfile03  options  inorder  getpath  testfile02  processoptions  verify  testfile05  testfile06  testfile04  testfile04  testfile05  testfile06  testfile02  testfile03  add  pathdata  setisdir  processarguments  testdir  testdirectory  verifynomoreinteractions  -c  mock  tostring
__label__flaky aa  a  a  ${a}  b  set  c  get  property  d  test  var  resolution  and  sys  props  ${user.name}  foo  user.name  conf  assert  equals  system  ${aa}  ${aaa}  set  system  property  get  un  get  raw  aa  a  a  ${a}  b  set  c  getproperty  d  testvarresolutionandsysprops  ${user.name}  foo  user.name  conf  assertequals  system  ${aa}  ${aaa}  setsystemproperty  get  un  getraw
__label__nflaky charset  submit  executor  service  channel  executors  get  bytes  write  completed  assert  1234567890  flush  get  duration  tmp  is  end  stream  get  boolean  task1  write  task2  output  buffer  await  output  request  new  fixed  thread  pool  standard  charsets  has  data  test  multithreading  write  stream  assert  equals  data  stream  channel  get  time  unit  call  to  byte  array  timeout  1234567890123456789012123456789012345678901234567890  charset  submit  executorservice  channel  executors  getbytes  writecompleted  assert  1234567890  flush  getduration  tmp  isendstream  get  boolean  task1  write  task2  outputbuffer  awaitoutputrequest  newfixedthreadpool  standardcharsets  hasdata  testmultithreadingwritestream  assertequals  datastreamchannel  gettimeunit  call  tobytearray  timeout  1234567890123456789012123456789012345678901234567890
__label__flaky r2  get  name  output  test.*.source.filter.exclude  get  test  filename  test  put  metrics  when  we  call  stop   at  most  two  sources  will  be  consumed  by  each  sink  thread.  s0  s1  add  check  metrics  records  ms  get  all  values  capture  test.sink.test.class  mr2  mr1  s1  desc  stop  size  *.period  test  metrics  config  test.sink.sink1.metric.filter.exclude  mock  shutdown  s0rec  publish  the  metrics  test.sink.sink2.metric.filter.exclude  save  test.source.s1.metric.filter.exclude  x*  verify  at  most  sink2  desc  hadoop-metrics2-test  s1rec  set  register  sink  incr  start  sink1  desc  assert  equals  y*  s0  desc  test  init  first  verify  stop  invoked  immediately  sink2  sink1  publish  metrics  now  register  r1  r2  getname  output  test.*.source.filter.exclude  gettestfilename  test  putmetrics   when we call stop  at most two sources will be consumed by each sink thread.  s0  s1  add  checkmetricsrecords  ms  getallvalues  capture  test.sink.test.class  mr2  mr1  s1 desc  stop  size  *.period  testmetricsconfig  test.sink.sink1.metric.filter.exclude  mock  shutdown  s0rec   publish the metrics  test.sink.sink2.metric.filter.exclude  save  test.source.s1.metric.filter.exclude  x*  verify  atmost  sink2 desc  hadoop-metrics2-test  s1rec  set  registersink  incr  start  sink1 desc  assertequals  y*  s0 desc  testinitfirstverifystopinvokedimmediately  sink2  sink1  publishmetricsnow  register  r1
__label__nflaky p  a  b  test2  size  a/b  get  assert  equals  peek  last  p  a  b  test2  size  a/b  get  assertequals  peeklast
__label__flaky bundle  job  get  executor  test  bundle  purge  x  command  failed  add  record  to  bundle  action  table  get  id  date  utils  get  status  parse  date  oozie  tz  assert  not  null  get  job  2011-01-01  t01:00  z  add  record  to  bundle  job  table  assert  equals  bundle  action  should  not  have  been  purged  execute  call  bundle  job  should  not  have  been  purged  services  fail  bundle  action  get  executor1  bundle  action  get  executor2  action1  job  action2  jpa  service  bundlejobgetexecutor  testbundlepurgexcommandfailed  addrecordtobundleactiontable  getid  dateutils  getstatus  parsedateoozietz  assertnotnull  get  job  2011-01-01t01:00z  addrecordtobundlejobtable  assertequals  bundle action should not have been purged  execute  call  bundle job should not have been purged  services  fail  bundleactiongetexecutor1  bundleactiongetexecutor2  action1  job  action2  jpaservice
__label__nflaky input  node  transform  node  to  string  transformer  property  container0  ${k0}  make  node  variable  v0  assert  equals  input  node  transform  nodetostringtransformer  propertycontainer0  ${k0}  makenode  variable  v0  assertequals
__label__flaky request  conditions  _exec  query  parse  date  utc  get  status  date  utils  test  single  record  get  bundle  br  startcreatedtime=2012-07-21  t00:00  z;endcreatedtime=2012-07-22  t02:00  z  get  coordinator  ;actionstatus=  failed;  get  coordinator  action  coord1  create_  time  get  app  name  assert  equals  get  action  br  list  only  1  action  satisfies  the  size  bundle  name  to  string  bundle=  get  created  time  request   conditions  _execquery  parsedateutc  getstatus  dateutils  testsinglerecord  getbundle  br  startcreatedtime=2012-07-21t00:00z;endcreatedtime=2012-07-22t02:00z  getcoordinator  ;actionstatus=failed;  get  coordinatoraction  coord1  create_time  getappname  assertequals  getaction  brlist   only 1 action satisfies the  size  bundlename  tostring  bundle=  getcreatedtime
__label__nflaky lookup  get  symbol  width  there\'s  no  rectangular  symbol  for  50  data  codewords  get  symbol  height  assert  equals  max  size  symbol  info  symbol  shape  hint  test  symbol  info  fail  assert  null  get  error  codewords  assert  not  null  there\'s  no  rectangular  symbol  for  more  than  1558  data  codewords  fixed  size  min  size  info  lookup  getsymbolwidth  there\'s no rectangular symbol for 50 data codewords  getsymbolheight  assertequals  maxsize  symbolinfo  symbolshapehint  testsymbolinfo  fail  assertnull  geterrorcodewords  assertnotnull  there\'s no rectangular symbol for more than 1558 data codewords  fixedsize  minsize  info
__label__flaky failed  proxy  users  rsrc  gr3 gr4 gr5  run  when  first  auth  for  superuser  can  proxy  for  this  group  super_user  get  user  name  authorize  gr2  then  return  so  the  server  side  will  pick  it  up  gr1  gr4  add  new  config  resource  test  refresh  super  user  groups  configuration  gr3  should\'ve  succeeded:  fail  keys  in  conf  mock  get  proxy  superuser  ip  conf  key  127.0.0.1  refresh  super  user  groups  configuration  get  proxy  superuser  group  conf  key  user  key  hosts  get  localized  message  super  user  get  group  names  admin  ugi1  l  ugi2  should\'ve  failed  succeeded  system  second  auth  for  user  l2  user  l1  su  ugi  get  short  user  name  user1  group_  names1  user2  group_  names2  set  e  set  groups  for  users  get  real  user  super_  user  args  expected  test  group  mapping  refresh_rsrc.xml  auth  for  -refresh  super  user  groups  configuration  check  before  config  user  key  groups   failed  proxyusers  rsrc  gr3 gr4 gr5  run  when  first auth for    superuser can proxy for this group  super_user  getusername  authorize  gr2  thenreturn   so the server side will pick it up  gr1  gr4  addnewconfigresource  testrefreshsuperusergroupsconfiguration  gr3   should\'ve succeeded:   fail   keys in conf  mock  getproxysuperuseripconfkey  127.0.0.1  refreshsuperusergroupsconfiguration  getproxysuperusergroupconfkey  userkeyhosts  getlocalizedmessage   super user  getgroupnames  admin  ugi1  l  ugi2   should\'ve failed    succeeded  system  second auth for   userl2  userl1  suugi  getshortusername  user1  group_names1  user2  group_names2  set  e   set groups for users  getrealuser  super_user  args   expected  testgroupmappingrefresh_rsrc.xml  auth for   -refreshsuperusergroupsconfiguration   check before  config  userkeygroups
__label__nflaky a  a  cc  e  e  gg  i  i  m  m  q  q  u  u  y  y  kk  oo  ss  ww  job  setup  b  b  dd  f  f  hh  j  j  n  n  r  r  v  v  z  z  ll  pp  tt  xx  test  camelize  some  stuff  map  map  mm  aa  c  c  yy  ee  g  g  k  k  o  o  s  s  w  w  ii  qq  uu  camelize  job_  setup  string  utils  nn  bb  d  d  zz  ff  h  h  l  l  p  p  t  t  x  x  jj  rr  vv  assert  equals  common  use  cases  sanity  checks  for  ascii  alphabet  against  unexpected  locale  issues.  some_stuff  aa  cc  ee  gg  ii  mm  qq  uu  yy  kk  oo  ss  ww  jobsetup  bb  dd  ff  hh  jj  nn  rr  vv  zz  ll  pp  tt  xx  testcamelize  somestuff  map  map  mm  aa  cc  yy  ee  gg  kk  oo  ss  ww  ii  qq  uu  camelize  job_setup  stringutils  nn  bb  dd  zz  ff  hh  ll  pp  tt  xx  jj  rr  vv  assertequals   common use cases   sanity checks for ascii alphabet against unexpected locale issues.  some_stuff
__label__flaky cluster  file_  size  conf  dir  /test  create  file  wait  active  webhdfsuri=  check  content  summary  /test/test2  /test/test1  exceeded  quota  ://  web  hdfs  file  system  dfs  config  keys  get  file  system  set  int  nn  addr  num  data  nodes  mkdirs  -set  space  quota  total  space  usage  including  shutdown  quota  is  half  consumed  quota_  size  test  block  allocation  adjusts  usage  conservatively  block_  size  admin  fs  wait  replication  system  assert  true  get  run  command  get  space  consumed  used  half  the  quota  for  the  first  file.  dfs  test  util  c  get  content  summary  webhdfs  assert  equals  creating  a  file  should  use  half  the  quota  quota  not  exceeded  repl.  integer  create  the  directory  and  set  the  quota  build  file2  webhdfsuri  to  string  file1  set  boolean  cluster  file_size  conf  dir  /test  createfile  waitactive  webhdfsuri=  checkcontentsummary  /test/test2  /test/test1  exceededquota  ://  webhdfsfilesystem  dfsconfigkeys  getfilesystem  setint  nnaddr  numdatanodes  mkdirs  -setspacequota   total space usage including  shutdown  quota is half consumed  quota_size  testblockallocationadjustsusageconservatively  block_size  admin  fs  waitreplication  system  asserttrue  get  runcommand  getspaceconsumed   used half the quota for the first file.  dfstestutil  c  getcontentsummary  webhdfs  assertequals   creating a file should use half the quota  quota not exceeded   repl.  integer   create the directory and set the quota  build  file2  webhdfsuri  tostring  file1  setboolean
__label__nflaky server  get  local  port  content  type  set  ssl  context  consume  bootstrap  set  conn  pool  listener  request1  some  stuff  set  entity  test  tls  trust  failure  create  server  ssl  context  set  socket  config  context  create  https  /stuff  set  exception  listener  create  default  requester  ssl  contexts  localhost  ssl  test  contexts  socket  config  set  stream  listener  custom  logging  http1  stream  listener  start  *  set  so  timeout  method  get  entity  execute  server  bootstrap  target  entity  utils  logging  conn  pool  listener  build  logging  exception  listener  requester  bootstrap  timeout  response1  register  server  getlocalport  contenttype  setsslcontext  consume  bootstrap  setconnpoollistener  request1  some stuff  setentity  testtlstrustfailure  createserversslcontext  setsocketconfig  context  create  https  /stuff  setexceptionlistener  createdefault  requester  sslcontexts  localhost  ssltestcontexts  socketconfig  setstreamlistener  custom  logginghttp1streamlistener  start  *  setsotimeout  method  getentity  execute  serverbootstrap  target  entityutils  loggingconnpoollistener  build  loggingexceptionlistener  requesterbootstrap  timeout  response1  register
__label__flaky test  interrupts  with  composite  callable  initial  callable  callables  key5  type  queue  serial  *  assuring  an  interrupt  command  will  be  executed  before  a  composite  *  callable  with  the  same  lock  key  queueservice  initial  key  assert  true  get  initial  type  lock  key  wait  for  key  exec_  order  add  init  c  initial  lock  key  ret  value  callable  queue  service  destroy  services  1  test  kill  int  callable  set  system  property  evaluate  queue  testinterruptswithcompositecallable  initialcallable  callables  key5  type  queueserial         * assuring an interrupt command will be executed before a composite       * callable with the same lock key         queueservice  initialkey  asserttrue  get  initialtype  lockkey  waitfor  key  exec_order  add  init  c  initiallockkey  retvalue  callablequeueservice  destroy  services  1  testkill  intcallable  setsystemproperty  evaluate  queue
__label__nflaky assert  correct  image2string  (11)100224(17)110224(3102)000100  test  decode  row2string1  1.png  assertcorrectimage2string  (11)100224(17)110224(3102)000100  testdecoderow2string1  1.png
__label__flaky context  get  class  get  resource  css  test  folder  test  expected  expected  folder  get  file  get  config  url  test  from  folder  set  ignore  missing  resources  get  wro  test  utils  compare  from  different  folders  by  extension  css  import  victim  context  getclass  getresource  css  testfolder  test  expected  expectedfolder  getfile  getconfig  url  testfromfolder  setignoremissingresources  get  wrotestutils  comparefromdifferentfoldersbyextension  cssimport  victim
__label__nflaky r2  get  name  output  test.*.source.filter.exclude  get  test  filename  test  put  metrics  when  we  call  stop   at  most  two  sources  will  be  consumed  by  each  sink  thread.  s0  s1  add  check  metrics  records  ms  get  all  values  capture  test.sink.test.class  mr2  mr1  s1  desc  stop  size  *.period  test  metrics  config  test.sink.sink1.metric.filter.exclude  mock  shutdown  s0rec  publish  the  metrics  test.sink.sink2.metric.filter.exclude  save  test.source.s1.metric.filter.exclude  x*  verify  at  most  sink2  desc  hadoop-metrics2-test  s1rec  set  register  sink  default  metrics  system  incr  start  sink1  desc  assert  equals  y*  s0  desc  test  init  first  verify  stop  invoked  immediately  sink2  sink1  publish  metrics  now  register  r1  r2  getname  output  test.*.source.filter.exclude  gettestfilename  test  putmetrics   when we call stop  at most two sources will be consumed by each sink thread.  s0  s1  add  checkmetricsrecords  ms  getallvalues  capture  test.sink.test.class  mr2  mr1  s1 desc  stop  size  *.period  testmetricsconfig  test.sink.sink1.metric.filter.exclude  mock  shutdown  s0rec   publish the metrics  test.sink.sink2.metric.filter.exclude  save  test.source.s1.metric.filter.exclude  x*  verify  atmost  sink2 desc  hadoop-metrics2-test  s1rec  set  registersink  defaultmetricssystem  incr  start  sink1 desc  assertequals  y*  s0 desc  testinitfirstverifystopinvokedimmediately  sink2  sink1  publishmetricsnow  register  r1
__label__flaky <value>  a</value>  <name>a</name>  <job-tracker>foo</job-tracker>  expected  d  validate  and  parse  </prepare>  </property>  replace  all  <archive>/tmp</archive>  <configuration>  wf-schema-valid-global.xml  </configuration>  app  <file>/tmp</file>  <mkdir  path=\""/tmp\""  />  d  get  conf  <reducer>/mywc.sh</reducer>  <prepare>  test  parser  global  <mapper>/mycat.sh</mapper>  <name>b</name>  assert  equals  <value>  b</value>  </map-reduce>  io  utils  parser  </streaming>  <streaming>  get  resource  as  reader  <property>  get  node  <delete  path=\""/tmp\""  />  <map-reduce  xmlns=\""uri:oozie:workflow:0.4\"">  <job-xml>/tmp</job-xml>  <name-node>bar</name-node>          <value>a</value>          <name>a</name>      <job-tracker>foo</job-tracker>    expectedd  validateandparse    </prepare>        </property>    replaceall    <archive>/tmp</archive>      <configuration>    wf-schema-valid-global.xml    </configuration>    app       <file>/tmp</file>        <mkdir path=\""/tmp\"" />    d  getconf      <reducer>/mywc.sh</reducer>      <prepare>    testparserglobal      <mapper>/mycat.sh</mapper>          <name>b</name>    assertequals        <value>b</value>    </map-reduce>  ioutils  parser    </streaming>      <streaming>    getresourceasreader      <property>    getnode      <delete path=\""/tmp\"" />    <map-reduce xmlns=\""uri:oozie:workflow:0.4\"">      <job-xml>/tmp</job-xml>      <name-node>bar</name-node>
__label__nflaky /0/1/2/mode/test  request  core  matchers  equal  to  test  mode  works.  assert  that  make  request  url  path  assert  test  test  mode  index012  response  get  test  server  url  /0/1/2/mode/test  request  corematchers  equalto  test mode works.  assertthat  makerequest  url  path  assert  testtestmodeindex012  response  get  testserverurl
__label__flaky validate  and  parse  conf  wf-invalid-fork.xml  oozie  level  default   wf  level  disabled  oozie  level  enabled   wf  level  enabled  oozie.wf.validate.  fork  join  oozie  level  enabled   wf  level  default  get  error  code  get  oozie  level  enabled   wf  level  disabled  oozie  level  disabled   wf  level  default  oozie  level  disabled   wf  level  disabled  init  set  false  get  message  destroy  assert  equals  oozie.validate.  fork  join  oozie  level  disabled   wf  level  enabled  test  disable  wf  validate  fork  join  services  io  utils  parser  e0730:  fork/  join  not  in  pair  wfe  set  system  property  get  resource  as  reader  true  oozie  level  default   wf  level  enabled  error  code  oozie  level  default   wf  level  default  validateandparse  conf  wf-invalid-fork.xml   oozie level default  wf level disabled   oozie level enabled  wf level enabled  oozie.wf.validate.forkjoin   oozie level enabled  wf level default  geterrorcode  get   oozie level enabled  wf level disabled   oozie level disabled  wf level default   oozie level disabled  wf level disabled  init  set  false  getmessage  destroy  assertequals  oozie.validate.forkjoin   oozie level disabled  wf level enabled  testdisablewfvalidateforkjoin  services  ioutils  parser  e0730: fork/join not in pair  wfe  setsystemproperty  getresourceasreader  true   oozie level default  wf level enabled  errorcode   oozie level default  wf level default
__label__nflaky set  depth  first  prepare  item2  item1  process  arguments  depth  first  max  depth  conf  set  root  expression  when  set  out  out  result  check  max  depth  is  handled  when  -depth  is  specified  find  in  order  verify  set  options  expr  finish  item1b  item1a  item5e  item5d  item5c  create  directories  item5b  item5a  set  err  fs  check  set  max  depth  err  test  in  order  fs  check  apply  then  return  check  process  arguments  any  set  conf  any  int  verify  no  more  interactions  mock  get  options  item4  items  item3  item5  setdepthfirst  prepare  item2  item1  processargumentsdepthfirstmaxdepth  conf  setrootexpression  when  setout  out  result   check max depth is handled when -depth is specified  find  inorder  verify  setoptions  expr  finish  item1b  item1a  item5e  item5d  item5c  createdirectories  item5b  item5a  seterr  fscheck  setmaxdepth  err  test  inorderfscheck  apply  thenreturn  check  processarguments  any  setconf  anyint  verifynomoreinteractions  mock  getoptions  item4  items  item3  item5
__label__flaky get  current  dateafter  incrementing  in  months  run  get  id  date  utils  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  test  coord  status  transit  service  stale  coord  actions  add  a  record  with  stale  reference  to  coord  job  id  sleep  get  coordinator  action  end  this  block  will  initialize  the  lastinstancetime  for  status  transit  service  current  date  plus  month  abcd  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  add  records  with  reference  to  correct  job  ids  coordinator  job  services  runnable  coord-action-get.xml  job  jpa  service  getcurrentdateafterincrementinginmonths  run  getid  dateutils  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  testcoordstatustransitservicestalecoordactions   add a record with stale reference to coord job id  sleep  get  coordinatoraction  end   this block will initialize the lastinstancetime for status transit service  currentdateplusmonth  abcd  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable   add records with reference to correct job ids  coordinatorjob  services  runnable  coord-action-get.xml  job  jpaservice
__label__nflaky encode  0  0  0  0  1  1  1  1  0  1  1  0  1  0  1  1  0  0  0  1  0  <<  mask  pattern:  4  1  0  1  1  1  0  1  0  0  1  0  1  0  0  1  0  1  1  1  0  1  >>  0  0  0  0  0  0  0  0  1  1  0  0  0  1  1  0  0  0  1  0  1  ec  level:  h  1  1  1  1  1  1  1  0  0  1  0  1  0  0  1  1  1  1  1  1  1  abcdef  1  0  0  1  1  1  0  0  1  1  1  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  0  qr  code  encoder  matrix:  1  0  0  0  0  0  1  0  1  1  0  1  0  0  0  1  0  1  1  1  1  1  1  1  1  1  1  1  0  1  1  1  1  0  0  0  0  0  1  1  0  0  expected  assert  equals  0  0  0  0  1  1  0  1  1  1  0  0  1  1  1  1  0  1  1  0  1  version:  1  0  1  1  1  1  1  1  0  1  0  1  0  1  1  1  0  0  1  1  0  0  1  0  0  0  0  0  1  0  1  0  0  1  1  0  1  0  0  0  0  0  1  1  0  1  1  1  0  1  0  0  0  0  0  0  0  1  0  1  1  1  0  1  1  1  1  1  1  1  1  0  0  0  1  0  0  1  0  0  0  0  1  1  1  1  0  0  0  0  1  1  0  0  1  0  1  0  0  0  1  1  1  0  1  1  1  0  0  0  0  0  1  0  1  0  1  0  1  0  1  0  0  0  0  0  1  1  0  1  1  1  0  1  0  0  1  0  1  0  0  0  1  1  0  0  0  0  1  0  0  0  0  0  1  0  0  1  0  0  1  0  0  1  1  0  0  0  1  test  encode  1  0  1  1  1  0  1  0  1  0  0  1  0  0  0  1  1  0  0  1  1  mode:  alphanumeric  1  0  1  1  1  0  1  0  0  1  0  0  1  0  1  0  1  1  1  0  1  to  string  1  1  1  1  1  1  1  0  1  0  1  0  1  0  1  1  1  1  1  1  1  error  correction  level  1  0  1  1  1  0  1  0  0  0  1  1  0  1  0  0  0  0  1  1  1  encode   0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0    <<     maskpattern: 4     1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1    >>     0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1     eclevel: h     1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1    abcdef   1 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0     0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0    qrcode  encoder   matrix:     1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1     1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 1 0 0    expected  assertequals   0 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1     version: 1     0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0     1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 1     1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 1     1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1     1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 1 1     1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1     1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0     1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 1    testencode   1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1     mode: alphanumeric     1 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 1 1 1 0 1    tostring   1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1    errorcorrectionlevel   1 0 1 1 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1
__label__flaky bab  add  record  to  bundle  action  table  cab  get  user  add  record  to  wf  action  table  get  id  workflow  instance  get  topic  add  record  to  coord  action  table  coord-action-for-action-input-check.xml  add  record  to  wf  job  table  get  coordinator  action  wab  cjb  bjb  workflow  job  job  test  topic  as  user  get  bundle  action  id  print  stack  trace  e  add  record  to  bundle  job  table  get  message  jms  topic  service  assert  equals  add  record  to  coord  job  table  fail  services  1  coordinator  job  workflow  action  wfj  bab  addrecordtobundleactiontable  cab  getuser  addrecordtowfactiontable  getid  workflowinstance  gettopic  addrecordtocoordactiontable  coord-action-for-action-input-check.xml  addrecordtowfjobtable  get  coordinatoraction  wab  cjb  bjb  workflowjob  job  testtopicasuser  getbundleactionid  printstacktrace  e  addrecordtobundlejobtable  getmessage  jmstopicservice  assertequals  addrecordtocoordjobtable  fail  services  1  coordinatorjob  workflowaction  wfj
__label__nflaky view  fs  get  child  file  system  view  fs  path1  mockfs2:/  view  fs  path2  remove  default  acl  /d/e/f  remove  acl  conf  set  acl  view  file  system  test  setup  get  raw  file  system  mock  fs2  mock  fs1  empty  list  setup  mock  file  system  file  system  get  mockfs1:/  /a/b/c  verify  /mounts/mockfs2/d/e/f  collections  remove  acl  entries  test  acl  methods  mock  fs  path2  get  acl  status  mock  fs  path1  create  config  fs  constants  entries  modify  acl  entries  /mounts/mockfs1/a/b/c  viewfs  getchildfilesystem  viewfspath1  mockfs2:/  viewfspath2  removedefaultacl  /d/e/f  removeacl  conf  setacl  viewfilesystemtestsetup  getrawfilesystem  mockfs2  mockfs1  emptylist  setupmockfilesystem  filesystem  get  mockfs1:/  /a/b/c  verify  /mounts/mockfs2/d/e/f  collections  removeaclentries  testaclmethods  mockfspath2  getaclstatus  mockfspath1  createconfig  fsconstants  entries  modifyaclentries  /mounts/mockfs1/a/b/c
__label__flaky get  status  sub  workflow  action  executor  proto  conf  create  base  workflow  get  workflow  client  new  conf  xyz  create  action  </app-path>  workflow.xml  write  get  base  proto  conf  wait  for  workflow  test  config  not  propagation  get  file  system  check  child  conf  </configuration>  workflow  action  file  evaluate  <sub-workflow  xmlns=\'uri:oozie:workflow:0.1\'  name=\'subwf\'>  <app-path>  <configuration>  get  job  info  <name>a</name>  </property>  get  actions  get  external  id  fs  app1  <value>  a</value>  wf  w  get  end  workflow  job  close  abc  set  get  conf  oozie  client  <property>  start  default  conf  sub  workflow  app  path  sub  workflow  assert  equals  job_  timeout  set  conf  assert  null  to  xml  string  </sub-workflow>  writer  get  fs  test  case  dir  getstatus  subworkflowactionexecutor  protoconf  createbaseworkflow  getworkflowclient  newconf  xyz  create  action  </app-path>  workflow.xml  write  getbaseprotoconf  waitfor  workflow  testconfignotpropagation  getfilesystem  check  childconf        </configuration>  workflowaction  file  evaluate  <sub-workflow xmlns=\'uri:oozie:workflow:0.1\' name=\'subwf\'>        <app-path>        <configuration>  getjobinfo            <name>a</name>          </property>  getactions  getexternalid  fs  app1            <value>a</value>  wf  w  get  end  workflowjob  close  abc  set  getconf  oozieclient          <property>  start  defaultconf  subworkflowapppath  subworkflow  assertequals  job_timeout  setconf  assertnull  toxmlstring  </sub-workflow>  writer  getfstestcasedir
__label__nflaky new.conf.to.replace.deprecated.conf  configuration  test  read  write  with  deprecated  keys  write  xml  conf  old.config.yet.to.be.deprecated  file  contents  add  deprecation  out  contains  assert  true  tests  reading  /  writing  a  conf  file  with  deprecation  after  setting  to  string  close  set  boolean  new.conf.to.replace.deprecated.conf  configuration  testreadwritewithdeprecatedkeys  writexml  conf  old.config.yet.to.be.deprecated  filecontents  adddeprecation  out  contains  asserttrue   tests reading / writing a conf file with deprecation after setting  tostring  close  setboolean
__label__flaky delete  list  add  record  to  bundle  action  table  bundle  action  b2  should  have  been  deleted  bundle  job  b  should  have  been  deleted  get  id  action  c1  action  c2  bundle  action  b1  should  have  been  deleted  action  a1  action  a2  bundle  action  a2  should  have  been  deleted  test  delete  bundles  bundle  action  a1  should  have  been  deleted  job  b  job  a  get  error  code  assert  not  null  job  c  get  job  get  bundle  id  bundle  job  a  should  have  been  deleted  add  get  coord  name  add  record  to  bundle  job  table  assert  equals  action  b1  execute  action  b2  services  fail  bundle  job  c  should  have  been  deleted  bundle  action  c2  should  have  been  deleted  error  code  je  bundle  action  c1  should  have  been  deleted  jpa  service  deletelist  addrecordtobundleactiontable  bundle action b2 should have been deleted  bundle job b should have been deleted  getid  actionc1  actionc2  bundle action b1 should have been deleted  actiona1  actiona2  bundle action a2 should have been deleted  testdeletebundles  bundle action a1 should have been deleted  jobb  joba  geterrorcode  assertnotnull  jobc  get  job  getbundleid  bundle job a should have been deleted  add  getcoordname  addrecordtobundlejobtable  assertequals  actionb1  execute  actionb2  services  fail  bundle job c should have been deleted  bundle action c2 should have been deleted  errorcode  je  bundle action c1 should have been deleted  jpaservice
__label__nflaky standard  charsets  assert  equals  get  bytes  entity  utils  assert  bytes  assert  not  null  to  byte  array  message  content  test  unknown  length  content  to  byte  array  bytes2  entity  standardcharsets  assertequals  getbytes  entityutils  assert  bytes  assertnotnull  tobytearray  message content  testunknownlengthcontenttobytearray  bytes2  entity
__label__flaky bc  cluster  start  up  cluster  shut  down  cluster  reset  configuration  get  pending  replication  blocks  dn  r  conf  bl  dn  wait  for  temp  replica  find  block  dn_  n0  block  report  get  bytes  chk  sum  dn_  n1  join  block  report_08  write  file  dfs  config  keys  return  the  initial  state  of  the  configuration  get  data  nodes  get  block  pool  id  get  method  name  all  blocks  belong  to  the  same  file   hence  same  bp  blocks  get  block  list  as  longs  file  path  start  generic  test  utils  assert  equals  get  name  node  rpc  wrong  number  of  pending  replication  blocks  /  set  int  print  stats  set  long  size  pool  id  method_  name  .dat  get  namesystem  get  dn  registration  for  bp  bc  cluster  startupcluster  shutdowncluster  resetconfiguration  getpendingreplicationblocks  dnr  conf  bl  dn  waitfortempreplica  findblock  dn_n0  blockreport  get  byteschksum  dn_n1  join  blockreport_08  writefile  dfsconfigkeys   return the initial state of the configuration  getdatanodes  getblockpoolid  getmethodname   all blocks belong to the same file  hence same bp  blocks  getblocklistaslongs  filepath  start  generictestutils  assertequals  getnamenoderpc  wrong number of pendingreplication blocks  /  setint  printstats  setlong  size  poolid  method_name  .dat  getnamesystem  getdnregistrationforbp
__label__nflaky get  name  token  signed  token_  validity_  sec  sign  when  as  list  get  init  parameter  names  invalidtype  assert  secret  provider  management.operation.return  signer  init  cookie  then  return  string  signer  secret  provider  creator  destroy  failed  ex  get  init  parameter  new  string  signer  secret  provider  set  property  true  mock  arrays  request  invalid  authentication  token  type  set  expires  secret  system  secret  provider  props  assert  true  get  cookies  authenticated  url  authentication  filter  get  message  assert  equals  token  token  not  invalid  type  filter  p  get  mocked  servlet  context  with  string  signer  mockito  u  elements  current  time  millis  get  token  to  string  config  test  get  token  invalid  type  getname  tokensigned  token_validity_sec  sign  when  aslist  getinitparameternames  invalidtype  assert  secretprovider  management.operation.return  signer  init  cookie  thenreturn  stringsignersecretprovidercreator  destroy  failed  ex  getinitparameter  newstringsignersecretprovider  setproperty  true  mock  arrays  request  invalid authenticationtoken type  setexpires  secret  system  secretproviderprops  asserttrue  getcookies  authenticatedurl  authenticationfilter  getmessage  assertequals  token  token not invalid type  filter  p  getmockedservletcontextwithstringsigner  mockito  u  elements  currenttimemillis  gettoken  tostring  config  testgettokeninvalidtype
__label__flaky end_  points  rest  constants  is_  security_  enabled  get  context  url  oozie  url  mock  dag  engine  service  run  assert  equals  test  resume  args  call  1  -oozie  size  job  -resume  servlet_  classes  run  test  end_points  restconstants  is_security_enabled  getcontexturl  oozieurl  mockdagengineservice  run  assertequals  testresume  args  call  1  -oozie  size  job  -resume  servlet_classes  runtest
__label__nflaky cache  mock  key  asserting  no  caching  when  key  is  not  known  get  current  key  get  conf  k1  then  return  k2  assert  equals  eq  when  thread  sleep  test  current  key  times  assert  mockito  mock  verify  asserting  caching  mock  prov  cache  mockkey   asserting no caching when key is not known  getcurrentkey  getconf  k1  thenreturn  k2  assertequals  eq  when  thread  sleep  testcurrentkey  times  assert  mockito  mock  verify   asserting caching  mockprov
__label__flaky play  ack  android  http_20_  draft_09  header  entries  shouldnt  impact  connection  accept  frame  this  stream  was  created  *after*  the  connection  settings  were  adjusted.  ack  2  assert  true  stream  get  initial  window  size  peer  default_  initial_  window_  size  type_  settings  connection  settings  headers  take  frame  settings  a  set  set  variant  and  client  initial  ack  frame  new  stream  is  has  the  most  recent  initial  window  size.  peer  http2  server  lowers  initial  window  size  initial  wasn\'t  affected.  persist_  value  assert  equals  send  frame  verify  the  peer  received  the  ack  new  stream  play   ack  android  http_20_draft_09  headerentries  shouldntimpactconnection  acceptframe   this stream was created *after* the connection settings were adjusted.   ack 2  asserttrue  stream  getinitialwindowsize  peer  default_initial_window_size  type_settings  connection  settings   headers  takeframe  settings  a  set  setvariantandclient  initial  ackframe   new stream is has the most recent initial window size.  peerhttp2serverlowersinitialwindowsize   initial wasn\'t affected.  persist_value  assertequals  sendframe   verify the peer received the ack  newstream
__label__nflaky secure  filter  test  that  username  is  correct  equal  to  assert  that  username  securefilter  testthatusernameiscorrect  equalto  assertthat  username
__label__flaky _test  update  wf  after  _test  get  actions()  _test  get  wf  _test  get  status  count  _test  insert  wf  _test  get  wf  infos();  _test  get  pending  actions  after  _test  pending  action()  after  _test  wf  info()  _test  purge  system  _test  get  action  for  wf  failure  _test  get  wfid  with  ext  id  _test  get  actions  for  wf  after  _test  get  action  for  wf  failure()  test  db  workflow  store  _test  load  action  _test  save  action  _test  delete  action  _test  wait  write  lock();  _test  update  action  after  _test  get  wf  infos()  _test  get  wf  info  _testupdatewf  after _testgetactions()  _testgetwf  _testgetstatuscount  _testinsertwf   _testgetwfinfos();  _testgetpendingactions  after _testpendingaction()  after _testwfinfo()  _testpurge  system  _testgetactionforwffailure  _testgetwfidwithextid  _testgetactionsforwf  after _testgetactionforwffailure()  testdbworkflowstore  _testloadaction  _testsaveaction  _testdeleteaction   _testwaitwritelock();  _testupdateaction  after _testgetwfinfos()  _testgetwfinfo
__label__nflaky whitelist  based  resolver  10.119.103.112  set  10.113.221.221  sasl_  privacy_  props  10.221.102.0/23  conf  get  server  properties  assert  equals  set  conf  test  null  ip  address  fixed  ips  create  file  with  entries  set  long  variablewhitelist.txt  remove  file  test  file  based  ip  list  wqr  variable  ips  10.222.0.0/16  fixedwhitelist.txt  set  boolean  whitelistbasedresolver  10.119.103.112  set  10.113.221.221  sasl_privacy_props  10.221.102.0/23  conf  getserverproperties  assertequals  setconf  testnullipaddress  fixedips  createfilewithentries  setlong  variablewhitelist.txt  removefile  testfilebasediplist  wqr  variableips  10.222.0.0/16  fixedwhitelist.txt  setboolean
__label__flaky cluster  handler  hi  set  last  heartbeat  time  set  hardware  profile  hm  set  hostname  after  registration  and  by  heartbeat  monitor  set  node  status  get  cluster  map  hosts  to  cluster  centos5  handle  registration  reg  set  response  id  join  get  host  info  add  add  cluster  log  command  captor  get  server  version  get  all  values  capture  am  eq  role  is  alive  fail  set  agent  version  size  name  yyy  mock  aq  mock  add  service  component  hdp-0.1  shutdown  set  desired  stack  version  set  os  host  names  get  service  name  system  sleep  hostname1  add  service  assert  true  centos5  cluster  name  cmds  heartbeat  monitor  should  generate  status  commands  for  host1  for  class  verify  host  status  persist  injector  clusters  set  timestamp  get  service  component  argument  captor  handle  heart  beat  heartbeat  monitor  should  be  already  stopped  cool  ambari  meta  info  start  hdfs  assert  equals  add  service  component  host  service  name  add  host  command  test  heartbeat  state  commands  enqueueing  thread  enqueue  set  os  type  current  time  millis  hdfs  heartbeat  monitor  wakeup  interval  ms  hb  at  least  get  instance  cluster  handler  hi  setlastheartbeattime  sethardwareprofile  hm  sethostname   after registration and by heartbeatmonitor  setnodestatus  getcluster  maphoststocluster  centos5  handleregistration  reg  setresponseid  join  gethost  info  add  addcluster  log  commandcaptor  getserverversion  getallvalues  capture  am  eq  role  isalive  fail  setagentversion  size  name  yyy  mock  aqmock  addservicecomponent  hdp-0.1  shutdown  setdesiredstackversion  setos  hostnames  getservicename  system  sleep  hostname1  addservice  asserttrue  centos5  clustername  cmds  heartbeatmonitor should generate statuscommands for host1  forclass  verify  hoststatus  persist  injector  clusters  settimestamp  getservicecomponent  argumentcaptor  handleheartbeat  heartbeatmonitor should be already stopped  cool  ambarimetainfo  start  hdfs  assertequals  addservicecomponenthost  servicename  addhost  command  testheartbeatstatecommandsenqueueing  thread  enqueue  setostype  currenttimemillis  hdfs  heartbeatmonitorwakeupintervalms  hb  atleast  getinstance
__label__nflaky test  file01  get  path  data  testfile01  get  time  add  contents  ls  format  line  mtime  out  found  3  items  check  multiple  directories  are  order  independently  testfile03  options  compute  line  format  in  order  testfile02  process  options  verify  testfile05  test  file06  set  mtime  testfile04  test  file04  test  file05  testfile06  test  file02  test  file03  set  file  mtime  in  different  order  to  file  names  add  path  data  line  format  -t  set  is  dir  process  arguments  verify  no  more  interactions  now  test  file  mock  test  dir02  test  dir01  process  path  dirs  order  mtime  test  directory02  test  directory01    testfile01  getpathdata  testfile01  gettime  addcontents  ls  formatlinemtime  out  found 3 items   check multiple directories are order independently  testfile03  options  computelineformat  inorder  testfile02  processoptions  verify  testfile05  testfile06  setmtime  testfile04  testfile04  testfile05  testfile06  testfile02  testfile03   set file mtime in different order to file names  add  pathdata  lineformat  -t  setisdir  processarguments  verifynomoreinteractions  now  testfile  mock  testdir02  testdir01  processpathdirsordermtime  testdirectory02  testdirectory01
__label__flaky get  class  test  assert  true  writable  name  equals  conf  test  add  name  alt  name  add  name  check  original  name  still  works  .alt  test  name  getclass  test  asserttrue  writablename  equals  conf  testaddname  altname  addname   check original name still works  .alt  testname
__label__nflaky read  skip  assert  equals  in2  in  buffer3  in1  in  buffer4  in  buffer1  in4  in  buffer2  in3  assert  test  skip  assert  true  input  stream4  input  stream3  input  stream2  input  stream1  close  read  skip  assertequals  in2  inbuffer3  in1  inbuffer4  inbuffer1  in4  inbuffer2  in3  assert  testskip  asserttrue  inputstream4  inputstream3  inputstream2  inputstream1  close
__label__flaky obtain  the  service  proxy  features  i\'m  some  service  active  assert  equals  some  service  disable  the  feature  flag  feature  context  get  spring  bean  assert  not  null  get  feature  manager  who  are  you  some  service  auto  detect  proxy  type  set  feature  state  i\'m  some  service  inactive  first  the  inactive  service  is  invoked  calls  are  now  delegated  to  the  other  service  implementation  enable  the  feature  flag  test  proxy  with  auto  detected  proxy  type   obtain the service  proxyfeatures  i\'m someserviceactive  assertequals  someservice   disable the feature flag  featurecontext  getspringbean  assertnotnull  getfeaturemanager  whoareyou  someserviceautodetectproxytype  setfeaturestate  i\'m someserviceinactive   first the inactive service is invoked   calls are now delegated to the other service implementation   enable the feature flag  testproxywithautodetectedproxytype
__label__nflaky aaa  ccc  name4=  value+4\%26  name4=  value+4\%26+\%3  d4  value1  xx   yy   zz  name4  name5  assert  name6  name7=aaa&  name7=b\%2  cb&  name7=ccc  name7  name2=  name8  name7=aaa;  name7=b\%2  cb;  name7=ccc  b b  name8=xx\%2  c++yy++\%2  czz  name1=  value1  name0  name1  name2  add  value+4&  bbb  name5=aaa&  name6=bbb  url  encoded  utils  standard  charsets  format  length  clear  assert  equals  params  test  format  value  4&  name4=  value\%2  b4\%26  value  4&  =4    aaa  ccc  name4=value+4\%26  name4=value+4\%26+\%3d4  value1  xx   yy   zz  name4  name5  assert  name6  name7=aaa&name7=b\%2cb&name7=ccc  name7  name2=  name8  name7=aaa;name7=b\%2cb;name7=ccc  b b  name8=xx\%2c++yy++\%2czz  name1=value1  name0  name1  name2  add  value+4&  bbb  name5=aaa&name6=bbb  urlencodedutils  standardcharsets  format  length  clear  assertequals  params  testformat  value 4&  name4=value\%2b4\%26  value 4& =4
__label__flaky test  count  put  thread  table  name  bytes  test  writes  while  scanning  scanner  join  prev  timestamp  new  binary  comparator(  bytes.to  bytes(\""row0\""))));  res  row1  row0  method  check  no  error  to  bytes  qualifiers  done  init  h  region  size  flush  interval  previous  empty  region  next  num  rows  scan  flush  assert  true  get  timestamp  get  timestamps  were  broke:  timestamp  num  qualifiers  system.out.println(\""flush  scan  iteration  =  \""  +  i);  prev:  start  is  empty  clear  num  families  assert  equals  expected  count  families  flushcache  i=  compact  stores  flush  thread  compact  interval  qual  family  get  scanner  testcount  putthread  tablename  bytes  testwriteswhilescanning  scanner  join  prevtimestamp   new binarycomparator(bytes.tobytes(\""row0\""))));  res  row1  row0  method  checknoerror  tobytes  qualifiers  done  inithregion  size  flushinterval  previousempty  region  next  numrows  scan  flush  asserttrue  gettimestamp  get  timestamps were broke:   timestamp  numqualifiers   system.out.println(\""flush scan iteration = \"" + i);   prev:   start  isempty  clear  numfamilies  assertequals  expectedcount  families  flushcache  i=  compactstores  flushthread  compactinterval  qual  family  getscanner
__label__nflaky get  parsed  type  no  null  form  primitives  parse  parameter  asdfasdf  is  matchers  assert  that  test  primitive  float  param  parser  param1  0  000  -123  123  0.1  float  param  parser  123.1  -123.1  validation    getparsedtype   no null form primitives  parseparameter  asdfasdf  is  matchers  assertthat  testprimitivefloatparamparser  param1  0  000  -123  123  0.1  floatparamparser  123.1  -123.1  validation
__label__flaky auth  calls  for  header  size  calls  realm=\""testrealm@host.com\""   qop=\""auth auth-int\""   assert  equals  nonce=\""dcd98b7102dd2f0e8b11d0f600bfb0c093\""   www-  authenticate:  digest  digest  authentication  opaque=\""5ccc069c403ebaf9f0171e9517f40e41\""  http://code.google.com/p/android/issues/detail?id=11140  authcallsforheader  size  calls  realm=\""testrealm@host.com\""  qop=\""auth auth-int\""    assertequals  nonce=\""dcd98b7102dd2f0e8b11d0f600bfb0c093\""    www-authenticate: digest   digestauthentication  opaque=\""5ccc069c403ebaf9f0171e9517f40e41\""   http://code.google.com/p/android/issues/detail?id=11140
__label__nflaky never  flush  a  b  25   50   75  c  4  out  of  8  calls  ns  hadoop:service=  conf  force  decay  test  priority  management  factory  scheduler  get  attribute  2  out  of  6  calls  assert  true  get  expected  jmx  for  call  volume  summary  after  decay  get  expected  jmx  of  call  volume  summary  before  decay  0  out  of  2  calls  get  platform  m  bean  server  1  out  of  1  calls  5  out  of  9  calls  mxbean  name  get  priority  increment  call  count  call  volume  summary  set  0  out  of  4  calls  decay  rpc  scheduler   name=  decay  rpc  scheduler  99999999  assert  equals  {\""  a\"":3 \""  b\"":1 \""  c\"":1}  3  out  of  7  calls  deprecation  .  1  out  of  3  calls  0  out  of  0  calls  equals  namespace  1  out  of  5  calls  cvs2  {\""  a\"":6 \""  b\"":2 \""  c\"":2}  mbs  cvs1   never flush  a  b  25  50  75  c   4 out of 8 calls  ns  hadoop:service=  conf  forcedecay  testpriority  managementfactory  scheduler  getattribute   2 out of 6 calls  asserttrue  get expected jmx for callvolumesummary after decay  get expected jmx of callvolumesummary before decay   0 out of 2 calls  getplatformmbeanserver   1 out of 1 calls   5 out of 9 calls  mxbeanname  getpriorityincrementcallcount  callvolumesummary  set   0 out of 4 calls  decayrpcscheduler   name=decayrpcscheduler  99999999  assertequals  {\""a\"":3 \""b\"":1 \""c\"":1}   3 out of 7 calls  deprecation  .   1 out of 3 calls   0 out of 0 calls  equals  namespace   1 out of 5 calls  cvs2  {\""a\"":6 \""b\"":2 \""c\"":2}  mbs  cvs1
__label__flaky add  record  to  bundle  job  table  negative  bundle  job  get  executor  job1  test  bundle  start  negative2  get  id  assert  equals  get  status  execute  call  services  assert  not  null  get  equals  job  job  jpa  service  evaluate  wait  for  addrecordtobundlejobtablenegative  bundlejobgetexecutor  job1  testbundlestartnegative2  getid  assertequals  getstatus  execute  call  services  assertnotnull  get  equals  job  job  jpaservice  evaluate  waitfor
__label__nflaky text/html  assert  true  is  textual  context  type  smoke  get  sub  type  html  assert  equals  content  type  util  text/html  asserttrue  istextual  contexttype  smoke  getsubtype  html  assertequals  contenttypeutil
__label__flaky row_1  row_2  test  multi  cell  get  put  xml  add  row  put  table  path  bytes  check  value  xml  marshal  yield  get  client  value_1  value_3  marshaller  value_2  get  code  make  sure  the  fake  row  was  not  actually  created  value_4  add  cell  to  bytes  assert  equals  cell  set  model  check  that  all  of  the  values  were  created  /  thread  delete  row  row  model  column_2  column_1  response  /fakerow  deliberate  nonexistent  row  to  string  writer  mimetype_  xml  row_1  row_2  testmulticellgetputxml  addrow  put  table  path  bytes  checkvaluexml  marshal  yield  get  client  value_1  value_3  marshaller  value_2  getcode   make sure the fake row was not actually created  value_4  addcell  tobytes  assertequals  cellsetmodel   check that all of the values were created  /  thread  deleterow  rowmodel  column_2  column_1  response  /fakerow   deliberate nonexistent row  tostring  writer  mimetype_xml
__label__nflaky src  src  exists   and  target  is  a  non-empty  directory:  src  file  src  exists   and  target  does  not  exist:  replace  file  delete  target  test  replace  file  check  up  the  post-condition:  nothing  is  deleted:  assert  true  tmp  target  file  mkdirs  exists  setup  dirs  src  exists  and  target  is  a  regular  file:  create  new  file  file  util  obstacle  is  directory  src   src exists  and target is a non-empty directory:  srcfile   src exists  and target does not exist:  replacefile  delete  target  testreplacefile   check up the post-condition: nothing is deleted:  asserttrue  tmp  targetfile  mkdirs  exists  setupdirs   src exists and target is a regular file:  createnewfile  fileutil  obstacle  isdirectory
__label__flaky get  connection  context  get  event  message  end  date  error  code  conf  parse  date  utc  date  utils  get  status  coord  action  success  message  wf-app-name1  get  end  time  ca  job  id1  ca  id1  coordinator  action  2012-07-22  t00:00  z  get  start  time  message  type  2011-07-11  t00:00  z  init  print  stack  trace  get  text  fail  contains  create  consumer  test  on  coordinator  job  success  event  app  type  start  date  get  parent  id  get  app  type  cae  session  coord  event  listener  assert  false  jms  messaging  utils  get  event  status  get  user  event  status  get  id  create  session  get  topic  on  coordinator  action  event  jms  context  consumer  user1  missing  dependency  get  message  type  nominal  time  receive  get  app  name  e  error  message  get  message  assert  equals  message  set  end  time  session  getconnectioncontext  geteventmessage  enddate  errorcode  conf  parsedateutc  dateutils  getstatus  coordactionsuccessmessage  wf-app-name1  getendtime  cajobid1  caid1  coordinatoraction  2012-07-22t00:00z  getstarttime  messagetype  2011-07-11t00:00z  init  printstacktrace  gettext  fail  contains  createconsumer  testoncoordinatorjobsuccessevent  apptype  startdate  getparentid  getapptype  cae  session  coordeventlistener  assertfalse  jmsmessagingutils  geteventstatus  getuser  eventstatus  getid  createsession  gettopic  oncoordinatoractionevent  jmscontext  consumer  user1  missingdependency  getmessagetype  nominaltime  receive  getappname  e  errormessage  getmessage  assertequals  message  setendtime  session
__label__nflaky left  pad  right  pad  buf  abc  long  string  to  string  assert  equals  space  padder  leftpad  rightpad  buf  abc  longstring  tostring  assertequals  spacepadder
__label__flaky date  script  executor  downgrading  consistency  retry  policy  session  with  consistency  level  given  simple  select  value  from  simple  where  id  =  eq  delete  quorum  when  of  where  id  row  value  table  execute  script  template  log  asserter  prepare  log  level  for  driver  connection  is  not  null  should_dsl_delete_with_options  random  utils  manager  one  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  assert  consistency  levels  is  true  with  retry  policy  then  is  null  long  build  date  key  from  base  table  dsl  date  scriptexecutor  downgradingconsistencyretrypolicy  session  withconsistencylevel   given  simple  select value from simple where id =   eq  delete  quorum   when  of  where  id  row  value  table  executescripttemplate  logasserter  prepareloglevelfordriverconnection  isnotnull  should_dsl_delete_with_options  randomutils  manager  one  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  assertconsistencylevels  istrue  withretrypolicy   then  isnull  long  builddatekey  frombasetable  dsl
__label__nflaky date  format  get  time  zone  body  parser  engine  json  equal  to  core  matchers  invoke  string  compare  to  json  obj  mapper  when  get  bytes  test  valid  json  body  cal  assert  true  context  set  time  zone  close  set  time  json  document  then  return  calendar  format  test  form  is  parse  assert  that  get  input  stream  time  zone  mockito  {\""first  name\"":\""\%s\""   \""last  name\"":\""\%s\""   \""birth  year\"":\%d   \""last  seen\"":\""\%s\""}  body  parser  engine  json  test  get  instance  dateformat  gettimezone  bodyparserenginejson  equalto  corematchers  invoke  string  compareto  jsonobjmapper  when  getbytes  testvalidjsonbody  cal  asserttrue  context  settimezone  close  settime  jsondocument  thenreturn  calendar  format  testform  is  parse  assertthat  getinputstream  timezone  mockito  {\""firstname\"":\""\%s\""  \""lastname\"":\""\%s\""  \""birthyear\"":\%d  \""lastseen\"":\""\%s\""}  bodyparserenginejsontest  getinstance
__label__flaky kills  a  b  add  node  def  f  enters  start  j  assert  equals  workflow  instance  get  status  as  list  wf  1  fail  exits  size  <worklfow-app/>  test  fail  with  running  nodes  end  arrays  job  fails  kills  a  b  addnode  def  f  enters  start  j  assertequals  workflowinstance  getstatus  aslist  wf  1  fail  exits  size  <worklfow-app/>  testfailwithrunningnodes  end  arrays  job  fails
__label__nflaky renew  token  fake  canceller  test  cancel  delegation  token  job  tracker  run  cancel  token  stop  threads  should  throw  token  generate  delegation  token  some  user  assert  assert  true  dt  secret  manager  start  threads  fake  renewer  should  not  be  able  to  renew  renewtoken  fakecanceller  testcanceldelegationtoken  jobtracker  run  canceltoken  stopthreads  shouldthrow  token  generatedelegationtoken  someuser  assert  asserttrue  dtsecretmanager  startthreads   fake renewer should not be able to renew
__label__flaky set  long  dfs  config  keys  f  name  modify  defaul  filesystem  settings  h  flush_02  conf  custom  per  checksum  size  custom  block  size  set  int  do  the  job  setlong  dfsconfigkeys  fname   modify defaul filesystem settings  hflush_02  conf  customperchecksumsize  customblocksize  setint  dothejob
__label__nflaky assert  d  option  parsing  key1  hdfs://somefs/  key2  expected  map  value2  value1  new  hash  map  -  dkey1=value1  test  d  option  parsing  put  key1=value1  someother  args  -  dkey2  arg2  shell  maps  -  dkey1  expected  remaining  args  arg1  -  d  -fs  we  expect  key2  not  set  assertdoptionparsing  key1  hdfs://somefs/  key2  expectedmap  value2  value1  newhashmap  -dkey1=value1  testdoptionparsing  put  key1=value1  someother  args  -dkey2  arg2  shell  maps  -dkey1  expectedremainingargs  arg1  -d  -fs   we expect key2 not set
__label__flaky cluster  parent  should  never  reach  here.  conf  get  file  system  fs  delete  not  a  hdfs:  build  assert  true  test  recrusive  rm  num  data  nodes  mkdirs  close  get  uri  shutdown  child  cluster  parent   should never reach here.  conf  getfilesystem  fs  delete  not a hdfs:   build  asserttrue  testrecrusiverm  numdatanodes  mkdirs  close  geturi  shutdown  child
__label__nflaky bb  test  buffer  wrapper  nested  echo  request  proto  dos  baos  writable  get  default  instance  assert  assert  true  write  delimited  to  write  actual  rpc  writable  assert  equals  new  instance  original  bb  now  appears  empty   but  rpc  writable  has  a  slice  of  the  bb.  byte  buffer  remaining  buf1  buf2  get  value  size  left  to  byte  array  wrap  message2  message1  bb  testbufferwrappernested  echorequestproto  dos  baos  writable  getdefaultinstance  assert  asserttrue  writedelimitedto  write  actual  rpcwritable  assertequals  newinstance   original bb now appears empty  but rpc writable has a slice of the bb.  bytebuffer  remaining  buf1  buf2  getvalue  size  left  tobytearray  wrap  message2  message1
__label__flaky date  rs  \%msg  -  \%thread\%n  set  script  executor  async_  logger_  string  given  update  simple  0  am  with  lwt  result  listener  eq  prepare  log  level  when  of  await  should_dsl_update_value_async  where  id  latch  count  down  get  and  set  value  execute  async  table  info  execute  script  template  log  asserter  on  error  random  utils  manager  with  result  set  async  listener  next  long  simple  entity/insert_single_row.cql  immutable  map  assert  contains  called  if_  value  success  then  long  build  date  key  logger  new  value  from  base  table  dsl  called  -  achilles-default-executor  on  success  date  rs  \%msg - \%thread\%n  set  scriptexecutor  async_logger_string   given  update  simple  0 am  withlwtresultlistener  eq  prepareloglevel   when  of  await  should_dsl_update_value_async  where  id  latch  countdown  getandset  value  executeasync  table  info  executescripttemplate  logasserter  onerror  randomutils  manager  withresultsetasynclistener  nextlong  simpleentity/insert_single_row.cql  immutablemap  assertcontains  called  if_value  success   then  long  builddatekey  logger  new value  frombasetable  dsl  called - achilles-default-executor  onsuccess
__label__nflaky next  is  one  joe  test  access  control  list  drwho  groups  iter  acl  drwho  tardis  assert  that  tardis  users  iterator  drwho  size  drwho joe  tardis   users  get  users  tardis  is  zero  is  equal  to  get  groups  next  isone  joe  testaccesscontrollist  drwho  groups  iter  acl  drwho tardis  assertthat   tardis  users  iterator  drwho   size  drwho joe tardis  users  getusers  tardis  iszero  isequalto  getgroups
__label__flaky init  -ve  test  coord  el  functions  test  data  in  partition  min  ph1  set  variable  +ve  test  assert  equals  oozie.dataname.  abcd  data-in  coord-job-submit-data  fail  ${coord:data  in  partition  min(\'  abcd\')}  eval  eval  and  wrap  should  throw  exception  because  el  function  requires  2  parameters  expr  oozie.dataname.  abc  ${coord:data  in  partition  min(\'  abc\'   \'mypartition\')}  init   -ve test  coordelfunctions  testdatainpartitionminph1  setvariable   +ve test  assertequals  oozie.dataname.abcd  data-in  coord-job-submit-data  fail  ${coord:datainpartitionmin(\'abcd\')}  eval  evalandwrap  should throw exception because el function requires 2 parameters  expr  oozie.dataname.abc  ${coord:datainpartitionmin(\'abc\'  \'mypartition\')}
__label__nflaky setting  total  failover  attempts  to  .  p1  p2  p3  get  kms  url  test  client  retries  non  idempotent  op  with  socket  timeout  exception  fails  conf  when  times  assert  true  should  fail  since  all  providers  threw  a  socket  timeout  exception  verify  then  throw  test  kp  e  any  string  then  return  get  providers  key  name  create  key  eq  any  set  int  common  configuration  keys  public  fail  mockito  mock   setting total failover attempts to .  p1  p2  p3  getkmsurl  testclientretriesnonidempotentopwithsockettimeoutexceptionfails  conf  when  times  asserttrue  should fail since all providers threw a sockettimeoutexception  verify  thenthrow  test  kp  e  anystring  thenreturn  getproviders  keyname  createkey  eq  any  setint  commonconfigurationkeyspublic  fail  mockito  mock
__label__flaky call  test  resource  get  post  param  get  post  my  json  rest  servlet  get  http  servlet  response  param=true  invoke  assert  equals  run  test    call  testresourcegetpostparamget  post  myjsonrestservlet  get  httpservletresponse  param=true  invoke  assertequals  runtest
__label__nflaky next  get  subject  concurrent  get  current  user  on  ugi1  should  not  be  blocked.  get  current  user  blocking  lookup  get  name  unblock  the  original  call.  submit  wait  for  the  thread  to  block  on  the  barrier  in  get  current  user.  test  ugi2  test  ugi1  principals  run  new  single  thread  executor  executors  when  remove  iterator  barrier  ugi  get  await  latch  count  down  user  group  information  add  call  real  method  concurrent  get  current  user  on  ugi2  should  not  be  blocked.  get  principals  test  concurrent  get  current  user  create  remote  user  assert  same  workaround  this  by  swapping  out  the  spy  with  the  original  user.  concurrent.  ie.  no  synchronization.  call  invocation  do  as  answer  mockito  spy  is  called  for  the  user  name.  spy  user  then  answer  user  spy  next  getsubject   concurrent getcurrentuser on ugi1 should not be blocked.  getcurrentuser  blockinglookup  getname   unblock the original call.  submit   wait for the thread to block on the barrier in getcurrentuser.  testugi2  testugi1  principals  run  newsinglethreadexecutor  executors  when  remove  iterator  barrier  ugi  get  await  latch  countdown  usergroupinformation  add  callrealmethod   concurrent getcurrentuser on ugi2 should not be blocked.  getprincipals  testconcurrentgetcurrentuser  createremoteuser  assertsame   workaround this by swapping out the spy with the original user.   concurrent.  ie. no synchronization.  call  invocation  doas  answer  mockito   spy is called for the user name.  spyuser  thenanswer  user  spy
__label__flaky cluster  dfs  test  util  dfs  config  keys  /testfile  the  edit  log  is  replayed.  shut  down  and  restart  cluster  with  new  minimum  replication  of  2  format  conf  get  file  system  fs  wait  replication  create  file  set  int  wait  active  p  test  replication  adjusted  build  num  data  nodes  start  a  cluster  repl  shutdown  create  a  file  with  replication  count  1  replicate  and  heartbeat  fast  to  shave  a  few  seconds  off  test  cluster  dfstestutil  dfsconfigkeys  /testfile   the edit log is replayed.   shut down and restart cluster with new minimum replication of 2  format  conf  getfilesystem  fs  waitreplication  createfile  setint  waitactive  p  testreplicationadjusted  build  numdatanodes   start a cluster  repl  shutdown   create a file with replication count 1   replicate and heartbeat fast to shave a few seconds off test
__label__nflaky request  conn  resolve  get  request  response  captor  send  response  header  error  when  receive  request  header  request  handler  assert  httpservice  assert  not  null  context  create  for  class  verify  get  code  close  process  argument  captor  http  status  then  return  test  unsupported  http  version  exception  capture  handle  assert  equals  send  response  entity  assert  same  get  entity  whatever  /  get  value  do  throw  response  factory  mockito  response  http  core  context  new  http  response  httprocessor  handle  request  handler  resolver  request  conn  resolve  getrequest  responsecaptor  sendresponseheader  error  when  receiverequestheader  requesthandler  assert  httpservice  assertnotnull  context  create  forclass  verify  getcode  close  process  argumentcaptor  httpstatus  thenreturn  testunsupportedhttpversionexception  capture  handle  assertequals  sendresponseentity  assertsame  getentity  whatever  /  getvalue  dothrow  responsefactory  mockito  response  httpcorecontext  newhttpresponse  httprocessor  handlerequest  handlerresolver
__label__flaky cluster  get  block  locations  file  name  conf  get  kind  fs  wait  active  out  sleep  assert  /test  block  token  in  last  located  block  located  blocks  create  write  close  get  last  located  block  dfs  config  keys  file  path  assert  equals  num  name  nodes  get  file  system  get  name  node  rpc  test  block  token  in  last  located  block  set  int  thread  token  get  block  token  block  token  identifier  build  num  data  nodes  shutdown  set  boolean  cluster  getblocklocations  filename  conf  getkind  fs  waitactive  out  sleep  assert  /testblocktokeninlastlocatedblock  locatedblocks  create  write  close  getlastlocatedblock  dfsconfigkeys  filepath  assertequals  numnamenodes  getfilesystem  getnamenoderpc  testblocktokeninlastlocatedblock  setint  thread  token  getblocktoken  blocktokenidentifier  build  numdatanodes  shutdown  setboolean
__label__nflaky check  is  using  current  secret  for  signing  sign  assert  set  current  secret  secret  provider  previous  secret  no  longer  valid  s1  verify  and  extract  assert  not  equals  signer  s2  s3  previous  secret  still  valid  test  assert  equals  e1  e2  e3  check  not  using  current  secret  for  signing  fail  test  multiple  secrets  e1b  set  previous  secret  secret  d  secret  b  t1  secret  c  t2  secret  a  t3   check is using current secret for signing  sign  assert  setcurrentsecret  secretprovider   previous secret no longer valid  s1  verifyandextract  assertnotequals  signer  s2  s3   previous secret still valid  test  assertequals  e1  e2  e3   check not using current secret for signing  fail  testmultiplesecrets  e1b  setprevioussecret  secretd  secretb  t1  secretc  t2  secreta  t3
__label__flaky services  test  get  sla  events  with  range  sla  events  get  cmd  last  seq  id  size  assert  not  null  get  assert  equals  filter  list  list  jpa  service  execute  services  testgetslaeventswithrange  slaeventsgetcmd  lastseqid  size  assertnotnull  get  assertequals  filterlist  list  jpaservice  execute
__label__nflaky transfer-  encoding  request  test  request  explicit  close  multiple  tokens  add  header  keep  alive  assert  false  connection  chunked  method  /  keep-alive  assert  response  context  reuse  strategy  blah   blah   blah  ok  close  transfer-encoding  request  testrequestexplicitclosemultipletokens  addheader  keepalive  assertfalse  connection  chunked  method  /  keep-alive  assert  response  context  reusestrategy  blah  blah  blah  ok  close
__label__flaky a  a:1-  l  a:2-  n  a:1-  u  l1  l2  start  assert  equals  sb  thread  sleep  trim  finish  to  string  test  timeout  timing  out  write  lock    a  a:1-l a:2-n a:1-u  l1  l2  start  assertequals  sb  thread  sleep  trim  finish  tostring  testtimeouttimingoutwritelock
__label__nflaky lookup  matcher  test  lookup  invalid  input  lookup  matcher  testlookupinvalidinput
__label__flaky set  classes  to  be  excluded  assert  false  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  is  pending  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  test  coord  status  transit  service  running3  assert  not  null  get  coordinator  action  end  current  date  plus  month  job  wait  for  init  get  conf  false  start  destroy  assert  equals  services  x  data  test  case  execute  add  record  to  coord  job  table  services  coordinator  job  job  id  runnable  coord-action-get.xml  excluded  services  set  system  property  status  transit  service  job  jpa  service  evaluate  setclassestobeexcluded  assertfalse  getcurrentdateafterincrementinginmonths  getid  run  dateutils  ispending  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  testcoordstatustransitservicerunning3  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  job  waitfor  init  getconf  false  start  destroy  assertequals  services  xdatatestcase  execute  addrecordtocoordjobtable  services  coordinatorjob  jobid  runnable  coord-action-get.xml  excludedservices  setsystemproperty  statustransitservice  job  jpaservice  evaluate
__label__nflaky matrix  util  get  version  for  number  1  1  1  1  1  1  1  0  0  1  1  1  1  1  1  1  expected  1  assert  equals  test  embed  basic  patterns1  matrix  1  0  0  0  0  0  1  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  embed  basic  patterns  1  0  1  1  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  version  1.  version  clear  matrix  to  string  1  0  1  1  1  0  1  0  0  1  0  1  1  1  0  1  1  1  1  1  1  1  1  0  1  0  1  0  1  0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  matrixutil  getversionfornumber   1 1 1 1 1 1 1 0           0 1 1 1 1 1 1 1    expected               1                                assertequals  testembedbasicpatterns1  matrix   1 0 0 0 0 0 1 0           0 1 0 0 0 0 0 1     0 0 0 0 0 0 0 0 1                            embedbasicpatterns   1 0 1 1 1 0 1 0                               0 0 0 0 0 0 0 0           0 0 0 0 0 0 0 0     1 0 0 0 0 0 1 0                               version 1.  version  clearmatrix  tostring   1 0 1 1 1 0 1 0           0 1 0 1 1 1 0 1     1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1     1 1 1 1 1 1 1 0                                           0
__label__flaky inject  edge  null  result  environment  edge  manager  assert  false  new  edge  assert  equals  injecting  null  will  result  in  default  being  assigned.  get  delegate  edge2  edge  assert  true  assert  not  null  reset  test  manage  singleton  injectedge  nullresult  environmentedgemanager  assertfalse  newedge  assertequals   injecting null will result in default being assigned.  getdelegate  edge2  edge  asserttrue  assertnotnull  reset  testmanagesingleton
__label__nflaky mecard:  adr:76  9th  ave;  n:  sean  owen;  url:google.com;  email:srowen@example.org;  mecard:  n:  sean  owen;;  sean  owen  76  9th  ave  srowen@example.org  google.com  sean  owen  +12125551212  google.com  n:  sean  owen;  tel:+12125551212;;  sean  owen  srowen@example.org  google.com  19760520  parsed  result  type  do  test  result  mecard:  tel:+12125551212;  n:  sean  owen;  url:google.com;;  mecard:  bday:19760520;  n:  sean  owen;  url:google.com;  email:srowen@example.org;  sean  owen  srowen@example.org  google.com  z  xing  team  mecard:  note:  z  xing  team;  n:  sean  owen;  url:google.com;  email:srowen@example.org;  sean  owen  mecard:  org:  google;  n:  sean  owen;  url:google.com;  email:srowen@example.org;  sean  owen  google  srowen@example.org  google.com  sean  owen  +12125551212  sean  owen  +12125551212  srowen@example.org  google.com  mecard:  tel:+12125551212;  n:  sean  owen;  url:google.com;  email:srowen@example.org;  mecard:  tel:+12125551212;  n:  sean  owen;;  test  address  book  type  mecard:adr:76 9th ave;n:sean owen;url:google.com;email:srowen@example.org;  mecard:n:sean owen;;  sean owen  76 9th ave  srowen@example.org  google.com  sean owen  +12125551212  google.com  n:sean owen;tel:+12125551212;;  sean owen  srowen@example.org  google.com  19760520  parsedresulttype  dotestresult  mecard:tel:+12125551212;n:sean owen;url:google.com;;  mecard:bday:19760520;n:sean owen;url:google.com;email:srowen@example.org;  sean owen  srowen@example.org  google.com  zxing team  mecard:note:zxing team;n:sean owen;url:google.com;email:srowen@example.org;  sean owen  mecard:org:google;n:sean owen;url:google.com;email:srowen@example.org;  sean owen  google  srowen@example.org  google.com  sean owen  +12125551212  sean owen  +12125551212  srowen@example.org  google.com  mecard:tel:+12125551212;n:sean owen;url:google.com;email:srowen@example.org;  mecard:tel:+12125551212;n:sean owen;;  testaddressbooktype
__label__flaky de  conn  /app  post  /v1/jobs  put  get  job  set  request  property  lib  path2  create  workflow.xml  lib  path1  open  connection  conf1  get  file  system  params     get  input  stream  get  dag  engine  json  value  oozie  client  size  mkdirs  reset  job  xml  path1  set  do  output  job  conf  set  request  method  is_  security_  enabled  assert  false  libpath1  write  xml  libpath2  test  submit  app  path  fs  assert  true  get  content-type  job  xml  path  run  test  sr  json  tags  set  rest  constants  get  conf  undef  mock  dag  engine  service  http  servlet  response  assert  equals  parse  services  url  call  services  get  test  user  obj  get  response  code  wf  count  create  url  to  string  get  output  stream  get  fs  test  case  dir    de  conn  /app  post  /v1/jobs  put  getjob  setrequestproperty  libpath2  create  workflow.xml  libpath1  openconnection  conf1  getfilesystem  params     getinputstream  getdagengine  jsonvalue  oozieclient  size  mkdirs  reset  jobxmlpath1  setdooutput  jobconf  setrequestmethod  is_security_enabled  assertfalse  libpath1  writexml  libpath2  testsubmit  apppath  fs  asserttrue  get  content-type  jobxmlpath  runtest  sr  jsontags  set  restconstants  getconf  undef  mockdagengineservice  httpservletresponse  assertequals  parse  services  url  call  services  gettestuser  obj  getresponsecode  wfcount  createurl  tostring  getoutputstream  getfstestcasedir
__label__nflaky a  a  b  b  set  size  test  size  conf  assert  equals  a  a  b  b  set  size  testsize  conf  assertequals
__label__flaky test_app_name  <execution>  lifo</execution>  </controls>  <datasets>  check  coord  jobs  test  submit  with  var  app  name  conf  </input-events>  app  path  substring  sc  </property></configuration>  </workflow>  </action>  </coordinator-app>  write  to  file  app  xml  timezone=\""  utc\"">  <uri-template>file:///tmp/coord/workflows/${  year}/${  day}</uri-template>  <property>  <name>input  b</name>  <value>${coord:data  out(\'  local_  a\')}</value>  file://  get  test  case  dir  unit_  testing  <done-flag>consume_me</done-flag>  </dataset>  <output-events>  <data-out  name=\""  local_  a\""  dataset=\""local_a\"">  timezone=\""  utc\"">  <uri-template>file:///tmp/coord/workflows/${  year}/${  day}</uri-template>  </dataset>  timezone=\""  utc\"">  <uri-template>file:///tmp/coord/workflowsb/${  year}/${  day}</uri-template>  coordinator.xml  get  app  name  set  <configuration>  <property>  <name>input  a</name>  <value>${coord:data  in(\'  a\')}</value>  </property>  length  <dataset  name=\""local_a\""  frequency=\""${coord:days(7)}\""  initial-instance=\""2009-02-01  t01:00  z\""  my_  done_  flag  assert  equals  <done-flag>${  my_  done_  flag}</done-flag>  </dataset>  <data-in  name=\""  b\""  dataset=\""local_b\"">  <instance>${coord:latest(0)}</instance>  </data-in>  name  call  oozie  client  job  id  get  test  user  <dataset  name=\""local_b\""  frequency=\""${coord:days(7)}\""  initial-instance=\""2009-02-01  t01:00  z\""  </datasets>  <input-events>  <instance>${coord:current(-1)}</instance>  </data-out>  </output-events>  <action>  <workflow>  <app-path>hdfs:///tmp/workflows/</app-path>  xmlns=\""uri:oozie:coordinator:0.3\"">  <controls>  <timeout>10</timeout>  <concurrency>2</concurrency>  -  c  <data-in  name=\""  a\""  dataset=\""a\"">  <instance>${coord:latest(0)}</instance>  </data-in>  <coordinator-app  name=\""${  name}\""  frequency=\""${coord:days(1)}\""  start=\""2009-02-01  t01:00  z\""  end=\""2009-02-03  t23:59  z\""  timezone=\""  utc\""  <dataset  name=\""a\""  frequency=\""${coord:days(7)}\""  initial-instance=\""2009-02-01  t01:00  z\""  complete  job  file  test_app_name  <execution>lifo</execution> </controls> <datasets>   checkcoordjobs  testsubmitwithvarappname  conf  </input-events>   apppath  substring  sc  </property></configuration> </workflow> </action> </coordinator-app>  writetofile  appxml  timezone=\""utc\""> <uri-template>file:///tmp/coord/workflows/${year}/${day}</uri-template>   <property> <name>inputb</name> <value>${coord:dataout(\'local_a\')}</value>   file://  gettestcasedir  unit_testing  <done-flag>consume_me</done-flag> </dataset>  <output-events> <data-out name=\""local_a\"" dataset=\""local_a\"">   timezone=\""utc\""> <uri-template>file:///tmp/coord/workflows/${year}/${day}</uri-template> </dataset>   timezone=\""utc\""> <uri-template>file:///tmp/coord/workflowsb/${year}/${day}</uri-template>   coordinator.xml  getappname  set  <configuration> <property> <name>inputa</name> <value>${coord:datain(\'a\')}</value> </property>   length  <dataset name=\""local_a\"" frequency=\""${coord:days(7)}\"" initial-instance=\""2009-02-01t01:00z\""   my_done_flag  assertequals  <done-flag>${my_done_flag}</done-flag> </dataset>  <data-in name=\""b\"" dataset=\""local_b\""> <instance>${coord:latest(0)}</instance> </data-in>    name  call  oozieclient  jobid  gettestuser  <dataset name=\""local_b\"" frequency=\""${coord:days(7)}\"" initial-instance=\""2009-02-01t01:00z\""   </datasets> <input-events>   <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>   xmlns=\""uri:oozie:coordinator:0.3\""> <controls> <timeout>10</timeout> <concurrency>2</concurrency>   -c  <data-in name=\""a\"" dataset=\""a\""> <instance>${coord:latest(0)}</instance> </data-in>    <coordinator-app name=\""${name}\"" frequency=\""${coord:days(1)}\"" start=\""2009-02-01t01:00z\"" end=\""2009-02-03t23:59z\"" timezone=\""utc\""   <dataset name=\""a\"" frequency=\""${coord:days(7)}\"" initial-instance=\""2009-02-01t01:00z\""   complete  job  file
__label__nflaky .name  foo  test  call  with  no  properties  for  a  given  prefix  conf  none  bar  assert  true  assert  not  null  get  prefix.  value  prefixed  props  set  value_bar  subprefix.  repeat  test  with  variable  substitution  subname  is  empty  is  assert  equals  value_${foo}  get  props  with  prefix  assert  that  different.prefix  size  name  test  getting  properties  with  prefix  .name  foo   test call with no properties for a given prefix  conf  none  bar  asserttrue  assertnotnull  get  prefix.  value  prefixedprops  set  value_bar  subprefix.   repeat test with variable substitution  subname  isempty  is  assertequals  value_${foo}  getpropswithprefix  assertthat  different.prefix  size  name  testgettingpropertieswithprefix
__label__flaky check  whether  transactions  are  rolled  back  or  not  expected  exception  due  to  commit  failure  but  didn\'t  get  any  prep  get  id  workflow  instance  action  get  cmd  deactivate  test  bulk  insert  updates  rollback  wf  bean  add  record  to  wf  job  table  get  error  code  assert  not  null  wf  update  cmd1  get  workflow  job  update  list  add  get  status  str  insert  list  expected  exception  but  didnt  get  any  wf  get  cmd  assert  equals  skip  commit  fault  injection  add  two  actions  to  insert  list  execute  set  status  fault  injection  1  services  fail  jpaee  2  workflow  action  org.apache.oozie.command.  skip  commit  fault  injection  set  system  property  true  create  workflow  action  action1  set  fault  injection  to  true   so  transaction  is  roll  backed  error  code  job  action2  add  to  update  list  status  should  not  be  running  jpa  service   check whether transactions are rolled back or not  expected exception due to commit failure but didn\'t get any  prep  getid  workflowinstance  actiongetcmd  deactivate  testbulkinsertupdatesrollback  wfbean  addrecordtowfjobtable  geterrorcode  assertnotnull  wfupdatecmd1  get  workflowjob  updatelist  add  getstatusstr  insertlist  expected exception but didnt get any  wfgetcmd  assertequals  skipcommitfaultinjection   add two actions to insert list  execute  setstatus  faultinjection  1  services  fail  jpaee  2  workflowaction  org.apache.oozie.command.skipcommitfaultinjection  setsystemproperty  true  createworkflowaction  action1   set fault injection to true  so transaction is roll backed  errorcode  job  action2   add to update list   status should not be running  jpaservice
__label__nflaky end:  vevent  begin:  vevent  20080504  t123456  z  do  test  test  no  v  calendar  dtend:20080505  t234555  z  20080505  t234555  z  dtstart:20080504  t123456  z  end:vevent  begin:vevent    20080504t123456z  dotest  testnovcalendar  dtend:20080505t234555z    20080505t234555z  dtstart:20080504t123456z
__label__flaky pausetime=null  ;concurrency=200  get  time  check  coord  jobs  ;pausetime=;concurrency=200  running  test  endtime=2012-12-20  t05:00;concurrency=-200  endtime=2012-12-20  t05:00  z;concurrency=2ac  date  utils  system  parse  date  oozie  tz  concurrency=-1  a=1;b=-200  pause  time  get  error  code  endtime=2012-12-20  t05:00  z;concurrency=-200  pausetime=2009-02-01  t01:03  z  error  code  should  be  e1015.  endtime=2012-12-20  t05:00  z  print  stack  trace  pausetime=2009-02-01  t01:08  z  should  not  reach  here.  endtime=  endtime=1900-12-20  t05:00  z  exception  thrown  convert  date  to  string  invalid  date  add  record  to  job  table  call  job  id  fail  ex  ;concurrency=200;pausetime=  test  coord  change  x  command  2012-12-20  t05:00  z  0000000-  change  value  end  time  error  code  -test  coord  change  x  command-  c  pausetime=1900-12-20  t05:00  z  pausetime=null  ;concurrency=200  gettime  checkcoordjobs  ;pausetime=;concurrency=200  running test  endtime=2012-12-20t05:00;concurrency=-200  endtime=2012-12-20t05:00z;concurrency=2ac  dateutils  system  parsedateoozietz  concurrency=-1  a=1;b=-200  pausetime  geterrorcode  endtime=2012-12-20t05:00z;concurrency=-200  pausetime=2009-02-01t01:03z  error code should be e1015.  endtime=2012-12-20t05:00z  printstacktrace  pausetime=2009-02-01t01:08z  should not reach here.  endtime=  endtime=1900-12-20t05:00z  exception thrown   convertdatetostring  invalid date  addrecordtojobtable  call  jobid  fail  ex  ;concurrency=200;pausetime=  testcoordchangexcommand  2012-12-20t05:00z  0000000-  changevalue  endtime  errorcode  -testcoordchangexcommand-c  pausetime=1900-12-20t05:00z
__label__nflaky request  acls  assert  false  foo  send  error  conf  when  get  attribute  assert  test  has  administrator  access  assert  true  context  verify  http  server2  authorization  on  &  user  not  null  &  ac  ls  null  common  configuration  keys  then  return  authorization  off  any  string  http  servlet  response  eq  any  authorization  on  &  user  null  authorization  on  &  user  not  null  &  ac  ls  not  null  &  user  not  in  ac  ls  mockito  get  remote  user  response  has  administrator  access  is  user  allowed  mock  authorization  on  &  user  not  null  &  ac  ls  not  null  &  user  in  in  ac  ls  set  boolean  request  acls  assertfalse  foo  senderror  conf  when  getattribute  assert  testhasadministratoraccess  asserttrue  context  verify  httpserver2   authorization on & user not null & acls null  commonconfigurationkeys  thenreturn   authorization off  anystring  httpservletresponse  eq  any   authorization on & user null   authorization on & user not null & acls not null & user not in acls  mockito  getremoteuser  response  hasadministratoraccess  isuserallowed  mock   authorization on & user not null & acls not null & user in in acls  setboolean
__label__flaky expected  to  fail  as  action  4  should  have  been  deleted  get  time  pausetime=  get  id  date  utils  get  status  add  record  to  coord  action  table  coord  get  cmd  coord  job  pause  time  get  error  code  get  coordinator  action  end  4  hrs  jpae  job  print  stack  trace  start  assert  equals  execute  2  hrs  call  get  pause  time  pause  time  change  str  coordinator  job  services  fail  coord-action-get.xml  get  last  action  number  test  coord  change  pause  time  format  date  oozie  tz  add  record  to  coord  job  table  for  pause  time  test  error  code  expected  to  fail  as  action  3  should  have  been  deleted  job  jpa  service  expected to fail as action 4 should have been deleted  gettime  pausetime=  getid  dateutils  getstatus  addrecordtocoordactiontable  coordgetcmd  coordjob  pausetime  geterrorcode  get  coordinatoraction  end   4 hrs  jpae  job  printstacktrace  start  assertequals  execute   2 hrs  call  getpausetime  pausetimechangestr  coordinatorjob  services  fail  coord-action-get.xml  getlastactionnumber  testcoordchangepausetime  formatdateoozietz  addrecordtocoordjobtableforpausetimetest  errorcode  expected to fail as action 3 should have been deleted  job  jpaservice
__label__nflaky key1  t.abc.ey3  key2  res  set  value2  value1  key3  contains  key  key4  value3  conf  t.abc.key1  t.abc.key2  conf  didn\'t  get  key  get  val  by  regex  assert  true  test  get  val  by  regex  picked  out  wrong  key  ^t\\..*\\.key\\d  tt.abc.key3  key1  t.abc.ey3  key2  res  set  value2  value1  key3  containskey  key4  value3  conf  t.abc.key1  t.abc.key2  conf didn\'t get key   getvalbyregex  asserttrue  testgetvalbyregex  picked out wrong key   ^t\\..*\\.key\\d  tt.abc.key3
__label__flaky set  app  name  get  message  iae  test  constructor  <workflow></workflow>  construction  with  illegal  args  failed  as  expected:  my  test  app  assert  assert  true  assert  not  null  json  wf  job  my  test  id  set  id  setappname  getmessage  iae  testconstructor  <workflow></workflow>  construction with illegal args failed as expected:   my test app  assert  asserttrue  assertnotnull  jsonwfjob  my test id  setid
__label__nflaky dst  codec  test  utils  10  1234567890123456  convert  set  max  line  length  metrics2  metrics1  assert  message  constraint  exception  expected  assert  not  null  http1  config  read  1234567890123456  standard  charsets  custom  decoder1  clear  bytes  read  channel1  inbuf1  assert  equals  channel2  decoder2  byte  buffer  inbuf2  trailers  fail  test  too  long  folded  footer  allocate  size  build  0  footer1:  blah  blah  blah  blah  blah  blah  blah  blah  http1  config  get  trailers  dst  codectestutils  10  1234567890123456    convert  setmaxlinelength  metrics2  metrics1  assert  messageconstraintexception expected  assertnotnull  http1config  read  1234567890123456  standardcharsets  custom  decoder1  clear  bytesread  channel1  inbuf1  assertequals  channel2  decoder2  bytebuffer  inbuf2  trailers  fail  testtoolongfoldedfooter  allocate  size  build  0  footer1: blah    blah    blah    blah    blah    blah    blah    blah      http1config  gettrailers
__label__flaky bundle  job  get  executor  bundle  job  should  have  been  purged  bundle  action  should  have  been  purged  add  record  to  bundle  action  table  get  id  date  utils  get  status  parse  date  oozie  tz  get  error  code  assert  not  null  get  job  test  fail  bundle  purge  x  command  2011-01-01  t01:00  z  add  record  to  bundle  job  table  assert  equals  execute  call  services  fail  bundle  action  get  executor1  bundle  action  get  executor2  action1  error  code  je  job  action2  jpa  service  bundlejobgetexecutor  bundle job should have been purged  bundle action should have been purged  addrecordtobundleactiontable  getid  dateutils  getstatus  parsedateoozietz  geterrorcode  assertnotnull  get  job  testfailbundlepurgexcommand  2011-01-01t01:00z  addrecordtobundlejobtable  assertequals  execute  call  services  fail  bundleactiongetexecutor1  bundleactiongetexecutor2  action1  errorcode  je  job  action2  jpaservice
__label__nflaky create  hard  link  are  all  linked   so  they  x1_one  x1  and  x1_one  are  linked  now  str3  assert  true  confirm  that  x2   which  we  didn\'t  change   still  shows  count  \""1\""  append  to  file  x1   x1_one   and  x11_one  str1  x11_one  validate  by  contents  hardlink  a  single  file  and  confirm  expected  result  fetch  file  contents  should  all  have  count  \""3\""  x3_one  create  another  link  to  a  file  that  already  has  count  2  validate  tgt  one  test  create  hard  link  assert  equals  so  they  both  have  count  \""2\""  get  link  count  y_one  now  do  a  few  more  equals  x1  exists  x2  validate  that  change  of  content  is  reflected  in  the  other  linked  files  x3  createhardlink   are all linked  so they  x1_one   x1 and x1_one are linked now  str3  asserttrue   confirm that x2  which we didn\'t change  still shows count \""1\""  appendtofile   x1  x1_one  and x11_one  str1  x11_one   validate by contents   hardlink a single file and confirm expected result  fetchfilecontents   should all have count \""3\""  x3_one   create another link to a file that already has count 2  validatetgtone  testcreatehardlink  assertequals   so they both have count \""2\""  getlinkcount  y_one   now do a few more  equals  x1  exists  x2   validate that change of content is reflected in the other linked files  x3
__label__flaky cluster  file  name  failed  to  leave  safe  mode  truncate  replica  of  block  and  the  block  to  be  replicated  change  replica  length  handled  correctly  assert  false  make  sure  that  truncated  block  will  be  deleted  conf  fs  wait  replication  get  self  addr  system  create  file  assure  the  cluster  has  left  safe  mode.  wait  active  assert  true  info  port  get  wait  for  block  deleted  start  time  block  wait  for  verification  dfs  test  util  dfs  config  keys  get  data  nodes  start  data  nodes  /file1  failed  to  find  or  change  length  of  replica  on  node  0  format  get  file  system  is  in  safe  mode  replication_  factor  get  name  node  set  long  then  truncate  it  on  datanode  0.  build  num  data  nodes  get  info  port  now  we  have  3  datanodes  current  time  millis  timeout  wait  cluster  up  get  first  block  shutdown  test  truncated  block  report  set  boolean  cluster  filename  failed to leave safe mode   truncate replica of block   and the block to be replicated  changereplicalength   handled correctly  assertfalse   make sure that truncated block will be deleted  conf  fs  waitreplication  getselfaddr  system  createfile   assure the cluster has left safe mode.  waitactive  asserttrue  infoport  get  waitforblockdeleted  starttime  block  waitforverification  dfstestutil  dfsconfigkeys  getdatanodes  startdatanodes  /file1  failed to find or change length of replica on node 0   format  getfilesystem  isinsafemode  replication_factor  getnamenode  setlong   then truncate it on datanode 0.  build  numdatanodes  getinfoport   now we have 3 datanodes  currenttimemillis  timeout  waitclusterup  getfirstblock  shutdown  testtruncatedblockreport  setboolean
__label__nflaky in  the  message  intercept  hello   world  test  intercept  intercept  string  result  lambda   in the message  intercept  hello  world  testinterceptinterceptstringresultlambda
__label__flaky create  symlink  link  opened  a  link  using  afs  test  access  link  from  abstract  file  system  wrapper  link  to  file  afs  fail  file  get  default  file  system  test  base  dir1  create  and  write  file  fc  open  createsymlink  link  opened a link using afs  testaccesslinkfromabstractfilesystem  wrapper  linktofile  afs  fail  file  getdefaultfilesystem  testbasedir1  createandwritefile  fc  open
__label__nflaky request  get  name  token  signed  token_  validity_  sec  set  expires  sign  secret  when  as  list  get  init  parameter  names  system  secret  provider  props  invalidtype  get  cookies  secret  provider  management.operation.return  verify  unauthorized  signer  authenticated  url  http://foo:8080/bar  get  request  url  init  chain  cookie  test  do  filter  authenticated  invalid  type  authentication  filter  then  return  string  signer  secret  provider  creator  www-  authenticate  destroy  token  filter  p  get  mocked  servlet  context  with  string  signer  get  init  parameter  new  string  signer  secret  provider  mockito  u  response  elements  current  time  millis  set  property  true  mock  to  string  contains  header  arrays  config  request  getname  tokensigned  token_validity_sec  setexpires  sign  secret  when  aslist  getinitparameternames  system  secretproviderprops  invalidtype  getcookies  secretprovider  management.operation.return  verifyunauthorized  signer  authenticatedurl  http://foo:8080/bar  getrequesturl  init  chain  cookie  testdofilterauthenticatedinvalidtype  authenticationfilter  thenreturn  stringsignersecretprovidercreator  www-authenticate  destroy  token  filter  p  getmockedservletcontextwithstringsigner  getinitparameter  newstringsignersecretprovider  mockito  u  response  elements  currenttimemillis  setproperty  true  mock  tostring  containsheader  arrays  config
__label__flaky excludes  reflection  test  utils  get  field  unchecked  includes  static/**  as  list  contains  resource  matcher  defaults  assert  true  **/*.jar  arrays    excludes  reflectiontestutils  getfield  unchecked  includes  static/**  aslist  contains  resourcematcher  defaults  asserttrue  **/*.jar  arrays
__label__nflaky ssl  test  constants  set  location  assert  not  null  create  key  store  factory  bean  test  defaults  ssltestconstants  setlocation  assertnotnull  createkeystore  factorybean  testdefaults
__label__flaky /////////////////////////////////////////////////////////////////////  ninja  test  browser  assert  false  contentcontent  test  get  and  post  article  via  json  system  one  new  result:  assert  true  new  title  new  title  api/bob@gmail.com/article.json  article  dto  get  server  address  do  login  response:  make  json  request  assert  equals  get  gson  with  long  to  date  parsing  api/bob@gmail.com/articles.json  articles  dto  error.  forbidden.  post  json  contains  size  response  from  json   /////////////////////////////////////////////////////////////////////  ninjatestbrowser  assertfalse  contentcontent  testgetandpostarticleviajson  system   one new result:  asserttrue  new title new title  api/bob@gmail.com/article.json  articledto  getserveraddress  dologin  response:   makejsonrequest  assertequals  getgsonwithlongtodateparsing  api/bob@gmail.com/articles.json  articlesdto  error. forbidden.  postjson  contains  size  response  fromjson
__label__nflaky mandatory  request  header  \':scheme\'  not  found  headers  test  convert  from  fields  missing  scheme  custom  converter  thrown  convert  www.example.com  as  list  expect  message  /  expect  :method  get  :path  arrays  value  :authority  mandatory request header \':scheme\' not found  headers  testconvertfromfieldsmissingscheme  custom  converter  thrown  convert  www.example.com  aslist  expectmessage  /  expect  :method  get  :path  arrays  value  :authority
__label__flaky set  job  status  <app-type>  workflow_  action</app-type>  <alert-percentage>ap</alert-percentage>  </event>  <parent-sla-id>psi</parent-sla-id>  set  \""  created\""  status  to  get  the  event  of  registration  kind:  to  xml  system  <sequence-id>1</sequence-id>  <sla-id>si</sla-id>  <notification-msg>nm</notification-msg>  <alert-frequency>af</alert-frequency>  test  to  xml  registration  event  <dev-contact>dc</dev-contact>  <registration>  <status-timestamp>1970-01-01  t00:00  z</status-timestamp>  bean  <event>  <expected-end>1970-01-01  t00:00  z</expected-end>  set  pretty  print  <job-data>jd</job-data>  xml  utils  el  </registration>  <user>u</user>  assert  equals  actual  xml  <alert-contact>ac</alert-contact>  <expected-start>1970-01-01  t00:00  z</expected-start>  <qa-contact>qc</qa-contact>  <upstream-apps>ua</upstream-apps>  <job-status>  created</job-status>  <app-name>an</app-name>  <group>gn</group>  to  string  <se-contact>sc</se-contact>  setjobstatus      <app-type>workflow_action</app-type>        <alert-percentage>ap</alert-percentage>    </event>      <parent-sla-id>psi</parent-sla-id>     set \""created\"" status to get the event of registration kind:  toxml  system    <sequence-id>1</sequence-id>        <sla-id>si</sla-id>        <notification-msg>nm</notification-msg>        <alert-frequency>af</alert-frequency>    testtoxmlregistrationevent      <dev-contact>dc</dev-contact>      <registration>        <status-timestamp>1970-01-01t00:00z</status-timestamp>    bean  <event>        <expected-end>1970-01-01t00:00z</expected-end>    set  prettyprint      <job-data>jd</job-data>    xmlutils  el    </registration>        <user>u</user>    assertequals  actualxml      <alert-contact>ac</alert-contact>        <expected-start>1970-01-01t00:00z</expected-start>        <qa-contact>qc</qa-contact>        <upstream-apps>ua</upstream-apps>        <job-status>created</job-status>        <app-name>an</app-name>        <group>gn</group>    tostring      <se-contact>sc</se-contact>
__label__nflaky status  line  test  sl  parse  not  found  get  reason  phrase  status  line  with  multi  word  reason  phrase  assert  reason  phrase  can  be  anyting  http/1.1  200  http/1.1  404  non  trouve  ok  http  version  http/1.1  200  ok  this  is  not  strictly  valid   but  is  lenient  http/1.1  404  not  found  non  trouve  http/1.1  200  parse  status  line  http/1.1  200  ok  http/1.1  200  ok  clear  assert  equals  http/1.1  200  ok  get  protocol  version  buf  get  status  code  this  is  valid  according  to  the  status-  line  bnf  its  ok  to  end  with  a   \\r  to  string  http/1.1  404  not  found  typical  status  line  append    statusline  testslparse  not found  getreasonphrase   status line with multi word reason phrase  assert   reason phrase can be anyting  http/1.1 200  http/1.1 404 non trouve  ok  httpversion  http/1.1 200 ok   this is not strictly valid  but is lenient  http/1.1 404 not found    non trouve  http/1.1 200   parsestatusline    http/1.1 200 ok    http/1.1 200 ok  clear  assertequals  http/1.1     200 ok  getprotocolversion  buf  getstatuscode   this is valid according to the status-line bnf   its ok to end with a  \\r  tostring  http/1.1 404 not found   typical status line  append
__label__flaky coord  client  2009-02-02  t23:59  z  local  oozie  coord  action  get  cmd  get  id  date  utils  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  job  test  coord  rerun  for  backward  support1  get  coord  client  rerun  scope  assert  not  null  get  coordinator  action  end  re  run  coord  init  rest  constants  2009-02-01  t01:00  z  start  destroy  assert  equals  services  set  app  namespace  execute  -  add  record  to  coord  job  table  integer  services  coordinator  job  coord  job  get  cmd  schema  service  set  system  property  assert  not  same  true  status  transit  service  to  string  action1  action2  jpa  service  action3  coord-rerun-action1.xml  coordclient  2009-02-02t23:59z  localoozie  coordactiongetcmd  getid  dateutils  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordjob  testcoordrerunforbackwardsupport1  getcoordclient  rerunscope  assertnotnull  get  coordinatoraction  end  reruncoord  init  restconstants  2009-02-01t01:00z  start  destroy  assertequals  services  setappnamespace  execute  -  addrecordtocoordjobtable  integer  services  coordinatorjob  coordjobgetcmd  schemaservice  setsystemproperty  assertnotsame  true  statustransitservice  tostring  action1  action2  jpaservice  action3  coord-rerun-action1.xml
__label__nflaky construct  result  test  case  util  get  row  number  second  row  get  name  rss  expanded  reader  decode  row2pairs  get  black  row  rss  expanded  reader  get  rows  first  expanded  row  result  get  height  get  pairs  get  get  start  end  binary  map  src/test/resources/blackbox/rssexpandedstacked-2/1000.png  test  decoding  row  by  row  second  row  number  get  text  get  finder  pattern  assert  equals  reverse  total  pairs  fail  first  row  size  get  binary  bitmap  expected  (01)98898765432106(3202)012345(15)991231  first  row  number  constructresult  testcaseutil  getrownumber  secondrow  getname  rssexpandedreader  decoderow2pairs  getblackrow  rssexpandedreader  getrows  firstexpandedrow  result  getheight  getpairs  get  getstartend  binarymap  src/test/resources/blackbox/rssexpandedstacked-2/1000.png  testdecodingrowbyrow  secondrownumber  gettext  getfinderpattern  assertequals  reverse  totalpairs  fail  firstrow  size  getbinarybitmap   expected  (01)98898765432106(3202)012345(15)991231  firstrownumber
__label__flaky add  node  def  enters  workflow  instance  get  status  as  list  wf  assert  true  end  error  ok  signal  test  action  ok  error  a  b  c  contains  key  start  clear  assert  equals  /  1  <worklfow-app/>  arrays  job    addnode  def  enters  workflowinstance  getstatus  aslist  wf  asserttrue  end  error  ok  signal  testactionokerror  a  b  c  containskey  start  clear  assertequals  /  1  <worklfow-app/>  arrays  job
__label__nflaky correctly  krb5  login  module  name  foo  get  login  module  name  system  principal  bar  com.ibm.security.auth.module.  krb5  login  module  /some/location/foo.keytab  assert  ibm  get  options  foo/localhost  com.sun.security.auth.module.  krb5  login  module  j  conf  use  key  tab  refresh  krb5  config  get  control  flag  get  property  test  store  key  key  tab  false  assert  equals  entry  contains  entries  app  configuration  entry  assert  null  java.vendor  size  true  get  options  use  ticket  cache  get  app  configuration  entry   correctly  krb5loginmodulename  foo  getloginmodulename  system  principal  bar  com.ibm.security.auth.module.krb5loginmodule  /some/location/foo.keytab  assert  ibm  get  options  foo/localhost  com.sun.security.auth.module.krb5loginmodule  jconf  usekeytab  refreshkrb5config  getcontrolflag  getproperty  test  storekey  keytab  false  assertequals  entry  contains  entries  appconfigurationentry  assertnull  java.vendor  size  true  getoptions  useticketcache  getappconfigurationentry
__label__flaky cancel  request  a  server  dispatch  set  body  new  call  execute  url  get  url  fail  /a  cancel  in  flight  before  response  read  throws  ioe  build  set  dispatcher  get  client  tag  cancel  request  a  server  dispatch  setbody  newcall  execute  url  geturl  fail  /a  cancelinflightbeforeresponsereadthrowsioe  build  setdispatcher  get  client  tag
__label__nflaky #  dfs-  hosts-excluded  get  excludes  file  excludes  file  excludes  len  new  excludes  file  assert  false  get  excluded  hosts  test  for  refreshing  hostreader  wit  new  include/exclude  host  files  hosts_  test_  dir  #  this-is-comment  assert  true  #  hosts-in-  dfs  node2  somehost3  #  host3  somehost4  /dfs1.exclude  get  includes  file  *  1.  create  dfs.exclude dfs.include  file  *  2.  write  host  names  per  line  *  3.  write  comments  starting  with  #  *  4.  close  file  *  5.  compare  if  number  of  hosts  reported  by  hosts  file  reader  *  are  equal  to  the  number  of  hosts  written  write  somehost2  close  get  hosts  test  hosts  file  reader  host4  /dfs1.include  host  details  somehost4  #  host4  host3  includes  file  somehost4  somehost5  refresh  assert  equals  get  host  details  new  includes  file  node1  contains  node2  hfp  size  efw  somehost5  get  included  hosts  somehost3  ifw  node1  somehost1  includes  len  #dfs-hosts-excluded    getexcludesfile  excludesfile  excludeslen  newexcludesfile  assertfalse  getexcludedhosts   test for refreshing hostreader wit new include/exclude host files  hosts_test_dir  #this-is-comment    asserttrue  #hosts-in-dfs    node2    somehost3 # host3    somehost4    /dfs1.exclude  getincludesfile       * 1.create dfs.exclude dfs.include file     * 2.write host names per line     * 3.write comments starting with #     * 4.close file     * 5.compare if number of hosts reported by hostsfilereader     *   are equal to the number of hosts written       write  somehost2    close  gethosts  testhostsfilereader  host4  /dfs1.include  hostdetails  somehost4 # host4    host3  includesfile  somehost4 somehost5    refresh  assertequals  gethostdetails  newincludesfile  node1  contains  node2  hfp  size  efw  somehost5  getincludedhosts  somehost3    ifw  node1    somehost1    includeslen
__label__flaky read  fields  workflow  to  byte  array  dos  test  empty  write  read  baos  write  close  dis  readfields  workflow  tobytearray  dos  testemptywriteread  baos  write  close  dis
__label__nflaky byte  buffer  notification  test  stream  that  ends  normally  from  publisher  materialize  is  on  complete  consume  output  assert  stream  end  assert  true  get  await  time  unit  synchronized  list  count  down  collections  consumer  add  for  each  assert  equals  byte  buffer  observable  accept  get  value  size  is  on  next  stream  did  not  finish  before  timeout  complete  wrap  bytebuffernotification  teststreamthatendsnormally  frompublisher  materialize  isoncomplete  consume  output  assert  streamend  asserttrue  get  await  timeunit  synchronizedlist  countdown  collections  consumer  add  foreach  assertequals  bytebuffer  observable  accept  getvalue  size  isonnext  stream did not finish before timeout  complete  wrap
__label__flaky post  my  json  rest  servlet  http  servlet  response  invoke  assert  equals  /any  call  get  test  multiple  resources  wild  card  /resource1  /resource2  run  test    post  myjsonrestservlet  httpservletresponse  invoke  assertequals  /any  call  get  testmultipleresourceswildcard  /resource1  /resource2  runtest
__label__nflaky exception  get  localized  message  ninja  constant  equal  to  when  get  bad  request  result  result  result  get  renderable  assert  true  verify  not  important  get  template  argument  matchers  then  return  get  with  default  get  message  eq  real  test:  assert  that  any  ninja  default  test  get  bad  request  get  status  code  context  impl  messages  ninja  properties  exception  getlocalizedmessage  ninjaconstant  equalto  when  getbadrequestresult  result  result  getrenderable  asserttrue  verify  not important  gettemplate  argumentmatchers  thenreturn  getwithdefault  getmessage  eq   real test:  assertthat  any  ninjadefault  testgetbadrequest  getstatuscode  contextimpl  messages  ninjaproperties
__label__flaky add  record  to  bundle  action  table  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  sleep  bundle  job  assert  not  null  get  coordinator  action  end  current  date  plus  month  job  first  time   service  will  call  bundle  kill  bundle  wait  for  test  bundle  status  transit  service  killed2  add  a  bundle  action  with  no  coordinator  to  make  it  fail  add  record  to  bundle  job  table  bundle  id  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  with  bundle  services  coordinator  job  runnable  coord-action-get.xml  action2  jpa  service  evaluate  addrecordtobundleactiontable  getcurrentdateafterincrementinginmonths  getid  run  dateutils  getstatus  addrecordtocoordactiontable  parsedateoozietz  sleep  bundlejob  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  job   first time  service will call bundle kill  bundle  waitfor  testbundlestatustransitservicekilled2   add a bundle action with no coordinator to make it fail  addrecordtobundlejobtable  bundleid  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtablewithbundle  services  coordinatorjob  runnable  coord-action-get.xml  action2  jpaservice  evaluate
__label__nflaky mock  res  init  mock  req  verify  zero  interactions  x_  custom_  header  object  under  test  then  return  browser_  agent  csrf  has  not  been  sent  objects  to  verify  interactions  based  on  request  setup  the  configuration  settings  of  the  server  test  missing  header  with  custom  header  config  bad  request  when  filter  config  get  header  filter  mock  chain  get  init  parameter  mockito  do  filter  mock  rest  csrf  prevention  filter  mockres  init  mockreq  verifyzerointeractions  x_custom_header   object under test  thenreturn  browser_agent   csrf has not been sent   objects to verify interactions based on request   setup the configuration settings of the server  testmissingheaderwithcustomheaderconfigbadrequest  when  filterconfig  getheader  filter  mockchain  getinitparameter  mockito  dofilter  mock  restcsrfpreventionfilter
__label__flaky play  server  request  abcabcabc  client  connection  read  ascii  get  content  encoding  add  header  accept-  encoding:  gzip  get  headers  take  request  gzip  assert  equals  set  body  get  content  length  get  input  stream  assert  contains  content-  encoding:  gzip  /  integer  enqueue  get  url  assert  null  gzip  encoding  enabled  by  default  open  play  server  request  abcabcabc  client  connection  readascii  getcontentencoding  addheader  accept-encoding: gzip  getheaders  takerequest  gzip  assertequals  setbody  getcontentlength  getinputstream  assertcontains  content-encoding: gzip  /  integer  enqueue  geturl  assertnull  gzipencodingenabledbydefault  open
__label__nflaky integer  fail  assert  tmp  test  invalid  append  ascii  byte  array  buffer  index  out  of  bounds  exception  should  have  been  thrown  append  integer  fail  assert  tmp  testinvalidappendasciibytearray  buffer  indexoutofboundsexception should have been thrown  append
__label__flaky cluster  mtime  on  is  test1.dat  (  get  modification  time  atime  before  close  conf  adate  wait  active  get  file  status  ipc.client.connection.maxidletime  mdir1  info  localhost  2s  shutdown  cluster  and  restart  new  mtime  on  dfs  config  keys  mtime1  datanode  report  verifying  times  after  cluster  restart  check  new  modification  time  on  file  format  )  get  file  system  atime  on  mtime2  stm  mtime3  set  int  before  close  is  adate3  max_  idle_  time  creating  testdir1  and  testdir1/test1.dat.  mdate  num  data  nodes  nnport  file  sys  get  name  node  port  set  times  print  datanode  report  shutdown  name  node  port  date  form  new  atime  on  system  sleep  assert  true  cluster  restart.  mdate3  client  atime1  num  datanodes  addr  test  times  close  write  file  atime2  cleanup  file  atime3  stat  e  replicas  set  the  modification  time  to  be  1  hour  in  the  past  get  access  time  assert  equals  dir1  set  the  access  time  to  be  one  day  in  the  past  thread  build  testdir1  number  of  datanodes  file1  check  new  access  time  on  file  datanode  report  type  cluster  mtime on    is   test1.dat   (  getmodificationtime  atimebeforeclose  conf  adate  waitactive  getfilestatus  ipc.client.connection.maxidletime  mdir1  info  localhost      2s   shutdown cluster and restart  new mtime on   dfsconfigkeys  mtime1  datanodereport  verifying times after cluster restart   check new modification time on file  format  )  getfilesystem  atime on   mtime2  stm  mtime3  setint   before close is   adate3  max_idle_time  creating testdir1 and testdir1/test1.dat.  mdate  numdatanodes  nnport  filesys  getnamenodeport  settimes  printdatanodereport  shutdown  namenodeport  dateform  new atime on   system  sleep  asserttrue   cluster restart.  mdate3  client  atime1  numdatanodes  addr  testtimes  close  writefile  atime2  cleanupfile  atime3  stat  e  replicas   set the modification time to be 1 hour in the past  getaccesstime  assertequals  dir1   set the access time to be one day in the past  thread  build  testdir1  number of datanodes   file1   check new access time on file  datanodereporttype
__label__nflaky server  server  assert  false  start  conf  assert  equals  run  override  client  to  store  the  call  id  side  we  should  see  retry  count  as  0  test  initial  call  retry  count  get  connect  address  attach  a  listener  that  tracks  every  call  id  received  by  the  server.  caller  assert  net  utils  stop  client  get  call  retry  count  addr  server  server  assertfalse  start  conf  assertequals  run   override client to store the call id   side we should see retry count as 0  testinitialcallretrycount  getconnectaddress   attach a listener that tracks every call id received by the server.  caller  assert  netutils  stop  client  getcallretrycount  addr
__label__flaky init  coord  el  functions  ${coord:months(1)  +  7}  ${coord:months(1)}  test  month  assert  equals  timeunit  get  variable  1  eval  eval  and  wrap  256  7  8  time  unit  ${coord:months(256)}  expr  coord-job-submit-freq  ${coord:months(coord:months(7))}  init  coordelfunctions  ${coord:months(1) + 7}  ${coord:months(1)}  testmonth  assertequals  timeunit  getvariable  1  eval  evalandwrap  256  7  8  timeunit  ${coord:months(256)}  expr  coord-job-submit-freq  ${coord:months(coord:months(7))}
__label__nflaky list  appender  add  appender  stop  do  append  start  smoke  verify  async  appender  base  listappender  addappender  stop  doappend  start  smoke  verify  asyncappenderbase
__label__flaky coord  id1  test  get  sla  events  for  or  assert  equals  create  filter  list  list  coord  action  id1  execute  jobid  services  sla  events  get  cmd  size  assert  not  null  get  filter  list  jpa  service  coordid1  testgetslaeventsforor  assertequals  createfilterlist  list  coordactionid1  execute  jobid  services  slaeventsgetcmd  size  assertnotnull  get  filterlist  jpaservice
__label__nflaky test  local  f  sset  owner  assume  not  windows  conf  {}:  {}  set  owner  bar  localfs  file  system  get  write  file  get  groups  info  create  files  and  manipulate  them.  set  get  permission  belongs  to  only  one  group.  common  configuration  keys  f  groups  g0  assert  equals  g1  044  filename  not  testing  changing  the  group  since  user  size  cleanup  get  local  get  group  logger  testlocalfssetowner  assumenotwindows  conf  {}: {}  setowner  bar  localfs  filesystem  get  writefile  getgroups  info   create files and manipulate them.  set  getpermission  belongs to only one group.  commonconfigurationkeys  f  groups  g0  assertequals  g1  044  filename  not testing changing the group since user   size  cleanup  getlocal  getgroup  logger
__label__flaky test  coord  re  run  neg2  end_  points  is_  security_  enabled  oozie  url  assert  false  run  app  path  get  create  servlet_  classes  close  run  test  app  mock  coordinator  engine  service  coordinator.xml  get  context  url  mock  dag  engine  service  assert  equals  get  file  system  -rerun  args  call  1  -oozie  assert  null  mkdirs  job  get  fs  test  case  dir  testcoordrerunneg2  end_points  is_security_enabled  oozieurl  assertfalse  run  apppath  get  create  servlet_classes  close  runtest  app  mockcoordinatorengineservice  coordinator.xml  getcontexturl  mockdagengineservice  assertequals  getfilesystem  -rerun  args  call  1  -oozie  assertnull  mkdirs  job  getfstestcasedir
__label__nflaky time  unit  test  factory  test  factory  for  millisseconds  timeunit  testfactory  testfactoryformillisseconds
__label__flaky get  block  locations  file  name  expected  replica  count  dfs  client  read  file  from  position  dfs  client  read  file  replica  count  verify  first  block  corrupted  create  a  file  with  corrupted  block  replicas  get  verify  corrupted  block  count  get  namenode  repl  corrupt  bloc  replicas  verify  fsck  health  blocks  file  path  *  the  order  of  data  nodes  in  located  block  returned  by  name  node  is  sorted  *  by  network  toplology#pseudo  sort  by  distance.  in  current  mini  dfs  cluster   *  when  located  block  is  returned   the  sorting  is  based  on  a  random  order.  *  that  is  to  say   the  dfs  client  and  simulated  data  nodes  in  mini  dfs  *  cluster  are  considered  not  on  the  same  host  nor  the  same  rack.  *  therefore   even  we  corrupted  the  first  two  block  replicas  based  in  *  order.  when  dfs  client  read  some  block  replicas   it  is  not  guaranteed  *  which  block  replicas  (good/bad)  will  be  returned  first.  so  we  try  to  *  re-read  the  file  until  we  know  the  expected  replicas  numbers  is  *  returned.  dfs  target  replicas  is  3  but  found  1  replica  /tmp/test  client  report  bad  block/  corrupt  two  out  of  three  replicas  test  corrupt  two  out  of  three  replicas  long  get  locations  to  string  test  fsck  list  corrupt  files  blocks  getblocklocations  filename  expectedreplicacount  dfsclientreadfilefromposition  dfsclientreadfile  replicacount  verifyfirstblockcorrupted  createafilewithcorruptedblockreplicas  get  verifycorruptedblockcount  getnamenode  repl  corruptblocreplicas  verifyfsckhealth  blocks  filepath           * the order of data nodes in locatedblock returned by name node is sorted          * by networktoplology#pseudosortbydistance. in current minidfscluster           * when locatedblock is returned  the sorting is based on a random order.         * that is to say  the dfs client and simulated data nodes in mini dfs         * cluster are considered not on the same host nor the same rack.         * therefore  even we corrupted the first two block replicas based in          * order. when dfsclient read some block replicas  it is not guaranteed          * which block replicas (good/bad) will be returned first. so we try to          * re-read the file until we know the expected replicas numbers is          * returned.           dfs  target replicas is 3 but found 1 replica  /tmp/testclientreportbadblock/corrupttwooutofthreereplicas  testcorrupttwooutofthreereplicas  long  getlocations  tostring  testfscklistcorruptfilesblocks
__label__nflaky then  return  /testroute  context  path  index  is  get  reverse  route  with  no  context  path  works  get  context  path  assert  that  when  router  route  get  reverse  route  ninja  properties    thenreturn  /testroute  contextpath  index  is  getreverseroutewithnocontextpathworks  getcontextpath  assertthat  when  router  route  getreverseroute  ninjaproperties
__label__flaky play  verify  the  peer  received  what  was  expected.  android  okio  type_  data  header  entries  util  get  sink  out  accept  frame  flush  type_  headers  peer  client  connection  buffer  write  close  take  frame  banana  a  b  syn  reply  set  variant  and  client  data  assert  equals  frame  count  syn_  stream  send  frame  client  sends  empty  data  server  doesnt  send  window  update  spdy3  play  it  back.  new  stream  play   verify the peer received what was expected.  android  okio  type_data  headerentries  util  getsink  out  acceptframe  flush  type_headers  peer  client  connection  buffer  write  close  takeframe  banana  a  b  synreply  setvariantandclient   data  assertequals  framecount   syn_stream  sendframe  clientsendsemptydataserverdoesntsendwindowupdate  spdy3   play it back.  newstream
__label__nflaky dst  codec  test  utils  channel  convert  assert  inbuf  assert  true  test  basic  decoding  is  completed  read  standard  charsets  5  01234  5  56789  6  abcdef  0  clear  bytes  read  assert  equals  chunk-coded;  completed:  true  decoder  0123456789abcdef  byte  buffer  trailers  allocate  to  string  metrics  get  trailers  dst  codectestutils  channel  convert  assert  inbuf  asserttrue  testbasicdecoding  iscompleted  read  standardcharsets  5  01234  5  56789  6  abcdef  0      clear  bytesread  assertequals  chunk-coded; completed: true  decoder  0123456789abcdef  bytebuffer  trailers  allocate  tostring  metrics  gettrailers
__label__flaky cluster  conf  namenode  args  get  default  uri  test  fs  option  build  file  system  test  property  option  to  string  test  conf  option  test  dfs  command  /data  shutdown  -mkdir  cluster  conf  namenode  args  getdefaulturi  testfsoption  build  filesystem  testpropertyoption  tostring  testconfoption  testdfscommand  /data  shutdown  -mkdir
__label__nflaky append  bits  test  append  bit  vector  append  bit  array  x.  xxxxx.  xxx.  xxxx  to  string  assert  equals  v1  beef  =  1011  1110  1110  1111  v2  appendbits  testappendbitvector  appendbitarray   x.xxxxx. xxx.xxxx  tostring  assertequals  v1   beef = 1011 1110 1110 1111  v2
__label__flaky _test  is  main  successful  action  dir  has  output  data  assert  false  running  job  is  main  done  get  file  system  fs  has  id  swap  get  id  swap  path  exit1  is  successful  assert  true  launcher  mapper  get  error  path  exists  get  output  data  path  evaluate  wait  for  test  exit1  get  fs  test  case  dir  is  complete  _test  ismainsuccessful  actiondir  hasoutputdata  assertfalse  runningjob  ismaindone  getfilesystem  fs  hasidswap  getidswappath  exit1  issuccessful  asserttrue  launchermapper  geterrorpath  exists  getoutputdatapath  evaluate  waitfor  testexit1  getfstestcasedir  iscomplete
__label__nflaky fail  empty  string  not  allowed  test  empty  tokenize    fail  empty string not allowed  testempty  tokenize
__label__flaky get  version  test  get  storage  cluster  version  xml  /version/cluster  get  body  log  cluster  version  model  create  unmarshaller  success  retrieving  storage  cluster  version  as  xml  unmarshal  assert  true  response  assert  not  null  get  context  client  get  code  mimetype_  xml  info  getversion  testgetstorageclusterversionxml  /version/cluster  getbody  log  clusterversionmodel  createunmarshaller  success retrieving storage cluster version as xml  unmarshal  asserttrue  response  assertnotnull  get  context  client  getcode  mimetype_xml  info
__label__nflaky make  graphite  argument  ms  info  is  connected  test  failure  and  put  metrics  graphite  when  result  put  metrics  record  host  verify  for  class  foo1  foo2  null.all.  context.  context=all.  hostname=host.foo1  1.25  10  write  close  reset  mock  and  try  again  mock  graphite  all  add  throw  exception  when  first  try  null.all.  context.  context=all.  hostname=host.foo2  2.25  10  argument  captor  sink  any  string  then  return  capture  assert  equals  io  exception  tags  make  metric  whitebox  get  value  do  throw  equals  reset  metrics  set  internal  state  makegraphite  argument  msinfo  isconnected  testfailureandputmetrics  graphite  when  result  putmetrics  record  host  verify  forclass  foo1  foo2  null.all.context.context=all.hostname=host.foo1 1.25 10    write  close   reset mock and try again  mockgraphite  all  add   throw exception when first try  null.all.context.context=all.hostname=host.foo2 2.25 10    argumentcaptor  sink  anystring  thenreturn  capture  assertequals  io exception  tags  makemetric  whitebox  getvalue  dothrow  equals  reset  metrics  setinternalstate
__label__flaky bundle  job  get  executor  bundle  job  should  have  been  purged  bundle  action  should  have  been  purged  add  record  to  bundle  action  table  get  id  date  utils  get  status  parse  date  oozie  tz  get  error  code  assert  not  null  get  job  2011-01-01  t01:00  z  add  record  to  bundle  job  table  assert  equals  execute  call  test  suc  bundle  purge  x  command  services  fail  bundle  action  get  executor1  bundle  action  get  executor2  action1  error  code  je  job  action2  jpa  service  bundlejobgetexecutor  bundle job should have been purged  bundle action should have been purged  addrecordtobundleactiontable  getid  dateutils  getstatus  parsedateoozietz  geterrorcode  assertnotnull  get  job  2011-01-01t01:00z  addrecordtobundlejobtable  assertequals  execute  call  testsucbundlepurgexcommand  services  fail  bundleactiongetexecutor1  bundleactiongetexecutor2  action1  errorcode  je  job  action2  jpaservice
__label__nflaky add  from  list  assert  equals  l  test  iterator  add  fromlist  assertequals  l  testiterator
__label__flaky cluster  dfs_  namenode_  replication_  min_  key  create  cluster  test  fs  close  after  cluster  shutdown  has  exception  test  fs  close  after  cluster  shutdown  successful  conf  system  create  file  get  bytes  test  fs  close  after  cluster  shutdown:  error  here  wait  active  out  ipc.ping.interval  hflush  hdfs  timeout  is  default  60  seconds  assert  true  something_test  fpath  create  a  new  file.  write  close  stop  data  node  encountered.  ensure  that  block  is  allocated  f  hdfs  timeout  is  now  10  second  get  file  system  test  file  creation  ipc.client.ping  dir  set  int  dfs  failed  to  close  file  after  cluster  shutdown  test  closing  file  after  cluster  is  shutdown  build  num  data  nodes  datanode_  num  test  test  fs  close  after  cluster  shutdown  start  shutdown  last  datanode  in  pipeline.  shutdown  set  boolean  cluster  dfs_namenode_replication_min_key   create cluster  testfscloseafterclustershutdown  hasexception  testfscloseafterclustershutdown successful  conf  system  createfile  getbytes  testfscloseafterclustershutdown: error here  waitactive  out  ipc.ping.interval  hflush   hdfs timeout is default 60 seconds  asserttrue  something_test  fpath   create a new file.  write  close  stopdatanode   encountered.   ensure that block is allocated  f   hdfs timeout is now 10 second  getfilesystem  testfilecreation  ipc.client.ping  dir  setint  dfs  failed to close file after cluster shutdown   test closing file after cluster is shutdown  build  numdatanodes  datanode_num  test testfscloseafterclustershutdown start   shutdown last datanode in pipeline.  shutdown  setboolean
__label__nflaky 10.241.23.1  10.241.24.0  10.241.23.0  10.119.103.111  assert  false  10.241.22.255  includes  test  for  exclusion  with  an  unknown  ip  test  for  inclusion/exclusion  test  cidr  with8  bit  mask  cidr_  list2  assert  true  create  machine  list  with  a  list  of  of  ip  ranges  specified  in  cidr  format  10.241.23.254  10.241.23.255  ml  10.241.23.1  10.241.24.0  10.241.23.0  10.119.103.111  assertfalse  10.241.22.255  includes   test for exclusion with an unknown ip   test for inclusion/exclusion  testcidrwith8bitmask  cidr_list2  asserttrue   create machinelist with a list of of ip ranges specified in cidr format  10.241.23.254  10.241.23.255  ml
__label__flaky script  executor  session  given  eq  select  *  from  entity_counter  where  id  =  delete  when  of  where  id  execute  script  template  actual  random  utils  manager  incr  all  columns_  from  base  table  one  should_dsl_delete  next  long  assert  that  execute  immutable  map  entity  with  counter  column/insert_single_row.cql  then  is  null  long  dsl  scriptexecutor  session   given  eq  select * from entity_counter where id =   delete   when  of  where  id  executescripttemplate  actual  randomutils  manager  incr  allcolumns_frombasetable  one  should_dsl_delete  nextlong  assertthat  execute  immutablemap  entitywithcountercolumn/insert_single_row.cql   then  isnull  long  dsl
__label__nflaky add  find  default  component  type  result  a  registry  other  assert  null  absent  add  finddefaultcomponenttype  result  a  registry  other  assertnull  absent
__label__flaky callable2  callable3  callables  other  callable1  callable6  callable4  callable  c  executed  :  callable5  math  queueservice  as  list  system  callable  callable  other  executed  :  assert  true  get  test  concurrency  reached  and  choose  next  eligible  wait  for  cl  callable  init  c  queue  size  x  test  case  last  callable  other  max  callable  queue  service  destroy  original  ratio  services  set  system  property  true  long  reset  concurrency  callable  queue  size  :  arrays  evaluate  queue  callable2  callable3  callables  other  callable1  callable6  callable4  callable c executed :  callable5  math  queueservice  aslist  system  callable callableother executed :  asserttrue  get  testconcurrencyreachedandchoosenexteligible  waitfor  clcallable  init  c  queuesize  xtestcase  last  callableother  max  callablequeueservice  destroy  originalratio  services  setsystemproperty  true  long  resetconcurrency  callable queue size :  arrays  evaluate  queue
__label__nflaky test  file01  get  path  data  check  reverse  default  ordering  testfile01  add  contents  ls  format  line  mtime  out  process  path  dir  order  default  reverse  testfile03  options  compute  line  format  in  order  testfile02  process  options  verify  testfile05  test  file06  testfile04  test  file04  test  file05  testfile06  test  file02  test  file03  add  found  6  items  path  data  line  format  -r  set  is  dir  process  arguments  test  dir  test  directory  verify  no  more  interactions  test  file  mock  add  contents  in  non-lexigraphic  order  to  show  they  get  sorted    testfile01  getpathdata   check reverse default ordering  testfile01  addcontents  ls  formatlinemtime  out  processpathdirorderdefaultreverse  testfile03  options  computelineformat  inorder  testfile02  processoptions  verify  testfile05  testfile06  testfile04  testfile04  testfile05  testfile06  testfile02  testfile03  add  found 6 items  pathdata  lineformat  -r  setisdir  processarguments  testdir  testdirectory  verifynomoreinteractions  testfile  mock   add contents in non-lexigraphic order to show they get sorted
__label__flaky test.txt  get  job  tracker  uri  get  name  lib  subwf  reader  local  oozie  lib/test.jar  conf  get  status  output  getting  external  i  ds  of  all  actions  on  first  run  </workflow-app>  writer2  writer1  get  test  case  dir  /workflow.xml  create  comparing  external  i  ds  of  first  run  and  rerun  are  different.  workflow.xml  write  wait  for  name  node  app  <start  to=\'end\'/>  wf  client  load  ext  ids  <end  name=\'end\'/>  is  get  file  system  test.jar  re  run  doing  a  rerun  skipping  no  nodes  del  path  input  oozie  client  copy  char  stream  mkdirs  set  property  get  resource  as  reader  create  configuration  file  evaluate  ext  id0  ext  id1  recovery-wf.xml  submit  mrclass  get  job  info  <workflow-app  xmlns=\'uri:oozie:workflow:0.1\'  name=\'app\'>  get  actions  app  path  fs  app1  job  id1  create  jar  job  tracker  workflow  job  close  get  name  node  uri  os  sub  wf  app  getting  external  i  ds  of  all  actions  on  rerun  start  sub  workflow  app  path  assert  equals  get  client  test  rerun  /subwf/workflow.xml  io  utils  jar  file  copy  stream  assert  not  same  to  string  writer  get  fs  test  case  dir  first  run  test.txt  getjobtrackeruri    getname  lib  subwf  reader  localoozie  lib/test.jar  conf  getstatus  output   getting external ids of all actions on first run  </workflow-app>  writer2  writer1  gettestcasedir  /workflow.xml  create   comparing external ids of first run and rerun are different.  workflow.xml  write  waitfor  namenode  app  <start to=\'end\'/>  wfclient  loadextids  <end name=\'end\'/>  is  getfilesystem  test.jar  rerun   doing a rerun skipping no nodes  delpath  input  oozieclient  copycharstream  mkdirs  setproperty  getresourceasreader  createconfiguration  file  evaluate  extid0  extid1  recovery-wf.xml  submit  mrclass  getjobinfo  <workflow-app xmlns=\'uri:oozie:workflow:0.1\' name=\'app\'>  getactions  apppath  fs  app1  jobid1  createjar  jobtracker  workflowjob  close  getnamenodeuri  os  subwfapp   getting external ids of all actions on rerun  start  subworkflowapppath  assertequals  getclient  testrerun  /subwf/workflow.xml  ioutils  jarfile  copystream  assertnotsame  tostring  writer  getfstestcasedir   first run
__label__nflaky vv  configuration  regular  key  not  found  conf  add  deprecation  n  k1  found  assert  true  v  get  vvv  n  k2  found  test  iterator  with  deprecated  keys  mapped  to  multiple  new  keys  get  key  d  k  found  new  key  2  not  found  set  d  k  assert  equals  deprecated  key  not  found  k  entry  get  value  k  found  n  k2  n  k1  v  equals  new  key  1  not  found  vv  configuration  regular key not found  conf  adddeprecation  nk1found  asserttrue  v  get  vvv  nk2found  testiteratorwithdeprecatedkeysmappedtomultiplenewkeys  getkey  dkfound  new key 2 not found  set  dk  assertequals  deprecated key not found  k  entry  getvalue  kfound  nk2  nk1  v  equals  new key 1 not found
__label__flaky test  mat  lookup  command1  check  coord  jobs  2009-02-01  t01:00  z  get  id  date  utils  parse  date  oozie  tz  add  record  to  coord  job  table  call  coordinator  job  2009-02-03  t23:59  z  start  time  end  time  job  testmatlookupcommand1  checkcoordjobs  2009-02-01t01:00z  getid  dateutils  parsedateoozietz  addrecordtocoordjobtable  call  coordinatorjob  2009-02-03t23:59z  starttime  endtime  job
__label__nflaky create  user  for  testing  set  set  conf   should  again  override  assert  false  rules  assert  equals  conf  kerberos  name  explicitly  set  a  rule  implicit  init  should  honor  rules  already  being  set  hadoop_  security_  auth_  to_  local  rule:1:  test2  rule:1:  test3  someone  rule:1:  test1  assert  true  test  set  config  with  rules  has  rules  been  set  reset  get  rules  set  rules  set  configuration  set  conf   should  override  user  group  information  createuserfortesting  set   set conf  should again override  assertfalse  rules  assertequals  conf  kerberosname   explicitly set a rule   implicit init should honor rules already being set  hadoop_security_auth_to_local  rule:1:test2  rule:1:test3  someone  rule:1:test1  asserttrue  testsetconfigwithrules  hasrulesbeenset  reset  getrules  setrules  setconfiguration   set conf  should override  usergroupinformation
__label__flaky server  proxy  users  test  protocol  rpc  get  proxy  superuser  group  conf  key  get  proxy  a  method  group_  names  conf  run  ret  val  assert  set  strings  test  real  user  ip  not  specified  real_  user_  short_  name  stop  proxy  addr  user  group  information  get  server  ret  proxy  user  ugi  print  stack  trace  e  start  create  remote  user  group1  get  connect  address  real_  user_  name  proxy  fail  do  as  net  utils  stop  address  proxy_  user_  name  the  rpc  must  have  failed  real  user  ugi  create  proxy  user  for  testing  server  proxyusers  testprotocol  rpc  getproxysuperusergroupconfkey  getproxy  amethod  group_names  conf  run  retval  assert  setstrings  testrealuseripnotspecified  real_user_short_name  stopproxy  addr  usergroupinformation  getserver  ret  proxyuserugi  printstacktrace  e  start  createremoteuser  group1  getconnectaddress  real_user_name  proxy  fail  doas  netutils  stop  address  proxy_user_name  the rpc must have failed   realuserugi  createproxyuserfortesting
__label__nflaky to  string  run  from  to  test  cp  without  p  assert  attributes  changed  tostring  run  from  to  testcpwithoutp  assertattributeschanged
__label__flaky my  file  file  name  get  name  create  a  file  with  a  new  name  list  status  conf  run  emptier  thread  file  system  should\'ve  been  deleted  and  current  might  not  have  been  recreated  yet  get  path  interrupt  join  emptier  mkdir  test_  dir  val  add  init  fs_  trash_  interval_  key  -rm  delete  the  file  to  trash  trash  dir  trash  test/mkdirs/my  file  fs_  trash_  checkpoint_  interval_  key  size  12  seconds  shell  first  create  a  new  directory  with  mkdirs  start  emptier  in  background  fs.default.name  files  scan  files  in  .  trash  and  add  them  to  set  of  checkpoints  get  uri  my  path  test  trash  emptier  6  seconds  get  localized  message  fs  system  sleep  file  assert  true  get  current  trash  dir  if  checkpoints  has  4  objects  it  is  current  +  3  checkpoint  directories  write  file  get  parent  set  file  index  e  set  class  start  checkpoints  set  conf  thread  args  0.1  0.2  exception  raised  from  trash.run  get  local  get  emptier  test/mkdirs  to  string  fs.file.impl  myfile  filename  getname   create a file with a new name  liststatus  conf  run  emptierthread  filesystem   should\'ve been deleted and current might not have been recreated yet  getpath  interrupt  join  emptier  mkdir  test_dir  val  add  init  fs_trash_interval_key  -rm   delete the file to trash  trashdir  trash  test/mkdirs/myfile  fs_trash_checkpoint_interval_key  size   12 seconds  shell   first create a new directory with mkdirs   start emptier in background  fs.default.name  files   scan files in .trash and add them to set of checkpoints  geturi  mypath  testtrashemptier   6 seconds  getlocalizedmessage  fs  system  sleep  file  asserttrue  getcurrenttrashdir   if checkpoints has 4 objects it is current + 3 checkpoint directories  writefile  getparent  set  fileindex  e  setclass  start  checkpoints  setconf  thread  args  0.1  0.2  exception raised from trash.run   getlocal  getemptier  test/mkdirs  tostring  fs.file.impl
__label__nflaky assert  correct  image2string  test  decode  row2string28  (10)1098/1234  28.png  assertcorrectimage2string  testdecoderow2string28  (10)1098/1234  28.png
__label__flaky end_  points  is_  security_  enabled  oozie  url  get  user  get  id  wc  get  status  get  bundle  job  info  bundle  job  get  coord  job  info  get  acl  servlet_  classes  wf  action  run  test  test  job  information  group  rest  constants  get  context  url  mock  dag  engine  service  assert  equals  call  1  job  id  succeeded  to  string  job  user  get  job  log  get  workflow  action  info  end_points  is_security_enabled  oozieurl  getuser  getid  wc  getstatus  getbundlejobinfo  bundlejob  getcoordjobinfo  getacl  servlet_classes  wfaction  runtest  testjobinformation  group  restconstants  getcontexturl  mockdagengineservice  assertequals  call  1  jobid  succeeded  tostring  job  user  getjoblog  getworkflowactioninfo
__label__nflaky hook2  hook1  timeouts  test  hook  finish  without  timeout  execute  shutdown  hook  clear  shutdown  hooks  assert  not  null  analyze  the  hooks  mgr  get  hook  time  unit  hook4  hook3  shutdown  completed  hook5  info  invocation_  count  a  default  timeout  hook  and  verify  it  gets  the  default  timeout  log  was  not  invoked  hook4  was  invoked  first   but  it  timed  out.  sleeping  hook4  blocked  other  threads  for  expected  to  complete  entry  hook  priority  size  now  execute  the  hook  shutdown  sequence  shutdown  hook  list  is  not  empty  invoking  execute  shutdown()  expected  to  be  invoked  first  get  shutdown  hooks  in  order  assert  false  is  the  longest.  add  shutdown  hook  shutdown  hook  manager  invocation  difference  too  short  assert  true  get  get  timeout  test  hook  finish  with  timeout;  highest  priority  number  of  timed  out  hooks  hooks  get  shutdown  timeout  hook4timeout  set  hook  entry5  failed  to  remove  assert  equals  service_  shutdown_  timeout_  default  did  any  hook  raise  an  exception?  no  shutdown  hook  manager  expected  to  time  out  remove  this  to  avoid  a  longer  sleep  in  the  test  run  maybe  throw  assertion  has  shutdown  hook  invocation  interval  finally   clear  the  hooks  get  priority  remove  shutdown  hook  and  verify  that  the  hooks  are  empty  default  timeout  not  used  shutdown  hook  manager  hook2  hook1  timeouts   test hook finish without timeout  executeshutdown  hook  clearshutdownhooks  assertnotnull   analyze the hooks  mgr  gethook  timeunit  hook4  hook3  shutdown completed  hook5  info  invocation_count   a default timeout hook and verify it gets the default timeout  log  was not invoked    hook4 was invoked first  but it timed out.  sleeping hook4 blocked other threads for   expected to complete   entry  hook priority  size   now execute the hook shutdown sequence  shutdown hook list is not empty  invoking executeshutdown()  expected to be invoked first   getshutdownhooksinorder  assertfalse   is the longest.  addshutdownhook  shutdownhookmanager  invocation difference too short   asserttrue  get  gettimeout   test hook finish with timeout; highest priority  number of timed out hooks  hooks  getshutdowntimeout  hook4timeout  set  hookentry5  failed to remove   assertequals  service_shutdown_timeout_default   did any hook raise an exception?  no shutdownhookmanager  expected to time out    remove this to avoid a longer sleep in the test run  maybethrowassertion  hasshutdownhook  invocationinterval   finally  clear the hooks  getpriority  removeshutdownhook   and verify that the hooks are empty  default timeout not used  shutdownhookmanager
__label__flaky subwf  job3  get  cmd  add  record  to  wf  action  table  workflow  action  2  should  have  been  purged  workflow  instance  get  status  wf  action5  get  cmd  sub  workflow  action  5  should  have  been  purged  wf  action1  get  cmd  assert  not  null  workflow  action  5  should  have  been  purged  sub  workflow  job  3  should  have  been  purged  subwf  action3  get  cmd  wf  job  get  cmd  subwf  job2  get  cmd  sub  workflow  action  2  should  have  been  purged  sub  workflow  job  1  should  have  been  purged  subwf  action4  get  cmd  sub  workflow  job  4  should  have  been  purged  execute  1  fail  2  3  4  workflow  action  5  wf  action2  get  cmd  workflow  action  3  should  have  been  purged  je  subwf  action5  subwf  job1  get  cmd  get  id  sub  workflow  job  2  should  have  been  purged  subwf  action5  get  cmd  subwf  job5  get  cmd  wf  job  subwf  action1  get  cmd  workflow  job  should  have  been  purged  add  record  to  wf  job  table  get  error  code  get  subwf  job1  workflow  action  1  should  have  been  purged  workflow  job  subwf  job5  subwf  action1  subwf  job4  subwf  action2  sub  workflow  action  4  should  have  been  purged  subwf  job3  subwf  action3  subwf  job2  subwf  action4  wf  action3  get  cmd  wf  action4  get  cmd  workflow  action  4  should  have  been  purged  assert  equals  wf  action1  sub  workflow  action  3  should  have  been  purged  wf  action2  wf  action3  wf  action4  wf  action5  call  services  test  purge  wf  with  sub  wf3  more  than  limit  sub  workflow  action  1  should  have  been  purged  sub  workflow  job  5  should  have  been  purged  subwf  action2  get  cmd  error  code  jpa  service  subwf  job4  get  cmd  subwfjob3getcmd  addrecordtowfactiontable  workflow action 2 should have been purged  workflowinstance  getstatus  wfaction5getcmd  subworkflow action 5 should have been purged  wfaction1getcmd  assertnotnull  workflow action 5 should have been purged  subworkflow job 3 should have been purged  subwfaction3getcmd  wfjobgetcmd  subwfjob2getcmd  subworkflow action 2 should have been purged  subworkflow job 1 should have been purged  subwfaction4getcmd  subworkflow job 4 should have been purged  execute  1  fail  2  3  4  workflowaction  5  wfaction2getcmd  workflow action 3 should have been purged  je  subwfaction5  subwfjob1getcmd  getid  subworkflow job 2 should have been purged  subwfaction5getcmd  subwfjob5getcmd  wfjob  subwfaction1getcmd  workflow job should have been purged  addrecordtowfjobtable  geterrorcode  get  subwfjob1  workflow action 1 should have been purged  workflowjob  subwfjob5  subwfaction1  subwfjob4  subwfaction2  subworkflow action 4 should have been purged  subwfjob3  subwfaction3  subwfjob2  subwfaction4  wfaction3getcmd  wfaction4getcmd  workflow action 4 should have been purged  assertequals  wfaction1  subworkflow action 3 should have been purged  wfaction2  wfaction3  wfaction4  wfaction5  call  services  testpurgewfwithsubwf3morethanlimit  subworkflow action 1 should have been purged  subworkflow job 5 should have been purged  subwfaction2getcmd  errorcode  jpaservice  subwfjob4getcmd
__label__nflaky my  app123.  path789.my  callback123  period  in  the  front   object  function  alert(document.cookie)  $42.ajax  handler  assert  false  .on  response  object  function   path  with  numbers  function  call  on  response  \\u0020  unicode  characters  assert  true  complex  path   $  in  identity.  simple  function  template  engine  json  p  .  my  path.path  42$.q  my  path.path  my  path.path.path2.  wrong  first  character  simple  array  my  app.  path.my  callback123  period  in  the  front   simple  period  in  the  end   complex  path  ext.data.  json  p.callback4  my  path..path.path2  period  in  the  end   simple  is  this  a  secure  callback  name  object  function  somearray12345  cases  not  supported  by  the  validator.  complex  path  on  response.  two  subsequent  periods  test  is  this  a  secure  callback  name  \\u0062oo  myapp123.path789.mycallback123  period in the front  object function  alert(document.cookie)  $42.ajaxhandler  assertfalse  .onresponse  object function  path with numbers  function call  onresponse  \\u0020  unicode characters  asserttrue  complex path  $ in identity.  simple function  templateenginejsonp  .mypath.path  42$.q  mypath.path  mypath.path.path2.  wrong first character  simple array  myapp.path.mycallback123  period in the front  simple  period in the end  complex path  ext.data.jsonp.callback4  mypath..path.path2  period in the end  simple  isthisasecurecallbackname  object function  somearray12345   cases not supported by the validator.  complex path  onresponse.  two subsequent periods  testisthisasecurecallbackname  \\u0062oo
__label__flaky get  name  oozie.service.  proxy  user  service.proxyuser.foo.groups  foo  conf  as  list  bar  assert  string  utils  assert  not  null  test  unknown  host  get  join  validate  localhost  init  set  oozie.service.  proxy  user  service.proxyuser.foo.hosts  get  conf  destroy  *  services     services  fail  ex  proxy  user  to  string  unknownhost.bar.foo  arrays  getname  oozie.service.proxyuserservice.proxyuser.foo.groups  foo  conf  aslist  bar  assert  stringutils  assertnotnull  testunknownhost  get  join  validate  localhost  init  set  oozie.service.proxyuserservice.proxyuser.foo.hosts  getconf  destroy  *  services     services  fail  ex  proxyuser  tostring  unknownhost.bar.foo  arrays
__label__nflaky conn  read  in  stream  then  return  argument  matchers  set  so  timeout  get  input  stream  when  any  any  int  times  bind  assert  mockito  assert  true  ensure  open  verify  get  so  timeout  await  input  socket  spy  test  await  input  in  socket  conn  read  instream  thenreturn  argumentmatchers  setsotimeout  getinputstream  when  any  anyint  times  bind  assert  mockito  asserttrue  ensureopen  verify  getsotimeout  awaitinput  socket  spy  testawaitinputinsocket
__label__flaky @  ::  close  trx  coord  client  get  store  get  time  local  oozie  2009-12-15  t01:00  z  could  not  update  db.  get  status  2009-12-17  t01:00  z  -test  coord  rerun-  c  get  coord  client  rerun  scope  get  begin  trx  coordinator  action  re  run  coord  action  num2  commit  trx  action  num1  coord-rerun-action2.xml  rest  constants  print  stack  trace  store1  e  store  action  id2  add  record  to  job  table  job  id  action  id1  services  fail  coordinator  job  add  record  to  action  table  assert  not  same  test  coord  rerun  date4  0000000-  action1  action2  coord-rerun-action1.xml  get  coordinator  action  @  ::  closetrx  coordclient  getstore  gettime  localoozie  2009-12-15t01:00z  could not update db.  getstatus  2009-12-17t01:00z  -testcoordrerun-c  getcoordclient  rerunscope  get  begintrx  coordinatoraction  reruncoord  actionnum2  committrx  actionnum1  coord-rerun-action2.xml  restconstants  printstacktrace  store1  e  store  actionid2  addrecordtojobtable  jobid  actionid1  services  fail  coordinatorjob  addrecordtoactiontable  assertnotsame  testcoordrerundate4  0000000-  action1  action2  coord-rerun-action1.xml  getcoordinatoraction
__label__nflaky http  headers  process  http  status  get  first  header  h1  interceptor  h2  get  entity  test  response  date  generated  assert  response  assert  not  null  context  ok  httpheaders  process  httpstatus  getfirstheader  h1  interceptor  h2  getentity  testresponsedategenerated  assert  response  assertnotnull  context  ok
__label__flaky get  connection  context  get  event  message  conf  parse  date  utc  date  utils  get  status  wf-app-name1  ca  id1  2012-07-22  t00:00  z  wf  id1  get  start  time  message  type  init  print  stack  trace  get  text  destroy  wf  event  listener  fail  contains  on  workflow  job  event  create  consumer  app  type  start  date  get  parent  id  get  app  type  session  assert  false  jms  messaging  utils  get  event  status  get  user  event  status  get  id  create  session  get  topic  test  on  workflow  job  suspend  event  get  error  code  workflow  job  jms  context  consumer  user1  get  message  type  receive  get  app  name  e  get  message  assert  equals  message  assert  null  wfe  wf  fail  message  end  time  session  get  error  message  getconnectioncontext  geteventmessage  conf  parsedateutc  dateutils  getstatus  wf-app-name1  caid1  2012-07-22t00:00z  wfid1  getstarttime  messagetype  init  printstacktrace  gettext  destroy  wfeventlistener  fail  contains  onworkflowjobevent  createconsumer  apptype  startdate  getparentid  getapptype  session  assertfalse  jmsmessagingutils  geteventstatus  getuser  eventstatus  getid  createsession  gettopic  testonworkflowjobsuspendevent  geterrorcode  workflowjob  jmscontext  consumer  user1  getmessagetype  receive  getappname  e  getmessage  assertequals  message  assertnull  wfe  wffailmessage  endtime  session  geterrormessage
__label__nflaky test  read  with  known  length  read  shorter  length   make  sure  it  shortens  in  line  assert  equals  hello  world  read  with  known  length  get  bytes  hello  w  input  bytes  read  longer  length   make  sure  it  lengthens  reset  to  string  text  he  charsets  testreadwithknownlength   read shorter length  make sure it shortens  in  line  assertequals  hello world  readwithknownlength  getbytes  hello w  inputbytes   read longer length  make sure it lengthens  reset  tostring  text  he  charsets
__label__flaky test  permission  mask  create  short  permission  -rwxrwxrwx  r--------  ae  400  777  to  string  assert  equals  rwxrwxrwx  -r--------  testpermissionmask  createshortpermission  -rwxrwxrwx  r--------  ae  400  777  tostring  assertequals  rwxrwxrwx  -r--------
__label__nflaky add  test  service  assert  in  state  state  services  test  service  stop  from  not  inited  stop  service  manager  service  num_  of_  services  to  array  add  services  get  services  service  manager  addtestservice  assertinstate  state  services  testservicestopfromnotinited  stop  servicemanager  service  num_of_services  toarray   add services  getservices  servicemanager
__label__flaky format  date  server  request  code  string  assert  equals  set  response  code  body  new  call  execute  url  /  enqueue  get  url  http  url  connection  build  response  client  supplied  condition  without  cached  result  if-  modified-  since  time  unit  header  client  formatdate    server  request  code  string  assertequals  setresponsecode  body  newcall  execute  url  /  enqueue  geturl  httpurlconnection  build  response  clientsuppliedconditionwithoutcachedresult  if-modified-since  timeunit  header  client
__label__nflaky test  succeeds  ten  times  then  fail  over  unreliable  succeeds  ten  times  then  fails  returning  string  impl2  create  assert  equals  impl1  new  flip  flop  proxy  provider  retry  proxy  testsucceedstentimesthenfailover  unreliable  succeedstentimesthenfailsreturningstring  impl2  create  assertequals  impl1  newflipflopproxyprovider  retryproxy
__label__flaky def  add  node  j1  j2  expected  to  catch  an  exception  but  did  not  encounter  any  f2  two  get  cause  as  list  we  been  j2  invoke  fork  join  get  error  code  assert  true  test  fork  join  mismatch  dummy  conf  end  f  one  get  message  assert  equals  join  j1  k  kill  fail  contains  ex  parser  fork  f  name  error  code  arrays  *  f->(1 2)  *  1->ok->j1  *  1->fail->k  *  2->ok->j2  *  2->fail->k  *  j1->end  *  j2->f2  *  f2->k k  def  addnode  j1  j2  expected to catch an exception but did not encounter any  f2  two  getcause  aslist  we  been j2  invokeforkjoin  geterrorcode  asserttrue  testforkjoinmismatch  dummyconf  end  f  one  getmessage  assertequals  join j1  k  kill  fail  contains  ex  parser  fork f  name  errorcode  arrays         * f->(1 2)       * 1->ok->j1       * 1->fail->k       * 2->ok->j2       * 2->fail->k       * j1->end       * j2->f2       * f2->k k
__label__nflaky test.txt  viewfs:///  wrong  file  content  starting  test  nfly  write  simple  list  status  conf  test  conf  should  exist!  /nfwd2  test  uri  uri  /nfwd1  read  utf  assert  true  file  system  get  create  close  info  test  uris  nfly  root  test  file  name  /nflyroot  test  nfly  write  simple  log  config  util  fs  dos  assert  equals  test  file  fsdis  nfly  get  local  test  string  add  link  nfly  write  utf  lfs  statuses  exists  target  test  root  to  string  hello  nfly!  open  test.txt  viewfs:///  wrong file content  starting testnflywritesimple  liststatus  conf  testconf   should exist!  /nfwd2  testuri  uri  /nfwd1  readutf  asserttrue  filesystem  get  create  close  info  testuris  nflyroot  testfilename  /nflyroot  testnflywritesimple  log  configutil  fsdos  assertequals  testfile  fsdis  nfly  getlocal  teststring  addlinknfly  writeutf  lfs  statuses  exists  targettestroot  tostring  hello nfly!  open
__label__flaky app  fw1  org.apache.oozie.core.command.  workflow  runner  callable  f1  stream  log  _  l23_  check  if  the  lines  of  the  log  contain  the  expected  strings  2012-04-24  22:43:13 961  info  _  l23_:317  -  split  _  l19_  get  test  case  dir  2012-04-24  22:43:13 958  debug  _  l22_:323  -  str2  job  token  write  from  oozie.log  set  log  level  _  l20_  /  between  the  start  and  end  times  of  the  job  contains  reset  pattern  and  parameters  like  job  id   username  etc.  and/or  based  on  log  level  like  info   debug   etc.  out  filename  test  for  the  log  retrieval  of  the  job  spanning  multiple  hours  oozie.log-2012-04-24-21.gz  sb1  write  to  gz  file  debug|  info  calendar  entry  get  time  released  lock  test  stream  log  multiple  hours  oozie.log-2012-04-24-19.gz  _  l21_  system  sw2  setting  start-time  to  2012-04-24-19  for  log  stream  (month-1  passed  as  parameter  since  0=  january)   and  end  time  is  current  time  out  group  test  to  check  if  all  gz  log  files  in  the  range  job  start  time-current  time  are  retrieved  14-200904160239--example-forkjoinwf  oozie.log  define  parameter  set  parameter  log  statement  curr  time  close  set  oozie.log-2012-04-24-20.gz  f  2012-04-24  21:43:13 958  debug  _  l21_:323  -  calendar  /oozie.log  x  log  streamer  assert  equals  user  _  l22_  log  lines  2012-04-24  19:43:13 958  debug  _  l19_:323  -  xf  action  2012-04-24  20:43:13 958  debug  _  l20_:323  -  current  time  millis  to  string  get  instance  append  set  last  modified  app  fw1  org.apache.oozie.core.command.workflowrunnercallable       f1  streamlog  _l23_   check if the lines of the log contain the expected strings    2012-04-24 22:43:13 961 info _l23_:317 -  split  _l19_  gettestcasedir    2012-04-24 22:43:13 958 debug _l22_:323 -  str2  job  token  write   from oozie.log  setloglevel  _l20_  /   between the start and end times of the job  contains  reset   pattern and parameters like jobid  username etc. and/or based on log level like info  debug  etc.  outfilename   test for the log retrieval of the job spanning multiple hours  oozie.log-2012-04-24-21.gz  sb1  writetogzfile  debug|info  calendarentry  gettime  released lock  teststreamlogmultiplehours  oozie.log-2012-04-24-19.gz  _l21_  system  sw2   setting start-time to 2012-04-24-19 for log stream (month-1 passed as parameter since 0=january)  and end time is current time  out  group   test to check if all gz log files in the range jobstarttime-currenttime are retrieved  14-200904160239--example-forkjoinwf  oozie.log  defineparameter  setparameter  logstatement  currtime  close  set  oozie.log-2012-04-24-20.gz  f    2012-04-24 21:43:13 958 debug _l21_:323 -  calendar  /oozie.log  xlogstreamer  assertequals  user  _l22_  loglines    2012-04-24 19:43:13 958 debug _l19_:323 -  xf  action    2012-04-24 20:43:13 958 debug _l20_:323 -  currenttimemillis  tostring  getinstance  append  setlastmodified
__label__nflaky unreliable  fails  once  then  succeeds  fails  ten  times  then  succeeds  create  unreliable  impl  retry_  forever  retry  proxy  always  succeeds  test  retry  forever  unreliable  failsoncethensucceeds  failstentimesthensucceeds  create  unreliableimpl  retry_forever  retryproxy  alwayssucceeds  testretryforever
__label__flaky get  connection  context  get  name  random  port  conf  wf-app-name1  tcp://localhost:  assert  not  null  ca  id1  test  connection  drop  wf  id1  init  print  stack  trace  destroy     wf  event  listener  active  mq  conn  factory  fail  java.naming.provider.url#  stop  on  workflow  job  event  create  consumer  ;  exception  listener  should  have  removed  the  old  conn  context  jms  job  event  listener  ;connection  factory  names#  session  create  session  get  topic  random  broker  u  rl  connection  factory  jms  context  workflow  job  java.naming.factory.initial#  consumer  user1  receive  set  get  conf  e  start  get  message  services  next  int  broker  message  add  connector  services  assert  null  wfe  session  getconnectioncontext  getname  randomport  conf  wf-app-name1  tcp://localhost:  assertnotnull  caid1  testconnectiondrop  wfid1  init  printstacktrace  destroy     wfeventlistener  activemqconnfactory  fail  java.naming.provider.url#  stop  onworkflowjobevent  createconsumer  ;   exception listener should have removed the old conn context  jmsjobeventlistener  ;connectionfactorynames#  session  createsession  gettopic  random  brokerurl  connectionfactory  jmscontext  workflowjob  java.naming.factory.initial#  consumer  user1  receive  set  getconf  e  start  getmessage  services  nextint  broker  message  addconnector  services  assertnull  wfe  session
__label__nflaky is  order  size  is  use  atime  is  human  readable  check  that  default  options  are  correct  is  order  reverse  ls  assert  false  process  options  none  is  dir  recurse  is  recursive  is  path  only  assert  true  is  order  time  options  process  options  is  display  ec  policy  isordersize  isuseatime  ishumanreadable   check that default options are correct  isorderreverse  ls  assertfalse  processoptionsnone  isdirrecurse  isrecursive  ispathonly  asserttrue  isordertime  options  processoptions  isdisplayecpolicy
__label__flaky request  ;coordinators=  coord1   coord2;actionstatus=  killed  _exec  query  test  multiple  coordinators  assert  equals  get  action  get  id  there  are  3  coordinators  but  giving  range  as  only  two  of  them  br  list  coord1@2  coord2@1  size  get  bundle  name  2  actions  satisfy  the  conditions  bundle=  request  ;coordinators=coord1 coord2;actionstatus=killed  _execquery  testmultiplecoordinators  assertequals  getaction  getid   there are 3 coordinators but giving range as only two of them  brlist  coord1@2  coord2@1  size  get  bundlename   2 actions satisfy the conditions  bundle=
__label__nflaky prepare  test  coding  direct  buffer_10x4_erasing_p1  test  coding  prepare  testcodingdirectbuffer_10x4_erasing_p1  testcoding
__label__flaky is  root  get  matched  has  item  *  src/test/resources/foo.jar  matcher  assert  that  as  list  resource  matcher  found  assert  true  find  **/*.jar  src/test/resources/templates  a  jar  file  is  always  treated  as  a  dependency  (stick  it  in  /lib)  arrays  jar  file  always  matches  isroot  getmatched  hasitem  *  src/test/resources/foo.jar  matcher  assertthat  aslist  resourcematcher  found  asserttrue  find  **/*.jar  src/test/resources/templates   a jar file is always treated as a dependency (stick it in /lib)  arrays  jarfilealwaysmatches
__label__nflaky get  bytes  transferred  codec  test  utils  test  coding  fragment  buffering  channel  saturated  channel  times  assert  flush  verify  more  stuff  dump  write  argument  matchers  standard  charsets  length  assert  equals  encoder  -  any  stuff---  mockito  outbuf  metrics  spy  wrap  stuff  getbytestransferred  codectestutils  testcodingfragmentbufferingchannelsaturated  channel  times  assert  flush  verify  more stuff  dump  write  argumentmatchers  standardcharsets  length  assertequals  encoder  -  any  stuff---  mockito  outbuf  metrics  spy  wrap  stuff
__label__flaky 2009-09-11  t23:59  z  coord  el  functions  ${coord:future(4   20)}  conf  coord-action-start  todo:  set  hadoop  properties  ds  should  fail  for  negative  instance  value  eval  and  wrap  /2009/09/10  /2009/09/11  get  test  case  dir  file://  set  uri  template  create  dir  expr  /${  year}/${  month}/${  day}  init  res  coord-job-submit-instances  set  variable  assert  equals  ${coord:future(1   20)}  test  dir  test  future  fail  eval  ${coord:future(-1   3)}  2009-09-11t23:59z  coordelfunctions  ${coord:future(4  20)}  conf  coord-action-start   todo:set hadoop properties  ds  should fail for negative instance value  evalandwrap  /2009/09/10  /2009/09/11  gettestcasedir  file://  seturitemplate  createdir  expr  /${year}/${month}/${day}  init  res  coord-job-submit-instances  setvariable  assertequals  ${coord:future(1  20)}  testdir  testfuture  fail  eval  ${coord:future(-1  3)}
__label__nflaky 10.119.103.112  is  not  in  the  list  10.221.104.1  is  in  the  list  assert  false  assert  true  ips.txt  10.221.104.0  is  in  the  list  10.221.102.1  is  not  in  the  list  10.119.103.113  is  in  the  list  10.221.102.0  is  not  in  the  list  ip  list  is  in  10.221.103.255  is  not  in  the  list  test  subnets  and  i  ps  10.119.103.112  10.119.103.113  10.221.102.0/23  10.221.104.1  10.221.102.1  ips  10.221.103.1  10.221.103.255  10.221.104.0  10.221.102.0  create  file  with  entries  10.221.103.1  is  not  in  the  list  10.119.103.112 is not in the list  10.221.104.1 is in the list  assertfalse  asserttrue  ips.txt  10.221.104.0 is in the list  10.221.102.1 is not in the list  10.119.103.113 is in the list  10.221.102.0 is not in the list  iplist  isin  10.221.103.255 is not in the list  testsubnetsandips  10.119.103.112  10.119.103.113  10.221.102.0/23  10.221.104.1  10.221.102.1  ips  10.221.103.1  10.221.103.255  10.221.104.0  10.221.102.0  createfilewithentries  10.221.103.1 is not in the list
__label__flaky get  location  set  batch  unmarshaller  body  count  cell  set  delete  put  confirm  batch  size  conformance  table  new  scanner  bytes  /scanner  assert  not  null  marshal  get  client  model  marshaller  get  code  add  column  scanner  uri  get  a  cell  set  get  body  cell  set  to  bytes  assert  equals  delete  the  scanner  /  batch_  size  unmarshal  column_1  response  test  simple  scanner  xml  to  string  writer  mimetype_  xml  getlocation  setbatch  unmarshaller  body  countcellset  delete  put   confirm batch size conformance  table   new scanner  bytes  /scanner  assertnotnull  marshal  get  client  model  marshaller  getcode  addcolumn  scanneruri   get a cell set  getbody  cellset  tobytes  assertequals   delete the scanner  /  batch_size  unmarshal  column_1  response  testsimplescannerxml  tostring  writer  mimetype_xml
__label__nflaky get  stats  test  multiple  loggers  with  values  should  log  get  max  foo  assert  false  assert  equals  all  should  log  once  the  period  has  elapsed  get  current  stats  timer  bar  helper  \""bar\""/\""baz\""  should  not  log  yet  because  \""foo\""  hasn\'t  been  triggered  assert  true  record  log_  period  get  mean  baz  get  count  getstats  testmultipleloggerswithvalues  shouldlog  getmax  foo  assertfalse  assertequals   all should log once the period has elapsed  getcurrentstats  timer  bar  helper   \""bar\""/\""baz\"" should not log yet because \""foo\"" hasn\'t been triggered  asserttrue  record  log_period  getmean  baz  getcount
__label__flaky test  concurrency  limit  queue  size  x  test  case  cl  callable  concurrency  :  original  ratio  queueservice  system  get  concurrency  services  assert  true  get  reset  concurrency  callable  queue  size  :  evaluate  wait  for  cl  callable  queue  testconcurrencylimit  queuesize  xtestcase  clcallable concurrency :  originalratio  queueservice  system  getconcurrency  services  asserttrue  get  resetconcurrency  callable queue size :  evaluate  waitfor  clcallable  queue
__label__nflaky init  test  get  parameter  servlet  context  init  the  context  then  return  default  value  this  will  not  work  and  return  null  assert  equals  http  servlet  request  when  and  return  the  parameter  map  when  any  parameter  is  called...  context  key_not_there  this  will  work  as  the  value  is  there...  http  servlet  response  value  this  will  return  the  default  value:  key  get  parameter  init  testgetparameter  servletcontext   init the context  thenreturn  defaultvalue   this will not work and return null  assertequals  httpservletrequest  when   and return the parameter map when any parameter is called...  context  key_not_there   this will work as the value is there...  httpservletresponse  value   this will return the default value:  key  getparameter
__label__flaky as  requested   one  exception!  just  throw  an  exception  fut  e  create  stage  get  message  handle  assert  equals  get  cause  checking  the  exception  0  ref  todo:  check  this.  ex  assert  true  i  actor  join  is  completed  exceptionally  get  reference  stage1  as requested  one exception!  justthrowanexception  fut  e  createstage  getmessage  handle  assertequals  getcause  checkingtheexception  0  ref   todo: check this.  ex  asserttrue  iactor  join  iscompletedexceptionally  getreference  stage1
__label__nflaky .gz  test2  with  compression_  file  blank_  no  restart_2  no_  restart  default  test  file_  option_  blank  .gz  test2  withcompression_fileblank_norestart_2  no_restart  defaulttest  file_option_blank
__label__flaky cluster  normal  write  get  class  get  name  get  filenum  get  log  need  hdfs-826  for  this  test  h  constants  conf  invoke  dnprop  write  data  old  filenum  wait  active  table  name  get  region  server  get  default  replication  when  the  meta  table  can  be  opened   the  region  servers  are  running  need  append  support  for  this  test  write  some  more  log  data  (this  should  use  a  new  hdfs_out)  start  data  nodes  get  data  nodes  stm  test  log  roll  on  datanode  death  set  auto  flush  cur  time  size  get  pipeline  add  family  the  log  shouldn\'t  have  rolled  yet  new  filenum  add  up  the  datanode  count   to  ensure  proper  replication  when  we  kill  1  ends  with  desc  server  create  table  log  dfs  cluster  this  test  requires  h  log  file  replication.  admin  missing  datanode  should\'ve  triggered  a  log  roll  fs  system  get  declared  methods  this  write  should  succeed   but  trigger  a  log  roll  assert  true  can  get  cur  replicas  log  should  have  a  timestamp  older  than  now  get  log  replication  repl  table  stop  data  node  don\'t  run  this  test  without  append  support  (  hdfs-200  &  hdfs-142)  set  accessible  the  log  should  not  roll  again.  kill  a  datanode  in  the  pipeline  to  force  a  log  roll  on  the  next  sync()  m  pipeline  create  the  test  table  and  open  it  is  append  current  time  millis  need  dfs  output  stream.get  pipeline()  for  this  test  get  output  stream  new  log  file  should  have  the  default  replication  h  log  cluster   normal write  getclass  getname  getfilenum  getlog  need hdfs-826 for this test  hconstants  conf  invoke  dnprop  writedata  oldfilenum  waitactive  tablename  getregionserver  getdefaultreplication   when the meta table can be opened  the region servers are running  need append support for this test   write some more log data (this should use a new hdfs_out)  startdatanodes  getdatanodes  stm  testlogrollondatanodedeath  setautoflush  curtime  size  getpipeline  addfamily  the log shouldn\'t have rolled yet  newfilenum   add up the datanode count  to ensure proper replication when we kill 1  endswith  desc  server  createtable  log  dfscluster  this test requires hlog file replication.  admin  missing datanode should\'ve triggered a log roll  fs  system  getdeclaredmethods   this write should succeed  but trigger a log roll  asserttrue  cangetcurreplicas  log should have a timestamp older than now  getlogreplication  repl  table  stopdatanode   don\'t run this test without append support (hdfs-200 & hdfs-142)  setaccessible  the log should not roll again.   kill a datanode in the pipeline to force a log roll on the next sync()  m  pipeline   create the test table and open it  isappend  currenttimemillis  need dfsoutputstream.getpipeline() for this test  getoutputstream  new log file should have the default replication  hlog
__label__nflaky int  param  should  be  parsed  to  integer  then  return  context  create  verify  invoke  when  20  param1  mock  controller  int  param  get  parameter  intparamshouldbeparsedtointeger  thenreturn  context  create  verify  invoke  when  20  param1  mockcontroller  intparam  getparameter
__label__flaky handler  get  uri  handler  dt=05  test  exists  assert  false  uri  service  add  partition  conf  year=2012;month=12;dt=02;country=us  assert  true  dt=02  hcat  uri  table  country=us;month=12  country=us  drop  test  table  year=2012;month=12  create  test  table  country=us;year=2012;month=12;dt=02  get  test  user  exists  db  get  h  cat  uri  year=2012;month=12;dt=03;country=us  month=02;dt=02  handler  geturihandler  dt=05  testexists  assertfalse  uriservice  addpartition  conf  year=2012;month=12;dt=02;country=us  asserttrue  dt=02  hcaturi  table  country=us;month=12  country=us  droptesttable  year=2012;month=12  createtesttable  country=us;year=2012;month=12;dt=02  gettestuser  exists  db  gethcaturi  year=2012;month=12;dt=03;country=us  month=02;dt=02
__label__nflaky renderable  assets  controller  helper  assets  controller  when  result  captor  mime  types  get  renderable  response  streams  verify  ok  render  result2  serve  static  finalize  headers  without  flash  and  session  cookie  byte  array  output  stream  then  return  capture  test  static  directory  class  path  when  file  not  in  file  system  in  dev  mode  assert  equals  normalize  path  without  leading  slash  context  renderable  any  /assets/testasset.txt  http  cache  toolkit  get  value  get  status  code  mockito  results  is  dev  mock  get  output  stream  ninja  properties  some  more  setup  needed:  get  request  path  renderable  assetscontrollerhelper  assetscontroller  when  resultcaptor  mimetypes  getrenderable  responsestreams  verify  ok  render  result2  servestatic  finalizeheaderswithoutflashandsessioncookie  bytearrayoutputstream  thenreturn  capture  teststaticdirectoryclasspathwhenfilenotinfilesystemindevmode  assertequals  normalizepathwithoutleadingslash  contextrenderable  any  /assets/testasset.txt  httpcachetoolkit  getvalue  getstatuscode  mockito  results  isdev  mock  getoutputstream  ninjaproperties   some more setup needed:  getrequestpath
__label__flaky cluster  file  name  datanode  get  rbw  dir  conf  get  self  addr  create  file  wait  active  get  the  block  belonged  to  the  created  file  write  block  block  storage  dir  clean  up  the  file  write  byte  start  data  nodes  get  data  nodes  get  block  pool  id  the  temporary  block  &  meta  files  should  be  deleted  get  name  node  close  the  connection  before  sending  the  content  of  the  block  get  instance  storage  dir  write  the  header.  bring  up  a  second  datanode  then  increase  the  file\'s  replication  factor  get  block  locations  name  node  adapter  snd  node  replicate  the  block  to  the  second  datanode  bpid  fs  wait  replication  delete  out  sleep  flush  get  get  address  close  list  files  should  only  find  1  block  block  token  secret  manager  write  int  dfs  test  util  get  block  replication  should  succeed  mini  dfs  cluster  blocks  /test.txt  assert  equals  dir2  dir1  set  replication  write  check  header  target  thread  file  len  get  port  create  a  file  of  replication  factor  of  1  to  string  get  output  stream  block  construction  stage  located  block  count  get  namesystem  test  replication  error    cluster  filename  datanode  getrbwdir  conf  getselfaddr  createfile  waitactive   get the block belonged to the created file  writeblock  block  storagedir   clean up the file  writebyte  startdatanodes  getdatanodes  getblockpoolid   the temporary block & meta files should be deleted  getnamenode   close the connection before sending the content of the block  getinstancestoragedir   write the header.   bring up a second datanode   then increase the file\'s replication factor  getblocklocations  namenodeadapter  sndnode   replicate the block to the second datanode  bpid  fs  waitreplication  delete  out  sleep  flush  get  getaddress  close  listfiles  should only find 1 block  blocktokensecretmanager  writeint  dfstestutil  getblock   replication should succeed  minidfscluster  blocks  /test.txt  assertequals  dir2  dir1  setreplication   write check header  target  thread  filelen  getport   create a file of replication factor of 1  tostring  getoutputstream  blockconstructionstage  locatedblockcount  getnamesystem  testreplicationerror
__label__nflaky test  chunk  no  exceed  codec  test  utils  standard  charsets  channel  assert  equals  encoder  assert  flush  4  1234  0  outbuf  1234  assert  true  metrics  dump  complete  wrap  write  is  completed  testchunknoexceed  codectestutils  standardcharsets  channel  assertequals  encoder  assert  flush  4  1234  0      outbuf  1234  asserttrue  metrics  dump  complete  wrap  write  iscompleted
__label__flaky exec  path  test  wf  action  get  with  exec  path  add  record  to  wf  action  table  get  id  workflow  instance  _test  get  action  with  exec  path  1  add  record  to  wf  job  table  workflow  action  /fork  action  to  string  workflow  job  job  append    execpath  testwfactiongetwithexecpath  addrecordtowfactiontable  getid  workflowinstance  _testgetactionwithexecpath  1  addrecordtowfjobtable  workflowaction  /fork  action  tostring  workflowjob  job  append
__label__nflaky symbol  10.00\%  1230  k  -8  e  0.5430\%  100m  891g  n=  0.54\%  1\%  0.5\%  invalid  prefix  3  g  invalid  size  prefix  \'  1.50  m  1  k  1.50  k  .0  byte  desc  does  not  fit  in  a  long  -1  e  10kb  test  passed  for  a  number  10e  0.543\%  456t  test  long2string(..)  .00  expected  1.5  k  1.50  mb  zeros  too  large  -8.00  e  decimal  place  0  -891  g  1  kb  10p  fail  too  small  num  str  test  string2long(..)  8.00  e  -100  m  long  n  =  2^e  +  1  n  =  2^e  -  1  traditional  binary  prefix  test  traditional  binary  prefix  string2long  format  percent  \'  in  \'  too  large  num  str  -1k  values  -10e  -10  p  too  small  0  b  test  byte  desc(..)  -1230  k  1e  -100  b  string  utils  1k  -1  k  test  format  percent(..)  n  =  2^e  -456  t  trailing  zeros  2  m  long2  string  e  10\%  g  \'.  allowed  prefixes  are  k   m   g   t   p   e(case  insensitive)  get  message  invalid  format  num  str  assert  equals  k  m  10.0\%  n  1.50  kb  p  t  has  invalid  format  3  gb    symbol  10.00\%  1230k  -8 e  0.5430\%  100m  891g  n=  0.54\%  1\%  0.5\%  invalidprefix  3 g  invalid size prefix \'  1.50 m  1 k  1.50 k  .0   bytedesc   does not fit in a long     -1e  10kb  test passed for a number   10e  0.543\%  456t   test long2string(..)  .00   expected  1.5 k  1.50 mb  zeros   too large  -8.00 e  decimalplace  0  -891g  1 kb  10p  fail  toosmallnumstr   test string2long(..)  8.00 e  -100m  long   n = 2^e + 1   n = 2^e - 1  traditionalbinaryprefix  testtraditionalbinaryprefix  string2long  formatpercent  \' in \'  toolargenumstr  -1k  values  -10e  -10p   too small  0 b   test bytedesc(..)  -1230k  1e  -100 b  stringutils  1k  -1 k   test formatpercent(..)   n = 2^e  -456t  trailingzeros  2 m  long2string  e  10\%  g  \'. allowed prefixes are k  m  g  t  p  e(case insensitive)  getmessage  invalidformatnumstr  assertequals  k  m  10.0\%  n  1.50 kb  p  t   has invalid format  3 gb
__label__flaky get  time  start  run  get  id  assert  equals  get  status  execute  add  record  to  coord  job  table  coord  get  cmd  coord  job  sleep  coordinator  job  services  runnable  test  coord  materialize  trigger  service2  get  end  job  jpa  service  gettime  start  run  getid  assertequals  getstatus  execute  addrecordtocoordjobtable  coordgetcmd  coordjob  sleep  coordinatorjob  services  runnable  testcoordmaterializetriggerservice2  get  end  job  jpaservice
__label__nflaky x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  test  encode1  x  x  x  x  x  x  x  x  x  x  x  x  x  this  is  an  example  aztec  symbol  for  wikipedia.  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  test  encode  real  life  tests    x   x       x x x x x x x x x x x x   x x           x   x   x x x   x   x   x x x x     x             x x x x x x   x x x x x   x x x x x x   x         x x x   x   x     x x x x         x x           x x   x   x x               x x x   x x x x       x x   x       x x x   x x x       x x           x   x     x x x               x x x x   x x               x               x                 x         x   x   x x       x   x         x x x     x     x       x   x x x x x x x x x x x     x   x x     x       x     x   x   x   x   x   x x   x         x x   x x x x x   x x x                 x               x   x x x   x       x   x     x x x         x     x x       x     x x     x     x             x         x     x x     x   x x   x x       x     x   x         x   x       x   x x x x       x             x x     x   x x   x   x   x       x x       x               x   x x     x     x x x         testencode1    x x x   x x x x   x     x   x     x x   x       this is an example aztec symbol for wikipedia.          x x x x x     x x x x   x   x     x       x     x x   x x   x x x x x   x x   x   x x x       x   x x x   x x   x   x x x x   x   x x x x     x x                 x x   x       x x x x x x     testencode   real life tests
__label__flaky cluster  conf  create  file  simulated  storage  wait  active  locations  =  error  blocks  were  not  cleaned  up  get  file  status  get  namenode  buffer  write  info  localhost  \""  datanode  report  verify  that  file  exists  in  fs  namespace  get  file  system  stm  set  int  shutdown  data  nodes  path  :  \""  wait  for  the  datanode  to  be  declared  dead  bad  block  allocations  were  cleaned  up  earlier.  long  dfs_  heartbeat_  interval_  key  get  name  node  port  simulated  fs  dataset  shutdown  /filestatus.dat  get  block  locations  hdfs  constants  seed  this  should  fail  because  all  datanodes  are  dead.  create  cluster  to  die.  fs  system  test  file  creation  error1:  waiting  for  datanode  sleep  assert  true  client  addr  close  dfs_  namenode_  heartbeat_  recheck_  interval_  key  random  bytes  is  file  encountered  expected  exception  kill  the  datanode  append  test  util  thread  build  should  be  a  file  to  string  locations  file1  set  boolean  located  block  count  test  file  creation  error1  cluster  conf  createfile  simulatedstorage  waitactive  locations =   error blocks were not cleaned up  getfilestatus  getnamenode  buffer  write  info  localhost     \""  datanodereport   verify that file exists in fs namespace  getfilesystem  stm  setint  shutdowndatanodes  path : \""   wait for the datanode to be declared dead   bad block allocations were cleaned up earlier.  long  dfs_heartbeat_interval_key  getnamenodeport  simulatedfsdataset  shutdown  /filestatus.dat  getblocklocations  hdfsconstants  seed   this should fail because all datanodes are dead.   create cluster   to die.  fs  system  testfilecreationerror1: waiting for datanode   sleep  asserttrue  client  addr  close  dfs_namenode_heartbeat_recheck_interval_key  randombytes  isfile  encountered expected exception   kill the datanode  appendtestutil  thread  build   should be a file  tostring  locations  file1  setboolean  locatedblockcount  testfilecreationerror1
__label__nflaky file  utils  is  prod  ninja  constant  uuid  default  configuration  set  file  name  assert  true  src/main/java/conf/application.conf  random  uuid  uuid  base  dir  without  trailing  slash  files  /tmp/ninja-test-  test  missing  secret  creates  new  one  in  dev  mode  length  get  string  check  that  application  secret  is  set  composite  configuration  contains  ninja  properties  impl  tool  to  string  file  delete  directory  dev  conf  charsets  tear  down  fileutils  isprod  ninjaconstant  uuid  defaultconfiguration  setfilename  asserttrue  src/main/java/conf/application.conf  randomuuid  uuid  basedirwithouttrailingslash  files  /tmp/ninja-test-  testmissingsecretcreatesnewoneindevmode  length  getstring  checkthatapplicationsecretisset  compositeconfiguration  contains  ninjapropertiesimpltool  tostring  file  deletedirectory  devconf  charsets   tear down
__label__flaky given  .installed  resolve  alpha.jar  will  return  assert  that  as  list  bravo  charlie.jar  get  names  of  files  in  lib  bravo.jar  install  alpha  create  temporary  file  contains  in  any  order  arrays  charlie  uninstall  all  given  .installed  resolve  alpha.jar  willreturn  assertthat  aslist  bravo  charlie.jar  getnamesoffilesinlib  bravo.jar  install  alpha  createtemporaryfile  containsinanyorder  arrays  charlie  uninstallall
__label__nflaky removed  header  check  headers  copy  remove  a  header  to  force  an  error  remove  put  status  assert  headers  run  tests  return  different  headers  than  expected.  get  to  array  add  test  deepcopy  key  set  web  server  testing  framework  exception  should  have  been  thrown  header  name  adapter  unchecked  assert  equals  response  expectations  execute  fail  testing  framework  framework  response  new  framework  and  set  adapter  body  removedheadercheck  headerscopy   remove a header to force an error  remove  put  status  assert  headers  runtests   return different headers than expected.  get  toarray  addtest  deepcopy  keyset  webservertestingframeworkexception should have been thrown  headername  adapter  unchecked  assertequals  responseexpectations  execute  fail  testingframework  framework  response  newframeworkandsetadapter  body
__label__flaky hdfs://p1/p2/2009/08/09/23/59/  coord  el  functions  assert  equals  hdfs://p1/p2/${  year}/${  month}/${  day}/${  minute}/  hdfs://p1/p2/2009/08/09/59/  system.out.println(\""  output  \""+  eval.evaluate(expr   string.class));  eval  hdfs://p1/p2/${  year}/${  month}/${  day}/${  hour}/${  minute}/  eval  and  wrap  2009-08-09  t23:59  z  expr  test  create  uriel  evaluator  create  uriel  evaluator  coord  el  evaluator  hdfs://p1/p2/2009/08/09/23/59/  coordelfunctions  assertequals  hdfs://p1/p2/${year}/${month}/${day}/${minute}/  hdfs://p1/p2/2009/08/09/59/   system.out.println(\""output \""+ eval.evaluate(expr  string.class));  eval  hdfs://p1/p2/${year}/${month}/${day}/${hour}/${minute}/  evalandwrap  2009-08-09t23:59z  expr  testcreateurielevaluator  createurielevaluator  coordelevaluator
__label__nflaky xxxxtestxxxx  test  full  region  set  regex  test  testxxxx  assert  true  start  .*test.*  matcher  matches  xxxxtest  xxxxtestxxxx  testfullregion  setregex  test  testxxxx  asserttrue  start  .*test.*  matcher  matches  xxxxtest
__label__flaky wf  job  b  add  record  to  wf  action  table  get  id  coord  action  b  workflow  instance  add  record  to  coord  action  table  add  record  to  wf  job  table  children  assert  not  null  get  coordinator  action  workflow  job  coord  job  b  coord  job  a  wf  job  a1  wf  job  a2  execute  add  record  to  coord  job  table  test  get  coordinator  parent  check  children  services  coordinator  job  1  coord  action  a2  coord-action-get.xml  workflow  action  coord  action  a1  add  all  succeeded  jpa  service  wf  action  a2  wf  action  b  wf  action  a1  wfjobb  addrecordtowfactiontable  getid  coordactionb  workflowinstance  addrecordtocoordactiontable  addrecordtowfjobtable  children  assertnotnull  get  coordinatoraction  workflowjob  coordjobb  coordjoba  wfjoba1  wfjoba2  execute  addrecordtocoordjobtable  testgetcoordinatorparent  checkchildren  services  coordinatorjob  1  coordactiona2  coord-action-get.xml  workflowaction  coordactiona1  addall  succeeded  jpaservice  wfactiona2  wfactionb  wfactiona1
__label__nflaky cluster  (i.e.  the  rpc  itself  should  not  take  3  seconds!)  ms  wait  for  elector  state  conf  time  cede  active  test  cede  active  get  local  target  since  the  other  node  in  the  cluster  would  have  taken  active.  assert  true  zkfc  now  active  standby  elector  rpc  to  cede  active  took  st  get  zkfc  proxy  et2  start  assert  equals  get  zkfc  get  elector  for  tests  et  should  take  ~3  seconds  to  rejoin.  only  took  proxy  get  state  for  tests  it  should  be  in  active  to  start.  at  this  point.  ms  before  rejoining.  cluster   (i.e. the rpc itself should not take 3 seconds!)   ms  waitforelectorstate  conf  time  cedeactive  testcedeactive  getlocaltarget   since the other node in the cluster would have taken active.  asserttrue  zkfc  now  activestandbyelector  rpc to cedeactive took   st  getzkfcproxy  et2  start  assertequals  getzkfc  getelectorfortests  et  should take ~3 seconds to rejoin. only took   proxy  getstatefortests   it should be in active to start.   at this point.  ms before rejoining.
__label__flaky end  key1  get  region  manager  meta  table  desc  end  key0  get  table  descriptor  get  start  key  master.region  manager.online  meta  regions  already  contains  first  .  meta.  region  at  key  bytes.to  bytes(\""\"")  h  constants  start  key  x  get  region  name  test  get  first  meta  region  for  region  after  meta  split  table  desc  meta  region  info2  bytes  meta  region  info1  meta  region  info0  offline  meta  region  with  start  key  region  info0  region  info1  }  put  meta  region  online  region  info  x  start  key0  meta2  get  first  meta  region  for  region  address  meta1  1st  .  meta.  region  will  be  something  like  .  meta.  1253625700761  meta0  start  key1  f  to  bytes  h  j  assert  equals  2nd  .  meta.  region  will  be  something  like  .  meta. _  my_  table_ f 1253625700761 1253625700761  3rd  .  meta.  region  will  be  something  like  .  meta. _  my_  table_ j 1253625700761 1253625700761  m  get  master  address  master  meta  end  key  x  get  master  _  my_  table_    endkey1  getregionmanager  metatabledesc  endkey0  gettabledescriptor  getstartkey   master.regionmanager.onlinemetaregions already contains first .meta. region at key bytes.tobytes(\""\"")  hconstants  startkeyx  getregionname  testgetfirstmetaregionforregionaftermetasplit  tabledesc  metaregioninfo2  bytes  metaregioninfo1  metaregioninfo0  offlinemetaregionwithstartkey  regioninfo0  regioninfo1   }  putmetaregiononline  regioninfox  startkey0  meta2  getfirstmetaregionforregion  address  meta1   1st .meta. region will be something like .meta.  1253625700761  meta0  startkey1  f  tobytes  h  j  assertequals   2nd .meta. region will be something like .meta. _my_table_ f 1253625700761 1253625700761   3rd .meta. region will be something like .meta. _my_table_ j 1253625700761 1253625700761  m  getmasteraddress  master  meta  endkeyx  getmaster  _my_table_
__label__nflaky server  get  current  user  rpc  get  proxy  superuser  group  conf  key  group_  names  default  impersonation  provider  get  user  new  empty  request  conf  run  ret  val  assert  set  strings  test  real  user  ip  not  specified  real_  user_  short_  name  refresh  conf  client  set  protocol  engine  addr  set  configuration  user  group  information  proxy  user  ugi  print  stack  trace  e  get  client  create  remote  user  group1  real_  user_  name  fail  do  as  get  test  provider  stop  setup  test  server  proxy_  user_  name  the  rpc  must  have  failed  real  user  ugi  create  proxy  user  for  testing  server  getcurrentuser  rpc  getproxysuperusergroupconfkey  group_names  defaultimpersonationprovider  getuser  newemptyrequest  conf  run  retval  assert  setstrings  testrealuseripnotspecified  real_user_short_name  refreshconf  client  setprotocolengine  addr  setconfiguration  usergroupinformation  proxyuserugi  printstacktrace  e  getclient  createremoteuser  group1  real_user_name  fail  doas  gettestprovider  stop  setuptestserver  proxy_user_name  the rpc must have failed   realuserugi  createproxyuserfortesting
__label__flaky kills  add  node  def  enters  one  start  test  synch  double  assert  equals  workflow  instance  get  status  two  as  list  wf  1  exits  size  <worklfow-app/>  end  arrays  job  fails  kills  addnode  def  enters  one  start  testsynchdouble  assertequals  workflowinstance  getstatus  two  aslist  wf  1  exits  size  <worklfow-app/>  end  arrays  job  fails
__label__nflaky 40  12345678901234561234567890123456  dst  compact  codec  test  utils  channel  10  1234567890123456  convert  put  assert  inbuf  assert  true  tmp  flip  is  completed  read  test  reading  wit  small  buffer  1234567890123456  standard  charsets  has  remaining  bytes  read  assert  equals  decoder  byte  buffer  12345678901234561234567890123456  allocate  metrics  12345678901234561234567890123456  0  40  12345678901234561234567890123456  dst  compact  codectestutils  channel  10  1234567890123456    convert  put  assert  inbuf  asserttrue  tmp  flip  iscompleted  read  testreadingwitsmallbuffer  1234567890123456  standardcharsets  hasremaining  bytesread  assertequals  decoder  bytebuffer  12345678901234561234567890123456  allocate  metrics  12345678901234561234567890123456  0
__label__flaky call  process  task  e  should  be  thread  safe  wro  test  utils  run  concurrently  processor  $side:  top;$radius:  10px;.rounded-#{$side}  {border-#{$side}-radius:  $radius;}  call  process  task  e  shouldbethreadsafe  wrotestutils  runconcurrently  processor  $side: top;$radius: 10px;.rounded-#{$side} {border-#{$side}-radius: $radius;}
__label__nflaky request  common  configuration  keys  acls  test  requires  authorization  access  then  return  assert  false  conf  when  any  requires  admin  access  to  instrumentation   true  get  attribute  assert  mockito  assert  true  response  is  user  allowed  context  mock  requires  admin  access  to  instrumentation   false  by  default  http  server2  is  instrumentation  access  allowed  set  boolean  request  commonconfigurationkeys  acls  testrequiresauthorizationaccess  thenreturn  assertfalse  conf  when  any   requires admin access to instrumentation  true  getattribute  assert  mockito  asserttrue  response  isuserallowed  context  mock   requires admin access to instrumentation  false by default  httpserver2  isinstrumentationaccessallowed  setboolean
__label__flaky ./test-workflow-app.xml  end_  points  invalid  content  is_  security_  enabled  valid  file  name  run  invalidfile  test  validate  work  flow  command  delete  <start  to=\""end\""/>  <end  name=\""end\""/>  </workflow-app>  <workflow-app  xmlns=\""uri:oozie:workflow:0.2\""  name=\""f\"">  servlet_  classes  run  test  validate  valid  content  validfile  invalid  file  name  assert  equals  args  call  io  utils  copy  char  stream  <workflow-app  xmlns=\""uri:oozie:workflow:0.2\""  name=\""no-op-wf\"">  ./test-invalid-workflow-app.xml  <tag=\""end\""/>  <tag=\""end\""/>  </workflow-app>  ./test-workflow-app.xml  end_points  invalidcontent  is_security_enabled  validfilename  run  invalidfile  testvalidateworkflowcommand  delete   <start to=\""end\""/> <end name=\""end\""/> </workflow-app>  <workflow-app xmlns=\""uri:oozie:workflow:0.2\"" name=\""f\"">   servlet_classes  runtest  validate  validcontent  validfile  invalidfilename  assertequals  args  call  ioutils  copycharstream  <workflow-app xmlns=\""uri:oozie:workflow:0.2\"" name=\""no-op-wf\"">   ./test-invalid-workflow-app.xml   <tag=\""end\""/> <tag=\""end\""/> </workflow-app>
__label__nflaky my  file  file  name  get  name  create  a  file  with  a  new  name  list  status  conf  run  emptier  thread  file  system  should\'ve  been  deleted  and  current  might  not  have  been  recreated  yet  get  path  interrupt  join  emptier  mkdir  test_  dir  val  add  init  fs_  trash_  interval_  key  -rm  delete  the  file  to  trash  trash  dir  trash  test/mkdirs/my  file  fs_  trash_  checkpoint_  interval_  key  size  12  seconds  shell  first  create  a  new  directory  with  mkdirs  start  emptier  in  background  fs.default.name  files  scan  files  in  .  trash  and  add  them  to  set  of  checkpoints  get  uri  my  path  test  trash  emptier  6  seconds  get  localized  message  fs  system  sleep  file  assert  true  get  current  trash  dir  if  checkpoints  has  4  objects  it  is  current  +  3  checkpoint  directories  write  file  get  parent  set  file  index  e  set  class  start  checkpoints  set  conf  thread  args  0.1  0.2  exception  raised  from  trash.run  get  local  get  emptier  test/mkdirs  to  string  fs.file.impl  myfile  filename  getname   create a file with a new name  liststatus  conf  run  emptierthread  filesystem   should\'ve been deleted and current might not have been recreated yet  getpath  interrupt  join  emptier  mkdir  test_dir  val  add  init  fs_trash_interval_key  -rm   delete the file to trash  trashdir  trash  test/mkdirs/myfile  fs_trash_checkpoint_interval_key  size   12 seconds  shell   first create a new directory with mkdirs   start emptier in background  fs.default.name  files   scan files in .trash and add them to set of checkpoints  geturi  mypath  testtrashemptier   6 seconds  getlocalizedmessage  fs  system  sleep  file  asserttrue  getcurrenttrashdir   if checkpoints has 4 objects it is current + 3 checkpoint directories  writefile  getparent  set  fileindex  e  setclass  start  checkpoints  setconf  thread  args  0.1  0.2  exception raised from trash.run   getlocal  getemptier  test/mkdirs  tostring  fs.file.impl
__label__flaky get  name  oozie.service.  proxy  user  service.proxyuser.foo.groups  foo  conf  as  list  bar  assert  string  utils  assert  not  null  get  join  validate  localhost  init  set  oozie.service.  proxy  user  service.proxyuser.foo.hosts  get  conf  destroy  test  validate  any  host  any  user  *  services     services  proxy  user  arrays  getname  oozie.service.proxyuserservice.proxyuser.foo.groups  foo  conf  aslist  bar  assert  stringutils  assertnotnull  get  join  validate  localhost  init  set  oozie.service.proxyuserservice.proxyuser.foo.hosts  getconf  destroy  testvalidateanyhostanyuser  *  services     services  proxyuser  arrays
__label__nflaky get  request  count  common  configuration  keys  clear  black  list  groups  refresh  conf  fake  group  mapping  assert  equals  disable  negative  cache.  as  list  cache  groups  add  set  long  second  count  hits  cache  my  groups  size  assert  true  first  call  hits  the  wire  test  cache  prevents  impl  request  me  arrays  get  groups  getrequestcount  commonconfigurationkeys  clearblacklist  groups  refresh  conf  fakegroupmapping  assertequals   disable negative cache.  aslist  cachegroupsadd  setlong   second count hits cache  mygroups  size  asserttrue   first call hits the wire  testcachepreventsimplrequest  me  arrays  getgroups
__label__flaky play  server  request  cookie:  $  version=\""1\"";  set  domain  android  accept_  original_  server  a=\""android\"";$  path=\""/\"";$  domain=\""  received  headers  get  cookie  a  cookie  manager  get  cookie  store  cookie  b  add  banana  a  b  \""  get  headers  take  request  to  uri  \"";  set  path  set  default  assert  contains  test  sending  cookies  from  store  /  enqueue  get  url  get  cookie  domain  b=\""banana\"";$  path=\""/\"";$  domain=\""  cookie  handler  play  server  request  cookie: $version=\""1\"";   setdomain  android  accept_original_server  a=\""android\"";$path=\""/\"";$domain=\""  receivedheaders  get  cookiea  cookiemanager  getcookiestore  cookieb  add  banana  a  b  \""  getheaders  takerequest  touri  \"";   setpath  setdefault  assertcontains  testsendingcookiesfromstore  /  enqueue  geturl  getcookiedomain  b=\""banana\"";$path=\""/\"";$domain=\""  cookiehandler
__label__nflaky set  name  test  detach  appender  by  name  add  appender  tab  test  assert  true  assert  false  start  aai  detach  appender  ta  test1  setname  testdetachappenderbyname  addappender  tab  test  asserttrue  assertfalse  start  aai  detachappender  ta  test1
__label__flaky play  a  server  clear  headers  assert  code  request2  request1  conditional  cache  hit  set  ok  response  cache  get  header  assert  body  http  url  connection  await  client  add  header  cache  receiver  take  request  assert  equals  set  body  set  response  code  url  /  if-  none-  match  enqueue  get  url  assert  null  build  v1  e  tag:  v1  play  a  server  clearheaders  assertcode  request2  request1  conditionalcachehit  setokresponsecache  getheader  assertbody  httpurlconnection  await  client  addheader  cache  receiver  takerequest  assertequals  setbody  setresponsecode  url  /  if-none-match  enqueue  geturl  assertnull  build  v1  etag: v1
__label__nflaky get  boolean  with  default  test  optional  then  return  ninja  constant  invoke  when  param1  empty  boolean  param  with  optional  context  create  verify  boolean  param  with  optional  should  handle  wrong  input  for  boolean  in  strict  mode  ninja  properties  mock  controller  get  parameter  getbooleanwithdefault  test  optional  thenreturn  ninjaconstant  invoke  when  param1  empty  booleanparamwithoptional  context  create  verify  booleanparamwithoptionalshouldhandlewronginputforbooleaninstrictmode  ninjaproperties  mockcontroller  getparameter
__label__flaky get  name  oozie.service.  proxy  user  service.proxyuser.foo.groups  foo  user.name  conf  test  validate  group  as  list  system  assert  string  utils  assert  not  null  get  join  validate  localhost  init  set  oozie.service.  proxy  user  service.proxyuser.foo.hosts  get  property  get  conf  destroy  *  services     services  get  group  proxy  user  arrays  getname  oozie.service.proxyuserservice.proxyuser.foo.groups  foo  user.name  conf  testvalidategroup  aslist  system  assert  stringutils  assertnotnull  get  join  validate  localhost  init  set  oozie.service.proxyuserservice.proxyuser.foo.hosts  getproperty  getconf  destroy  *  services     services  getgroup  proxyuser  arrays
__label__nflaky setting  total  failover  attempts  to  .  p1  test  client  retries  idempotent  op  with  io  exception  succeeds  second  time  p2  p3  get  current  key  get  kms  url  conf  when  result  times  verify  then  throw  test  kp  any  string  then  return  get  providers  key  name  assert  equals  eq  set  int  common  configuration  keys  public  key  version  mockito  mock  v1   setting total failover attempts to .  p1  testclientretriesidempotentopwithioexceptionsucceedssecondtime  p2  p3  getcurrentkey  getkmsurl  conf  when  result  times  verify  thenthrow  test  kp  anystring  thenreturn  getproviders  keyname  assertequals  eq  setint  commonconfigurationkeyspublic  keyversion  mockito  mock  v1
__label__flaky _test  wf  info  with  action  subset  get  add  record  to  wf  action  table  get  id  workflow  instance  system  1  2  add  record  to  wf  job  table  workflow  action  workflow  job  job  test  wf  info  with  action  subset  get  successful  test  wf  info  with  action  subset  get  _testwfinfowithactionsubsetget  addrecordtowfactiontable  getid  workflowinstance  system  1  2  addrecordtowfjobtable  workflowaction  workflowjob  job  testwfinfowithactionsubsetget successful  testwfinfowithactionsubsetget
__label__nflaky codec  test  utils  channel  empty  assert  flush  assert  true  678  90  test  coding  empty  buffer  dump  write  flip  is  completed  standard  charsets  assert  equals  encoder  byte  buffer  5  12345  3  678  2  90  0  allocate  outbuf  12345  metrics  complete  wrap  codectestutils  channel  empty  assert  flush  asserttrue  678  90  testcodingemptybuffer  dump  write  flip  iscompleted  standardcharsets  assertequals  encoder  bytebuffer  5  12345  3  678  2  90  0      allocate  outbuf  12345  metrics  complete  wrap
__label__flaky test  single  cell  get  put  xml  row_1  assert  equals  table  get  value  xml  check  value  xml  delete  row  column_1  response  value_1  put  value  xml  get  code  value_2  testsinglecellgetputxml  row_1  assertequals  table  getvaluexml  checkvaluexml  deleterow  column_1  response  value_1  putvaluexml  getcode  value_2
__label__nflaky request  get  name  token  signed  token_  validity_  sec  set  expires  sign  secret  when  as  list  get  init  parameter  names  system  secret  provider  props  get  cookies  dummy  authentication  handler  secret  provider  management.operation.return  verify  unauthorized  signer  authenticated  url  http://foo:8080/bar  get  request  url  init  chain  cookie  authentication  filter  then  return  test  do  filter  authenticated  expired  string  signer  secret  provider  creator  www-  authenticate  destroy  token  filter  p  get  mocked  servlet  context  with  string  signer  get  init  parameter  new  string  signer  secret  provider  mockito  u  response  elements  current  time  millis  set  property  true  mock  to  string  contains  header  arrays  config  request  getname  tokensigned  token_validity_sec  setexpires  sign  secret  when  aslist  getinitparameternames  system  secretproviderprops  getcookies  dummyauthenticationhandler  secretprovider  management.operation.return  verifyunauthorized  signer  authenticatedurl  http://foo:8080/bar  getrequesturl  init  chain  cookie  authenticationfilter  thenreturn  testdofilterauthenticatedexpired  stringsignersecretprovidercreator  www-authenticate  destroy  token  filter  p  getmockedservletcontextwithstringsigner  getinitparameter  newstringsignersecretprovider  mockito  u  response  elements  currenttimemillis  setproperty  true  mock  tostring  containsheader  arrays  config
__label__flaky conn  /v1/jobs  id-valid  put  assert  not  null  name=x  open  connection  test  jobs  params  get  input  stream  json  value  pst  get  header  field  2  size  get  ends  with  reset  set  request  method  is_  security_  enabled  wf  external-valid  assert  true  array  get  json  content-type  start  time  run  test  pdt  json  tags  rest  constants  mock  dag  engine  service  http  servlet  response  assert  equals  parse  url  call  100  pdt  if  on  daylight  saving  time  assert  null  obj  get  response  code  wf  count  create  url  to  string  external-invalid  starts  with    conn  /v1/jobs  id-valid  put  assertnotnull  name=x  openconnection  testjobs  params  getinputstream  jsonvalue  pst  getheaderfield  2  size  get  endswith  reset  setrequestmethod  is_security_enabled  wf  external-valid  asserttrue  array  get  json  content-type  starttime  runtest  pdt  jsontags  restconstants  mockdagengineservice  httpservletresponse  assertequals  parse  url  call  100   pdt if on daylight saving time  assertnull  obj  getresponsecode  wfcount  createurl  tostring  external-invalid  startswith
__label__nflaky hostname  get  default  host  assert  not  null  dns  test  get  local  host  default  hostname  getdefaulthost  assertnotnull  dns  testgetlocalhost  default
__label__flaky ce  rest  constants  create  coordinator  engine  get  filter  params  test  stream  log4  job  log  action  (  assert  equals  stream  log  services  run  jobs  impl  @946)  filter  job  id  678   123-127   946  dag  x  log  info  service  @125|  @124|  service  @123|  get  @678|  @127|  @126|  ce  restconstants  createcoordinatorengine  getfilterparams  teststreamlog4joblogaction  (  assertequals  streamlog  services  runjobsimpl  @946)  filter  jobid  678  123-127  946  dagxloginfoservice  @125|  @124|  service  @123|  get  @678|  @127|  @126|
__label__nflaky type  info  bits  =  100000011001110.  matrix  util  expected  1  0  0  0  0  0  0  1  1  1  0  0  1  1  1  0  assert  equals  0  matrix  1  clear  matrix  to  string  error  correction  level  embed  type  info  test  embed  type  info   type info bits = 100000011001110.  matrixutil  expected   1 0 0 0 0 0   0 1         1 1 0 0 1 1 1 0    assertequals                   0                            matrix                   1                                                                          clearmatrix  tostring  errorcorrectionlevel  embedtypeinfo  testembedtypeinfo
__label__flaky bee  =aaa    bbb  bundle  engine  incorrect  status:  assert  equals  no  eq  sign  in  token:  unparseable  time  value:  xx=yy=zz  fail  bundle  engine  exception  expected.  winniethepooh  =foo  get  error  code  bulk  response  impl  parse  bulk  filter  incorrect  key=value  pair  syntax:  to  string  one  of  the  values  is  a  whitespace:  error  code  filter  does  not  contain  \""  bulk  response  impl.  bulk_  filter_  bundle_  name\""  field:  test  parse  bulk  filter  negative  =blah-blah  bee  =aaa   bbb  bundleengine   incorrect status:  assertequals   no eq sign in token:   unparseable time value:  xx=yy=zz  fail  bundleengineexception expected.  winniethepooh  =foo  geterrorcode  bulkresponseimpl  parsebulkfilter   incorrect key=value pair syntax:  tostring   one of the values is a whitespace:  errorcode   filter does not contain \""bulkresponseimpl.bulk_filter_bundle_name\"" field:  testparsebulkfilternegative  =blah-blah
__label__nflaky other_  group_  names  proxy  users  refresh  super  user  groups  configuration  get  proxy  superuser  group  conf  key  assert  authorized  group_  names  default  impersonation  provider  from  the  other  test  case!)  conf  proxy_  ip  from  bad  ip  user  group  information  first  try  proxying  a  group  that\'s  allowed  set  proxy  user  ugi  test  wildcard  group  1.2.3.4  1.2.3.5  *  create  remote  user  real_  user_  name  assert  not  authorized  get  test  provider  from  good  ip  get  proxy  superuser  ip  conf  key  proxy_  user_  name  real  user  ugi  create  proxy  user  for  testing  other_group_names  proxyusers  refreshsuperusergroupsconfiguration  getproxysuperusergroupconfkey  assertauthorized  group_names  defaultimpersonationprovider   from the other test case!)  conf  proxy_ip   from bad ip  usergroupinformation   first try proxying a group that\'s allowed  set  proxyuserugi  testwildcardgroup  1.2.3.4  1.2.3.5  *  createremoteuser  real_user_name  assertnotauthorized  gettestprovider   from good ip  getproxysuperuseripconfkey  proxy_user_name  realuserugi  createproxyuserfortesting
__label__flaky app  get  test  case  conf  dir  get  log  ls  do  stream  disabled  check  2009-06-24  02:43:14 505  info  _  l4_:317  userblah  groupoozie  token-  app-  job-  split  _  l4_  do  stream  log  lines  2  and  4  are  filtered  out  because  they  have  the  wrong  user  job  token  info  action-  released  lock  test-log4j.properties  init  current  thread  test-no-dash-log4j.properties  out  arr  set  log  level  destroy  is  contains  _  l3_  get  context  class  loader  reset  log4j  file  debug|  info  assert  false  out  group  assert  true  _  l2_  define  parameter  set  parameter  2009-06-24  02:43:14 505  info  _  l3_:317  useroozie  groupoozie  token-  app-  job-  2009-06-24  02:43:14 505  info  _  l2_:317  -  userblah  groupoozie  token-  app-  job-  a  2009-06-24  02:43:14 505  info  _  l1_:317  -  useroozie  groupoozie  token-  app-  job-  x  log  service  oozie  get  resource  as  stream  x  log  streamer  cl  assert  equals  user  xf  thread  log  factory  io  utils  action  test  no  dash  in  conversion  pattern  copy  stream  set  system  property  _  l1_  checks  that  this  condition  is  no  longer  required  for  log  streaming  to  work  app  gettestcaseconfdir  getlog  ls      dostreamdisabledcheck  2009-06-24 02:43:14 505 info _l4_:317 userblah groupoozie token- app- job-   split  _l4_  dostreamlog   lines 2 and 4 are filtered out because they have the wrong user  job  token  info  action- released lock  test-log4j.properties  init  currentthread  test-no-dash-log4j.properties  outarr  setloglevel  destroy  is  contains  _l3_  getcontextclassloader  reset  log4jfile  debug|info  assertfalse  out  group  asserttrue  _l2_  defineparameter  setparameter  2009-06-24 02:43:14 505 info _l3_:317 useroozie groupoozie token- app- job-   2009-06-24 02:43:14 505 info _l2_:317 - userblah groupoozie token- app- job-   a  2009-06-24 02:43:14 505 info _l1_:317 - useroozie groupoozie token- app- job-   xlogservice  oozie  getresourceasstream  xlogstreamer  cl  assertequals  user  xf  thread  logfactory  ioutils  action  testnodashinconversionpattern  copystream  setsystemproperty  _l1_   checks that this condition is no longer required for log streaming to work
__label__nflaky fs.default  fs  resource  string  returned  for  an  unset  property  must  sources  conf  fs.default  foo  resource  string  returned  for  a  file-loaded  property  append  property  out  assert  array  equals  config  bar  test  property  source  add  resource  value  set  resource  string  returned  for  a  set()  property  must  be  \""programmatically\""  must  be  a  proper  absolute  path  programmatically  end  config  start  config  assert  equals  get  property  sources  be  null  file  resource  test.foo  fs.defaultfs  resource string returned for an unset property must   sources  conf  fs.defaultfoo  resource string returned for a file-loaded property  appendproperty  out  assertarrayequals  config  bar  testpropertysource  addresource  value  set  resource string returned for a set() property must be   \""programmatically\""   must be a proper absolute path  programmatically  endconfig  startconfig  assertequals  getpropertysources  be null  fileresource  test.foo
__label__flaky date  \%msg  -  \%thread\%n  given  simple  select  *  from  simple  where  id  =  crud  execute  async  with  stats  prepare  log  level  when  execution  info  id  should_delete_instance_async  info  log  asserter  all  random  utils  with  result  set  async  listener  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  assert  contains  then  long  build  date  key  logger  rs  called  script  executor  async_  logger_  string  session  delete  is  up  of  get  await  latch  count  down  value  table  execute  script  template  get  queried  host  manager  is  empty  next  long  rows  called  is  true  future  entity  date  \%msg - \%thread\%n   given  simple  select * from simple where id =   crud  executeasyncwithstats  prepareloglevel   when  executioninfo  id  should_delete_instance_async  info  logasserter  all  randomutils  withresultsetasynclistener  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  assertcontains   then  long  builddatekey  logger  rs  called  scriptexecutor  async_logger_string  session  delete  isup  of  get  await  latch  countdown  value  table  executescripttemplate  getqueriedhost  manager  isempty  nextlong  rows  called  istrue  future  entity
__label__nflaky encode  charset  submit  executor  service  update  executors  assert  1234567890  get  duration  tmp  get  verify  test  multithreading  read  boolean  task1  task2  capacity  channel  input  buffer  read  new  fixed  thread  pool  standard  charsets  value  of  assert  equals  fill  get  time  unit  call  integer  update  capacity  mockito  mock  reset  timeout  encode  charset  submit  executorservice  update  executors  assert  1234567890  getduration  tmp  get  verify  testmultithreadingread  boolean  task1  task2  capacitychannel  inputbuffer  read  newfixedthreadpool  standardcharsets  valueof  assertequals  fill  gettimeunit  call  integer  updatecapacity  mockito  mock  reset  timeout
__label__flaky subwf  action5  add  record  to  wf  action  table  get  id  workflow  instance  test  get  coordinator  parent  too  many  wf  job  add  record  to  wf  job  table  children  assert  not  null  get  subwf  job1  get  the  next  3  (though  there\'s  only  2  more)  workflow  job  subwf  job5  subwf  action1  subwf  job4  subwf  action2  subwf  job3  subwf  action3  subwf  job2  subwf  action4  get  the  first  3  assert  equals  wf  action1  wf  action2  execute  wf  action3  wf  action4  wf  action5  check  children  services  1  2  3  4  size  workflow  action  5  add  all  jpa  service  subwfaction5  addrecordtowfactiontable  getid  workflowinstance  testgetcoordinatorparenttoomany  wfjob  addrecordtowfjobtable  children  assertnotnull  get  subwfjob1   get the next 3 (though there\'s only 2 more)  workflowjob  subwfjob5  subwfaction1  subwfjob4  subwfaction2  subwfjob3  subwfaction3  subwfjob2  subwfaction4   get the first 3  assertequals  wfaction1  wfaction2  execute  wfaction3  wfaction4  wfaction5  checkchildren  services  1  2  3  4  size  workflowaction  5  addall  jpaservice
__label__nflaky default  factory  foo  codec  full  factory  bar  codec  /tmp/foo.bz2  get  canonical  name  empty  factory  lz4  codec  conf  get  codec  classes  bzip2  bzip2  codec  /tmp/foo.gz  bar  /tmp/foo.lz4  klass  full  codec  bzip2  codec  org.apache.hadoop.io.compress.  b  zip2  codec  /tmp/.foo.bar.gz  empty  factory  snappy  codec  get  codec  empty  factory  for  .bz2  foo  test  finding  default  factory  for  .gz  get  codec  by  name  get  codec  class  by  name  bzip2codec  full  factory  foo  bar  codec  full  factory  for  .bz2  deflatecodec  codec  fail  deflate  /tmp/foo.foo  overridden  factory  for  gzip  codec  default  factory  for  .bz2  default  factory  for  deflate  codec  /tmp/foo/baz.foo.bar  empty  factory  gz  codec  full  factory  foo  codec  /tmp/foo.bar  foo  org.apache.hadoop.io.compress.  default  codec     overridden  factory  for  .gz  empty  factory  for  bzip2  codec  deflatecodec  full  codec  gz  codec  /tmp/foo.snappy  default  factory  for  bzip2  codec  foobar  compression  codec  factory  full  factory  gz  codec  default  factory  for  gzip  codec  bzip2  check  codec  factory  set  common  configuration  keys  org.apache.hadoop.io.compress.  gzip  codec     gz   bz2   snappy   lz4  are  picked  up  by  service  loader   but  bar  isn\'t  assert  equals  gzip  illegal  argument  exception  is  unexpected  gzip  codec  deflate  gzipcodec  empty  factory  bar  codec  bar  gzip  set  classes  foobar  get  codec  by  class  name  default factory foo codec  full factory bar codec  /tmp/foo.bz2  getcanonicalname  empty factory lz4 codec  conf  getcodecclasses  bzip2  bzip2codec  /tmp/foo.gz  bar  /tmp/foo.lz4  klass  full codec bzip2 codec   org.apache.hadoop.io.compress.bzip2codec     /tmp/.foo.bar.gz  empty factory snappy codec  getcodec  empty factory for .bz2  foo  testfinding  default factory for .gz  getcodecbyname  getcodecclassbyname  bzip2codec  full factory foo bar codec  full factory for .bz2  deflatecodec  codec  fail  deflate  /tmp/foo.foo  overridden factory for gzip codec  default factory for .bz2  default factory for deflate codec  /tmp/foo/baz.foo.bar  empty factory gz codec  full factory foo codec  /tmp/foo.bar  foo      org.apache.hadoop.io.compress.defaultcodec      overridden factory for .gz  empty factory for bzip2 codec  deflatecodec  full codec gz codec  /tmp/foo.snappy  default factory for bzip2 codec  foobar  compressioncodecfactory  full factory gz codec  default factory for gzip codec  bzip2  checkcodec  factory  set  commonconfigurationkeys     org.apache.hadoop.io.compress.gzipcodec        gz  bz2  snappy  lz4 are picked up by service loader  but bar isn\'t  assertequals  gzip  illegalargumentexception is unexpected  gzipcodec  deflate  gzipcodec  empty factory bar codec  bar  gzip  setclasses  foobar  getcodecbyclassname
__label__flaky add  process  do  filter  with  processors  should  throw  exception  when  processor  fails  processors  processor  fails  add  process  dofilterwithprocessors  shouldthrowexceptionwhenprocessorfails  processors  processor fails
__label__nflaky array  contains  both  local  node   local  node  group  &  local  rack  node  cluster  data  nodes  array  contains  local  node  &  rack  node  assert  true  compute  node  test  sort  by  distance  array  contains  local  node  &  local  node  group  array  contains  local-nodegroup  node  (not  a  data  node  also)  &  rack  node  test  nodes  sort  by  distance   array contains both local node  local node group & local rack node  cluster  datanodes   array contains local node & rack node  asserttrue  computenode  testsortbydistance   array contains local node & local node group   array contains local-nodegroup node (not a data node also) & rack node  testnodes  sortbydistance
__label__flaky cluster  checking  for  file  choose  3  copies  of  block  file  -  delete  1  and  corrupt  the  remaining  2  conf  dfs  client  file  count  wait  active  first  time  format  wait  for  block  replication  only  3  copies  exist  get  block  file  len  get  namenode  create  block  buffer  write  info  localhost  deleting  file  dfs  config  keys  dfs.datanode.block.write.timeout.sec  log  format  get  file  system  0.75f  test  file  dn  index  num  data  nodes  get  first  block  of  the  file.  corrupt  it.  long  get  name  node  port  shutdown  get  block  locations  restarting  minicluster  after  deleting  a  replica  and  corrupting  2  crcs  rw  corrupting  file  seek  delete  out  block  file  test  pending  replication  retry  assert  true  get  close  /replication-test-file  get  block  block  out  set  mini  dfs  cluster  length  this  test  makes  sure  that  name  node  retries  all  the  available  blocks  *  for  under  replicated  blocks.  *  *  it  creates  a  file  with  one  block  and  replication  of  4.  it  corrupts  *  two  of  the  blocks  and  removes  one  of  the  replicas.  expected  behavior  is  *  that  missing  replica  will  be  copied  from  one  valid  source.  assert  equals  start  the  mini  dfs  cluster  with  more  datanodes  since  once  a  write  block  *  to  a  datanode  node  fails   same  block  can  not  be  written  to  it  *  immediately.  in  our  case  some  replication  attempts  will  fail.  integer  test  path  build  exists  to  string  cluster  checking for file    choose 3 copies of block file - delete 1 and corrupt the remaining 2  conf  dfsclient  filecount  waitactive   first time format  waitforblockreplication   only 3 copies exist  getblockfile  len  getnamenode  create  block  buffer  write  info  localhost  deleting file   dfsconfigkeys  dfs.datanode.block.write.timeout.sec  log  format  getfilesystem  0.75f  testfile  dnindex  numdatanodes   get first block of the file.   corrupt it.  long  getnamenodeport  shutdown  getblocklocations  restarting minicluster after deleting a replica and corrupting 2 crcs  rw  corrupting file   seek  delete  out  blockfile  testpendingreplicationretry  asserttrue  get  close  /replication-test-file  getblock  blockout  set  minidfscluster  length   this test makes sure that namenode retries all the available blocks      * for under replicated blocks.      *      * it creates a file with one block and replication of 4. it corrupts      * two of the blocks and removes one of the replicas. expected behavior is     * that missing replica will be copied from one valid source.       assertequals   start the minidfscluster with more datanodes since once a writeblock         * to a datanode node fails  same block can not be written to it         * immediately. in our case some replication attempts will fail.           integer  testpath  build  exists  tostring
__label__nflaky of  seconds  core  matchers  equal  to  compare  to  assert  that  null  pointer  exception  expected  tv1  tv3  tv2  fail  tv5  tv4  assert  tv6  of  milliseconds  test  compare  to  of  minutes  time  value  ofseconds  corematchers  equalto  compareto  assertthat  nullpointerexception expected  tv1  tv3  tv2  fail  tv5  tv4  assert  tv6  ofmilliseconds  testcompareto  ofminutes  timevalue
__label__flaky container  callback  servlet  ${d}${d}  reader  conf  ${e}${e}  get  status  /config-default.xml  ${c}${c}  get  job  get  test  case  dir  /workflow.xml  file://  create  workflow.xml  wait  for  ?job  id=$job  id&status=$status&node  name=$node  name  bean  aa  external-status  is  end  state  oozie  client  copy  char  stream  get  resource  as  reader  /callback  file  evaluate  bb  b  submit  job  c  get  workflow  end.error  get  workflow  instance  write  xml  test  submit  get  id  error  wf  t:null  job  id1  get  servlet  url  cccccccc  engine  get  ok  ok  workflow  job  close  wf  conf  cccc  cc  a  b  set  c  os  d  get  conf  e  f  wf-ext-schema-valid.xml  default  conf  assert  equals  kill  services  io  utils  get  test  user  t  signal-value  writer  container  callbackservlet  ${d}${d}  reader  conf  ${e}${e}  getstatus  /config-default.xml  ${c}${c}  getjob  gettestcasedir  /workflow.xml  file://  create  workflow.xml  waitfor  ?jobid=$jobid&status=$status&nodename=$nodename  bean  aa  external-status  isendstate  oozieclient  copycharstream  getresourceasreader  /callback  file  evaluate  bb  b  submitjob  c  getworkflow  end.error  getworkflowinstance  writexml  testsubmit  getid  error  wf  t:null  jobid1  getservleturl  cccccccc  engine  get  ok  ok  workflowjob  close  wfconf  cccc  cc  a  b  set  c  os  d  getconf  e  f  wf-ext-schema-valid.xml  defaultconf  assertequals  kill  services  ioutils  gettestuser  t  signal-value  writer
__label__nflaky stream  is  not  input  checker  in  assert  false  set  verify  checksum  get  wrapped  stream  local  fs  test  path  assert  true  test_  root_  dir  test  stream  type  create  stream  is  input  checker  close  open  stream is not input checker  in  assertfalse  setverifychecksum  getwrappedstream  localfs  testpath  asserttrue  test_root_dir  teststreamtype  create  stream is input checker  close  open
__label__flaky format  date  a  last-  modified:  server  date:  add  header  b  string  no  default  expiration  for  urls  with  query  string  assert  equals  set  body  body  url  enqueue  get  url  /?foo=bar  get  time  unit  formatdate  a  last-modified:   server  date:   addheader  b  string  nodefaultexpirationforurlswithquerystring  assertequals  setbody  body  url  enqueue  geturl  /?foo=bar  get  timeunit
__label__nflaky read  write  disk  validator  source  last  failure  time  test.build.data  failure  count  test  metrics  records  get  metric  value  by  name  ms  test  dir  000  the  first  failure  time  should  be  less  than  the  second  one  fail  test  check  failures  get  source  to  file  disk  check  should  fail.  get  metrics  delete  verify  the  first  metrics  record  system  collector  last  failure  time2  last  failure  time1  shell  check  status  assert  true  get  create  a  temporary  test  directory  under  the  system  test  directory  read  write  disk  validator  metrics  get  records  paths  assert  metric  files  disk  check  failed!  exec  command  get  property  create  temp  directory  e  get  absolute  path  verify  the  second  metrics  record  read  write  disk  validator  get  message  assert  equals  disk  validator  factory  get  set  permission  command  to  string  get  instance  source  name  readwritediskvalidator  source  lastfailuretime  test.build.data  failurecount  test  metricsrecords  getmetricvaluebyname  ms  testdir  000  the first failure time should be less than the second one  fail  testcheckfailures  getsource  tofile  disk check should fail.  getmetrics  delete   verify the first metrics record  system  collector  lastfailuretime2  lastfailuretime1  shell  checkstatus  asserttrue  get   create a temporary test directory under the system test directory  readwritediskvalidatormetrics  getrecords  paths  assertmetric  files  disk check failed!  execcommand  getproperty  createtempdirectory  e  getabsolutepath   verify the second metrics record  readwritediskvalidator  getmessage  assertequals  diskvalidatorfactory  getsetpermissioncommand  tostring  getinstance  sourcename
__label__flaky fail  stop  assert  not  null  local  oozie  start  get  oozie  url  assert  equals  get  client  wc  test  local  oozie  init  destroy  localoozie  fail  stop  assertnotnull  localoozie  start  getoozieurl  assertequals  getclient  wc  testlocaloozieinitdestroy  localoozie
__label__nflaky get  bytes  transferred  codec  test  utils  channel  times  assert  flush  verify  more  stuff  dump  stuff---more  stuff  write  test  coding  fragment  buffering  tiny  fragments  argument  matchers  standard  charsets  assert  equals  encoder  -  any  mockito  outbuf  metrics  spy  wrap  stuff  getbytestransferred  codectestutils  channel  times  assert  flush  verify  more stuff  dump  stuff---more stuff  write  testcodingfragmentbufferingtinyfragments  argumentmatchers  standardcharsets  assertequals  encoder  -  any  mockito  outbuf  metrics  spy  wrap  stuff
__label__flaky add  record  to  wf  action  table  coord  action  get  cmd  get  id  get  num  days  to  not  be  purged  workflow  instance  get  status  add  record  to  coord  action  table  coord  job  wf  job  add  record  to  wf  job  table  assert  not  null  get  workflow  job  should  not  have  been  purged  coordinator  action  workflow  job  wf  action  wf  job  get  cmd  wf  action  get  cmd  coordinator  action  should  not  have  been  purged  assert  equals  get  last  modified  time  execute  add  record  to  coord  job  table  coordinator  job  should  not  have  been  purged  call  services  coordinator  job  1  coord  job  get  cmd  fail  coord-action-get.xml  workflow  action  coord  action  succeeded  jpa  service  test  purge  coord  with  wf  child1  workflow  action  should  not  have  been  purged  addrecordtowfactiontable  coordactiongetcmd  getid  getnumdaystonotbepurged  workflowinstance  getstatus  addrecordtocoordactiontable  coordjob  wfjob  addrecordtowfjobtable  assertnotnull  get  workflow job should not have been purged  coordinatoraction  workflowjob  wfaction  wfjobgetcmd  wfactiongetcmd  coordinator action should not have been purged  assertequals  getlastmodifiedtime  execute  addrecordtocoordjobtable  coordinator job should not have been purged  call  services  coordinatorjob  1  coordjobgetcmd  fail  coord-action-get.xml  workflowaction  coordaction  succeeded  jpaservice  testpurgecoordwithwfchild1  workflow action should not have been purged
__label__nflaky path  request  adapter  response  expectations  execute  put  echo_  path  fail  request  handler  assert  mockito  default  uri  mock  no  method  web  server  testing  framework  exception  should  have  been  thrown    path  request  adapter  responseexpectations  execute  put  echo_path  fail  requesthandler  assert  mockito  defaulturi  mock  nomethod  webservertestingframeworkexception should have been thrown
__label__flaky cluster  test  server  defaults  dfs_  block_  size_  default  dfs_  replication_  key  dfs_  block_  size_  key  get  bytes  per  checksum  conf  io_  file_  buffer_  size_  key  fs  get  server  defaults  wait  active  io_  file_  buffer_  size_  default  get  replication  get  block  size  close  get  write  packet  size  dfs_  replication_  default  dfs  config  keys  get  file  buffer  size  assert  equals  get  file  system  dfs_  client_  write_  packet_  size_  key  dfs_  client_  write_  packet_  size_  default  set  int  dfs_  bytes_  per_  checksum_  key  set  long  build  num  data  nodes  server  defaults  dfs_  bytes_  per_  checksum_  default  shutdown  cluster  testserverdefaults  dfs_block_size_default  dfs_replication_key  dfs_block_size_key  getbytesperchecksum  conf  io_file_buffer_size_key  fs  getserverdefaults  waitactive  io_file_buffer_size_default  getreplication  getblocksize  close  getwritepacketsize  dfs_replication_default  dfsconfigkeys  getfilebuffersize  assertequals  getfilesystem  dfs_client_write_packet_size_key  dfs_client_write_packet_size_default  setint  dfs_bytes_per_checksum_key  setlong  build  numdatanodes  serverdefaults  dfs_bytes_per_checksum_default  shutdown
__label__nflaky users  user1   user2  are  allowed  test  acl  string  members  of  the  groups  group1   group2  are  allowed  user1 user2  *  acl  assert  that  no  users  are  allowed  group1 group2  members  of  the  groups  group1   group2  are  allowed  with  space  also  validate  if  get  acl  string()  for  various  cases.  user1 user2  user1 user2  group1 group2  users  user1   user2  and  to  string  all  users  are  allowed  is  equal  to  validate  get  acl  string     users user1  user2 are allowed  testaclstring  members of the groups group1  group2 are allowed  user1 user2   *  acl  assertthat  no users are allowed   group1 group2  members of the groups group1  group2 are allowed   with space   also validate if getaclstring() for various cases.  user1 user2  user1 user2 group1 group2  users user1  user2 and   tostring  all users are allowed  isequalto  validategetaclstring
__label__flaky get  name  oozie.service.  proxy  user  service.proxyuser.foo.groups  foo  user.name  conf  as  list  system  assert  string  utils  assert  not  null  get  join  nobody  validate  localhost  init  set  oozie.service.  proxy  user  service.proxyuser.foo.hosts  get  property  get  conf  destroy  services     services  fail  ex  test  invalid  group  proxy  user  to  string  arrays  getname  oozie.service.proxyuserservice.proxyuser.foo.groups  foo  user.name  conf  aslist  system  assert  stringutils  assertnotnull  get  join  nobody  validate  localhost  init  set  oozie.service.proxyuserservice.proxyuser.foo.hosts  getproperty  getconf  destroy  services     services  fail  ex  testinvalidgroup  proxyuser  tostring  arrays
__label__nflaky do  check  validation  failed  with  three  fields  length  is  now  tooooo  loooong  build  dto  context  validate  jsr303  validation  failed  with  three  fields  regex!!!  docheckvalidationfailedwiththreefields  length is now tooooo loooong  builddto  context  validatejsr303  validationfailedwiththreefields  regex!!!
__label__flaky for  testing  action  executor  set  retrieval  to  enlist  the  codes  properly   otherwise  whitespaces  cause  the  key-value  lookup  to  return  false  get  conf  test  conf  allowed  retry  codes  error  code  with  whitespaces  services  contains  assert  true  get  lite  workflow  store  service  introducing  whitespaces  in  the  error  codes  string  setting  configuration  parameter  for  error  codes  test  retry  get  user  retry  error  code     fortestingactionexecutor  set   retrieval to enlist the codes properly  otherwise whitespaces cause the key-value lookup to return false  getconf    \t\t        testconf  allowedretrycodes  errorcodewithwhitespaces  services  contains  asserttrue  get  liteworkflowstoreservice   introducing whitespaces in the error codes string   setting configuration parameter for error codes  testretry  getuserretryerrorcode
__label__nflaky reverse  router  www.greenback.com  path  param  is  assert  that  with  route  build  absolute  https://www.greenback.com/user/test\%40example.com/1000000  id  test@example.com  https  email  reverserouter  www.greenback.com  pathparam  is  assertthat  with  route  build  absolute  https://www.greenback.com/user/test\%40example.com/1000000  id  test@example.com  https  email
__label__flaky /version  rest  servlet  body  java.vm.vendor  system  os.version  bytes  assert  true  get  client  os.name  get  code  get  package  test  get  stargate  version  text  get  property  get  body  java.version  os.arch  mimetype_  text  length  contains  java.vm.version  response  to  string  get  implementation  version  /version  restservlet  body  java.vm.vendor  system  os.version  bytes  asserttrue  get  client  os.name  getcode  getpackage  testgetstargateversiontext  getproperty  getbody  java.version  os.arch  mimetype_text  length  contains  java.vm.version  response  tostring  getimplementationversion
__label__nflaky cursor  http/1.123  assert  false  get  major  http  minor  version  number  http  major  version  number  assert  http  version  number  assert  true  parse  protocol  version  get  pos  http/1.1  buffer  http  protocol  name  at  end  length  clear  http  get  protocol  assert  equals  version  http/1.123  123  test  http  version  parsing  get  minor  parser  to  string  append  char  at  cursor  http/1.123  assertfalse  getmajor  http minor version number  http major version number  assert  http version number  asserttrue  parseprotocolversion  getpos  http/1.1  buffer  http protocol name  atend  length  clear  http  getprotocol  assertequals  version  http/1.123 123  testhttpversionparsing  getminor  parser  tostring  append  charat
__label__flaky this  will  force  the  creation  of  concurrent  activations  in  each  node  1000  await  for  create  stage  stateless  test  all  match  actor5  bind  assert  true  it  is  very  likely  that  there  will  be  more  than  one  activation  per  stage  host.  of  each  node  will  have  at  most  one  activation  of  the  stateless  worker  get  client  time  unit  stream  only  25*5  calls  =>  there  should  not  be  more  than  125  activations  join  get  reference  create  client  add  we  are  using  \""  await  for(stages  idle)\""  to  ensure  no  stages  are  processing  any  messages.  but  was:  set  get  unique  activation  id  e  f  for  each  clear  assert  equals  futures  stages  idle  actor4  expecting  >4  but  was:  expecting  <=  actor3  actor2  actor1  size  stage3  i  actor  stage2  is  idle  stage4  stage1   this will force the creation of concurrent activations in each node  1000  awaitfor  createstage  statelesstest  allmatch  actor5  bind  asserttrue   it is very likely that there will be more than one activation per stage host.  of   each node will have at most one activation of the stateless worker  get  client  timeunit  stream   only 25*5 calls => there should not be more than 125 activations  join  getreference  createclient  add   we are using \"" awaitfor(stagesidle)\"" to ensure no stages are processing any messages.   but was:   set  getuniqueactivationid  e  f  foreach  clear  assertequals  futures  stagesidle  actor4  expecting >4 but was:   expecting <=  actor3  actor2  actor1  size  stage3  iactor  stage2  isidle  stage4  stage1
__label__nflaky add  test  service  verify  that  stop()  call  sequence  numbers  for  every  service  don\'t  change.  test  call  sequence  verify  the  start()  call  sequence  numbers  for  every  service  assert  in  state  state  conf  get  call  sequence  number  try  to  stop  again.  this  should  be  a  no-op.  service  manager  num_  of_  services  verify  they  were  all  started  service   start()  call  sequence  number  should  have  been  to  array  get  services  reset  the  call  sequence  numbers  verify  the  stop()  call  sequence  numbers  for  every  service  init  verify  the  init()  call  sequence  numbers  for  every  service  service   stop()  call  sequence  number  should  have  been  verify  they  were  all  stopped  number  of  registered  services  start  assert  equals  services  service   init()  call  sequence  number  should  have  been  initialise  the  composite  service  stop  service  for  add  services  reset  services  service  manager  verify  they  were  all  inited  addtestservice   verify that stop() call sequence numbers for every service don\'t change.  testcallsequence   verify the start() call sequence numbers for every service  assertinstate  state  conf  getcallsequencenumber   try to stop again. this should be a no-op.  servicemanager  num_of_services   verify they were all started   service  start() call sequence number should have been   toarray  getservices   reset the call sequence numbers   verify the stop() call sequence numbers for every service  init   verify the init() call sequence numbers for every service   service  stop() call sequence number should have been    verify they were all stopped  number of registered services   start  assertequals  services   service  init() call sequence number should have been    initialise the composite service  stop  service  for    add services  resetservices  servicemanager   verify they were all inited
__label__flaky conn  set  request  method  is_  security_  enabled  put  assert  true  get  json  /v1/job/*  content-type  /v1/admin/*  collections  run  test  system_  mode  json  tags  rest  constants  open  connection  contains  key  mock  dag  engine  service  http  servlet  response  assert  equals  parse  params  get  input  stream  url  put  json  value  call  1  get  header  field  get  response  code  get  reset  create  url  to  string  test  safe  mode  starts  with  conn  setrequestmethod  is_security_enabled  put  asserttrue  get  json  /v1/job/*  content-type  /v1/admin/*  collections  runtest  system_mode  jsontags  restconstants  openconnection  containskey  mockdagengineservice  httpservletresponse  assertequals  parse  params  getinputstream  url  put  jsonvalue  call  1  getheaderfield  getresponsecode  get  reset  createurl  tostring  testsafemode  startswith
__label__nflaky key  provider  p1  get  class  generate  encrypted  key  test  class  cast  exception  get  name  kp  authentication  exception  foo  encrypted  key  version  create  key  conf  get  cause  roll  new  version  contains  assert  true  decrypt  encrypted  key  options  mock  kms://http@host1:9600/kms/foo  ioe  keyprovider  p1  getclass  generateencryptedkey  testclasscastexception  getname  kp  authenticationexception  foo  encryptedkeyversion  createkey  conf  getcause  rollnewversion  contains  asserttrue  decryptencryptedkey  options  mock  kms://http@host1:9600/kms/foo  ioe
__label__flaky add  record  to  wf  action  table  get  id  workflow  instance  _test  wf  action  subset  get  system  test  wf  action  subset  get  1  2  add  record  to  wf  job  table  workflow  action  test  wf  action  subset  get  successful  workflow  job  job  addrecordtowfactiontable  getid  workflowinstance  _testwfactionsubsetget  system  testwfactionsubsetget  1  2  addrecordtowfjobtable  workflowaction  testwfactionsubsetget successful  workflowjob  job
__label__nflaky get  stats  should  log  get  max  assert  false  assert  equals  test  logging  with  value  advance  timer  helper  get  min  assert  true  record  log_  period  action  get  mean  get  count  getstats  shouldlog  getmax  assertfalse  assertequals  testloggingwithvalue  advance  timer  helper  getmin  asserttrue  record  log_period  action  getmean  getcount
__label__flaky execute  script  template  actual  random  utils  script  executor  manager  incr  session  one  given  next  long  select  *  from  entity_counter  where  id  =  assert  that  execute  immutable  map  crud  entity  with  counter  column/insert_single_row.cql  when  of  then  is  null  long  delete  by  id  id  should_delete_by_id  executescripttemplate  actual  randomutils  scriptexecutor  manager  incr  session  one   given  nextlong  select * from entity_counter where id =   assertthat  execute  immutablemap  crud  entitywithcountercolumn/insert_single_row.cql   when  of   then  isnull  long  deletebyid  id  should_delete_by_id
__label__nflaky server  request  bytes  server  address  await  response  timeout  send  error  generate  random  bytes  cause  conf  get  cause  client  thread  assert  await  invocation  assert  true  get  call  succeeded.  was  expecting  an  exception  e  start  client  callable  get  connect  address  deferred  error  fail  contains  net  utils  re  stop  future  test  deferred  exception  to  string  server  requestbytes  serveraddress  awaitresponsetimeout  senderror  generaterandombytes  cause  conf  getcause  clientthread  assert  awaitinvocation  asserttrue  get  call succeeded. was expecting an exception  e  start  clientcallable  getconnectaddress  deferrederror  fail  contains  netutils  re  stop  future  testdeferredexception  tostring
__label__flaky cluster  failover  by  session  expiration  ======  restarting  server  ======  failing  over  by  session  expiration  ha  service  state  wait  for  server  down  host  port  wait  for  server  up  graceful  failovers  info  log  failover  by  bad  health  stop  server  connection_  timeout  start  wait  for  health  state  graceful  failover  to  you  get  zkfc  test  one  of  everything  set  healthy  wait  for  ha  state  stop  start  server  state  restart  zk  expire  and  verify  failover  cluster   failover by session expiration  ====== restarting server  ====== failing over by session expiration  haservicestate  waitforserverdown  hostport  waitforserverup   graceful failovers  info  log   failover by bad health  stopserver  connection_timeout  start  waitforhealthstate  gracefulfailovertoyou  getzkfc  testoneofeverything  sethealthy  waitforhastate  stop  startserver  state   restart zk  expireandverifyfailover
__label__nflaky custom-key  src  standard  charsets  test  plain  string  decoding  create  byte  buffer  has  remaining  assert  false  length  assert  equals  decoding  completed  assert  array  decode  plain  string  buffer  h  pack  decoder  custom-key  src  standardcharsets  testplainstringdecoding  createbytebuffer  hasremaining  assertfalse  length  assertequals  decoding completed  assert  array  decodeplainstring  buffer  hpackdecoder
__label__flaky init  ${coord:data  out  partition  value(\'  abc\'   \'mypartition\')}  -ve  test  coord  el  functions  test  data  out  partition  value  ph1  set  variable  +ve  test  assert  equals  oozie.dataname.  abcd  ${coord:data  out  partition  value(\'  abcd\')}  coord-job-submit-data  fail  eval  eval  and  wrap  should  throw  exception  because  el  function  requires  2  parameters  expr  oozie.dataname.  abc  data-out  init  ${coord:dataoutpartitionvalue(\'abc\'  \'mypartition\')}   -ve test  coordelfunctions  testdataoutpartitionvalueph1  setvariable   +ve test  assertequals  oozie.dataname.abcd  ${coord:dataoutpartitionvalue(\'abcd\')}  coord-job-submit-data  fail  eval  evalandwrap  should throw exception because el function requires 2 parameters  expr  oozie.dataname.abc  data-out
__label__nflaky then  return  invoke  double  param  double  validation  should  work  when  param1  assert  true  context  create  verify  mock  controller  validation  has  violation  blah  get  parameter  thenreturn  invoke  doubleparam  doublevalidationshouldwork  when  param1  asserttrue  context  create  verify  mockcontroller  validation  hasviolation  blah  getparameter
__label__flaky r2  get  name  output  test.*.source.filter.exclude  get  test  filename  test  put  metrics  s0  s1  add  check  metrics  records  on  timer  event  test  init  first  ms  get  all  values  capture  test.sink.test.class  mr2  mr1  s1  desc  stop  *.period  test  metrics  config  test.sink.sink1.metric.filter.exclude  mock  trigger  something  interesting  s0rec  test.sink.sink2.metric.filter.exclude  save  test.source.s1.metric.filter.exclude  x*  times  verify  sink2  desc  hadoop-metrics2-test  s1rec  cb  set  register  sink  incr  start  sink1  desc  assert  equals  y*  s0  desc  sink2  sink1  register  r1  r2  getname  output  test.*.source.filter.exclude  gettestfilename  test  putmetrics  s0  s1  add  checkmetricsrecords  ontimerevent  testinitfirst  ms  getallvalues  capture  test.sink.test.class  mr2  mr1  s1 desc  stop  *.period  testmetricsconfig  test.sink.sink1.metric.filter.exclude  mock   trigger something interesting  s0rec  test.sink.sink2.metric.filter.exclude  save  test.source.s1.metric.filter.exclude  x*  times  verify  sink2 desc  hadoop-metrics2-test  s1rec  cb  set  registersink  incr  start  sink1 desc  assertequals  y*  s0 desc  sink2  sink1  register  r1
__label__nflaky store  password  get  resource  to  char  array  server  socket  new  single  thread  executor  executors  server  ssl  context  as  list  get  server  socket  factory  assert  bind  assert  not  null  nopassword  is  windows  create  boolean  ssl  context  builder  /test-client.p12  localhost  start  handshake  read  local  port  load  key  material  load  trust  material  resource2  thrown  input  stream  set  so  timeout  get  input  stream  /test-server.p12  resource1  accept  contains  create  socket  test  ssl  handshake  protocol  mismatch2  client  ssl  context  timeout  arrays  supported  server  protocols  get  supported  protocols  get  local  port  submit  supported  client  protocols  client  socket  ss  lv3  assert  true  tl  sv1  key  password  close  connect  assert  equals  set  enabled  protocols  call  get  socket  factory  expect  build  to  milliseconds  int  bound  socket  get  session  create  server  socket  storepassword  getresource  tochararray  serversocket  newsinglethreadexecutor  executors  serversslcontext  aslist  getserversocketfactory  assert  bind  assertnotnull  nopassword  iswindows  create  boolean  sslcontextbuilder  /test-client.p12  localhost  starthandshake  read  localport  loadkeymaterial  loadtrustmaterial  resource2  thrown  inputstream  setsotimeout  getinputstream  /test-server.p12  resource1  accept  contains  createsocket  testsslhandshakeprotocolmismatch2  clientsslcontext  timeout  arrays  supportedserverprotocols  getsupportedprotocols  getlocalport  submit  supportedclientprotocols  clientsocket  sslv3  asserttrue  tlsv1  keypassword  close  connect  assertequals  setenabledprotocols  call  getsocketfactory  expect  build  tomillisecondsintbound  socket  getsession  createserversocket
__label__flaky headers  /i18n/en  de-  de  get  server  address  ninja  test  browser  new  hash  map  /i18n/de  make  request  put  language  on  the  root.  result  test  that  explicit  lang  setting  works  text_  en  contains  2)  test  that  fallback  is  accept-language  header  maps  /i18n/tk  assert  true  4)  normal  operation  text_  de  accept-  language  1)  test  that  overriding  of  accept-language  header  works  headers  /i18n/en  de-de  getserveraddress  ninjatestbrowser  newhashmap  /i18n/de  makerequest  put   language on the root.  result  testthatexplicitlangsettingworks  text_en  contains   2) test that fallback is accept-language header  maps  /i18n/tk  asserttrue   4) normal operation  text_de  accept-language   1) test that overriding of accept-language header works
__label__nflaky other_  group_  names  proxy  users  now  set  up  an  unallowed  group  refresh  super  user  groups  configuration  get  proxy  superuser  group  conf  key  assert  authorized  group_  names  default  impersonation  provider  conf  as  list  string  utils  join  user  group  information  first  try  proxying  a  group  that\'s  allowed  set  proxy  user  ugi  neither  ip  should  be  ok  test  wildcard  ip  1.2.3.4  1.2.3.5  *     create  remote  user  real_  user_  name  assert  not  authorized  get  test  provider  from  either  ip  should  be  fine  arrays  get  proxy  superuser  ip  conf  key  proxy_  user_  name  real  user  ugi  create  proxy  user  for  testing  other_group_names  proxyusers   now set up an unallowed group  refreshsuperusergroupsconfiguration  getproxysuperusergroupconfkey  assertauthorized  group_names  defaultimpersonationprovider  conf  aslist  stringutils  join  usergroupinformation   first try proxying a group that\'s allowed  set  proxyuserugi   neither ip should be ok  testwildcardip  1.2.3.4  1.2.3.5  *     createremoteuser  real_user_name  assertnotauthorized  gettestprovider   from either ip should be fine  arrays  getproxysuperuseripconfkey  proxy_user_name  realuserugi  createproxyuserfortesting
__label__flaky test  client  with  anonymous  get  context  url  oozie  url  admin  run  assert  equals  oozie.authentication.simple.anonymous.allowed  args  call  -oozie  set  system  property  true  -status  run  test  testclientwithanonymous  getcontexturl  oozieurl  admin  run  assertequals  oozie.authentication.simple.anonymous.allowed  args  call  -oozie  setsystemproperty  true  -status  runtest
__label__nflaky test  close  expired  get  stats  release  close  expired  sleep  assert  update  expiry  assert  true  stats  assert  not  null  get  of  time  unit  verify  close  entry2  time  value  get  leased  conn2  entry1  conn1  assign  connection  argument  matchers  somehost  pool  assert  equals  totals  is  done  any  thread  never  future1  future2  mockito  close  mode  mock  lease  get  pending  get  total  stats  get  available  testcloseexpired  getstats  release  closeexpired  sleep  assert  updateexpiry  asserttrue  stats  assertnotnull  get  of  timeunit  verify  close  entry2  timevalue  getleased  conn2  entry1  conn1  assignconnection  argumentmatchers  somehost  pool  assertequals  totals  isdone  any  thread  never  future1  future2  mockito  closemode  mock  lease  getpending  gettotalstats  getavailable
__label__flaky random  port  assert  false  topic.topic1  start  the  broker  and  check  if  listening  to  topic  now  sleep  random  broker  u  rl  is  topic  in  retry  list  connection  factory  is  connection  in  retry  list  h  cat  accessor  service  assert  true  tcp://localhost:  connection  factory  names#  publisher  authority  get  services  conf  register  for  notification  default=java.naming.factory.initial#  init  set  get  jms  connection  info  get  conf  hcat  service  test  connection  retry  hcat.server.com:5080  start  destroy  jms  service  services  next  int  hcat://hcat.server.com:8020  broker  jms  accessor  service  add  connector  active  mq  conn  factory  thread  1  services  3  java.naming.provider.url#  conn  info  stop  setup  services  for  h  catalog  is  listening  to  topic  topic  ;  randomport  assertfalse  topic.topic1   start the broker and check if listening to topic now  sleep  random  brokerurl  istopicinretrylist  connectionfactory  isconnectioninretrylist  hcataccessorservice  asserttrue  tcp://localhost:  connectionfactorynames#  publisherauthority  get  servicesconf  registerfornotification  default=java.naming.factory.initial#  init  set  getjmsconnectioninfo  getconf  hcatservice  testconnectionretry  hcat.server.com:5080  start  destroy  jmsservice  services  nextint  hcat://hcat.server.com:8020  broker  jmsaccessorservice  addconnector  activemqconnfactory  thread  1  services  3  java.naming.provider.url#  conninfo  stop  setupservicesforhcatalog  islisteningtotopic  topic  ;
__label__nflaky args  assert  test  arg  not  empty  pass  stuff  not  empty  assert  same  stuff  args  assert  testargnotemptypass  stuff  notempty  assertsame  stuff
__label__flaky reader  local  oozie  check  suspend  actions  conf  get  status  assert  not  null  decision1  create  workflow.xml  app  :start:  *  get  file  system  action4a  action4b  action4c  oozie  client  job  id  copy  char  stream  mkdirs  set  property  get  resource  as  reader  create  configuration  file  oozie.suspend.on.nodes  submit  get  job  info  fs  app  path  join1  wf  oc  end  workflow  job  close  resume  start  assert  equals  get  client  wf-suspendpoints.xml  io  utils  get  test  user  test  suspend  points  all  to  string  writer  action1  action2  action3  fork1  get  fs  test  case  dir  reader  localoozie  checksuspendactions  conf  getstatus  assertnotnull  decision1  create  workflow.xml  app  :start:  *  getfilesystem  action4a  action4b  action4c  oozieclient  jobid  copycharstream  mkdirs  setproperty  getresourceasreader  createconfiguration  file  oozie.suspend.on.nodes  submit  getjobinfo  fs  apppath  join1  wf  oc  end  workflowjob  close  resume  start  assertequals  getclient  wf-suspendpoints.xml  ioutils  gettestuser  testsuspendpointsall  tostring  writer  action1  action2  action3  fork1  getfstestcasedir
__label__nflaky handler  request  test  valid  jwt  get  time  jwt  alice  public  key  set  public  key  when  service_  url  assert  assert  not  null  get  cookies  get  jwt  get  user  name  alternate  authentication  should  not  have  thrown  an  authentication  exception  get  request  url  init  cookie  then  return  get  properties  hadoop-jwt  encode  redirect  url  alternate  authenticate  assert  equals  props  token  fail  private  key  serialize  mockito  token  should  not  be  null.  response  mock  alternate  authentication  should  not  have  thrown  a  servlet  exception.  handler  request  testvalidjwt  gettime  jwt  alice  publickey  setpublickey  when  service_url  assert  assertnotnull  getcookies  getjwt  getusername  alternateauthentication should not have thrown an authenticationexception  getrequesturl  init  cookie  thenreturn  getproperties  hadoop-jwt  encoderedirecturl  alternateauthenticate  assertequals  props  token  fail  privatekey  serialize  mockito  token should not be null.  response  mock  alternateauthentication should not have thrown a servletexception.
__label__flaky conn  set  request  method  is_  security_  enabled  assert  false  put  /v0/admin/*  assert  true  get  json  content-type  collections  run  test  json  tags  rest  constants  open  connection  contains  key  false  mock  dag  engine  service  http  servlet  response  assert  equals  parse  params  get  input  stream  url  put  json  value  call  /v0/job/*  get  header  field  get  response  code  get  true  reset  create  url  test  safe  mode  starts  with  conn  setrequestmethod  is_security_enabled  assertfalse  put  /v0/admin/*  asserttrue  get  json  content-type  collections  runtest  jsontags  restconstants  openconnection  containskey  false  mockdagengineservice  httpservletresponse  assertequals  parse  params  getinputstream  url  put  jsonvalue  call  /v0/job/*  getheaderfield  getresponsecode  get  true  reset  createurl  testsafemode  startswith
__label__nflaky dst  src  assert  false  dir2  test  rename  replace  existing  empty  directory  dir1  delete  assert  true  rename  test_  root_  dir  mkdirs  file  sys  file2  exists  file1  write  file  dst  src  assertfalse  dir2  testrenamereplaceexistingemptydirectory  dir1  delete  asserttrue  rename  test_root_dir  mkdirs  filesys  file2  exists  file1  writefile
__label__flaky end_  points  rest  constants  is_  security_  enabled  get  context  url  oozie  url  get  job  id  mock  dag  engine  service  assert  equals  id-valid  wc  external-valid  call  assert  null  test  external  id  external-invalid  servlet_  classes  run  test  end_points  restconstants  is_security_enabled  getcontexturl  oozieurl  getjobid  mockdagengineservice  assertequals  id-valid  wc  external-valid  call  assertnull  testexternalid  external-invalid  servlet_classes  runtest
__label__nflaky path  request  server  /custom/*  get  method  put  custom_  path  assert  request  handler  default  uri  localhost  adapter  method  start  thrown  method  not  expected  assert  equals  handle  response  expectations  execute  target  register  handler  testing  framework  with  live  server  custom  request  handler  get  port  t  junk  method  to  string  path  request  server  /custom/*  getmethod  put  custom_path  assert  requesthandler  defaulturi  localhost  adapter  method  start  thrown  method not expected  assertequals  handle  responseexpectations  execute  target  registerhandler  testingframework  withliveservercustomrequesthandler  getport  t  junk  method  tostring
__label__flaky b  end_  points  is_  security_  enabled  submit  test  submit  with  property  arguments  oozie  url  assert  false  run  app  path  -submit  get  -config  x  create  workflow.xml  servlet_  classes  close  run  test  -  da=  x  app  a  create  config  file  b  get  context  url  mock  dag  engine  service  -  db=  b  assert  equals  get  file  system  args  call  -oozie  mkdirs  wf  count  to  string  job  get  fs  test  case  dir  b  end_points  is_security_enabled  submit  testsubmitwithpropertyarguments  oozieurl  assertfalse  run  apppath  -submit  get  -config  x  create  workflow.xml  servlet_classes  close  runtest  -da=x  app  a  createconfigfile  b  getcontexturl  mockdagengineservice  -db=b  assertequals  getfilesystem  args  call  -oozie  mkdirs  wfcount  tostring  job  getfstestcasedir
__label__nflaky test  expiry  does  not  overflow  assign  connection  deadline  assert  equals  current  time  supplier  entry  route1  assert  mockito  of  get  validity  deadline  long  time  unit  mock  time  value  testexpirydoesnotoverflow  assignconnection  deadline  assertequals  currenttimesupplier  entry  route1  assert  mockito  of  getvaliditydeadline  long  timeunit  mock  timevalue
__label__flaky action  num  test  coord  action  get  get  action  nominal  time  action  nomial  time  get  id  _test  get  action  for  nominal  time  date  utils  add  record  to  coord  action  table  app  path  add  record  to  coord  job  table  parse  date  oozie  tz  action  xml  coordinator  job  coord  coord-action-get.xml  coordinator  action  action  job  get  coord  action  xml  get  fs  test  case  dir  actionnum  testcoordactionget  getactionnominaltime  actionnomialtime  getid  _testgetactionfornominaltime  dateutils  addrecordtocoordactiontable  apppath  addrecordtocoordjobtable  parsedateoozietz  actionxml  coordinatorjob  coord  coord-action-get.xml  coordinatoraction  action  job  getcoordactionxml  getfstestcasedir
__label__nflaky date  test  body  parser  integer  primitive  core  matchers  equal  to  3000  invoke  when  put  4.567  date  time  string  context  1.234  validation  character  primitive  a  string  something  else  what  should  be  skipped  then  return  some  setup  for  this  method:  2000  long  object  do  assert  that  2014-10-10  t20:09:10  2014-10-10  character  object  float  primitive  string  and  test:  body  parser  engine  post  get  validation  assert  false  1000  has  violations  test  object  double  primitive  map  timestamp  a  b  4000  integer  object  to  date  date  string  float  object  2.345  mockito  long  primitive  get  parameters  double  object  3.456  date  testbodyparser  integerprimitive  corematchers  equalto  3000  invoke  when  put  4.567  datetimestring  context  1.234  validation  characterprimitive  astring  somethingelsewhatshouldbeskipped  thenreturn   some setup for this method:  2000  longobject   do  assertthat  2014-10-10t20:09:10  2014-10-10  characterobject  floatprimitive  string   and test:  bodyparserenginepost  getvalidation  assertfalse  1000  hasviolations  testobject  doubleprimitive  map  timestamp  a  b  4000  integerobject  todate  datestring  floatobject  2.345  mockito  longprimitive  getparameters  doubleobject  3.456
__label__flaky cluster  init  buffer  write  to  file  verify  that  full  blocks  are  sane  mid  conf  fs  system  /simple  flush.dat  create  file  simulated  storage  exception  :  created  file  simple  flush.dat  wrote  and  flushed  first  part  of  file.  hflush  written  second  part  of  file  create  a  new  file.  close  write  check  file  closed  file.  read  2  print  stack  trace  e  throwable  :  wrote  and  flushed  second  part  of  file.  write  the  remainder  of  the  file  get  file  system  file  contents  stm  append  test  util  check  full  file  verify  that  entire  file  is  good  throwable  :  build  simulated  fs  dataset  file1  test  simple  flush  shutdown  set  boolean  cluster  initbuffer   write to file   verify that full blocks are sane  mid  conf  fs  system  /simpleflush.dat  createfile  simulatedstorage  exception :  created file simpleflush.dat  wrote and flushed first part of file.  hflush  written second part of file   create a new file.  close  write  checkfile  closed file.  read 2  printstacktrace  e  throwable :  wrote and flushed second part of file.   write the remainder of the file  getfilesystem  filecontents  stm  appendtestutil  checkfullfile   verify that entire file is good  throwable :   build  simulatedfsdataset  file1  testsimpleflush  shutdown  setboolean
__label__nflaky encode  charset  submit  executor  service  update  executors  test  multithreading  single  read  assert  get  duration  get  verify  boolean  task1  task2  a  capacity  channel  input  buffer  read  new  fixed  thread  pool  standard  charsets  value  of  assert  equals  fill  get  time  unit  call  integer  update  capacity  mockito  mock  reset  timeout  encode  charset  submit  executorservice  update  executors  testmultithreadingsingleread  assert  getduration  get  verify  boolean  task1  task2  a  capacitychannel  inputbuffer  read  newfixedthreadpool  standardcharsets  valueof  assertequals  fill  gettimeunit  call  integer  updatecapacity  mockito  mock  reset  timeout
__label__flaky cluster  get  current  user  half  conf  run  hard_  lease_  limit  wait  active  ugi  file  system  create  d.  on  m2   open  file  and  read  1  block  of  data  from  it.  close  file.  set  lease  period  write  check  file  info  user  group  information  create  user  for  testing  of  data  can  be  read  successfully.  dfs  config  keys  interrupt  and  join  new  instance  get  file  system  dfs  get  int  set  long  get  wrapped  stream  do  as  hflush  num  data  nodes  pipeline_02_03  shutdown  create  cluster  wait  for  the  cluster  block_  size  fs  out  leasechecker.interrupt  and  join()  sleep  enable  append  current  sleep  to  let  the  lease  is  expired.  hflush  do  not  close  file  yet.  c.  on  m1   append  another  half  block  of  data.  close  file  on  m1.  close  soft_  lease_  limit  get  short  user  name  supergroup  get  conf  dir  io.file.buffer.size  append  test  util  thread  p  build  file1  change  the  lease  limits.  append  set  boolean  cluster  getcurrentuser  half  conf  run  hard_lease_limit  waitactive  ugi  filesystem  create   d. on m2  open file and read 1 block of data from it. close file.  setleaseperiod  write  checkfile  info  usergroupinformation  createuserfortesting   of data can be read successfully.  dfsconfigkeys  interruptandjoin  newinstance  getfilesystem  dfs  getint  setlong  getwrappedstream  doas   hflush  numdatanodes  pipeline_02_03  shutdown   create cluster   wait for the cluster  block_size  fs  out  leasechecker.interruptandjoin()  sleep   enable append  current   sleep to let the lease is expired.  hflush   do not close file yet.   c. on m1  append another half block of data.  close file on m1.  close  soft_lease_limit  getshortusername  supergroup  getconf  dir  io.file.buffer.size  appendtestutil  thread  p  build  file1   change the lease limits.  append  setboolean
__label__nflaky ninja  cache  test  safe  add  checks  serializable  safe  add  not  serializable  ninjacache  testsafeaddchecksserializable  safeadd  notserializable
__label__flaky bundle  job  get  executor  add  record  to  bundle  action  table  get  time  add  record  to  bundle  job  table  with  paused  time  assert  false  get  id  test  bundle  rerun  in  paused  get  status  is  pending  pause  time  assert  not  null  get  curr  job  assert  equals  execute  add  record  to  coord  job  table  call  get  pause  time  coordinator  job  services  action1  job  action2  jpa  service  bundlejobgetexecutor  addrecordtobundleactiontable  gettime  addrecordtobundlejobtablewithpausedtime  assertfalse  getid  testbundlereruninpaused  getstatus  ispending  pausetime  assertnotnull  get  curr  job  assertequals  execute  addrecordtocoordjobtable  call  getpausetime  coordinatorjob  services  action1  job  action2  jpaservice
__label__nflaky set  bind  address  set  num  handlers  e  set  protocol  conf  set  verbose  set  port  test  mandatory  field  protocol  fail  didn\'t  throw  hadoop  illegal  argument  exception  build  address  expecting  hadoop  illegal  argument  exception  but  caught  test  mandatory  field  conf  test  mandatory  field  instance  test  rpc  builder  set  instance  setbindaddress  setnumhandlers  e  setprotocol  conf  setverbose  setport   test mandatory field protocol  fail  didn\'t throw hadoopillegalargumentexception  build  address  expecting hadoopillegalargumentexception but caught    test mandatory field conf   test mandatory field instance  testrpcbuilder  setinstance
__label__flaky get  name  oozie.service.  proxy  user  service.proxyuser.foo.groups  foo  conf  as  list  bar  assert  string  utils  assert  not  null  test  invalid  host  get  join  validate  localhost  init  set  oozie.service.  proxy  user  service.proxyuser.foo.hosts  get  conf  destroy  *  services     www.example.com  services  fail  ex  proxy  user  to  string  arrays  getname  oozie.service.proxyuserservice.proxyuser.foo.groups  foo  conf  aslist  bar  assert  stringutils  assertnotnull  testinvalidhost  get  join  validate  localhost  init  set  oozie.service.proxyuserservice.proxyuser.foo.hosts  getconf  destroy  *  services     www.example.com  services  fail  ex  proxyuser  tostring  arrays
__label__nflaky aaa  ccc  value1  xx   yy   zz  name8=xx\%2  c\%20\%20yy\%20\%20\%2  czz  result  name3  value  4!  name4  name5  assert  name4=  value\%204\%21  name6  name7=aaa&  name7=b\%2  cb&  name7=ccc  name7  test  parse  url  coded  content  assert  true  name2=  name8  price  get  b b  name1=  value1  name4=  value\%204\%21\%20\%214  name0  name1  name2  bbb  name5=aaa&  name6=bbb  is  empty  assert  equals  parse  name4=  value\%2  b4\%21  value+4!  price=10\%20\%  e2\%82\%  ac  assert  name  value  pair  size  value  4!  !4  10  â‚¬    aaa  ccc  value1  xx   yy   zz  name8=xx\%2c\%20\%20yy\%20\%20\%2czz  result  name3  value 4!  name4  name5  assert  name4=value\%204\%21  name6  name7=aaa&name7=b\%2cb&name7=ccc  name7  testparseurlcodedcontent  asserttrue  name2=  name8  price  get  b b  name1=value1  name4=value\%204\%21\%20\%214  name0  name1  name2  bbb  name5=aaa&name6=bbb  isempty  assertequals  parse  name4=value\%2b4\%21  value+4!  price=10\%20\%e2\%82\%ac  assertnamevaluepair  size  value 4! !4  10 â‚¬
__label__flaky ce  create  coordinator  engine  get  filter  params  assert  equals  stream  log  services  run  jobs  impl  filter  job  id  dag  x  log  info  service  service  test  stream  log2  get  ce  createcoordinatorengine  getfilterparams  assertequals  streamlog  services  runjobsimpl  filter  jobid  dagxloginfoservice  service  teststreamlog2  get
__label__nflaky srowen@example.org  mailto:?cc=srowen@example.org  do  test  test  c  cs  mailto:?cc=srowen@example.org bob@example.org  bob@example.org  srowen@example.org  mailto:?cc=srowen@example.org  dotest  testccs  mailto:?cc=srowen@example.org bob@example.org  bob@example.org
__label__flaky date  all  script  executor  session  local_  one  given  update  simple  eq  consistencylist  contains  exactly  quorum  when  get  list  of  where  id  row  table  execute  script  template  random  utils  manager  one  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  select  consistencylist  from  simple  where  id  =  then  long  build  date  key  from  base  table  consistency  list  dsl  should_dsl_update_list_append  consistency  list_  append  to  date  all  scriptexecutor  session  local_one   given  update  simple  eq  consistencylist  containsexactly  quorum   when  getlist  of  where  id  row  table  executescripttemplate  randomutils  manager  one  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  select consistencylist from simple where id =    then  long  builddatekey  frombasetable  consistencylist  dsl  should_dsl_update_list_append  consistencylist_appendto
__label__nflaky both  expired  period  and  max  in  active  interval  are  not  reached.  expires  token_  max_  inactive_  interval  test  do  filter  authentication  authorized  _test  do  filter  authentication  max  inactive  interval  token_  validity_  sec  current  time  millis  authorized  max  inactives  system   both expired period and maxinactiveinterval are not reached.  expires  token_max_inactive_interval  testdofilterauthenticationauthorized  _testdofilterauthenticationmaxinactiveinterval  token_validity_sec  currenttimemillis  authorized  maxinactives  system
__label__flaky _test  non  transient  test  end  non  transient  end.non-transient  assert  true  end  workflow  action  bean  _testnontransient  testendnontransient  end.non-transient  asserttrue  end  workflowactionbean
__label__nflaky lookup  assert  assert  true  assert  not  null  exact  h  h1  h2  *  matcher  test  match  exact  register  lookup  assert  asserttrue  assertnotnull  exact  h  h1  h2  *  matcher  testmatchexact  register
__label__flaky get  name  oozie.service.  proxy  user  service.proxyuser.foo.groups  foo  conf  as  list  bar  assert  assert  true  string  utils  assert  not  null  get  join  validate  init  set  oozie.service.  proxy  user  service.proxyuser.foo.hosts  get  conf  get  message  destroy  services     test  null  host  services  fail  contains  ex  proxy  user  to  string  arrays  getname  oozie.service.proxyuserservice.proxyuser.foo.groups  foo  conf  aslist  bar  assert  asserttrue  stringutils  assertnotnull  get  join  validate  init  set  oozie.service.proxyuserservice.proxyuser.foo.hosts  getconf  getmessage  destroy  services     testnullhost  services  fail  contains  ex  proxyuser  tostring  arrays
__label__nflaky test  data  line  next  buffer  head  token  char  \'a\'  as  a  filler  for  the  test  string  replace  get  bytes  </entity><entity><id>  gelesh</  current  buffer  tail  token  assert  test  custom  delimiter1  delimiter  fill  buffer  </entity>  line  reader  id><name>  omathil</name></entity>  close  number  of  char  to  fill  the  buffer  supposing  the  start  of  next  buffer  is  this  it  contains  \'</\'  ie  delimiter  character  test  part  of  input  filler  string  standard  charsets  expected  length  assert  equals  fill  read  line  expected  must  capture  from  both  the  buffer   excluding  delimiter  to  string  arrays  buffer  size    testdata  line  nextbufferheadtoken   char \'a\' as a filler for the test string  replace  getbytes  </entity><entity><id>gelesh</  currentbuffertailtoken  assert  testcustomdelimiter1  delimiter  fillbuffer  </entity>  linereader  id><name>omathil</name></entity>  close  numberofchartofillthebuffer   supposing the start of next buffer is this   it contains \'</\' ie delimiter character  testpartofinput  fillerstring  standardcharsets  expected  length  assertequals  fill  readline   expected must capture from both the buffer  excluding delimiter  tostring  arrays  buffersize
__label__flaky a  l1  l2  start  assert  equals  sb  thread  sleep  a:1-  l  a:1-  u  a:2-  l  a:2-  u  trim  finish  to  string  test  wait  write  lock    a  l1  l2  start  assertequals  sb  thread  sleep  a:1-l a:1-u a:2-l a:2-u  trim  finish  tostring  testwaitwritelock
__label__nflaky <value></value>  bais  </configuration>  is  empty  conf  conf  test  test  property  has  empty  value  <name>foo</name>  get  bytes  assert  true  check  conf  </property>  <property>  <configuration>  errors  <value></value>    bais  </configuration>  isempty  conf  conftest  testpropertyhasemptyvalue  <name>foo</name>    getbytes  asserttrue  checkconf  </property>    <property>    <configuration>    errors
__label__flaky in  get  test  string  before  utf-8  test  that  it  reads  correctly  read  string  assert  equals  generate  a  random  string  after3  out  after2  test  io  test  that  it  reads  correctly  with  data  input  write  it  read  utf  utf8  test  that  it  is  compatible  with  java\'s  other  decoder  reset  get  length  after  write  string  get  data  in  getteststring  before  utf-8   test that it reads correctly  readstring  assertequals   generate a random string  after3  out  after2  testio   test that it reads correctly with datainput   write it  readutf  utf8   test that it is compatible with java\'s other decoder  reset  getlength  after  writestring  getdata
__label__nflaky q1  qq1  expect  metrics  exception  test  add  illegal  parameters  interval  should  be  positive.  value  passed  is:  -20  r  illegal  param  test  run  qv1  new  quantiles  new  quantile  1  q1  qq1  expectmetricsexception  testaddillegalparameters  interval should be positive.  value passed is: -20  r  illegalparamtest  run  qv1  newquantiles  new quantile 1
__label__flaky date  script  executor  session  given  simple  with  lwt  result  listener  eq  delete  select  *  from  simple  where  id  =  lwt  result  listener  when  of  get  where  id  get  and  set  row  table  _  execute  script  template  on  error  random  utils  manager  all  columns_  from  base  table  one  lt  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  should_delete_with_inequal_condition  is  true  if_  value  success  then  is  null  long  build  date  key  dsl  on  success  date  scriptexecutor  session   given  simple  withlwtresultlistener  eq  delete  select * from simple where id =   lwtresultlistener   when  of  get  where  id  getandset  row  table  _  executescripttemplate  onerror  randomutils  manager  allcolumns_frombasetable  one  lt  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  should_delete_with_inequal_condition  istrue  if_value  success   then  isnull  long  builddatekey  dsl  onsuccess
__label__nflaky set  float  configuration  double_  delta  assert  equals  get  float  value  test  float  setfloat  configuration  double_delta  assertequals  getfloat  value  testfloat
__label__flaky construct  prepare  xml  block  with  the  path  parse  the  xml  to  get  the  node  </prepare>  do  operations  <delete  path=\'  expected  to  catch  an  exception  but  did  not  encounter  any  expected  a  launcher  exception  but  received  an  exception  conf  substring  scheme  hftp  not  supported  in  uri  get  document  from  xml  create  job  conf  path  trim  launcher  mapper  <prepare>  \'/>  test  for  invalid  scheme  value  in  the  path  for  action  get  named  item  test  for  invalid  scheme  item  get  attributes  hftp:/  action  dir  get  document  element  get  message  assert  equals  construct  a  path  with  invalid  scheme  n  get  node  value  /delete  fail  new  dir  prepare  xml  doc  le  to  string  prepare  actions  driver  setup  launcher  uri  handler  conf  get  fs  test  case  dir  get  child  nodes   construct prepare xml block with the path   parse the xml to get the node  </prepare>  dooperations  <delete path=\'  expected to catch an exception but did not encounter any  expected a launcherexception but received an exception  conf  substring  scheme hftp not supported in uri   getdocumentfromxml  createjobconf  path  trim  launchermapper  <prepare>  \'/>   test for invalid scheme value in the path for action  getnameditem  testforinvalidscheme  item  getattributes  hftp:/  actiondir  getdocumentelement  getmessage  assertequals   construct a path with invalid scheme  n  getnodevalue  /delete  fail  newdir  preparexml  doc  le  tostring  prepareactionsdriver  setuplauncherurihandlerconf  getfstestcasedir  getchildnodes
__label__nflaky offer  c  size  fcq  assert  equals  remaining  capacity  mocked  priorities  mock  call  test  all  queues  full  remaining  capacity  offer  c  size  fcq  assertequals  remainingcapacity  mockedpriorities  mockcall  testallqueuesfullremainingcapacity
__label__flaky test  coord  action  get  _  e  error  code  get  id  date  utils  set  tracker  uri  replace  all  app  path  set  error  code  parse  date  oozie  tz  resource  xml  name  action  xml  set  error  message  set  time  out  coord  action  nominal  time  console  url  get  test  case  dir  coordinator  action  action  set  created  time  miss  deps  action  num  tracker  uri  pass  expected  values  #test  dir  error  message  get  action  nominal  time  set  console  url  set  external  status  add  some  attributes  test  dir  set  missing  dependencies  add  record  to  coord  job  table  _test  get  actions  subset  coordinator  job  create  coord  action  coord-action-get.xml  file://#test  dir/2009/29/_  success#file://#test  dir/2009/22/_  success#file://#test  dir/2009/15/_  success#file://#test  dir/2009/08/_  success  dummy  creation  time  insert  the  action  insert  record  coord  action  external  status  job  get  coord  action  xml  get  fs  test  case  dir  testcoordactionget  _e  errorcode  getid  dateutils  settrackeruri  replaceall  apppath  seterrorcode  parsedateoozietz  resourcexmlname  actionxml  seterrormessage  settimeout  coord  actionnominaltime  consoleurl  gettestcasedir  coordinatoraction  action  setcreatedtime  missdeps  actionnum  trackeruri   pass expected values  #testdir  errormessage  getactionnominaltime  setconsoleurl  setexternalstatus   add some attributes  testdir  setmissingdependencies  addrecordtocoordjobtable  _testgetactionssubset  coordinatorjob  createcoordaction  coord-action-get.xml  file://#testdir/2009/29/_success#file://#testdir/2009/22/_success#file://#testdir/2009/15/_success#file://#testdir/2009/08/_success  dummycreationtime   insert the action  insertrecordcoordaction  externalstatus  job  getcoordactionxml  getfstestcasedir
__label__nflaky release  assert  false  get  connection  assert  assert  true  assert  not  null  get  entry8  set  max  per  route  entry9  entry6  entry7  entry4  entry5  test  max  limits  entry2  entry3  get  leased  conn3  conn2  entry1  conn1  assign  connection  somehost  pool  future7  future8  assert  equals  future9  totals  future3  assert  same  future4  is  done  future5  future6  future1  future2  mockito  otherhost  mock  lease  get  pending  get  total  stats  get  available  release  assertfalse  getconnection  assert  asserttrue  assertnotnull  get  entry8  setmaxperroute  entry9  entry6  entry7  entry4  entry5  testmaxlimits  entry2  entry3  getleased  conn3  conn2  entry1  conn1  assignconnection  somehost  pool  future7  future8  assertequals  future9  totals  future3  assertsame  future4  isdone  future5  future6  future1  future2  mockito  otherhost  mock  lease  getpending  gettotalstats  getavailable
__label__flaky read  fields  set  _test  get  bean2  to  byte  array  dos  test  serialization  baos  write  close  bean  readfields  set  _testget  bean2  tobytearray  dos  testserialization  baos  write  close  bean
__label__nflaky new  gauge  unsupported  add  average  time  for  s1  run  s1  avg  time  add  counter  get  verify  s1  test  add  info  add  test  number  of  ops  for  s1  add  gauge  g1  c1  rb  expect  metrics  exception  r  new  counter  mock  metrics  record  builder  s1  num  ops  test  add  by  name  snapshot  newgauge  unsupported add  average time for s1  run  s1avgtime  addcounter  get  verify  s1  test add  info  add  test  number of ops for s1  addgauge  g1  c1  rb  expectmetricsexception  r  newcounter  mockmetricsrecordbuilder  s1numops  testaddbyname  snapshot
__label__flaky action  dir  assert  false  delete  the  file  if  it  is  already  there  </prepare>  do  operations  <delete  path=\'  conf  get  file  system  fs  delete  test  for  delete  as  prepare  action  create  job  conf  test  delete  launcher  mapper  new  dir  <prepare>  \'/>  mkdirs  prepare  xml  exists  prepare  block  that  contains  delete  action  setup  launcher  uri  handler  conf  prepare  actions  driver  get  fs  test  case  dir  actiondir  assertfalse   delete the file if it is already there  </prepare>  dooperations  <delete path=\'  conf  getfilesystem  fs  delete   test for delete as prepare action  createjobconf  testdelete  launchermapper  newdir  <prepare>  \'/>  mkdirs  preparexml  exists   prepare block that contains delete action  setuplauncherurihandlerconf  prepareactionsdriver  getfstestcasedir
__label__nflaky valid1  valid2  assert  equals  test  valid  tags  equal  valid1  valid2  assertequals  testvalidtagsequal
__label__flaky handler  get  current  user  get  end  job  commit  failure  file  conf  staging  dir  to  application  attempt  id  when  assert  not  null  file  system  commit  job  get  clock  user  group  information  init  wait  for  it  handler  get  application  id  mock  committer  then  return  get  event  handler  get  and  clear  event  handle  get  end  job  commit  success  file  mr  apps  job  id  stop  mock  start  commit  file  mr  job  config  test  basic  get  application  id  assert  false  converter  utils  fs  mock  job  context  get  application  attempt  id  assert  true  get  verify  appattempt_1234567890000_0001_0  from  yarn  get  short  user  name  set  get  start  job  commit  file  end  commit  failure  file  e  to  yarn  start  mock  clock  any  end  commit  success  file  type  converter  mock  context  exists  to  string  user  attemptid  handler  getcurrentuser  getendjobcommitfailurefile  conf  stagingdir  toapplicationattemptid  when  assertnotnull  filesystem  commitjob  getclock  usergroupinformation  init  waitforithandler  getapplicationid  mockcommitter  thenreturn  geteventhandler  getandclearevent  handle  getendjobcommitsuccessfile  mrapps  jobid  stop  mock  startcommitfile  mrjobconfig  testbasic  getapplicationid  assertfalse  converterutils  fs  mockjobcontext  getapplicationattemptid  asserttrue  get  verify  appattempt_1234567890000_0001_0  fromyarn  getshortusername  set  getstartjobcommitfile  endcommitfailurefile  e  toyarn  start  mockclock  any  endcommitsuccessfile  typeconverter  mockcontext  exists  tostring  user  attemptid
__label__nflaky store  password  get  resource  to  char  array  set  want  client  auth  server  socket  new  single  thread  executor  executors  server  ssl  context  get  server  socket  factory  assert  bind  assert  not  null  nopassword  client  principal  create  time  unit  ssl  context  builder  /test-client.p12  write  get  peer  principal  localhost  start  handshake  read  local  port  load  key  material  load  trust  material  resource2  input  stream  set  so  timeout  test  ssl  handshake  client  unauthenticated  get  input  stream  /test-server.p12  resource1  accept  create  socket  client  ssl  context  timeout  get  local  port  submit  session  client  socket  flush  key  password  get  output  stream  close  connect  assert  equals  call  get  socket  factory  assert  null  build  future  to  milliseconds  int  bound  get  output  stream  socket  get  session  create  server  socket  storepassword  getresource  tochararray  setwantclientauth  serversocket  newsinglethreadexecutor  executors  serversslcontext  getserversocketfactory  assert  bind  assertnotnull  nopassword  clientprincipal  create  timeunit  sslcontextbuilder  /test-client.p12  write  getpeerprincipal  localhost  starthandshake  read  localport  loadkeymaterial  loadtrustmaterial  resource2  inputstream  setsotimeout  testsslhandshakeclientunauthenticated  getinputstream  /test-server.p12  resource1  accept  createsocket  clientsslcontext  timeout  getlocalport  submit  session  clientsocket  flush  keypassword  get  outputstream  close  connect  assertequals  call  getsocketfactory  assertnull  build  future  tomillisecondsintbound  getoutputstream  socket  getsession  createserversocket
__label__flaky bundle  job  get  executor  add  record  to  bundle  job  table  get  id  assert  equals  get  status  execute  test  bundle  start1  call  sleep  services  size  assert  not  null  get  bundle  actions  get  executor  is  critical  job  job  get  bundle  id  jpa  service  actions  bundlejobgetexecutor  addrecordtobundlejobtable  getid  assertequals  getstatus  execute  testbundlestart1  call  sleep  services  size  assertnotnull  get  bundleactionsgetexecutor  iscritical  job  job  getbundleid  jpaservice  actions
__label__nflaky testing  stale  checksum  get  checksum  file  checksum  didn\'t  change  on  disk  testing  1  2  3  get  bytes  get  raw  file  system  out  write  a  file  to  generate  checksum  assert  true  test_  root_  dir  assert  not  null  get  file  status  create  got  checksum  error  write  close  stat  ce  e  test  corrupt  checksum  assert  equals  set  verify  checksum  checksum  path  str  local  fs  test  path  read  file  alter  file  directly  so  checksum  is  invalid  exists  test  corrupted  checksum  testing stale checksum  getchecksumfile   checksum didn\'t change on disk  testing 1 2 3  getbytes  getrawfilesystem  out   write a file to generate checksum  asserttrue  test_root_dir  assertnotnull  getfilestatus  create  got checksum error  write  close  stat  ce  e  testcorruptchecksum  assertequals  setverifychecksum  checksumpath  str  localfs  testpath  readfile   alter file directly so checksum is invalid  exists  testcorruptedchecksum
__label__flaky date  consistency  list_  prepend  all  to  script  executor  should_dsl_update_list_prepend  all  session  local_  one  given  update  simple  eq  consistencylist  as  list  contains  exactly  quorum  when  get  list  of  where  id  row  table  execute  script  template  random  utils  manager  one  next  long  assert  that  two  execute  simple  entity/insert_single_row.cql  immutable  map  select  consistencylist  from  simple  where  id  =  then  long  build  date  key  from  base  table  consistency  list  dsl  three  date  consistencylist_prependallto  scriptexecutor  should_dsl_update_list_prependall  session  local_one   given  update  simple  eq  consistencylist  aslist  containsexactly  quorum   when  getlist  of  where  id  row  table  executescripttemplate  randomutils  manager  one  nextlong  assertthat  two  execute  simpleentity/insert_single_row.cql  immutablemap  select consistencylist from simple where id =    then  long  builddatekey  frombasetable  consistencylist  dsl  three
__label__nflaky get  stats  release  sleep  assert  update  expiry  assert  true  stats  assert  not  null  get  of  time  unit  verify  collections  close  time  value  get  leased  singleton  test  create  new  if  expired  entry1  conn1  assign  connection  somehost  pool  assert  equals  totals  is  done  thread  future1  get  routes  future2  mockito  close  mode  mock  lease  get  total  stats  get  available  getstats  release  sleep  assert  updateexpiry  asserttrue  stats  assertnotnull  get  of  timeunit  verify  collections  close  timevalue  getleased  singleton  testcreatenewifexpired  entry1  conn1  assignconnection  somehost  pool  assertequals  totals  isdone  thread  future1  getroutes  future2  mockito  closemode  mock  lease  gettotalstats  getavailable
__label__flaky cluster  init  buffer  verify  that  full  blocks  are  sane  test  complex  flush  conf  fs  system  create  file  simulated  storage  exception  :  hflush  create  a  new  file.  close  write  /complex  flush.dat  check  file  read  2  created  file  complex  flush.dat  print  stack  trace  e  throwable  :  start  get  file  system  file  contents  stm  append  test  util  check  full  file  verify  that  entire  file  is  good  throwable  :  build  simulated  fs  dataset  file1  shutdown  set  boolean  cluster  initbuffer   verify that full blocks are sane  testcomplexflush  conf  fs  system  createfile  simulatedstorage  exception :  hflush   create a new file.  close  write  /complexflush.dat  checkfile  read 2  created file complexflush.dat  printstacktrace  e  throwable :  start  getfilesystem  filecontents  stm  appendtestutil  checkfullfile   verify that entire file is good  throwable :   build  simulatedfsdataset  file1  shutdown  setboolean
__label__nflaky contains  stdout  assert  true  utf8  classpath  to  byte  array  prints  the  classpath  test  help  short  str  out  main  -h  stderr  contains  stdout  asserttrue  utf8  classpath  tobytearray  prints the classpath  testhelpshort  strout  main  -h  stderr
__label__flaky callable2  callable3  callables  test  serial  concurrency  limit  callable1  callable4  callable5  type  queue  serial  math  as  list  queueservice  min  assert  true  get  second  batch  test  serial  concurrency  limit  serial  concurrency  limit  wait  for  exec_  order  c  services  long  arrays  evaluate  first  callable2  callable3  callables  testserialconcurrencylimit  callable1  callable4  callable5  type  queueserial  math  aslist  queueservice  min  asserttrue  get  secondbatch  testserialconcurrencylimit  serialconcurrencylimit  waitfor  exec_order  c  services  long  arrays  evaluate  first
__label__nflaky do  test  test  isbn  9784567890123  dotest  testisbn  9784567890123
__label__flaky cluster  conf  run  exitcode  args=  fs  input  checker  as  list  get  path  options  runner  mkdir  -get  fname  create  local  file  count  stringify  exception  get  file  system  /test/get  files=  /  dfs  shell  num  data  nodes  files  set  log  level2  all  arrays  shutdown  copy  from  local  file  dst  show  localf  delete  substring  test  get  assert  true  test_  root_  dir  string  utils  corruptedcontent  root  close  localfcontent  dfs  test  util  corrupt  find  and  modify  the  block  files  e  test  get.txt  assert  equals  get  block  files  set  conf  args  remotef  build  -ignore  crc  read  file  to  string  char  at  cluster  conf  run  exitcode  args=  fsinputchecker  aslist  getpath  options  runner  mkdir  -get  fname  createlocalfile  count  stringifyexception  getfilesystem  /test/get  files=  /  dfs  shell  numdatanodes  files  setloglevel2all  arrays  shutdown  copyfromlocalfile  dst  show  localf  delete  substring  testget  asserttrue  test_root_dir  stringutils  corruptedcontent  root  close  localfcontent  dfstestutil  corrupt   find and modify the block files  e  testget.txt  assertequals  getblockfiles  setconf  args  remotef  build  -ignorecrc  readfile  tostring  charat
__label__nflaky add  header  /_non_existing_url  http  constants  request  ninja  constant  core  matchers  equal  to  assert  equals  message  assert  that  make  request  url  path  assert  response  get  test  that  not  found  works  json  payload  json  as  test  server  url  addheader  /_non_existing_url  httpconstants  request  ninjaconstant  corematchers  equalto  assertequals  message  assertthat  makerequest  url  path  assert  response  get  testthatnotfoundworksjson  payloadjsonas  testserverurl
__label__flaky check  for  resolved  conf  test  dry  run  push  dependencies  e  action  property  action  coord-job-for-action-input-check.xml  create  action  element  element  list  dry  run  coord  print  stack  trace  workflow  populate  table  get  child  parse  xml  hcat  dependency  fail  coordinator  job  get  children  get  namespace  file:// test  dir/2009/29  coord  command  utils  job  add  record  to  coord  job  table  for  waiting  make  sure  conf  is  not  resolved  as  dependencies  are  not  met  set  push  missing  dependencies  configuration  ${coord:data  in(\'  a\')}  app  path  create  coordinator  action  bean  action  xml  coord  default  coord-action-for-action-input-check.xml  get  tablename  value  action  bean  table  xml  utils  e  newaction  xml  get  message  assert  equals  e1  e2  ${coord:data  out(\'  local_  a\')}  get  value  make  the  dependencies  available  config  elem  file:// test  dir/2009/29 file:// test  dir/2009/22 file:// test  dir/2009/15 file:// test  dir/2009/08  get  push  missing  dependencies  get  coord  action  xml  action  xml  only  to  check  whether  coord  conf  got  resolved  or  not  db  get  fs  test  case  dir   check for resolved conf  testdryrunpushdependencies  eaction  property  action  coord-job-for-action-input-check.xml  createactionelement  elementlist  dryruncoord  printstacktrace  workflow  populatetable  getchild  parsexml  hcatdependency  fail  coordinatorjob  getchildren  getnamespace  file:// testdir/2009/29  coordcommandutils  job  addrecordtocoordjobtableforwaiting   make sure conf is not resolved as dependencies are not met  setpushmissingdependencies  configuration  ${coord:datain(\'a\')}  apppath  createcoordinatoractionbean  actionxml  coord  default  coord-action-for-action-input-check.xml  get  tablename  value  actionbean  table  xmlutils  e  newactionxml  getmessage  assertequals  e1  e2  ${coord:dataout(\'local_a\')}  getvalue   make the dependencies available  configelem  file:// testdir/2009/29 file:// testdir/2009/22 file:// testdir/2009/15 file:// testdir/2009/08  getpushmissingdependencies  getcoordactionxml   actionxml only to check whether coord conf got resolved or not  db  getfstestcasedir
__label__nflaky keep  alive  assert  http  status  response  assert  false  context  no  content  use  http  1.0  reuse  strategy  test  no  content  response  http10  set  protocol  version  http  version  keepalive  assert  httpstatus  response  assertfalse  context  no content   use http 1.0  reusestrategy  testnocontentresponsehttp10  setprotocolversion  httpversion
__label__flaky i_dont_exist  test  automatic  creation  of  column  family  get  column  family  new  builder  togglz  test  keyspace  test  cluster  assert  null  column  family  column  family  name  build  cassandra  state  repository  assert  not  null  auto  create  column  family  set  thrift  port  describe  keyspace  i_dont_exist  testautomaticcreationofcolumnfamily  getcolumnfamily  newbuilder  togglztest  keyspace  test cluster  assertnull  columnfamily  columnfamilyname  build  cassandrastaterepository  assertnotnull  autocreatecolumnfamily  setthriftport  describekeyspace
__label__nflaky get  long  set  long  configuration  assert  equals  value  test  long  getlong  setlong  configuration  assertequals  value  testlong
__label__flaky init  ${  hour}  ${  year}  coord  el  functions  ${  minute}  assert  equals  should  throw  exception  beacuse  coord-job-submit-freq  doesn\'t  resolve  year/  month/  day  ${  day}  test  uri  vars  fail  eval  eval  and  wrap  expr  *  public  void  test  setup()  throws  exception  {  services  =  new  services();  *  services.init();  }  coord-job-submit-freq  coord-job-submit-nofuncs  ${  month}  init  ${hour}  ${year}  coordelfunctions  ${minute}  assertequals  should throw exception beacuse coord-job-submit-freq doesn\'t resolve year/month/day  ${day}  testurivars  fail  eval  evalandwrap  expr         * public void testsetup() throws exception { services = new services();       * services.init(); }         coord-job-submit-freq  coord-job-submit-nofuncs  ${month}
__label__nflaky uuid  param  parser  get  parsed  type  parse  parameter  asdfasdf  is  matchers  assert  that  null  value  param1  fe45481f-ed31-40e4-9bca-9cec383302c2  from  string  uuid  test  uuid  param  parser  validation    uuidparamparser  getparsedtype  parseparameter  asdfasdf  is  matchers  assertthat  nullvalue  param1  fe45481f-ed31-40e4-9bca-9cec383302c2  fromstring  uuid  testuuidparamparser  validation
__label__flaky delete  list  add  action  to  delete  bulk  del  rerun  cmd  add  record  to  wf  action  table  should  not  be  found  test  bulk  updates  deletes  check  for  update  after  running  bulk  jpa.  job  should  be  updated  from  killed  ->  runing  get  id  workflow  instance  check  for  non  existence  after  running  bulk  jpa  add  record  to  wf  job  table  get  error  code  assert  not  null  get  action  add  job  to  update  workflow  job  jex  update  list  add  get  status  str  set  delete  list  running  assert  equals  execute  set  status  1  services  fail  set  update  list  workflow  action  error  code  job  jpa  service  deletelist   add action to delete  bulkdelreruncmd  addrecordtowfactiontable   should not be found  testbulkupdatesdeletes   check for update after running bulkjpa. job should be updated from killed -> runing  getid  workflowinstance   check for non existence after running bulkjpa  addrecordtowfjobtable  geterrorcode  assertnotnull  get  action   add job to update  workflowjob  jex  updatelist  add  getstatusstr  setdeletelist  running  assertequals  execute  setstatus  1  services  fail  setupdatelist  workflowaction  errorcode  job  jpaservice
__label__nflaky file  file  file  item  context.get  parameter  as  file  item  ninja  test  browser  let\'s  upload  a  simple  txt  file...  str  file  str  file2  fileitem  sb  result  compute  excepted  result  file  src/test/resources/test_for_upload_2.txt  upload  finish  auto  file  file  items  file2  src/test/resources/test_for_upload.txt  fileitems  get  server  address  upload  files  inputstream  file  inputstream  assert  equals  file  test  that  upload  works  io  utils  inputstreams  let\'s  see  if  that  has  worked...  file2  to  string  files  get  parameter  as  file  item  append  files  files  inputstream  file2  file     file fileitem   context.getparameterasfileitem  ninjatestbrowser   let\'s upload a simple txt file...      strfile  strfile2  fileitem    sb  result   compute excepted result  file  src/test/resources/test_for_upload_2.txt  uploadfinishauto   file fileitems  file2    src/test/resources/test_for_upload.txt  fileitems    getserveraddress  uploadfiles  inputstream     file inputstream  assertequals   file  testthatuploadworks  ioutils  inputstreams     let\'s see if that has worked...  file2  tostring  files    getparameterasfileitem    append   files   files inputstream   file2
__label__flaky map-reduce  yarn.resourcemanager.address  execute  while  job  tracker  is  shutdown  add  record  to  wf  action  table  make  the  max  number  of  retries  lower  so  the  test  won\'t  take  as  long  conf  workflow  instance  it  should  now  continue  and  finish  with  succeeded  get  job  context  wait  for  test  action  check  transient  during  launcher  init  get  status  str  job0  job2  job1  running  parse  xml  destroy  mapper  id  execute  job  id  1  max  retries  disable  action  checker  service  so  it  doesn\'t  interfere  by  triggering  any  extra  action  check  x  commands  workflow  action  suspended  succeeded  action  id  evaluate  job  id  set  classes  to  be  excluded  launcher  id  start_  manual  assert  false  action  executor  user.name  get  id  get  external  id  action1a  create  base  hadoop  conf  has  id  swap  create  job  conf  action1b  is  successful  add  record  to  wf  job  table  get  retries  assert  true  launcher  mapper  get  when  using  yarn   skip  this  test  because  it  relies  on  shutting  down  the  job  tracker   which  isn\'t  used  in  yarn  workflow  job  now   shutdown  the  job  tracker  to  pretend  it  has  gone  down  during  the  launcher  job  launcher  job  get  conf  xml  utils  for  name  wf  action  get  cmd  oozie.action.retries.max  org.apache.oozie.service.  action  checker  service  assert  equals  services  mr  job  get  external  status  integer  call  original  launcher  id  services  create  job  client  set  system  property  equals  to  string  action0  job  client  action1  action2  jpa  service  user  action3  action4  is  complete  action5  map-reduce  yarn.resourcemanager.address  executewhilejobtrackerisshutdown  addrecordtowfactiontable   make the max number of retries lower so the test won\'t take as long  conf  workflowinstance   it should now continue and finish with succeeded  getjob  context  waitfor  testactionchecktransientduringlauncher  init  getstatusstr  job0  job2  job1  running  parsexml  destroy  mapperid  execute  jobid  1  maxretries   disable actioncheckerservice so it doesn\'t interfere by triggering any extra actioncheckxcommands  workflowaction  suspended  succeeded  actionid  evaluate  jobid  setclassestobeexcluded  launcherid  start_manual  assertfalse  actionexecutor  user.name  getid  getexternalid  action1a  createbasehadoopconf  hasidswap  createjobconf  action1b  issuccessful  addrecordtowfjobtable  getretries  asserttrue  launchermapper  get   when using yarn  skip this test because it relies on shutting down the job tracker  which isn\'t used in yarn  workflowjob   now  shutdown the job tracker to pretend it has gone down during the launcher job  launcherjob  getconf  xmlutils  forname  wfactiongetcmd  oozie.action.retries.max  org.apache.oozie.service.actioncheckerservice  assertequals  services  mrjob  getexternalstatus  integer  call  originallauncherid  services  createjobclient  setsystemproperty  equals  tostring  action0  jobclient  action1  action2  jpaservice  user  action3  action4  iscomplete  action5
__label__nflaky cluster  failover  by  session  expiration  ======  restarting  server  ======  failing  over  by  session  expiration  ha  service  state  wait  for  server  down  host  port  wait  for  server  up  graceful  failovers  info  log  failover  by  bad  health  stop  server  connection_  timeout  start  wait  for  health  state  graceful  failover  to  you  get  zkfc  test  one  of  everything  set  healthy  wait  for  ha  state  start  server  state  restart  zk  expire  and  verify  failover  cluster   failover by session expiration  ====== restarting server  ====== failing over by session expiration  haservicestate  waitforserverdown  hostport  waitforserverup   graceful failovers  info  log   failover by bad health  stopserver  connection_timeout  start  waitforhealthstate  gracefulfailovertoyou  getzkfc  testoneofeverything  sethealthy  waitforhastate  startserver  state   restart zk  expireandverifyfailover
__label__flaky check  coord  actions  get  id  date  utils  parse  date  oozie  tz  add  record  to  coord  job  table  2009-03-06  t10:00  z  call  coordinator  job  pause  time  2009-03-06  t10:08  z  start  time  end  time  job  test  action  mater  with  pause  time2  2009-03-06  t10:14  z  checkcoordactions  getid  dateutils  parsedateoozietz  addrecordtocoordjobtable  2009-03-06t10:00z  call  coordinatorjob  pausetime  2009-03-06t10:08z  starttime  endtime  job  testactionmaterwithpausetime2  2009-03-06t10:14z
__label__nflaky value  of  assert  false  assert  equals  http  float  assert  assert  true  hash  code  equals  ver2  ver1  http  test  http  version  equality  http  version  valueof  assertfalse  assertequals  http  float  assert  asserttrue  hashcode  equals  ver2  ver1  http  testhttpversionequality  httpversion
__label__flaky test  exec_60  killed:  multiplier:  system  max  retries:  seconds  add  argument  avg  need  to  add  \""1\""  to  wait  the  requested  number  of  seconds  assert  true  start  time  however  if  the  increase  is  too  gradual   we  never  wait  long  enough  for  any  test  to  exit  normally  set  watchdog  cmd  line  killed  process  offset  multiplier  process  terminated  counter  system.out.println(offset  +  \"":  process  was  killed:  \""  +  watchdog.killed  process());  offset  start  elapsed  (avg  ms):  processes  terminated:  execute  integer  not  a  single  process  terminated  on  its  own  max  retries  watchdog  watchdog  killed  process  counter  system.out.println(offset  +  \"":  process  has  terminated:  \""  +  watchdog.killed  process());  current  time  millis  to  string  not  a  single  process  was  killed  by  the  watch  dog  ping  script  exec  watchdog  killed  the  process  testexec_60   killed:    multiplier:   system   maxretries:   seconds  addargument  avg   need to add \""1\"" to wait the requested number of seconds  asserttrue  starttime   however if the increase is too gradual  we never wait long enough for any test to exit normally  setwatchdog  cmdline  killedprocess  offsetmultiplier  processterminatedcounter   system.out.println(offset + \"": process was killed: \"" + watchdog.killedprocess());  offset  start   elapsed (avg ms):   processes terminated:   execute  integer  not a single process terminated on its own  maxretries  watchdog  watchdogkilledprocesscounter   system.out.println(offset + \"": process has terminated: \"" + watchdog.killedprocess());  currenttimemillis  tostring  not a single process was killed by the watch dog  pingscript  exec  watchdog killed the process
__label__nflaky server  server  set  call  id  and  retry  count  check  response  conf  run  put  assert  get  set  different  call  id  and  retry  count  for  the  next  call  client  get  call  retry  count  client  attach  a  listener  that  tracks  every  call  received  by  the  server.  addr  info  get  call  id  get  retry  count  next  call  id  rpc  kind  test  ipc  assert  return  values  start  rpc  request  assert  equals  next  int  create  call  get  connect  address  call  caller  test  call  id  and  retry  net  utils  override  client  to  store  the  call  info  and  check  response  stop  header  info  map  server  server  setcallidandretrycount  checkresponse  conf  run  put  assert  get   set different call id and retry count for the next call  client  getcallretrycount  client   attach a listener that tracks every call received by the server.  addr  info  getcallid  getretrycount  nextcallid  rpckind  testipc  assertreturnvalues  start  rpcrequest  assertequals  nextint  createcall  getconnectaddress  call  caller  testcallidandretry  netutils   override client to store the call info and check response  stop  header  infomap
__label__flaky aaa  create  table  get  cached  region  count  create  many  regions  for  the  table.  assert  false  conf  test_  util  h  table  now  we  enable  cached  prefetch.  test  region  cache  pre  warm  family  the  total  number  of  cached  regions  ==  region(\'aaa\"")  +  prefeched  regions.  bytes  create  multi  regions  get  connection  only  one  region  should  be  cached  if  the  cache  prefetch  is  disabled.  get  configuration  create  table:  assert  true  the  table  is  disabled  for  region  cache  prefetch  get  number  of  cached  region  is  incorrect  if  there  is  a  cache  miss   some  additional  regions  should  be  prefetched.  prefetch  region  number  table  get  the  configured  number  of  cache  read-ahead  regions  clear  region  cache  disable  region  cache  for  the  table.  h  connection  manager  bbb  abc  test  cache  prewarm  tablename  a  get  is  suppose  to  do  a  region  lookup  request  to  bytes  g  set  region  cache  prefetch  get  region  cache  prefetch  assert  equals  g2  g3  the  table  is  enabled  for  region  cache  prefetch  get  int  hbase.client.prefetch.limit  aaa  createtable  getcachedregioncount   create many regions for the table.  assertfalse  conf  test_util  htable   now we enable cached prefetch.  testregioncacheprewarm  family   the total number of cached regions == region(\'aaa\"") + prefeched regions.  bytes  createmultiregions  getconnection   only one region should be cached if the cache prefetch is disabled.  getconfiguration   create table:  asserttrue  the table is disabled for region cache prefetch  get  number of cached region is incorrect    if there is a cache miss  some additional regions should be prefetched.  prefetchregionnumber  table   get the configured number of cache read-ahead regions  clearregioncache   disable region cache for the table.  hconnectionmanager  bbb  abc  testcacheprewarm  tablename   a get is suppose to do a region lookup request  tobytes  g  setregioncacheprefetch  getregioncacheprefetch  assertequals  g2  g3  the table is enabled for region cache prefetch  getint  hbase.client.prefetch.limit
__label__nflaky test  build  initial  instance  set  path  assert  equals  dir  file  assert  true  build  get  used  create  new  file  set  klass  close  set  initial  used  testbuildinitial  instance  setpath  assertequals  dir  file  asserttrue  build  getused  createnewfile  setklass  close  setinitialused
__label__flaky cluster  data  dir  conf  dn  data  dirs  dir  check  permissions  on  directories  in  \'dfs.datanode.data.dir\'  test  local  dirs  local  fs  get  file  system  get  file  status  actual  dfs  config  keys  get  permission     while  expected  is  get  data  nodes  get  conf  permission  for  dir:  expected  assert  equals  perm  str  get  strings  get  local     is  cluster  datadir  conf  dn  datadirs  dir   check permissions on directories in \'dfs.datanode.data.dir\'  testlocaldirs  localfs  get  filesystem  getfilestatus  actual  dfsconfigkeys  getpermission    while expected is   getdatanodes  getconf  permission for dir:   expected  assertequals  permstr  getstrings  getlocal    is
__label__nflaky excludes  file  lazy  refresh  lazy  details:  no.  of  excluded  hosts  lazy  details  details:  no.  of  included  hosts  host2  get  excluded  hosts  finish  refresh  host3  details  get  lazy  loaded  host  details  write  close  details:  no.  of  excluded  hosts  test  lazy  refresh  includes  file  get  host  details  assert  equals  host1  lay  details:  no.  of  included  hosts  hfp  assert  null  host4  size  efw  get  included  hosts  ifw  lazy  host  details  should  be  null  excludesfile  lazyrefresh  lazydetails: no. of excluded hosts  lazydetails  details: no. of included hosts  host2    getexcludedhosts  finishrefresh  host3    details  getlazyloadedhostdetails  write  close  details: no. of excluded hosts  testlazyrefresh  includesfile  gethostdetails  assertequals  host1    laydetails: no. of included hosts  hfp  assertnull  host4    size  efw  getincludedhosts  ifw  lazy host details should be null
__label__flaky server  nanoseconds  request  +  response:  \%sms  string  system  abcdef  set  body  delay  elapsed  nanos  assert  true  nano  time  delay  response  connection  to  millis  read  in  open  connection  seconds  format  assert  equals  set  body  get  input  stream  elapsed  millis  /  enqueue  get  url  start  nanos  server  nanoseconds  request + response: \%sms  string  system  abcdef  setbodydelay  elapsednanos  asserttrue  nanotime  delayresponse  connection  tomillis  read  in  openconnection  seconds  format  assertequals  setbody  getinputstream  elapsedmillis  /  enqueue  geturl  startnanos
__label__nflaky http  headers  12  add  header  process  protocol  exception  should  have  been  thrown  chunked  interceptor  method  test  request  content  protocol  exception  request2  get  entity  request1  /  fail  assert  context  httpheaders  12  addheader  process  protocolexception should have been thrown  chunked  interceptor  method  testrequestcontentprotocolexception  request2  getentity  request1  /  fail  assert  context
__label__flaky add  node  def  enters  workflow  instance  get  status  as  list  wf  exits  test  wf  fail  with  running  nodes  end  signal  fails  a  b  f  start  assert  equals(1   kills.size());  j  assert  equals  1  size  <worklfow-app/>  arrays  job  /b/    addnode  def  enters  workflowinstance  getstatus  aslist  wf  exits  testwffailwithrunningnodes  end  signal  fails  a  b  f  start   assertequals(1  kills.size());  j  assertequals  1  size  <worklfow-app/>  arrays  job  /b/
__label__nflaky 1644  932  1644  932  masked_permission_value  permission_mask_map  get  sticky  bit  33700  -rw-r-t  fs  permission  has  sticky  bit  assert  equals  original_permission_value  test  int  permission  16804  drw-r--  17316  drw-r-t  permission_mask_maps  to  short   1644            932             1644            932  masked_permission_value  permission_mask_map  getstickybit   33700    -rw-r-t  fspermission  hasstickybit  assertequals  original_permission_value  testintpermission   16804    drw-r--   17316    drw-r-t  permission_mask_maps  toshort
__label__flaky play  verify  the  peer  received  what  was  expected.  android  okio  type_  data  header  entries  util  get  sink  out  accept  frame  flush  type_  headers  peer  variant  client  connection  buffer  write  close  take  frame  banana  a  b  syn  reply  set  variant  and  client  data  assert  equals  frame  count  syn_  stream  send  frame  client  sends  empty  data  server  doesnt  send  window  update  spdy3  play  it  back.  new  stream  play   verify the peer received what was expected.  android  okio  type_data  headerentries  util  getsink  out  acceptframe  flush  type_headers  peer  variant  client  connection  buffer  write  close  takeframe  banana  a  b  synreply  setvariantandclient   data  assertequals  framecount   syn_stream  sendframe  clientsendsemptydataserverdoesntsendwindowupdate  spdy3   play it back.  newstream
__label__nflaky result  sleep  set  daemon  t  future  get  start  time  unit  run  completed  test  async  timeout  thread  result  sleep  setdaemon  t  future  get  start  timeunit  run  completed  testasynctimeout  thread
__label__flaky date  downgrading  consistency  retry  policy  session  with  consistency  level  one  given  insert  select  *  from  simple  where  id  =  crud  when  id  row  should_insert_with_downgrading_consistency  value  log  asserter  prepare  log  level  for  driver  connection  is  not  null  random  utils  manager  one  next  long  assert  that  two  execute  assert  consistency  levels  with  retry  policy  then  long  build  date  key  entity  date  downgradingconsistencyretrypolicy  session  withconsistencylevel  one   given  insert  select * from simple where id =   crud   when  id  row  should_insert_with_downgrading_consistency  value  logasserter  prepareloglevelfordriverconnection  isnotnull  randomutils  manager  one  nextlong  assertthat  two  execute  assertconsistencylevels  withretrypolicy   then  long  builddatekey  entity
__label__nflaky current  thread  set  unlock  get  method  name  log  assert  false  start  lock  thread  assert  equals  run  acl  testname  test  try  with  resource  syntax  acquire  competing  thread  try  lock  thread  local  lock  assert  null  get  name  lock  join  assert  not  equals  currentthread  set  unlock  getmethodname  log  assertfalse  start  lockthread  assertequals  run  acl  testname  testtrywithresourcesyntax  acquire  competingthread  trylock  thread  locallock  assertnull  get  name  lock  join  assertnotequals
__label__flaky init  ${coord:data  out  partitions(\'  abcd\')}  -ve  test  coord  el  functions  ${coord:data  out  partitions(\'  abc\')}  set  variable  +ve  test  assert  equals  coord-job-submit-data  fail  test  data  out  partitions  ph1  eval  eval  and  wrap  should  throw  exception  because  data-in  is  not  defiend  expr  oozie.dataname.  abc  data-out  init  ${coord:dataoutpartitions(\'abcd\')}   -ve test  coordelfunctions  ${coord:dataoutpartitions(\'abc\')}  setvariable   +ve test  assertequals  coord-job-submit-data  fail  testdataoutpartitionsph1  eval  evalandwrap  should throw exception because data-in is not defiend  expr  oozie.dataname.abc  data-out
__label__nflaky advance  clock  tester  17177038848 8589467648 15232745472 6400417792 1 2805000 6261812   assert  equals  1234567 2345678 3456789 4567890  cpu  time  tracker  advance  sys  info  windows  refresh  and  cpu  usage  verify  information  has  not  been  refreshed  get  available  physical  memory  size  set  sysinfo  string  get  num  v  cores  used  17177038848 8589467648 15232745472 5400417792 1 2805000 6263012   info  str  derived  from  windows  shell  command  has  \\r   termination  verify  information  has  been  refreshed  get  cpu  usage  percentage   advance clock  tester  17177038848 8589467648 15232745472 6400417792 1 2805000 6261812   assertequals  1234567 2345678 3456789 4567890    cputimetracker  advance  sysinfowindows  refreshandcpuusage   verify information has not been refreshed  getavailablephysicalmemorysize  setsysinfostring  getnumvcoresused  17177038848 8589467648 15232745472 5400417792 1 2805000 6263012    info str derived from windows shell command has \\r  termination   verify information has been refreshed  getcpuusagepercentage
__label__flaky init  jms  topic  service  set  get  conf  not  allowed  in  default  get  message  destroy  services  setup  services  for  topic  expected  service  exception  fail  se  contains  invalidvalue  assert  true  test  incorrect  configuration  default  default=  init  jmstopicservice  set  getconf  not allowed in default  getmessage  destroy  services  setupservicesfortopic  expected service exception  fail  se  contains  invalidvalue  asserttrue  testincorrectconfigurationdefault  default=
__label__nflaky get  payload  content  read  value  of  get  stream  id  assert  equals  test  read  empty  frame  in  buffer  readable  channel  assert  assert  null  get  type  payload  frame  type  get  flags  frame  getpayloadcontent  read  valueof  getstreamid  assertequals  testreademptyframe  inbuffer  readablechannel  assert  assertnull  gettype  payload  frametype  getflags  frame
__label__flaky conn  set  request  method  is_  security_  enabled  /v0/admin/*  assert  true  json  content-type  collections  run  test  rest  constants  open  connection  contains  key  http  servlet  response  assert  equals  parse  user  get  input  stream  url  json  value  call  test  os  env  get  header  field  get  get  response  code  create  url  starts  with  conn  setrequestmethod  is_security_enabled  /v0/admin/*  asserttrue  json  content-type  collections  runtest  restconstants  openconnection  containskey  httpservletresponse  assertequals  parse  user  getinputstream  url  jsonvalue  call  testosenv  getheaderfield  get  getresponsecode  createurl  startswith
__label__nflaky user  with  spaces:group  assert  illegal  arguments  user  with  spaces:  group  with  spaces  conf  run  us^er  the  following  are  invalid  (exception  expected).  user:gr#oup  user:group  us!er  user:  group  with  spaces  /path  :group  hadoop_  shell_  missing_  default_  fs_  warning_  key  chown  enable  warning  :gr#oup  the  following  are  valid  only  on  windows.  set  conf  the  following  are  valid  (no  exception  expected).  :gr\%oup  :  group  with  spaces  user  with  spaces  user:gr\%oup  test  chown  user  and  group  validity  user  assert  valid  arguments  on  windows  set  boolean  user with spaces:group  assertillegalarguments  user with spaces:group with spaces  conf  run  us^er   the following are invalid (exception expected).  user:gr#oup  user:group  us!er  user:group with spaces  /path  :group  hadoop_shell_missing_default_fs_warning_key  chown  enablewarning  :gr#oup   the following are valid only on windows.  setconf   the following are valid (no exception expected).  :gr\%oup  :group with spaces  user with spaces  user:gr\%oup  testchownuserandgroupvalidity  user  assertvalidargumentsonwindows  setboolean
__label__flaky excludes  reflection  test  utils  -static/**  assert  false  get  field  unchecked  includes  foo.jar  static/**  -**/*.jar  as  list  included  deltas  and  new  entries  contains  resource  matcher  assert  true  templates/**  **/*.jar  arrays  excludes  reflectiontestutils  -static/**  assertfalse  getfield  unchecked  includes  foo.jar  static/**  -**/*.jar  aslist  includeddeltasandnewentries  contains  resourcematcher  asserttrue  templates/**  **/*.jar  arrays
__label__nflaky status  top_  optional_  resource  status  printer  assert  equals  verify  config  status  checker  get  highest  level  tc  optional  resource  print  do  configure  ia  context  ib  status  top_optional_resource  statusprinter  assertequals  verifyconfig  statuschecker  gethighestlevel  tc  optionalresource  print  doconfigure  ia  context  ib
__label__flaky localized  resource  localizer  event  handler  lr  conf  create  local  resource  request  rel  event2  rel  event1  notified  with  container  resource  failed  event.  rel  event3  container-3  releasing  the  resource.  registering  event  handlers.  assert  removed  after  the  failed  event.  resource  no  resource  request  is  initially  present  in  local  cache  lc2  lc1  dispatcher  lc3  exception.  test  contains  key  unchecked  localrsrc  handle  container-2  releases  the  resource  number  of  waiting  containers  should  be  1.  contains  stop  size  is  coming  prior  to  container-2\'s  release  call.  and  the  requesting  container  will  be  added  to  its  waiting  queue.  mock  c  id2  c  id3  c  id1  localized  path  test  local  resource  cache  req  event1  create  dispatcher  req  event3  localized  event  req  event2  local  resource  visibility  container  2  requesting  the  resource  times  assert  true  is  a  get  tracker  verify  making  sure  that  there  is  no  change  in  the  cache  after  the  release.  get  ref  count  resource  state  resource  failed  event  container  1  requesting  local  resource.  container  event  handler  send  container  resource  localized  event  to  waiting  containers.  new  container  id  verifying  container  resource  localized  event  .  testuser  get  message  assert  equals  failing  resource  localization  get  state  /tmp/file1  container-1  requesting  local  resource.  user  builder  utils  register  localizedresource  localizereventhandler  lr  conf  createlocalresourcerequest  relevent2  relevent1   notified with container resource failed event.  relevent3   container-3 releasing the resource.   registering event handlers.  assert   removed after the failed event.   resource   no resource request is initially present in local cache  lc2  lc1  dispatcher  lc3   exception.  test  containskey  unchecked  localrsrc  handle   container-2 releases the resource   number of waiting containers should be 1.  contains  stop  size   is coming prior to container-2\'s release call.   and the requesting container will be added to its waiting queue.  mock  cid2  cid3  cid1  localizedpath  testlocalresourcecache  reqevent1  createdispatcher  reqevent3  localizedevent  reqevent2  localresourcevisibility   container 2 requesting the resource  times  asserttrue  isa  get  tracker  verify   making sure that there is no change in the cache after the release.  getrefcount  resourcestate  resourcefailedevent   container 1 requesting local resource.  containereventhandler   send container resource localized event to waiting containers.  newcontainerid   verifying containerresourcelocalizedevent .  testuser  getmessage  assertequals   failing resource localization  getstate  /tmp/file1   container-1 requesting local resource.  user  builderutils  register
__label__nflaky create  multi  part  email  with  content  /////////////////////////////////////////////////////////////////////  mail  simple  body  text  set  only  text:  assert  true  set  body  html  test  create  multi  part  email  with  content  commonsmail  helper  <br>simple  body  text<br>  set  body  text  multi  part  email  createmultipartemailwithcontent   /////////////////////////////////////////////////////////////////////  mail  simple body text   set only text:  asserttrue  setbodyhtml  testcreatemultipartemailwithcontent  commonsmailhelper  <br>simple body text<br>  setbodytext  multipartemail
__label__flaky get  connection  context  get  event  message  end  date  conf  parse  date  utc  date  utils  get  status  set  error  code  wf-app-name1  set  error  message  get  end  time  ca  job  id1  ca  id1  coordinator  action  2012-07-22  t00:00  z  dummy  error  get  start  time  message  type  2011-07-11  t00:00  z  init  print  stack  trace  get  text  fail  contains  create  consumer  app  type  start  date  get  parent  id  get  app  type  cae  session  coord  event  listener  assert  false  jms  messaging  utils  get  event  status  get  user  event  status  get  id  coord  action  fail  message  create  session  get  topic  on  coordinator  action  event  get  error  code  jms  context  test  on  coordinator  job  failure  event  consumer  user1  missing  dependency  get  message  type  nominal  time  receive  get  app  name  e0101  e  get  message  assert  equals  message  set  end  time  session  get  error  message  getconnectioncontext  geteventmessage  enddate  conf  parsedateutc  dateutils  getstatus  seterrorcode  wf-app-name1  seterrormessage  getendtime  cajobid1  caid1  coordinatoraction  2012-07-22t00:00z  dummyerror  getstarttime  messagetype  2011-07-11t00:00z  init  printstacktrace  gettext  fail  contains  createconsumer  apptype  startdate  getparentid  getapptype  cae  session  coordeventlistener  assertfalse  jmsmessagingutils  geteventstatus  getuser  eventstatus  getid  coordactionfailmessage  createsession  gettopic  oncoordinatoractionevent  geterrorcode  jmscontext  testoncoordinatorjobfailureevent  consumer  user1  missingdependency  getmessagetype  nominaltime  receive  getappname  e0101  e  getmessage  assertequals  message  setendtime  session  geterrormessage
__label__nflaky assert  to  string  assert  equals  buffer  append  test  append  null  byte  array    assert  tostring  assertequals  buffer  append  testappendnullbytearray
__label__flaky init  .dataout.  abc.unresolved  coord  el  functions  .datain.  abc.unresolved  set  variable  assert  equals  coord-action-start  eval  ${coord:table  in(\'  abc\')}  eval  and  wrap  .dataout.  abc  clicks  test  table  .datain.  abc  expr  ${coord:table  out(\'  abc\')}  boolean  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us  init  .dataout.abc.unresolved  coordelfunctions  .datain.abc.unresolved  setvariable  assertequals  coord-action-start  eval  ${coord:tablein(\'abc\')}  evalandwrap  .dataout.abc  clicks  testtable  .datain.abc  expr  ${coord:tableout(\'abc\')}  boolean  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us
__label__nflaky wait  for  the  async  task  to  finish  test  sync  generation  policy  k1  assert  equals  get  next  trigger  a  prefill  (5)  and  an  async  refill  (6)  the  prefill  to  the  low  watermark   1  consumed  by  get  next())  wait  for  refill  assert  wait  a  while  to  make  sure  that  no  async  refills  are  triggered  get  top  filler  vq  take  another  value   queue  is  still  above  the  watermark  test  no  refill  shutdown   wait for the async task to finish  test  syncgenerationpolicy  k1  assertequals  getnext   trigger a prefill (5) and an async refill (6)   the prefill to the low watermark  1 consumed by getnext())  waitforrefill  assert   wait a while to make sure that no async refills are triggered  gettop  filler  vq   take another value  queue is still above the watermark  testnorefill  shutdown
__label__flaky cluster  close  the  file  and  the  counter  should  go  to  zero.  dm  dn  get  block  manager  fs  test  blocks  scheduled  counter  wait  active  out  open  a  file  an  write  a  few  bytes:  hflush  get  datanode  manager  get  /test  block  scheduled  counter  create  write  fetch  datanodes  close  dn  list  flush  to  make  sure  a  block  is  allocated.  assert  equals  get  file  system  get  wrapped  stream  build  get  blocks  scheduled  get  namesystem  cluster   close the file and the counter should go to zero.  dm  dn  getblockmanager  fs  testblocksscheduledcounter  waitactive  out   open a file an write a few bytes:  hflush  getdatanodemanager  get  /testblockscheduledcounter  create  write  fetchdatanodes  close  dnlist   flush to make sure a block is allocated.  assertequals  getfilesystem  getwrappedstream  build  getblocksscheduled  getnamesystem
__label__nflaky get  bytes  transferred  rw  stuff;  codec  test  utils  more  stuff;  channel  assert  inbuf  get  channel  pos  test  basic  decoding  file  stuff;  more  stuff;  a  lot  more  stuff!  a  lot  more  stuff!!!  close  fchannel  is  completed  testfile  standard  charsets  length  bytes  read  create  temp  file  assert  equals  decoder  transfer  read  from  file  -----------------  file  channel  part  testing  ---------------------------  metrics  getbytestransferred  rw  stuff;   codectestutils  more stuff;   channel  assert  inbuf  getchannel  pos  testbasicdecodingfile  stuff; more stuff; a lot more stuff!  a lot more stuff!!!  close  fchannel  iscompleted  testfile  standardcharsets  length  bytesread  createtempfile  assertequals  decoder  transfer  readfromfile   ----------------- filechannel part testing ---------------------------   metrics
__label__flaky log4j  file  init  current  thread  get  test  case  conf  dir  x  log  service  get  resource  as  stream  ls  assert  false  cl  destroy  is  assert  equals  test  default  log4j  from  config  dir  get  log4j  properties  thread  io  utils  assert  test-oozie-log4j.properties  get  from  classpath  get  context  class  loader  copy  stream  log4jfile  init  currentthread  gettestcaseconfdir  xlogservice  getresourceasstream  ls  assertfalse  cl  destroy  is  assertequals  testdefaultlog4jfromconfigdir  getlog4jproperties  thread  ioutils  assert  test-oozie-log4j.properties  getfromclasspath  getcontextclassloader  copystream
__label__nflaky fail  adapter  does  not  support  assert  adapter  framework  call  method  should  not  have  been  called  run  tests  new  framework  and  set  adapter  add  test  execute  is  request  supported  fail  adapterdoesnotsupport  assert  adapter  framework  callmethod should not have been called  runtests  newframeworkandsetadapter  addtest  execute  isrequestsupported
__label__flaky cluster  build  change  block  len  num  data  nodes  test  truncated  block  test  extended  block  shutdown  test  replicate  len  mismatched  block  wait  active  cluster  build  changeblocklen  numdatanodes   test truncated block   test extended block  shutdown  testreplicatelenmismatchedblock  waitactive
__label__nflaky next  then  build  route  ninja  constant  equal  to  get  filter  chain  when  filter  chain  result  get  context  get  provider  verify  injector  when  then  return  dummy  filter  filter  provider  filters  matchers  assert  that  ninja  base  directory  resolver  /  with  different  setup  that  uses  com.example  packages  and  thus  reads  the  filters  there  route  mockito  expected  result  get  mock  route  builder  com.example  get  instance  ninja  properties  test  global  filters  next   then  buildroute  ninjaconstant  equalto  getfilterchain  when  filterchain  result  get  context  getprovider  verify  injector   when  thenreturn  dummyfilter  filterprovider  filters  matchers  assertthat  ninjabasedirectoryresolver  /  with   different setup that uses com.example packages and thus reads the filters there  route  mockito  expectedresult  get  mock  routebuilder  com.example  getinstance  ninjaproperties  testglobalfilters
__label__flaky cluster  name  node  adapter  ns  racks  conf  wait  for  replication  /rack2  /rack1  fs  create  file  test  under  replicated  uses  new  racks  all  datanodes  are  on  the  same  rack  sure  at  least  one  of  the  hosts  on  the  new  rack  is  used.  dfs  test  util  b  start  data  nodes  get  conf  new  racks  file  path  get  file  system  set  replication  replication_  factor  get  name  node  /test  file  build  num  data  nodes  create  a  file  with  one  block  get  first  block  shutdown  get  namesystem  *  creates  a  block  with  all  datanodes  on  the  same  rack.  add  additional  *  datanodes  on  a  different  rack  and  increase  the  replication  factor   *  making  sure  there  are  enough  replicas  across  racks.  if  the  previous  *  test  passes  this  one  should  too   however  this  test  may  pass  when  *  the  previous  one  fails  because  the  replication  code  is  explicitly  *  triggered  by  setting  the  replication  factor.  cluster  namenodeadapter  ns  racks  conf  waitforreplication  /rack2  /rack1  fs  createfile  testunderreplicatedusesnewracks   all datanodes are on the same rack   sure at least one of the hosts on the new rack is used.  dfstestutil  b  startdatanodes  getconf  newracks  filepath  getfilesystem  setreplication  replication_factor  getnamenode  /testfile  build  numdatanodes   create a file with one block  getfirstblock  shutdown  getnamesystem       * creates a block with all datanodes on the same rack. add additional     * datanodes on a different rack and increase the replication factor       * making sure there are enough replicas across racks. if the previous     * test passes this one should too  however this test may pass when     * the previous one fails because the replication code is explicitly     * triggered by setting the replication factor.
__label__nflaky get  name  context  cookie1  context  cookie2  test  against  cookie  that  is  really  there  http  servlet  request  cookie1  when  get  cookie  cookie2  does  not  exist  get  cookies  context  get  cookie  test  servlet  cookies  servlet  cookie1  test  2  against  cookie  that  is  really  there  servlet  cookie2  init  then  return  servlet  context  assert  equals  the  value1  the  value2  negative  test:  get  value  assert  null  http  servlet  response  getname  contextcookie1  contextcookie2   test  against cookie that is really there  httpservletrequest  cookie1  when  getcookie  cookie2  doesnotexist  getcookies  context  getcookietest  servletcookies  servletcookie1   test 2 against cookie that is really there  servletcookie2  init  thenreturn  servletcontext  assertequals  thevalue1  thevalue2   negative test:  getvalue  assertnull  httpservletresponse
__label__flaky cluster  log  conf  check  result  current  name  node  dirs  create  empty  dirs  num  dirs  startup  option  this  test  requires  that  \""current\""  directory  not  change  after  *  the  upgrade.  actually  it  is  ok  for  those  contents  to  change.  *  for  now  disabling  block  verification  so  that  the  contents  are  *  not  changed.  startup  option  manage  data  dfs  dirs  dfs  config  keys  finalize  with  existing  previous  dir  previous  format  test  finalize  initialize  storage  state  conf  set  int  get  strings  upgrade  utilities  build  create  name  node  storage  dirs  data  node  dirs  manage  name  dfs  dirs  create  data  node  storage  dirs  initialize  finalize  without  existing  previous  dir  finalize  cluster  shutdown  cluster  log  conf  checkresult  current  namenodedirs  createemptydirs  numdirs  startupoption   this test requires that \""current\"" directory not change after         * the upgrade. actually it is ok for those contents to change.         * for now disabling block verification so that the contents are          * not changed.           startupoption  managedatadfsdirs  dfsconfigkeys  finalize with existing previous dir  previous  format  testfinalize  initializestoragestateconf  setint  getstrings  upgradeutilities  build  createnamenodestoragedirs  datanodedirs  managenamedfsdirs  createdatanodestoragedirs  initialize  finalize without existing previous dir  finalizecluster  shutdown
__label__nflaky cursor  parse  exception  should  have  been  thrown  test  invalid  http  version  parsing  clear  length  htt  http/1  crap  fail  assert  http/crap  parse  protocol  version  http/1234  http/whatever.whatever  whatever  http/1.  http/1.whatever  whatever  buffer  append  cursor  parseexception should have been thrown  testinvalidhttpversionparsing  clear  length  htt  http/1        crap  fail  assert  http/crap  parseprotocolversion  http/1234  http/whatever.whatever whatever  http/1.  http/1.whatever whatever  buffer  append
__label__flaky cluster  adding  3rd  region  server  adding  3rd  region  server.  test  table  should  have  20  regions  adding  4th  region  server  conf  wait  on  region  server  assert  regions  are  balanced  adding  2nd  region  server.  killing  the  3rd  region  server.  table  stop  region  server  debug  add  a  region  server  -  total  of  3  test  log  assert  equals  add  a  region  server  -  total  of  2  kill  a  region  server  -  total  of  2  verify  that  the  region  assignments  are  balanced  to  start  out  start  two  more  region  servers  -  total  of  4  adding  start  region  server  th  region  server  get  start  keys  test  rebalancing  cluster  adding 3rd region server  adding 3rd region server.  test table should have 20 regions  adding 4th region server  conf  waitonregionserver  assertregionsarebalanced  adding 2nd region server.  killing the 3rd region server.  table  stopregionserver  debug   add a region server - total of 3  test  log  assertequals   add a region server - total of 2   kill a region server - total of 2   verify that the region assignments are balanced to start out   start two more region servers - total of 4  adding   startregionserver  th region server  getstartkeys  testrebalancing
__label__nflaky get  component  count  size  now  tracker  assert  equals  remove  stale  components  empty0  live  keys  as  ordered  list  getcomponentcount  size  now  tracker  assertequals  removestalecomponents  empty0  livekeysasorderedlist
__label__flaky jcoord  bundle-  test  /v1/jobs  parse  date  utc  date  utils  action  status=  failed;startcreatedtime=2012-07-21  t00:00  z  test  single  record  split  failed  array  assert  not  null  get  coord1  create_  time  run  test  jbundle  json  tags  jaction  running  ;coordinators=  coord1;  assert  equals  to  gmt  string  call  size     bundle  name  to  string  _request  to  server  bulk  request  bundle=  jcoord  bundle-test  /v1/jobs  parsedateutc  dateutils  actionstatus=failed;startcreatedtime=2012-07-21t00:00z  testsinglerecord  split  failed  array  assertnotnull  get  coord1  create_time  runtest  jbundle  jsontags  jaction  running  ;coordinators=coord1;  assertequals  togmtstring  call  size      bundlename  tostring  _requesttoserver  bulkrequest  bundle=
__label__nflaky prepare  append  value  root  reader  block_  size  dos  conf  fs  build  value  get  bytes  out  nentry  advance  path  get  len  get  file  status  scanner  create  cube  close  write  value  key  set  at  end  in  j  class  long  writable  comparator  assert  equals  get  file  system  create  scanner  test  sorted  long  writable  prepare  append  key  entry  get  value  gz  name  get  length  writer  open  prepareappendvalue  root  reader  block_size  dos  conf  fs  buildvalue  getbytes  out  nentry  advance  path  getlen  getfilestatus  scanner  create  cube  close  write  value  key  set  atend  in  jclasslongwritablecomparator  assertequals  getfilesystem  createscanner  testsortedlongwritable  prepareappendkey  entry  getvalue  gz  name  getlength  writer  open
__label__flaky set  name  23  24  test  hours  in  day  25  2010-10-01  t00:00  z  coord  el  functions  utc  get  time  zone  2009-09-10  t23:59  z  coord-action-create  date  utils  test1  ${coord:hours  in  day(coord:hours  in  day(1))}  set  frequency  parse  date  oozie  tz  ds  eval  and  wrap  ${coord:hours  in  day(1)}  configure  evaluator  ${coord:hours  in  day(0)}  set  time  zone  europe/  london  time  unit  expr  set  end  of  duration  init  res  set  nominal  time  2009-11-01  t08:00  z  ${coord:hours  in  day(-2)}  2009-03-08  t08:00  z  ${coord:hours  in  day(-1)}  set  init  instance  assert  equals  set  type  set  actual  time  app  inst  2009-01-01  t08:00  z  america/  los_  angeles  set  time  unit  eval  2009-01-02  t00:00  z  sync  setname  23  24  testhoursinday  25  2010-10-01t00:00z  coordelfunctions  utc  gettimezone  2009-09-10t23:59z  coord-action-create  dateutils  test1  ${coord:hoursinday(coord:hoursinday(1))}  setfrequency  parsedateoozietz  ds  evalandwrap  ${coord:hoursinday(1)}  configureevaluator  ${coord:hoursinday(0)}  settimezone  europe/london  timeunit  expr  setendofduration  init  res  setnominaltime  2009-11-01t08:00z  ${coord:hoursinday(-2)}  2009-03-08t08:00z  ${coord:hoursinday(-1)}  setinitinstance  assertequals  settype  setactualtime  appinst  2009-01-01t08:00z  america/los_angeles  settimeunit  eval  2009-01-02t00:00z  sync
__label__nflaky bb  a  prop;  ignoring.  logging  event  get  log  logger  declare  property  make  a  configuration  file  with  2  final  properties  with  different  values  conf  test  final  warnings  multiple  override  logger  get  rendered  message  get  bytes  out  remove  appender  make  sure  the  appender  is  removed  add  appender  did  not  see  expected  string  inside  message  assert  true  add  resource  prop  get  overriding  a  final  parameter  should  cause  logging  get  root  logger  events  add  the  resource  -  this  should  produce  a  warning  end  config  attach  our  own  log  appender  so  we  can  verify  output  start  config  appender  assert  equals  in1  contains  should  see  the  value  size  bytes  an  attempt  to  override  final  parameter:  to  string  writer  rendered  message  bb  a  prop;  ignoring.  loggingevent  getlog  logger  declareproperty   make a configuration file with 2 final properties with different values  conf  testfinalwarningsmultipleoverride  logger  getrenderedmessage  getbytes  out  removeappender   make sure the appender is removed  addappender  did not see expected string inside message   asserttrue  addresource  prop  get  overriding a final parameter should cause logging  getrootlogger  events   add the resource - this should produce a warning  endconfig   attach our own log appender so we can verify output  startconfig  appender  assertequals  in1  contains  should see the value  size  bytes  an attempt to override final parameter:   tostring  writer  renderedmessage
__label__flaky check  coord  actions  get  time  date  utils  parse  date  oozie  tz  2009-03-06  t10:00  z  add  record  to  job  table  call  job  id  coordinator  job  2009-03-06  t09:58  z  pause  time  -test  action  mater-  c  0000000-  start  time  end  time  2009-03-06  t10:14  z  test  action  mater  with  pause  time3  checkcoordactions  gettime  dateutils  parsedateoozietz  2009-03-06t10:00z  addrecordtojobtable  call  jobid  coordinatorjob  2009-03-06t09:58z  pausetime  -testactionmater-c  0000000-  starttime  endtime  2009-03-06t10:14z  testactionmaterwithpausetime3
__label__nflaky argument  make  graphite  ms  info  graphite  result  put  metrics  record  host  for  class  verify  foo1  foo2  null.all.  context.  context=all.  hostname=host.foo1  1.25  10  write  mock  graphite  all  add  null.all.  context.  context=all.  hostname=host.foo2  2.25  10  argument  captor  print  stack  trace  e  sink  capture  assert  equals  tags  make  metric  whitebox  get  value  test  put  metrics  equals  metrics  set  internal  state  argument  makegraphite  msinfo  graphite  result  putmetrics  record  host  forclass  verify  foo1  foo2  null.all.context.context=all.hostname=host.foo1 1.25 10    write  mockgraphite  all  add  null.all.context.context=all.hostname=host.foo2 2.25 10    argumentcaptor  printstacktrace  e  sink  capture  assertequals  tags  makemetric  whitebox  getvalue  testputmetrics  equals  metrics  setinternalstate
__label__flaky action  num  coordinator  job  coord-action-get.xml  _test  pending  false  status  count  coordinator  action  get  id  job  add  record  to  coord  action  table  test  coord  action  pending  false  status  count  get  add  record  to  coord  job  table  actionnum  coordinatorjob  coord-action-get.xml  _testpendingfalsestatuscount  coordinatoraction  getid  job  addrecordtocoordactiontable  testcoordactionpendingfalsestatuscountget  addrecordtocoordjobtable
__label__nflaky test  file01  get  path  data  process  path  dir  order  length  large  testfile01  add  contents  -  s  ls  format  line  mtime  out  overflow  issues)  testfile03  set  file  length  in  different  order  to  file  names  options  compute  line  format  in  order  testfile02  process  options  verify  testfile05  test  file06  testfile04  test  file04  test  file05  testfile06  test  file02  test  file03  add  found  6  items  path  data  line  format  length  set  is  dir  process  arguments  test  dir  integer  test  directory  set  length  verify  no  more  interactions  test  file  mock    testfile01  getpathdata  processpathdirorderlengthlarge  testfile01  addcontents  -s  ls  formatlinemtime  out   overflow issues)  testfile03   set file length in different order to file names  options  computelineformat  inorder  testfile02  processoptions  verify  testfile05  testfile06  testfile04  testfile04  testfile05  testfile06  testfile02  testfile03  add  found 6 items  pathdata  lineformat  length  setisdir  processarguments  testdir  integer  testdirectory  setlength  verifynomoreinteractions  testfile  mock
__label__flaky jms  topic  service  bab  add  record  to  bundle  action  table  cab  oozie.  add  record  to  wf  action  table  get  id  workflow  instance  get  topic  add  record  to  coord  action  table  setup  services  for  topic  coord-action-for-action-input-check.xml  add  record  to  wf  job  table  get  topic_  prefix  coordinator  action  wab  cjb  bjb  workflow  job  job  init  set  get  bundle  action  id  print  stack  trace  get  conf  e  add  record  to  bundle  job  table  get  message  destroy  jms  topic  service  assert  equals  services  add  record  to  coord  job  table  fail  get  value  services  1  coordinator  job  workflow  action  get  topic  prefix  test  topic  as  job  id  default=  wfj  jmstopicservice  bab  addrecordtobundleactiontable  cab  oozie.  addrecordtowfactiontable  getid  workflowinstance  gettopic  addrecordtocoordactiontable  setupservicesfortopic  coord-action-for-action-input-check.xml  addrecordtowfjobtable  get  topic_prefix  coordinatoraction  wab  cjb  bjb  workflowjob  job  init  set  getbundleactionid  printstacktrace  getconf  e  addrecordtobundlejobtable  getmessage  destroy  jmstopicservice  assertequals  services  addrecordtocoordjobtable  fail  getvalue  services  1  coordinatorjob  workflowaction  gettopicprefix  testtopicasjobid  default=  wfj
__label__nflaky 1.1.1.1  verify  resolve  host  verify  inet  address  test  resolver  qualifed  host.a.b.  addr  1.1.1.1  verifyresolve  host  verifyinetaddress  testresolverqualifed  host.a.b.  addr
__label__flaky play  c3po  data  ping  android  play  it  back  assert  stream  data  header  entries  verify  the  peer  received  what  was  expected  robot  accept  frame  stream  type_  headers  peer  get  response  headers  type_  ping  connection  write  utf8  take  frame  banana  a  b  syn  reply  remote  sends  data  after  in  finished  assert  equals  ping  just  to  make  sure  the  stream  was  fastforwarded.  headers  mode  ignored.  syn_  stream  send  frame  spdy3  get  source  ping  syn  stream  new  stream  play  c3po  data  ping  android   play it back  assertstreamdata  headerentries   verify the peer received what was expected  robot  acceptframe  stream  type_headers  peer  getresponseheaders  type_ping  connection  writeutf8  takeframe  banana  a  b  synreply  remotesendsdataafterinfinished  assertequals   ping just to make sure the stream was fastforwarded.  headersmode   ignored.   syn_stream  sendframe  spdy3  getsource   ping  synstream  newstream
__label__nflaky append  bit  get  size  in  bytes  append  bits  v  assert  equals  1  bit  was  added  in  the  vector   so  1  byte  should  be  consumed.  we  now  have  17  bits   so  3  bytes  should  be  consumed.  test  num  bytes  appendbit  getsizeinbytes  appendbits  v  assertequals   1 bit was added in the vector  so 1 byte should be consumed.   we now have 17 bits  so 3 bytes should be consumed.  testnumbytes
__label__flaky the  match  calls  a  player  event  on  it\'s  deactivation  get  match  event  count  1000  create  stage  mach  event  count  touching  the  player  to  prevent  it\'s  deactivation;  add  player  get  client  time  unit  to  millis  get  reference  assert  not  equals  player  increment  time  millis  create  client  deactivation  test  int  value  match  assert  equals  clock  101  stage  cleanup  i  actor  moving  the  time  ahead   the match calls a player event on it\'s deactivation  getmatcheventcount  1000  createstage  macheventcount   touching the player to prevent it\'s deactivation;  addplayer  get  client  timeunit  tomillis  getreference  assertnotequals  player  incrementtimemillis  createclient  deactivationtest  intvalue  match  assertequals  clock  101  stage  cleanup  iactor   moving the time ahead
__label__nflaky ex  reps  count  await  assert  equals  timeout  test  await  lambda  repetitions  lambda  expression  which  will  succeed  after  exactly  4  probes  timeout  ex  reps  count  await  assertequals  timeout  testawaitlambdarepetitions   lambda expression which will succeed after exactly 4 probes  timeout
__label__flaky test  wf  kill  failed  wf  action  get  cmd  get  workflow  instance  add  record  to  wf  action  table  get  id  assert  equals  workflow  instance  get  status  execute  call  1  services  add  record  to  wf  job  table  workflow  action  assert  not  null  get  action  workflow  job  job  wf  instance  jpa  service  wf  job  get  cmd  testwfkillfailed  wfactiongetcmd  getworkflowinstance  addrecordtowfactiontable  getid  assertequals  workflowinstance  getstatus  execute  call  1  services  addrecordtowfjobtable  workflowaction  assertnotnull  get  action  workflowjob  job  wfinstance  jpaservice  wfjobgetcmd
__label__nflaky args  assert  number  not  negative  test  not  negative  int  pass1  assert  equals  args  assert  number  notnegative  testnotnegativeintpass1  assertequals
__label__flaky write  store  file  test  basic  half  map  file  get  writer  regionname  familyname  store  file  get  path  check  half  h  file  conf  writer  make  up  a  directory  hierarchy  that  has  a  regiondir  and  familyname.  writestorefile  testbasichalfmapfile  getwriter  regionname  familyname  storefile  getpath  checkhalfhfile  conf  writer   make up a directory hierarchy that has a regiondir and familyname.
__label__nflaky /a/b/*  test  prefix  matching  rule  element  selector  assert  equals  test  prefix  match  p  /a  /a/b  /x/*  /  a/b  /a/*  /  a/*  /*  get  prefix  match  length  /a/b/*   test prefix matching  ruleelementselector  assertequals  testprefixmatch  p  /a  /a/b  /x/*  /a/b  /a/*  /a/*  /*  getprefixmatchlength
__label__flaky date  script  executor  table  name  for  session  given  table  name  crud  select  *  from  should_delete_with_schema_name_provider  simple_delete_with_schema_name  provider  when  of  id  row  table  simple  entity/create_simple_mirror_table.cql  execute  script  template  with  schema  name  provider  random  utils  manager  one  where  id  =  next  long  assert  that  execute  immutable  map  simple  entity/insert_single_row.cql  keyspace  for  then  is  null  long  delete  by  id  build  date  key  default_  cassandra_  embedded_  keyspace_  name  date  scriptexecutor  tablenamefor  session   given  tablename  crud  select * from   should_delete_with_schema_name_provider  simple_delete_with_schema_name  provider   when  of  id  row  table  simpleentity/create_simple_mirror_table.cql  executescripttemplate  withschemanameprovider  randomutils  manager  one   where id =   nextlong  assertthat  execute  immutablemap  simpleentity/insert_single_row.cql  keyspacefor   then  isnull  long  deletebyid  builddatekey  default_cassandra_embedded_keyspace_name
__label__nflaky compress  gz  compare  checker  is  error  free  test2  compression  mode  compress2.txt.gz  assert  true  core  test  constants  compress2.txt  context  set  context  compare  input/compress2.txt  compressor  witness/compress2.txt.gz  compress  gzcompare  checker  iserrorfree  test2  compressionmode  compress2.txt.gz  asserttrue  coretestconstants  compress2.txt  context  setcontext  compare  input/compress2.txt  compressor  witness/compress2.txt.gz
__label__flaky bundle  job  get  cmd  test  bundle  kill1  add  record  to  bundle  job  table  get  id  assert  equals  get  status  execute  call  services  assert  not  null  get  job  job  jpa  service  bundlejobgetcmd  testbundlekill1  addrecordtobundlejobtable  getid  assertequals  getstatus  execute  call  services  assertnotnull  get  job  job  jpaservice
__label__nflaky rc  is  too  soon  assert  true  recovery  not  needed  after  init  rc  istoosoon  asserttrue  recoverynotneededafterinit
__label__flaky end_  points  is_  security_  enabled  submit  oozie  url  run  app  path  assert  true  get  -config  create  workflow.xml  servlet_  classes  close  run  test  app  create  config  file  get  context  url  -run  mock  dag  engine  service  assert  equals  get  file  system  test  run  args  call  -oozie  mkdirs  wf  count  to  string  job  get  fs  test  case  dir  end_points  is_security_enabled  submit  oozieurl  run  apppath  asserttrue  get  -config  create  workflow.xml  servlet_classes  close  runtest  app  createconfigfile  getcontexturl  -run  mockdagengineservice  assertequals  getfilesystem  testrun  args  call  -oozie  mkdirs  wfcount  tostring  job  getfstestcasedir
__label__nflaky ../boo/bud  ../../foo  /boo/bud  ../../../../boo/bud  ../../../../..  /foo/bar/baz/.././../fud  ../../..  .././../foo/bar  /foo/bar/baz/boo  foo/baz  ../../foo/bar  baz/bud  ../../boo/bud  /foo/bar/../baz  /foo/bar/./baz  foo/bar  foo/bar/baz/bud  /foo/bar  foo/bar/../baz  foo/bar/baz  ../../../boo/bud  /foo/bar/../../baz/boo  /foo/bar/baz  boo/bud  /foo/boo/bud  ./foo/bar/baz  foo/bar/  foo/boo/bud  test  dots  foo/bar/../../baz/boo  assert  equals  /foo/baz  .  /foo/bar/baz/../../fud  /baz/boo  /foo/fud  ../..  test  path(  string)  baz/boo  test  path(  path   path)  to  string  ../../foo/boo/bud  ../../  ../boo/bud    ../../foo  /boo/bud  ../../../../boo/bud  ../../../../..  /foo/bar/baz/.././../fud  ../../..  .././../foo/bar  /foo/bar/baz/boo  foo/baz  ../../foo/bar  baz/bud  ../../boo/bud  /foo/bar/../baz  /foo/bar/./baz  foo/bar  foo/bar/baz/bud  /foo/bar  foo/bar/../baz  foo/bar/baz  ../../../boo/bud  /foo/bar/../../baz/boo  /foo/bar/baz  boo/bud  /foo/boo/bud  ./foo/bar/baz  foo/bar/  foo/boo/bud  testdots  foo/bar/../../baz/boo  assertequals  /foo/baz  .  /foo/bar/baz/../../fud  /baz/boo  /foo/fud  ../..   test path(string)  baz/boo   test path(path path)  tostring  ../../foo/boo/bud  ../../
__label__flaky action  num  get  id  coord  utils  assert  equals  add  record  to  coord  action  table  add  record  to  coord  job  table  integer  get  coord  actions  from  ids  check  for  the  expected  size  of  actions  list  coordinator  job  job  id  coord-action-get.xml  check  for  the  expected  action  coord  actions  size  test  retrieval  of  single  action  (action  1)  get  coordinator  action  to  string  action1  job  test  get  coord  actions  from  ids  actionnum  getid  coordutils  assertequals  addrecordtocoordactiontable  addrecordtocoordjobtable  integer  getcoordactionsfromids   check for the expected size of actions list  coordinatorjob  jobid  coord-action-get.xml   check for the expected action  coordactions  size   test retrieval of single action (action 1)  get  coordinatoraction  tostring  action1  job  testgetcoordactionsfromids
__label__nflaky exception  get  localized  message  get  internal  server  error  result  ninja  constant  equal  to  when  result  result  get  renderable  assert  true  verify  not  important  get  template  argument  matchers  then  return  get  with  default  get  message  eq  real  test:  assert  that  any  ninja  default  get  status  code  context  impl  messages  ninja  properties  exception  getlocalizedmessage  getinternalservererrorresult  ninjaconstant  equalto  when  result  result  getrenderable  asserttrue  verify  not important  gettemplate  argumentmatchers  thenreturn  getwithdefault  getmessage  eq   real test:  assertthat  any  ninjadefault  getstatuscode  contextimpl  messages  ninjaproperties
__label__flaky positive  test  get  status  sub  workflow  action  executor  proto  conf  create  base  workflow  get  workflow  client  get  test  group  new  conf  create  </app-path>  action  set  id  workflow.xml  write  get  base  proto  conf  wait  for  action  conf  workflow  get  file  system  check  child  conf  test  get  group  from  parent  oozie  client  </configuration>  workflow  action  w1  file  evaluate  negative  test  <sub-workflow  xmlns=\'uri:oozie:workflow:0.1\'  name=\'subwf\'>  <app-path>  <configuration>  get  job  info  assert  false  <name>a</name>  </property>  get  actions  get  external  id  fs  app1  <value>  a</value>  workflow  action  bean  wf  w  get  end  close  set  get  conf  oozie  client  <property>  start  default  conf  sub  workflow  app  path  sub  workflow  assert  equals  set  conf  to  xml  string  </sub-workflow>  writer  action1  get  fs  test  case  dir   positive test  getstatus  subworkflowactionexecutor  protoconf  createbaseworkflow  getworkflowclient  gettestgroup  newconf  create  </app-path>  action  setid  workflow.xml  write  getbaseprotoconf  waitfor  actionconf  workflow  getfilesystem  check  childconf  testgetgroupfromparent  oozieclient        </configuration>  workflowaction  w1  file  evaluate   negative test  <sub-workflow xmlns=\'uri:oozie:workflow:0.1\' name=\'subwf\'>        <app-path>        <configuration>  getjobinfo  assertfalse            <name>a</name>          </property>  getactions  getexternalid  fs  app1            <value>a</value>  workflowactionbean  wf  w  get  end  close  set  getconf  oozieclient          <property>  start  defaultconf  subworkflowapppath  subworkflow  assertequals  setconf  toxmlstring  </sub-workflow>  writer  action1  getfstestcasedir
__label__nflaky ullamcorper  metus  quis  diam  cursus  facilisis.  sed  mollis  quam  id  justo  rutrum  laoreet  rutrum  est   nec  convallis  mauris  condimentum  sit  amet.  phasellus  gravida   diam   lobortis  eu  tristique  ac   p.  in  ut  magna  vel  mauris  malesuada  dictum.  nulla  test  encode  decode  phasellus  gravida   justo  et  congue  auctor   nisi  ipsum  viverra  erat   eget  hendrerit  test  encode  decode23  erat  pulvinar  nisi   id  elementum  sapien  dolor  et  diam.  in  ut  magna  vel  mauris  malesuada  dictum.  nulla  ullamcorper  metus  quis  diam  felis  turpis  nec  lorem.  nulla  ultrices   elit  pellentesque  aliquet  laoreet   justo  est   nec  convallis  mauris  condimentum  sit  amet.  phasellus  gravida   justo  et  congue  cursus  facilisis.  sed  mollis  quam  id  justo  rutrum  sagittis.  donec  laoreet  rutrum  ultrices   elit  pellentesque  aliquet  laoreet   justo  erat  pulvinar  nisi   id  sed  ornare  luctus  ornare.  vestibulum  vehicula   massa  at  pharetra  fringilla   risus  tristique  ac   p.  in  ut  magna  vel  mauris  malesuada  dictum.  nulla  ullamcorper  metus  justo  et  congue  auctor   nisi  ipsum  viverra  erat   eget  hendrerit  felis  turpis  nec  sagittis.  donec  laoreet  rutrum  est   nec  convallis  mauris  condimentum  sit  amet.  fringilla   risus  justo  faucibus  erat   nec  porttitor  nibh  tellus  sed  est.  ut  justo  justo  faucibus  erat   nec  porttitor  nibh  tellus  sed  est.  ut  justo  diam   lobortis  eu  nisi   id  elementum  sapien  dolor  et  diam.  donec  ac  nunc  sodales  elit  placerat  eleifend.  sed  ornare  luctus  ornare.  vestibulum  vehicula   massa  at  pharetra  elementum  sapien  dolor  et  diam.  donec  ac  nunc  sodales  elit  placerat  eleifend.  quis  diam  cursus  facilisis.  sed  mollis  quam  id  justo  rutrum  sagittis.  donec  auctor   nisi  ipsum  viverra  erat   eget  hendrerit  felis  turpis  nec  lorem.  nulla  lorem.  nulla  ultrices   elit  pellentesque  aliquet  laoreet   justo  erat  pulvinar   ullamcorper metus quis diam cursus facilisis. sed mollis quam id justo rutrum   laoreet rutrum est  nec convallis mauris condimentum sit amet. phasellus gravida    diam  lobortis eu tristique ac  p. in ut magna vel mauris malesuada dictum. nulla  testencodedecode   phasellus gravida  justo et congue auctor  nisi ipsum viverra erat  eget hendrerit  testencodedecode23   erat pulvinar nisi  id elementum sapien dolor et diam.  in ut magna vel mauris malesuada dictum. nulla ullamcorper metus quis diam   felis turpis nec lorem. nulla ultrices  elit pellentesque aliquet laoreet  justo   est  nec convallis mauris condimentum sit amet. phasellus gravida  justo et congue   cursus facilisis. sed mollis quam id justo rutrum sagittis. donec laoreet rutrum   ultrices  elit pellentesque aliquet laoreet  justo erat pulvinar nisi  id   sed ornare luctus ornare. vestibulum vehicula  massa at pharetra fringilla  risus   tristique ac  p.in ut magna vel mauris malesuada dictum. nulla ullamcorper metus   justo et congue auctor  nisi ipsum viverra erat  eget hendrerit felis turpis nec   sagittis. donec laoreet rutrum est  nec convallis mauris condimentum sit amet.   fringilla  risus justo faucibus erat  nec porttitor nibh tellus sed est. ut justo   justo faucibus erat  nec porttitor nibh tellus sed est. ut justo diam  lobortis eu   nisi  id elementum sapien dolor et diam. donec ac nunc sodales elit placerat   eleifend. sed ornare luctus ornare. vestibulum vehicula  massa at pharetra   elementum sapien dolor et diam. donec ac nunc sodales elit placerat eleifend.   quis diam cursus facilisis. sed mollis quam id justo rutrum sagittis. donec   auctor  nisi ipsum viverra erat  eget hendrerit felis turpis nec lorem. nulla   lorem. nulla ultrices  elit pellentesque aliquet laoreet  justo erat pulvinar
__label__flaky subwf  job  get  cmd  add  record  to  wf  action  table  coord  action  get  cmd  get  id  get  num  days  to  not  be  purged  workflow  instance  get  status  add  record  to  coord  action  table  sub  workflow  job  should  not  have  been  purged  coord  job  sub  workflow  action  should  not  have  been  purged  wf  job  add  record  to  wf  job  table  assert  not  null  get  workflow  job  should  not  have  been  purged  coordinator  action  workflow  job  wf  action  subwf  action  wf  job  get  cmd  wf  action  get  cmd  coordinator  action  should  not  have  been  purged  assert  equals  get  last  modified  time  execute  add  record  to  coord  job  table  subwf  action  get  cmd  coordinator  job  should  not  have  been  purged  call  services  coordinator  job  1  coord  job  get  cmd  fail  coord-action-get.xml  test  purge  coord  with  wf  child  with  sub  wf1  workflow  action  coord  action  succeeded  subwf  job  jpa  service  workflow  action  should  not  have  been  purged  subwfjobgetcmd  addrecordtowfactiontable  coordactiongetcmd  getid  getnumdaystonotbepurged  workflowinstance  getstatus  addrecordtocoordactiontable  subworkflow job should not have been purged  coordjob  subworkflow action should not have been purged  wfjob  addrecordtowfjobtable  assertnotnull  get  workflow job should not have been purged  coordinatoraction  workflowjob  wfaction  subwfaction  wfjobgetcmd  wfactiongetcmd  coordinator action should not have been purged  assertequals  getlastmodifiedtime  execute  addrecordtocoordjobtable  subwfactiongetcmd  coordinator job should not have been purged  call  services  coordinatorjob  1  coordjobgetcmd  fail  coord-action-get.xml  testpurgecoordwithwfchildwithsubwf1  workflowaction  coordaction  succeeded  subwfjob  jpaservice  workflow action should not have been purged
__label__nflaky test  rl  parse  clear  assert  equals  method  get  method  parse  request  line  lots  of  blanks  get  /stuff  http/1.1  get  protocol  version  buf  assert  get  /stuff  http/1.1  requestline  name  get  /stuff  http/1.1  to  string  /stuff  http  version  typical  request  line  append  get  uri  this  is  not  strictly  valid   but  is  lenient  testrlparse  clear  assertequals  method  getmethod  parserequestline   lots of blanks    get /stuff http/1.1  getprotocolversion  buf  assert  get /stuff http/1.1  requestline  name    get    /stuff   http/1.1     tostring  /stuff  httpversion   typical request line  append  geturi   this is not strictly valid  but is lenient
__label__flaky job  conf  submit  log  submit  result  should  not  contain  -->  app  path  configuration  parse  error.  read  from  db  :  get  job  result  result  includes  bundle-submit-job.xml  file  instead  of  job  id  since  this  is  a  dry  run  mode  assert  true  assert  not  null  get  bundle-submit-job.xml  contains  the  apache  license  but  this  result  should  not  contain  the  comment  block  create_  time  set  start  time  job  bundle  bean  <!--  -->  test  job  xml  comment  removed  set  get  conf  add  record  to  bundle  job  table  bundle.xml  command  call  services  warn  oozie  client  contains  submit  result  should  not  contain  <!--  set  end  time  this  retrieves  bundle-submit-job.xml  to  string  error  code  job  jpa  service  ioe  jobconf  submit  log  submit result should not contain -->   apppath  configuration parse error. read from db :  getjob  result   result includes bundle-submit-job.xml file instead of jobid since this is a dryrun mode  asserttrue  assertnotnull  get   bundle-submit-job.xml contains the apache license but this result should not contain the comment block  create_time  setstarttime  job  bundlebean  <!--  -->  testjobxmlcommentremoved  set  getconf  addrecordtobundlejobtable  bundle.xml  command  call  services  warn  oozieclient  contains  submit result should not contain <!--   setendtime   this retrieves bundle-submit-job.xml  tostring  errorcode  job  jpaservice  ioe
__label__nflaky cluster  excluded  nodes  with  ~  scope  should  be  considered  excluded  nodes  without  ~  scope  should  be  considered  get  new  node  create  exclude  list  add  one  existing  node  to  exclude  list  4  nodes  should  be  available  with  extra  excluded  node  remove  node  base  remove  a  node  from  the  cluster  1  node  should  be  available  no  nodes  should  be  considered  for  non-exist  scope  getting  count  with  non-exist  scope.  test  count  num  nodes  4  nodes  should  be  available  excluded  nodes  add  create  the  topology  assert  equals  /non-exist  node1  node4  excluded  nodes  with  root  scope  should  be  considered  node5  dead  node  node2  get  network  location  node3  network  topology  /d1/r2  excluded  nodes  with  rack  scope  should  be  considered  /d1/r1  get  instance  count  num  of  available  nodes  /d1/r4  ~  /d1/r3  adding  the  node  in  excluded  scope  to  excluded  list  cluster  excluded nodes with ~ scope should be considered  excluded nodes without ~ scope should be considered  getnewnode   create exclude list   add one existing node to exclude list  4 nodes should be available with extra excluded node  remove  nodebase   remove a node from the cluster  1 node should be available  no nodes should be considered for non-exist scope   getting count with non-exist scope.  testcountnumnodes  4 nodes should be available  excludednodes  add   create the topology  assertequals  /non-exist  node1  node4  excluded nodes with root scope should be considered  node5  deadnode  node2  getnetworklocation  node3  networktopology  /d1/r2  excluded nodes with rack scope should be considered  /d1/r1  getinstance  countnumofavailablenodes  /d1/r4  ~  /d1/r3   adding the node in excluded scope to excluded list
__label__flaky end_  points  is_  security_  enabled  oozie  url  concurrency=10  run  app  path  -change  -value  create  servlet_  classes  close  run  test  app  mock  coordinator  engine  service  coordinator.xml  rest  constants  test  change  value  get  context  url  assert  equals  get  file  system  0  args  call  -oozie  mkdirs  job  get  fs  test  case  dir  end_points  is_security_enabled  oozieurl  concurrency=10  run  apppath  -change  -value  create  servlet_classes  close  runtest  app  mockcoordinatorengineservice  coordinator.xml  restconstants  testchangevalue  getcontexturl  assertequals  getfilesystem  0  args  call  -oozie  mkdirs  job  getfstestcasedir
__label__nflaky parent  init  incorrect  number  of  services  add  sibling  service  start  assert  equals  expected  an  exception   got  add  child  to  service  fail  stop  size  get  services  child  test  add  started  child  before  init  parent  init  incorrect number of services  addsiblingservice  start  assertequals  expected an exception  got   addchildtoservice  fail  stop  size  getservices  child  testaddstartedchildbeforeinit
__label__flaky lib  reader  /libx  /liby  /libz  /lib/reduceutil.so  proto  conf  get  test  case  dir  /workflow.xml  file://  create  test  case  sub  dir  /libx/maputil_x.jar  collections  write  add  init  libx  liby  libz  expected  destroy  sort  oozie  client  copy  char  stream  get  resource  as  reader  /libz/maputil_z.jar  wps  job  conf  auth  token  test  createproto  conf  with  muliple  lib  path  /liby/maputil_y2.jar  create  proto  action  conf  found  set  strings  get  bla  bla  close  /lib/maputil.jar  /liby/maputil_y1.jar  set  wf-schema-valid.xml  workflow  app  service  assert  equals  services  get  strings  services  io  utils  get  test  user  writer  lib  reader  /libx  /liby  /libz  /lib/reduceutil.so  protoconf  gettestcasedir  /workflow.xml  file://  createtestcasesubdir  /libx/maputil_x.jar  collections  write  add  init  libx  liby  libz  expected  destroy  sort  oozieclient  copycharstream  getresourceasreader  /libz/maputil_z.jar  wps  jobconf  authtoken  testcreateprotoconfwithmuliplelibpath  /liby/maputil_y2.jar  createprotoactionconf  found  setstrings  get  bla bla  close  /lib/maputil.jar  /liby/maputil_y1.jar  set  wf-schema-valid.xml  workflowappservice  assertequals  services  getstrings  services  ioutils  gettestuser  writer
__label__nflaky setup  compare  fs  test  compare  fs  directories  fs2  fs1  fs4  fs3  fs6  compare  fs  fs5  assert  equals  file  util  setupcomparefs  testcomparefsdirectories  fs2  fs1  fs4  fs3  fs6  comparefs  fs5  assertequals  fileutil
__label__flaky rows_  one  expected  k  vs   the  first  kv  from  each  of  the  remaining  6  rows  qualifiers_  two  qualifiers_  one  verify  scan  full  families  rows_  two  kvs  values  test  first  key  only  filter  set  filter  rows_one   expected kvs  the first kv from each of the remaining 6 rows  qualifiers_two  qualifiers_one  verifyscanfull  families  rows_two  kvs  values  testfirstkeyonlyfilter  setfilter
__label__nflaky microseconds  configuration  values  nanoseconds  days  conf  convert  check  default  suffix  1d  get  time  duration  30  s  test  time  duration  get  7s  30  10  milliseconds  ptd  set  test.time.unit  seconds  set  time  duration  assert  equals  test.time.a  check  suffix  insensitive  test.time.b  test.time.c  unit  test.time.d  hours  30s  40s  minutes  2m  test.time.  x  microseconds  configuration  values  nanoseconds  days  conf  convert   check default  suffix  1d  gettimeduration  30s  testtimeduration  get  7s  30  10  milliseconds  ptd  set  test.time.unit  seconds  settimeduration  assertequals  test.time.a   check suffix insensitive  test.time.b  test.time.c  unit  test.time.d  hours  30s  40s  minutes  2m  test.time.x
__label__flaky write  lock  ensure  time  for  operations  to  start  blocking  channel  run  executors  interrupt  exception  get  cause  sleep  uninterruptibly  write  assert  true  executor  get  interrupt  await  lock  ensure  all  operations  on  the  channel  will  block  latch  count  down  write  milliseconds  ensure  time  for  thread  to  start  blocking  on  the  write  lock  set  e  test  close  by  interrupt  expected  start  store  thread  byte  store  futures  new  cached  thread  pool  byte  buffer  closed  by  interrupt  exception  read  fail  allocate  queue  all  blocking  operations  future  uninterruptibles  interrupt  this  thread.  writelock   ensure time for operations to start blocking  channel  run  executors  interruptexception  getcause  sleepuninterruptibly  write  asserttrue  executor  get  interrupt  await  lock   ensure all operations on the channel will block  latch  countdown  write  milliseconds   ensure time for thread to start blocking on the write lock  set  e  testclosebyinterrupt  expected  start  store  thread  bytestore  futures  newcachedthreadpool  bytebuffer   closedbyinterruptexception  read  fail  allocate  queueallblockingoperations  future  uninterruptibles   interrupt this thread.
__label__nflaky request  http  headers  add  header  process  get  first  header  test  request  user  agent  not  generated  interceptor  assert  equals  method  get  entity  whatever  /  get  value  assert  assert  not  null  context  some  agent  header  request  httpheaders  addheader  process  getfirstheader  testrequestuseragentnotgenerated  interceptor  assertequals  method  getentity  whatever  /  getvalue  assert  assertnotnull  context  some agent  header
__label__flaky cluster  /texttest  get  working  directory  set  texttest  conf  get  file  system  dfs  text  test  build  num  data  nodes  get  local  test_  root_  dir  make  qualified  file  system  fs.default.name  lfs  to  string  test  text  shutdown  get  uri  cluster  /texttest  getworkingdirectory  set  texttest  conf  getfilesystem  dfs  texttest  build  numdatanodes  getlocal  test_root_dir  makequalified  filesystem  fs.default.name  lfs  tostring  testtext  shutdown  geturi
__label__nflaky perm  apply  u  mask  foo  assume  not  windows  conf  f1  none  f2  delete  /foo_copy  localfs  file  system  foo1  fs  permission  set  permission  foo2  test  local  f  sset  permission  write  file  filename2  filename1  all  create  files  and  manipulate  them.  set  get  permission  common  configuration  keys  initial  permission  f  assert  equals  test_  path_  prefix  copy  path  044  filename  cleanup  rename  get  local  exists  get  u  mask  get  file  default  copy  permission  perm  applyumask  foo  assumenotwindows  conf  f1  none  f2  delete  /foo_copy  localfs  filesystem  foo1  fspermission  setpermission  foo2  testlocalfssetpermission  writefile  filename2  filename1  all   create files and manipulate them.  set  getpermission  commonconfigurationkeys  initialpermission  f  assertequals  test_path_prefix  copypath  044  filename  cleanup  rename  getlocal  exists  getumask  getfiledefault  copypermission
__label__flaky execute  script  template  log  asserter  prepare  log  level  for  driver  connection  is  not  null  actual  random  utils  script  executor  manager  given  next  long  assert  that  immutable  map  local_  quorum  assert  consistency  levels  crud  entity  with  static  annotations/insert_single_row.cql  when  of  find  by  id  get  then  long  id  should_find_using_static_consistency  executescripttemplate  logasserter  prepareloglevelfordriverconnection  isnotnull  actual  randomutils  scriptexecutor  manager   given  nextlong  assertthat  immutablemap  local_quorum  assertconsistencylevels  crud  entitywithstaticannotations/insert_single_row.cql   when  of  findbyid  get   then  long  id  should_find_using_static_consistency
__label__nflaky test  expression  not  blank  fail3  not  blank  asserts  stuff  testexpressionnotblankfail3  notblank  asserts  stuff
__label__flaky next  get  block  locations  dir1  assert  false  file1  file2  file3  test  empty  directory  file_  len  assert  true  get  len  get  path  fs  permission  mkdir  list  files  write  file  test_  dir  stat  is  file  test  more  complicated  directory  get  default  has  next  assert  equals  test  directory  testing  directory  with  1  file  util  make  qualified  fc  itor  next  getblocklocations  dir1  assertfalse  file1  file2  file3   test empty directory  file_len  asserttrue  getlen  getpath  fspermission  mkdir  listfiles  writefile  test_dir  stat  isfile   test more complicated directory  getdefault  hasnext  assertequals  testdirectory   testing directory with 1 file  util  makequalified  fc  itor
__label__nflaky test  user  name  anonymous  on  _test  user  name  testusernameanonymouson  _testusername
__label__flaky coord  client  2009-02-02  t23:59  z  local  oozie  coord  action  get  cmd  get  id  date  utils  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  job  get  coord  client  test  coord  rerun  for  backward  support3  rerun  scope  assert  not  null  get  coordinator  action  end  re  run  coord  init  rest  constants  2009-02-01  t01:00  z  start  destroy  assert  equals  services  set  app  namespace  execute  -  add  record  to  coord  job  table  integer  services  coordinator  job  coord  job  get  cmd  schema  service  set  system  property  assert  not  same  true  status  transit  service  to  string  action1  action2  jpa  service  action3  coord-rerun-action1.xml  coordclient  2009-02-02t23:59z  localoozie  coordactiongetcmd  getid  dateutils  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordjob  getcoordclient  testcoordrerunforbackwardsupport3  rerunscope  assertnotnull  get  coordinatoraction  end  reruncoord  init  restconstants  2009-02-01t01:00z  start  destroy  assertequals  services  setappnamespace  execute  -  addrecordtocoordjobtable  integer  services  coordinatorjob  coordjobgetcmd  schemaservice  setsystemproperty  assertnotsame  true  statustransitservice  tostring  action1  action2  jpaservice  action3  coord-rerun-action1.xml
__label__nflaky assert  true  release  is  locked  assert  false  start  lock  run  test  multiple  thread  join  acquire  competing  thread  try  lock  asserttrue  release  islocked  assertfalse  start  lock  run  testmultiplethread  join  acquire  competingthread  trylock
__label__flaky server  check  coord  action  coord  el  functions  assert  false  add  partition  add  init  records  get  waiting  actions  default  be  ready  /dt=20120430;country=usa  make  first  dependency  available  assert  true  get  coordinator  action  checks  for  all  missing  dependencies  test  update  coord  table  multiple  deps  v3  tablename  new  h  cat  dependency  table  new  h  cat  dependency2  new  h  cat  dependency1  hcat  service  populate  table  dt=20120430;country=brazil  hcat://  pdms  is  registered  for  notification  /  call  services  contains  assert  null  /dt=20120430;country=brazil  action  id  db    server  checkcoordaction  coordelfunctions  assertfalse  addpartition  addinitrecords  getwaitingactions  default   be ready  /dt=20120430;country=usa   make first dependency available  asserttrue  get  coordinatoraction   checks for all missing dependencies  testupdatecoordtablemultipledepsv3  tablename  newhcatdependency  table  newhcatdependency2  newhcatdependency1  hcatservice  populatetable  dt=20120430;country=brazil  hcat://  pdms  isregisteredfornotification  /  call  services  contains  assertnull  /dt=20120430;country=brazil  actionid  db
__label__nflaky theirs  check  on  bytes  utf-8  update  next  int  get  bytes  check  same  next  bytes  hello  world!  ours  test  correctness  random  bytes  theirs  checkonbytes  utf-8  update  nextint  getbytes  checksame  nextbytes  hello world!  ours  testcorrectness  randombytes
__label__flaky conn  set  request  method  is_  security_  enabled  assert  true  json  content-type  /v1/admin/*  collections  run  test  test  v1  queue  dump  json  tags  rest  constants  open  connection  contains  key  http  servlet  response  assert  equals  parse  get  input  stream  url  json  value  call  get  header  field  get  get  response  code  create  url  starts  with  conn  setrequestmethod  is_security_enabled  asserttrue  json  content-type  /v1/admin/*  collections  runtest  testv1queuedump  jsontags  restconstants  openconnection  containskey  httpservletresponse  assertequals  parse  getinputstream  url  jsonvalue  call  getheaderfield  get  getresponsecode  createurl  startswith
__label__nflaky abc  \%7hello  abc  llo  abc  hel  abc  \%.3hello  head  result  abc  123  abc  hell  compile  abc  hello  converter  map  context  set  context  write  abc  hello  abc  \%4.5  ott  abc  123  abc  \%-4.5  ott  abc  \%3.4hello  assert  equals  parse  test  format  abc  \%.-3hello  p  t  abc  \%-7hello  abc  \%-3.-4hello  abc  ello  abc \%7hello  abc llo  abc hel  abc \%.3hello  head  result  abc 123   abc hell  compile  abc hello    convertermap  context  setcontext  write  abc   hello  abc \%4.5ott  abc  123  abc \%-4.5ott  abc \%3.4hello  assertequals  parse  testformat  abc \%.-3hello  p  t  abc \%-7hello  abc \%-3.-4hello  abc ello
__label__flaky coord-multiple-input-end-instance1.xml  expected  to  catch  errors  due  to  incorrectly  specified  input  data  set  end-instances  reader  conf  get  status  app  path  get  job  sc  coord-multiple-input-end-instance2.xml  test  basic  submit  with  multiple  end  instances  input  event  get  error  code  assert  true  file://  get  test  case  dir  unit_  testing  case  1:  failure  case  i.e.  multiple  data-in  start-instances  get  path  coordinator  app  definition  should  not  have  multiple  end-instances  job  coordinator.xml  set  e  get  message  assert  equals  call  oozie  client  fail  io  utils  contains  get  test  user  copy  char  stream  unexpected  failure:  get  resource  as  reader  writer  error  code  file  case  2:  success  case  i.e.  single  end  instances  for  input  and  single  end  instance  for  output   but  both  with  \"" \""  coord-multiple-input-end-instance1.xml  expected to catch errors due to incorrectly specified input data set end-instances  reader  conf  getstatus  apppath  getjob  sc  coord-multiple-input-end-instance2.xml  testbasicsubmitwithmultipleendinstancesinputevent  geterrorcode  asserttrue  file://  gettestcasedir  unit_testing   case 1: failure case i.e. multiple data-in start-instances  getpath  coordinator app definition should not have multiple end-instances  job  coordinator.xml  set  e  getmessage  assertequals  call  oozieclient  fail  ioutils  contains  gettestuser  copycharstream  unexpected failure:   getresourceasreader  writer  errorcode  file   case 2: success case i.e. single end instances for input and single end instance for output  but both with \"" \""
__label__nflaky this  is  a  test  20080504  t123456  z  description:  this  is  a  test  do  test  begin:  vcalendar  begin:  vevent  description:  this  is  a  test  with  a  continuation  test  description  dtstart:20080504  t123456  z  end:  vevent  end:  vcalendar  this  is  a  test  with  a  continuation  this is a test  20080504t123456z  description:this is a test    dotest  begin:vcalendar  begin:vevent    description:this is a test  \t with a continuation    testdescription  dtstart:20080504t123456z    end:vevent  end:vcalendar  this is a test with a continuation
__label__flaky /////////////////////////////////////////////////////////////////////  post  retrieving  articles  for  a  user  (  json)  replace  core  matchers  contentcontent  get_  articles_  url  post_  article_  url  test  get  and  post  article  via  json  path  we  are  now  getting  4  articles.  one  new  result:  bob@gmail.com  say  and  make  request  payload  new  title  new  title  {username}  test  server  url  article  dto  now  we  are  authenticated  and  expect  the  post  to  succeed...  we  get  back  all  3  articles  of  that  user  posting  a  new  article  is  a  post  request  to  do  login  if  we  now  fetch  the  articles  again  we  are  getting  a  new  article  (the  one  we  have  posted  successfully  content  type  application  json  retrieving  all  articles  of  a  user  is  a  get  request  to  request  say  is  user  say  next  section  url  get  gson  with  long  to  date  parsing  articles  dto  posting  new  article  (  json)  please  note  that  you  have  to  be  authenticated  in  order  to  be  allowed  to  post.  size  response  get  from  json  say  and  assert  that  you  have  to  be  authenticated  in  order  to  post  articles  after  successful  login  we  are  able  to  post  articles   /////////////////////////////////////////////////////////////////////  post  retrieving articles for a user (json)  replace  corematchers  contentcontent  get_articles_url  post_article_url  testgetandpostarticleviajson  path  we are now getting 4 articles.   one new result:  bob@gmail.com  sayandmakerequest  payload  new title new title  {username}  testserverurl  articledto  now we are authenticated and expect the post to succeed...  we get back all 3 articles of that user  posting a new article is a post request to   dologin  if we now fetch the articles again we are getting a new article (the one we have posted successfully  contenttypeapplicationjson  retrieving all articles of a user is a get request to   request  say  is  user  saynextsection  url  getgsonwithlongtodateparsing  articlesdto  posting new article (json)  please note that you have to be authenticated in order to be allowed to post.  size  response  get  fromjson  sayandassertthat  you have to be authenticated in order to post articles  after successful login we are able to post articles
__label__nflaky get  parameter  values  mock  req  b  a&lt;b  a<b  test  that  missing  parameters  dont  cause  npe  for  array  do  return  assert  equals  when  quoter  assert  array  equals  test  escaping  of  an  array  test  request  quoting  mockito  mock  test  simple  param  quoting  test  that  missing  parameters  dont  cause  npe  get  parameter  getparametervalues  mockreq  b  a&lt;b  a<b  test that missing parameters dont cause npe for array  doreturn  assertequals  when  quoter  assertarrayequals  test escaping of an array  testrequestquoting  mockito  mock  test simple param quoting  test that missing parameters dont cause npe  getparameter
__label__flaky init  destroy  get  id  assert  equals  services  set  app  namespace  get  status  execute  add  record  to  coord  job  table  call  services  coordinator  job  coord  job  get  cmd  schema  service  assert  not  null  get  set  system  property  true  status  transit  service  test  coord  suspend  and  resume  for  prep  with  backward  compatibility  job  jpa  service  init  destroy  getid  assertequals  services  setappnamespace  getstatus  execute  addrecordtocoordjobtable  call  services  coordinatorjob  coordjobgetcmd  schemaservice  assertnotnull  get  setsystemproperty  true  statustransitservice  testcoordsuspendandresumeforprepwithbackwardcompatibility  job  jpaservice
__label__nflaky get  property  prior  default  encoding  utf-8  declare  property  write  xml  end  config  start  config  conf  assert  equals  fos  system  config_  multi_  byte_  saved  test  multi  byte  characters  us-  ascii  out  config_  multi_  byte  file.encoding  add  resource  set  property  get  name  multi_byte_æ„›_name  multi_byte_Ù?_value  value  getproperty  priordefaultencoding  utf-8  declareproperty  writexml  endconfig  startconfig  conf  assertequals  fos  system  config_multi_byte_saved  testmultibytecharacters  us-ascii  out  config_multi_byte  file.encoding  addresource  setproperty  get  name  multi_byte_æ„›_name  multi_byte_Ù?_value  value
__label__flaky check  coord  jobs  <coordinator-app  name=\""  name\""  frequency=\""10\""  start=\""2009-02-01  t01:00  z\""  end=\""2009-02-03  t23:59  z\""  timezone=\""  utc\""  conf  app  path  substring  sc  write  to  file  app  xml  file://  get  test  case  dir  unit_  testing  xmlns=\""uri:oozie:coordinator:0.2\"">  <configuration>  <property>  <name>input  a</name>  <value>blah</value>  </property>  coordinator.xml  set  length  assert  equals  test  submit  no  controls  </configuration>  </workflow>  </action>  </coordinator-app>  call  oozie  client  job  id  get  test  user  -  c  <action>  <workflow>  <app-path>hdfs:///tmp/workflows/</app-path>  file  checkcoordjobs  <coordinator-app name=\""name\"" frequency=\""10\"" start=\""2009-02-01t01:00z\"" end=\""2009-02-03t23:59z\"" timezone=\""utc\""   conf  apppath  substring  sc  writetofile  appxml  file://  gettestcasedir  unit_testing  xmlns=\""uri:oozie:coordinator:0.2\"">   <configuration> <property> <name>inputa</name> <value>blah</value> </property>   coordinator.xml  set  length  assertequals  testsubmitnocontrols  </configuration> </workflow> </action> </coordinator-app>  call  oozieclient  jobid  gettestuser  -c  <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>   file
__label__nflaky 10.119.103.112  10.113.221.222  10.222.103.121  is  in  the  list  10.113.221.221  assert  false  test  add  with  sleep  for  cache  timeout  10.222.103.121  is  not  in  the  list  10.221.102.0/23  cipl  ips  10.222.103.121  thread  sleep  create  file  with  entries  remove  file  assert  true  ips.txt  test  file  based  ip  list  ips2  10.113.221.222  is  in  the  list  10.222.0.0/16  is  in  10.113.221.222  is  not  in  the  list  10.119.103.112  10.113.221.222  10.222.103.121 is  in the list  10.113.221.221  assertfalse  testaddwithsleepforcachetimeout  10.222.103.121 is not in the list  10.221.102.0/23  cipl  ips  10.222.103.121  thread  sleep  createfilewithentries  removefile  asserttrue  ips.txt  testfilebasediplist  ips2  10.113.221.222 is in the list  10.222.0.0/16  isin  10.113.221.222 is not in the list
__label__flaky init  coord  el  functions  assert  equals  timeunit  get  variable  1  eval  eval  and  wrap  ${coord:minutes(1)}  time  unit  expr  coord-job-submit-freq  ${coord:minutes(coord:minutes(1))}  test  minutes  init  coordelfunctions  assertequals  timeunit  getvariable  1  eval  evalandwrap  ${coord:minutes(1)}  timeunit  expr  coord-job-submit-freq  ${coord:minutes(coord:minutes(1))}  testminutes
__label__nflaky args  number  not  negative  test  not  negative  int  fail1  args  number  notnegative  testnotnegativeintfail1
__label__flaky request  test  most  popular  assert  equals  target  accept  list_  id_  count_  type  get  value  assert  top  size  assert  true  get  media  type  /most  active  users  this  count  request  testmostpopular  assertequals  target  accept  list_id_count_type  getvalue  assert  top  size  asserttrue  get  mediatype  /mostactiveusers  thiscount
__label__nflaky cursor  value5  get  name  value7  value1  value4  value3  2nd  element  has  1  parameter  test  parse  header  elements  1st  element  assert  2nd  element  parse  elements  3rd  element  name5=value5   name6=  ;  name7  =  value7;  name8  =  \""  value8\""  length  header  value  assert  equals  value8  name6  name1  =  value1;  name2;  name3=\""value3\""     name4=value4;  get  value  name5  buf  1st  element  has  2  get  parameters()  name4  3rd  element  has  2  get  parameters()  name3  name8  elements  name7  get  parameters  there  are  3  elements  name2  name1  append  cursor    value5  getname  value7  value1  value4  value3   2nd element has 1 parameter  testparseheaderelements   1st element  assert   2nd element  parseelements   3rd element  name5=value5  name6= ; name7 = value7; name8 = \"" value8\""  length  headervalue  assertequals   value8  name6  name1 = value1; name2; name3=\""value3\""   name4=value4;   getvalue  name5  buf   1st element has 2 getparameters()  name4   3rd element has 2 getparameters()  name3  name8  elements  name7  getparameters   there are 3 elements  name2  name1  append
__label__flaky cluster  other  unmanaged  a  ms  do  return  amrm  token  foo  run  assert  create  yarn  client  assert  not  null  app  id  user  group  information  create  user  for  testing  init  managed  a  ms  don\'t  return  amrm  token  rm  client  test  ammr  tokens  start  yarn  conf  other  users  don\'t  get  amrm  token  create  app  test  mram  tokens  get  config  yarn  client  get  amrm  token  wait  till  accepted  do  as  assert  null  stop  cluster  other   unmanaged ams do return amrm token  foo  run  assert  createyarnclient  assertnotnull  appid  usergroupinformation  createuserfortesting  init   managed ams don\'t return amrm token  rmclient  testammrtokens  start  yarnconf   other users don\'t get amrm token  createapp  testmramtokens  getconfig  yarnclient  getamrmtoken  waittillaccepted  doas  assertnull  stop
__label__nflaky key1  p1  p2  get  kms  url  kp  e  any  string  then  return  key  name  conf  when  warm  up  encrypted  keys  get  cause  fail  do  throw  times  should  fail  since  both  providers  threw  io  exception  mockito  assert  true  mock  verify  test  warm  up  encrypted  keys  when  all  providers  fail  key1  p1  p2  getkmsurl  kp  e  anystring  thenreturn  keyname  conf  when  warmupencryptedkeys  getcause  fail  dothrow  times  should fail since both providers threw ioexception  mockito  asserttrue  mock  verify  testwarmupencryptedkeyswhenallprovidersfail
__label__flaky get  job  tracker  uri  test  oozie  server  action  sharelib  setting  java  share  lib  path  create  context  cache  files  str  context  create  workflow.xml  get  cache  files  <job-tracker>  test  add  action  share  lib  e  action  xml  workflow  ae  jar5.jar  parse  xml  </job-tracker>  get  file  system  jar5  path  <name-node>  </name-node>  setup  launcher  conf  set  lib  files  archives  oozie  client  contains  mkdirs  jar4  path  systemlib  arrays  hcat  share  lib  path  other  job  conf  jar3.jar  get  workflow  cache  files  other hcat  <java>  assert  false  get  app  path  jar3  path  create  base  hadoop  conf  action  xml  oozie.action.sharelib.for.java  jar4.jar  java hcat  distributed  cache  <job-xml>job.xml</job-xml>  assert  true  get  <job-xml>job2.xml</job-xml>  jar2  path  system  lib  path  close  wf  conf  hcat  get  name  node  uri  jar1  path  set  pretty  print  </java>  xml  utils  get  conf  workflow  app  service  jar1.jar  other  share  lib  path  test  per  workflow  action  sharelib  setting  <main-class>  main-  class</main-class>  the  oozie  server  setting  should  have  been  overridden  by  workflow  setting  set  conf  services  get  test  user  to  string  jar2.jar  get  fs  test  case  dir  set  boolean  getjobtrackeruri   test oozie server action sharelib setting  javasharelibpath  createcontext  cachefilesstr  context  create  workflow.xml  getcachefiles  <job-tracker>  testaddactionsharelib  eactionxml  workflow  ae  jar5.jar  parsexml  </job-tracker>  getfilesystem  jar5path  <name-node>  </name-node>  setuplauncherconf  setlibfilesarchives  oozieclient  contains  mkdirs  jar4path  systemlib  arrays  hcatsharelibpath  other  jobconf  jar3.jar  getworkflow  cachefiles  other hcat  <java>  assertfalse  getapppath  jar3path  createbasehadoopconf  actionxml  oozie.action.sharelib.for.java  jar4.jar  java hcat  distributedcache  <job-xml>job.xml</job-xml>  asserttrue  get  <job-xml>job2.xml</job-xml>  jar2path  systemlibpath  close  wfconf  hcat  getnamenodeuri  jar1path  set  prettyprint  </java>  xmlutils  getconf  workflowappservice  jar1.jar  othersharelibpath   test per workflow action sharelib setting  <main-class>main-class</main-class>   the oozie server setting should have been overridden by workflow setting  setconf  services  gettestuser  tostring  jar2.jar  getfstestcasedir  setboolean
__label__nflaky client  of  this  ldap  server  is  expected  to  get  a  read  timeout.  fin  latch  get  local  port  test  ldap  read  timeout  run  conf  do  get  groups  server  sock  ldap://localhost:  authenticate_  success_  msg  await  ldap  url  client  sock  count  down  hadoop  join  write  4s  ldap  response  read  timed  out   timeout  used:  ldap  server  mapping  debug  print  stack  trace  e  log  ms  start  got  the  exception  while  ldap  querying:  get  input  stream  set  conf  accept  set  int  read_  timeout  fail  io  utils  skip  fully  ne  assert  exception  contains  get  output  stream  read  timeout  ms  the  ldap  query  should  have  timed  out!  get  base  conf  remaining  name   client of this ldap server is expected to get a read timeout.  finlatch  getlocalport  testldapreadtimeout  run  conf  dogetgroups  serversock  ldap://localhost:  authenticate_success_msg  await  ldapurl  clientsock  countdown  hadoop  join  write   4s  ldap response read timed out  timeout used:  ldapserver  mapping  debug  printstacktrace  e  log  ms  start  got the exception while ldap querying:   getinputstream  setconf  accept  setint  read_timeout  fail  ioutils  skipfully  ne  assertexceptioncontains  getoutputstream  readtimeoutms  the ldap query should have timed out!  getbaseconf  remaining name
__label__flaky add  org.springframework.boot  grab  annotations  1.2.3  assert  grab  annotation  size  get  assert  equals  annotation  node  non  transitive  add  get  annotations  spring-boot-starter-logging  add  org.springframework.boot  grabannotations  1.2.3  assertgrabannotation  size  get  assertequals  annotationnode  nontransitiveadd  getannotations  spring-boot-starter-logging
__label__nflaky bool16  byte9  decoder  byte8  assert  array  equals  convert  bool  array  to  byte  array  byte7  bool7  byte1  test  raw  bytes  byte0  bool9  bool8  byte16  bool1  bool0  bool16  byte9  decoder  byte8  assertarrayequals  convertboolarraytobytearray  byte7  bool7  byte1  testrawbytes  byte0  bool9  bool8  byte16  bool1  bool0
__label__flaky server  get  name  get  hdfs  conf  conf  dir  fs  as  list  test  dir  helper  assert  create  hadoop  conf  /tmp/foo  server.services  string  utils  get  server.hadoop.filesystem.cache.purge.timeout  join  hadoop  get  file  system  configuration  init  set  get  absolute  path  test  hdfs  helper  get  test  dir  hadoop  conf  destroy  file  system  executor  exception  assert  equals  services     execute  common  configuration  keys  public  0  get  error  fail  ex  fsa  u  mkdirs  file  system  access  exception  arrays  server  getname  gethdfsconf  conf  dir  fs  aslist  testdirhelper  assert  createhadoopconf  /tmp/foo  server.services  stringutils  get  server.hadoop.filesystem.cache.purge.timeout  join  hadoop  getfilesystemconfiguration  init  set  getabsolutepath  testhdfshelper  gettestdir  hadoopconf  destroy  filesystemexecutorexception  assertequals  services     execute  commonconfigurationkeyspublic  0  geterror  fail  ex  fsa  u  mkdirs  filesystemaccessexception  arrays
__label__nflaky test  is  before  from  unix  milliseconds  assert  assert  true  current  time  millis  deadline  now  plus  one  min  deadline  system  is  before  testisbefore  fromunixmilliseconds  assert  asserttrue  currenttimemillis  deadline  nowplusonemin  deadline  system  isbefore
__label__flaky main  thread  current  thread  how  could  it  not  call  get  block  commits()?)  block  commits  start  after  run  interrupted  will  reach  t.join().  thread  but  i  don\'t  see  a  good  alternative  here)  process  commit  t  assert  true  limiter  interrupt  await  latch  count  down  join  empty_  node  using  a  latch  to  avoid  having  to  rely  on  timing  get  block  commits  mainthread  currentthread   how could it not call getblockcommits()?)  blockcommits  start  after  run  interrupted   will reach t.join().  thread   but i don\'t see a good alternative here)  processcommit  t  asserttrue  limiter  interrupt  await  latch  countdown  join  empty_node   using a latch to avoid having to rely on timing  getblockcommits
__label__nflaky failed  controller  registration  with  route  e  assert  true  get  build  route  /failure  route  builder  does  not  exist  injector  failedcontrollerregistration  with  route  e  asserttrue  get  buildroute  /failure  routebuilder  doesnotexist  injector
__label__flaky parallel  took:  {}ms  log  set  parallel  processing  serial  took:  {}ms  system  end  parallel  serial  parallel  assert  true  current  time  millis  end  serial  victim  begin  test  mojo  with  configurable  wro  manager  factory  with  valid  config  file  set  info  should  be  faster  when  running  processing  in  parallel  parallel took: {}ms  log  setparallelprocessing  serial took: {}ms  system  endparallel  serial  parallel  asserttrue  currenttimemillis  endserial  victim  begin  testmojowithconfigurablewromanagerfactorywithvalidconfigfileset  info  shouldbefasterwhenrunningprocessinginparallel
__label__nflaky body  parser  engine  xml  test  xml  body  with  missing  variables  then  return  <form><first  name>\%s</first  name><last  name>\%s</last  name></form>  body  parser  engine  xml  test  format  equal  to  test  form  is  invoke  string  assert  that  get  input  stream  when  get  bytes  mockito  assert  true  xml  obj  mapper  context  xml  document  close  bodyparserenginexml  testxmlbodywithmissingvariables  thenreturn  <form><firstname>\%s</firstname><lastname>\%s</lastname></form>  bodyparserenginexmltest  format  equalto  testform  is  invoke  string  assertthat  getinputstream  when  getbytes  mockito  asserttrue  xmlobjmapper  context  xmldocument  close
__label__flaky server  check  for  timeout  status  and  unregistered  missing  dependencies  time  out  creation  time  check  coord  action  coord  el  functions  timeout.  assert  false  test  time  out  add  init  records  get  waiting  actions  system  sleep  default  /dt=20120430;country=usa  assert  true  get  coordinator  action  tablename  new  h  cat  dependency  table  set  coord  action  creation  time  new  h  cat  dependency2  new  h  cat  dependency1  hcat  service  populate  table  hcat://  pdms  is  registered  for  notification  /  thread  call  services  contains  assert  null  current  time  millis  /dt=20120430;country=brazil  action  id  db  server   check for timeout status and unregistered missing dependencies  timeoutcreationtime  checkcoordaction  coordelfunctions   timeout.  assertfalse  testtimeout  addinitrecords  getwaitingactions  system  sleep  default  /dt=20120430;country=usa  asserttrue  get  coordinatoraction  tablename  newhcatdependency  table  setcoordactioncreationtime  newhcatdependency2  newhcatdependency1  hcatservice  populatetable  hcat://  pdms  isregisteredfornotification  /  thread  call  services  contains  assertnull  currenttimemillis  /dt=20120430;country=brazil  actionid  db
__label__nflaky see  also  http://jira.qos.ch/browse/  logback-1164  status  printer  assert  equals  checker  aggregation  type  orange  citrus  bridge  methods  should  be  ignored  print  context  compute  aggregation  type  assert  is  warning  or  error  free  orange  setter   see also http://jira.qos.ch/browse/logback-1164  statusprinter  assertequals  checker  aggregationtype  orange  citrus  bridgemethodsshouldbeignored  print  context  computeaggregationtype  assertiswarningorerrorfree  orangesetter
__label__flaky date  rs  set  session  given  update  with  lwt  result  listener  should_dsl_update_value_if_exists  error  eq  when  get  where  id  get  and  set  row  value  on  error  random  utils  manager  with  result  set  async  listener  one  is  false  next  long  assert  that  execute  is  true  then  is  null  long  if  exists  build  date  key  new  value  from  base  table  dsl  was  applied  select  simplemap  from  simple  where  id  =  on  success  date  rs  set  session   given  update  withlwtresultlistener  should_dsl_update_value_if_exists  error  eq   when  get  where  id  getandset  row  value  onerror  randomutils  manager  withresultsetasynclistener  one  isfalse  nextlong  assertthat  execute  istrue   then  isnull  long  ifexists  builddatekey  new value  frombasetable  dsl  wasapplied  select simplemap from simple where id =   onsuccess
__label__nflaky test  add  remove  cycle  h  h1  h2  assert  equals  h3  fifo  buffer  h4  assert  same  get  last  remove  last  1  2  3  assert  4  size  get  first  get  add  first  testaddremovecycle  h  h1  h2  assertequals  h3  fifobuffer  h4  assertsame  getlast  removelast  1  2  3  assert  4  size  getfirst  get  addfirst
__label__flaky exec_  order  callable2  callable3  callables  callable1  c  queue  uniqueness  with  diff  key  as  list  queueservice  services  assert  true  queue  uniqueness  with  diff  key2  queue  uniqueness  with  diff  key1  get  queue  uniqueness  with  diff  key3  test  queue  uniqueness  with  diff  key  arrays  evaluate  wait  for  queue  exec_order  callable2  callable3  callables  callable1  c  queueuniquenesswithdiffkey  aslist  queueservice  services  asserttrue  queueuniquenesswithdiffkey2  queueuniquenesswithdiffkey1  get  queueuniquenesswithdiffkey3  testqueueuniquenesswithdiffkey  arrays  evaluate  waitfor  queue
__label__nflaky request  conn  when  set  entity  flush  executor  context  create  verify  ok  post  process  test  execution  entity  enclosing  request  process  then  return  method  get  entity  execute  /  mockito  response  http  core  context  httprocessor  mock  pre  process  entity  receive  response  header  send  request  entity  send  request  header  receive  response  entity  request  conn  when  setentity  flush  executor  context  create  verify  ok  postprocess  testexecutionentityenclosingrequest  process  thenreturn  method  getentity  execute  /  mockito  response  httpcorecontext  httprocessor  mock  preprocess  entity  receiveresponseheader  sendrequestentity  sendrequestheader  receiveresponseentity
__label__flaky conn  /v1/jobs  00002-12345-  b  put  test  multiple  bundle  ids  for  name  set  id  set  start  time  bundle  records  found  for  this  bundle  run  test  bundle  insert  set  app  name  rest  constants  open  connection  http  servlet  response  assert  equals  adding  another  bundle  having  same  name  params  execute  set  status  url  call  1  5  get  response  code  bundle  name  create  url  bundle  job  bulk  request  jpa  service  bundle=    conn  /v1/jobs  00002-12345-b  put  testmultiplebundleidsforname  setid  setstarttime  bundle   records found for this bundle  runtest  bundleinsert  setappname  restconstants  openconnection  httpservletresponse  assertequals   adding another bundle having same name  params  execute  setstatus  url  call  1  5  getresponsecode  bundlename  createurl  bundlejob  bulkrequest  jpaservice  bundle=
__label__nflaky create  mapping  mapping  set  is  single  switch  script  based  mapping  expected  to  be  multi  switch  test  filename  means  multi  switch  assert  false  conf  any-filename  set  conf  expected  to  be  single  switch  assert  true  createmapping  mapping  set  issingleswitch  scriptbasedmapping  expected to be multi switch  testfilenamemeansmultiswitch  assertfalse  conf  any-filename  setconf  expected to be single switch  asserttrue
__label__flaky get  current  dateafter  incrementing  in  months  get  id  run  date  utils  get  status  add  record  to  coord  action  table  test  coord  status  transit  service  for  timeout  parse  date  oozie  tz  coord  get  cmd  coord  job  sleep  get  coordinator  action  end  current  date  plus  month  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  coordinator  job  services  runnable  coord-action-get.xml  job  jpa  service  getcurrentdateafterincrementinginmonths  getid  run  dateutils  getstatus  addrecordtocoordactiontable  testcoordstatustransitservicefortimeout  parsedateoozietz  coordgetcmd  coordjob  sleep  get  coordinatoraction  end  currentdateplusmonth  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  coordinatorjob  services  runnable  coord-action-get.xml  job  jpaservice
__label__nflaky test  expand  h  h1  h2  assert  equals  h3  h4  fifo  buffer  assert  same  remove  last  get  last  n  1  2  3  assert  4  size  get  first  get  add  first  testexpand  h  h1  h2  assertequals  h3  h4  fifobuffer  assertsame  removelast  getlast  n  1  2  3  assert  4  size  getfirst  get  addfirst
__label__flaky get  id  assert  equals  get  status  execute  add  record  to  coord  job  table  call  coordinator  job  services  coord  job  get  cmd  test  coord  suspend  and  resume  for  prep  assert  not  null  get  job  jpa  service  getid  assertequals  getstatus  execute  addrecordtocoordjobtable  call  coordinatorjob  services  coordjobgetcmd  testcoordsuspendandresumeforprep  assertnotnull  get  job  jpaservice
__label__nflaky 1010  assert  equals  test  append  bit  1  append  bit  get  size  get  size  in  bytes  v  10101  10101010  10101010  10  10101010  1  get  unsigned  int  1010101  101  101010  10   1010  assertequals  testappendbit   1  appendbit  getsize  getsizeinbytes  v   10101   10101010   10101010 10   10101010 1  getunsignedint   1010101   101   101010   10
__label__flaky read  fields  to  byte  array  action  dos  test  empty  write  read  baos  write  close  dis  readfields  tobytearray  action  dos  testemptywriteread  baos  write  close  dis
__label__nflaky key1  -description  list  keys  hadoop-10586  key  shell  didn\'t  allow  -description.  created  ks  list  out  key1  has  been  successfully  description  run  assert  equals  set  conf  test  key  successful  creation  with  description  rc  some  description  contains  -provider  assert  true  args1  reset  create  jceks  provider  to  string  out  content  key1  -description  listkeys   hadoop-10586 keyshell didn\'t allow -description.   created  ks  listout  key1 has been successfully   description  run  assertequals  setconf  testkeysuccessfulcreationwithdescription  rc  somedescription  contains  -provider  asserttrue  args1  reset  create  jceksprovider  tostring  outcontent
__label__flaky set  classes  to  be  excluded  add  record  to  bundle  action  table  assert  false  get  id  run  is  pending  get  status  bundle  job  assert  not  null  get  job  bundle  wait  for  init  test  bundle  status  transit  service  suspended  with  error  get  conf  false  add  record  to  bundle  job  table  bundle  id  destroy  assert  equals  services  execute  services  runnable  excluded  services  set  system  property  status  transit  service  action1  action2  jpa  service  evaluate  setclassestobeexcluded  addrecordtobundleactiontable  assertfalse  getid  run  ispending  getstatus  bundlejob  assertnotnull  get  job  bundle  waitfor  init  testbundlestatustransitservicesuspendedwitherror  getconf  false  addrecordtobundlejobtable  bundleid  destroy  assertequals  services  execute  services  runnable  excludedservices  setsystemproperty  statustransitservice  action1  action2  jpaservice  evaluate
__label__nflaky get  canonical  host  name  replaced  assert  equals  should  replace  user  principal  test  get  server  principal  hdfs/  name  never  hostname  not  used  @  realm  foo@  foorealm  mockito  service  get  server  principal  verify  mock  testing  reverse  dns  lookup  doesn\'t  happen  realm  security  util  foohost  should  not  replace  getcanonicalhostname  replaced  assertequals  shouldreplace  userprincipal  testgetserverprincipal  hdfs/  name  never  hostname  notused  @realm  foo@foorealm  mockito  service  getserverprincipal  verify  mock   testing reverse dns lookup doesn\'t happen  realm  securityutil  foohost  shouldnotreplace
__label__flaky f0  f1  f2  test  that  it  can  delete  more  than  one  file  when  necessary  and  that  it  works  with  non  .gz  files  f3  f4  set  max  history  cal  f5  f6  f7  f8  oozie.log  assert  true  get  test  case  dir  blah.txt  test  deleting  old  files  wait  for  oozie  log  path  add  .gz  (instead  of  the  time  from  the  filename)  calendar  get  time  in  millis  test  that  it  only  deletes  the  oldest  file  (f1)  get  x  log  service  format  date  for  filename  orp  only  keep  3  newest  logs  mock  one  instead.  oozie  log  name  is  triggering  event  exists  create  new  file  evaluate  xls  set  last  modified  f0  f1  f2   test that it can delete more than one file when necessary and that it works with non .gz files  f3  f4  setmaxhistory  cal  f5  f6  f7  f8  oozie.log  asserttrue  gettestcasedir  blah.txt  testdeletingoldfiles  waitfor  oozielogpath  add  .gz   (instead of the time from the filename)  calendar  gettimeinmillis   test that it only deletes the oldest file (f1)  getxlogservice  formatdateforfilename  orp   only keep 3 newest logs   mock one instead.  oozielogname  istriggeringevent  exists  createnewfile  evaluate  xls  setlastmodified
__label__nflaky p{a\\/b c\\/d}s  {/  test  expansion  is  identical  {a}  /}{a b}  p\\{a/b c/d\\}s  {a b}/{b c}  check  expansion  is  identical  /}    p{a\\/b c\\/d}s  {/  testexpansionisidentical  {a}  /}{a b}  p\\{a/b c/d\\}s  {a b}/{b c}  checkexpansionisidentical  /}
__label__flaky cluster  name  node  adapter  ns  racks  conf  /rack2  wait  for  replication  /rack1  fs  ie  we  should  still  have  2  racks  after  reducing  the  repl  factor.  create  file  dfs  test  util  b  get  conf  file  path  test  reduce  repl  factor  respects  rack  policy  get  file  system  set  replication  replication_  factor  get  name  node  /test  file  build  num  data  nodes  *  reduce  the  replication  factor  of  a  file   making  sure  that  the  only  *  cross  rack  replica  is  not  removed  when  deleting  replicas.  create  a  file  with  one  block  get  first  block  shutdown  get  namesystem  cluster  namenodeadapter  ns  racks  conf  /rack2  waitforreplication  /rack1  fs   ie we should still have 2 racks after reducing the repl factor.  createfile  dfstestutil  b  getconf  filepath  testreducereplfactorrespectsrackpolicy  getfilesystem  setreplication  replication_factor  getnamenode  /testfile  build  numdatanodes       * reduce the replication factor of a file  making sure that the only     * cross rack replica is not removed when deleting replicas.        create a file with one block  getfirstblock  shutdown  getnamesystem
__label__nflaky write  object  in  stream  somehost  raw  outbuffer  assert  equals  test  serialization  out  stream  in  buffer  read  object  assert  orig  to  byte  array  clone  close  writeobject  instream  somehost  raw  outbuffer  assertequals  testserialization  outstream  inbuffer  readobject  assert  orig  tobytearray  clone  close
__label__flaky expected  a  <value>  a</value>  aaa  <name>a</name>  <job-tracker>foo</job-tracker>  validate  and  parse  </prepare>  </property>  <value>  c</value>  <script>script.q</script>  replace  all  system  <configuration>  </configuration>  <hive  xmlns=\""uri:oozie:hive-action:0.2\"">  app  a  <mkdir  path=\""/tmp\""  />  get  conf  test  parser  global  extension  actions  <prepare>  <name>b</name>  assert  equals  wf-schema-valid-global-ext.xml  <value>  b</value>  </hive>  <param>  input=/tmp/table</param>  io  utils  <name>c</name>  parser  <param>  output=/tmp/hive</param>  get  resource  as  reader  <property>  get  node  <delete  path=\""/tmp\""  />  <name-node>bar</name-node>  expecteda          <value>a</value>    aaa         <name>a</name>      <job-tracker>foo</job-tracker>    validateandparse    </prepare>        </property>          <value>c</value>      <script>script.q</script>    replaceall  system    <configuration>      </configuration>    <hive xmlns=\""uri:oozie:hive-action:0.2\"">    app     a      <mkdir path=\""/tmp\"" />    getconf  testparserglobalextensionactions    <prepare>          <name>b</name>    assertequals  wf-schema-valid-global-ext.xml        <value>b</value>    </hive>    <param>input=/tmp/table</param>    ioutils        <name>c</name>    parser    <param>output=/tmp/hive</param>    getresourceasreader      <property>    getnode      <delete path=\""/tmp\"" />      <name-node>bar</name-node>
__label__nflaky get  content  encoding  abc  content  type  byte  channel  standard  charsets  assert  false  assert  equals  get  content  length  produce  test  text  content  assert  is  open  producer  get  content  type  to  string  dump  stream  channel  getcontentencoding  abc  contenttype  bytechannel  standardcharsets  assertfalse  assertequals  getcontentlength  produce  testtextcontent  assert  isopen  producer  getcontenttype  tostring  dump  streamchannel
__label__flaky test  reconstruction  initial  count  res  table_  name  create  table  new  count  to  bytes  load  table  scan  count  assert  equals  test_  util  family  bytes  create  multi  regions  load  up  the  table  with  simple  rows  and  count  them  family  get  scanner  expire  region  server  session  results  close  table  testreconstruction  initialcount  res  table_name  createtable  newcount  tobytes  loadtable  scan  count  assertequals  test_util  family  bytes  createmultiregions   load up the table with simple rows and count them  family  getscanner  expireregionserversession  results  close  table
__label__nflaky encode  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  hints  barcode  format  expected  hello  google  assert  equals  matrix  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  put  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  x  encode  hint  type  size  test  data  matrix  image  writer  assert  not  null  to  string  writer  encode  x x x x x x x x   x   x   x       x x x x   x   x         x         x   x x     x     x x x x x x     x x x           x   x x       x   x x x   x           x x     x     x x x x x x   x   x   x x x       x x x x x x x   x       x   x     x     x x x x x x x x   x   x   x       x   x   x x x x     x x x x       x         x x       x x     x     x   x     x x x x       x x x x   x       x x       x x         x   x x   x   x x x x     x x x x x   x x x x x x x   x       x   x     x     hints  barcodeformat  expected  hello google  assertequals  matrix  x x x x x x x x   x   x   x       x   x   x     x x x x             x   x x x       x       x x       x     x x   x x     x x x x       x x       x x x x x     x     x   x   x   x         x x x x         x x x x x x x   x       x   x     x     x x x x x x x x   x   x   x       x x   x   x x x           x       x x     x       x x x     x       x x x x x x   x x   x     x x     x   x x x   x     x x x x x       x x x   x   x x x     x x         x x x x x x x   x       x   x     x     put  x x x x x x x x   x   x   x       x x x x   x   x   x x x x         x x   x   x           x x         x x x x   x x     x     x x x     x x   x           x       x x     x x x x x   x   x   x x x x x     x x x x x x x   x       x   x     x     x x x x x x x x   x   x   x       x x x x x   x   x x x x   x x     x           x   x       x x x x   x       x   x         x x x x     x           x x x   x       x x   x x x x   x   x x x x x   x x     x x x x x x x   x       x   x     x     encodehinttype  size  testdatamatriximagewriter  assertnotnull  tostring  writer
__label__flaky unexpected  exception  def  add  node  j1  j2  f1  f2  three  two  as  list  invoke  fork  join  four  dummy  conf  end  five  *  1->decision  node->{f1   f2}  *  f1->(2 3)  *  f2->(4 5)  *  (2 3)->j1  *  (4 5)->j2  *  j1->end  *  j2->end  print  stack  trace  e  one  k  kill  fail  test  decision  multiple  forks  parser  name  arrays  unexpected exception  def  addnode  j1  j2  f1  f2  three  two  aslist  invokeforkjoin  four  dummyconf  end  five         * 1->decision node->{f1  f2}       * f1->(2 3)       * f2->(4 5)       * (2 3)->j1       * (4 5)->j2       * j1->end       * j2->end         printstacktrace  e  one  k  kill  fail  testdecisionmultipleforks  parser  name  arrays
__label__nflaky parent  foo2://bar2/baz2  test  child  parent  resolution  assert  equals  foo1://bar1/baz1  child  parent  foo2://bar2/baz2  testchildparentresolution  assertequals  foo1://bar1/baz1  child
__label__flaky get  job  tracker  uri  a  get  name  <java>  get  status  create  context  action  xml  is  successful  load  assert  true  assert  not  null  get  context  end  <arg>out</arg>  wait  for  <job-tracker>  get  data  sr  get  name  node  uri  a  </java>  ae  </main-class>  <capture-output/>  </job-tracker>  running  job  get  action  assert  equals  check  test  output  submit  ok  get  external  status  <name-node>  <main-class>  props  </name-node>  workflow  action  succeeded  submit  action  evaluate  is  complete  getjobtrackeruri  a  getname  <java>  getstatus  createcontext  actionxml  issuccessful  load  asserttrue  assertnotnull  get  context  end  <arg>out</arg>  waitfor  <job-tracker>  getdata  sr  getnamenodeuri  a  </java>  ae  </main-class>  <capture-output/>  </job-tracker>  runningjob  getaction  assertequals  check  testoutputsubmitok  getexternalstatus  <name-node>  <main-class>  props  </name-node>  workflowaction  succeeded  submitaction  evaluate  iscomplete
__label__nflaky 12345678901234561234512345  get  name  dst  codec  test  utils  channel  convert  assert  inbuf  assert  true  get  is  completed  read  fghij  test  complex  decoding  standard  charsets  footer1  has  remaining  abcde  footer2  clear  bytes  read  5  12345  5  12345  0  footer1:  abcde  footer2:  fghij  assert  equals  decoder  byte  buffer  10;key=\""value\""  1234567890123456  trailers  get  value  allocate  size  metrics  get  trailers  12345678901234561234512345  getname  dst  codectestutils  channel  convert  assert  inbuf  asserttrue  get  iscompleted  read  fghij  testcomplexdecoding  standardcharsets  footer1  hasremaining  abcde  footer2  clear  bytesread  5  12345  5  12345  0  footer1: abcde  footer2: fghij      assertequals  decoder  bytebuffer  10;key=\""value\""  1234567890123456    trailers  getvalue  allocate  size  metrics  gettrailers
__label__flaky a  fail  test  not  null  elements  name  not  empty  elements  arrays  param  checker  as  list  a  fail  testnotnullelements  name  notemptyelements  arrays  paramchecker  aslist
__label__nflaky encode  a  \""  data  assert  false  specifically_exclude_special_cookie_chars  assert  equals     decode  in  map  put  contains  size  get  \"" ;\\  ;  \\  out  map  encode     a  \""  data  assertfalse  specifically_exclude_special_cookie_chars  assertequals     decode  inmap  put  contains  size  get   \"" ;\\  ;  \\  outmap
__label__flaky dag  el  functions  def  conf  dir  create  evaluator  ${fs:file  size(wf:conf(\'file2\'))}  proto  conf  get  test  case  dir  create  set  id  action  set  user  write  group  test  functions  workflow  test.dir  ${fs:file  size(wf:conf(\'file1\'))}  get  file  system     ${fs:block  size(wf:conf(\'file2\'))}  oozie  client  set  group  eval  ${fs:exists(wf:conf(\'file1\'))}  mkdirs  ${fs:exists(wf:conf(\'dir\'))}  name  action  id  ${fs:exists(wf:conf(\'file2\'))}  job  evaluate  action  name  set  name  add  node  write  xml  get  id  fs  app  path  set  app  path  baos  ${file2}  wf  assert  true  configure  evaluator  get  <workflow-app/>  end  hadoop.job.ugi  close  set  proto  action  conf  set  workflow  instance  ${fs:block  size(wf:conf(\'file1\'))}  arr  a  b  set  app  name  set  os  assert  equals  ${fs:is  dir(wf:conf(\'file1\'))}  services  get  test  user  ${fs:dir  size(wf:conf(\'dir\'))}  file2  file3  to  string  file1  wf  id  get  fs  test  case  dir  dagelfunctions  def  conf  dir  createevaluator  ${fs:filesize(wf:conf(\'file2\'))}  protoconf  gettestcasedir  create  setid  action  setuser  write  group  testfunctions  workflow  test.dir  ${fs:filesize(wf:conf(\'file1\'))}  getfilesystem     ${fs:blocksize(wf:conf(\'file2\'))}  oozieclient  setgroup  eval  ${fs:exists(wf:conf(\'file1\'))}  mkdirs  ${fs:exists(wf:conf(\'dir\'))}  name  actionid  ${fs:exists(wf:conf(\'file2\'))}  job  evaluate  actionname  setname  addnode  writexml  getid  fs  apppath  setapppath  baos  ${file2}  wf  asserttrue  configureevaluator  get  <workflow-app/>  end  hadoop.job.ugi  close  setprotoactionconf  setworkflowinstance  ${fs:blocksize(wf:conf(\'file1\'))}  arr  a  b  setappname  set  os  assertequals  ${fs:isdir(wf:conf(\'file1\'))}  services  gettestuser  ${fs:dirsize(wf:conf(\'dir\'))}  file2  file3  tostring  file1  wfid  getfstestcasedir
__label__nflaky add  create  the  framework  without  deleting  the  default  tests.  request  adapter  method  set  adapter  already  checked  response  called  method  set  execute  method  not  in  default  tests.  method=  contains  testing  framework  framework  assert  default  tests  with  mocked  adapter  run  tests  assert  true  get  method  add   create the framework without deleting the default tests.  request  adapter  method  setadapter  alreadycheckedresponse  calledmethodset  execute  method not in default tests.  method=  contains  testingframework  framework  assert  defaulttestswithmockedadapter  runtests  asserttrue  get  method
__label__flaky check  whether  transactions  are  rolled  back  or  not  expected  exception  due  to  commit  failure  but  didn\'t  get  any  prep  get  id  workflow  instance  action  get  cmd  deactivate  test  bulk  insert  updates  rollback  wf  bean  add  record  to  wf  job  table  get  error  code  assert  not  null  wf  update  cmd1  get  workflow  job  update  list  add  get  status  str  insert  list  expected  exception  but  didnt  get  any  wf  get  cmd  assert  equals  skip  commit  fault  injection  add  two  actions  to  insert  list  execute  set  status  fault  injection  1  services  fail  jpaee  2  workflow  action  org.apache.oozie.command.  skip  commit  fault  injection  set  system  property  true  create  workflow  action  action1  set  fault  injection  to  true   so  transaction  is  roll  backed  error  code  job  action2  add  to  update  list  status  should  not  be  running  jpa  service   check whether transactions are rolled back or not  expected exception due to commit failure but didn\'t get any  prep  getid  workflowinstance  actiongetcmd  deactivate  testbulkinsertupdatesrollback  wfbean  addrecordtowfjobtable  geterrorcode  assertnotnull  wfupdatecmd1  get  workflowjob  updatelist  add  getstatusstr  insertlist  expected exception but didnt get any  wfgetcmd  assertequals  skipcommitfaultinjection   add two actions to insert list  execute  setstatus  faultinjection  1  services  fail  jpaee  2  workflowaction  org.apache.oozie.command.skipcommitfaultinjection  setsystemproperty  true  createworkflowaction  action1   set fault injection to true  so transaction is roll backed  errorcode  job  action2   add to update list   status should not be running  jpaservice
__label__nflaky date  format  get  time  zone  equal  to  core  matchers  invoke  string  compare  to  when  get  bytes  cal  assert  true  test  valid  xml  body  context  set  time  zone  xml  document  close  set  time  body  parser  engine  xml  then  return  calendar  body  parser  engine  xml  test  format  test  form  is  parse  assert  that  get  input  stream  time  zone  <form><first  name>\%s</first  name><last  name>\%s</last  name><birth  year>\%d</birth  year><last  seen>\%s</last  seen></form>  mockito  xml  obj  mapper  get  instance  dateformat  gettimezone  equalto  corematchers  invoke  string  compareto  when  getbytes  cal  asserttrue  testvalidxmlbody  context  settimezone  xmldocument  close  settime  bodyparserenginexml  thenreturn  calendar  bodyparserenginexmltest  format  testform  is  parse  assertthat  getinputstream  timezone  <form><firstname>\%s</firstname><lastname>\%s</lastname><birthyear>\%d</birthyear><lastseen>\%s</lastseen></form>  mockito  xmlobjmapper  getinstance
__label__flaky custom  grab  metadata.groovy  grape.root  system  javax.ejb\\:ejb-api=3.0  target  target/repository/test/test/1.0.0  test-1.0.0.properties  test  artifact  assert  true  set  property  mkdirs  custom  metadata  writer  test  artifact  dir  create  new  file  grab  close  --autoconfigure=false  target/repository/javax/ejb/ejb-api/3.0  is  directory  customgrabmetadata.groovy  grape.root  system  javax.ejb\\:ejb-api=3.0  target  target/repository/test/test/1.0.0  test-1.0.0.properties  testartifact  asserttrue  setproperty  mkdirs  custommetadata  writer  testartifactdir  createnewfile  grab  close  --autoconfigure=false  target/repository/javax/ejb/ejb-api/3.0  isdirectory
__label__nflaky create  user  for  testing  ip_  range  set  now  set  a  blocked  machine  list  drwho  refresh  blocked_  host_  config  conf  test  blocked  machine  list  drwho@  example.  com  group2  group1  service  authorization  manager  fail  reset  blocked  machine  list  test  without  setting  a  blocked  machine  list  get  by  name  inet  address  authorize  10.222.0.0  user  group  information  createuserfortesting    ip_range  set   now set a blocked machinelist  drwho  refresh  blocked_host_config  conf  testblockedmachinelist  drwho@example.com  group2  group1  serviceauthorizationmanager  fail   reset blocked machinelist   test without setting a blocked machinelist  getbyname  inetaddress  authorize  10.222.0.0  usergroupinformation
__label__flaky cluster  blockfile  datanode  find  block  file  conf  create  file  get  bytes  wait  active  test  lease  expire  hard  limit  start  lease  period  should  be  replicated  to  get  namenode  set  lease  period  write  datanodes.  get  block  pool  id  in  get  file  system  something  set  int  dfs  get  wrapped  stream  successcount  test  lease  expire  hard  limit  successful  num  data  nodes  actual  repl  datanode_  num  long  get  data  node  dfs_  heartbeat_  interval_  key  get  locations  shutdown  get  block  locations  get  located  blocks  create  cluster  foo  system  out  sleep  hflush  get  block  id  assert  true  close  stream  get  blockfile=  fpath  create  a  new  file.  close  dfs_  namenode_  heartbeat_  recheck_  interval_  key  blk  datanodeinfo  get  block  b  f  wait  for  the  lease  to  expire  assert  equals  test  file  creation  successcount=  dir  read  line  get  stored  block  get  num  current  replicas  thread  test  lease  expire  hard  limit  locatedblock  io  utils  build  locations  namenode  triggers  lease  recovery  dataset  located  block  count  cluster  blockfile  datanode  findblockfile  conf  createfile  getbytes  waitactive  testleaseexpirehardlimit start  leaseperiod   should be replicated to   getnamenode  setleaseperiod  write   datanodes.  getblockpoolid  in  getfilesystem  something  setint  dfs  getwrappedstream  successcount  testleaseexpirehardlimit successful  numdatanodes  actualrepl  datanode_num  long  getdatanode  dfs_heartbeat_interval_key  getlocations  shutdown  getblocklocations  getlocatedblocks   create cluster  foo  system  out  sleep  hflush  getblockid  asserttrue  closestream  get  blockfile=  fpath   create a new file.  close  dfs_namenode_heartbeat_recheck_interval_key  blk  datanodeinfo  getblock  b  f   wait for the lease to expire  assertequals  testfilecreation  successcount=  dir  readline  getstoredblock  getnumcurrentreplicas  thread  testleaseexpirehardlimit  locatedblock  ioutils  build  locations   namenode triggers lease recovery  dataset  locatedblockcount
__label__nflaky get  class  first   transparently  via  object  writable  object  writable  result  set  out  assert  true  get  write  a  big  set  of  data   one  of  each  primitive  type  array  expected  result  set  write  get  data  in  deep  equals  write  object  validate  data  structures  and  values  in  and  out  arrays  didn\'t  match  values  apw  assert  equals  read  object  second   explicitly  big  set  read  fields  first   transparently  component  type  of  array  test  many  now  read  the  data  back  in  get  component  type  get  length  reset  second   explicitly  via  array  primitive  writable  arrays  getclass   first  transparently via objectwritable  objectwritable  resultset  out  asserttrue  get   write a big set of data  one of each primitive type array  expectedresultset  write  getdata  in  deepequals  writeobject   validate data structures and values  in and out arrays didn\'t match values  apw  assertequals  readobject   second  explicitly  bigset  readfields   first  transparently  componenttype of array   testmany   now read the data back in  getcomponenttype  getlength  reset   second  explicitly via arrayprimitivewritable  arrays
__label__flaky cluster  num_  of_  datanodes  get  metrics  conf  test  datanode  report  wait  until  the  cluster  is  up  remove  wait  active  sleep  client  addr  localhost  dfs  config  keys  get  data  nodes  0.5s  datanode  report  bring  down  one  datanode  assert  equals  assert  counter  set  int  datanodes  thread  set  long  size  build  num  data  nodes  expired  heartbeats  get  name  node  port  node  info  shutdown  fs  namesystem  datanode  report  type  cluster  num_of_datanodes  getmetrics  conf  testdatanodereport   wait until the cluster is up  remove  waitactive  sleep  client  addr  localhost  dfsconfigkeys  getdatanodes   0.5s  datanodereport   bring down one datanode  assertequals  assertcounter  setint  datanodes  thread  setlong  size  build  numdatanodes  expiredheartbeats  getnamenodeport  nodeinfo  shutdown  fsnamesystem  datanodereporttype
__label__nflaky request  get  name  authentication  required  send  error  when  as  list  get  init  parameter  names  do  answer  assert  do  filter  verify  management.operation.return  http://foo:8080/bar  get  request  url  init  chain  authentication  filter  then  return  www-  authenticate  destroy  http  servlet  response  any  test  do  filter  not  authenticated  filter  fail  get  mocked  servlet  context  with  string  signer  get  init  parameter  answer  mockito  response  elements  true  mock  contains  header  arrays  config  request  getname  authentication required  senderror  when  aslist  getinitparameternames  doanswer  assert  dofilter  verify  management.operation.return  http://foo:8080/bar  getrequesturl  init  chain  authenticationfilter  thenreturn  www-authenticate  destroy  httpservletresponse  any  testdofilternotauthenticated  filter  fail  getmockedservletcontextwithstringsigner  getinitparameter  answer  mockito  response  elements  true  mock  containsheader  arrays  config
__label__flaky call  post  my  json  rest  servlet  get  http  servlet  response  invoke  assert  equals  test  multiple  resources  /resource1  /resource2  run  test    call  post  myjsonrestservlet  get  httpservletresponse  invoke  assertequals  testmultipleresources  /resource1  /resource2  runtest
__label__nflaky test  simple  edit  exit  code  run  -alias  dt  assert  true  test  simple  edit  output  service  old:  out  content  test  simple  edit  print  old  exit  code  test  edit  test  simple  edit  output  kind  old:  edit  service2  old  service  test  simple  edit  print  new  exit  code  assert  equals  test  simple  edit  output  kind  new:  args  -service  rc  token  filename2  print  contains  kind  to  string  new  name:12345  new  alias  test  simple  edit  output  service  new:  test simple edit exit code  run  -alias  dt  asserttrue  test simple edit output service old:    outcontent  test simple edit print old exit code  testedit  test simple edit output kind old:    edit  service2  oldservice  test simple edit print new exit code  assertequals  test simple edit output kind new:    args  -service  rc  tokenfilename2  print  contains  kind  tostring  newname:12345  newalias  test simple edit output service new:
__label__flaky init  generate  id  destroy  counter  services  0001000-  uuid  application  type  assert  true  test  padding  set  system  property  get  0000000-  uuid  service  id  starts  with  init  generateid  destroy  counter  services  0001000-  uuid  applicationtype  asserttrue  testpadding  setsystemproperty  get  0000000-  uuidservice  id  startswith
__label__nflaky test  verify  checksum  passthru  mock  verify  reset  set  verify  checksum  mock  fs  eq  fs  testverifychecksumpassthru  mock  verify  reset  setverifychecksum  mockfs  eq  fs
__label__flaky server  check  coord  action  new  h  cat  dependency2  new  h  cat  dependency1  coord  el  functions  populate  table  hcat://  add  init  records  test  for  two  dependencies  which  are  already  in  the  hcat  server  /  call  default  /dt=20120430;country=usa  /dt=20120412;country=brazil  coordinator  action  action  id  tablename  new  h  cat  dependency  test  update  coord  table  multiple  deps  v1  db  table    server  checkcoordaction  newhcatdependency2  newhcatdependency1  coordelfunctions  populatetable  hcat://  addinitrecords   test for two dependencies which are already in the hcat server  /  call  default  /dt=20120430;country=usa  /dt=20120412;country=brazil  coordinatoraction  actionid  tablename  newhcatdependency  testupdatecoordtablemultipledepsv1  db  table
__label__nflaky read  do  return  input  stream  test  copy  bytes  should  close  streams  when  close  is  true  when  at  least  once  io  utils  mockito  mock  verify  output  stream  close  copy  bytes  read  doreturn  inputstream  testcopybytesshouldclosestreamswhencloseistrue  when  atleastonce  ioutils  mockito  mock  verify  outputstream  close  copybytes
__label__flaky cluster  ha  test  util  get  canonical  service  name  spy  ns  list  status  conf  logical  host  lookup  all  host  addr  fs  root  verify  get  host  get  conf  get  file  context  test  file  context  doesnt  dns  resolve  logical  uri  eq  ensure  that  the  logical  hostname  was  never  resolved.  configure  failover  fs  /  never  get  default  file  system  mockito  make  qualified  spy  on  name  service  ha  client  conf  fc  get  uri  file  context  cluster  hatestutil  getcanonicalservicename  spyns  liststatus  conf  logicalhost  lookupallhostaddr  fs  root  verify  gethost  getconf  getfilecontext  testfilecontextdoesntdnsresolvelogicaluri  eq   ensure that the logical hostname was never resolved.  configurefailoverfs  /  never  getdefaultfilesystem  mockito  makequalified  spyonnameservice  haclientconf  fc  geturi  filecontext
__label__nflaky path  net  utils  create  test  canonical  uri  with  path  to  string  assert  equals  uri  uri  get  canonical  uri  /path  path  netutils  create  testcanonicaluriwithpath  tostring  assertequals  uri  uri  getcanonicaluri  /path
__label__flaky test  some  methods  end_  points  archive2  is_  security_  enabled  oozie  url  configuration  add  archive  wc  file1 file2  get  archive1  servlet_  classes  run  test  get  context  url  e  x  oozie  client  archive1 archive2  get  message  assert  equals  call  file  cannot  be  null  or  empty  file2  create  configuration  file1  test  archive  add  file  testsomemethods  end_points  archive2  is_security_enabled  oozieurl  configuration  addarchive  wc  file1 file2  get  archive1  servlet_classes  runtest  getcontexturl  e  xoozieclient  archive1 archive2  getmessage  assertequals  call  file cannot be null or empty  file2  createconfiguration  file1   test archive  addfile
__label__nflaky next  get  endpoints  await  shutdown  get  status  io  reactor  listen  iterator  endpoint  assert  io  reactor  status  assert  not  null  get  get  address  close  time  value  endpoint1  endpoint2  of  seconds  endpoints  start  assert  equals  future1  future2  get  port  size  port  test  endpoint  up  and  down  close  mode  next  getendpoints  awaitshutdown  getstatus  ioreactor  listen  iterator  endpoint  assert  ioreactorstatus  assertnotnull  get  getaddress  close  timevalue  endpoint1  endpoint2  ofseconds  endpoints  start  assertequals  future1  future2  getport  size  port  testendpointupanddown  closemode
__label__flaky get  name  file  f  file  d  src/test/resources/resource-matcher/three  bravo/file  e  bravo/file  c  three  as  list  system  assert  true  src/test/resources/resource-matcher/one  find  resource  matching  bravo/*  matched  resources  add  resource  contains  all  alpha/**  *  assert  equals  alpha/nested/file  a  resource  matcher  size  paths  alpha/**/excluded  arrays  .*  src/test/resources/resource-matcher/two  getname  filef  filed  src/test/resources/resource-matcher/three  bravo/filee  bravo/filec  three  aslist  system  asserttrue  src/test/resources/resource-matcher/one  find  resourcematching  bravo/*  matchedresources  add  resource  containsall  alpha/**  *  assertequals  alpha/nested/filea  resourcematcher  size  paths  alpha/**/excluded  arrays  .*  src/test/resources/resource-matcher/two
__label__nflaky add  e  start  get  message  tsl  could  not  open    should  be  greater  than  or  equal  to  1  input/joran/  filename  size  assert  true  do  test  core  test  constants  nothere  blah.xml  get  inexistent  file  context  get  status  manager  s0  starts  with  add  e  start  getmessage  tsl  could not open    should be greater than or equal to 1  input/joran/  filename  size  asserttrue  dotest  coretestconstants  nothereblah.xml  get  inexistentfile  context  getstatusmanager  s0  startswith
__label__flaky tfs  /0  clients  get  clients  test  m  tfs  ls  assert  equals  m  local  tachyon  cluster  multi  master  get  client  k  create  file  /  assert  size  get  files  tfs  /0  clients  getclientstest  mtfs  ls  assertequals  mlocaltachyonclustermultimaster  getclient  k  createfile  /  assert  size  get  files
__label__nflaky then  return  true  context  prim  boolean  param  create  verify  invoke  prim  boolean  param  should  be  parsed  to  boolean  when  param1  mock  controller  get  parameter  thenreturn  true  context  primbooleanparam  create  verify  invoke  primbooleanparamshouldbeparsedtoboolean  when  param1  mockcontroller  getparameter
__label__flaky init  coord  el  functions  ${coord:data  out(\'  efg\')}  set  variable  assert  equals  ${coord:data  in(\'  abc\')}  data-in  ${coord:data  in(\'  abcd\')}  coord-job-submit-data  fail  should  throw  exception  beacuse  data  in  is  not  defiend  eval  eval  and  wrap  ${coord:data  out(\'  efgh\')}  test  data  names  ph1  expr  oozie.dataname.  abc  data-out  oozie.dataname.  efg  init  coordelfunctions  ${coord:dataout(\'efg\')}  setvariable  assertequals  ${coord:datain(\'abc\')}  data-in  ${coord:datain(\'abcd\')}  coord-job-submit-data  fail  should throw exception beacuse data in is not defiend  eval  evalandwrap  ${coord:dataout(\'efgh\')}  testdatanamesph1  expr  oozie.dataname.abc  data-out  oozie.dataname.efg
__label__nflaky result  test  and  add  headers  add  header  header2  header1  value2  get  headers  size  value1  get  assert  equals  result  testandaddheaders  addheader  header2  header1  value2  getheaders  size  value1  get  assertequals
__label__flaky call  fail  add  record  to  bundle  job  table  bundle-id  test  bundle  start  negative1  job  job  doesn\'t  exist.  should  fail.  call  fail  addrecordtobundlejobtable  bundle-id  testbundlestartnegative1  job  job doesn\'t exist. should fail.
__label__nflaky process  watch  event  data  become  standby  assert  false  test  successive  standby  calls  when  zk_  lock_  name  times  assert  is  standby.  no  need  to  notify  anything  now  assert  true  monitoring  should  be  setup  again  after  event  is  received  mock  event  get  path  verify  ids  create  another  join  election  called.  verify  exist  call  monitor  is  set  again  mock  app  stat  int  value  then  return  lost  election  enter  neutral  mode  process  result  make  the  object  go  into  the  monitoring  standby  state  elector  code  still  standby.  so  no  need  to  notify  again  is  monitor  lock  node  pending  mock  zk  set  ephemeral  owner  create  mode  mockito  get  type  join  election  mock  event  get  session  id  processwatchevent  data  becomestandby  assertfalse  testsuccessivestandbycalls  when  zk_lock_name  times  assert   is standby. no need to notify anything now  asserttrue   monitoring should be setup again after event is received  mockevent  getpath  verify  ids  create   another joinelection called.  verifyexistcall   monitor is set again  mockapp  stat  intvalue  thenreturn   lost election  enterneutralmode  processresult   make the object go into the monitoring standby state  elector  code   still standby. so no need to notify again  ismonitorlocknodepending  mockzk  setephemeralowner  createmode  mockito  gettype  joinelection  mock  event  getsessionid
__label__flaky format  date  expires:  last-  modified:  headers  add  header  get  headers  last  modified  date  if-  modified-  since:  contains  assert  true  time  unit  cache  control  no  cache  and  expiration  date  in  the  future  assert  conditionally  cached  conditional  request  cache-  control:  no-cache  formatdate  expires:   last-modified:   headers  addheader  getheaders  lastmodifieddate  if-modified-since:   contains  asserttrue  timeunit  cachecontrolnocacheandexpirationdateinthefuture  assertconditionallycached  conditionalrequest  cache-control: no-cache
__label__nflaky prepare  item5ca  conf  set  root  expression  when  set  out  out  result  set  min  depth  find  in  order  verify  set  options  expr  finish  item1b  item1a  item5e  process  arguments  min  depth  item5d  item5c  create  directories  item5b  item5a  set  err  fs  check  err  test  in  order  fs  check  apply  then  return  check  process  arguments  any  set  conf  any  int  verify  no  more  interactions  mock  get  options  item1aa  items  check  minimum  depth  is  handledfollow  link  prepare  item5ca  conf  setrootexpression  when  setout  out  result  setmindepth  find  inorder  verify  setoptions  expr  finish  item1b  item1a  item5e  processargumentsmindepth  item5d  item5c  createdirectories  item5b  item5a  seterr  fscheck  err  test  inorderfscheck  apply  thenreturn  check  processarguments  any  setconf  anyint  verifynomoreinteractions  mock  getoptions  item1aa  items   check minimum depth is handledfollowlink
__label__flaky play  ping  android  play  it  back  header  entries  verify  the  peer  received  what  was  expected  source  system  accept  frame  elapsed  nanos  stream  open  stream  count  type_  headers  peer  nano  time  round  trip  time  time  unit  connection  to  millis  prevent  the  peer  from  exiting  prematurely.  take  frame  banana  a  b  syn  reply  read  read  timeout  expires  assert  equals  set  read  timeout  fail  syn_  stream  send  frame  spdy3  get  source  ping  syn  stream  new  stream  start  nanos  play  ping  android   play it back  headerentries   verify the peer received what was expected  source  system  acceptframe  elapsednanos  stream  openstreamcount  type_headers  peer  nanotime  roundtriptime  timeunit  connection  tomillis   prevent the peer from exiting prematurely.  takeframe  banana  a  b  synreply  read  readtimeoutexpires  assertequals  setreadtimeout  fail   syn_stream  sendframe  spdy3  getsource   ping  synstream  newstream  startnanos
__label__nflaky get  authentication  handler  configuration  _test  authentication  test  authentication  anonymous  disallowed  auth  authenticator  test  case  set  authentication  handler  config  getauthenticationhandlerconfiguration  _testauthentication  testauthenticationanonymousdisallowed  auth  authenticatortestcase  setauthenticationhandlerconfig
__label__flaky rest  constants  get  time  2009-12-15  t01:00  z  get  id  assert  equals  coord  job  get  executor  get  status  add  record  to  coord  action  table  execute  test  coord  rerun  in  paused  with  error  call  get  pause  time  services  pause  time  assert  not  null  get  coordinator  action  curr  job  job  jpa  service  coord-rerun-action1.xml  add  record  to  coord  job  table  with  paused  time  restconstants  gettime  2009-12-15t01:00z  getid  assertequals  coordjobgetexecutor  getstatus  addrecordtocoordactiontable  execute  testcoordreruninpausedwitherror  call  getpausetime  services  pausetime  assertnotnull  get  coordinatoraction  curr  job  job  jpaservice  coord-rerun-action1.xml  addrecordtocoordjobtablewithpausedtime
__label__nflaky check  fs  conf  test  get  local  fs  sets  confs  get  local  file  system  lfs  conf  checkfsconf  testgetlocalfssetsconfs  getlocal  filesystem  lfs  conf
__label__flaky get  class  </prepare>  do  operations  expected  to  catch  an  exception  but  did  not  encounter  any  expected  a  launcher  exception  but  received  an  exception  conf  fs  delete  get  cause  create  job  conf  content  is  not  allowed  in  prolog.  launcher  mapper  <mkdir  path=\'  \'/>  action  dir  delete  the  file  if  it  is  already  there  get  message  test  do  operations  with  invalid  xml  assert  equals  get  file  system  prepare>  test  to  check  if  launcher  exception  is  thrown  when  the  prepare  xml  block  is  invalid  fail  new  dir  prepare  xml  exists  le  setup  launcher  uri  handler  conf  prepare  actions  driver  get  fs  test  case  dir    getclass  </prepare>  dooperations  expected to catch an exception but did not encounter any  expected a launcherexception but received an exception  conf  fs  delete  getcause  createjobconf  content is not allowed in prolog.  launchermapper  <mkdir path=\'  \'/>  actiondir   delete the file if it is already there  getmessage  testdooperationswithinvalidxml  assertequals  getfilesystem  prepare>   test to check if launcherexception is thrown when the prepare xml block is invalid  fail  newdir  preparexml  exists  le  setuplauncherurihandlerconf  prepareactionsdriver  getfstestcasedir
__label__nflaky colin  new  token  get  sequence  number  get  user  alice  clone  orig  token  into  new  token  test  serialization  orig  token  out  buf  now  test  the  fields  set  issue  date  get  issue  date  get  user  name  get  master  key  id  write  get  data  get  max  date  assert  equals  get  real  user  get  renewer  read  fields  set  master  key  id  bob  in  buf  set  sequence  number  set  max  date  get  length  reset  colin  newtoken  getsequencenumber  getuser  alice   clone origtoken into newtoken  testserialization  origtoken  outbuf   now test the fields  setissuedate  getissuedate  getusername  getmasterkeyid  write  getdata  getmaxdate  assertequals  getrealuser  getrenewer  readfields  setmasterkeyid  bob  inbuf  setsequencenumber  setmaxdate  getlength  reset
__label__flaky date  script  executor  and  date  =  \'2015-10-01  00:00:00+0000\'  session  given  update  simple  update  simple  set  simpleset  =  simpleset  +  {3}  where  id  =  eq  select  simpleset  from  simple  where  id  =  simpleset  contains  exactly  sets  when  of  where  id  row  table  execute  script  template  random  utils  manager  get  set  one  next  long  simple  set_  remove  all  from  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  simple  set  new  hash  set  then  should_dsl_update_set_remove  all  long  build  date  key  from  base  table  dsl  date  scriptexecutor  and date = \'2015-10-01 00:00:00+0000\'  session   given  update  simple  update simple set simpleset = simpleset + {3} where id =   eq  select simpleset from simple where id =   simpleset  containsexactly  sets   when  of  where  id  row  table  executescripttemplate  randomutils  manager  getset  one  nextlong  simpleset_removeallfrom  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  simpleset  newhashset   then  should_dsl_update_set_removeall  long  builddatekey  frombasetable  dsl
__label__nflaky get  name  set  fs2  fs1  conf  get  file  system  class  fs.uncachedfile.impl  file  uncachedfile://a  file  system  get  assert  not  same  test  cache  disabled  fs.uncachedfile.impl.disable.cache  set  boolean  getname  set  fs2  fs1  conf  getfilesystemclass  fs.uncachedfile.impl  file  uncachedfile://a  filesystem  get  assertnotsame  testcachedisabled  fs.uncachedfile.impl.disable.cache  setboolean
__label__flaky prep  get  id  workflow  instance  action  get  cmd  coord  job  wf  bean  add  record  to  wf  job  table  assert  not  null  get  add  two  jobs  to  update  list  workflow  job  job  test  bulk  insert  updates  update  list  add  get  status  str  insert  list  running  wf  get  cmd  assert  equals  add  two  actions  to  insert  list  execute  add  record  to  coord  job  table  set  status  coordinator  job  1  services  2  workflow  action  bulk  update  cmd  succeeded  create  workflow  action  action1  job  action2  jpa  service  prep  getid  workflowinstance  actiongetcmd  coordjob  wfbean  addrecordtowfjobtable  assertnotnull  get   add two jobs to update list  workflowjob  job  testbulkinsertupdates  updatelist  add  getstatusstr  insertlist  running  wfgetcmd  assertequals   add two actions to insert list  execute  addrecordtocoordjobtable  setstatus  coordinatorjob  1  services  2  workflowaction  bulkupdatecmd  succeeded  createworkflowaction  action1  job  action2  jpaservice
__label__nflaky data  received  create  error  from  zookeeper.  code:  connectionloss  mock  no  prior  active  when  zk_  lock_  name  notify  fatal  error  times  assert  verify  ids  create  verify  exist  call  mock  app  stat  for  path  4  errors  results  in  fatal  error  int  value  not  retrying  further  znode  create  connection  errors.  then  return  recreate  connection  via  get  new  zoo  keeper  count  process  result  assert  equals  elector  code  mock  zk  .  set  ephemeral  owner  create  mode  mockito  become  active  join  election  test  create  node  result  retry  become  active  get  session  id  data  received create error from zookeeper. code:connectionloss   mocknoprioractive  when  zk_lock_name  notifyfatalerror  times  assert  verify  ids  create  verifyexistcall  mockapp  stat  for path    4 errors results in fatalerror  intvalue  not retrying further znode create connection errors.  thenreturn   recreate connection via getnewzookeeper  count  processresult  assertequals  elector  code  mockzk  .   setephemeralowner  createmode  mockito  becomeactive  joinelection  testcreatenoderesultretrybecomeactive  getsessionid
__label__flaky def  add  node  expected  to  catch  an  exception  but  did  not  encounter  any  three  two  get  cause  as  list  we  invoke  fork  join  get  error  code  assert  true  four  dummy  conf  end  f  one  get  message  j  assert  equals  k  kill  make  sure  the  message  contains  the  node  involved  in  the  invalid  transition  fail  contains  ex  parser  name  *f->(2 3)  *2->decision  node->{3 4}  *3->ok->j  *3->fail->k  *4->ok->j  *4->fail->k  *j->end  test  decision  fork  join  failure  error  code  arrays  def  addnode  expected to catch an exception but did not encounter any  three  two  getcause  aslist  we  invokeforkjoin  geterrorcode  asserttrue  four  dummyconf  end  f  one  getmessage  j  assertequals  k  kill   make sure the message contains the node involved in the invalid transition  fail  contains  ex  parser  name         *f->(2 3)       *2->decision node->{3 4}       *3->ok->j       *3->fail->k       *4->ok->j       *4->fail->k       *j->end         testdecisionforkjoinfailure  errorcode  arrays
__label__nflaky test  explicit  passphrase  set  password  ssl  test  constants  set  location  assert  not  null  create  key  store  factory  bean  ssl  testexplicitpassphrase  setpassword  ssltestconstants  setlocation  assertnotnull  createkeystore  factorybean  ssl
__label__flaky /a1/a2  cluster  /b1/b2/b3.txt  conf  error  fs  wait  active  out  check  permission  dir  perm  string  utils  get  default  replication  file  system  get  create  fs  permission  close  write  /c1  /a1  dfs  config  keys  set  e  log  test  create  stringify  exception  file  perm  permission  io.file.buffer.size  get  default  block  size  /b1/b2  /  000  inherit  perm  022  get  int  build  /a1/a2/a3  num  data  nodes  mkdirs  /c1/c2.txt  create  immutable  shutdown  root  perm  to  short  /b1  set  boolean  /a1/a2  cluster  /b1/b2/b3.txt  conf  error  fs  waitactive  out  checkpermission  dirperm  stringutils  getdefaultreplication  filesystem  get  create  fspermission  close  write  /c1  /a1  dfsconfigkeys  set  e  log  testcreate  stringifyexception  fileperm  permission  io.file.buffer.size  getdefaultblocksize  /b1/b2  /  000  inheritperm  022  getint  build  /a1/a2/a3  numdatanodes  mkdirs  /c1/c2.txt  createimmutable  shutdown  rootperm  toshort  /b1  setboolean
__label__nflaky source  get  bytes  make  sure  the  channels  are  still  open  add  thread  interrupted  io  exception.  first  open  pipe:  interrupt  pipe  write  test_  string  info  read  in  ste  log  sink  ctx  generic  test  utils  fail  write  bytes  is  open  stop  assert  exception  contains  timeout  arrays  larger  buffers  in  do  io.  nothing  helped  the  situation  though.  assert  false  out  sleep  got  expection  while  reading  as  expected  :  shell  assert  true  do  work  start  threads  test  socket  io  with  timeout  byte  with  high  bit  close  do  io  stream  is  closed  *  verify  that  it  handles  interrupted  threads  properly.  *  use  a  large  timeout  and  expect  the  thread  to  return  quickly  *  upon  interruption.  did  not  throw  change  timeout  on  the  read  side.  get  message  assert  equals  pipe  thread  thread  set  timeout  make  sure  close()  closes  the  underlying  channel.  equals  close  sink  and  expect  -1  from  source.read()  did  not  fail  with  interrupt  read  bytes  open  ioe  source  getbytes   make sure the channels are still open  addthread   interruptedioexception.   first open pipe:  interrupt  pipe  write  test_string  info  read  in  ste  log  sink  ctx  generictestutils  fail  writebytes  isopen  stop  assertexceptioncontains  timeout  arrays   larger buffers in doio.  nothing helped the situation though.  assertfalse  out  sleep  got expection while reading as expected :   shell  asserttrue  dowork  startthreads  testsocketiowithtimeout  bytewithhighbit  close  doio  stream is closed           * verify that it handles interrupted threads properly.         * use a large timeout and expect the thread to return quickly         * upon interruption.           did not throw   change timeout on the read side.  getmessage  assertequals  pipe  thread  thread  settimeout   make sure close() closes the underlying channel.  equals   close sink and expect -1 from source.read()  did not fail with interrupt  readbytes  open  ioe
__label__flaky cluster  dfs  config  keys  set  conf  get  file  system  simulated  storage  dfs.datanode.simulateddatastorage  1  build  file  sys  file1  close  smallblocktest.dat  write  file  test  small  block  shutdown  cleanup  file  set  boolean  check  file  cluster  dfsconfigkeys  set  conf  getfilesystem  simulatedstorage  dfs.datanode.simulateddatastorage  1  build  filesys  file1  close  smallblocktest.dat  writefile  testsmallblock  shutdown  cleanupfile  setboolean  checkfile
__label__nflaky should  work  when  metrics  system  is  not  started  ms  test  register  dups  ts2  ts1  get  source  assert  not  null  assert  not  same  s1  shutdown  register  s2     should work when metrics system is not started  ms  testregisterdups  ts2  ts1  getsource  assertnotnull  assertnotsame  s1  shutdown  register  s2
__label__flaky running  ds  client  --shell_command  --container_memory  --num_containers  ls  run  dir  yarn  cluster  result  shell  assert  assert  true  512  client  info  init  test  ds  shell  log  --jar  appmaster_  jar  get  config  args  init  success  2  128  initializing  ds  client  client  run  completed.  result=  --master_memory  running ds client  --shell_command  --container_memory  --num_containers  ls  run  dir  yarncluster  result  shell  assert  asserttrue  512  client  info  init  testdsshell  log  --jar  appmaster_jar  getconfig  args  initsuccess  2  128  initializing ds client  client run completed. result=  --master_memory
__label__nflaky svc  entered  state  injected  rte  hm  log  health  monitor  test  callback  throws  rte  mocking  bad  health  check   waiting  for  unhealthy  wait  for  state  add  callback  info  svc  enteredstate  injected rte  hm  log  healthmonitor  testcallbackthrowsrte  mocking bad health check  waiting for unhealthy  waitforstate  addcallback  info
__label__flaky should  see  all  keys  in  all  group  two  rows  match  group  one  rows  test  value  two  bytes  families  expect  half  the  rows  values  match  all  values  using  regex  expected  keys  verify  scan  no  early  out  test  value  one  expect  all  rows  expected  rows  f  rows_  two  to  bytes  kvs  test  value((  one)|(  two))  expect  group  one  rows  test  value  filter  set  filter  qualifiers_  two  verify  scan  full  expect  half  rows  compare  op  test  row  two-3  match  group  two  rows  test  row  two-2   should see all keys in all group two rows   match group one rows  testvaluetwo  bytes  families   expect half the rows  values   match all values using regex  expectedkeys  verifyscannoearlyout  testvalueone   expect all rows  expectedrows  f  rows_two  tobytes  kvs  testvalue((one)|(two))   expect group one rows  testvaluefilter  setfilter  qualifiers_two  verifyscanfull   expect half rows  compareop   testrowtwo-3   match group two rows   testrowtwo-2
__label__nflaky http://  get  name  records  =  prefix  /list  paths  conf  /logs/a.log  stacks  url  http  server2  /data  log  url  info  all  url  log  fsck  url  /  verify  records  contains  /stream  file  stop  size  http  access  accesing  \""/\""  will  redirect  to  /index.html  start  a  http  server  with  counting  filter  /stacks  /a.jsp  remove  out  url  urls  get  host  port  string  get  connector  address  assert  true  /static/a.out  /*  stream  file  access  the  urls  data  url  /fsck  set  list  paths  url  test  servlet  filter  create  test  server  start  ajsp  url  root  url  records  net  utils  /index.html  http://  getname  records =   prefix  /listpaths  conf  /logs/a.log  stacksurl  httpserver2  /data  logurl  info  allurl  log  fsckurl  /   verify records  contains  /streamfile  stop  size  http  access   accesing \""/\"" will redirect to /index.html   start a http server with countingfilter  /stacks  /a.jsp  remove  outurl  urls  gethostportstring  getconnectoraddress  asserttrue  /static/a.out  /*  streamfile   access the urls  dataurl  /fsck  set  listpathsurl  testservletfilter  createtestserver  start  ajspurl  rooturl  records  netutils  /index.html
__label__flaky date  simple  map_  set  script  executor  session  given  update  simple  simplemap  eq  does  not  contain  entry  when  of  where  id  row  ten  table  execute  script  template  contains  entry  random  utils  manager  one  new_twenty  simple  map  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  get  map  has  size  should_dsl_update_map_set  then  long  build  date  key  from  base  table  dsl  select  simplemap  from  simple  where  id  =  thirty  date  simplemap_set  scriptexecutor  session   given  update  simple  simplemap  eq  doesnotcontainentry   when  of  where  id  row  ten  table  executescripttemplate  containsentry  randomutils  manager  one  new_twenty  simplemap  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  getmap  hassize  should_dsl_update_map_set   then  long  builddatekey  frombasetable  dsl  select simplemap from simple where id =   thirty
__label__nflaky sasl_  privacy_  props  conf  10.221.103.121  10.222.103.121  variablewhitelist.txt  remove  file  get  by  name  wqr  10.222.0.0/16  whitelist  based  resolver  10.119.103.112  set  10.119.103.113  10.113.221.222  10.113.221.221  10.221.102.0/23  get  server  properties  assert  equals  10.221.104.0  set  conf  fixed  ips  create  file  with  entries  set  long  test  fixed  and  local  white  list  test  file  based  ip  list  variable  ips  get  default  properties  inet  address  fixedwhitelist.txt  127.0.0.1  set  boolean  10.223.104.0  sasl_privacy_props  conf  10.221.103.121  10.222.103.121  variablewhitelist.txt  removefile  getbyname  wqr  10.222.0.0/16  whitelistbasedresolver  10.119.103.112  set  10.119.103.113  10.113.221.222  10.113.221.221  10.221.102.0/23  getserverproperties  assertequals  10.221.104.0  setconf  fixedips  createfilewithentries  setlong  testfixedandlocalwhitelist  testfilebasediplist  variableips  getdefaultproperties  inetaddress  fixedwhitelist.txt  127.0.0.1  setboolean  10.223.104.0
__label__flaky add  node  def  start  assert  equals  workflow  instance  get  status  wf  1  <worklfow-app/>  test  empty  workflow  end  job  evaluate  wait  for  addnode  def  start  assertequals  workflowinstance  getstatus  wf  1  <worklfow-app/>  testemptyworkflow  end  job  evaluate  waitfor
__label__nflaky j  test  mask6  test  mask  across  dimensions  j  testmask6  testmaskacrossdimensions
__label__flaky conn  set  request  method  is_  security_  enabled  put  test  start  testing  for  the  start  action  set  request  property  check  if  the  state  remains  uninitialized  /v1/job/*  content-type  run  test  mock  coordinator  engine  service  rest  constants  open  connection  http  servlet  response  assert  equals  params  url  put  call  get  response  code  check  if  the  response  is  400  reset  create  url  set  do  output  conn  setrequestmethod  is_security_enabled  put  teststart   testing for the start action  setrequestproperty   check if the state remains uninitialized  /v1/job/*  content-type  runtest  mockcoordinatorengineservice  restconstants  openconnection  httpservletresponse  assertequals  params  url  put  call  getresponsecode   check if the response is 400  reset  createurl  setdooutput
__label__nflaky files  option  does  not  match  file  name  get  current  user  -token  cache  file  get  credentials  conf  create  file  delete  creds  get  bytes  password  ugi  creds  mapreduce.job.credentials.binary  assert  true  number  of  tokens  assert  not  null  file  system  token-service  token-alias  get  files  is  null  user  group  information  token  cache  file  identifier  add  token  e  get  absolute  path  to  uri  ugi  token  assert  equals  write  token  storage  file  test  dir  tmp  file  file  not  found  exception  is  not  thrown  pass  a  files  option  token-kind  token  args  local  fs  th  get  local  make  qualified  get  token  exists  test  non  existing  file  to  string  test  token  cache  option  tmp  path  files option does not match  filename  getcurrentuser  -tokencachefile  getcredentials  conf   create file  delete  creds  getbytes  password  ugicreds  mapreduce.job.credentials.binary  asserttrue  numberoftokens  assertnotnull  filesystem  token-service  token-alias  get  files is null  usergroupinformation  tokencachefile  identifier  addtoken  e  getabsolutepath  touri  ugitoken  assertequals  writetokenstoragefile  testdir  tmpfile  filenotfoundexception is not thrown   pass a files option  token-kind  token  args  localfs  th  getlocal  makequalified  gettoken  exists   test non existing file  tostring  testtokencacheoption  tmppath
__label__flaky cluster  conf  create  file  simulated  storage  wait  active  lease  period  the  file  now  has  blocks.  locations  =  get  namenode  set  lease  period  test  file  creation  error2:  count  get  file  system  set  int  dfs  long  dfs_  heartbeat_  interval_  key  simulated  fs  dataset  verify  that  the  last  block  was  synchronized.  shutdown  /filestatus.dat  get  block  locations  the  file  has  create  cluster  test  file  creation  error2  start  added  block  system  sleep  test  file  creation  error2  successful  add  block  close  stream  client  dfs_  namenode_  heartbeat_  recheck_  interval_  key  get  block  wait  for  the  lease  to  expire  assert  equals  thread  io  utils  add  one  block  to  the  file  build  created  file  filestatus.dat  with  one  replicas.  to  string  locations  location  file1  namenode  triggers  lease  recovery  test  file  creation  error2  set  boolean  located  block  count  cluster  conf  createfile  simulatedstorage  waitactive  leaseperiod  the file now has    blocks.  locations =   getnamenode  setleaseperiod  testfilecreationerror2:      count  getfilesystem  setint  dfs  long  dfs_heartbeat_interval_key  simulatedfsdataset   verify that the last block was synchronized.  shutdown  /filestatus.dat  getblocklocations  the file has    create cluster  testfilecreationerror2 start  added block   system  sleep  testfilecreationerror2 successful  addblock  closestream  client  dfs_namenode_heartbeat_recheck_interval_key  getblock   wait for the lease to expire  assertequals  thread  ioutils   add one block to the file  build  created file filestatus.dat with one replicas.  tostring  locations  location  file1   namenode triggers lease recovery  testfilecreationerror2  setboolean  locatedblockcount
__label__nflaky generated  force  checks  -1  timeout  probes  intercept  test  intercept  await  lambda  diagnostics  await  generated   force checks -1 timeout probes  intercept  testinterceptawaitlambdadiagnostics  await
__label__flaky here  got  exception  :  \%s  conf  run  string  error  out  file  opener  done  hflush  string  utils  unable  to  close  file  get  interrupt  create  required  successful  opens  join  close  write  generate  sequential  bytes  init  file  system  dfs  test  util  current  thread  dfs  config  keys  set  /file1  e  log  error  message  format  start  stringify  exception  error  in  writer  write  size  test  immediate  read  of  new  file  block  size  thread  warn  fail  set  long  assert  null  opener  case  of  client  getting  a  dn  that  hasn\'t  yet  created  the  blocks  writer  open  here  got exception : \%s  conf  run  string  error  out  file  openerdone  hflush  stringutils  unable to close file  get  interrupt  create  requiredsuccessfulopens  join  close  write  generatesequentialbytes  init  filesystem  dfstestutil  currentthread  dfsconfigkeys  set  /file1  e  log  errormessage  format  start  stringifyexception  error in writer  writesize  testimmediatereadofnewfile  blocksize  thread  warn  fail  setlong  assertnull  opener   case of client getting a dn that hasn\'t yet created the blocks  writer  open
__label__nflaky \%(\%a\%(\%b))  add  witness  a  b  tl  test  nested  token  assert  equals  tokenize  \%(\%a\%(\%b))  add  witness  a  b  tl  testnested  token  assertequals  tokenize
__label__flaky conn  rest  constants  set  request  method  is_  security_  enabled  open  connection  mock  dag  engine  service  http  servlet  response  test  graph  assert  equals  params  put  url  call  /v0/job/*  get  header  field  get  get  response  code  name  reset  create  url  error  code  run  test  conn  restconstants  setrequestmethod  is_security_enabled  openconnection  mockdagengineservice  httpservletresponse  testgraph  assertequals  params  put  url  call  /v0/job/*  getheaderfield  get  getresponsecode  name  reset  createurl  errorcode  runtest
__label__nflaky /blah/my.id/myname  entry  set  build  route  assert  false  get  path  parameters  encoded  assert  equals  my.id  and  another  slightly  different  route  route  from  server  matches  route  size  assert  true  get  get  the  \"".\""  in  the  route  should  not  make  any  trouble:  route  builder  /blah/{id}/myname  id  /blah/my.id/myname/should_not_match  points  in  regex  dont  crash  regex  in  the  middle  of  the  route  /blah/my.id/myname  entryset  buildroute  assertfalse  getpathparametersencoded  assertequals  my.id   and another slightly different route  routefromserver  matches  route  size  asserttrue  get  get   the \"".\"" in the route should not make any trouble:  routebuilder  /blah/{id}/myname  id  /blah/my.id/myname/should_not_match  pointsinregexdontcrashregexinthemiddleoftheroute
__label__flaky get  location  test  simple  scanner  pb  set  batch  count  cell  set  delete  put  confirm  batch  size  conformance  table  new  scanner  bytes  /scanner  assert  not  null  get  client  model  get  code  add  column  scanner  uri  get  a  cell  set  get  body  cell  set  to  bytes  assert  equals  delete  the  scanner  get  object  from  message  /  mimetype_  protobuf  batch_  size  column_1  response  create  protobuf  output  getlocation  testsimplescannerpb  setbatch  countcellset  delete  put   confirm batch size conformance  table   new scanner  bytes  /scanner  assertnotnull  get  client  model  getcode  addcolumn  scanneruri   get a cell set  getbody  cellset  tobytes  assertequals   delete the scanner  getobjectfrommessage  /  mimetype_protobuf  batch_size  column_1  response  createprotobufoutput
__label__nflaky add  token  test  fs  with  child  tokens  one  exists  fs2  add  delegation  tokens  credentials  create  file  system  for  service  name  fs1  fs3  renewer  service2  service1  assert  equals  assert  same  token  single  token  fs1  multi  fs  number  of  tokens  assert  not  null  single  token  fs2  get  token  mock  we  had  added  its  token  to  credentials  verify  token  fetch  addtoken  testfswithchildtokensoneexists  fs2  adddelegationtokens  credentials  createfilesystemforservicename  fs1  fs3  renewer  service2  service1  assertequals  assertsame  token  singletokenfs1  multifs  numberoftokens  assertnotnull  singletokenfs2  gettoken  mock   we had added its token to credentials  verifytokenfetch
__label__flaky add  node  def  test  invalid  execution  path  one  start  assert  equals  workflow  instance  get  status  as  list  wf  1  <worklfow-app/>  end  arrays  job  /a/  signal    addnode  def  testinvalidexecutionpath  one  start  assertequals  workflowinstance  getstatus  aslist  wf  1  <worklfow-app/>  end  arrays  job  /a/  signal
__label__nflaky long  param  assert  false  context  create  verify  has  violations  invoke  mock  controller  validation  long  param  should  handle  null  longparam  assertfalse  context  create  verify  hasviolations  invoke  mockcontroller  validation  longparamshouldhandlenull
__label__flaky 22  cluster  23  my  file  get  localized  message  conf  run  fs  system  set  out  out  ps  out  exception  raised  from  dfs  shell.run  assert  true  /test/dir  close  write  file  val  /test/dir/file2  e  my  file2  get  file  system  set  conf  not  a  hdfs:  dfs  ps  backup  args  return  string  check  if  size  matchs  as  expected  contains  test  du  build  shell  num  data  nodes  mkdirs  exists  reset  to  string  get  uri  shutdown  my  path  -du  /test/dir/file  22  cluster  23  myfile  getlocalizedmessage  conf  run  fs  system  setout  out  psout  exception raised from dfsshell.run   asserttrue  /test/dir  close  writefile  val  /test/dir/file2  e  myfile2  getfilesystem  setconf  not a hdfs:   dfs  psbackup  args  returnstring   check if size matchs as expected  contains  testdu  build  shell  numdatanodes  mkdirs  exists  reset  tostring  geturi  shutdown  mypath  -du  /test/dir/file
__label__nflaky object  under  test  conf  allowed  methods  do  not  match  destroy  filter  values  compare  to  put  filter  config  assert  assert  true  initialize  filter  allowed  headers  do  not  match  get  allowed  methods  header  example.com  init  destroy  filter  values  and  clear  conf  content-  type   origin  verify  filter  values  x-  requested-  with   accept  get  allowed  headers  header  clear  destroy  setup  the  configuration  settings  of  the  server  cross  origin  filter  are  origins  allowed  newexample.com  filter  get   head  test  cross  origin  filter  after  restart  get   post   object under test  conf  allowed methods do not match   destroy filter values  compareto  put  filterconfig  assert  asserttrue   initialize filter  allowed headers do not match  getallowedmethodsheader  example.com  init   destroy filter values and clear conf  content-type origin   verify filter values  x-requested-with accept  getallowedheadersheader  clear  destroy   setup the configuration settings of the server  crossoriginfilter  areoriginsallowed  newexample.com  filter  get head  testcrossoriginfilterafterrestart  get post
__label__flaky prepare  script  executor  should_perform_bound_statement_typed_query  session  given  simple  0  am  bind  bound  statement  when  of  id  table  execute  script  template  is  not  null  actual  random  utils  manager  query  next  long  assert  that  simple  entity/insert_single_row.cql  immutable  map  get  value  contains  typed  query  for  select  then  long  get  one  select  *  from  simple  where  id  =  :id  prepare  scriptexecutor  should_perform_bound_statement_typed_query  session   given  simple  0 am  bind  boundstatement   when  of  id  table  executescripttemplate  isnotnull  actual  randomutils  manager  query  nextlong  assertthat  simpleentity/insert_single_row.cql  immutablemap  getvalue  contains  typedqueryforselect   then  long  getone  select * from simple where id = :id
__label__nflaky ./tmp/test-config2.xml  get  name  conf  rel  config2  cleanup  delete  append  property  out  end  include  add  resource  get  test  relative  includes  a  get  parent  b  start  include  add  the  relative  path  instead  of  the  absolute  one.  c  d  get  absolute  path  verify  that  the  includes  file  contains  all  properties  end  config  start  config  assert  equals  tear  down  rel  config  mkdirs  ./tmp/test-config.xml  file  resource  ./tmp/test-config2.xml  getname  conf  relconfig2   cleanup  delete  appendproperty  out  endinclude  addresource  get  testrelativeincludes  a  getparent  b  startinclude   add the relative path instead of the absolute one.  c  d  getabsolutepath   verify that the includes file contains all properties  endconfig  startconfig  assertequals  teardown  relconfig  mkdirs  ./tmp/test-config.xml  fileresource
__label__flaky prepare  script  executor  session  prepared  statement  given  simple  0  am  should_perform_prepared_typed_query  when  of  id  table  execute  script  template  is  not  null  actual  random  utils  manager  query  next  long  assert  that  simple  entity/insert_single_row.cql  immutable  map  get  value  contains  typed  query  for  select  then  long  get  one  select  *  from  simple  where  id  =  :id  prepare  scriptexecutor  session  preparedstatement   given  simple  0 am  should_perform_prepared_typed_query   when  of  id  table  executescripttemplate  isnotnull  actual  randomutils  manager  query  nextlong  assertthat  simpleentity/insert_single_row.cql  immutablemap  getvalue  contains  typedqueryforselect   then  long  getone  select * from simple where id = :id
__label__nflaky integer  set  array  get  bit  array  ints  assert  equals  test  get  array  integer  set  array  getbitarray  ints  assertequals  testgetarray
__label__flaky ensure  time  to  poll  test  watch  for  multiple  event  types  resolve  immutable  list  foo  entry_  create  fs  delete  create  file  path  bar  foo/bar  of  get  path  create  directory  baz  files  create  directories  watcher  entry_  modify  watcher  polls   seeing  modification   then  polls  again   seeing  delete  this  could  be  __label__flaky;  may  need  to  increase  time  between  polling  if  so  (or  just  not  test  it)  entry_  delete  register  assert  watcher  has  events  ensuretimetopoll  testwatchformultipleeventtypes  resolve  immutablelist  foo  entry_create  fs  delete  createfile  path  bar  foo/bar  of  getpath  createdirectory  baz  files  createdirectories  watcher  entry_modify   watcher polls  seeing modification  then polls again  seeing delete   this could be __label__flaky; may need to increase time between polling if so (or just not test it)  entry_delete  register  assertwatcherhasevents
__label__nflaky request  conn  get  endpoint  details  user-  agent  out  stream  when  bind  assert  flush  test  write  request  head  get  /stuff  http/1.1  user-  agent:  test  /stuff  get  request  count  add  header  test  then  return  standard  charsets  assert  equals  method  mockito  to  byte  array  get  output  stream  socket  send  request  header  request  conn  getendpointdetails  user-agent  outstream  when  bind  assert  flush  testwriterequesthead  get /stuff http/1.1  user-agent: test      /stuff  getrequestcount  addheader  test  thenreturn  standardcharsets  assertequals  method  mockito  tobytearray  getoutputstream  socket  sendrequestheader
__label__flaky call  fail  add  record  to  bundle  job  table  bundle-id  test  bundle  suspend  failed  job  job  doesn\'t  exist.  should  fail.  call  fail  addrecordtobundlejobtable  bundle-id  testbundlesuspendfailed  job  job doesn\'t exist. should fail.
__label__nflaky parse  exception  should  have  been  thrown  :  blah  clear  header  :  blah  fail  buf  assert  test  invalid  header  parsing  :  :  :  blah  append  blah    parseexception should have been thrown   : blah  clear  header : blah  fail  buf  assert  testinvalidheaderparsing     :  :  : blah  append  blah
__label__flaky a  a  set  xml  utils  conf  cannot  be  null  parse  xml  get  message  assert  equals  conf  <root  xmlns=\""uri:oozie:workflow:0.4\""></root>  test  verify  parameters  null  fail  ex  size  get  parameter  verifier  verify  parameters  a  a  set  xmlutils  conf cannot be null  parsexml  getmessage  assertequals  conf  <root xmlns=\""uri:oozie:workflow:0.4\""></root>  testverifyparametersnull  fail  ex  size  get  parameterverifier  verifyparameters
__label__nflaky shutdown  timeout  millis  get  current  user  submit  foo  test  stop  threads  conf  sleep  assert  update  interval  seconds  assert  not  null  tm1  get  delegation  token  secret  manager  sm  get  secret  conf  user  group  information  get  listener  thread  pool  init  get  connect  string  zk  delegation  token  secret  manager  zk  server  unchecked  destroy  create  token  es  token  thread  call  set  long  zksm  force  this  to  be  shutdown  now  connect  string  it  will  cause  an  error.  delegation  token  manager  rawtypes  shutdowntimeoutmillis  getcurrentuser  submit  foo  teststopthreads  conf  sleep  assert  updateintervalseconds  assertnotnull  tm1  getdelegationtokensecretmanager  sm  getsecretconf  usergroupinformation  getlistenerthreadpool  init  getconnectstring  zkdelegationtokensecretmanager  zkserver  unchecked  destroy  createtoken  es  token  thread  call  setlong  zksm   force this to be shutdownnow  connectstring   it will cause an error.  delegationtokenmanager  rawtypes
__label__flaky test  decision  add  node  def  enters  dec  trans  workflow  instance  get  status  two  three  as  list  exits  assert  true  bla  end  signal  add  d  contains  key  one  abcde  start  clear  assert  equals  /  fail  size  test  wf  <worklfow-app/>  arrays  job    testdecision  addnode  def  enters  dectrans  workflowinstance  getstatus  two  three  aslist  exits  asserttrue  bla  end  signal  add  d  containskey  one  abcde  start  clear  assertequals  /  fail  size  testwf  <worklfow-app/>  arrays  job
__label__nflaky test  set  closed  is  open  assert  true  reference  count  should  be  open  assert  false  clr  set  closed  reference  count  should  be  closed  testsetclosed  isopen  asserttrue  reference count should be open  assertfalse  clr  setclosed  reference count should be closed
__label__flaky add  org.springframework.boot  grab  annotations  basic  add  1.2.3  assert  grab  annotation  size  get  assert  equals  annotation  node  get  annotations  spring-boot-starter-logging  add  org.springframework.boot  grabannotations  basicadd  1.2.3  assertgrabannotation  size  get  assertequals  annotationnode  getannotations  spring-boot-starter-logging
__label__nflaky p1  p2  test  get  kms  url  kp  any  string  then  return  key  name  create  key  conf  eq  any  when  test  client  retries  with  ssl  handshake  exception  succeeds  second  time  set  int  common  configuration  keys  public  times  mockito  mock  verify  v1  then  throw  p1  p2  test  getkmsurl  kp  anystring  thenreturn  keyname  createkey  conf  eq  any  when  testclientretrieswithsslhandshakeexceptionsucceedssecondtime  setint  commonconfigurationkeyspublic  times  mockito  mock  verify  v1  thenthrow
__label__flaky xml  utils  <bundle-app  name=\'  name\'  xmlns:xsi=\'http://www.w3.org/2001/  xml  schema-instance\'  xmlns=\'uri:oozie:bundle:0.1\'>  <coordinator  name=\'c12\'>  e  <configuration>  validator  <property>  <name>  start_  time</name>  <value>2009-02-01  t00:00  z</value>  </property>  </configuration>  parse  xml  new  validator  <controls>  <kick-off-time>2009-02-02  t00:00  z</kick-off-time>  </controls>  get  schema  bundle_  app  services  <app-path>hdfs://localhost:9001/tmp/bundle-apps/coordinator1.xml</app-path>  </coordinator></bundle-app>  test  bundle  schema  wss  get  schema  name  validate  system.out.println(\""  xml  :\""+  xml  utils.pretty  print(e));  xmlutils  <bundle-app name=\'name\' xmlns:xsi=\'http://www.w3.org/2001/xmlschema-instance\' xmlns=\'uri:oozie:bundle:0.1\'>   <coordinator name=\'c12\'>   e  <configuration>   validator  <property> <name>start_time</name> <value>2009-02-01t00:00z</value> </property> </configuration>   parsexml  newvalidator  <controls> <kick-off-time>2009-02-02t00:00z</kick-off-time> </controls>   getschema  bundle_app  services  <app-path>hdfs://localhost:9001/tmp/bundle-apps/coordinator1.xml</app-path>  </coordinator></bundle-app>  testbundleschema  wss  get  schemaname  validate   system.out.println(\""xml :\""+ xmlutils.prettyprint(e));
__label__nflaky test  ioe  on  client  write  param  do  error  test  testioeonclientwriteparam  doerrortest
__label__flaky user11  create  resource  conf  is  continuous  scheduling  enabled  node  event1  check  consumption  assert  get  continuous  scheduling  sleep  ms  resource  manager  add  send  application  request  handle  test  continuous  scheduling  available  resource  node1  get  memory  add  one  node  allocate  create  configuration  resources  resource  request  127.0.0.1  get  cluster  capacity  request  reinitialize  new  node  info  add  application  continuous  scheduling  should  be  enabled.  create  app  attempt  id  fs  get  rm  context  sleep  assert  true  get  fair  scheduler  configuration  get  current  consumption  get  conf  assert  equals  consumption  at  least  one  pass  app  attempt  id  thread  set  continuous  scheduling  enabled  mock  nodes  get  virtual  cores  create  resource  request  ask  queue11  set  boolean  user11  createresource  conf  iscontinuousschedulingenabled  nodeevent1   check consumption  assert  getcontinuousschedulingsleepms  resourcemanager  add   send application request  handle  testcontinuousscheduling   available resource  node1  getmemory   add one node  allocate  createconfiguration  resources  resourcerequest  127.0.0.1  getclustercapacity  request  reinitialize  newnodeinfo  addapplication  continuous scheduling should be enabled.  createappattemptid  fs  getrmcontext  sleep  asserttrue  get  fairschedulerconfiguration  getcurrentconsumption  getconf  assertequals  consumption   at least one pass  appattemptid  thread   set continuous scheduling enabled  mocknodes  getvirtualcores  createresourcerequest  ask  queue11  setboolean
__label__nflaky yyyy.  mmm.dd  do  test  dot  cal_2009_08_3_  night  yyyy.mmm.dd  dotest  dot  cal_2009_08_3_night
__label__flaky 2009-05-31  t00:00  z  coord  el  functions  2009-09-10  t23:59  z  2009-05-30  t00:00  z  2009-10-30  t08:00  z  2009-03-06  t10:00  z  2009-01-01  t08:01  z  2009-01-01  t7:00  z  2009-04-01  t07:00  z  2009-03-07  t09:00  z  time  unit  set  end  of  duration  changed  case  8  init  test  with  eom  2009-03-08  t07:00  z  set  init  instance  ${coord:current(1)}  case  1  case  2  case  3  case  4  endof  day  testing  case  5  case  6  case  7  2009-01-01  t08:00  z  2009-03-11  t07:00  z  ${coord:current(-3)}  evaluate  2009-10-30  t08:00  z  2009-10-31  t08:00  z  2009-11-01  t08:00  z  2009-11-02  t09:00  z  2009-11-03  t09:00  z  set  name  test  current  coord-action-create  test1  eval  and  wrap  winter  dst  transition  2009-02-01  t00:00  z  set  time  zone  2009-05-27  t00:00  z  2009-09-08  t23:59  z  2009-02-02  t08:00  z  2009-01-02  t09:00  z  set  nominal  time  2009-03-06  t10:00  z  2009-03-07  t10:00  z  2009-03-08  t09:00  z  2009-03-09  t09:00  z  2009-03-10  t09:00  z  assert  equals  ${coord:current(0)}  2009-01-01  t18:00  z  ${coord:current(-2)}  ${coord:current(-1)}  ${coord:current(0)}  ${coord:current(1)}  ${coord:current(2)}  2009-03-07  t07:00  z  2009-03-01  t08:00  z  2009-01-02  t00:00  z  2009-03-10  t07:00  z  2009-05-29  t23:00  z  2009-05-30  t23:00  z  2009-05-28  t23:00  z  2009-05-26  t23:00  z  get  time  zone  utc  2009-03-10  t08:01  z  date  utils  parse  date  oozie  tz  set  frequency  spring  dst  transition  ds  ${coord:current(0)}  ${coord:current(1)}  ${coord:current(-1)}  ${coord:current(-3)}  2009-05-30  t12:00  z  2009-11-01  t08:00  z  2009-01-01  t07:01  z  2009-03-02  t08:00  z  2009-03-08  t08:00  z  app  inst  set  time  unit  eval  2009-01-01  t00:00  z  sync  2009-05-30  t00:30  z  2009-05-30  t01:00  z  2009-05-30  t00:00  z  2009-05-29  t23:00  z  2009-03-08  t10:45  z  ${coord:current(-1)}  2009-06-04  t00:00  z  2009-05-30  t00:00  z  2009-05-21  t00:00  z  2009-05-07  t00:00  z  2009-05-29  t00:00  z  2009-05-28  t00:00  z  configure  evaluator  2009-06-01  t07:00  z  expr  2009-02-01  t08:00  z  2009-03-09  t07:00  z  2009-05-30  t00:45  z  2009-03-07  t08:00  z  2009-01-31  t08:00  z  set  type  set  actual  time  america/  los_  angeles  2009-03-12  t07:00  z  2009-03-01  t00:00  z  2009-01-02  t08:00  z  expr));  2009-01-08  t00:00  z    2009-05-31t00:00z  coordelfunctions  2009-09-10t23:59z  2009-05-30t00:00z  2009-10-30t08:00z  2009-03-06t10:00z  2009-01-01t08:01z  2009-01-01t7:00z  2009-04-01t07:00z  2009-03-07t09:00z  timeunit  setendofduration   changed   case 8  init   test with eom  2009-03-08t07:00z  setinitinstance  ${coord:current(1)}   case 1   case 2   case 3   case 4   endofday testing   case 5   case 6   case 7  2009-01-01t08:00z  2009-03-11t07:00z  ${coord:current(-3)}  evaluate  2009-10-30t08:00z 2009-10-31t08:00z 2009-11-01t08:00z 2009-11-02t09:00z 2009-11-03t09:00z  setname  testcurrent  coord-action-create  test1  evalandwrap   winter dst transition  2009-02-01t00:00z  settimezone  2009-05-27t00:00z  2009-09-08t23:59z  2009-02-02t08:00z  2009-01-02t09:00z  setnominaltime  2009-03-06t10:00z 2009-03-07t10:00z 2009-03-08t09:00z 2009-03-09t09:00z 2009-03-10t09:00z  assertequals  ${coord:current(0)}  2009-01-01t18:00z  ${coord:current(-2)} ${coord:current(-1)} ${coord:current(0)} ${coord:current(1)} ${coord:current(2)}  2009-03-07t07:00z  2009-03-01t08:00z  2009-01-02t00:00z  2009-03-10t07:00z  2009-05-29t23:00z 2009-05-30t23:00z 2009-05-28t23:00z 2009-05-26t23:00z  gettimezone  utc  2009-03-10t08:01z  dateutils  parsedateoozietz  setfrequency   spring dst transition  ds  ${coord:current(0)} ${coord:current(1)} ${coord:current(-1)} ${coord:current(-3)}  2009-05-30t12:00z   2009-11-01t08:00z  2009-01-01t07:01z  2009-03-02t08:00z  2009-03-08t08:00z  appinst  settimeunit  eval  2009-01-01t00:00z  sync  2009-05-30t00:30z 2009-05-30t01:00z 2009-05-30t00:00z 2009-05-29t23:00z  2009-03-08t10:45z  ${coord:current(-1)}  2009-06-04t00:00z  2009-05-30t00:00z   2009-05-21t00:00z  2009-05-07t00:00z  2009-05-29t00:00z  2009-05-28t00:00z  configureevaluator  2009-06-01t07:00z  expr  2009-02-01t08:00z  2009-03-09t07:00z  2009-05-30t00:45z  2009-03-07t08:00z  2009-01-31t08:00z  settype  setactualtime  america/los_angeles  2009-03-12t07:00z  2009-03-01t00:00z  2009-01-02t08:00z   expr));  2009-01-08t00:00z
__label__nflaky create  multi  part  email  with  content  get  subject  reply  to2@domain  mail  subject  mail  impl  test  helper  get  reply  to  addresses  reply  to1@domain  get  to  addresses  assert  true  commonsmail  helper  get  mail  impl  with  demo  content  multi  part  email  to1@domain  get  bcc  addresses  assert  equals  from1@domain  cc1@domain  get  cc  addresses  test  do  populate  multipart  mail  with  content  contains  get  from  address  bcc1@domain  bcc2@domain  do  convert  adresses  to  internet  address  list  to2@domain  do  populate  multipart  mail  with  content  createmultipartemailwithcontent  getsubject  replyto2@domain  mail  subject  mailimpltesthelper  getreplytoaddresses  replyto1@domain  gettoaddresses  asserttrue  commonsmailhelper  getmailimplwithdemocontent  multipartemail  to1@domain  getbccaddresses  assertequals  from1@domain  cc1@domain  getccaddresses  testdopopulatemultipartmailwithcontent  contains  getfromaddress  bcc1@domain  bcc2@domain  doconvertadressestointernetaddresslist  to2@domain  dopopulatemultipartmailwithcontent
__label__flaky set  classes  to  be  excluded  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  sleep  assert  not  null  get  coordinator  action  end  current  date  plus  month  init  get  conf  test  coord  status  transit  service  no  done  with  error  for  backward  support  start  destroy  assert  equals  services  x  data  test  case  set  app  namespace  execute  add  record  to  coord  job  table  services  coordinator  job  runnable  coord-action-get.xml  excluded  services  schema  service  set  system  property  true  status  transit  service  jpa  service  setclassestobeexcluded  getcurrentdateafterincrementinginmonths  getid  run  dateutils  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  sleep  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  init  getconf  testcoordstatustransitservicenodonewitherrorforbackwardsupport  start  destroy  assertequals  services  xdatatestcase  setappnamespace  execute  addrecordtocoordjobtable  services  coordinatorjob  runnable  coord-action-get.xml  excludedservices  schemaservice  setsystemproperty  true  statustransitservice  jpaservice
__label__nflaky request  increment  and  get  data  channel  increment  update  capacity  channel#update  should  not  have  been  invoked  yet  consume  last  increment  subscription  assert  get  consumer  test  capacity  increments  set  on  error  subscribe  on  complete  assert  equals  received  duplicate  byte  buffer  on  next  update  capacity  on  subscribe  wrap  request  incrementandget  data  channel  increment  update  capacitychannel#update should not have been invoked yet  consume  lastincrement  subscription  assert  get  consumer  testcapacityincrements  set  onerror  subscribe  oncomplete  assertequals  received  duplicate  bytebuffer  onnext  updatecapacity  onsubscribe  wrap
__label__flaky -version  end_  points  is_  security_  enabled  get  context  url  oozie  url  header  testing  version  servlet  clear  admin  run  assert  equals  args  call  test  server  build  version  -oozie  servlet_  classes  run  test  -version  end_points  is_security_enabled  getcontexturl  oozieurl  headertestingversionservlet  clear  admin  run  assertequals  args  call  testserverbuildversion  -oozie  servlet_classes  runtest
__label__nflaky set  expected  exception:  log  test  default  uri  without  scheme  get  file  context  conf  /  fail  not  thrown!  ufse  file  system  file  context  info  set  expected exception:   log  testdefaulturiwithoutscheme  getfilecontext  conf  /  fail   not thrown!  ufse  filesystem  filecontext  info
__label__flaky bundle  job  get  executor  add  record  to  bundle  action  table  get  id  get  status  assert  not  null  get  2009-02-01  t00:00  z  job  init  test  bundle  rerun  with  error  false  add  record  to  bundle  job  table  destroy  assert  equals  services  execute  add  record  to  coord  job  table  call  services  coordinator  job  set  system  property  status  transit  service  action1  job  action2  jpa  service  bundlejobgetexecutor  addrecordtobundleactiontable  getid  getstatus  assertnotnull  get  2009-02-01t00:00z  job  init  testbundlererunwitherror  false  addrecordtobundlejobtable  destroy  assertequals  services  execute  addrecordtocoordjobtable  call  services  coordinatorjob  setsystemproperty  statustransitservice  action1  job  action2  jpaservice
__label__nflaky get  boolean  with  default  then  return  ninja  constant  invoke  when  param1  integer  param  strict  mode  works  context  create  integer  param  ninja  properties  mock  controller  get  parameter  getbooleanwithdefault  thenreturn  ninjaconstant  invoke  when  param1  integerparamstrictmodeworks  context  create  integerparam  ninjaproperties  mockcontroller  getparameter
__label__flaky check  subworkflow  lib  helper  child  libs1  expected  libs1  expected  libs2  test  create  proto  conf  with  sub  workflow  lib1  expected  libs3  expected  libs4  expected  libs5  same.jar  child  libs3  parent2.jar  child  libs2  child  libs5  child1.jar  child  libs4  inherit  wf  parent  libs2  parent  libs3  parent  libs1  parent1.jar  parent  libs4  parent  libs5  inherit  child2.so  true  checksubworkflowlibhelper  childlibs1  expectedlibs1  expectedlibs2  testcreateprotoconfwithsubworkflowlib1  expectedlibs3  expectedlibs4  expectedlibs5  same.jar  childlibs3  parent2.jar  childlibs2  childlibs5  child1.jar  childlibs4  inheritwf  parentlibs2  parentlibs3  parentlibs1  parent1.jar  parentlibs4  parentlibs5  inherit  child2.so  true
__label__nflaky long  param  assert  false  context  create  verify  has  violations  invoke  mock  controller  validation  long  param  should  handle  null  longparam  assertfalse  context  create  verify  hasviolations  invoke  mockcontroller  validation  longparamshouldhandlenull
__label__flaky conn  set  request  method  is_  security_  enabled  assert  true  get  test  status  json  content-type  /v1/admin/*  collections  run  test  system_  mode  json  tags  rest  constants  open  connection  http  servlet  response  assert  equals  parse  get  input  stream  url  json  value  call  get  header  field  get  get  response  code  create  url  to  string  starts  with  conn  setrequestmethod  is_security_enabled  asserttrue  get  teststatus  json  content-type  /v1/admin/*  collections  runtest  system_mode  jsontags  restconstants  openconnection  httpservletresponse  assertequals  parse  getinputstream  url  jsonvalue  call  getheaderfield  get  getresponsecode  createurl  tostring  startswith
__label__nflaky find  class  org.apache.hadoop.util.  test  find  class$  private  class  run  test  create  fails  private  class  findclass  org.apache.hadoop.util.testfindclass$privateclass  run  testcreatefailsprivateclass
__label__flaky mapred.child.java.opts  conf  get  launcher  main  setup  action  conf  as  list  a1  a2  proto  conf  action.bar  get  main  arguments  context  get  path  action  java  action  executor  <job-tracker>  f.jar  aa  action  conf  ae  lib/a.so.1#a.so.1  get  file  system  java-launcher.jar  check  for  disallowed  props  app  so  path  <name-node>  set  lib  files  archives  aq  fail  contains  main-  class  get  type  lib/a.so  ends  with  <property><name>a</name><value>  aa</value></property>  arrays  java-  opts  mapred.job.classpath.files  bb  action.foo  get  classes  for  launcher  c  d  e  f  write  xml  user.name  get  actions  app  path  create  base  hadoop  conf  oozie.action.sharelib.for.java  assert  true  launcher  mapper  get  job.xml  close  a  mapred.job.tracker  b  set  c  xml  utils  d  e  to  uri  mapred.cache.archives  assert  equals  get  launcher  jar  name  <property><name>mapred.job.queue.name</name><value>  aq</value></property>  services  get  test  user  assert  null  action.barbar  add  all  la  exists  to  string  get  oozie  launcher  jar  get  job  tracker  uri  lq  mapred.job.queue.name  </configuration>  prepare  action  dir  <property><name>oozie.launcher.mapred.job.queue.name</name><value>  lq</value></property>  create  base  workflow  app  so1  path  <arg>  a2</arg>  create  job2.xml  test  setup  methods  lib/a.so.1  add  mapred.cache.files  parse  xml  </job-tracker>  create  launcher  conf  </name-node>  setup  launcher  conf  add  to  cache  <file>f.jar</file>  fs.default.name  app  jar  path  action.foofoo  <property><name>oozie.action.sharelib.for.java</name><value>sharelib-java</value></property>  <java-opts>  java-  opts</java-opts>  </name-node>  <configuration>  <java>  classes  expected  so1  path  assert  false  oozie.launcher.f  archive  path  wf  action  xml  oozie.launcher.a  oozie.launcher.d  <job-xml>job.xml</job-xml>  set  strings  <job-xml>job2.xml</job-xml>  clean  up  action  dir  <archive>a.tar</archive>  <property><name>oozie.launcher.a</name><value>  la</value></property>  get  name  node  uri  </java>  os  workflow  app  service  file  path  get  launcher  classes  <property><name>b</name><value>  bb</value></property>  <main-class>  main-  class</main-class>  <configuration>  set  type  <arg>  a1</arg>  a.tar  lib/a.jar  get  fs  test  case  dir  get  action  dir  starts  with  sharelib-java  mapred.child.java.opts  conf  getlaunchermain  setupactionconf  aslist  a1  a2  protoconf  action.bar  getmainarguments  context  getpath  action  javaactionexecutor  <job-tracker>  f.jar  aa  actionconf  ae  lib/a.so.1#a.so.1  getfilesystem  java-launcher.jar  checkfordisallowedprops  appsopath  <name-node>  setlibfilesarchives  aq  fail  contains  main-class  gettype  lib/a.so  endswith  <property><name>a</name><value>aa</value></property>  arrays  java-opts  mapred.job.classpath.files  bb  action.foo  getclassesforlauncher  c  d  e  f  writexml  user.name  getactions  apppath  createbasehadoopconf  oozie.action.sharelib.for.java  asserttrue  launchermapper  get  job.xml  close  a  mapred.job.tracker  b  set  c  xmlutils  d  e  touri  mapred.cache.archives  assertequals  getlauncherjarname  <property><name>mapred.job.queue.name</name><value>aq</value></property>  services  gettestuser  assertnull  action.barbar  addall  la  exists  tostring  getoozielauncherjar  getjobtrackeruri  lq  mapred.job.queue.name  </configuration>  prepareactiondir  <property><name>oozie.launcher.mapred.job.queue.name</name><value>lq</value></property>  createbaseworkflow  appso1path  <arg>a2</arg>  create  job2.xml  testsetupmethods  lib/a.so.1  add  mapred.cache.files  parsexml  </job-tracker>  createlauncherconf  </name-node>  setuplauncherconf  addtocache  <file>f.jar</file>  fs.default.name  appjarpath  action.foofoo  <property><name>oozie.action.sharelib.for.java</name><value>sharelib-java</value></property>  <java-opts>java-opts</java-opts>  </name-node> <configuration>  <java>  classes  expectedso1path  assertfalse  oozie.launcher.f  archivepath  wf  actionxml  oozie.launcher.a  oozie.launcher.d  <job-xml>job.xml</job-xml>  setstrings  <job-xml>job2.xml</job-xml>  cleanupactiondir  <archive>a.tar</archive>  <property><name>oozie.launcher.a</name><value>la</value></property>  getnamenodeuri  </java>  os  workflowappservice  filepath  getlauncherclasses  <property><name>b</name><value>bb</value></property>  <main-class>main-class</main-class>  <configuration>  settype  <arg>a1</arg>  a.tar  lib/a.jar  getfstestcasedir  getactiondir  startswith  sharelib-java
__label__nflaky mid  key  write  a  mapfile  of  simple  data:  keys  are  reader  conf  assert  equals  deprecation  fs  test  mid  key  empty.mapfile  get  local  file  system  make  qualified  qualified  dir  name  test  mid  key  empty  to  string  writer  close  test_  dir  now  do  get  closest  on  created  mapfile.  dir  name  midkey   write a mapfile of simple data: keys are  reader  conf  assertequals  deprecation  fs  testmidkeyempty.mapfile  getlocal  filesystem  makequalified  qualifieddirname  testmidkeyempty  tostring  writer  close  test_dir   now do getclosest on created mapfile.  dirname
__label__flaky check  bundles  get  the  first  3  test  bundle  jobs  get  for  purge  jpa  executor  too  many  job2  job1  job4  2011-01-01  t01:00  z  job3  add  record  to  bundle  job  table  job5  assert  equals  get  id  date  utils  list  execute  parse  date  oozie  tz  services  size  add  all  assert  not  null  get  get  the  next  3  (though  there\'s  only  2  more)  job  jpa  service  checkbundles   get the first 3  testbundlejobsgetforpurgejpaexecutortoomany  job2  job1  job4  2011-01-01t01:00z  job3  addrecordtobundlejobtable  job5  assertequals  getid  dateutils  list  execute  parsedateoozietz  services  size  addall  assertnotnull  get   get the next 3 (though there\'s only 2 more)  job  jpaservice
__label__nflaky worker  should  stop  even  if  interrupt  exception  consumed  within  subappender  add  appender  stop  assert  true  do  append  start  verify  delaying  list  appender  interrupted  async  appender  base  thread  workershouldstopevenifinterruptexceptionconsumedwithinsubappender  addappender  stop  asserttrue  doappend  start  verify  delayinglistappender  interrupted  asyncappenderbase  thread
__label__flaky a  evaluated  bad  expression  ${a:a()}  assert  false  parsed  bad  expression  assert  true  a a  check  for  existence  el  evaluator  ${a:a()   a:a()}  evaluator  a  !  ${a:d(\'foo\'   \'bar\')}  ${a:a()} ${a:a()}  add  function  d  ${a:a()}${a:a()}!  test  check  for  existence  set  variable  assert  equals     fail  function  d  assert  null  function  a  get  current  support  evaluate  a  evaluated bad expression  ${a:a()}  assertfalse  parsed bad expression  asserttrue  a a  checkforexistence  elevaluator  ${a:a()  a:a()}  evaluator  a  !  ${a:d(\'foo\'  \'bar\')}  ${a:a()} ${a:a()}  addfunction  d  ${a:a()}${a:a()}!  testcheckforexistence  setvariable  assertequals     fail  functiond  assertnull  functiona  getcurrent  support  evaluate
__label__nflaky x  .  x  x  x  .  .  x  .  x  .  x  .  .  .  x  .  x  .  x  x  x  .  .  .  x  x  x  .  .  x  x  .  .  x  x  .  x  .  x  .  .  .  .  x  .  x  .  .  x  .  .  x  .  x  x  .  .  x  x  .  .  .  .  .  x  x  .  .  .  x  x  .  .  .  x  .  x  .  .  x  x  x  .  x  .  x  .  .  .  x  .  x  .  .  .  .  x  x  .  x  .  .  x  x  .  .  .  .  .  .  .  x  .  x  x  x  .  .  .  .  x  x  x  x  .  .  x  x  x  x  .  .  .  .  x  .  .  .  .  .  .  .  x  .  x  .  .  .  .  .  .  .  x  x  x  x  .  .  .  x  x  x  bit  matrix  matrix  decode  x  x  x  .  .  x  x  x  x  x  .  .  .  .  .  x  x  .  .  .  x  .  x  .  x  .  x  x  .  .  x  x  x  .  x  x  x  x  x  x  x  x  x  x  x  x  x  .  .  .  x  .  x  x  x  .  x  .  x  .  .  x  .  x  x  x  x  x  x  x  x  .  x  x  x  x  .  .  x  x  .  x  x  .  x  .  .  .  x  x  .  .  .  x  .  .  x  x  x  .  x  .  x  x  x  x  x  .  .  .  x  .  .  x  .  x  .  .  .  x  .  x  x  .  x  x  .  x  .  .  .  x  .  x  .  x  x  .  .  .  .  .  .  .  .  x  .  .  .  x  .  x  x  x  .  x  .  .  x  .  .  .  x  .  x  x  .  .  x  x  .  .  .  .  .  x  .  .  .  .  .  .  x  x  .  x  x  x  .  test  decode  too  many  errors  .  .  .  x  .  x  .  x  .  .  .  .  .  x  x  x  x  x  x  .  .  .  .  .  .  x  x  x  x  .  .  x  .  .  x  .  x  x  x  x  x  x  x  x  x  x  x  x  x  .  .  x  .  x  no_  points  .  .  .  .  x  x  .  .  .  x  .  .  .  .  .  .  .  x  x  .  .  .  x  x  .  x  .  x  .  .  .  .  x  .  x  .  x  .  x  .  .  .  x  .  x  .  x  x  .  x  x  .  x  x  x  .  .  .  x  .  x  x  x  x  x  x  .  .  x  x  x  .  x  .  x  x  x  x  x  x  .  .  .  .  x  x  x  .  .  x  x  .  x  x  x  x  x  .  x  .  .  x  .  .  .  .  .  .  x  .  .  .  x  x  .  .  x  x  x  .  x  x  .  x  x  x  x  .  x  x  .  .  x  .  .  x  x  x  x  x  x  x  x  .  x  .  x  x  x  x  x  .  x  .  x  .  x  .  x  x  x  .  parse  .  .  .  .  x  .  x  x  .  .  x  x  .  x  x  .  x  .  x  x  x  x  .  x  .  .  x  x  x  .  .  x  .  .  x  x  x  x  x  x  x  .  .  x  .  x  x  x  x  x  x  x  .  .  x  .  x  .  .  x  .  x  .  x  .  x  .  x  .  x  .  x  .  .  .  .  .  x  .  x  x  x  x  x  .  x  x  x  x  .  .  x  x  x  x  .  .  x  .  .  .  .  x  .  .  x  x  x  .  r  x  x  .  .  x  .  .  .  .  .  x  x  .  .  .  .  .  x  .  .  .  .  x  .  .  x  x  x  x  x  x  .  .  .  x  .  .  x  x  x  .  x  x  .  .  x  .  .  .  .  x  x  x  .    x . x x x . . x . x . x . . . x . x . x x x . . . x x     x . . x x . . x x . x . x . . . . x . x . . x . . x .     x x . . x x . . . . . x x . . . x x . . . x . x . . x     x x . x . x . . . x . x . . . . x x . x . . x x . . .     . . . . x . x x x . . . . x x x x . . x x x x . . . .     x   . . . . . . . x . x . . . . . . . x x x x . . . x x x     bitmatrix  matrix  decode  x x x . . x x x x x . . . . . x x . . . x . x . x . x     x . . x x x . x x x x x x x x x x x x x . . . x . x x     x . x . x . . x . x x x x x x x x . x x x x . . x x .     x x . x . . . x x . . . x . . x x x . x . x x x x x .     . . x . . x . x . . . x . x x . x x . x . . . x . x .     x x . . . . . . . . x . . . x . x x x . x . . x . . .     x . x x . . x x . . . . . x . . . . . . x x . x x x .     testdecodetoomanyerrors  . . . x . x . x . . . . . x x x x x x . . . . . . x x     x x . . x . . x . x x x x x x x x x x x x x . . x . x     no_points  . . . . x x . . . x . . . . . . . x x . . . x x . x .     x . . . . x . x . x . x . . . x . x . x x . x x . x x     x . . . x . x x x x x x . . x x x . x . x x x x x x .     . . . x x x . . x x . x x x x x . x . . x . . . . . .     x . . . x x . . x x x . x x . x x x x . x x . . x . .     x x x x x x x x . x . x x x x x . x . x . x . x x x .     parse  . . . . x . x x . . x x . x x . x . x x x x . x . . x     x x . . x . . x x x x x x x . . x . x x x x x x x . .     x . x . . x . x . x . x . x . x . x . . . . . x . x x     x x x . x x x x . . x x x x . . x . . . . x . . x x x     .   r  x x . . x . . . . . x x . . . . . x . . . . x . . x x     x x x x . . . x . . x x x . x x . . x . . . . x x x .
__label__flaky do  test  table  create  drop  do  test  table  mutations  do  test  table  timestamps  and  columns  do  test  table  scanners  test  all  run  all  tests  dotesttablecreatedrop  dotesttablemutations  dotesttabletimestampsandcolumns  dotesttablescanners  testall   run all tests
__label__nflaky input  caught  exception  get  buffer  try  writing  one  more  byte   should  fail  get  limit  try  writing  beyond  end  of  buffer.  should  throw  an  exception  size  new  buf  reset  the  stream  and  try   should  succeed  limit  did  not  get  reset  correctly  stream  assert  true  array  contents  mismatch  reset  buffer  equals  test  reset  buffer  writing  beyond  limit  did  not  throw  an  exception  write  to  the  stream   get  the  data  back  and  check  for  contents  arrays  write  input  caughtexception  getbuffer   try writing one more byte  should fail  getlimit   try writing beyond end of buffer. should throw an exception  size  newbuf   reset the stream and try  should succeed  limit did not get reset correctly  stream  asserttrue  array contents mismatch  resetbuffer  equals  testresetbuffer  writing beyond limit did not throw an exception   write to the stream  get the data back and check for contents  arrays  write
__label__flaky reader  wf  actions  get  cmd  wf-test-kill-node-message.xml  conf  get  status  workflow  instance  failed/  killed  assert  not  null  get  test  case  dir  /workflow.xml  file://  action  workflow.xml  wait  for  wf  job  get  cmd  bean  external-status  test  test  kill  node  error  message  execute  oozie  client  fail  job  id  size  get  type  workflow  action  copy  char  stream  get  resource  as  reader  job  file  evaluate  actions  submit  job  end.error  get  workflow  instance  error  engine  get  error  code  get  end  workflow  job  test_  error  a  set  assert  equals  n  services  io  utils  get  test  user  t  signal-value  u  equals  writer  jpa  service  get  error  message  reader  wfactionsgetcmd  wf-test-kill-node-message.xml  conf  getstatus  workflowinstance  failed/killed  assertnotnull  gettestcasedir  /workflow.xml  file://  action  workflow.xml  waitfor  wfjobgetcmd  bean  external-status  test  testkillnodeerrormessage  execute  oozieclient  fail  jobid  size  gettype  workflowaction  copycharstream  getresourceasreader  job  file  evaluate  actions  submitjob  end.error  getworkflowinstance  error  engine  geterrorcode  get  end  workflowjob  test_error  a  set  assertequals  n  services  ioutils  gettestuser  t  signal-value  u  equals  writer  jpaservice  geterrormessage
__label__nflaky verify  interruption  does  not  prevent  logging  list  appender  current  thread  and  https://jira.qos.ch/browse/  logback-1247  is  interrupted  value  of  start  interrupted  the  interruption  needs  to  be  consumed  thread  integer  add  appender  stop  assert  true  do  append  interrupt  verify  async  appender  base  verifyinterruptiondoesnotpreventlogging  listappender  currentthread   and https://jira.qos.ch/browse/logback-1247  isinterrupted  valueof  start  interrupted   the interruption needs to be consumed  thread  integer  addappender  stop  asserttrue  doappend  interrupt  verify  asyncappenderbase
__label__flaky write  to  hosts  file  get  metrics  conf  host  file  test  decommission  with  exclude  hosts  nm2  nm1  node  action  assert  node  heartbeat  get  node  action  yarn  configuration  nm3  assert  true  the  decommisioned  metrics  are  not  updated  metric  count  refresh  nodes  localhost  get  nodes  list  manager  check  decommissioned  nm  count  set  get  absolute  path  ip  host2  start  localhost:4433  host2:5678  host1:1234  normalize  host  name  net  utils  cluster  metrics  register  node  equals  get  num  decommisioned  n  ms  rm  to  test  that  i  ps  also  work    writetohostsfile  getmetrics  conf  hostfile  testdecommissionwithexcludehosts  nm2  nm1  nodeaction  assert  nodeheartbeat  getnodeaction  yarnconfiguration  nm3  asserttrue  the decommisioned metrics are not updated  metriccount  refreshnodes  localhost  getnodeslistmanager  checkdecommissionednmcount  set  getabsolutepath  ip  host2  start  localhost:4433  host2:5678  host1:1234  normalizehostname  netutils  clustermetrics  registernode  equals  getnumdecommisionednms  rm   to test that ips also work
__label__nflaky big  enough  encode  strange  width  barcode  format  assert  equals  get  width  matrix  test  qr  code  writer  the  qr  should  be  multiplied  up  to  fit   with  extra  padding  if  necessary  get  height  assert  true  assert  not  null  we  should  also  be  able  to  handle  non-square  requests  by  padding  them  too  small  strange  height  writer  http://www.google.com/  the  qr  will  not  fit  in  this  size   so  the  matrix  should  come  back  bigger  bigenough  encode  strangewidth  barcodeformat  assertequals  getwidth  matrix  testqrcodewriter   the qr should be multiplied up to fit  with extra padding if necessary  getheight  asserttrue  assertnotnull   we should also be able to handle non-square requests by padding them  toosmall  strangeheight  writer  http://www.google.com/   the qr will not fit in this size  so the matrix should come back bigger
__label__flaky call  /resource  test  fixed  resource  post  my  json  rest  servlet  get  http  servlet  response  invoke  assert  equals  run  test    call  /resource  testfixedresource  post  myjsonrestservlet  get  httpservletresponse  invoke  assertequals  runtest
__label__nflaky server  get  current  user  rpc  some  super  user  group_  names  get  user  new  empty  request  run  master  conf  authentication  method  (auth:  token)  via  some  super  user  (auth:  simple)  *  the  user  gets  the  token  via  a  superuser.  server  should  authenticate  *  this  user.  set  rpc  engine  to  protobuf  rpc  engine  ret  val  set  authentication  method  current  assert  new  conf  refresh  conf  test  token  by  super  user  get  user  name  client  sm  set  protocol  engine  addr  set  configuration  user  group  information  create  user  for  testing  add  token  token  id  print  stack  trace  e  expected  assert  equals  get  client  set  token  service  real_  user_  name  token  do  as  stop  security  util  setup  test  server  !=  server  getcurrentuser  rpc  somesuperuser  group_names  getuser  newemptyrequest  run  masterconf  authenticationmethod   (auth:token) via somesuperuser (auth:simple)       * the user gets the token via a superuser. server should authenticate     * this user.         set rpc engine to protobuf rpc engine  retval  setauthenticationmethod  current  assert  newconf  refreshconf  testtokenbysuperuser  getusername  client  sm  setprotocolengine  addr  setconfiguration  usergroupinformation  createuserfortesting  addtoken  tokenid  printstacktrace  e  expected  assertequals  getclient  settokenservice  real_user_name  token  doas  stop  securityutil  setuptestserver  !=
__label__flaky exec_  order  callable2  test  concurrency  callable3  callables  callable1  c  callable4  callable5  math  as  list  queueservice  test  concurrency  services  min  assert  true  get  second  batch  long  arrays  evaluate  wait  for  queue  first  exec_order  callable2  testconcurrency  callable3  callables  callable1  c  callable4  callable5  math  aslist  queueservice  testconcurrency  services  min  asserttrue  get  secondbatch  long  arrays  evaluate  waitfor  queue  first
__label__nflaky conn  server  in  stream  get  endpoint  details  get  content  http/1.1  200  ok  server:  test  content-  length:  3  123  when  get  bytes  content  bind  assert  assert  true  assert  not  null  get  response  count  get  code  standard  charsets  then  return  assert  equals  get  entity  get  content  length  get  input  stream  test  read  response  entity  with  content  length  mockito  response  socket  contains  header  receive  response  header  entity  receive  response  entity  conn  server  instream  getendpointdetails  getcontent  http/1.1 200 ok  server: test  content-length: 3    123  when  getbytes  content  bind  assert  asserttrue  assertnotnull  getresponsecount  getcode  standardcharsets  thenreturn  assertequals  getentity  getcontentlength  getinputstream  testreadresponseentitywithcontentlength  mockito  response  socket  containsheader  receiveresponseheader  entity  receiveresponseentity
__label__flaky /newfile3  /newfile1  /newfile2  test  touchz  on  a  non-zero  length  file  fs2  <fs/>  fs1  is  a  directory  assert  false  f1  dir  f2  fs  create  context  f3  assert  true  get  len  context  get  file  status  create  write  close  must  be  a  zero-length  file  touchz  ae  test  touchz  get  message  get  file  system  dir1  fail  contains  ex  mkdirs  exists  writer  create  new  file  this  is  not  a  zero  length  file  get  fs  test  case  dir  is  dir  /newfile3  /newfile1  /newfile2   test touchz on a non-zero length file  fs2  <fs/>  fs1  is a directory  assertfalse  f1  dir  f2  fs  createcontext  f3  asserttrue  getlen  context  getfilestatus  create  write  close  must be a zero-length file  touchz  ae  testtouchz  getmessage  getfilesystem  dir1  fail  contains  ex  mkdirs  exists  writer  createnewfile  this is not a zero length file  getfstestcasedir  isdir
__label__nflaky p  test4  size  get  cvvsdf  b1234  assert  equals  a123  /a123/b1234/cvvsdf  p  test4  size  get  cvvsdf  b1234  assertequals  a123  /a123/b1234/cvvsdf
__label__flaky regions  log  merge  region  0  and  region  1  get  log  get  region  name  as  string  h  constants  system  family  result  bytes  merging  regions  0+1  and  2  close  the  region  and  delete  the  log  assert  true  log  path  assert  not  null  get  merge  and  verify  merging  regions  0  and  1  test  merge  tool  merge  the  result  of  merging  regions  0   1  and  2  with  region  3  close  merge  the  result  of  merging  regions  0  and  1  with  region  2  /tmp  _  info  log  old  log  dir  merged  merging  regions  0+1+2  and  3  j  rows  close  and  delete  contain  the  right  data.  get  region  info  get  value  sorted  add  family  bytes  equals  current  time  millis  create  a  log  that  we  can  reuse  when  we  need  to  open  regions  merging  regions  0+1+2+3  and  4  to  string  creating  log  merge  the  result  of  merging  regions  0   1   2  and  3  with  region  4  regions  log   merge region 0 and region 1  getlog  getregionnameasstring  hconstants  system  family  result  bytes  merging regions 0+1 and 2   close the region and delete the log  asserttrue  logpath  assertnotnull  get  mergeandverify  merging regions 0 and 1  testmergetool   merge the result of merging regions 0  1 and 2 with region 3  close   merge the result of merging regions 0 and 1 with region 2  /tmp  _  info  log  oldlogdir  merged  merging regions 0+1+2 and 3  j  rows  closeanddelete   contain the right data.  getregioninfo  getvalue  sorted  addfamily  bytes  equals  currenttimemillis   create a log that we can reuse when we need to open regions  merging regions 0+1+2+3 and 4  tostring  creating log    merge the result of merging regions 0  1  2 and 3 with region 4
__label__nflaky ser  get  deserializer  unchecked  serializer  deserializer  assert  equals  deser  test  writable  comparator  java  serialization  serialize  get  serializer  orig  dob  get  length  reset  dib  close  open  get  data  deserialize  rawtypes  ser  getdeserializer  unchecked  serializer  deserializer  assertequals  deser  testwritablecomparatorjavaserialization  serialize  getserializer  orig  dob  getlength  reset  dib  close  open  getdata  deserialize  rawtypes
__label__flaky action  num  coordinator  job  coord-action-get.xml  coordinator  action  get  id  job  add  record  to  coord  action  table  add  record  to  coord  job  table  _test  pending  false  count  test  coord  actions  pending  false  count  get  actionnum  coordinatorjob  coord-action-get.xml  coordinatoraction  getid  job  addrecordtocoordactiontable  addrecordtocoordjobtable  _testpendingfalsecount  testcoordactionspendingfalsecountget
__label__nflaky svc  init  stop  l2  unregister  service  listener  listener  start  test  service  notifications  unregister  during  callback  register  service  listener  assert  event  count  svc  init  stop  l2  unregisterservicelistener  listener  start  testservicenotificationsunregisterduringcallback  registerservicelistener  asserteventcount
__label__flaky get  job  tracker  uri  get  name  get  status  create  context  get  test  case  dir  context  create  wait  for  <job-tracker>  test-extra.jar  test  additional  jar  submit  ok  ae  </job-tracker>  is  get  file  system  check  <name-node>  <main-class>  </name-node>  workflow  action  <file>  succeeded  app  jar  path  submit  action  evaluate  <java>  assert  false  get  app  path  action  xml  is  successful  create  jar  assert  true  </file>  end  get  data  is  completed  get  name  node  uri  os  </java>  </main-class>  running  job  get  action  assert  equals  get  external  status  io  utils  assert  null  jar  file  copy  stream  to  string  is  complete  getjobtrackeruri  getname  getstatus  createcontext  gettestcasedir  context  create  waitfor  <job-tracker>  test-extra.jar  testadditionaljarsubmitok  ae  </job-tracker>  is  getfilesystem  check  <name-node>  <main-class>  </name-node>  workflowaction  <file>  succeeded  appjarpath  submitaction  evaluate  <java>  assertfalse  getapppath  actionxml  issuccessful  createjar  asserttrue  </file>  end  getdata  iscompleted  getnamenodeuri  os  </java>  </main-class>  runningjob  getaction  assertequals  getexternalstatus  ioutils  assertnull  jarfile  copystream  tostring  iscomplete
__label__nflaky add  token  new  token  should  be  selected  when  both  exist  kp  old  token  conf  assert  equals  creds  uri  get  service  token  provider  uri  string  test  select  token  when  both  exist  t  select  delegation  token  close  addtoken  new token should be selected when both exist  kp  oldtoken  conf  assertequals  creds  uri  getservice  token  provideruristring  testselecttokenwhenbothexist  t  selectdelegationtoken  close
__label__flaky format  date  play  a  last-  modified:  server  read  ascii  add  header  warning  open  connection  assert  equals  set  body  set  response  code  get  headers  deletes  cached100  level  warnings  /  cache-  control:  max-age=0  enqueue  get  url  get  header  field  warning:  199  test  danger  http  url  connection  connection1  time  unit  199  test  danger  connection2  formatdate  play  a  last-modified:   server  readascii  addheader  warning  openconnection  assertequals  setbody  setresponsecode  getheadersdeletescached100levelwarnings  /  cache-control: max-age=0  enqueue  geturl  getheaderfield  warning: 199 test danger  httpurlconnection  connection1  timeunit  199 test danger  connection2
__label__nflaky files  option  does  not  match  #link  file:///xyz.txt  conf  assert  true  assert  not  null  get  files  is  null  create  generic  option  parser  should  throw  exception  test  files  option  e  to  uri  conf2  assert  equals  conf1  test  dir  tmp  file  file  not  found  exception  is  not  thrown  pass  a  files  option  args  -files  local  fs  tmp  uri  assert  null  th  make  qualified  files  to  string  files  is  not  null  pass  file  as  uri  all  platforms  and  generic  options  parser  accepts  only  valid  ur  is  tmpfiles  tmpfile  tmp  path  throwable  is  null  files option does not match  #link  file:///xyz.txt  conf  asserttrue  assertnotnull  get  files is null  create   genericoptionparser should throw exception  testfilesoption  e  touri  conf2  assertequals  conf1  testdir  tmpfile  filenotfoundexception is not thrown   pass a files option  args  -files  localfs  tmpuri  assertnull  th  makequalified  files  tostring  files is not null   pass file as uri   all platforms and genericoptionsparser accepts only valid uris  tmpfiles  tmpfile  tmppath  throwable is null
__label__flaky end_  points  is_  security_  enabled  oozie  url  run  test  re  run  app  path  assert  true  get  -config  create  workflow.xml  servlet_  classes  close  run  test  app  create  config  file  rest  constants  get  context  url  mock  dag  engine  service  assert  equals  get  file  system  -rerun  args  call  1  -oozie  mkdirs  to  string  job  get  fs  test  case  dir  end_points  is_security_enabled  oozieurl  run  testrerun  apppath  asserttrue  get  -config  create  workflow.xml  servlet_classes  close  runtest  app  createconfigfile  restconstants  getcontexturl  mockdagengineservice  assertequals  getfilesystem  -rerun  args  call  1  -oozie  mkdirs  tostring  job  getfstestcasedir
__label__nflaky io  session1  arg  that  core  matchers  not  null  value  equal  to  has  item  connect  future  when  impl  do  answer  times  assert  get  verify  of  seconds  argument  matchers  any  string  then  return  timeout  somehost  get  argument  test  get  sessions  completed  assert  that  eq  future3  any  execute  is  done  matches  same  instance  invocation  future1  get  routes  is  open  future2  answer  mockito  callback  validate  session  connect  session  get  session  iosession1  argthat  corematchers  notnullvalue  equalto  hasitem  connectfuture  when  impl  doanswer  times  assert  get  verify  ofseconds  argumentmatchers  anystring  thenreturn  timeout  somehost  getargument  testgetsessions  completed  assertthat  eq  future3  any  execute  isdone  matches  sameinstance  invocation  future1  getroutes  isopen  future2  answer  mockito  callback  validatesession  connectsession  getsession
__label__flaky kills  add  node  workflow  job  enters  one  abcde  start  assert  equals  workflow  instance  get  status  three  two  as  list  test  immediate  error  exits  size  four  test  wf  <worklfow-app/>  end  arrays  workflow  def  fails  kills  addnode  workflowjob  enters  one  abcde  start  assertequals  workflowinstance  getstatus  three  two  aslist  testimmediateerror  exits  size  four  testwf  <worklfow-app/>  end  arrays  workflowdef  fails
__label__nflaky set  an  integer  set  an  int  innocent  smoke  back  assert  equals  write  and  read  seta  string  setaninteger  setanint  innocent  smoke  back  assertequals  writeandread  setastring
__label__flaky <execution>  lifo</execution>  </controls>  <datasets>  submit  job  get  missing  dependencies  /workflows/${  year}/${  month}/${  day}</uri-template>  <done-flag></done-flag>  </dataset>  test  empty  done  flag  conf  <data-in  name=\""  a\""  dataset=\""local_a\"">  <instance>${coord:current(0)}</instance>  </data-in>  get  actions  </input-events>  get  status  app  path  system  write  to  file  app  xml  action  status  <dataset  name=\""local_a\""  frequency=\""${coord:days(1)}\""  initial-instance=\""2009-02-01  t01:00  z\""  assert  true  file://  get  test  case  dir  unit_  testing  get  coordinator  action  ..  missing  deps=  action  missing  deps  xmlns=\""uri:oozie:coordinator:0.1\"">  <controls>  <timeout>10</timeout>  <concurrency>2</concurrency>  wait  for  timezone=\""  utc\"">  <uri-template>file://  get  coord  job  coordinator.xml  ce  set  <coordinator-app  name=\""  name\""  frequency=\""${coord:days(1)}\""  start=\""2009-02-01  t01:00  z\""  end=\""2009-02-01  t02:00  z\""  timezone=\""  utc\""  <configuration>  <property>  <name>input  a</name>  <value>${coord:data  in(\'  a\')}</value>  </property>  assert  equals  <action>  <workflow>  <app-path>hdfs:///tmp/workflows2/</app-path>  </configuration>  </workflow>  </action>  </coordinator-app>  oozie  client  job  id  get  test  user  size  </datasets>  <input-events>  /workflows/2009/02/01  file  actions  evaluate  <execution>lifo</execution> </controls> <datasets>   submitjob  getmissingdependencies  /workflows/${year}/${month}/${day}</uri-template>   <done-flag></done-flag> </dataset>  testemptydoneflag  conf  <data-in name=\""a\"" dataset=\""local_a\""> <instance>${coord:current(0)}</instance> </data-in>    getactions  </input-events>   getstatus  apppath  system  writetofile  appxml  actionstatus  <dataset name=\""local_a\"" frequency=\""${coord:days(1)}\"" initial-instance=\""2009-02-01t01:00z\""   asserttrue  file://  gettestcasedir  unit_testing  get  coordinatoraction  ..missing deps=  action  missingdeps  xmlns=\""uri:oozie:coordinator:0.1\""> <controls> <timeout>10</timeout> <concurrency>2</concurrency>   waitfor  timezone=\""utc\""> <uri-template>file://  getcoordjob  coordinator.xml  ce  set  <coordinator-app name=\""name\"" frequency=\""${coord:days(1)}\"" start=\""2009-02-01t01:00z\"" end=\""2009-02-01t02:00z\"" timezone=\""utc\""   <configuration> <property> <name>inputa</name> <value>${coord:datain(\'a\')}</value> </property>   assertequals  <action> <workflow> <app-path>hdfs:///tmp/workflows2/</app-path>   </configuration> </workflow> </action> </coordinator-app>  oozieclient  jobid  gettestuser  size  </datasets> <input-events>   /workflows/2009/02/01  file  actions  evaluate
__label__nflaky create  user  for  testing  test  without  setting  a  default  machine  list  ip_  range  set  test  with  a  default  machine  list  drwho  refresh  conf  drwho@  example.  com  group2  group1  security.service.authorization.default.hosts  service  authorization  manager  fail  test  default  machine  list  unauthorized_  ip  get  by  name  inet  address  authorize  10.222.0.0  user  group  information  createuserfortesting   test without setting a default machinelist  ip_range  set   test with a default machinelist  drwho  refresh  conf  drwho@example.com  group2  group1  security.service.authorization.default.hosts  serviceauthorizationmanager  fail  testdefaultmachinelist  unauthorized_ip  getbyname  inetaddress  authorize  10.222.0.0  usergroupinformation
__label__flaky services  callable  assert  true  get  test  queuing  evaluate  wait  for  queueservice  queue  services  callable  asserttrue  get  testqueuing  evaluate  waitfor  queueservice  queue
__label__nflaky 0  1  0  set  test  to  string  array  1  0  1  expected  to  string  assert  equals   0 1 0    set  testtostring  array   1 0 1    expected  tostring  assertequals
__label__flaky /*/*  pattern  assert  equals  user_  dir  prepare  testing  path  test  path  filter  /a  /a/b  quote  files  matched  path  ^.*  cleanup  dfs  /*/*  pattern  assertequals  user_dir  preparetesting  path  testpathfilter  /a  /a/b  quote  files  matchedpath  ^.*  cleanupdfs
__label__nflaky roll  master  key  retrieve  password  bi  new  passwd  compare  the  passwords  old  passwd  after  rolling   the  length  of  the  keys  list  must  increase  sleep  generate  delegation  token  assert  wait  for  keys  to  expire  get  all  keys  assert  true  is  greater  than  or  equal  to  get  identifier  dt  secret  manager  start  threads  prev  num  keys  create  identifier  identifier  job  tracker  assert  equals  stop  threads  assert  that  token  thread  read  fields  some  user  get  password  curr  num  keys  is  not  valid)  store  the  length  of  the  keys  list  test  roll  master  key  generate  a  token  and  store  the  password  rollmasterkey  retrievepassword  bi  newpasswd   compare the passwords  oldpasswd   after rolling  the length of the keys list must increase  sleep  generatedelegationtoken  assert   wait for keys to expire  getallkeys  asserttrue  isgreaterthanorequalto  getidentifier  dtsecretmanager  startthreads  prevnumkeys  createidentifier  identifier  jobtracker  assertequals  stopthreads  assertthat  token  thread  readfields  someuser  getpassword  currnumkeys   is not valid)   store the length of the keys list  testrollmasterkey   generate a token and store the password
__label__flaky cluster  backup  get  first  tx  id  nn  image  before  bn  checkpoint  get  rpc  server  conf  /edit-while-bn-down  nn  should  have  received  new  checkpoint.  before:  assert  not  null  startup  option  get  fs  image  nn  should  have  received  a  new  image  do  checkpoint  is  in  progress  nn  image  after  info  roll  edit  log  should  not  have  finalized  log  bn  should  stay  in  sync  after  checkpoint  get  file  system  bn  should  stay  in  sync  after  roll  get  name  node  do  some  edits  stop  num  data  nodes  mkdirs  file  sys  get  storage  get  file  info  shutdown  test  backup  node  tails  edits  nn  get  storage  dir  nn  rpc  get  most  recent  checkpoint  tx  id  start  a  new  backup  node  force  a  roll  --  bn  should  roll  with  nn.  find  latest  edits  log  sd  edits  log  assert  true  close  get  cur  segment  tx  id  bn  image  get  edit  log  after:  shutting  down...  still  open  on  the  nn  stop  bn  test  bn  in  sync  assert  equals  start  backup  node  build  assert  storage  dirs  match  fs  image  test  util  get  namesystem  cluster  backup  getfirsttxid  nnimagebefore   bn checkpoint  getrpcserver  conf  /edit-while-bn-down  nn should have received new checkpoint. before:   assertnotnull  startupoption  getfsimage   nn should have received a new image  docheckpoint  isinprogress  nnimageafter  info  rolleditlog  should not have finalized   log   bn should stay in sync after checkpoint  getfilesystem   bn should stay in sync after roll  getnamenode   do some edits  stop  numdatanodes  mkdirs  filesys  getstorage  getfileinfo  shutdown  testbackupnodetailsedits  nn  getstoragedir  nnrpc  getmostrecentcheckpointtxid   start a new backup node   force a roll -- bn should roll with nn.  findlatesteditslog  sd  editslog  asserttrue  close  getcursegmenttxid  bnimage  geteditlog   after:   shutting down...   still open on the nn   stop bn  testbninsync  assertequals  startbackupnode  build  assertstoragedirsmatch  fsimagetestutil  getnamesystem
__label__nflaky end  date  get  time  hadoop_  kerberos_  min_  seconds_  before_  relogin  conf  time  authentication  method  suppose  tgt  start  time  is  now   end  time  is  20  seconds  from  now.     retry:  set  authentication  method  relogin  interval  exponential  backoff  retry  make  sure  no  more  retries  after  (tgt  end  time  -  login  interval).  now  retry  policies  time  unit  5th  retry   now:  set  configuration  value  user  group  information  info  test  get  next  retry  time  set  log  level  incr  log  relogin  happens  every  1  second.  generic  test  utils  assert  equals  assert  within  bounds  get  renewal  failures  relogin  interval  ms  current  time  last  retry  str  last  try  should  be  right  before  expiry.  set  long  overflow  retry   now:  long  level  security  util  get  next  tgt  renewal  time  end  time  verify  exponential  backoff  and  max=(login  interval  before  end  time).  rp  enddate  gettime  hadoop_kerberos_min_seconds_before_relogin  conf  time  authenticationmethod   suppose tgt start time is now  end time is 20 seconds from now.    retry:  setauthenticationmethod  relogininterval  exponentialbackoffretry   make sure no more retries after (tgt endtime - login interval).  now  retrypolicies  timeunit  5th retry  now:  setconfiguration  value  usergroupinformation  info  testgetnextretrytime  setloglevel  incr  log   relogin happens every 1 second.  generictestutils  assertequals  assertwithinbounds  getrenewalfailures  reloginintervalms  currenttime  lastretry  str   last try should be right before expiry.  setlong  overflow retry  now:  long  level  securityutil  getnexttgtrenewaltime  endtime   verify exponential backoff and max=(login interval before endtime).  rp
__label__flaky abc  print  stack  trace  def  e  foo  prepare  xml  with  include  conf  assert  equals  parent  xml  x  include  failed  fail  bar  oozie.dummy  get  test  case  dir  get  test  add  x  include  from  stream  verify  the  properties  from  include  file  default  abc  printstacktrace  def  e  foo  preparexmlwithinclude  conf  assertequals  parentxml  xinclude failed  fail  bar  oozie.dummy  gettestcasedir  get  testaddxincludefromstream   verify the properties from include file  default
__label__nflaky get  the  switch  map  and  examine  it  mapping  n1  add  node  to  rack  resolve  switch  map  log  topology  dump  topology  test  add  resolve  nodes  get  switch  map  new  instance  assert  equals  /r1  query  list  static  mapping  size  get  network  topology  create  query  list  resolved  info   get the switch map and examine it  mapping  n1  addnodetorack  resolve  switchmap  log  topology  dumptopology  testaddresolvenodes  getswitchmap  newinstance  assertequals  /r1  querylist  staticmapping  size  get  networktopology  createquerylist  resolved  info
__label__flaky test  count  put  thread  got  value  test  writes  while  getting  table  name  bytes  test  writes  while  scanning  join  prev  timestamp  row0  method  check  no  error  to  bytes  qualifiers  raw  done  init  h  region  sorted  size  search  looking  for  the  qualifier  in  question?  flush  interval  previous  empty  region  num  rows  result  system.out.println(\""iteration  =  \""  +  i);  flush  assert  true  get  timestamp  get  timestamp  num  qualifiers  this  value  start  is  empty  num  families  assert  equals  expected  count  kv  families  flushcache  get  value  i=  get  family  compact  stores  equals  flush  thread  compact  interval  qual  family  get  qualifier  testcount  putthread  gotvalue  testwriteswhilegetting  tablename  bytes  testwriteswhilescanning  join  prevtimestamp  row0  method  checknoerror  tobytes  qualifiers  raw  done  inithregion  sorted  size   search looking for the qualifier in question?  flushinterval  previousempty  region  numrows  result   system.out.println(\""iteration = \"" + i);  flush  asserttrue  gettimestamp  get  timestamp  numqualifiers  thisvalue  start  isempty  numfamilies  assertequals  expectedcount  kv  families  flushcache  getvalue  i=  getfamily  compactstores  equals  flushthread  compactinterval  qual  family  getqualifier
__label__nflaky handler  registry  resolve  /tes?test=a  /test?test=a  assert  equals  method  /test*  test  by  request  uri  with  query  assert  context  assert  not  equals  stuff  register  handlerregistry  resolve  /tes?test=a  /test?test=a  assertequals  method  /test*  testbyrequesturiwithquery  assert  context  assertnotequals  stuff  register
__label__flaky a  l1  l2  start  assert  equals  sb  thread  sleep  a:1-  l  a:1-  u  a:2-  l  a:2-  u  trim  test  read  write  lock  finish  to  string    a  l1  l2  start  assertequals  sb  thread  sleep  a:1-l a:1-u a:2-l a:2-u  trim  testreadwritelock  finish  tostring
__label__nflaky test  file01  get  path  data  testfile01  test  dir06  test  dir05  ls  format  line  mtime  check  listing  of  multiple  files  out  testfile03  options  compute  line  format  in  order  testfile02  process  options  verify  testfile05  test  file06  testfile04  process  path  files  test  file04  test  file05  testfile06  test  file02  test  file03  add  path  data  line  format  process  arguments  verify  no  more  interactions  test  file  test  dir04  test  dir03  mock  test  dir02  test  dir01  testfile01  getpathdata  testfile01  testdir06  testdir05  ls  formatlinemtime   check listing of multiple files  out  testfile03  options  computelineformat  inorder  testfile02  processoptions  verify  testfile05  testfile06  testfile04  processpathfiles  testfile04  testfile05  testfile06  testfile02  testfile03  add  pathdata  lineformat  processarguments  verifynomoreinteractions  testfile  testdir04  testdir03  mock  testdir02  testdir01
__label__flaky xml  utils  <property><name></name></property>  parse  xml  conf  assert  equals  <root  xmlns=\""uri:oozie:workflow:0.4\""><parameters>  str  fail  ex  get  error  code  <property><name>hello</name></property>  parameter  verifier  test  verify  parameters  empty  name  error  code  verify  parameters  </parameters></root>  xmlutils  <property><name></name></property>  parsexml  conf  assertequals  <root xmlns=\""uri:oozie:workflow:0.4\""><parameters>  str  fail  ex  geterrorcode  <property><name>hello</name></property>  parameterverifier  testverifyparametersemptyname  errorcode  verifyparameters  </parameters></root>
__label__nflaky get  content  encoding  abc  content  type  byte  channel  standard  charsets  assert  false  assert  equals  get  content  length  produce  test  binary  content  assert  is  open  producer  get  content  type  to  string  dump  stream  channel  getcontentencoding  abc  contenttype  bytechannel  standardcharsets  assertfalse  assertequals  getcontentlength  produce  testbinarycontent  assert  isopen  producer  getcontenttype  tostring  dump  streamchannel
__label__flaky handler  get  current  user  get  end  job  commit  failure  file  conf  staging  dir  to  application  attempt  id  when  assert  not  null  file  system  commit  job  get  clock  user  group  information  init  wait  for  it  handler  get  application  id  mock  committer  then  return  get  event  handler  intentional  failure  get  and  clear  event  handle  get  end  job  commit  success  file  mr  apps  job  id  do  throw  stop  mock  start  commit  file  mr  job  config  get  application  id  assert  false  converter  utils  fs  test  failure  mock  job  context  get  application  attempt  id  assert  true  get  verify  appattempt_1234567890000_0001_0  from  yarn  get  short  user  name  set  get  start  job  commit  file  end  commit  failure  file  e  to  yarn  start  mock  clock  any  end  commit  success  file  type  converter  mock  context  exists  user  attemptid  handler  getcurrentuser  getendjobcommitfailurefile  conf  stagingdir  toapplicationattemptid  when  assertnotnull  filesystem  commitjob  getclock  usergroupinformation  init  waitforithandler  getapplicationid  mockcommitter  thenreturn  geteventhandler  intentional failure  getandclearevent  handle  getendjobcommitsuccessfile  mrapps  jobid  dothrow  stop  mock  startcommitfile  mrjobconfig  getapplicationid  assertfalse  converterutils  fs  testfailure  mockjobcontext  getapplicationattemptid  asserttrue  get  verify  appattempt_1234567890000_0001_0  fromyarn  getshortusername  set  getstartjobcommitfile  endcommitfailurefile  e  toyarn  start  mockclock  any  endcommitsuccessfile  typeconverter  mockcontext  exists  user  attemptid
__label__nflaky multiple  evaluation  murmur  hash  error  !!!  murmur  hash  test  hash  jenkins  error  !!!  hash  get  bytes  undefined  assert  true  line  jenkins  test  hash  murmur  error  !!!  multiple  evaluation  jenkins  hash  error  !!!  parse  hash  type  test  hash  test  hash  undefine  configuration  error  !!!  test  hash  error  jenkin  get  instance  !!!  set  hadoop.util.hash.type  cfg  murmur  test  hash  jenkins  configuration  error  !!!  test  hash  undefined  iterations  jenkins  hash  jenkins  hash  assert  null  murmur  hash  test  hash  error  murmur  get  instance  !!!  get  instance  test  hash  error  invalid  get  instance  !!!  hash  multiple evaluation murmur hash error !!!  murmurhash  testhash jenkins error !!!  hash  getbytes  undefined  asserttrue  line  jenkins  testhash murmur error !!!  multiple evaluation jenkins hash error !!!  parsehashtype  testhash  testhash undefine configuration error !!!  testhash error jenkin getinstance !!!  set  hadoop.util.hash.type  cfg  murmur  testhash jenkins configuration error !!!  testhash undefined  iterations  jenkinshash  jenkinshash  assertnull  murmurhash  testhash error murmur getinstance !!!  getinstance  testhash error invalid getinstance !!!  hash
__label__flaky coord  action  get  cmd  get  current  dateafter  incrementing  in  months  get  id  date  utils  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  assert  not  null  get  coordinator  action  action  end  current  date  plus  month  test  coord  kill  success2  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  call  coordinator  job  services  coord  job  get  cmd  coord-action-get.xml  job  jpa  service  coordactiongetcmd  getcurrentdateafterincrementinginmonths  getid  dateutils  getstatus  addrecordtocoordactiontable  parsedateoozietz  assertnotnull  get  coordinatoraction  action  end  currentdateplusmonth  testcoordkillsuccess2  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  call  coordinatorjob  services  coordjobgetcmd  coord-action-get.xml  job  jpaservice
__label__nflaky set  max  45  witness  set  min  fi  value  of  assert  equals  4.5  test  basic  format  info  setmax  45  witness  setmin  fi  valueof  assertequals  4.5  testbasic  formatinfo
__label__flaky cluster  failed  to  throw  ioe  when  seeking  after  close  conf  failed  to  throw  ioe  when  seeking  past  end  create  file  seek  test  dfs  seek  exceptions  output  path  get  test  configuration  file  assert  true  create  close  threw  get  file  system  some  test  data  to  write  longer  than  10  bytes  input  write  bytes  build  num  data  nodes  /test/fileclosethenseek/file-0  file  sys  success  shutdown  open  cluster  failed to throw ioe when seeking after close  conf  failed to throw ioe when seeking past end   create file  seek  testdfsseekexceptions  output  path  gettestconfiguration  file  asserttrue  create  close  threw  getfilesystem  some test data to write longer than 10 bytes  input  writebytes  build  numdatanodes  /test/fileclosethenseek/file-0  filesys   success  shutdown  open
__label__nflaky enum  param  assert  false  context  enum  param  should  handle  null  create  verify  has  violations  invoke  mock  controller  validation  enumparam  assertfalse  context  enumparamshouldhandlenull  create  verify  hasviolations  invoke  mockcontroller  validation
__label__flaky server  proxy  users  test  protocol  rpc  configure  super  user  ip  addresses  get  proxy  superuser  group  conf  key  get  proxy  a  method  group_  names  conf  run  ret  val  test  real  user  group  authorization  failure  assert  set  strings  real_  user_  short_  name  stop  proxy  addr  user  group  information  get  server  ret  proxy  user  ugi  print  stack  trace  e  start  group3  create  remote  user  get  connect  address  real_  user_  name  proxy  fail  do  as  net  utils  stop  address  proxy_  user_  name  the  rpc  must  have  failed  real  user  ugi  create  proxy  user  for  testing  server  proxyusers  testprotocol  rpc  configuresuperuseripaddresses  getproxysuperusergroupconfkey  getproxy  amethod  group_names  conf  run  retval  testrealusergroupauthorizationfailure  assert  setstrings  real_user_short_name  stopproxy  addr  usergroupinformation  getserver  ret  proxyuserugi  printstacktrace  e  start  group3  createremoteuser  getconnectaddress  real_user_name  proxy  fail  doas  netutils  stop  address  proxy_user_name  the rpc must have failed   realuserugi  createproxyuserfortesting
__label__nflaky did  not  find  3rd  occurrence  of  character  \'l\'  did  not  find  2nd  occurrence  of  character  \'l\'  test  find  nth  byte  data  hello   world!  utf8  byte  array  utils  assert  equals  4th  occurrence  of  character  \'l\'  does  not  exist  find  nth  byte  get  bytes  did not find 3rd occurrence of character \'l\'  did not find 2nd occurrence of character \'l\'  testfindnthbyte  data  hello  world!  utf8bytearrayutils  assertequals  4th occurrence of character \'l\' does not exist  findnthbyte  getbytes
__label__flaky <fs/>  dir  fs  create  context  -rwxr-----  path  rwx---r--  rwx-----x  get  file  status  context  rwx------  chmod  fs  permission  set  permission  grandchild  -rwxr----x  -rwx-----x  get  permission  ae  test  chmod  recursive  value  of  rwxr-----  assert  equals  get  file  system  rwxr----x  -rwx------  mkdirs  to  string  get  fs  test  case  dir  child  -rwx---r--  <fs/>  dir  fs  createcontext  -rwxr-----  path  rwx---r--  rwx-----x  getfilestatus  context  rwx------  chmod  fspermission  setpermission  grandchild  -rwxr----x  -rwx-----x  getpermission  ae  testchmodrecursive  valueof  rwxr-----  assertequals  getfilesystem  rwxr----x  -rwx------  mkdirs  tostring  getfstestcasedir  child  -rwx---r--
__label__nflaky .0  get  queue  class  common  configuration  keys  server  manager  assert  can  put  ns  org.apache.hadoop.ipc.  decay  rpc  scheduler  default  fcq  has  4  levels  and  the  max  capacity  is  8  get  canonical  name  conf  queue  class  name  org.apache.hadoop.ipc.  fair  call  queue  .  scheduler  get  scheduler  class  test  fcq  backward  compatibility  set  strings  assert  true  equals  ensure  the  decay  scheduler  will  be  added  to  avoid  breaking.  work  without  explicitly  specifying  decay  rpc  scheduler  queue    .0  getqueueclass  commonconfigurationkeys  server  manager  assertcanput  ns  org.apache.hadoop.ipc.decayrpcscheduler   default fcq has 4 levels and the max capacity is 8  getcanonicalname  conf  queueclassname  org.apache.hadoop.ipc.faircallqueue  .  scheduler  getschedulerclass  testfcqbackwardcompatibility  setstrings  asserttrue  equals   ensure the decayscheduler will be added to avoid breaking.   work without explicitly specifying decayrpcscheduler  queue
__label__flaky cluster  mock  resource  checker  has  available  disk  space  get  name  get  all  stack  traces  test  check  that  name  node  resource  monitor  is  running  make  sure  the  nnrm  thread  has  a  chance  to  run.  assert  false  thread  conf  nn  should  not  presently  be  in  safe  mode  when  system  wait  active  sleep  assert  true  key  set  name  dir  start  millis  dfs  config  keys  set  get  absolute  path  then  return  is  in  safe  mode  get  name  node  thread  nn  resource  monitor  should  be  running  set  long  is  name  node  monitor  running  running  threads  nn  should  be  in  safe  mode  after  resources  crossed  threshold  build  mockito  num  data  nodes  current  time  millis  name  mock  to  string  shutdown  running  thread  get  namesystem  starts  with  cluster  mockresourcechecker  hasavailablediskspace  getname  getallstacktraces  testcheckthatnamenoderesourcemonitorisrunning   make sure the nnrm thread has a chance to run.  assertfalse  thread  conf  nn should not presently be in safe mode  when  system  waitactive  sleep  asserttrue  keyset  namedir  startmillis  dfsconfigkeys  set  getabsolutepath  thenreturn  isinsafemode  getnamenode  thread  nn resource monitor should be running  setlong  isnamenodemonitorrunning  runningthreads  nn should be in safe mode after resources crossed threshold  build  mockito  numdatanodes  currenttimemillis  name  mock  tostring  shutdown  runningthread  getnamesystem  startswith
__label__nflaky item  get  conf  apply  glob  apply  n*e  /directory/path/name  name  setup  assert  equals  mock  fs  result  test  a  matching  glob  pattern  item  getconf  applyglob  apply  n*e  /directory/path/name  name  setup  assertequals  mockfs  result   test a matching glob pattern
__label__flaky test  start  non  transient  with  coord  action  update  start.non-transient  assert  true  start  _test  non  transient  with  coord  action  update  workflow  action  bean  teststartnontransientwithcoordactionupdate  start.non-transient  asserttrue  start  _testnontransientwithcoordactionupdate  workflowactionbean
__label__nflaky fails  if  identifier  doesnt  match  proxy  provider  millis  to  sleep  set  identifier  sleep  at  least  ignore  interrupts  impl2  start  run  assert  equals  impl1  retry  proxy  result  type  of  exception  to  fail  with  test  failover  between  multiple  standbys  retry  policies  unreliable  create  failover  on  network  exception  thread  util  renamed-impl1  failsifidentifierdoesntmatch  proxyprovider  millistosleep  setidentifier  sleepatleastignoreinterrupts  impl2  start  run  assertequals  impl1  retryproxy  result  typeofexceptiontofailwith  testfailoverbetweenmultiplestandbys  retrypolicies  unreliable  create  failoveronnetworkexception  threadutil  renamed-impl1
__label__flaky conn  set  request  method  is_  security_  enabled  assert  true  json  content-type  /v1/admin/*  collections  run  test  rest  constants  java.version  open  connection  contains  key  http  servlet  response  assert  equals  parse  get  input  stream  url  json  value  call  get  header  field  test  java  sys  props  get  get  response  code  create  url  starts  with  conn  setrequestmethod  is_security_enabled  asserttrue  json  content-type  /v1/admin/*  collections  runtest  restconstants  java.version  openconnection  containskey  httpservletresponse  assertequals  parse  getinputstream  url  jsonvalue  call  getheaderfield  testjavasysprops  get  getresponsecode  createurl  startswith
__label__nflaky 00  reader  first_  key  less  than  first  key  in  the  mapfile   that  the  first  key  is  returned.  cleanup  with  logger  test  get  closest  on  current  api  get  closest  if  we  were  looking  for  the  key  before   we  should  get  the  last  key  91  92  51  close  value  key  test_  prefix  55  log  create  reader  test  get  closest  on  current  api.mapfile  assert  equals  assert  that  null  is  returned  if  key  is  >  last  entry  in  mapfile.  integer  parse  int  io  utils  create  writer  assert  null  t  test  keys:  11 21 31 ... 91  test  get  closest  with  step  forward  not  null  key  in  test  get  closest  with  new  code  test  get  closest  when  we  pass  explicit  key  explicit  key  to  string  writer  61  test  get  closest  with  step  back  append  closest  21  00  reader  first_key   less than first key in the mapfile  that the first key is returned.  cleanupwithlogger  testgetclosestoncurrentapi  getclosest   if we were looking for the key before  we should get the last key  91  92  51  close  value  key  test_prefix  55  log  createreader  testgetclosestoncurrentapi.mapfile  assertequals   assert that null is returned if key is > last entry in mapfile.  integer  parseint  ioutils  createwriter  assertnull  t   test keys: 11 21 31 ... 91   test get closest with step forward  not null key in testgetclosestwithnewcode   test get closest when we pass explicit key  explicitkey  tostring  writer  61   test get closest with step back  append  closest  21
__label__flaky set  classes  to  be  excluded  set  the  pause  time  explicity  to  make  sure  the  job  is  not  unpaused  assert  false  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  is  pending  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  set  pause  time  test  coord  status  transit  service  paused  with  error  assert  not  null  get  coordinator  action  end  current  date  plus  month  wait  for  create  coord  job  init  get  conf  coord  insert  cmd  false  start  2009-02-01  t01:00  z  destroy  assert  equals  services  x  data  test  case  execute  services  coordinator  job  job  id  runnable  coord-action-get.xml  excluded  services  set  system  property  status  transit  service  job  jpa  service  evaluate  setclassestobeexcluded   set the pause time explicity to make sure the job is not unpaused  assertfalse  getcurrentdateafterincrementinginmonths  getid  run  dateutils  ispending  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  setpausetime  testcoordstatustransitservicepausedwitherror  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  waitfor  createcoordjob  init  getconf  coordinsertcmd  false  start  2009-02-01t01:00z  destroy  assertequals  services  xdatatestcase  execute  services  coordinatorjob  jobid  runnable  coord-action-get.xml  excludedservices  setsystemproperty  statustransitservice  job  jpaservice  evaluate
__label__nflaky date  a  get  cipher  add  version  description  get  description  put  second  my  cipher  assert  true  get  versions  get  bit  length  metadata  with  description  2013/12/25  test  metadata  a  get  attributes  format  is  empty  metadata  without  description  get  created  assert  equals  parse  y/m/d  serialize  assert  null  meta  attributes  new  version  date  a  getcipher  addversion  description  getdescription  put  second  mycipher  asserttrue  getversions  getbitlength   metadata with description  2013/12/25  testmetadata  a  getattributes  format  isempty   metadata without description  getcreated  assertequals  parse  y/m/d  serialize  assertnull  meta  attributes  newversion
__label__flaky task  event  type  values  1000  conf  staging  dir  timeout  get  attempts  job  has  only  1  mapper  task.  no  reducers  times  create  running  stubbed  job  committer  fail_  abort  state  await  verify  dispatcher  test  fail  abort  doesnt  hang  init  set  commit  handler  job  state  internal  start  get  id  handle  assert  job  state  ta  any  set  int  task  t  stop  mockito  abort  job  mock  mr  job  config  create  committer  event  handler  job  verify  abort  job  is  called  once  and  the  job  failed  taskeventtype  values  1000  conf  stagingdir  timeout  getattempts   job has only 1 mapper task. no reducers  times  createrunningstubbedjob  committer   fail_abort state  await  verify  dispatcher  testfailabortdoesnthang  init  set  commithandler  jobstateinternal  start  getid  handle  assertjobstate  ta  any  setint  task  t  stop  mockito  abortjob  mock  mrjobconfig  createcommittereventhandler  job   verify abortjob is called once and the job failed
__label__nflaky my  file  incorrect  filesystem  is  passed  testlfs:/  list  status  run  recent  checkpoint  incorrectfs:/  file  system  -expunge  trash  root  add  file  system  for  testing  mkdir  test_  dir  expunge  immediate  should  return  exit  code  1  when  assert  not  equals  testlfsshell  old  checkpoint  should  be  removed  val  fs_  trash_  interval_  key  set  uri  format  incorrect  file  system  scheme  fs_  trash_  interval_  default  yy  m  mdd  h  hmm  set  long  is  enabled  test/mkdirs/test  file  -fs  current  get  uri  my  path  fs.default  fs  expunge  immediate  with  filesystem  should  return  zero  assert  false  remove  file  system  for  testing  -immediate  time  fs.testlfs.impl  testlfs  assert  true  get  current  trash  dir  10  minute  now  checkpoint  format  testlfs  uri  trash  interval  write  file  test  expunge  with  file  system  get  parent  set  set  class  assert  equals  ensure  trash  folder  is  empty  expunge  immediate  should  fail  when  filesystem  is  null  set  conf  recent  checkpoint  should  be  removed  get  long  args  incorrect  fs  current  folder  should  be  removed  current  folder  test/mkdirs  exists  to  string  initialize  empty  file  system  scheme  config  old  checkpoint    myfile  incorrect filesystem is passed  testlfs:/  liststatus  run  recentcheckpoint  incorrectfs:/  filesystem  -expunge  trashroot  addfilesystemfortesting  mkdir  test_dir  expunge immediate should return exit code 1 when   assertnotequals  testlfsshell  old checkpoint should be removed  val  fs_trash_interval_key  seturi  format   incorrect filesystem scheme  fs_trash_interval_default  yymmddhhmm  setlong  isenabled  test/mkdirs/testfile  -fs  current  geturi  mypath  fs.defaultfs  expunge immediate with filesystem should return zero  assertfalse  removefilesystemfortesting  -immediate  time  fs.testlfs.impl  testlfs  asserttrue  getcurrenttrashdir   10 minute  now  checkpointformat  testlfsuri  trashinterval  writefile  testexpungewithfilesystem  getparent  set  setclass  assertequals  ensure trash folder is empty  expunge immediate should fail when filesystem is null  setconf  recent checkpoint should be removed  getlong  args  incorrectfs  current folder should be removed  currentfolder  test/mkdirs  exists  tostring  initialize   empty filesystem scheme  config  oldcheckpoint
__label__flaky play  server  abc  clear  headers  timeout  read  timeouts  to  keep  the  server  alive  client  connection  content-  length:  4  add  header  read  try  to  read  more  bytes  than  are  sent   which  results  in  a  timeout.  in  if  content-  length  was  accurate   this  would  return  -1  immediately  assert  equals  set  body  get  input  stream  /  enqueue  get  url  set  read  timeout  fail  unused  open  play  server  abc  clearheaders  timeout  readtimeouts   to keep the server alive  client  connection  content-length: 4  addheader  read   try to read more bytes than are sent  which results in a timeout.  in   if content-length was accurate  this would return -1 immediately  assertequals  setbody  getinputstream  /  enqueue  geturl  setreadtimeout  fail  unused  open
__label__nflaky test  that  the  add  children  method  is  called  verify  no  more  interactions  test  unchecked  add  children  mock  verify  expr  expressions   test that the addchildren method is called  verifynomoreinteractions  test  unchecked  addchildren  mock  verify  expr  expressions
__label__flaky get  class  end  date  reader  job  should  be  purged.  should  fail.  conf  run  get  status  get  job  get  test  group  dex  get  test  case  dir  /workflow.xml  file://  workflow.xml  wait  for  wf  job  get  cmd  external-status  test  purge  service  for  workflow  execute  oozie  client  job  id  fail  ex  copy  char  stream  get  resource  as  reader  file  evaluate  submit  job  system  sleep  wf  bean  engine  set  strings  get  error  code  get  purge  runnable  ok  workflow  job  a  set  wf-ext-schema-valid.xml  assert  equals  call  services  io  utils  get  test  user  t  signal-value  u  based_on_action_status  current  time  millis  set  end  time  wf  update  cmd  writer  error  code  jpa  service  getclass  enddate  reader  job should be purged. should fail.  conf  run  getstatus  getjob  gettestgroup  dex  gettestcasedir  /workflow.xml  file://  workflow.xml  waitfor  wfjobgetcmd  external-status  testpurgeserviceforworkflow  execute  oozieclient  jobid  fail  ex  copycharstream  getresourceasreader  file  evaluate  submitjob  system  sleep  wfbean  engine  setstrings  geterrorcode  get  purgerunnable  ok  workflowjob  a  set  wf-ext-schema-valid.xml  assertequals  call  services  ioutils  gettestuser  t  signal-value  u  based_on_action_status  currenttimemillis  setendtime  wfupdatecmd  writer  errorcode  jpaservice
__label__nflaky create  g  set  test  put  with  a  null  element  data  test  remove  while  iterating  put  remove  okay  because  data0  is  not  in  gset  assert  test  putting  an  element  which  is  not  implementing  linked  element  good:  getting  get  test  get  with  a  null  element  info  test  contains  light  weight  g  set  resizable  e  test  iterator  test  put  new  element  while  iterating  gset  exception  because  data1  is  in  gset  test  exception  cases  fail  contains  test  put  existing  element  while  iterating  test  get  test  contains  with  a  null  element  v  test  put  creategset   test put with a null element  data   test remove while iterating  put  remove   okay because data0 is not in gset  assert   test putting an element which is not implementing linkedelement  good: getting   get   test get with a null element  info   test contains  lightweightgset  resizable  e   test iterator   test put new element while iterating  gset   exception because data1 is in gset  testexceptioncases  fail  contains   test put existing element while iterating   test get   test contains with a null element  v   test put
__label__flaky def  add  node  expected  to  catch  an  exception  but  did  not  encounter  any  three  two  get  cause  as  list  we  invoke  fork  join  get  error  code  assert  true  dummy  conf  end  f  one  get  message  j  assert  equals  k  kill  make  sure  the  message  contains  the  node  involved  in  the  invalid  transition  fail  contains  ex  parser  test  transition  failure1  name  f->(2 3)  2->ok->3  2->fail->j  3->ok->j  3->fail->k  j->k  error  code  arrays  def  addnode  expected to catch an exception but did not encounter any  three  two  getcause  aslist  we  invokeforkjoin  geterrorcode  asserttrue  dummyconf  end  f  one  getmessage  j  assertequals  k  kill   make sure the message contains the node involved in the invalid transition  fail  contains  ex  parser  testtransitionfailure1  name         f->(2 3)       2->ok->3       2->fail->j       3->ok->j       3->fail->k       j->k        errorcode  arrays
__label__nflaky _mkdirs  default  perm  test  mkdirs_dir  exists  _mkdirs  defaultperm  testmkdirs_direxists
__label__flaky test  decision  action  executor  exception  <case  to=\'a\'>true</case>  <case  to=\'b\'>true</case>  get  status  <case  to=\'a\'>false</case>  get  error  code  <case  to=\'c\'>false</case>  get  action  end  init  <default  to=\'d\'/></switch>  a  b  decision  d  <switch  xmlns=\'uri:oozie:workflow:0.1\'>  start  destroy  assert  equals  <case  to=\'b\'>false</case>  <wrong>  get  external  status  set  conf  services  fail  ex  get  type  workflow  action  decision  action  executor  get  error  type  testdecision  actionexecutorexception  <case to=\'a\'>true</case>  <case to=\'b\'>true</case>  getstatus  <case to=\'a\'>false</case>  geterrorcode  <case to=\'c\'>false</case>  get  action  end  init  <default to=\'d\'/></switch>  a  b  decision  d  <switch xmlns=\'uri:oozie:workflow:0.1\'>  start  destroy  assertequals  <case to=\'b\'>false</case>  <wrong>  getexternalstatus  setconf  services  fail  ex  gettype  workflowaction  decisionactionexecutor  geterrortype
__label__nflaky add  with  filter  instance  test  num  insertions  assert  false  with  test  cases  hash  bloom  filter  test  strategy  hash  id  delete  filter  hash  function  number  counting  bloom  filter.approximate  count  error  immutable  set  assert  true  bit  size  of  membership  test  test  counting  bloom  filter  bloom  filter  common  tester  key  counting  bloom  filter.membership  error  approximate  count  add  withfilterinstance  test  numinsertions  assertfalse  withtestcases  hash  bloomfilterteststrategy  hashid  delete  filter  hashfunctionnumber  countingbloomfilter.approximatecount error  immutableset  asserttrue  bitsize  of  membershiptest  testcountingbloomfilter  bloomfiltercommontester  key  countingbloomfilter.membership error   approximatecount
__label__flaky cluster  /foo  write  2  files  at  the  same  time  read  in  conf  assert  equals  get  file  system  fs  out  p  /bar  build  dfs_  datanode_  synconclose_  key  create  test  file  creation  sync  on  close  write  close  shutdown  open  verify  set  boolean  cluster  /foo   write 2 files at the same time  read  in  conf  assertequals  getfilesystem  fs  out  p  /bar  build  dfs_datanode_synconclose_key  create  testfilecreationsynconclose  write  close  shutdown  open   verify  setboolean
__label__nflaky msg  conn  http  exception  utils  get  response  message  when  put  get  bytes  get  error  stream  http  url  connection  assert  assert  true  json  foo  exception  test  validate  response  json  error  unknown  exception  validate  response  then  return  get  message  is  json  mapper  fail  contains  ex  ex  mockito  response  get  response  code  mock  foo.  foo  exception  write  value  as  string  msg  conn  httpexceptionutils  getresponsemessage  when  put  getbytes  geterrorstream  httpurlconnection  assert  asserttrue  json  fooexception  testvalidateresponsejsonerrorunknownexception  validateresponse  thenreturn  getmessage  is  jsonmapper  fail  contains  ex  ex  mockito  response  getresponsecode  mock  foo.fooexception  writevalueasstring
__label__flaky reader  conf  run  get  status  get  job  assert  not  null  get  test  case  dir  /workflow.xml  file://  action  workflow.xml  wait  for  actions2  bean  action  check  runnable  running-mode  external-status  test  execute  oozie  client  job  id  get  type  copy  char  stream  get  resource  as  reader  file  evaluate  actions  submit  job  workflow  action  bean  sleep  actions  get  executor  engine  get  ok  workflow  job  a  set  workflow  app  service  wf-ext-schema-valid.xml  assert  equals  async  services  io  utils  get  test  user  t  signal-value  based_on_action_status  equals  writer  test  action  checker  service  action2  jpa  service  reader  conf  run  getstatus  getjob  assertnotnull  gettestcasedir  /workflow.xml  file://  action  workflow.xml  waitfor  actions2  bean  actioncheckrunnable  running-mode  external-status  test  execute  oozieclient  jobid  gettype  copycharstream  getresourceasreader  file  evaluate  actions  submitjob  workflowactionbean  sleep  actionsgetexecutor  engine  get  ok  workflowjob  a  set  workflowappservice  wf-ext-schema-valid.xml  assertequals  async  services  ioutils  gettestuser  t  signal-value  based_on_action_status  equals  writer  testactioncheckerservice  action2  jpaservice
__label__nflaky test  factory  for  hours  time  unit  test  factory  testfactoryforhours  timeunit  testfactory
__label__flaky file  name  file  path  *  this  test  creates  a  file  with  one  block  replica.  corrupt  the  block.  make  *  dfs  client  read  the  corrupted  file.  corrupted  block  is  expected  to  be  *  reported  to  name  node.  verify  fsck  block  corrupted  expected  replica  count  dfs  client  read  file  from  position  dfs  client  read  file  /tmp/test  client  report  bad  block/  one  block  replica  verify  first  block  corrupted  create  a  file  with  corrupted  block  replicas  create  a  file  verify  corrupted  block  count  test  one  block  replica  repl  test  fsck  list  corrupt  files  blocks  corrupt  block  number  corrupted.  filename  filepath       * this test creates a file with one block replica. corrupt the block. make     * dfsclient read the corrupted file. corrupted block is expected to be     * reported to name node.       verifyfsckblockcorrupted  expectedreplicacount  dfsclientreadfilefromposition  dfsclientreadfile  /tmp/testclientreportbadblock/oneblockreplica  verifyfirstblockcorrupted  createafilewithcorruptedblockreplicas   create a file  verifycorruptedblockcount  testoneblockreplica  repl  testfscklistcorruptfilesblocks  corruptblocknumber   corrupted.
__label__nflaky fail  test5  byte  utf8  sequence  utf8  invalid  generic  test  utils  assert  exception  contains  from  bytes  did  not  throw  an  exception  invalid  utf8  at  f88880808004  utfde  fail  test5byteutf8sequence  utf8  invalid  generictestutils  assertexceptioncontains  frombytes  did not throw an exception  invalid utf8 at f88880808004  utfde
__label__flaky start  server  produce  consume  topics  get  name  other  id  config  utils  put  assert  array  equals  features  iterator  get  first  test  als  speed  up  id  known  users  items  expected  oryx.speed.streaming.block-interval-sec  unchecked  mock  als  model  update  generator  oryx.als.hyperparams.features  size  overlay  on  is  debug  enabled  get  extension  value  build  matrix  next  *  user  100  -  104  are  solutions  to  eye(5)*  y*pinv(  y\'*  y)   but  default  scaling  *  will  produce  values  that  are  3/4  of  this  since  they  are  brand  new.  *  that  is   it\'s  really  the  solution  to  (0.75*eye(5))*  y*pinv(  y\'*  y)  *  likewise  105  -  108  are  (0.75*eye(4))*  x*pinv(  x\'*  x)  pmml  utils  log  update  updates  start  messaging  convert  value  10  original  updates.  9  generate  just  1  update  since  user  or  item  is  new.  expected  known  users  items  assert  true  get  x  y  mapper  read  value  {}  debug  contains  all  app  pmml  utils  assert  equals  model  get  config  is  x  integer  parse  int  oryx.speed.streaming.generation-interval-sec  equals  get  second  overlay  config  to  string  from  string  oryx.speed.model-manager-class  config  startserverproduceconsumetopics  getname  otherid  configutils  put  assertarrayequals  features  iterator  getfirst  testalsspeed  up  id  knownusersitems  expected  oryx.speed.streaming.block-interval-sec  unchecked  mockalsmodelupdategenerator  oryx.als.hyperparams.features  size  overlayon  isdebugenabled  getextensionvalue  buildmatrix  next         * user 100 - 104 are solutions to eye(5)*y*pinv(y\'*y)  but default scaling       * will produce values that are 3/4 of this since they are brand new.       * that is  it\'s really the solution to (0.75*eye(5))*y*pinv(y\'*y)       * likewise 105 - 108 are (0.75*eye(4))*x*pinv(x\'*x)         pmmlutils  log  update  updates  startmessaging  convertvalue   10 original updates. 9 generate just 1 update since user or item is new.  expectedknownusersitems  asserttrue  get  x  y  mapper  readvalue  {}  debug  containsall  apppmmlutils  assertequals  model  getconfig  isx  integer  parseint  oryx.speed.streaming.generation-interval-sec  equals  getsecond  overlayconfig  tostring  fromstring  oryx.speed.model-manager-class  config
__label__nflaky get  a  token  in  check  equal  source  token  out  read  fields  set  service  read  the  token  back  dest  token  assert  true  service  write  it  to  an  output  buffer  get  length  reset  test  token  serialization  write  get  data   get a token  in  checkequal  sourcetoken  out  readfields  setservice   read the token back  desttoken  asserttrue  service   write it to an output buffer  getlength  reset  testtokenserialization  write  getdata
__label__flaky workflow  auth  token  get  log  token  assert  equals  set  log  token  workflow.set  workflow  instance(new  my  workflow  instance());  get  proto  action  conf  proto  assert  not  null(workflow.get  workflow  instance());  set  auth  token  get  auth  token  log  token  set  proto  action  conf  test  workflow  workflow  authtoken  getlogtoken  assertequals  setlogtoken   workflow.setworkflowinstance(new myworkflowinstance());  getprotoactionconf  proto   assertnotnull(workflow.getworkflowinstance());  setauthtoken  getauthtoken  logtoken  setprotoactionconf  testworkflow
__label__nflaky verify  paths  test  partial  authority  myfs://host.a  fs  ips  authorities  myfs://host.a.b:123  get  verified  fs  verifypaths  testpartialauthority  myfs://host.a  fs  ips  authorities  myfs://host.a.b:123  getverifiedfs
__label__flaky get  current  block  pool  id  cluster  dfs.datanode.scan.period.hours  test  cases  log  bpid  assert  false  current_  should_  exist_  after_  recover  prev  after  recover  check  result  block  pool  conf  create  name  node  storage  state  previous_  should_  exist_  after_  recover  get  num  dirs  should_  recover  startup  option  previous_  tmp_  exists  cur  after  recover  start  data  nodes  get  data  nodes  should  recover  current_  exists  first  setup  the  datanode  storage  directory  test  block  pool  storage  states  initialize  storage  state  conf  data  node  will  create  and  format  current  if  no  directories  exist  base  dirs  is  bp  service  alive  removed_  tmp_  exists  set  int  create  block  pool  storage  state  upgrade  utilities  previous_  exists  block_  pool  recovery  create  cluster  shutdown  num_  dn_  test_  cases  test  case  getcurrentblockpoolid  cluster  dfs.datanode.scan.period.hours  testcases  log  bpid  assertfalse  current_should_exist_after_recover  prevafterrecover  checkresultblockpool  conf  createnamenodestoragestate  previous_should_exist_after_recover  get  numdirs  should_recover  startupoption  previous_tmp_exists  curafterrecover  startdatanodes  getdatanodes  shouldrecover  current_exists   first setup the datanode storage directory  testblockpoolstoragestates  initializestoragestateconf   datanode will create and format current if no directories exist  basedirs  isbpservicealive  removed_tmp_exists  setint  createblockpoolstoragestate  upgradeutilities  previous_exists  block_pool recovery  createcluster  shutdown  num_dn_test_cases  testcase
__label__nflaky get  template  for  result  get  with  default  equal  to  invoke  assert  that  eq  any  test  basic  invocation  template  engine  freemarker  get  suffix  of  templating  engine  .ftl.html  route  results  context  verify  template  engine  helper  to  string  writer  ok  ninja  properties  just  a  plain  template  for  testing...  template  engine  freemarker  gettemplateforresult  getwithdefault  equalto  invoke  assertthat  eq  any  testbasicinvocation  templateenginefreemarker  getsuffixoftemplatingengine  .ftl.html  route  results  context  verify  templateenginehelper  tostring  writer  ok  ninjaproperties  just a plain template for testing...  templateenginefreemarker
__label__flaky cluster  parent  but  found  to  be  of  size  get  name  write  to  file  get  remaining  conf  dn  create  file  simulated  storage  path  len  get  file  status  but  found  to  take  create  ie  get  dfs  used  \""  should  take  get  data  nodes  get  fs  dataset  verify  that  file  exists  in  fs  namespace  get  file  system  set  quota  stm  block  size  /  dfs  contains  path  :  \""  /test_dir  file  size  can\'t  check  capacities  for  real  storage  since  the  os  file  system  may  be  changing  under  us.  disk  space  mkdirs  bytes  disk  space  simulated  fs  dataset  shutdown  is  directory  should  be  of  size  /  should  be  a  directory  create  file:  creating  verify  the  disk  space  the  file  occupied  test  file  creation  fs  system  create  path   overwrite=true  assert  true  get  len  get  verify  that  file  size  has  changed  to  the  full  size  close  write  file  get  parent  is  file  filestatus.dat  get  content  summary  get  message  did  not  prevent  directory  from  being  overwritten.  assert  equals  dir1  bytes  build  get  length  to  string  should  be  a  file  for  overwrite  of  existing  directory.  file1  set  boolean  already  exists  as  a  directory.  cluster  parent   but found to be of size   getname   write to file  getremaining  conf  dn  createfile  simulatedstorage  path  len  getfilestatus  but found to take   create  ie  getdfsused     \""   should take   getdatanodes  getfsdataset   verify that file exists in fs namespace  getfilesystem  setquota  stm  blocksize  /  dfs  contains  path : \""  /test_dir  filesize   can\'t check capacities for real storage since the os file system may be changing under us.  diskspace  mkdirs   bytes disk space   simulatedfsdataset  shutdown  isdirectory   should be of size   / should be a directory  createfile: creating    verify the disk space the file occupied  testfilecreation  fs  system   create path  overwrite=true  asserttrue  getlen  get   verify that file size has changed to the full size  close  writefile  getparent  isfile  filestatus.dat  getcontentsummary  getmessage  did not prevent directory from being overwritten.  assertequals  dir1   bytes  build  getlength  tostring   should be a file   for overwrite of existing directory.  file1  setboolean  already exists as a directory.
__label__nflaky conn  read  in  stream  then  return  argument  matchers  set  so  timeout  get  input  stream  when  any  any  int  never  times  bind  assert  mockito  assert  true  ensure  open  test  await  input  in  buffer  verify  await  input  socket  spy  conn  read  instream  thenreturn  argumentmatchers  setsotimeout  getinputstream  when  any  anyint  never  times  bind  assert  mockito  asserttrue  ensureopen  testawaitinputinbuffer  verify  awaitinput  socket  spy
__label__flaky cluster  get  block  locations  name  node  adapter  get  metrics  find  and  mark  block  as  corrupt  bm  ns_  metrics  fs  delete  create  file  file  corrupt  blocks  get  block  assert  gauge  test  corrupt  block  get  block  pending  replication  blocks  scheduled  replication  blocks  create  a  file  with  single  block  with  two  replicas  get  name  node  get  test  path  rb  update  metrics  get  locations  to  string  corrupt  first  replica  of  the  block  cluster  getblocklocations  namenodeadapter  getmetrics  findandmarkblockascorrupt  bm  ns_metrics  fs  delete  createfile  file  corruptblocks  get  block  assertgauge  testcorruptblock  getblock  pendingreplicationblocks  scheduledreplicationblocks   create a file with single block with two replicas  getnamenode  gettestpath  rb  updatemetrics  getlocations  tostring   corrupt first replica of the block
__label__nflaky get  bytes  transferred  payload2  get  metrics  outbuffer  in  buffer  readable  channel  test  read  write  frame  assert  assert  not  null  frame  type  get  frame  consts  get  frames  transferred  write  get  payload  content  read  frame2  get  stream  id  assert  equals  byte  buffer  remaining  get  value  allocate  get  type  bytes  to  byte  array  get  flags  wrap  writable  channel  frame  getbytestransferred  payload2  getmetrics  outbuffer  inbuffer  readablechannel  testreadwriteframe  assert  assertnotnull  frametype  get  frameconsts  getframestransferred  write  getpayloadcontent  read  frame2  getstreamid  assertequals  bytebuffer  remaining  getvalue  allocate  gettype  bytes  tobytearray  getflags  wrap  writablechannel  frame
__label__flaky play  server  request  fail  auth  three  times...  ...then  succeed  the  fourth  time  successful  auth!  client  connection  assert  contains  none  matching  get  /  http/1.1  authenticator  read  ascii  add  header  get  headers  take  request  authorization:  basic  .*  no  authorization  header  for  the  first  request...  assert  equals  authorization:  basic  www-  authenticate:  basic  realm=\""protected  area\""  set  response  code  set  body  set  default  get  input  stream  ...but  the  three  requests  that  follow  requests  include  an  authorization  header  assert  contains  /  integer  authenticate  with  get  enqueue  get  url  get  request  line  please  authenticate.  open  recording  authenticator  please  authenticate  play  server  request   fail auth three times...   ...then succeed the fourth time  successful auth!  client  connection  assertcontainsnonematching  get / http/1.1  authenticator  readascii  addheader  getheaders  takerequest  authorization: basic .*   no authorization header for the first request...  assertequals  authorization: basic   www-authenticate: basic realm=\""protected area\""  setresponsecode  setbody  setdefault  getinputstream   ...but the three requests that follow requests include an authorization header  assertcontains  /  integer  authenticatewithget  enqueue  geturl  getrequestline  please authenticate.  open  recordingauthenticator  pleaseauthenticate
__label__nflaky should  work  with  or  without  sleep  test  empty  blocking  e  log  dequeue  start  assert  equals  run  consume  trigger  try  consuming  emtpy  equeue  and  blocking  thread  interrupted  sleep  q  warn  enqueue  awhile  t  mock  verify  join  element   should work with or without sleep  testemptyblocking  e  log  dequeue  start  assertequals  run  consume  trigger   try consuming emtpy equeue and blocking  thread  interrupted  sleep  q  warn  enqueue  awhile  t  mock  verify  join  element
__label__flaky play  ping  play  it  back  this  ping  will  not  be  returned.  verify  the  peer  received  what  was  expected  assert  equals  accept  frame  send  frame  peer  spdy3  write  the  mocking  script  ping4  unexpected  ping  is  not  returned  ping  connection  ping2  take  frame  play  ping   play it back   this ping will not be returned.   verify the peer received what was expected  assertequals  acceptframe  sendframe  peer  spdy3   write the mocking script  ping4  unexpectedpingisnotreturned   ping  connection  ping2  takeframe
__label__nflaky server  get  current  user  rpc  configure  super  user  ip  addresses  get  proxy  superuser  group  conf  key  group_  names  default  impersonation  provider  get  user  new  empty  request  conf  run  ret  val  test  real  user  group  authorization  failure  assert  set  strings  real_  user_  short_  name  refresh  conf  client  set  protocol  engine  addr  set  configuration  user  group  information  proxy  user  ugi  print  stack  trace  e  group3  get  client  create  remote  user  real_  user_  name  fail  do  as  get  test  provider  stop  setup  test  server  proxy_  user_  name  the  rpc  must  have  failed  real  user  ugi  create  proxy  user  for  testing  server  getcurrentuser  rpc  configuresuperuseripaddresses  getproxysuperusergroupconfkey  group_names  defaultimpersonationprovider  getuser  newemptyrequest  conf  run  retval  testrealusergroupauthorizationfailure  assert  setstrings  real_user_short_name  refreshconf  client  setprotocolengine  addr  setconfiguration  usergroupinformation  proxyuserugi  printstacktrace  e  group3  getclient  createremoteuser  real_user_name  fail  doas  gettestprovider  stop  setuptestserver  proxy_user_name  the rpc must have failed   realuserugi  createproxyuserfortesting
__label__flaky get  job  tracker  uri  map-reduce  test  map  reduce  with  credentials  _test  submit  with  credentials  fs  output  action  xml  <map-reduce>  create  write  close  <job-tracker>  get  name  node  uri  output  dir  </job-tracker>  dummy  get  file  system  input  dir  <name-node>  </name-node>  </map-reduce>  input  get  map  reduce  credentials  config  w  to  xml  string  to  string  data.txt  get  fs  test  case  dir  getjobtrackeruri  map-reduce  testmapreducewithcredentials  _testsubmitwithcredentials  fs  output  actionxml  <map-reduce>  create  write  close  <job-tracker>  getnamenodeuri  outputdir  </job-tracker>  dummy    getfilesystem  inputdir  <name-node>  </name-node>  </map-reduce>  input  getmapreducecredentialsconfig  w  toxmlstring  tostring  data.txt  getfstestcasedir
__label__nflaky channel  out  stream  assert  construct  string  like  hello  and  stuff  flush  russian_  hello  inbuf  tmp  write  line  chbuffer  s1  s2  s3  standard  charsets  new  decoder  swiss_  german_  hello  clear  assert  equals  fill  read  line  outbuf  to  byte  array  new  encoder  to  string  new  channel  test  multibyte  coded  read  write  line  append  out  channel  channel  outstream  assert  constructstring  like hello and stuff  flush  russian_hello  inbuf  tmp  writeline  chbuffer  s1  s2  s3  standardcharsets  newdecoder  swiss_german_hello  clear  assertequals  fill  readline  outbuf  tobytearray  newencoder  tostring  newchannel  testmultibytecodedreadwriteline  append  outchannel
__label__flaky bundle  job  get  executor  c  job1  add  record  to  bundle  action  table  pause  start  runnable  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  get  status  parse  date  oozie  tz  set  pause  time  assert  not  null  get  set  bundle  id  end  current  date  plus  month  job  wait  for  b  job1  bundle  action1  bundle  action2  add  record  to  bundle  job  table  start  assert  equals  test  unpause  bundle  and  coordinator  x  data  test  case  execute  add  record  to  coord  job  table  coord  job2  services  coordinator  job  job  id  coord  job1  coord  job  id1  coord  job  id2  action1  job  action2  jpa  service  evaluate  bundlejobgetexecutor  cjob1  addrecordtobundleactiontable  pausestartrunnable  getcurrentdateafterincrementinginmonths  getid  run  dateutils  getstatus  parsedateoozietz  setpausetime  assertnotnull  get  setbundleid  end  currentdateplusmonth  job  waitfor  bjob1  bundleaction1  bundleaction2  addrecordtobundlejobtable  start  assertequals  testunpausebundleandcoordinator  xdatatestcase  execute  addrecordtocoordjobtable  coordjob2  services  coordinatorjob  jobid  coordjob1  coordjobid1  coordjobid2  action1  job  action2  jpaservice  evaluate
__label__nflaky keys  values  remove  elements  test  basic  operations  the  element  should  not  exist  after  remove  check  all  elements  exist  in  the  set  and  the  data  is  correct  check  the  set  size  put  remove  check  all  elements  exist  in  the  set  and  the  data  is  updated  to  new  value  generate  new  elements  with  same  key   but  new  data  get  is  zero  get  data  new  elements  element  is  not  null  set  generate  elements  c  elements  is  false  get  keys  assert  that  put  all  elements  is  true  contains  size  elements  is  null  update  the  set  is  equal  to  test  light  weight  hash  g  set#values  keys  values   remove elements  testbasicoperations   the element should not exist after remove   check all elements exist in the set and the data is correct   check the set size  put  remove   check all elements exist in the set and the data is updated to new value   generate new elements with same key  but new data  get  iszero  getdata  newelements  element  isnotnull  set  generateelements  celements  isfalse  getkeys  assertthat   put all elements  istrue  contains  size  elements  isnull   update the set  isequalto   test lightweighthashgset#values
__label__flaky cluster  file  name  bpid  get  rbw  dir  conf  dn  windows  fs  wait  replication  delete  system  create  file  wait  active  assert  true  get  os.name  storage  dir  dfs  test  util  get  property  start  data  nodes  get  block  pool  id  mini  dfs  cluster  set  writable  get  data  nodes  restore  its  old  permission  create  files  and  make  sure  that  first  datanode  will  be  down  /test.txt  dir2  dir1  couldn\'t  chmod  local  vol  test  shutdown  dn  index  bring  up  two  more  datanodes  get  instance  storage  dir  set  read  only  make  the  data  directory  of  the  first  datanode  to  be  readonly  starts  with  get  namesystem  is  datanode  up  cluster  filename  bpid  getrbwdir  conf  dn  windows  fs  waitreplication  delete  system  createfile  waitactive  asserttrue  get  os.name  storagedir  dfstestutil  getproperty  startdatanodes  getblockpoolid  minidfscluster  setwritable  getdatanodes   restore its old permission   create files and make sure that first datanode will be down  /test.txt  dir2  dir1  couldn\'t chmod local vol  testshutdown  dnindex   bring up two more datanodes  getinstancestoragedir  setreadonly   make the data directory of the first datanode to be readonly  startswith  getnamesystem  isdatanodeup
__label__nflaky fruit  context  print  simple  configurator  status  printer  implcit_  dir  verify  fruit  do  configure  nested  complex  without  class  atrribute.xml  je  nested  complex  without  class  atrribute  fruitcontext  print  simpleconfigurator  statusprinter  implcit_dir  verifyfruit  doconfigure  nestedcomplexwithoutclassatrribute.xml  je  nestedcomplexwithoutclassatrribute
__label__flaky cluster  /foo  write  2  files  at  the  same  time  read  in  conf  assert  equals  get  file  system  test  concurrent  file  creation  fs  out  p  /bar  build  create  write  close  shutdown  open  verify  cluster  /foo   write 2 files at the same time  read  in  conf  assertequals  getfilesystem  testconcurrentfilecreation  fs  out  p  /bar  build  create  write  close  shutdown  open   verify
__label__nflaky path  response  should  not  be  null  returned  body  server  request  assert  false  body  put  status  request  handler  assert  headers  assert  not  null  get  body  should  be  in  the  response  default  uri  status  unexpected  mybody  localhost  headers  body  should  be  echoed  adapter  with  live  server  echo  start  unchecked  is  empty  assert  equals  method  /echo/*  response  expectations  execute  target  echo_  path  headers  should  be  in  the  response  register  handler  get  port  mockito  initialize  the  server-side  request  handler  response  name  method  mock  to  string  body  path  response should not be null  returnedbody  server  request  assertfalse  body  put  status  requesthandler  assert  headers  assertnotnull  get  body should be in the response  defaulturi  status unexpected  mybody  localhost  headers  body should be echoed  adapter  withliveserverecho  start  unchecked  isempty  assertequals  method  /echo/*  responseexpectations  execute  target  echo_path  headers should be in the response  registerhandler  getport  mockito   initialize the server-side request handler  response  name  method  mock  tostring  body
__label__flaky java.naming.provider.url#tcp://broker.${2}:61616  http://unknown:9999/fs  conf  server2  hcat://server1.colo1.server.com:8020/db/table/pk1=val1;pk2=val2  no  default  jms  mapping  server3  h  cat  accessor  service  test  get  jms  connection  info  no  default  get  get  jndi  properties  string  java.naming.factory.initial#  dummy.  factory;java.naming.provider.url#tcp://broker.colo1:61616  hcat://xyz.corp.dummy.com/db/table  hcat://xyz.corp.dummy.com=java.naming.factory.initial#  dummy.  factory;  init  set  get  jms  connection  info  get  conf  hcat  service  destroy  assert  equals  services  hcat://${1}.${2}.server.com:8020=java.naming.factory.initial#  dummy.  factory;     java.naming.provider.url#tcp:localhost:61616  assert  null  conn  info  java.naming.factory.initial#  dummy.  factory;java.naming.provider.url#tcp:localhost:61616  setup  services  for  h  catalog  jms  connection  url  java.naming.provider.url#tcp://broker.${2}:61616  http://unknown:9999/fs  conf  server2  hcat://server1.colo1.server.com:8020/db/table/pk1=val1;pk2=val2   no default jms mapping  server3  hcataccessorservice  testgetjmsconnectioninfonodefault  get  getjndipropertiesstring  java.naming.factory.initial#dummy.factory;java.naming.provider.url#tcp://broker.colo1:61616  hcat://xyz.corp.dummy.com/db/table  hcat://xyz.corp.dummy.com=java.naming.factory.initial#dummy.factory;  init  set  getjmsconnectioninfo  getconf  hcatservice  destroy  assertequals  services  hcat://${1}.${2}.server.com:8020=java.naming.factory.initial#dummy.factory;     java.naming.provider.url#tcp:localhost:61616  assertnull  conninfo  java.naming.factory.initial#dummy.factory;java.naming.provider.url#tcp:localhost:61616  setupservicesforhcatalog  jmsconnectionurl
__label__nflaky num  inputs  coder  util  inputs  find  first  valid  input  test  no  valid  input  numinputs  coderutil  inputs  findfirstvalidinput  testnovalidinput
__label__flaky end_  points  rest  constants  is_  security_  enabled  get  context  url  oozie  url  test  job  info  mock  dag  engine  service  run  assert  equals  -offset  -info  0  args  call  1  2  -oozie  3  reset  job  servlet_  classes  -len  run  test  end_points  restconstants  is_security_enabled  getcontexturl  oozieurl  testjobinfo  mockdagengineservice  run  assertequals  -offset  -info  0  args  call  1  2  -oozie  3  reset  job  servlet_classes  -len  runtest
__label__nflaky expected  ioe  disconnect  the  open  connection  checks  above  ensure  correct  behavior.  fuzz  the  client.  keepalive  unwrap  remote  exception  testing123  get  internal  state  conf  get  cause  the  connection  closing.  test  disconnect  request  rpc  status  proto  last  conn  info  set  queue  size  per  handler  request  test  reader  exceptions  log  rse  error  auth  metric  will  disconnect=  verify  whether  the  connection  should  have  been  reused.  expected  auths  proxy  fail  re  rse  fatal  stop  get  connections  get  rpc  status  proto  get  rpc  metrics  server  new  server  builder  should  connect=  ping  new  empty  request  if  it  wasn\'t  fatal   verify  there\'s  only  one  open  connection.  is  disconnected  correctly.  current  should  close  assert  true  builder  thread  local  random  rpc  authorization  successes  addr    value  conns  set  num  handlers    e  fake  request  class  assert  equals  get  client  next  int  set  verbose  assert  same  whitebox  r  req  name  serial  assert  not  same  rpc  request  class  do  disconnect  setup  test  server  didn\'t  fail  set  internal  state  expectedioe  disconnect   the open connection checks above ensure correct behavior.   fuzz the client.  keepalive  unwrapremoteexception  testing123  getinternalstate  conf  getcause   the connection closing.  testdisconnect request  rpcstatusproto  lastconn  info  setqueuesizeperhandler  request  testreaderexceptions  log  rseerror  authmetric   willdisconnect=   verify whether the connection should have been reused.  expectedauths  proxy  fail  re  rsefatal  stop  getconnections  getrpcstatusproto  getrpcmetrics  server  newserverbuilder   shouldconnect=  ping  newemptyrequest   if it wasn\'t fatal  verify there\'s only one open connection.  isdisconnected   correctly.  current  shouldclose  asserttrue  builder  threadlocalrandom  rpcauthorizationsuccesses  addr    value  conns  setnumhandlers     e  fakerequestclass  assertequals  getclient  nextint  setverbose  assertsame  whitebox  r  reqname  serial  assertnotsame  rpcrequestclass  dodisconnect  setuptestserver   didn\'t fail  setinternalstate
__label__flaky reader  conf  coord-dataset-initial-instance.xml  get  status  app  path  get  job  earlier  than  the  default  initial  instance  sc  get  error  code  file://  get  test  case  dir  unit_  testing  get  path  job  coordinator.xml  set  unexpected  failure  -  get  message  assert  equals  call  oozie  client  fail  test  submit  dataset  initial  instance  io  utils  contains  expected  to  catch  errors  due  to  invalid  dataset  initial  instance  get  test  user  cx  copy  char  stream  get  resource  as  reader  writer  error  code  file  reader  conf  coord-dataset-initial-instance.xml  getstatus  apppath  getjob  earlier than the default initial instance  sc  geterrorcode  file://  gettestcasedir  unit_testing  getpath  job  coordinator.xml  set  unexpected failure -   getmessage  assertequals  call  oozieclient  fail  testsubmitdatasetinitialinstance  ioutils  contains  expected to catch errors due to invalid dataset initial instance  gettestuser  cx  copycharstream  getresourceasreader  writer  errorcode  file
__label__nflaky de  en-  us  ninja  constant  language  when  get  cookie  test  get  all  with  context  and  result  result  assert  true  of  get  deutsch  context  english  builder  lang  ok  map  key  set  a_property_only_in_the_default  language  cookie  torÃ¶Ã¶Ã¶Ã¶  -  das  ist  der  platzhalter:  {0}  get  all  optional  message_with_placeholder  then  return  contains  key  any  string  en  a_propert_with_commas  assert  equals  reset  result  and  set  context  cookie:  size  results  build  mockito  name  messages  get  string  array  fr-  fr  ninja  properties  get  accept  language  german  locale  testing:  us  locale  testing:  set  language  de  en-us  ninjaconstant  language  when  getcookie  testgetallwithcontextandresult  result  asserttrue  of  get  deutsch  context  english  builder  lang  ok  map  keyset  a_property_only_in_the_defaultlanguage  cookie  torÃ¶Ã¶Ã¶Ã¶ - das ist der platzhalter: {0}  getall  optional  message_with_placeholder  thenreturn  containskey  anystring  en  a_propert_with_commas  assertequals   reset result and set context cookie:  size  results  build  mockito  name  messages  getstringarray  fr-fr  ninjaproperties  getacceptlanguage   german locale testing:   us locale testing:  setlanguage
__label__flaky coord-rerun-action2.xml  ::  2009-12-15  t01:00  z  2009-12-16  t01:00  z  get  id  coord  utils  assert  equals  get  coord  actions  from  dates  test  retrieval  of  action  corresponding  to  range  of  dates  (date1::date2);  add  record  to  coord  action  table  add  record  to  coord  job  table  coordinator  job  job  id  test  get  coord  actions  from  date  range  rerun  scope  coord  actions  size  coordinator  action  action  num2  job  coord-rerun-action1.xml  action  num1  coord-rerun-action2.xml  ::  2009-12-15t01:00z  2009-12-16t01:00z  getid  coordutils  assertequals  getcoordactionsfromdates   test retrieval of action corresponding to range of dates (date1::date2);  addrecordtocoordactiontable  addrecordtocoordjobtable  coordinatorjob  jobid  testgetcoordactionsfromdaterange  rerunscope  coordactions  size  coordinatoraction  actionnum2  job  coord-rerun-action1.xml  actionnum1
__label__nflaky then  return  eq  fs  when  delete  path  test  delete  on  exit  /a  delete  on  close  if  path  does  exist  assert  true  get  file  status  mock  verify  reset  mock  fs  close  delete  on  exit  thenreturn  eq  fs  when  delete  path  testdeleteonexit  /a   delete on close if path does exist  asserttrue  getfilestatus  mock  verify  reset  mockfs  close  deleteonexit
__label__flaky close  trx  coord  client  get  store  local  oozie  could  not  update  db.  get  status  test  coord  rerun  cleanup  get  coord  client  begin  trx  coordinator  action  create  commit  trx  wait  for  bean  action  num  print  stack  trace  store2  get  file  system  job  id  fail  coordinator  job  after  cleanup  _  success  add  record  to  action  table  success  mkdirs  action  id  /coord-input/2009/12/14/11/00  evaluate  get  coordinator  action  @  before  cleanup  get  time  assert  false  app  path  fs  -test  coord  rerun-  c  coord  assert  true  get  re  run  coord  output  dir  rest  constants  e  store  add  record  to  job  table  integer  services  get  coord  action  info  assert  not  same  exists  0000000-  to  string  action2  coord-rerun-action1.xml  get  fs  test  case  dir  closetrx  coordclient  getstore  localoozie  could not update db.  getstatus  testcoordreruncleanup  getcoordclient  begintrx  coordinatoraction  create  committrx  waitfor  bean  actionnum  printstacktrace  store2  getfilesystem  jobid  fail  coordinatorjob   after cleanup  _success  addrecordtoactiontable  success  mkdirs  actionid  /coord-input/2009/12/14/11/00  evaluate  getcoordinatoraction  @   before cleanup  gettime  assertfalse  apppath  fs  -testcoordrerun-c  coord  asserttrue  get  reruncoord  outputdir  restconstants  e  store  addrecordtojobtable  integer  services  getcoordactioninfo  assertnotsame  exists  0000000-  tostring  action2  coord-rerun-action1.xml  getfstestcasedir
__label__nflaky test  expression  not  empty  blank2  not  blank  asserts  stuff    testexpressionnotemptyblank2  notblank  asserts  stuff
__label__flaky server  proxy  users  test  protocol  rpc  configure  super  user  ip  addresses  get  proxy  superuser  group  conf  key  get  proxy  a  method  group_  names  via  conf  run  test  real  user  authorization  success  ret  val  assert  set  strings  real_  user_  short_  name  refresh  conf  stop  proxy  addr  user  group  information  get  server  ret  proxy  user  ugi  print  stack  trace  e  start  assert  equals  create  remote  user  group1  get  connect  address  real_  user_  name  fail  proxy  do  as  net  utils  stop  address  proxy_  user_  name  real  user  ugi  create  proxy  user  for  testing  server  proxyusers  testprotocol  rpc  configuresuperuseripaddresses  getproxysuperusergroupconfkey  getproxy  amethod  group_names   via   conf  run  testrealuserauthorizationsuccess  retval  assert  setstrings  real_user_short_name  refreshconf  stopproxy  addr  usergroupinformation  getserver  ret  proxyuserugi  printstacktrace  e  start  assertequals  createremoteuser  group1  getconnectaddress  real_user_name  fail  proxy  doas  netutils  stop  address  proxy_user_name  realuserugi  createproxyuserfortesting
__label__nflaky owner  big  buf  test  overlong  dtid  serialization  real  user  renewer  assert  false  test  delegation  token  identifer  serialization  round  trip  text  owner  bigbuf  testoverlongdtidserialization  realuser  renewer  assertfalse  testdelegationtokenidentiferserializationroundtrip  text
__label__flaky get  counters  a  1  get  value  2  b  size  incr  test  instrumentation  counter  inst  get  assert  equals  getcounters  a  1  getvalue  2  b  size  incr  testinstrumentationcounter  inst  get  assertequals
__label__nflaky add  token  get  cached  fs  foo  unchecked  ugi  a2  conf  create  remote  user  assert  same  fs  a1  bar  and  so  are  different.  file  system.  fs  b  fs  a  new  conf  assert  not  same  mock  since  the  ug  is  are  the  same   we  should  have  the  same  filesystem  for  both  corresponding  to  the  two  ug  is  ugi  a  ugi  b  t1  user  group  information  test  cache  for  ugi  addtoken  getcachedfs  foo  unchecked  ugia2  conf  createremoteuser  assertsame  fsa1  bar   and so are different.   file system.  fsb  fsa  newconf  assertnotsame  mock   since the ugis are the same  we should have the same filesystem for both   corresponding to the two ugis  ugia  ugib  t1  usergroupinformation  testcacheforugi
__label__flaky 2009-12-15  t01:00  z  2009-12-16  t01:00  z  get  id  date  utils  get  status  get  external  id  add  record  to  coord  action  table  myapp  parse  date  oozie  tz  test  action  start  with  escape  strings  coord  job  is  :  assert  true  assert  not  null  get  coordinator  action  action  end  expected  to  be  not  submitted  (i.e.  running)  wait  for  wf  action  coord-action-start-escape-strings.xml  start  undef  myjob  wf  action  id  execute  add  record  to  coord  job  table  wf  actions  call  coord  action  start  command  didn\'t  work  because  the  status  for  action  id  coordinator  job  services  fail  get  test  user  size  action  id  jpa  service  wf  id  evaluate  2009-12-15t01:00z  2009-12-16t01:00z  getid  dateutils  getstatus  getexternalid  addrecordtocoordactiontable  myapp  parsedateoozietz  testactionstartwithescapestrings  coordjob   is :  asserttrue  assertnotnull  get  coordinatoraction  action  end   expected to be not submitted (i.e. running)  waitfor  wfaction  coord-action-start-escape-strings.xml  start  undef  myjob  wfactionid  execute  addrecordtocoordjobtable  wfactions  call  coordactionstartcommand didn\'t work because the status for action id  coordinatorjob  services  fail  gettestuser  size  actionid  jpaservice  wfid  evaluate
__label__nflaky get  subject  get  current  user  get  name  create  a  new  ugi  instance  based  on  subject  from  the  logged  in  user.  keytab  run  authentication  method  when  logout  barrier  relogin  executor  second  relogin  didn\'t  block!  ugi  relogin  from  keytab  get  path  time  unit  another  concurrent  re-login  should  block.  get  user  name  user  group  information  create  a  keytab  ugi.  get  ugi  from  subject  current  thread  credentials  corruption   but  getting  a  ugi  for  the  subject  does  not  block.  is  blocked.  kdc  login  user  from  keytab  and  return  ugi  fail  invocation  do  as  spy  login  is  security  enabled  create  principal  relogin.  spy  set  name  are  atomic.  do  nothing  submit  get  user  assert  false  user1.keytab  cloned  ugi  login  principal  do  answer  assert  true  get  await  knows  from  its  login  params  that  it  is  supposed  to  be  from  a  keytab.  latch  test  user  work  dir  count  down  know  it\'s  supposed  to  be  from  a  keytab.  call  real  method  cloned  relogin  test  concurrent  relogin  assert  equals  is  done  first  relogin  didn\'t  block  thread  get  login  call  answer  mockito  set  login  get  authentication  method  user  login  ugi  is  from  keytab  getsubject  getcurrentuser  getname   create a new ugi instance based on subject from the logged in user.  keytab  run  authenticationmethod  when  logout  barrier  relogin  executor  second relogin didn\'t block!  ugi  reloginfromkeytab  getpath  timeunit   another concurrent re-login should block.  getusername  usergroupinformation   create a keytab ugi.  getugifromsubject  currentthread   credentials corruption  but getting a ugi for the subject does not block.   is blocked.  kdc  loginuserfromkeytabandreturnugi  fail  invocation  doas  spylogin  issecurityenabled  createprincipal   relogin.  spy  setname   are atomic.  donothing  submit  getuser  assertfalse  user1.keytab  clonedugi  login  principal  doanswer  asserttrue  get  await   knows from its login params that it is supposed to be from a keytab.  latch  testuser  workdir  countdown   know it\'s supposed to be from a keytab.  callrealmethod  clonedrelogin  testconcurrentrelogin  assertequals  isdone  first relogin didn\'t block  thread  getlogin  call  answer  mockito  setlogin  getauthenticationmethod  user  loginugi  isfromkeytab
__label__flaky app  fw1  2009-06-24  02:43:13 958  warn  _  l8_:323  f1  stream  log  end  workflow  state  change  2009-06-24  02:43:13 958  warn  _  l10_:323  !@#$\%^&*()  blah  blah  check  if  the  lines  of  the  log  contain  the  expected  strings  2009-06-24  02:43:13 958  debug  _  l4_:323  abc  split  _  l4_  get  test  case  dir  2009-06-24  02:43:13 958  debug  _  l2_:323  +  2009-06-24  02:43:13 958  debug  _  l3_:323  job  token  2009-06-24  02:43:13 958  debug  _  l1_:323  -  write  set  log  level  str  contains  _  l3_  reset  2009-06-24  02:43:13 958  warn  _  l7_:323  +  checks  that  this  condition  is  no  longer  required  sb1  filtering  shouldn\'t  care  whether  or  not  there  is  a  dash  while  the  last  five  lines  don\'t  pass  the  normal  filtering  debug|  info  2009-06-24  02:43:13 958  warn  _  l6_:323  -  system  out  group  test  stream  log  no  dash  14-200904160239--example-forkjoinwf  oozie.log  _  l2_  define  parameter  set  parameter  log  statement  curr  time  close  sw  /oozie.log  x  log  streamer  2009-06-24  02:43:13 958  debug  _  l5_:323  !@#$\%^&*()  blah  blah  assert  equals  user  xf  2009-06-24  02:43:13 958  warn  _  l9_:323  abc  action  current  time  millis  _  l1_  to  string  _  l5_  append  set  last  modified  app  fw1  2009-06-24 02:43:13 958 warn _l8_:323      f1  streamlog  end workflow state change    2009-06-24 02:43:13 958 warn _l10_:323 !@#$\%^&*() blah blah   check if the lines of the log contain the expected strings  2009-06-24 02:43:13 958 debug _l4_:323 abc  split  _l4_  gettestcasedir  2009-06-24 02:43:13 958 debug _l2_:323 +  2009-06-24 02:43:13 958 debug _l3_:323  job  token  2009-06-24 02:43:13 958 debug _l1_:323 -  write  setloglevel  str  contains  _l3_  reset  2009-06-24 02:43:13 958 warn _l7_:323 +   checks that this condition is no longer required  sb1   filtering shouldn\'t care whether or not there is a dash while the last five lines don\'t pass the normal filtering  debug|info  2009-06-24 02:43:13 958 warn _l6_:323 -  system  out  group  teststreamlognodash  14-200904160239--example-forkjoinwf  oozie.log  _l2_  defineparameter  setparameter  logstatement  currtime  close  sw  /oozie.log  xlogstreamer  2009-06-24 02:43:13 958 debug _l5_:323 !@#$\%^&*() blah blah  assertequals  user  xf  2009-06-24 02:43:13 958 warn _l9_:323 abc  action  currenttimemillis  _l1_  tostring  _l5_  append  setlastmodified
__label__nflaky key  provider  test  root  dir  get  current  key  no  password  file  property   env  not  set   it  should  fail  key3  conf  our  url  delete  unset  bar  using  non  existing  password  file   it  should  fail  test  jks  provider  password  via  config  file  assert  flush  provider  assert  not  null  get  options  java  key  store  provider  test.jks  set  get  providers  core-site.xml  to  uri  could  not  create  keystore  with  password  file  using  different  password  file   it  should  fail  create  key  javakeystoreprovider.password  fail  jks  path  ://file  to  string  key  provider  factory  keyprovider  testrootdir  getcurrentkey  no password file property  env not set  it should fail  key3  conf  oururl  delete  unset  bar  using non existing password file  it should fail  testjksproviderpasswordviaconfig  file  assert  flush  provider  assertnotnull  get  options  javakeystoreprovider  test.jks  set  getproviders  core-site.xml  touri  could not create keystore with password file  using different password file  it should fail  createkey  javakeystoreprovider.password  fail  jkspath  ://file  tostring  keyproviderfactory
__label__flaky a  a  set  xml  utils  parse  xml  <parameters></parameters></root>  conf  assert  equals  <root  xmlns=\""uri:oozie:workflow:0.4\""></root>  test  verify  parameters  empty  size  get  parameter  verifier  verify  parameters  <root  xmlns=\""uri:oozie:workflow:0.4\"">  a  a  set  xmlutils  parsexml  <parameters></parameters></root>  conf  assertequals  <root xmlns=\""uri:oozie:workflow:0.4\""></root>  testverifyparametersempty  size  get  parameterverifier  verifyparameters  <root xmlns=\""uri:oozie:workflow:0.4\"">
__label__nflaky fail  assert  outbuf  channel  test  invalid  constructor  metrics  illegal  argument  exception  should  have  been  thrown  fail  assert  outbuf  channel  testinvalidconstructor  metrics  illegalargumentexception should have been thrown
__label__flaky init  get  property  get  conf  get  resource  as  stream  oozie-  cl  user.name  destroy  assert  equals  custom  conf  dir  system  oozie-site1.xml  test  alternate  conf  dir  io  utils  assert  null  xconf  oozie.system.id  oozie.dummy  set  system  property  copy  stream  get  create  test  case  sub  dir  oozie-site.xml  configuration  service  init  getproperty  getconf  getresourceasstream  oozie-  cl  user.name  destroy  assertequals  customconfdir  system  oozie-site1.xml  testalternateconfdir  ioutils  assertnull  xconf  oozie.system.id  oozie.dummy  setsystemproperty  copystream  get  createtestcasesubdir  oozie-site.xml  configurationservice
__label__nflaky conn  response  captor  when  assert  executor  assert  not  null  context  create  get  code  test  execution  skip  intermediate  responses  then  return  argument  matchers  get  response  get  all  values  capture  method  eq  execute  /  size  info1  mock  receive  response  header  send  request  header  info2  request  get  request  continue  times  flush  get  verify  for  class  ok  post  process  process  argument  captor  huh?  assert  equals  get  entity  assert  same  mockito  response  http  core  context  httprocessor  callback  pre  process  infos  receive  response  entity  conn  responsecaptor  when  assert  executor  assertnotnull  context  create  getcode  testexecutionskipintermediateresponses  thenreturn  argumentmatchers  getresponse  getallvalues  capture  method  eq  execute  /  size  info1  mock  receiveresponseheader  sendrequestheader  info2  request  getrequest  continue  times  flush  get  verify  forclass  ok  postprocess  process  argumentcaptor  huh?  assertequals  getentity  assertsame  mockito  response  httpcorecontext  httprocessor  callback  preprocess  infos  receiveresponseentity
__label__flaky hdfsfoocs  cluster  qualified  get  current  user  data  qfoocs=  conf  run  dir  set  level  webhdfsuri=  bar  ugi  test  permission  error  on  webhdfs  file  system  create  ://  hftp  file  system  web  hdfs  file  system  write  user  group  information  hftpuri  info  localhost  create  user  for  testing  dfs  config  keys  data.length=  webhdfs_qfoocs  write  another  file  generate  random  data  write  data  to  a  file  get  logger  get  file  system  get  file  checksum  set  int  get  int  fail  do  as  nn  addr  hftpfoocs  test  permission  error  on  hftp  num  data  nodes  level  webhdfsfoocs=  barhashcode  set  seed  shutdown  webhdfsqualified  qfoocs  webhdfsfoocs  hftpuri=  seed  hdfsfoocs=  buffer_size  foo  hftp  hftp://  system  next  bytes  out  compute  checksum  barcs  get  test  configuration  current  /filechecksum  hash  code  get  set  permission  block_size  close  get  short  user  name  webhdfs_qfoocs=  set  webhdfs  hftp  webhdfs  assert  equals  test  file  checksum  next  int  next  long  io.file.buffer.size  try  different  number  of  blocks  n  seed=  good:  getting  an  exception  build  hdfs  webhdfsuri  verify  checksum  hftpfoocs=  user  ran  ioe  set  boolean  hdfsfoocs  cluster  qualified  getcurrentuser  data  qfoocs=  conf  run  dir  setlevel  webhdfsuri=  bar  ugi   test permission error on webhdfs  filesystem  create  ://  hftpfilesystem  webhdfsfilesystem  write  usergroupinformation  hftpuri  info  localhost  createuserfortesting  dfsconfigkeys  data.length=  webhdfs_qfoocs   write another file   generate random data   write data to a file  getlogger  getfilesystem  getfilechecksum  setint  getint  fail  doas  nnaddr  hftpfoocs   test permission error on hftp  numdatanodes  level  webhdfsfoocs=  barhashcode  setseed  shutdown  webhdfsqualified  qfoocs  webhdfsfoocs  hftpuri=  seed  hdfsfoocs=  buffer_size  foo  hftp  hftp://  system  nextbytes  out   compute checksum  barcs  gettestconfiguration  current  /filechecksum  hashcode  get  setpermission  block_size  close  getshortusername  webhdfs_qfoocs=  set   webhdfs   hftp  webhdfs  assertequals  testfilechecksum  nextint  nextlong  io.file.buffer.size   try different number of blocks  n  seed=  good: getting an exception  build  hdfs  webhdfsuri   verify checksum  hftpfoocs=  user  ran  ioe  setboolean
__label__nflaky result  handle  result  context  equal  to  fallback  content  type  get  content  type  test  that  fallback  content  type  works  result  handler  assert  that  content  type  result  result  handleresult  context  equalto  fallbackcontenttype  getcontenttype  testthatfallbackcontenttypeworks  resulthandler  assertthat  contenttype  result
__label__flaky bundle  job  get  executor  test  bundle  rerun1  add  record  to  bundle  action  table  add  record  to  bundle  job  table  get  id  assert  equals  get  status  execute  add  record  to  coord  job  table  call  coordinator  job  services  assert  not  null  get  2009-02-01  t00:00  z  action1  job  job  action2  jpa  service  bundlejobgetexecutor  testbundlererun1  addrecordtobundleactiontable  addrecordtobundlejobtable  getid  assertequals  getstatus  execute  addrecordtocoordjobtable  call  coordinatorjob  services  assertnotnull  get  2009-02-01t00:00z  action1  job  job  action2  jpaservice
__label__nflaky rw  assert  false  channel  get  bytes  head  assert  get  channel  write  line  dump  chbuffer  close  write  fchannel  test  coding  from  file  channel  saturated  is  completed  testfile  standard  charsets  create  temp  file  assert  equals  encoder  transfer  outbuf  header  metrics  append  stuff  rw  assertfalse  channel  getbytes  head  assert  getchannel  writeline  dump  chbuffer  close  write  fchannel  testcodingfromfilechannelsaturated  iscompleted  testfile  standardcharsets  createtempfile  assertequals  encoder  transfer  outbuf  header  metrics  append  stuff
__label__flaky cluster  namenode  has  fetch  bad  file  list  from  namenode.  there  should  be  one  file.  get  name  length  test  corrupt  files  corrupted  block  fetch  bad  file  list  from  namenode.  there  should  be  none.  .meta  channel  conf  get  channel  bad  files.  expecting  1.  storage  dir  buffer  /srcdat10  write  info  deliberately  corrupting  file  dfs  config  keys  get  block  pool  id  read  all  files  to  trigger  detection  of  corrupted  replica  log  list  corrupt  file  blocks  get  file  system  blocks  do  not  exist  in  data-dir  set  int  get  name  node  /  blk_  corrupted  replicas  not  handled  properly.  expecting  block  missing  exception  util  size  cleanup  ends  with  position  get  instance  storage  dir  idx  shutdown  datanode  sends  block  reports  get  finalized  dir  rw  bpid  fs  namenode  system  next  bytes  random  bad  files  file  assert  true  list  files  close  test  list  corrupt  files  corrupted  block  data_dir  mini  dfs  cluster  e  blocks  now  deliberately  corrupt  one  block  at  offset  length  namenode  has  bad  files.  byte  buffer  corrupt  files.  expecting  none.  data  directory  does  not  exist  create  files  build  exists  check  files  but  received  io  exception  received  block  missing  exception  as  expected.  wrap  create  two  files  with  one  block  each  datanode  scans  directories  get  namesystem  starts  with  cluster  namenode has    fetch bad file list from namenode. there should be one file.  getname   length   testcorruptfilescorruptedblock   fetch bad file list from namenode. there should be none.  .meta  channel  conf  getchannel   bad files. expecting 1.  storagedir  buffer  /srcdat10  write  info     deliberately corrupting file   dfsconfigkeys  getblockpoolid   read all files to trigger detection of corrupted replica  log  listcorruptfileblocks  getfilesystem  blocks do not exist in data-dir  setint  getnamenode  /  blk_  corrupted replicas not handled properly. expecting blockmissingexception   util  size  cleanup  endswith  position  getinstancestoragedir  idx  shutdown   datanode sends block reports  getfinalizeddir  rw  bpid  fs  namenode  system  nextbytes  random  badfiles  file  asserttrue  listfiles  close  testlistcorruptfilescorruptedblock  data_dir  minidfscluster  e  blocks   now deliberately corrupt one block   at offset   length  namenode has bad files.   bytebuffer   corrupt files. expecting none.  data directory does not exist  createfiles  build  exists  checkfiles   but received ioexception   received blockmissingexception as expected.  wrap   create two files with one block each   datanode scans directories  getnamesystem  startswith
__label__nflaky process  path  dir  order  mtime  reverse  test  file01  get  path  data  testfile01  get  time  add  contents  ls  format  line  mtime  out  testfile03  options  compute  line  format  in  order  testfile02  process  options  verify  testfile05  test  file06  set  mtime  testfile04  test  file04  test  file05  testfile06  test  file02  test  file03  set  file  mtime  in  different  order  to  file  names  add  found  6  items  path  data  line  format  -r  -t  set  is  dir  process  arguments  test  dir  test  directory  verify  no  more  interactions  now  test  file  mock  check  reverse  mtime  ordering  (-t  -r  options)    processpathdirordermtimereverse  testfile01  getpathdata  testfile01  gettime  addcontents  ls  formatlinemtime  out  testfile03  options  computelineformat  inorder  testfile02  processoptions  verify  testfile05  testfile06  setmtime  testfile04  testfile04  testfile05  testfile06  testfile02  testfile03   set file mtime in different order to file names  add  found 6 items  pathdata  lineformat  -r  -t  setisdir  processarguments  testdir  testdirectory  verifynomoreinteractions  now  testfile  mock   check reverse mtime ordering (-t -r options)
__label__flaky date  script  executor  session  given  update  simple  simplemap  eq  simple  map_  put  to  when  of  where  id  row  ten  table  twenty  execute  script  template  contains  entry  should_dsl_update_map_put  random  utils  manager  one  simple  map  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  get  map  then  long  build  date  key  from  base  table  dsl  select  simplemap  from  simple  where  id  =  thirty  date  scriptexecutor  session   given  update  simple  simplemap  eq  simplemap_putto   when  of  where  id  row  ten  table  twenty  executescripttemplate  containsentry  should_dsl_update_map_put  randomutils  manager  one  simplemap  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  getmap   then  long  builddatekey  frombasetable  dsl  select simplemap from simple where id =   thirty
__label__nflaky queue  size  should  enqueue  e  dequeue  back  queue  front  assert  equals  consume  q  enqueue  size  assert  true  test  common  front  queue  back  element  queue size  should enqueue  e  dequeue  back  queue front  assertequals  consume  q  enqueue  size  asserttrue  testcommon  front  queue back  element
__label__flaky get  job  tracker  uri  map-reduce  root  archive  root  so  so  file.so.1  with  leading  and  trailing  spaces  create  context  setup  action  conf  files  in  cache  <map-reduce>  context  get  path  create  jar  root  jar  get  cache  files  <main-class>  class</main-class>  <job-tracker>  e  action  xml  <file>  ae  </file>  parse  xml  </job-tracker>  archive  get  file  system        archive  </name-node>  set  lib  files  archives  found  in  classpath  so  file.so  root  so  file.so  not  found  in  cache  job  conf  archive.tar  <archive>  assert  false  get  app  path  app  path  create  base  hadoop  conf  action  xml  root  so1  root  jar.jar  file  found  so1  distributed  cache  assert  true  root  so  files  in  classpath  close  get  name  node  uri  get  file  class  paths  root  archive.tar  c  xml  utils  root  so  file.so.1  </archive>  to  uri  test  comma  separated  files  and  archives  archives  in  cache  file  get  symlink  not  found  in  classpath  </map-reduce>  p  get  cache  archives     equals  root  file  to  string  <name-node>  get  fs  test  case  dir  jar.jar  getjobtrackeruri  map-reduce  rootarchive  rootso  sofile.so.1   with leading and trailing spaces  createcontext  setupactionconf  filesincache  <map-reduce>  context  getpath  create  jar  rootjar  getcachefiles        <main-class>class</main-class>        <job-tracker>  eactionxml        <file>  ae  </file>    parsexml  </job-tracker>  archive  getfilesystem          archive   </name-node>  setlibfilesarchives   found in classpath  sofile.so  rootsofile.so   not found in cache  jobconf  archive.tar        <archive>  assertfalse  getapppath  apppath  createbasehadoopconf  actionxml  rootso1  rootjar.jar  file  found  so1  distributedcache  asserttrue  root  so  filesinclasspath  close  getnamenodeuri  getfileclasspaths  rootarchive.tar  c  xmlutils  rootsofile.so.1   </archive>    touri  testcommaseparatedfilesandarchives  archivesincache  file   getsymlink   not found in classpath  </map-reduce>  p  getcachearchives      equals  rootfile  tostring        <name-node>  getfstestcasedir  jar.jar
__label__nflaky key  provider  corrupt  file  and  check  if  jks  can  reload  from  _  old  file  check  that  an  uppercase  keyname  results  in  an  error  test  root  dir  inject  failure  during  keystore  write  old  file  rename  to  key5  set  bit  length  key6  replace  conf  our  url  path  assert  assert  not  null  s  hould  be  reset  to  pre-flush  state  options  get  file  status  get  path  get  a  new  instance  of  the  provider  to  ensure  it  was  saved  correctly  jks  should  load  from  _  old  file  !!  rw-------  _  new  and  current  file  should  not  exist  together  !!  test  jks  provider  expected  failure  on  creating  key  name  with  uppercase  get  permission  get  providers  load  from  _  new  file  generic  test  utils  get  file  system  set  backup  fail  fail  ://file  f  provider  should  be  deleted  assert  exception  contains  key  provider  factory  set  write  fail  _  new  exists  but  corrupt..  must  load  from  _  old  start  :  test  flush  error  by  failure  injection  inject  failure  during  keystore  backup  failure  injecting  java  key  store  provider  get  current  key  assert  false  verify  after  reload  new  file  jks  should  load  from  _  new  file  !!  delete  fs  characters  file  flush  provider  assert  true  get  777  uppercase  _  new  and  current  file  should  not  exist  together  set  permission  java  key  store  provider  check  permission  retention  after  explicit  change  test.jks  unnest  uri  set  end  :  test  flush  error  by  failure  injection  check  specific  provider  is  file  _  old  e  to  uri  create  key  assert  equals  should  not  succeed  uppercase  key  names  should  exist  _  new  jks  path  assert  null  check  permission  retention  exists  to  string  provider  utils  create  new  file  keyprovider   corrupt file and check if jks can reload from _old file   check that an uppercase keyname results in an error  testrootdir   inject failure during keystore write  oldfile  renameto  key5  setbitlength  key6  replace  conf  oururl  path  assert  assertnotnull   should be reset to pre-flush state  options  getfilestatus  getpath   get a new instance of the provider to ensure it was saved correctly  jks should load from _old file !!  rw-------  _new and current file should not exist together !!  testjksprovider  expected failure on creating key name with uppercase   getpermission  getproviders   load from _new file  generictestutils  getfilesystem  setbackupfail  fail  ://file  fprovider  should be deleted  assertexceptioncontains  keyproviderfactory  setwritefail   _new exists but corrupt.. must load from _old   start : test flush error by failure injection   inject failure during keystore backup  failureinjectingjavakeystoreprovider  getcurrentkey  assertfalse  verifyafterreload  newfile  jks should load from _new file !!  delete  fs  characters  file  flush  provider  asserttrue  get  777  uppercase   _new and current file should not exist together  setpermission  javakeystoreprovider   check permission retention after explicit change  test.jks  unnesturi  set   end : test flush error by failure injection  checkspecificprovider  isfile  _old  e  touri  createkey  assertequals  should not succeed  uppercase key names   should exist  _new  jkspath  assertnull  checkpermissionretention  exists  tostring  providerutils  createnewfile
__label__flaky get  job  tracker  uri  _test  submit  <pipes>  output  <map-reduce>  create  write  <job-tracker>  <program>  current  thread  </job-tracker>  is  dummy  get  file  system  get  pipes  config  <name-node>  </name-node>  input  get  context  class  loader  </program>  <file>  data.txt  test  pipes  wordcount-simple  </pipes>  fs  binary  \'wordcount-simple\'  not  available  in  the  classpath  system  action  xml  </file>  close  pipes  get  name  node  uri  output  dir  skipping  test:  test  map  reduce  action  executor.test  pipes()   os  get  resource  as  stream  input  dir  thread  </map-reduce>  io  utils  program  path  copy  stream  w  #wordcount-simple  to  xml  string  to  string  get  fs  test  case  dir  getjobtrackeruri  _testsubmit        <pipes>  output  <map-reduce>  create  write  <job-tracker>          <program>  currentthread  </job-tracker>  is  dummy    getfilesystem  getpipesconfig  <name-node>  </name-node>  input  getcontextclassloader  </program>  <file>  data.txt  testpipes  wordcount-simple        </pipes>  fs  binary \'wordcount-simple\' not available in the classpath  system  actionxml  </file>  close  pipes  getnamenodeuri  outputdir  skipping test: testmapreduceactionexecutor.testpipes()    os  getresourceasstream  inputdir  thread  </map-reduce>  ioutils  programpath  copystream  w  #wordcount-simple  toxmlstring  tostring  getfstestcasedir
__label__nflaky prim  long  param  assert  false  context  create  verify  has  violations  prim  long  param  should  handle  null  invoke  mock  controller  validation  primlongparam  assertfalse  context  create  verify  hasviolations  primlongparamshouldhandlenull  invoke  mockcontroller  validation
__label__flaky unexpected  exception  def  add  node  print  stack  trace  e  f  one  j  k  test  decision  fork  join  kill  three  two  as  list  fail  invoke  fork  join  parser  four  name  dummy  conf  end  f->(2 3)  2->decision  node->{4 5 4}  4->j  5->j  3->j  arrays  five  unexpected exception  def  addnode  printstacktrace  e  f  one  j  k  testdecisionforkjoin  kill  three  two  aslist  fail  invokeforkjoin  parser  four  name  dummyconf  end        f->(2 3)      2->decision node->{4 5 4}      4->j      5->j      3->j        arrays  five
__label__nflaky set  handler  conn  get  current  user  proxyuser  using  raw  http   verifying  do  as  is  case  insensitive  run  string  /bar  assert  /foo/bar  foo_  user  ugi  context  read  lines  dispatcher  type  user  group  information  ret  /foo  \%s?user.name=\%s&  doas=\%s  ok_  user  open  connection  requests  using  delegation  token  as  auth  do  not  honor  do  as  format  unauthorized  proxy  user  using  authentication  handler  authentication  set  context  path  create  jetty  server  str  url  create  remote  user  get  input  stream  to  external  form  do  as  stop  size  add  filter  proxy  using  delegation  token  authentication  fail_  user  http  url  connection  of  get  jetty  /*  get  jetty  url  add  token  a  url  add  servlet  enum  set  start  assert  equals  test  proxy  user  url  token  io  utils  proxyuser  using  authentication  handler  authentication  get  response  code  get  delegation  token  \%s?user.name=\%s&doas=\%s  sethandler  conn  getcurrentuser   proxyuser using raw http  verifying doas is case insensitive  run  string  /bar  assert  /foo/bar  foo_user  ugi  context  readlines  dispatchertype  usergroupinformation  ret  /foo  \%s?user.name=\%s&doas=\%s  ok_user  openconnection   requests using delegation token as auth do not honor doas  format   unauthorized proxy user using authentication handler authentication  setcontextpath  createjettyserver  strurl  createremoteuser  getinputstream  toexternalform  doas  stop  size  addfilter   proxy using delegation token authentication  fail_user  httpurlconnection  of  get  jetty  /*  getjettyurl  addtoken  aurl  addservlet  enumset  start  assertequals  testproxyuser  url  token  ioutils   proxyuser using authentication handler authentication  getresponsecode  getdelegationtoken  \%s?user.name=\%s&doas=\%s
__label__flaky get  time  get  id  get  status  coord  get  cmd  coord  job  pause  time  get  start  time  job  ;pausetime=  init  false  destroy  endtime=  assert  equals  services  convert  date  to  string  execute  add  record  to  coord  job  table  new  end  time  call  services  coordinator  job  set  system  property  status  transit  service  end  time  job  jpa  service  test  coord  change  status  gettime  getid  getstatus  coordgetcmd  coordjob  pausetime  get  starttime  job  ;pausetime=  init  false  destroy  endtime=  assertequals  services  convertdatetostring  execute  addrecordtocoordjobtable  newendtime  call  services  coordinatorjob  setsystemproperty  statustransitservice  endtime  job  jpaservice  testcoordchangestatus
__label__nflaky de  renderer  get  internal  server  error  result  contains  string  is  diagnostics  enabled  get  method  get  context  path  when  instance  of  diagnostic  error  renderer  out  assert  renderable  in  test  result  is  the  diagnostic  error  get  renderable  build  context  that  will  have  html  entites  in  key  spots  assert  not  null  of  context  boolean  render  attribute  with  <  >  &  entities  get  attributes  then  return  do  return  build  and  render  diagnostic  error  with  html  entities  assert  that  immutable  map  /  attribute  with  &lt;  &gt;  &amp;  entities  exception  message  with  &lt;  &gt;  &amp;  entities  mockito  ninja  build  test-  attr  get  test  result  spy  exception  message  with  <  >  &  entities  de  renderer  getinternalservererrorresult  containsstring  isdiagnosticsenabled  getmethod  getcontextpath  when  instanceof  diagnosticerrorrenderer  out  assert   renderable in testresult is the diagnosticerror  getrenderable   build context that will have html entites in key spots  assertnotnull  of  context  boolean  render  attribute with < > & entities  getattributes  thenreturn  doreturn  buildandrenderdiagnosticerrorwithhtmlentities  assertthat  immutablemap  /  attribute with &lt; &gt; &amp; entities  exception message with &lt; &gt; &amp; entities  mockito  ninja  build  test-attr  get  testresult  spy  exception message with < > & entities
__label__flaky play  server  abc  get  sequence  number  def  receiver  take  request  ghi  connection  pooling  assert  equals  set  body  url  enqueue  get  url  assert  body  /a  /b  /c  build  await  client  play  server  abc  getsequencenumber  def  receiver  takerequest  ghi  connectionpooling  assertequals  setbody  url  enqueue  geturl  assertbody  /a  /b  /c  build  await  client
__label__nflaky rollover  every  15  sec  init  get  all  secrets  rollover  frequency  get  current  secret  destroy  assert  equals  secret2  secret3  get  bytes  secret1  assert  array  equals  thread  doctor  sleep  test  get  and  roll  secrets  assert  assert  null  current  secret  tardis  secret  provider  all  secrets  who   rollover every 15 sec  init  getallsecrets  rolloverfrequency  getcurrentsecret  destroy  assertequals  secret2  secret3  getbytes  secret1  assertarrayequals  thread  doctor  sleep  testgetandrollsecrets  assert  assertnull  currentsecret  tardis  secretprovider  allsecrets  who
__label__flaky get  waiting  actions  system  dep  sleep  testevictionontimetoidle  get  setup  services  start  time  info  time  to  idle  seconds  is  1  add  missing  dependency  log  pdms  hcat://hcat.server.com:5080/mydb/mytbl/id=  time  taken  to  insert  and  retrive  num  items  verify  waiting  action  thread  services  assert  null  items  is  current  time  millis  test  eviction  on  time  to  idle    getwaitingactions  system  dep  sleep  testevictionontimetoidle  get  setupservices  starttime  info   timetoidleseconds is 1  addmissingdependency  log  pdms  hcat://hcat.server.com:5080/mydb/mytbl/id=  time taken to insert and retrive   numitems  verifywaitingaction  thread  services  assertnull   items is   currenttimemillis  testevictionontimetoidle
__label__nflaky dir  y  dir  x  foo  chrooted  to  list  status  fs  create  file  /bar  bar  assert  assert  true  note  2  crc  files  assert  not  null  /dir  x/dir  xx  get  file  status  get  path  file  system  test  helper  get  test  root  path  note  the  the  file  status  paths  are  the  full  paths  on  target  /dir  y  /dir  x  dir  paths  /foo  list  on  slash  is  file  f  sys  assert  equals  should  return  the  full  path  not  the  chrooted  path  /  file  system  test  helper  test  list  mkdirs  contains  path  is  directory  diry  dirx  foo  chrootedto  liststatus  fs  createfile  /bar  bar  assert  asserttrue   note 2 crc files  assertnotnull  /dirx/dirxx  getfilestatus  getpath  filesystemtesthelper  gettestrootpath   note the the file status paths are the full paths on target  /diry  /dirx  dirpaths  /foo   list on slash  isfile  fsys  assertequals   should return the full path not the chrooted path  /  filesystemtesthelper  testlist  mkdirs  containspath  isdirectory
__label__flaky get  current  user  fourth  attempt(after  timeout)   should  be  different:  should  be  different  group  assert  false  admin  run  second  attempt   should  be  same:  system  sleep  str_groups  groups  get  user  to  groups  mapping  service  get  to  array  get  user  name  should  be  same  group  get  groups  user  group  information  first  attempt:  test  group  mapping  refresh  groups  g1  assert  equals  group  refresh  timeout  sec  g2  g3  g4  should  be  different  group:  thread  args  -refresh  user  to  groups  mappings  size  third  attempt(after  refresh  command)   should  be  different:  equals  and  to  string  arrays  config  user  test  time  out  getcurrentuser  fourth attempt(after timeout)  should be different:  should be different group   assertfalse  admin  run  second attempt  should be same:  system  sleep  str_groups  groups  getusertogroupsmappingservice  get  toarray  getusername  should be same group   getgroups  usergroupinformation  first attempt:  testgroupmappingrefresh  groups  g1  assertequals  grouprefreshtimeoutsec  g2  g3  g4  should be different group:   thread  args  -refreshusertogroupsmappings  size  third attempt(after refresh command)  should be different:  equals   and   tostring  arrays  config  user   test time out
__label__nflaky next  metrics  record  increment  cnt  get  metrics  create  test  source  with  a  single  metric  counter  of  value  0  source  metrics  records  sa  long  value  c1  sb  sleep  iterator  get  attribute  assert  true  builder  injected  tags  new  source  builder  value  all  metrics  are  initially  assumed  to  have  changed  skip  jmx  cache  ttl  test  assert  equals  has  next  thread  change  metric  value  validate  get  metrics  and  jmx  initial  values  build  test  desc  metrics  annotations  metrics  validate  get  metrics  and  jmx  test  get  metrics  and  jmx  next  metricsrecord  incrementcnt  getmetrics   create test source with a single metric counter of value 0  source  metricsrecords  sa  longvalue  c1  sb  sleep  iterator  getattribute  asserttrue  builder  injectedtags  newsourcebuilder  value   all metrics are initially assumed to have changed   skip jmx cache ttl  test  assertequals  hasnext  thread   change metric value   validate getmetrics and jmx initial values  build  test desc  metricsannotations  metrics   validate getmetrics and jmx  testgetmetricsandjmx
__label__flaky cluster  get  max  block  acquire  failures  conf  when  create  file  wait  active  then  fail  some  more  on  another  read   it  shouldn\'t  fail.  set  short  retry  timeout  so  this  test  runs  faster  if  we  fail  exactly  that  many  times   then  it  should  succeed.  read  fully  first  read  successful  after  some  failures.  info  dfs  config  keys  any  string  is  get  file  system  set  int  pre  spy  nn  fail  got  expected  exception  file  size  any  long  the  block  info  won\'t  do  anything.  spy  shutdown  get  block  locations  max  block  acquires  test  failures  are  per  operation  fs  seek  do  answer  file  assert  true  fail.  client  copy  bytes  dfs  client  dfs  test  util  didn\'t  get  exception  starting  test  case  for  failure  reset  we\'re  starting  a  new  operation  on  the  user  level.  get  name  node  rpc  /test  file  io  utils  buf  build  spy  nn  to  string  ioe  open  open  info  cluster  getmaxblockacquirefailures  conf  when  createfile  waitactive   then fail some more on another read  it shouldn\'t fail.   set short retry timeout so this test runs faster   if we fail exactly that many times  then it should succeed.  readfully  first read successful after some failures.  info  dfsconfigkeys  anystring  is  getfilesystem  setint  prespynn  fail  got expected exception  filesize  anylong   the block info won\'t do anything.  spy  shutdown  getblocklocations  maxblockacquires  testfailuresareperoperation  fs  seek  doanswer  file  asserttrue   fail.  client  copybytes  dfsclient  dfstestutil  didn\'t get exception  starting test case for failure reset   we\'re starting a new operation on the user level.  getnamenoderpc  /testfile  ioutils  buf  build  spynn  tostring  ioe  open  openinfo
__label__nflaky init  test  get  uploaded  file  stream  servlet  context  is  assert  equals  http  servlet  request  get  input  stream  get  parameter  as  file  item  io  utils  file  x  assert  file1  data  assert  null  assert  not  null  context  file2  to  string  file1  http  servlet  response  init  testgetuploadedfilestream  servletcontext  is  assertequals  httpservletrequest  getinputstream  getparameterasfileitem  ioutils  filex  assert  file1data  assertnull  assertnotnull  context  file2  tostring  file1  httpservletresponse
__label__flaky subwf  get  status  sub  workflow  action  executor  proto  conf  create  base  workflow  get  workflow  client  new  conf  create  action  </app-path>  workflow.xml  get  base  proto  conf  write  wait  for  workflow  get  file  system  check  child  conf  oozie  client  lib/subwf  library.jar  workflow  action  wps  file  evaluate  <sub-workflow  xmlns=\'uri:oozie:workflow:0.1\'  name=\'subwf\'>  <app-path>  get  job  info  auth  token  subwf  lib  jar  get  actions  get  external  id  fs  app1  test  subworkflow  lib  wf  create  proto  action  conf  assert  true  w  lib/parent  library.jar  get  end  workflow  job  close  get  parent  set  get  conf  workflow  app  service  oozie  client  start  default  conf  sub  workflow  app  path  sub  workflow  assert  equals  job_  timeout  parent  lib  jar  set  conf  services  to  xml  string  exists  to  string  </sub-workflow>  writer  get  fs  test  case  dir  subwf  getstatus  subworkflowactionexecutor  protoconf  createbaseworkflow  getworkflowclient  newconf  create  action  </app-path>  workflow.xml  getbaseprotoconf  write  waitfor  workflow  getfilesystem  check  childconf  oozieclient  lib/subwflibrary.jar  workflowaction  wps  file  evaluate  <sub-workflow xmlns=\'uri:oozie:workflow:0.1\' name=\'subwf\'>        <app-path>  getjobinfo  authtoken  subwflibjar  getactions  getexternalid  fs  app1  testsubworkflowlib  wf  createprotoactionconf  asserttrue  w  lib/parentlibrary.jar  get  end  workflowjob  close  getparent  set  getconf  workflowappservice  oozieclient  start  defaultconf  subworkflowapppath  subworkflow  assertequals  job_timeout  parentlibjar  setconf  services  toxmlstring  exists  tostring  </sub-workflow>  writer  getfstestcasedir
__label__nflaky process  watch  event  data  mock  no  prior  active  when  once  in  initial  join  election()  and  one  now  zk_  lock_  name  notify  fatal  error  assert  monitoring  should  be  setup  again  after  event  is  received  get  path  ids  create  no  new  watches  after  fatal  error  verify  exist  call  mock  app  then  return  make  the  object  go  into  the  monitoring  state  enter  neutral  mode  count  process  result  code  create  mode  get  type  become  active  fatal  error  means  no  new  connection  other  than  one  from  constructor  mock  get  session  id  become  standby  assert  false  times  another  join  election  called  assert  true  enter  neutral  mode  not  called  when  app  is  standby  and  leader  is  lost  mock  event  verify  unexpected  watch  error  from  zookeeper  stat  bad  path  name  results  in  fatal  error  test  process  callback  event  node  int  value  successful  znode  creation  enters  active  state  and  sets  monitor  assert  equals  elector  monitor  is  monitor  lock  node  pending  mock  zk  set  ephemeral  owner  mockito  join  election  event  processwatchevent  data  mocknoprioractive  when   once in initial joinelection() and one now  zk_lock_name  notifyfatalerror  assert   monitoring should be setup again after event is received  getpath  ids  create   no new watches after fatal error  verifyexistcall  mockapp  thenreturn   make the object go into the monitoring state  enterneutralmode  count  processresult  code  createmode  gettype  becomeactive   fatal error means no new connection other than one from constructor  mock  getsessionid  becomestandby  assertfalse  times   another joinelection called  asserttrue   enterneutralmode not called when app is standby and leader is lost  mockevent  verify  unexpected watch error from zookeeper  stat   bad path name results in fatal error  testprocesscallbackeventnode  intvalue   successful znode creation enters active state and sets monitor  assertequals  elector   monitor  ismonitorlocknodepending  mockzk  setephemeralowner  mockito  joinelection  event
__label__flaky p1  p2  <property><name>p2</name><value>v2</value></property>  p3  p4  v3b  v3a  <java>  v1b  v1a  </configuration>  write  xml  parse  job  xml  and  configuration  conf  app  path  create  context  test  parse  job  xml  and  configuration  xml  get  create  <job-xml>job2.xml</job-xml>  j  conf  java  action  executor  job2.xml  close  app  set  </java>  xml  utils  os  parse  xml  <java/>  job1.xml  assert  equals  get  file  system  <configuration>  str  size  mkdirs  <job-xml>job1.xml</job-xml>  v2  v4  <property><name>p1</name><value>v1a</value></property>  get  fs  test  case  dir  p1  p2  <property><name>p2</name><value>v2</value></property>  p3  p4  v3b  v3a  <java>  v1b  v1a  </configuration>  writexml  parsejobxmlandconfiguration  conf  apppath  createcontext  testparsejobxmlandconfiguration  xml  get  create  <job-xml>job2.xml</job-xml>  jconf  javaactionexecutor  job2.xml  close  app  set  </java>  xmlutils  os  parsexml  <java/>  job1.xml  assertequals  getfilesystem  <configuration>  str  size  mkdirs  <job-xml>job1.xml</job-xml>  v2  v4  <property><name>p1</name><value>v1a</value></property>  getfstestcasedir
__label__nflaky key1  test  invalid  provider  ks  run  assert  equals  set  conf  aes  rc  contains  -provider  assert  true  args1  create  to  string  key  shell  -cipher  sdff://file/tmp/keystore.jceks  out  content  key1  testinvalidprovider  ks  run  assertequals  setconf  aes  rc  contains  -provider  asserttrue  args1  create  tostring  keyshell  -cipher  sdff://file/tmp/keystore.jceks  outcontent
__label__flaky conn  set  request  method  is_  security_  enabled  assert  false  assert  true  array  get  json  content-type  test  available  time  zones  /v1/admin/*  collections  run  test  json  tags  rest  constants  open  connection  contains  key  is  empty  http  servlet  response  assert  equals  parse  get  input  stream  url  json  value  call  get  header  field  get  get  response  code  create  url  starts  with  conn  setrequestmethod  is_security_enabled  assertfalse  asserttrue  array  get  json  content-type  testavailabletimezones  /v1/admin/*  collections  runtest  jsontags  restconstants  openconnection  containskey  isempty  httpservletresponse  assertequals  parse  getinputstream  url  jsonvalue  call  getheaderfield  get  getresponsecode  createurl  startswith
__label__nflaky next  then  return  get  internal  server  error  result  get  filter  chain  test  on  route  request  when  internal  server  error  exception  filter  chain  when  ninja  default  route  mockito  context  impl  internal  server  error  exception  mock  verify  that\'s  an  internal  server  error  exception  that  should  be  handled  by  on  error!  on  route  request  then  throw  next  thenreturn  getinternalservererrorresult  getfilterchain  testonrouterequestwheninternalservererrorexception  filterchain  when  ninjadefault  route  mockito  contextimpl  internalservererrorexception  mock  verify  that\'s an internalservererrorexception that should be handled by onerror!  onrouterequest  thenthrow
__label__flaky p2  test  rerun  from  fail  nodes  submit  reader  get  job  info  local  oozie  conf  get  status  delete  path  job  id1  get  test  case  dir  /workflow.xml  file://  get  path  create  workflow.xml  workflow  job  wait  for  skip  succeeded  nodes  nnbase  rerun-wf.xml  wf  client  to  uri  start  assert  equals  get  file  system  get  client  re  run  oozie  client  io  utils  get  test  user  copy  char  stream  set  property  get  resource  as  reader  true  create  configuration  to  string  writer  file  evaluate  get  fs  test  case  dir  base  p2  testrerunfromfailnodes  submit  reader  getjobinfo  localoozie  conf  getstatus  delete  path  jobid1  gettestcasedir  /workflow.xml  file://  getpath  create  workflow.xml  workflowjob  waitfor   skip succeeded nodes  nnbase  rerun-wf.xml  wfclient  touri  start  assertequals  getfilesystem  getclient  rerun  oozieclient  ioutils  gettestuser  copycharstream  setproperty  getresourceasreader  true  createconfiguration  tostring  writer  file  evaluate  getfstestcasedir  base
__label__nflaky set  queue  size  add  appender  stop  no  event  loss  do  append  start  verify  loop  len  delaying  list  appender  buffer  size  async  appender  base  setqueuesize  addappender  stop  noeventloss  doappend  start  verify  looplen  delayinglistappender  buffersize  asyncappenderbase
__label__flaky a  b  test  forked  context  add  node  def  f  start  j  assert  equals  workflow  instance  get  status  as  list  wf  1  <worklfow-app/>  end  arrays  job  a  b  testforkedcontext  addnode  def  f  start  j  assertequals  workflowinstance  getstatus  aslist  wf  1  <worklfow-app/>  end  arrays  job
__label__nflaky add  new  value  test  extra  config  extra  config  set  test.extra.config  trace  utils  conf  assert  equals  wrap  hadoop  conf  get  old  value  new  value  old  value  wrapped  key  test_  prefix  add  newvalue  testextraconfig  extraconfig  set  test.extra.config  traceutils  conf  assertequals  wraphadoopconf  get  old value  new value  oldvalue  wrapped  key  test_prefix
__label__flaky play  server  request  user-  agent  assert  code  assert  body  content-  type:  text/plain  assert  true  assert  contains  headers  get  await  client  async  api  test  add  header  abc  receiver  get  headers  take  request  user-  agent:  async  api  test  set  body  url  /  enqueue  get  url  contains  build  header  play  server  request  user-agent  assertcode  assertbody  content-type: text/plain  asserttrue  assertcontainsheaders  get  await  client  asyncapitest  addheader  abc  receiver  getheaders  takerequest  user-agent: asyncapitest  setbody  url  /  enqueue  geturl  contains  build  header
__label__nflaky request  default  status  expected.  default  request  query  parameters  expected.  default  headers  expected.  default  request  body  expected.  default  protocol  version  expected.  default  response  content  type  expected.  status  assert  headers  protocol_  version  assert  not  null  content_  type  get  default  request  content  type  expected.  default  request  headers  expected.  init  response  expectations  init  request  test  default  method  should  be  get  default  body  expected.  assert  equals  response  expectations  testing  framework  response  expectations  should  not  be  null  request  should  not  be  null  defaults  query  get  method  body  request  default status expected.  default request query parameters expected.  default headers expected.  default request body expected.  default protocol version expected.  default response content type expected.  status  assert  headers  protocol_version  assertnotnull  content_type  get  default request content type expected.  default request headers expected.  initresponseexpectations  initrequest  test  default method should be get  default body expected.  assertequals  responseexpectations  testingframework  responseexpectations should not be null  request should not be null  defaults  query  get  method  body
__label__flaky suspend  end_  points  rest  constants  is_  security_  enabled  get  context  url  oozie  url  mock  dag  engine  service  conf  assert  equals  wc  call  oozie  client  1  set  property  create  configuration  test  suspend  servlet_  classes  run  test  suspend  end_points  restconstants  is_security_enabled  getcontexturl  oozieurl  mockdagengineservice  conf  assertequals  wc  call  oozieclient  1  setproperty  createconfiguration  testsuspend  servlet_classes  runtest
__label__nflaky factory  test  explicit  provider  get  name  set  provider  assert  not  null  trust  manager  factory  get  default  algorithm  get  provider  get  instance  factory  bean  create  trust  manager  factory  factory  testexplicitprovider  getname  setprovider  assertnotnull  trustmanagerfactory  getdefaultalgorithm  getprovider  getinstance  factorybean  createtrustmanagerfactory
__label__flaky set  desired  stack  version  fsm  add  mapreduce  service  configuration  hbase_master_hosts  assert  false  h1  h2  h3  h4  get  cluster  add  hdfs  service  map  host  to  cluster  centos5  mapred_tt_hosts  test  get  cluster  host  info  assert  true  get  persist  injector  get  host  info  add  cluster  add  hbase  service  get  cluster  host  info  address  get  canonical  host  name  get  hosts  for  cluster  assert  equals  add  host  c1  get  local  host  stage  utils  set  os  type  contains  slave_hosts  host  list  size  all_hosts  hbase_rs_hosts  get  instance  hdp-0.1  ambari_db_rca_url  inet  address  setdesiredstackversion  fsm  addmapreduceservice  configuration  hbase_master_hosts  assertfalse  h1  h2  h3  h4  getcluster  addhdfsservice  maphosttocluster  centos5  mapred_tt_hosts  testgetclusterhostinfo  asserttrue  get  persist  injector  gethost  info  addcluster  addhbaseservice  getclusterhostinfo  address  getcanonicalhostname  gethostsforcluster  assertequals  addhost  c1  getlocalhost  stageutils  setostype  contains  slave_hosts  hostlist  size  all_hosts  hbase_rs_hosts  getinstance  hdp-0.1  ambari_db_rca_url  inetaddress
__label__nflaky optional  assert  false  context  date  param  with  optional  create  verify  has  violations  invoke  custom  date  format  param  with  optional  should  handle  empty  mock  controller  validation  empty  optional  assertfalse  context  dateparamwithoptional  create  verify  hasviolations  invoke  customdateformatparamwithoptionalshouldhandleempty  mockcontroller  validation  empty
__label__flaky check  coord  jobs  to  date  get  id  date  utils  system  parse  date  oozie  tz  add  record  to  coord  job  table  call  coordinator  job  2099-02-03  t23:59  z  current  time  millis  start  time  end  time  job  test  mat  lookup  command4  checkcoordjobs  todate  getid  dateutils  system  parsedateoozietz  addrecordtocoordjobtable  call  coordinatorjob  2099-02-03t23:59z  currenttimemillis  starttime  endtime  job  testmatlookupcommand4
__label__nflaky renderable  but  it  should  finalize  headers  without  flash  and  session  cookie  then  return  capture  assert  equals  assets  controller  context  renderable  when  result  captor  result  get  value  get  renderable  get  status  code  results  /assets/../../conf/heroku.conf  test  serve  static  security  no  relativ  path  works  verify  not  found  ok  render  result2  get  request  path  serve  static  renderable   but it should  finalizeheaderswithoutflashandsessioncookie  thenreturn  capture  assertequals  assetscontroller  contextrenderable  when  resultcaptor  result  getvalue  getrenderable  getstatuscode  results  /assets/../../conf/heroku.conf  testservestaticsecuritynorelativpathworks  verify  notfound  ok  render  result2  getrequestpath  servestatic
__label__flaky expiring  keys  conf  rm  dt  master  key  state  when  get  rm  delegation  token  assert  delegation  token  get  client  rm  service  get  rmdt  secret  manager  state  token1  record  the  current  key  init  token  remover  thread.roll  master  key()  then  return  contains  key  get  token  state  old  current  key  decode  identifier  get  renewer  convert  from  yarn  roll  master  key  is  called  every  1  second.  contains  stop  mock  request  to  generate  a  rm  delegation  token  test  rmdt  master  key  state  on  rolling  master  key  request  get  current  key  assert  false  converter  utils  sleep  assert  true  rm1  get  rm  state  dt  secret  manager  wait  for  the  first  roll  master  key  renewer1  rm  dt  state  start  assert  equals  thread  mem  store  dt  id1  get  state  assert  all  master  keys  are  saved  get  rmdt  secret  manager  get  all  master  keys  add  all  response  get  master  key  state  get  delegation  token  assert  old-current-key  and  new-current-key  exist  new  current  key  expiringkeys  conf  rmdtmasterkeystate  when  getrmdelegationtoken  assert  delegationtoken  getclientrmservice  getrmdtsecretmanagerstate  token1   record the current key  init   tokenremoverthread.rollmasterkey()  thenreturn  containskey  gettokenstate  oldcurrentkey  decodeidentifier  getrenewer  convertfromyarn   rollmasterkey is called every 1 second.  contains  stop  mock   request to generate a rmdelegationtoken  testrmdtmasterkeystateonrollingmasterkey  request  getcurrentkey  assertfalse  converterutils  sleep  asserttrue  rm1  get  rmstate  dtsecretmanager   wait for the first rollmasterkey  renewer1  rmdtstate  start  assertequals  thread  memstore  dtid1  getstate   assert all master keys are saved  getrmdtsecretmanager  getallmasterkeys  addall  response  getmasterkeystate  getdelegationtoken   assert old-current-key and new-current-key exist  newcurrentkey
__label__nflaky 5.png  assert  correct  image2binary  (01)90614141000015(3202)000150  test  decode  row2binary5  ..  x.  x...  .  xxxx.  x.  xx..  xxxx  ....  xx..  x.......  ....  x...  ....  x..  x  .  xx.  5.png  assertcorrectimage2binary   (01)90614141000015(3202)000150  testdecoderow2binary5   ..x.x... .xxxx.x. xx..xxxx ....xx.. x....... ....x... ....x..x .xx.
__label__flaky end_  points  rest  constants  is_  security_  enabled  get  context  url  oozie  url  -kill  mock  dag  engine  service  run  assert  equals  args  call  1  test  kill  -oozie  size  job  servlet_  classes  run  test  end_points  restconstants  is_security_enabled  getcontexturl  oozieurl  -kill  mockdagengineservice  run  assertequals  args  call  1  testkill  -oozie  size  job  servlet_classes  runtest
__label__nflaky java.version  env  util  assert  true  set  property  assert  false  1.5  is  jdk6  or  higher  is  jdk5  test  java1_5  system  is  jdk7  or  higher  java.version  envutil  asserttrue  setproperty  assertfalse  1.5  isjdk6orhigher  isjdk5  testjava1_5  system  isjdk7orhigher
__label__flaky date  local_  one  given  simple  0  am  select  *  from  simple  where  id  =  as  list  consistency  list_  set  consistency  level  when  get  list  id  is  not  null  random  utils  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  using  time  to  live  has  size  then  long  build  date  key  from  base  table  consistency  list  arrays  dsl  set  script  executor  get  time  session  update  eq  consistencylist  using  timestamp  sleep  contains  exactly  quorum  of  where  row  value  table  execute  script  template  manager  one  should_dsl_update_with_ttl  get  string  next  long  thread  new  value  is  equal  to  and  date  =  \'2015-10-01  00:00:00.000+0000\'  date  local_one   given  simple  0 am  select * from simple where id =   aslist  consistencylist_set  consistencylevel   when  getlist  id  isnotnull  randomutils  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  usingtimetolive  hassize   then  long  builddatekey  frombasetable  consistencylist  arrays  dsl  set  scriptexecutor  gettime  session  update  eq  consistencylist  usingtimestamp  sleep  containsexactly  quorum  of  where  row  value  table  executescripttemplate  manager  one  should_dsl_update_with_ttl  getstring  nextlong  thread  new value  isequalto   and date = \'2015-10-01 00:00:00.000+0000\'
__label__nflaky get  bytes  transferred  read  identity;  completed:  true  dst  standard  charsets  codec  test  utils  assert  false  channel  clear  bytes  read  assert  equals  decoder  convert  byte  buffer  stuff;  assert  allocate  inbuf  assert  true  test  basic  decoding  to  string  more  stuff  metrics  is  completed  getbytestransferred  read  identity; completed: true  dst  standardcharsets  codectestutils  assertfalse  channel  clear  bytesread  assertequals  decoder  convert  bytebuffer  stuff;  assert  allocate  inbuf  asserttrue  testbasicdecoding  tostring  more stuff  metrics  iscompleted
__label__flaky init  .dataout.  abc.unresolved  coord  el  functions  .datain.  abc.unresolved  ${coord:database  in(\'  abc\')}  set  variable  ${coord:database  out(\'  abc\')}  assert  equals  coord-action-start  test  database  eval  eval  and  wrap  .dataout.  abc  mydb  .datain.  abc  expr  boolean  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us  init  .dataout.abc.unresolved  coordelfunctions  .datain.abc.unresolved  ${coord:databasein(\'abc\')}  setvariable  ${coord:databaseout(\'abc\')}  assertequals  coord-action-start  testdatabase  eval  evalandwrap  .dataout.abc  mydb  .datain.abc  expr  boolean  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us
__label__nflaky request  handler  test  cannot  renew  token  using  token  assert  false  get  method  when  token  str  assert  verify  try  renew  a  token  using  itself   should  get  401.  op  pwriter  then  return  &  delegation  token  authenticator  get  query  string  http  servlet  response  set  status  management  operation  mockito  response  get  writer  get  token  mock  reset  get  http  method  to  string  writer  =  request  handler  testcannotrenewtokenusingtoken  assertfalse  getmethod  when  tokenstr  assert  verify   try renew a token using itself  should get 401.  op  pwriter  thenreturn  &  delegationtokenauthenticator  getquerystring  httpservletresponse  setstatus  managementoperation  mockito  response  getwriter  gettoken  mock  reset  gethttpmethod  tostring  writer  =
__label__flaky resuming  job  get  event  status  get  user  get  workflow  instance  event  status  get  id  poll  suspending  job  workflow  instance  get  status  starting  job  get  end  time  add  record  to  wf  job  table  assert  not  null  get  get  start  time  workflow  job  event  wf  instance  wf  job  get  cmd  wf  action  get  app  name  start  assert  equals  execute  call  killing  job  services  test  workflow  job  event  size  successful  job  (testing  signal  x)  @one  _create  workflow  job  set  wf  instance  job  jpa  service  app  type  queue  get  app  type   resuming job  geteventstatus  getuser  getworkflowinstance  eventstatus  getid  poll   suspending job  workflowinstance  getstatus   starting job  getendtime  addrecordtowfjobtable  assertnotnull  get  getstarttime  workflowjob  event  wfinstance  wfjobgetcmd  wfaction  getappname  start  assertequals  execute  call   killing job  services  testworkflowjobevent  size   successful job (testing signalx)  @one  _createworkflowjob  setwfinstance  job  jpaservice  apptype  queue  getapptype
__label__nflaky request  conn  in  stream  get  endpoint  details  get  content  user-  agent  get  method  when  get  bytes  content  receive  request  header  receive  request  entity  bind  assert  assert  true  assert  not  null  get  path  get  request  count  standard  charsets  then  return  assert  equals  method  get  entity  get  content  length  get  input  stream  /  assert  null  mockito  name  socket  contains  header  test  read  request  entity  with  content  length  entity  post  /  http/1.1  user-  agent:  test  content-  length:  3  123  request  conn  instream  getendpointdetails  getcontent  user-agent  getmethod  when  getbytes  content  receiverequestheader  receiverequestentity  bind  assert  asserttrue  assertnotnull  getpath  getrequestcount  standardcharsets  thenreturn  assertequals  method  getentity  getcontentlength  getinputstream  /  assertnull  mockito  name  socket  containsheader  testreadrequestentitywithcontentlength  entity  post / http/1.1  user-agent: test  content-length: 3    123
__label__flaky start  server  produce  consume  topics  input  to  update  get  name  log  config  utils  should  be  model  update  updates  put  start  messaging  get  first  up  key  else  should  be  just  an  int  info  models  oryx.speed.streaming.block-interval-sec  assert  equals  model  message     get  config  integer  parse  int  test  speed  layer  contains  oryx.speed.streaming.generation-interval-sec  get  second  it\'s  an  input  converted  to  update  overlay  config  received  updates  overlay  on  oryx.speed.model-manager-class  config  received  {}  models   {}  inputs  converted  to  updates   and  {}  other  updates  startserverproduceconsumetopics  inputtoupdate  getname  log  configutils  shouldbemodel  update  updates  put  startmessaging  getfirst  up  key   else should be just an int  info  models  oryx.speed.streaming.block-interval-sec  assertequals  model  message     getconfig  integer  parseint  testspeedlayer  contains  oryx.speed.streaming.generation-interval-sec  getsecond   it\'s an input converted to update  overlayconfig  receivedupdates  overlayon  oryx.speed.model-manager-class  config  received {} models  {} inputs converted to updates  and {} other updates
__label__nflaky num  attempts  test_  user_  name  set  the  first  expected  url  and  add  it  back  to  the  queue  ldap_  num_  attempts_  before_  failover_  key  conf  decrement  and  get  ldap_  num_  attempts_  key  when  get  groups  mapping  remove  search  times  groups  mapping  set  strings  assert  true  get  verify  get  groups  add  ldap://test  set  any  string  is  empty  server  attempts  groups  ldap  urls  any  set  conf  set  int  dummy  ldap  ctx  factory  next  ldap  url  set  expected  ldap  url  test  that  we  made  6  attempts  overall  answer  ldap://test2  ldap://test1  num  attempts  before  failover  ldap_  url_  key  take  the  head  of  the  queue  and  re-queue  it  to  the  back  then  answer  get  base  conf  get  context  number  of  attempts  using  a  single  ldap  server  url  test  failover  numattempts  test_user_name   set the first expected url and add it back to the queue  ldap_num_attempts_before_failover_key  conf  decrementandget  ldap_num_attempts_key  when  getgroupsmapping  remove  search  times  groupsmapping  setstrings  asserttrue  get  verify  getgroups  add  ldap://test  set  anystring  isempty  serverattempts  groups  ldapurls  any  setconf  setint  dummyldapctxfactory  nextldapurl  setexpectedldapurl   test that we made 6 attempts overall  answer  ldap://test2  ldap://test1  numattemptsbeforefailover  ldap_url_key   take the head of the queue and re-queue it to the back  thenanswer  getbaseconf  getcontext   number of attempts using a single ldap server url  testfailover
__label__flaky bulk  insert  cmd  create  workflow  add  node  auth  get  app  path  prep  conf  get  id  test  token  workflow  instance  action  get  cmd  set  insert  list  assert  not  null  get  test  app  <workflow-app/>  end  workflow.xml  workflow  job  app  add  get  status  str  set  check  for  expected  status  after  running  bulk  update  jpa  insert  list  wf  get  cmd  test  inserts  assert  equals  execute  app  uri  oozie  client  1  services  2  get  test  user  workflow  action  to  string  create  workflow  action  action1  insert  one  workflow  job  and  two  actions  job  action2  jpa  service  bulkinsertcmd  createworkflow  addnode  auth  getapppath  prep  conf  getid  testtoken  workflowinstance  actiongetcmd  setinsertlist  assertnotnull  get  testapp  <workflow-app/>  end  workflow.xml  workflowjob  app  add  getstatusstr  set   check for expected status after running bulkupdatejpa  insertlist  wfgetcmd  testinserts  assertequals  execute  appuri  oozieclient  1  services  2  gettestuser  workflowaction  tostring  createworkflowaction  action1   insert one workflow job and two actions  job  action2  jpaservice
__label__nflaky server  rpc  configure  super  user  ip  addresses  get  proxy  superuser  group  conf  key  group_  names  default  impersonation  provider  conf  test  real  user  authorization  success  assert  set  strings  real_  user_  short_  name  refresh  conf  client  set  protocol  engine  set  configuration  user  group  information  proxy  user  ugi  print  stack  trace  e  create  remote  user  group1  real_  user_  name  fail  get  test  provider  stop  check  remote  ugi  setup  test  server  proxy_  user_  name  real  user  ugi  create  proxy  user  for  testing  server  rpc  configuresuperuseripaddresses  getproxysuperusergroupconfkey  group_names  defaultimpersonationprovider  conf  testrealuserauthorizationsuccess  assert  setstrings  real_user_short_name  refreshconf  client  setprotocolengine  setconfiguration  usergroupinformation  proxyuserugi  printstacktrace  e  createremoteuser  group1  real_user_name  fail  gettestprovider  stop  checkremoteugi  setuptestserver  proxy_user_name  realuserugi  createproxyuserfortesting
__label__flaky ret  get  local  block  get  block  the  dn  should  have  register  to  both  n  ns.  wait  for  initialization  register  datanode  start  assert  equals  any  when  we  receive  a  block   it  should  report  it  to  both  n  ns  mock  nn1  wait  for  block  report  should  get  block  reports  from  both  n  ns  wait  for  block  received  test  basic  functionality  stop  mockito  verify  notify  namenode  received  block  bpos  mock  nn2  setup  bpos  for  n  ns  fake_  block    ret  getlocalblock  getblock   the dn should have register to both nns.  waitforinitialization  registerdatanode  start  assertequals  any   when we receive a block  it should report it to both nns  mocknn1  waitforblockreport   should get block reports from both nns  waitforblockreceived  testbasicfunctionality  stop  mockito  verify  notifynamenodereceivedblock  bpos  mocknn2  setupbposfornns  fake_block
__label__nflaky format  name  value  pair  value1  format  parameters  format  header  element  params  test  invalid  arguments  fail  buf  regular_stuff  assert  param  format  elements  elements  name1  element  illegal  argument  exception  should  habe  been  thrown  formatnamevaluepair  value1  formatparameters  formatheaderelement  params  testinvalidarguments  fail  buf  regular_stuff  assert  param  formatelements  elements  name1  element  illegalargumentexception should habe been thrown
__label__flaky x-  timestamp  get  name  row_3  body  put  table  path  bytes  mimetype_  binary  assert  true  yield  get  client  value_3  test  single  cell  get  put  binary  get  code  found  timestamp  header  get  headers  get  body  to  bytes  assert  equals  /  thread  delete  row  column_1  response  equals  header  x-timestamp  getname  row_3  body  put  table  path  bytes  mimetype_binary  asserttrue  yield  get  client  value_3  testsinglecellgetputbinary  getcode  foundtimestampheader  getheaders  getbody  tobytes  assertequals  /  thread  deleterow  column_1  response  equals  header
__label__nflaky timed  out  on  barrier  passed  get  name  test.sink.collector.  thread  source  rec  run  collector  of  values  from  all  threads.  as  list  barrier  get  test  filename  test  thread  source  time  unit  join  equals  ignore  case  results  add  all  current  thread  ms  sink  input  barrier2  a  source  of  my  threaded  goodness.  stop  barrier1  *.period  test  metrics  config  safe  await  arrays  shutdown  my  source  sources  save  test  multi  threaded  publish  metrics  config  collector  iterables  assert  true  string  utils  get  await  metric  not  collected!  value  hadoop-metrics2-test  someone  else  collected  my  metric!  register  sink  set  broken  barrier  apply  start  threads  the  system  at  the  same  time  i  need  to  wait  for  the  threads  to  finish  before  checking.  assert  equals  num  threads  thread  interrupted  integer  parse  int  t  publish  metrics  now  register  timed out on barrier  passed    getname  test.sink.collector.  threadsourcerec  run      collector of values from all threads.  aslist  barrier  gettestfilename  test  threadsource  timeunit  join  equalsignorecase  results  add  all  currentthread  ms  sink  input  barrier2  a source of my threaded goodness.  stop  barrier1  *.period  testmetricsconfig  safeawait  arrays  shutdown  mysource  sources  save  testmultithreadedpublish  metricsconfig  collector  iterables  asserttrue  stringutils  get  await  metric not collected!  value  hadoop-metrics2-test  someone else collected my metric!  registersink  set  broken barrier  apply  start  threads   the system at the same time   i need to wait for the threads to finish before checking.  assertequals  numthreads  thread  interrupted  integer  parseint  t  publishmetricsnow  register
__label__flaky poll  date  utils  get  status  as  list  parse  date  oozie  tz  assert  not  null  coordinator  action  coordinator_action  action  coord  action  get  start  time  wait  for  2013-01-01  t10:00  z  get  job  id  modify  coord  for  running  execute  ehs  coordinator  job  action  success  size  arrays  app  type  get  created  time  evaluate  get  parent  id  make  action  ready  test  coordinator  action  event  get  app  type  get  event  status  get  user  event  status  get  id  get  external  id  coord  get  cmd  set  app  types  action  failure  coord  wf  job  get  start  time  action  waiting  on  materialization  event  workflow  job  get  app  name  2013-01-01  t10:14  z  assert  equals  get  nominal  time  add  record  to  coord  job  table  set  status  call  services  @1  end  time  jpa  service  queue  _poll  queue  poll  dateutils  getstatus  aslist  parsedateoozietz  assertnotnull  coordinatoraction  coordinator_action  action   coord action  getstarttime  waitfor  2013-01-01t10:00z  getjobid  modifycoordforrunning  execute  ehs  coordinatorjob   action success  size  arrays  apptype  getcreatedtime  evaluate  getparentid   make action ready  testcoordinatoractionevent  getapptype  geteventstatus  getuser  eventstatus  getid  getexternalid  coordgetcmd  setapptypes   action failure  coord  wfjob  get  starttime   action waiting on materialization  event  workflowjob  getappname  2013-01-01t10:14z  assertequals  getnominaltime  addrecordtocoordjobtable  setstatus  call  services  @1  endtime  jpaservice  queue  _pollqueue
__label__nflaky get  path  parameter  then  return  session  multiple  invoke  when  multiple  different  extractors  should  work  fine  param1  param2  context  create  verify  value  20  mock  controller  get  parameter  getpathparameter  thenreturn  session  multiple  invoke  when  multipledifferentextractorsshouldworkfine  param1  param2  context  create  verify  value  20  mockcontroller  getparameter
__label__flaky stateless  worker  deactivation  test  this  will  force  the  creation  of  concurrent  activations  in  each  node  1000  await  for  touch  a  single  activation  (that  will  probably  not  be  collected)  create  stage  this  will  collect  all  but  one  activation  actor5  increment  the  clock  assert  true  get  client  time  unit  to  millis  get  reference  increment  time  millis  create  client  add  now  there  should  be  a  single  element  from  the  first  set1  that  still  exists  here.  and  no  other  ids  will  match  get  unique  activation  id  there  should  be  multiple  activations   off  course  statistics  might  let  use  down  here.  the  surviving  set2  f  assert  equals  clock  futures  contains  size  cleanup  multiple  activations   again  i  actor  set1  is  idle  unused  do  the  shenanigans  again  stage1  retain  all  statelessworkerdeactivationtest   this will force the creation of concurrent activations in each node  1000  awaitfor   touch a single activation (that will probably not be collected)  createstage   this will collect all but one activation  actor5   increment the clock  asserttrue  get  client  timeunit  tomillis  getreference  incrementtimemillis  createclient  add   now there should be a single element from the first set1 that still exists here.   and no other ids will match  getuniqueactivationid   there should be multiple activations  off course statistics might let use down here.  thesurviving  set2  f  assertequals  clock  futures  contains  size  cleanup   multiple activations  again  iactor  set1  isidle  unused   do the shenanigans again  stage1  retainall
__label__nflaky bb  make  a  configuration  file  with  a  final  property  a  prop;  ignoring.  logging  event  get  log  logger  declare  property  conf  logger  get  rendered  message  get  bytes  out  remove  appender  make  sure  the  appender  is  removed  add  appender  did  not  see  expected  string  inside  message  assert  true  add  resource  prop  get  overriding  a  final  parameter  should  cause  logging  get  root  logger  make  a  second  config  file  with  a  final  property  with  a  different  value  events  should  see  the  first  value  end  config  attach  our  own  log  appender  so  we  can  verify  output  start  config  appender  assert  equals  in2  in1  contains  size  bytes  an  attempt  to  override  final  parameter:  to  string  writer  add  the  2  different  resources  -  this  should  generate  a  warning  test  final  warnings  bytes2  rendered  message  bb   make a configuration file with a final property  a  prop;  ignoring.  loggingevent  getlog  logger  declareproperty  conf  logger  getrenderedmessage  getbytes  out  removeappender   make sure the appender is removed  addappender  did not see expected string inside message   asserttrue  addresource  prop  get  overriding a final parameter should cause logging  getrootlogger   make a second config file with a final property with a different value  events  should see the first value  endconfig   attach our own log appender so we can verify output  startconfig  appender  assertequals  in2  in1  contains  size  bytes  an attempt to override final parameter:   tostring  writer   add the 2 different resources - this should generate a warning  testfinalwarnings  bytes2  renderedmessage
__label__flaky context  set  resource  watcher  update  period  delta  start  update  period  g1  resource  type  check  get  config  system  should  check  only  after  timeout  times  mockito  get  current  time  millis  mock  resource  watcher  verify  victim  key  context  setresourcewatcherupdateperiod  delta  start  updateperiod  g1  resourcetype  check  getconfig  system  shouldcheckonlyaftertimeout  times  mockito  get  currenttimemillis  mockresourcewatcher  verify  victim  key
__label__nflaky aiue  in  hiragana  in  shift_  jis  test  choose  mode  choose  mode  a  a  sou-  utsu-  byou  in  kanji  in  shift_  jis.  #  numeric  mode.  mode  8-bit  byte  mode.  assert  same  nihon  in  kanji  in  shift_  jis.  0  0123456789  abcdefghijklmnopqrstuvwxyz  $\%*+-./:  0123456789  encoder  bytes  alphanumeric  mode.  shift  jis  string     aiue in hiragana in shift_jis  testchoosemode  choosemode  a  a   sou-utsu-byou in kanji in shift_jis.  #   numeric mode.  mode   8-bit byte mode.  assertsame   nihon in kanji in shift_jis.  0  0123456789abcdefghijklmnopqrstuvwxyz $\%*+-./:  0123456789  encoder  bytes   alphanumeric mode.  shiftjisstring
__label__flaky test  coord  actions  not  completeted  for  column  values  action  num  get  id  get  status  add  record  to  coord  action  table  add  record  to  coord  job  table  _test  coord  action  for  correct  column  values  coordinator  job  job  id  coord-action-get.xml  *  add  a  coordinator  action  with  status  waiting  and  check  for  expected  column  values  coordinator  action  action  job  get  pending  testcoordactionsnotcompletetedforcolumnvalues  actionnum  getid  getstatus  addrecordtocoordactiontable  addrecordtocoordjobtable  _testcoordactionforcorrectcolumnvalues  coordinatorjob  jobid  coord-action-get.xml         * add a coordinator action with status waiting and check for expected column values         coordinatoraction  action  job  getpending
__label__nflaky fcq  assert  can  take  test  take  blocks  when  empty  fcq  assertcantake  testtakeblockswhenempty
__label__flaky interval  get  own  avg  get  own  min  get  total  max  start  assert  equals  cron1  cron2  add  cron  thread  sleep  timer  get  ticks  get  value  get  total  square  sum  stop  get  total  avg  get  own  max  get  total  min  get  own  get  total  test  timer  get  own  square  sum  interval  getownavg  getownmin  gettotalmax  start  assertequals  cron1  cron2  addcron  thread  sleep  timer  getticks  getvalue  gettotalsquaresum  stop  gettotalavg  getownmax  gettotalmin  getown  gettotal  testtimer  getownsquaresum
__label__nflaky prepare  test  coding  direct  buffer_10x4_erasing_d0_d1_p0_p1  test  coding  prepare  testcodingdirectbuffer_10x4_erasing_d0_d1_p0_p1  testcoding
__label__flaky exec_  order  callable2  init  callable3  callable1  callable  low  callable  queue  service  destroy  queueservice  services  1  assert  true  get  set  system  property  test  priority  execution  callable  high  evaluate  wait  for  queue  exec_order  callable2  init  callable3  callable1  callablelow  callablequeueservice  destroy  queueservice  services  1  asserttrue  get  setsystemproperty  testpriorityexecution  callablehigh  evaluate  waitfor  queue
__label__nflaky get  bytes  transferred  a  lot  more  stuff!  rw  stuff;  codec  test  utils  more  stuff;  channel  assert  inbuf  get  channel  pos  stuff;  more  stuff;  a  lot  more  stuff!  close  fchannel  is  completed  testfile  standard  charsets  length  bytes  read  assert  equals  create  temp  file  decoder  fill  transfer  count  everything  except  the  initial  7  bytes  that  went  to  the  session  buffer  read  from  file  metrics  test  decoding  file  with  buffered  session  data  getbytestransferred  a lot more stuff!  rw  stuff;   codectestutils  more stuff;   channel  assert  inbuf  getchannel  pos  stuff; more stuff; a lot more stuff!  close  fchannel  iscompleted  testfile  standardcharsets  length  bytesread  assertequals  createtempfile  decoder  fill  transfer   count everything except the initial 7 bytes that went to the session buffer  readfromfile  metrics  testdecodingfilewithbufferedsessiondata
__label__flaky construct  prepare  xml  block  with  the  path  parse  the  xml  to  get  the  node  </prepare>  do  operations  <delete  path=\'  expected  to  catch  an  exception  but  did  not  encounter  any  expected  a  launcher  exception  but  received  an  exception  conf  fs  delete  test/oozietests/test  delete/delete  get  document  from  xml  create  job  conf  path  trim  scheme  not  present  in  uri  launcher  mapper  <prepare>  \'/>  test  for  null  scheme  get  named  item  item  get  attributes  delete  the  file  if  it  is  already  there  get  document  element  get  message  assert  equals  get  file  system  n  get  node  value  fail  construct  a  path  without  scheme  new  dir  test  for  null  scheme  value  in  the  path  for  action  prepare  xml  exists  doc  le  prepare  actions  driver  setup  launcher  uri  handler  conf  get  child  nodes   construct prepare xml block with the path   parse the xml to get the node  </prepare>  dooperations  <delete path=\'  expected to catch an exception but did not encounter any  expected a launcherexception but received an exception  conf  fs  delete  test/oozietests/testdelete/delete  getdocumentfromxml  createjobconf  path  trim  scheme not present in uri   launchermapper  <prepare>  \'/>  testfornullscheme  getnameditem  item  getattributes   delete the file if it is already there  getdocumentelement  getmessage  assertequals  getfilesystem  n  getnodevalue  fail   construct a path without scheme  newdir   test for null scheme value in the path for action  preparexml  exists  doc  le  prepareactionsdriver  setuplauncherurihandlerconf  getchildnodes
__label__nflaky set  name  clear  mapping  http://  get  name  authorization  is  disabled  by  default  servlet  set  find  port  conf  my  groups  provider  as  list  put  set  attribute  get  host  port  string  get  connector  address  http  url  connection  test  disabled  authorization  of  default  servlets  log  level  groups  my  server  get  user  to  groups  mapping  service  server  url  http  server2  logs  group  b  group  a  add  endpoint  set  common  configuration  keys  test  stacks  start  assert  equals  get  http  status  code  /  user  a  user  b  http://localhost:0  net  utils  stop  build  arrays  user  setname  clearmapping  http://  getname   authorization is disabled by default  servlet  setfindport  conf  mygroupsprovider  aslist  put  setattribute  gethostportstring  getconnectoraddress  httpurlconnection  testdisabledauthorizationofdefaultservlets  loglevel  groups  myserver  getusertogroupsmappingservice  serverurl  httpserver2  logs  groupb  groupa  addendpoint  set  commonconfigurationkeys  test  stacks  start  assertequals  gethttpstatuscode  /  usera  userb  http://localhost:0  netutils  stop  build  arrays  user
__label__flaky do  an  edit  make  sure  runtime.exit(...)  hasn\'t  been  called  at  all  yet.  cluster  assert  true  assert  exit  invocations  invalidate  one  edits  journal.  assert  false  test  single  failed  edits  dir  on  set  ready  to  flush  a  single  journal  failure  should  not  result  in  a  call  to  runtime.exit(...).  is  in  safe  mode  invalidate  edits  dir  at  index  get  name  node  doanedit   make sure runtime.exit(...) hasn\'t been called at all yet.  cluster  asserttrue  assertexitinvocations   invalidate one edits journal.  assertfalse  testsinglefailededitsdironsetreadytoflush   a single journal failure should not result in a call to runtime.exit(...).  isinsafemode  invalidateeditsdiratindex  getnamenode
__label__nflaky localhost  set  host  //localhost:8443  test  tolerate  blank  input  set  fragment  core  matchers  equal  to  set  path  set  scheme  assert  that  set  port  uri  set  user  info  assert  build  set  custom  query  create    localhost  sethost  //localhost:8443  testtolerateblankinput  setfragment  corematchers  equalto  setpath  setscheme  assertthat  setport  uri  setuserinfo  assert  build  setcustomquery  create
__label__flaky oozie  url  get  reader  as  string  assert  false  new  cache  admin  run  secret  oozie.authentication.simple.anonymous.allowed  not  using  cache  delete  test  client  auth  token  cache  assert  true  -status  run  test  get  context  url  oozie.authentication.signature.secret  false  assert  equals  using  cache  args  call  oozie.auth.token.cache  io  utils  -oozie  current  cache  set  system  property  auth  oozie  client  true  exists  re-using  cache  oozieurl  getreaderasstring  assertfalse  newcache  admin  run  secret  oozie.authentication.simple.anonymous.allowed   not using cache  delete  testclientauthtokencache  asserttrue  -status  runtest  getcontexturl  oozie.authentication.signature.secret  false  assertequals   using cache  args  call  oozie.auth.token.cache  ioutils  -oozie  currentcache  setsystemproperty  authoozieclient  true  exists   re-using cache
__label__nflaky test  encode  decode  random  test  encode  decode  test  aztec  generic  gf  compact  mode  message  real  life  test  cases  full  mode  message  testencodedecoderandom  testencodedecode  testaztec  genericgf   compact mode message   real life test cases   full mode message
__label__flaky delete  list  add  record  to  wf  action  table  get  id  workflow  instance  action  c1  action  c2  action  a1  workflow  action  a1  should  not  have  been  deleted  action  a2  deactivate  job  b  add  record  to  wf  job  table  job  a  assert  not  null  remove  fault  injection  job  c  get  workflow  action  a2  should  not  have  been  deleted  workflow  action  c1  should  not  have  been  deleted  workflow  job  test  delete  workflows  rollback  add  should  have  skipped  commit  for  failover  testing  skipping  commit  for  failover  testing  workflow  job  a  should  not  have  been  deleted  workflow  action  b1  should  not  have  been  deleted  get  message  workflow  action  c2  should  not  have  been  deleted  assert  equals  workflow  job  b  should  not  have  been  deleted  skip  commit  fault  injection  action  b1  execute  action  b2  fault  injection  1  services  fail  2  re  workflow  action  b2  should  not  have  been  deleted  workflow  action  org.apache.oozie.command.  skip  commit  fault  injection  set  system  property  true  set  fault  injection  to  true   so  transaction  is  roll  backed  jpa  service  workflow  job  c  should  not  have  been  deleted  deletelist  addrecordtowfactiontable  getid  workflowinstance  actionc1  actionc2  actiona1  workflow action a1 should not have been deleted  actiona2  deactivate  jobb  addrecordtowfjobtable  joba  assertnotnull   remove fault injection  jobc  get  workflow action a2 should not have been deleted  workflow action c1 should not have been deleted  workflowjob  testdeleteworkflowsrollback  add  should have skipped commit for failover testing  skipping commit for failover testing  workflow job a should not have been deleted  workflow action b1 should not have been deleted  getmessage  workflow action c2 should not have been deleted  assertequals  workflow job b should not have been deleted  skipcommitfaultinjection  actionb1  execute  actionb2  faultinjection  1  services  fail  2  re  workflow action b2 should not have been deleted  workflowaction  org.apache.oozie.command.skipcommitfaultinjection  setsystemproperty  true   set fault injection to true  so transaction is roll backed  jpaservice  workflow job c should not have been deleted
__label__nflaky aaa  ccc  value1  xx   yy   zz  name8=xx\%2  c\%20\%20yy\%20\%20\%2  czz  result  name3  value  4!  name4  name5  assert  name4=  value\%204\%21  name6  name7=aaa&  name7=b\%2  cb&  name7=ccc  name7  assert  true  name2=  name8  price  get  b b  name1=  value1  name4=  value\%204\%21\%20\%214  name0  test  parse  url  coded  content  string  name1  name2  a  b\""c  bbb  name5=aaa&  name6=bbb  d  e  is  empty  assert  equals  name4=  value\%2  b4\%21  value+4!  parse  price=10\%20\%  e2\%82\%  ac  a=b\""c&d=e  assert  name  value  pair  size  parse  string  value  4!  !4  10  â‚¬    aaa  ccc  value1  xx   yy   zz  name8=xx\%2c\%20\%20yy\%20\%20\%2czz  result  name3  value 4!  name4  name5  assert  name4=value\%204\%21  name6  name7=aaa&name7=b\%2cb&name7=ccc  name7  asserttrue  name2=  name8  price  get  b b  name1=value1  name4=value\%204\%21\%20\%214  name0  testparseurlcodedcontentstring  name1  name2  a  b\""c  bbb  name5=aaa&name6=bbb  d  e  isempty  assertequals  name4=value\%2b4\%21  value+4!  parse  price=10\%20\%e2\%82\%ac  a=b\""c&d=e  assertnamevaluepair  size  parsestring  value 4! !4  10 â‚¬
__label__flaky oozie.launcher.action.main.class  set  setup  main  class  conf  assert  equals  test  setup  main  class  assert  null  launcher  mapper  the  passed  argument  (myclass1)  should  have  priority  get  org.blah.myclass2  org.blah.myclass1    oozie.launcher.action.main.class  set  setupmainclass  conf  assertequals  testsetupmainclass  assertnull  launchermapper   the passed argument (myclass1) should have priority  get  org.blah.myclass2  org.blah.myclass1
__label__nflaky another  message  get  name  get  outgoing  flash  cookie  data  yet  another  message  save  make  sure  the  old  cookue  gets  parsed:  get  cookie  when  put  setup  this  testmethod  but  the  old  has  disappeared  (flash  scope):  add  cookie  another+message=is+there...&yet+another+message=is+there...  cookie  captor  get  builder  context  verify  verify  some  stuff  on  the  set  cookie  flash  scope  cookie  init  test  that  flash  cookie  works  and  is  active  only  one  time  ninja_  flash  cookie  then  return  hello=flash  scope  flash  cookie  capture  assert  equals  get  value  size  build  is  there...  get  current  flash  cookie  data  a  cookie  will  be  set  =>  hello:flash  scope  ninja  properties  another message  getname  getoutgoingflashcookiedata  yet another message  save   make sure the old cookue gets parsed:  getcookie  when  put   setup this testmethod   but the old has disappeared (flashscope):  addcookie  another+message=is+there...&yet+another+message=is+there...  cookiecaptor  get  builder  context  verify   verify some stuff on the set cookie  flashscope  cookie  init  testthatflashcookieworksandisactiveonlyonetime  ninja_flash  cookie  thenreturn  hello=flashscope  flashcookie  capture  assertequals  getvalue  size  build  is there...  getcurrentflashcookiedata   a cookie will be set => hello:flashscope  ninjaproperties
__label__flaky end_  points  is_  security_  enabled  -action  oozie  url  assert  false  2009-12-15  t01:00  z  run  app  path  test  coord  re  run  neg4  get  -config  create  servlet_  classes  close  run  test  app  mock  coordinator  engine  service  coordinator.xml  create  config  file  get  context  url  assert  equals  get  file  system  -rerun  0  args  call  1  -date  -oozie  assert  null  mkdirs  to  string  job  get  fs  test  case  dir  end_points  is_security_enabled  -action  oozieurl  assertfalse  2009-12-15t01:00z  run  apppath  testcoordrerunneg4  get  -config  create  servlet_classes  close  runtest  app  mockcoordinatorengineservice  coordinator.xml  createconfigfile  getcontexturl  assertequals  getfilesystem  -rerun  0  args  call  1  -date  -oozie  assertnull  mkdirs  tostring  job  getfstestcasedir
__label__nflaky 3s  fin  latch  get  local  port  assert  false  run  conf  do  get  groups  server  sock  ldap://localhost:  await  ldap  url  count  down  hadoop  join  ldap  response  read  timed  out   timeout  used:  ldap  server  ignored  mapping  debug  print  stack  trace  e  log  ms  connection_  timeout  start  get  message  got  the  exception  while  ldap  querying:  test  ldap  connection  timeout  set  conf  accept  set  int  fail  contains  connection  timeout  ms  ne  assert  exception  contains  client  of  this  ldap  server  is  expected  to  get  a  connection  timeout.  the  ldap  query  should  have  timed  out!  get  base  conf  remaining  name   3s  finlatch  getlocalport  assertfalse  run  conf  dogetgroups  serversock  ldap://localhost:  await  ldapurl  countdown  hadoop  join  ldap response read timed out  timeout used:  ldapserver  ignored  mapping  debug  printstacktrace  e  log  ms  connection_timeout  start  getmessage  got the exception while ldap querying:   testldapconnectiontimeout  setconf  accept  setint  fail  contains  connectiontimeoutms  ne  assertexceptioncontains   client of this ldap server is expected to get a connection timeout.  the ldap query should have timed out!  getbaseconf  remaining name
__label__flaky reader  local  oozie  check  suspend  actions  conf  get  status  assert  not  null  decision1  create  workflow.xml  app  :start:  get  file  system  action4a  action4b  action4c  oozie  client  job  id  copy  char  stream  mkdirs  set  property  get  resource  as  reader  create  configuration  file  action1 nonexistant_action_name decision1   action3 join1   fork1 action4b  oozie.suspend.on.nodes  submit  get  job  info  fs  app  path  join1  wf  oc  end  workflow  job  close  resume  start  assert  equals  get  client  test  suspend  points  wf-suspendpoints.xml  io  utils  get  test  user  to  string  writer  action1  action2  action3  fork1  get  fs  test  case  dir  reader  localoozie  checksuspendactions  conf  getstatus  assertnotnull  decision1  create  workflow.xml  app  :start:  getfilesystem  action4a  action4b  action4c  oozieclient  jobid  copycharstream  mkdirs  setproperty  getresourceasreader  createconfiguration  file  action1 nonexistant_action_name decision1  action3 join1  fork1 action4b  oozie.suspend.on.nodes  submit  getjobinfo  fs  apppath  join1  wf  oc  end  workflowjob  close  resume  start  assertequals  getclient  testsuspendpoints  wf-suspendpoints.xml  ioutils  gettestuser  tostring  writer  action1  action2  action3  fork1  getfstestcasedir
__label__nflaky 1.0   2.0   3.0m  geo  1.0   2.0  geo:80.33 -32.3344 3.35  geo:1 2  geo:1 2 3  geography  parsed  result  type  do  test  result  test  geo  geo:1 2  80.33   -32.3344   3.35m  1.0  2.0  3.0m  geo  1.0  2.0  geo:80.33 -32.3344 3.35  geo:1 2  geo:1 2 3  geography  parsedresulttype  dotestresult  testgeo  geo:1 2  80.33  -32.3344  3.35m
__label__flaky play  ping  play  it  back  assert  false  client  pings  server  verify  the  peer  received  what  was  expected  assert  equals  to  nanos  accept  frame  send  frame  assert  true  peer  spdy3  round  trip  time  ping  frame  time  unit  type_  ping  ping  connection  payload2  ignored  in  spdy!  take  frame  play  ping   play it back  assertfalse  clientpingsserver   verify the peer received what was expected  assertequals  tonanos  acceptframe  sendframe  asserttrue  peer  spdy3  roundtriptime  pingframe  timeunit  type_ping   ping  connection   payload2 ignored in spdy!  takeframe
__label__nflaky dev  and  test  works.  /0/1/2/mode/dev/and/test  request  server  runs  in  test  mode.  this  route  is  dev  &  test.  core  matchers  equal  to  test  dev  and  test  mode012  assert  that  make  request  url  path  assert  response  get  test  server  url  dev and test works.  /0/1/2/mode/dev/and/test  request   server runs in test mode. this route is dev & test.  corematchers  equalto  testdevandtestmode012  assertthat  makerequest  url  path  assert  response  get  testserverurl
__label__flaky add  node  def  test  loop  fork  f  one  start  j  assert  equals  workflow  instance  get  status  three  two  as  list  wf  1  fail  ex  get  error  code  four  <worklfow-app/>  end  error  code  arrays  job  addnode  def  testloopfork  f  one  start  j  assertequals  workflowinstance  getstatus  three  two  aslist  wf  1  fail  ex  geterrorcode  four  <worklfow-app/>  end  errorcode  arrays  job
__label__nflaky prefix  declare  property  conf  run  string  out  config  some.config  some.config.value-  add  resource  xyz  join  value  add  set  value  of  test  concurrent  accesses  start  end  config  threads  start  config  t  file  resource  config  prefix  declareproperty  conf  run  string  out  config  some.config  some.config.value-  addresource  xyz  join  value  add  set  valueof  testconcurrentaccesses  start  endconfig  threads  startconfig  t  fileresource  config
__label__flaky init  get  name  set  get  conf  destroy  conf  services     as  list  services  assert  string  utils  assert  not  null  get  proxy  user  join  arrays  test  service  init  getname  set  getconf  destroy  conf  services     aslist  services  assert  stringutils  assertnotnull  get  proxyuser  join  arrays  testservice
__label__nflaky test  results  result  text  test  count  resolve  expected  text  get  rotation  print  the  results  of  all  tests  first  test  image  group  string  expected  text  file  source  decode  total  found  get  test  base  as  list  .bin  image  io  comparator  .txt  fine  assert  not  null  starting  image  group  \%s  bitmap  warning  results  test  base  info  \%d  of  \%d  images  passed  (\%d  required)  get  must  pass  count  get  key  image  result  metadata  read  entry  set  standard  charsets  get  text  try  harder  counts  rotate  image  format  sort  number  of  tests  +++  test  too  lax  by  \%d  images  get  file  id  size  decoded  \%d  images  out  of  \%d  (\%d\%\%   \%d  required)  to  file  rotation  file  id  ---  test  failed  by  \%d  images  arrays  test  result  file  id  log  rotated  image  assert  false  get  image  file  lists  image  files  get  segment  index  result  expected  text  rotation  \%d  degrees:  file  base  name  assert  true  image  file  get  read  file  as  string  degrees:  too  many  images  failed  files  passed  counts  key  set  rotation  try  harder   is  empty  assert  equals  label  total  must  pass  get  try  harder  count  test  black  box  \%d  of  \%d  images  passed  with  try  harder  (\%d  required)  total  tests  get  value  r  add  all  comparing  int  exists  get  meta  to  string  append  then  run  through  again  and  assert  if  any  failed  testresults  resulttext  testcount  resolve  expectedtext  getrotation   print the results of all tests first  testimagegroup  string  expectedtextfile  source  decode  totalfound  gettestbase  aslist  .bin  imageio  comparator  .txt  fine  assertnotnull  starting image group \%s  bitmap  warning  results  testbase  info   \%d of \%d images passed (\%d required)  getmustpasscount  getkey  image  resultmetadata  read  entryset  standardcharsets  gettext  tryhardercounts  rotateimage  format  sort  numberoftests  +++ test too lax by \%d images  getfileid  size  decoded \%d images out of \%d (\%d\%\%  \%d required)  tofile  rotation   fileid  --- test failed by \%d images  arrays  testresult  fileid  log  rotatedimage  assertfalse  getimagefilelists  imagefiles  getsegmentindex  result  expectedtext  rotation \%d degrees:  filebasename  asserttrue  imagefile  get  readfileasstring   degrees: too many images failed  files  passedcounts  keyset  rotation  try harder    isempty  assertequals  label  totalmustpass  gettryhardercount  testblackbox   \%d of \%d images passed with try harder (\%d required)  totaltests  getvalue  r  addall  comparingint  exists  getmeta  tostring  append   then run through again and assert if any failed
__label__flaky get  stats  get  console  url  set  job  id  set  execution  data  get  log  token  set  end  data  set  external  child  i  ds  set  pending  age  is  pending  get  status  get  external  id  system  console  url  assert  true  assert  not  null  action  set  pending  json  stats  id  signal  get  signal  value  get  data  tracker  uri  get  pending  age  get  job  id  set  start  data  get  properties  external  id  assert  equals  set  log  token  set  stats  get  external  status  execution  path  set  execution  path  get  execution  path  set  signal  value  workflow  action  external  status  job1 job2  get  external  child  i  ds  log  token  get  tracker  uri  test  action  getstats  getconsoleurl  setjobid  setexecutiondata  getlogtoken  setenddata  setexternalchildids  setpendingage  ispending  getstatus  getexternalid  system  consoleurl  asserttrue  assertnotnull  action  setpending  jsonstats  id  signal  getsignalvalue  getdata  trackeruri  getpendingage  getjobid  setstartdata  getproperties  externalid  assertequals  setlogtoken  setstats  getexternalstatus  executionpath  setexecutionpath  getexecutionpath  setsignalvalue  workflowaction  externalstatus  job1 job2  getexternalchildids  logtoken  gettrackeruri  testaction
__label__nflaky e  assert  false  get  properties  get  message  conf  is  reloaded  test  reload  not  quiet  should  not  have  got  here  fail  contains  assert  true  add  resource  to  string  set  quiet  mode  not  found  properties  not-a-valid-resource  e  assertfalse  getproperties  getmessage  conf  isreloaded  testreloadnotquiet  should not have got here  fail  contains  asserttrue  addresource  tostring  setquietmode  not found  properties  not-a-valid-resource
__label__flaky /test/test  get  file  block  locations  cluster  computed  f  expected  assert  equals  the  following  are  new  tests  (i.e.  not  over-riding  the  super  class  methods)  get  file  system  test  get  file  block  locations  fs  create  file  path  to  string  get  file  block  locations  /test/testgetfileblocklocations  cluster  computed  f  expected  assertequals   the following are new tests (i.e. not over-riding the super class methods)  getfilesystem  testgetfileblocklocations  fs  createfile  path  tostring  getfileblocklocations
__label__nflaky _index  io  exception  expected.  index  path  delete  set  owner  foo/bar  assert  create  har  file  system  set  permission  +rwx  group  har  path  test  negative  har  fs  modifications  root  path  foo  path  set  replication  +x  fail  mkdirs  local  file  system  start  local  output  create  new  file  user  all  the  modification  methods  of  har  fs  must  lead  to  ioe.  copy  from  local  file  complete  local  output  _index  ioexception expected.  indexpath  delete  setowner  foo/bar  assert  create  harfilesystem  setpermission  +rwx  group  harpath  testnegativeharfsmodifications  rootpath  foopath  setreplication  +x  fail  mkdirs  localfilesystem  startlocaloutput  createnewfile  user   all the modification methods of harfs must lead to ioe.  copyfromlocalfile  completelocaloutput
__label__flaky get  job  tracker  uri  <java-opt>  java-  opt2</java-opt>  mapred.child.java.opts  </configuration>  conf  <arg>  a2</arg>  context  action  java-  opt2  <job-tracker>  java-  opt1  action  conf  ae  parse  xml  </job-tracker>  create  launcher  conf  get  file  system  <name-node>  </name-node>  contains  get  type  <file>f.jar</file>  <property><name>a</name><value>  aa</value></property>  <java>  get  actions  test1  create  base  hadoop  conf  <java-opts>  java-  opt1  java-  opt2</java-opts>  action  xml  wf  bean  <job-xml>job.xml</job-xml>  add  record  to  wf  job  table  assert  true  get  <job-xml>job2.xml</job-xml>  <archive>a.tar</archive>  <property><name>oozie.launcher.a</name><value>  la</value></property>  get  name  node  uri  </java>  get  conf  xml  utils  <property><name>b</name><value>  bb</value></property>  <main-class>  main-  class</main-class>  <java-opt>  java-  opt1</java-opt>  <configuration>  set  type  set  conf  action  xmlconf  <arg>  a1</arg>  test  java  opts  getjobtrackeruri  <java-opt>java-opt2</java-opt>  mapred.child.java.opts  </configuration>  conf  <arg>a2</arg>  context  action  java-opt2  <job-tracker>  java-opt1  actionconf  ae  parsexml  </job-tracker>  createlauncherconf  getfilesystem  <name-node>  </name-node>  contains  gettype  <file>f.jar</file>  <property><name>a</name><value>aa</value></property>  <java>  getactions  test1  createbasehadoopconf  <java-opts>java-opt1 java-opt2</java-opts>  actionxml  wfbean  <job-xml>job.xml</job-xml>  addrecordtowfjobtable  asserttrue  get  <job-xml>job2.xml</job-xml>  <archive>a.tar</archive>  <property><name>oozie.launcher.a</name><value>la</value></property>  getnamenodeuri  </java>  getconf  xmlutils  <property><name>b</name><value>bb</value></property>  <main-class>main-class</main-class>  <java-opt>java-opt1</java-opt>  <configuration>  settype  setconf  actionxmlconf  <arg>a1</arg>  testjavaopts
__label__nflaky application/xml  test  that  content  negotiation  with  fallback  works  headers  get  server  address  accept  ninja  test  browser  new  hash  map  equal  to  person  is:  zeeess  name  -  and  some  utf8  =&gt;  Ã¶Ã¤Ã¼  assert  that  make  request  put  maps  text/html  response  application/unknown_content_type  api/person_with_content_negotiation_fallback  application/xml  testthatcontentnegotiationwithfallbackworks  headers  getserveraddress  accept  ninjatestbrowser  newhashmap  equalto  person is: zeeess name - and some utf8 =&gt; Ã¶Ã¤Ã¼  assertthat  makerequest  put  maps  text/html  response  application/unknown_content_type  api/person_with_content_negotiation_fallback
__label__flaky test  coord  action  get  last  modified  time  _  e  error  code  get  id  _test  get  for  info  date  utils  set  tracker  uri  app  path  set  error  code  parse  date  oozie  tz  resource  xml  name  action  xml  set  error  message  coord  action  nominal  time  console  url  sla  xml  pass  the  expected  values  coordinator  action  missing  deps  created  time  action  add  extra  attributes  for  action  set  created  time  action  num  tracker  uri  error  message  get  action  nominal  time  set  console  url  set  external  status  set  last  modified  time  set  missing  dependencies  add  record  to  coord  job  table  000  coordinator  job  create  coord  action  coord-action-get.xml  insert  the  action  set  sla  xml  insert  record  coord  action  external  status  job  get  coord  action  xml  dummy  get  fs  test  case  dir  testcoordactionget  lastmodifiedtime  _e  errorcode  getid  _testgetforinfo  dateutils  settrackeruri  apppath  seterrorcode  parsedateoozietz  resourcexmlname  actionxml  seterrormessage  coord  actionnominaltime  consoleurl  slaxml   pass the expected values  coordinatoraction  missingdeps  createdtime  action   add extra attributes for action  setcreatedtime  actionnum  trackeruri  errormessage  getactionnominaltime  setconsoleurl  setexternalstatus  setlastmodifiedtime  setmissingdependencies  addrecordtocoordjobtable  000  coordinatorjob  createcoordaction  coord-action-get.xml   insert the action  setslaxml  insertrecordcoordaction  externalstatus  job  getcoordactionxml  dummy  getfstestcasedir
__label__nflaky verify  zero  interactions  object  under  test  expected_  message  browser_  agent  send  error  when  filter  config  get  header  at  least  once  mock  chain  do  filter  verify  mock  res  init  mock  req  then  return  csrf  has  not  been  sent  objects  to  verify  interactions  based  on  request  http  servlet  response  setup  the  configuration  settings  of  the  server  filter  test  no  header  default  config  bad  request  get  init  parameter  mockito  mock  rest  csrf  prevention  filter  verifyzerointeractions   object under test  expected_message  browser_agent  senderror  when  filterconfig  getheader  atleastonce  mockchain  dofilter  verify  mockres  init  mockreq  thenreturn   csrf has not been sent   objects to verify interactions based on request  httpservletresponse   setup the configuration settings of the server  filter  testnoheaderdefaultconfigbadrequest  getinitparameter  mockito  mock  restcsrfpreventionfilter
__label__flaky 2015-01-02  t00:45  z  2016-01-02  t00:45  z  2014-01-02  t00:45  z  2012-01-02  t00:45  z  ${coord:offset(7   \""  hour\"")}  coord  el  functions  get  time  zone  ${coord:offset(-3   \""  hour\"")}  date  utils  parse  date  oozie  tz  set  frequency  ds  2015-01-02  t00:45  z  2015-02-02  t00:45  z  2014-12-02  t00:45  z  2014-10-01  t23:45  z  4.5  is  not  a  valid  integer  2010-01-02  t00:01  z  year  ${coord:offset(-26304   \""  hour\"")}  ${coord:offset(1   \""  month\"")}  ${coord:offset(-1096   \""  day\"")}  test  offset  time  unit  ${coord:offset(-24   \""  hour\"")}  ${coord:offset(-1   \""  day\"")}  init  2015-01-02  t00:01  z  2016-01-02  t00:01  z  2014-01-02  t00:01  z  2012-01-02  t00:01  z  ${coord:offset(-3   \""  minute\"")}  should  have  thrown  an  exception  ${coord:offset(5   \""  minute\"")}  set  init  instance  2015-01-02  t00:45  z  ${coord:offset(-36   \""  month\"")}  its  -1096  instead  of  -1095  because  of  dst  (extra  1  day)  2015-01-02  t00:01  z  ${coord:offset(-3   \""  year\"")}  ${coord:offset(-3   \""  day\"")}  2015-01-01  t20:01  z  app  inst  ${coord:offset(0   \""  minute\"")}  ${coord:offset(1   \""  minute\"")}  ${coord:offset(-1   \""  minute\"")}  ${coord:offset(0   \""  day\"")}  ${coord:offset(365   \""  day\"")}  ${coord:offset(-365   \""  day\"")}  fail  set  time  unit  ${coord:offset(-43825   \""  hour\"")}  contains  eval  ${coord:offset(0   \""  minute\"")}  ${coord:offset(525600   \""  minute\"")}  ${coord:offset(-525600   \""  minute\"")}  ${coord:offset(1   \""blah\"")}  evaluate  its  -1578240  instead  of  -1576800  because  of  dst  (extra  1440  minutes)  frequency  ${coord:offset(-1440   \""  minute\"")}  hour  unable  to  evaluate  ${coord:offset(1   \""  year\"")}  ${coord:offset(0   \""  hour\"")}  ${coord:offset(1   \""  hour\"")}  ${coord:offset(-1   \""  hour\"")}  ${coord:offset(-1578240   \""  minute\"")}  coord-action-create  month  ${coord:offset(0   \""  month\"")}  ${coord:offset(1   \""  month\"")}  ${coord:offset(-1   \""  month\"")}  eval  and  wrap  2010-09-09  t23:59  z  day  assert  true  ${coord:offset(1   \""  hour\"")}  2015-01-02  t00:45  z  2015-01-02  t00:46  z  2015-01-02  t00:44  z  2015-01-02  t00:42  z  set  time  zone  ${coord:offset(-10   \""  day\"")}  expr  its  -26304  instead  of  -26280  because  of  dst  (extra  24  hours)  eval  of  ${coord:offset(0   \""  day\"")}  ${coord:offset(1   \""  day\"")}  ${coord:offset(-1   \""  day\"")}  2015-01-02  t00:45  z  2015-01-03  t00:45  z  2015-01-01  t00:45  z  2014-12-30  t00:45  z  2009-09-08  t23:59  z  2009-10-09  t23:59  z  ${coord:offset(0   \""  year\"")}  ${coord:offset(1   \""  year\"")}  ${coord:offset(-1   \""  year\"")}  ${coord:offset(0   \""  hour\"")}  ${coord:offset(8760   \""  hour\"")}  ${coord:offset(-8760   \""  hour\"")}  set  nominal  time  ${coord:offset(-2   \""  hour\"")}  e  2015-01-02  t04:01  z  get  message  assert  equals  \""blah\""  is  not  a  valid  time  unit  america/  los_  angeles  ${coord:offset(0   \""  month\"")}  ${coord:offset(12   \""  month\"")}  ${coord:offset(-12   \""  month\"")}  minute  2015-01-02  t00:45  z  2015-01-02  t01:45  z  2015-01-01  t23:45  z  2015-01-01  t21:45  z  ${coord:offset(-3   \""  month\"")}  ${coord:offset(4.5   \""blah\"")}    2015-01-02t00:45z 2016-01-02t00:45z 2014-01-02t00:45z 2012-01-02t00:45z  ${coord:offset(7  \""hour\"")}  coordelfunctions  gettimezone   ${coord:offset(-3  \""hour\"")}  dateutils  parsedateoozietz  setfrequency  ds  2015-01-02t00:45z 2015-02-02t00:45z 2014-12-02t00:45z 2014-10-01t23:45z   4.5 is not a valid integer  2010-01-02t00:01z   year   ${coord:offset(-26304  \""hour\"")}  ${coord:offset(1  \""month\"")}   ${coord:offset(-1096  \""day\"")}  testoffset  timeunit  ${coord:offset(-24  \""hour\"")}  ${coord:offset(-1  \""day\"")}  init  2015-01-02t00:01z 2016-01-02t00:01z 2014-01-02t00:01z 2012-01-02t00:01z   ${coord:offset(-3  \""minute\"")}   should have thrown an exception  ${coord:offset(5  \""minute\"")}  setinitinstance  2015-01-02t00:45z   ${coord:offset(-36  \""month\"")}   its -1096 instead of -1095 because of dst (extra 1 day)  2015-01-02t00:01z   ${coord:offset(-3  \""year\"")}   ${coord:offset(-3  \""day\"")}  2015-01-01t20:01z  appinst  ${coord:offset(0  \""minute\"")} ${coord:offset(1  \""minute\"")} ${coord:offset(-1  \""minute\"")}  ${coord:offset(0  \""day\"")} ${coord:offset(365  \""day\"")} ${coord:offset(-365  \""day\"")}  fail  settimeunit  ${coord:offset(-43825  \""hour\"")}  contains  eval  ${coord:offset(0  \""minute\"")} ${coord:offset(525600  \""minute\"")} ${coord:offset(-525600  \""minute\"")}  ${coord:offset(1  \""blah\"")}  evaluate   its -1578240 instead of -1576800 because of dst (extra 1440 minutes)   frequency  ${coord:offset(-1440  \""minute\"")}   hour  unable to evaluate  ${coord:offset(1  \""year\"")}  ${coord:offset(0  \""hour\"")} ${coord:offset(1  \""hour\"")} ${coord:offset(-1  \""hour\"")}   ${coord:offset(-1578240  \""minute\"")}  coord-action-create   month  ${coord:offset(0  \""month\"")} ${coord:offset(1  \""month\"")} ${coord:offset(-1  \""month\"")}  evalandwrap  2010-09-09t23:59z   day  asserttrue  ${coord:offset(1  \""hour\"")}  2015-01-02t00:45z 2015-01-02t00:46z 2015-01-02t00:44z 2015-01-02t00:42z  settimezone  ${coord:offset(-10  \""day\"")}  expr   its -26304 instead of -26280 because of dst (extra 24 hours)  eval of   ${coord:offset(0  \""day\"")} ${coord:offset(1  \""day\"")} ${coord:offset(-1  \""day\"")}  2015-01-02t00:45z 2015-01-03t00:45z 2015-01-01t00:45z 2014-12-30t00:45z  2009-09-08t23:59z  2009-10-09t23:59z  ${coord:offset(0  \""year\"")} ${coord:offset(1  \""year\"")} ${coord:offset(-1  \""year\"")}  ${coord:offset(0  \""hour\"")} ${coord:offset(8760  \""hour\"")} ${coord:offset(-8760  \""hour\"")}  setnominaltime  ${coord:offset(-2  \""hour\"")}  e  2015-01-02t04:01z  getmessage  assertequals   \""blah\"" is not a valid timeunit  america/los_angeles  ${coord:offset(0  \""month\"")} ${coord:offset(12  \""month\"")} ${coord:offset(-12  \""month\"")}   minute  2015-01-02t00:45z 2015-01-02t01:45z 2015-01-01t23:45z 2015-01-01t21:45z   ${coord:offset(-3  \""month\"")}  ${coord:offset(4.5  \""blah\"")}
__label__nflaky conf  should  have  thrown  an  exception  here  as  list  test  entries  expire  if  background  refresh  fails  advance  timer  cache  groups  add  me  stops  throw  exceptions  get  groups  load  must  be  called  synchronously  as  there  is  no  key  present  common  configuration  keys  clear  black  list  groups  refresh  fake  group  mapping  assert  that  will  be  retrievable  until  it  is  evicted  after  about  10  seconds.  fail  set  long  my  groups  size  we  make  an  initial  request  to  populate  the  cache  set  throw  exception  now  make  all  calls  to  the  fake  group  mapper  throw  exceptions  arrays  is  equal  to  set  boolean  conf  should have thrown an exception here  aslist  testentriesexpireifbackgroundrefreshfails  advance  timer  cachegroupsadd  me   stops throw exceptions  getgroups   load must be called synchronously as there is no key present  commonconfigurationkeys  clearblacklist  groups  refresh  fakegroupmapping  assertthat   will be retrievable until it is evicted after about 10 seconds.  fail  setlong  mygroups  size   we make an initial request to populate the cache  setthrowexception   now make all calls to the fakegroupmapper throw exceptions  arrays  isequalto  setboolean
__label__flaky bab  add  record  to  bundle  action  table  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  job  assert  not  null  get  coordinator  action  end  current  date  plus  month  job  wait  for  add  record  to  bundle  job  table  bundle  id  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  with  bundle  services  coordinator  job  runnable  coord-action-get.xml  equals  action1  job  jpa  service  evaluate  test  bundle  status  transit  service  for  terminal  states  bab  addrecordtobundleactiontable  getcurrentdateafterincrementinginmonths  getid  run  dateutils  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordjob  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  job  waitfor  addrecordtobundlejobtable  bundleid  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtablewithbundle  services  coordinatorjob  runnable  coord-action-get.xml  equals  action1  job  jpaservice  evaluate  testbundlestatustransitserviceforterminalstates
__label__nflaky captured  \""this\""  get  impl  class  get  impl  method  name  replace  specific  instance  method  reference  get  canonical  name  invoke  get  kind  serialized  lambda  get  functional  interface  method  name  lambda  reflect  kind  get  serialized  lambda  get  functional  method  value  lambda  info  lambdas  apply  verify  it  can  be  dynamically  invoked  is  assert  that  l2s  string  value  =  (  string)lambda.get  class().get  method(\""apply\""   long.class).invoke(calc   1  l);  get  captured  arg  count  get  captured  arg  2  (  ljava/lang/  long;)  ljava/lang/  string;  calc  get  impl  method  signature   captured \""this\""  getimplclass  getimplmethodname  replace  specificinstancemethodreference  getcanonicalname  invoke  getkind  serializedlambda  getfunctionalinterfacemethodname  lambda  reflect  kind  getserializedlambda  getfunctionalmethod  value  lambdainfo  lambdas  apply   verify it can be dynamically invoked  is  assertthat  l2s   string value = (string)lambda.getclass().getmethod(\""apply\""  long.class).invoke(calc  1l);  getcapturedargcount  getcapturedarg  2  (ljava/lang/long;)ljava/lang/string;  calc  getimplmethodsignature
__label__flaky bundle  job  get  executor  add  record  to  bundle  job  table  test  bundle  start  dryrun  get  id  assert  equals  get  status  execute  call  sleep  services  size  assert  not  null  get  bundle  actions  get  executor  is  critical  job  job  get  bundle  id  jpa  service  actions  bundlejobgetexecutor  addrecordtobundlejobtable  testbundlestartdryrun  getid  assertequals  getstatus  execute  call  sleep  services  size  assertnotnull  get  bundleactionsgetexecutor  iscritical  job  job  getbundleid  jpaservice  actions
__label__nflaky expected  contents  build  test  base  resolve  get  result  metadata  test  image  reader  you  get  to  create  our  journal  prompt  for  the  day!  yay!  way  to  go!  source  very  basic  test  for  now  barcode  contents  image  io  result  you  earned  the  class  a  5  minute  dance  party!!  awesome!  way  to  go!  let\'s  boogie!  assert  not  null  bitmap  you  earned  the  class  5  extra  minutes  of  recess!!  fabulous!!  way  to  go!!  results  test  base  add  image  read  1.png  get  text  barcode  format  assert  equals  decode  multiple  src/test/resources/blackbox/multi-qrcode-1  you  get  to  sit  at  mrs.  sigmon\'  s  desk  for  a  day!!  awesome!!  way  to  go!!  guess  i  better  clean  up!  :)  abstract  black  box  test  case  get  barcode  format  to  file  test  multi  qr  codes  expectedcontents  buildtestbase  resolve  getresultmetadata  testimage  reader  you get to create our journal prompt for the day!  yay!  way to go!    source   very basic test for now  barcodecontents  imageio  result  you earned the class a 5 minute dance party!!  awesome!  way to go!  let\'s boogie!  assertnotnull  bitmap  you earned the class 5 extra minutes of recess!!  fabulous!!  way to go!!  results  testbase  add  image  read  1.png  gettext  barcodeformat  assertequals  decodemultiple  src/test/resources/blackbox/multi-qrcode-1  you get to sit at mrs. sigmon\'s desk for a day!!  awesome!!  way to go!! guess i better clean up! :)  abstractblackboxtestcase  getbarcodeformat  tofile  testmultiqrcodes
__label__flaky init  set  get  conf  _test  event  handler  service  assert  false  destroy  get  event  queue  conf  services  ehs  services  contains  event  handler  service  get  app  types  assert  true  check  default  initializations  workflow_job  get  is  enabled  coordinator_action  jobtypes  test  service    init  set  getconf  _testeventhandlerservice  assertfalse  destroy  geteventqueue  conf  services  ehs  services  contains  eventhandlerservice  getapptypes  asserttrue   check default initializations  workflow_job  get  isenabled  coordinator_action  jobtypes  testservice
__label__nflaky add  token  one  duplicate  with  different  value   one  new  get  secret  key  number  of  secret  keys  new  token  &  secret  should  be  added  assert  equals  secret  creds  non-duplicate  token  &  secret  should  be  present  get  bytes  token  merge  all  number  of  tokens  service  creds  to  add  get  token  add  secret  key  existing  token  &  secret  should  not  be  overwritten  addtoken   one duplicate with different value  one new  getsecretkey  numberofsecretkeys   new token & secret should be added  assertequals  secret  creds   non-duplicate token & secret should be present  getbytes  token  mergeall  numberoftokens  service  credstoadd  gettoken  addsecretkey   existing token & secret should not be overwritten
__label__flaky dummy  error  code  get  connection  context  get  event  message  end  date  conf  parse  date  utc  date  utils  get  status  set  error  code  wf-app-name1  set  error  message  get  end  time  ca  id1  test  on  workflow  job  failure  event  2012-07-22  t00:00  z  wf  id1  get  start  time  message  type  init  print  stack  trace  destroy  wf  event  listener  fail  on  workflow  job  event  create  consumer  app  type  start  date  get  parent  id  get  app  type  session  jms  messaging  utils  get  event  status  get  user  event  status  get  id  create  session  get  topic  get  error  code  workflow  job  jms  context  consumer  user1  get  message  type  receive  get  app  name  e  get  message  assert  equals  message  dummy  error  message  wfe  wf  fail  message  session  get  error  message  dummyerrorcode  getconnectioncontext  geteventmessage  enddate  conf  parsedateutc  dateutils  getstatus  seterrorcode  wf-app-name1  seterrormessage  getendtime  caid1  testonworkflowjobfailureevent  2012-07-22t00:00z  wfid1  getstarttime  messagetype  init  printstacktrace  destroy  wfeventlistener  fail  onworkflowjobevent  createconsumer  apptype  startdate  getparentid  getapptype  session  jmsmessagingutils  geteventstatus  getuser  eventstatus  getid  createsession  gettopic  geterrorcode  workflowjob  jmscontext  consumer  user1  getmessagetype  receive  getappname  e  getmessage  assertequals  message  dummyerrormessage  wfe  wffailmessage  session  geterrormessage
__label__nflaky get  payload  content  read  value  of  test  read  frame  partial  reads  get  stream  id  assert  equals  in  buffer  readable  channel  byte  buffer  remaining  frame  flag  assert  allocate  get  type  payload  assert  not  null  frame  type  of  get  get  flags  frame  getpayloadcontent  read  valueof  testreadframepartialreads  getstreamid  assertequals  inbuffer  readablechannel  bytebuffer  remaining  frameflag  assert  allocate  gettype  payload  assertnotnull  frametype  of  get  getflags  frame
__label__flaky cluster  write  xml  conf  /test  write  conf.xml  fs  setting  conf  in:  system  identity  hash  code  foobar  create  close  test  write  conf  dfs  config  keys  set  os  file  path  long  string  get  file  system  set  int  500  kb  io  utils  build  cleanup  num  data  nodes  to  string  shutdown  append  cluster  writexml  conf  /testwriteconf.xml  fs  setting conf in:   system  identityhashcode  foobar  create  close  testwriteconf  dfsconfigkeys  set  os  filepath  longstring  getfilesystem  setint   500kb  ioutils  build  cleanup  numdatanodes  tostring  shutdown  append
__label__nflaky set  name  user2  acl  parsed  list  fs  action  parsed  acl  not  correct  group1  acl  parse  acl  spec  set  permission  group::rwx user:user1:rwx user:user2:rw-   basic  acl  user1  add  user2  acl  entry  scope  acl  entry  type  expected  list  acl  entry  user1  acl  assert  equals  set  type  group:group1:rw- default:group:group1:rw-  group1  build  default  acl  set  scope  test  multiple  acl  spec  parsing  setname  user2acl  parsedlist  fsaction  parsed acl not correct  group1acl  parseaclspec  setpermission  group::rwx user:user1:rwx user:user2:rw-   basicacl  user1  add  user2  aclentryscope  aclentrytype  expectedlist  aclentry  user1acl  assertequals  settype  group:group1:rw- default:group:group1:rw-  group1  build  defaultacl  setscope  testmultipleaclspecparsing
__label__flaky authenticate  is  authenticated  test  authenticate  user  was  not  created  result  authentication  provider  password  find  ldap  user  by  name  assert  null  user  alread  exists  in  db  assert  true  assert  not  null  user  dao  allowed  user  authentication  authenticate  isauthenticated  testauthenticate  user was not created  result  authenticationprovider  password  findldapuserbyname  assertnull  user alread exists in db  asserttrue  assertnotnull  userdao  alloweduser  authentication
__label__nflaky add  stat  max  sample  stat  num  samples  assert  equals  epsilon  min  variance  num  samples  mean  reset  test  simple  stddev  add  stat  max  samplestat  num samples  assertequals  epsilon  min  variance  numsamples  mean  reset  testsimple  stddev
__label__flaky msg  hcat.topic1  dt=20120101;country=us;state=  ca  create  text  message  create  producer  get  waiting  actions  test  cache  update  by  message  h  cat  constants  get  available  dependency  ur  is  construct  message  exception:  dt=20120101;country=us;state=  ny  1234465454  json  msg  1234465452  1234465453  register  for  notification  add  get  server  test  message  processing  through  jms  notification  listener  print  stack  trace  hcat  service  hcat.server.com:5080  dep3  dep4  dep1  dep2  pdms  get  db  h  cat  event  message  action  id2  fail  action  id1  action  id4  contains  action  id3  hcat://hcat.server.com:5080/mydb/mytbl/dt=20120102;country=us;state=  ca  get  table  hcat  handler  topic  producer  get  partition  map  add  partition  as  missing  send  get  uri  set  string  property  thrift://  session  system  sleep  assert  true  get  hcat://hcat.server.com:5080/mydb/mytbl/country=us;dt=20120101  add  missing  dependency  process  hcat://hcat.server.com:5080/mydb/mytbl/dt=20120101;country=us  create  topic  e  1234465451  clear  get  message  test  message  processing  partitions  list  dt=20120102;country=us;state=  ny  thread  services  assert  null  current  time  millis  to  string  dt=20120102;country=us;state=  ca  hcat://hcat.server.com:5080/mydb/mytbl/dt=20120102;country=us    msg  hcat.topic1  dt=20120101;country=us;state=ca  createtextmessage  createproducer  getwaitingactions  testcacheupdatebymessage  hcatconstants  getavailabledependencyuris   construct message  exception:   dt=20120101;country=us;state=ny  1234465454  jsonmsg  1234465452  1234465453  registerfornotification  add  getserver   test message processing through jms notification listener  printstacktrace  hcatservice  hcat.server.com:5080  dep3  dep4  dep1  dep2  pdms  getdb  hcateventmessage  actionid2  fail  actionid1  actionid4  contains  actionid3  hcat://hcat.server.com:5080/mydb/mytbl/dt=20120102;country=us;state=ca  gettable  hcathandler  topic  producer  getpartitionmap   add partition as missing  send  geturi  setstringproperty  thrift://  session  system  sleep  asserttrue  get  hcat://hcat.server.com:5080/mydb/mytbl/country=us;dt=20120101  addmissingdependency  process  hcat://hcat.server.com:5080/mydb/mytbl/dt=20120101;country=us  createtopic  e  1234465451  clear  getmessage   test message processing  partitionslist  dt=20120102;country=us;state=ny  thread  services  assertnull  currenttimemillis  tostring  dt=20120102;country=us;state=ca  hcat://hcat.server.com:5080/mydb/mytbl/dt=20120102;country=us
__label__nflaky charset  content  type  text/blah;  p=blah  get  charset  that  this  and  that  assert  test  with  params  create  text/blah;  charset=  iso-8859-1;  p=blah  content  type  ascii  text/plain  blah  get  mime  type  text/plain;  charset=  utf-8;  p=this;  p=that  standard  charsets  utf-8  this  text/blah  assert  equals  p  text/plain;  charset=ascii;  p=\""this  and  that\""  with  parameters  to  string  charset  contenttype  text/blah; p=blah  getcharset  that  this and that  assert  testwithparams  create  text/blah; charset=iso-8859-1; p=blah  contenttype  ascii  text/plain  blah  getmimetype  text/plain; charset=utf-8; p=this; p=that  standardcharsets  utf-8  this  text/blah  assertequals  p  text/plain; charset=ascii; p=\""this and that\""  withparameters  tostring
__label__flaky check  coord  action  add  init  records  get  available  dependency  ur  is  partition  available  available  ur  is  assert  true  get  coordinator  action  mydb  hcat  uri  new  h  cat  dependency  add  missing  dependency  hcat.server.com:5080  assert  equals  pdms  call  services  contains  src=search;datastamp=12;region=us  assert  null  size  test  update  coord  table  basic  action  id  clicks  get  partition  map  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us    checkcoordaction  addinitrecords  getavailabledependencyuris  partitionavailable  availableuris  asserttrue  get  coordinatoraction  mydb  hcaturi  newhcatdependency  addmissingdependency  hcat.server.com:5080  assertequals  pdms  call  services  contains  src=search;datastamp=12;region=us  assertnull  size  testupdatecoordtablebasic  actionid  clicks  getpartitionmap  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us
__label__nflaky set  authentication  method  get  current  user  test  test  auth  method  ugi  get  authentication  method  values  get  auth  method  assert  equals  authentication  method  am  verify  the  reverse  mappings  works  user  group  information  setauthenticationmethod  getcurrentuser  testtestauthmethod  ugi  getauthenticationmethod  values  getauthmethod  assertequals  authenticationmethod  am   verify the reverse mappings works  usergroupinformation
__label__flaky job  conf  bundle  job  get  cmd  log  submit  cmd  get  id  get  status  app  path  configuration  parse  error.  read  from  db  :  get  job  test  bundle  suspend3  assert  not  null  get  get  auth  token  job  set  get  conf  add  record  to  bundle  job  table  assert  equals  execute  bundle.xml  call  services  warn  oozie  client  to  string  error  code  job  jpa  service  ioe  jobconf  bundlejobgetcmd  log  submitcmd  getid  getstatus  apppath  configuration parse error. read from db :  getjob  testbundlesuspend3  assertnotnull  get  getauthtoken  job  set  getconf  addrecordtobundlejobtable  assertequals  execute  bundle.xml  call  services  warn  oozieclient  tostring  errorcode  job  jpaservice  ioe
__label__nflaky add  test  directory  test  file  path  data  get  path  data  ls  options  -e  process  options  process  arguments  process  path  file  display  ec  policy  when  unsupported  add  testdirectory  testfile  pathdata  getpathdata  ls  options  -e  processoptions  processarguments  processpathfiledisplayecpolicywhenunsupported
__label__flaky play  a  server  read  ascii  add  header  b  open  connection  foo  vary  matches  removed  request  header  field  assert  equals  set  body  add  request  property  /  enqueue  get  url  bar  cache-  control:  max-age=60  vary:  foo  foo  connection  play  a  server  readascii  addheader  b  openconnection  foo  varymatchesremovedrequestheaderfield  assertequals  setbody  addrequestproperty  /  enqueue  geturl  bar  cache-control: max-age=60  vary: foo  fooconnection
__label__nflaky assert  assert  true  exists  jar  picking  a  class  that  is  for  sure  in  a  jar  in  the  classpath  get  jar  jar  finder  test  jar  assert  asserttrue  exists  jar   picking a class that is for sure in a jar in the classpath  getjar  jarfinder  testjar
__label__flaky test  that  sla  processes  the  job  event  from  kill  command  sla  event  conf  run  poll  date  utils  get  cmd  as  list  run  sla  worker  for  start_miss  assert  not  null  get  resource  as  string  unit_  testing  coordinator  action  coordinator_action  action  time  for  event  listeners  to  run  coord  action  workflow.xml  get  actual  start  set  time  add  get  alert  events  set  start  processed  expected  end  coord  xml  get  job  id  get  sla  status  waiting  for  materialize  command  to  run  get  event  queue  sla  status  write  cmd  execute  get  expected  end  ehs  oozie  client  job  id  format  date  oozie  tz  name  action  id  arrays  app  type  get  app  type  test-coord-sla  resetting  flag  for  testing  sla  event  get  expected  duration  get  actual  end  get  time  get  event  status  event  status  expected  start  get  id  get  expected  start  app  path  clear  the  coord-action  waiting  event  generated  test  coordinator  action  commands  set  app  types  cal  sc  sleep  write  to  file  test  that  sla  processes  the  job  event  from  start  command  nominal  get  wf-credentials.xml  jpa  workflow  job  nominal_time  command  coordinator.xml  nominal  time  get  app  name  alert_events  get  job  status  set  app  name  calendar  clear  authtoken  assert  equals  services  get  sla  calculator  get  nominal  time  set  status  thread  call  coord-action-sla.xml  @1  io  utils  get  test  user  wf  xml  to  string  as  per  the  sla  xml  wf  app  path  slas  get  fs  test  case  dir   test that sla processes the job event from kill command  slaevent  conf  run  poll  dateutils  getcmd  aslist  runslaworker   for start_miss  assertnotnull  getresourceasstring  unit_testing  coordinatoraction  coordinator_action  action   time for event listeners to run   coord action  workflow.xml  getactualstart  settime  add  getalertevents  setstartprocessed  expectedend  coordxml  getjobid  getslastatus   waiting for materialize command to run  geteventqueue  slastatus  writecmd  execute  getexpectedend  ehs  oozieclient  jobid  formatdateoozietz  name  actionid  arrays  apptype  getapptype  test-coord-sla   resetting flag for testing sla event  getexpectedduration  getactualend  gettime  geteventstatus  eventstatus  expectedstart  getid  getexpectedstart  apppath   clear the coord-action waiting event generated  testcoordinatoractioncommands  setapptypes  cal  sc  sleep  writetofile   test that sla processes the job event from start command  nominal  get  wf-credentials.xml  jpa  workflowjob  nominal_time   command  coordinator.xml  nominaltime  getappname  alert_events  getjobstatus  set  appname  calendar  clear  authtoken  assertequals  services  getslacalculator  getnominaltime  setstatus  thread  call  coord-action-sla.xml  @1  ioutils  gettestuser  wfxml  tostring   as per the sla xml  wfapppath  slas  getfstestcasedir
__label__nflaky result  not  important  test  that  get  forbidden  request  content  negotiation  ninja  default  get  forbidden  result  size  context  impl  supported  content  types  equal  to  get  content  type  assert  that  result  not important  testthatgetforbiddenrequestcontentnegotiation  ninjadefault  getforbiddenresult  size  contextimpl  supportedcontenttypes  equalto  getcontenttype  assertthat
__label__flaky generate  event  create  event  with  error  code  and  message  get  event  status  event  status  error  code  get  id  assert  equals  poll  workflow  instance  test  workflow  job  event  error  execute  error  msg  call  add  record  to  wf  job  table  get  error  code  my  cmd  assert  not  null  workflow  job  job  event  queue  workflow  x  command  get  error  message  generateevent   create event with error code and message  geteventstatus  eventstatus  errorcode  getid  assertequals  poll  workflowinstance  testworkflowjobeventerror  execute  errormsg  call  addrecordtowfjobtable  geterrorcode  mycmd  assertnotnull  workflowjob  job  event  queue  workflowxcommand  geterrormessage
__label__nflaky set  trim  test_  ldap_  url  test  get  groups  with  default  base  dn  do  test  get  groups  with  base  dn  conf  dc=xxx dc=com  base  dn  get  base  conf  ldap  groups  mapping  set  trim  test_ldap_url  testgetgroupswithdefaultbasedn  dotestgetgroupswithbasedn  conf   dc=xxx dc=com   basedn  getbaseconf  ldapgroupsmapping
__label__flaky init  res  hcat://hcat.server.com:5080/mydb/clicks/datastamp=10;region=us  hcat://hcat.server.com:5080/mydb/clicks/datastamp=20;region=us   coord  el  functions  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us   hcat://hcat.server.com:5080/mydb/clicks/datastamp=13;region=us   .datain.  abc.unresolved  set  variable  coord-action-start  ${coord:data  in  partition  max(\'  abc\' \'datastamp\')}  test  data  in  partition  max  eval  eval  and  wrap  assert  true  equals  .datain.  abc  expr  boolean  20  init  res  hcat://hcat.server.com:5080/mydb/clicks/datastamp=10;region=us  hcat://hcat.server.com:5080/mydb/clicks/datastamp=20;region=us   coordelfunctions  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us   hcat://hcat.server.com:5080/mydb/clicks/datastamp=13;region=us   .datain.abc.unresolved  setvariable  coord-action-start  ${coord:datainpartitionmax(\'abc\' \'datastamp\')}  testdatainpartitionmax  eval  evalandwrap  asserttrue  equals  .datain.abc  expr  boolean  20
__label__nflaky get  dynamic  entry  test  request  decoding  with  huffman  rfc7541  examples  assert  header  equals  no-cache  dynamic  table  custom-value  get  current  size  assert  :scheme  get  https  cache-control  :authority  custom-key  standard  charsets  create  byte  buffer  assert  equals  headers2  decoder  headers3  headers1  www.example.com  /  size  :method  get  src1  decode  headers  http  :path  src3  src2  /index.html  dynamic  length  getdynamicentry  testrequestdecodingwithhuffmanrfc7541examples  assertheaderequals  no-cache  dynamictable  custom-value  getcurrentsize  assert  :scheme  get  https  cache-control  :authority  custom-key  standardcharsets  createbytebuffer  assertequals  headers2  decoder  headers3  headers1  www.example.com  /  size  :method  get  src1  decodeheaders  http  :path  src3  src2  /index.html  dynamiclength
__label__flaky get  time  check  coordinators  date  utils  parse  date  oozie  tz  job  id3  insert  job  job  id2  job  id1  assert  not  null  job  id5  get  job  id4  00002-  get  the  next  3  (though  there\'s  only  2  more)  00004-  get  the  first  3  2011-01-01  t01:00  z  assert  equals  list  execute  services  coordinator  job  -  test  coord  jobs  get  for  purge  jpa  executor-  c  size  add  all  00003-  00005-  jpa  service  00001-  test  coord  jobs  get  for  purge  jpa  executor  too  many  gettime  checkcoordinators  dateutils  parsedateoozietz  jobid3  insertjob  jobid2  jobid1  assertnotnull  jobid5  get  jobid4  00002-   get the next 3 (though there\'s only 2 more)  00004-   get the first 3  2011-01-01t01:00z  assertequals  list  execute  services  coordinatorjob  -testcoordjobsgetforpurgejpaexecutor-c  size  addall  00003-  00005-  jpaservice  00001-  testcoordjobsgetforpurgejpaexecutortoomany
__label__nflaky conf  seek  system  hadoop-1489  now  read  the  file  for  io  buf  size  bytes  assert  true  test_  root_  dir  file  system  get  len  get  file  status  read  close  write  file  read  4  more  bytes  before  marking  bytes.  read  in  first  create  a  test  input  file.  io.file.buffer.size  set  int  file  pos  test  file  seek  beyond  data  buffered  by  open  marked  io  buf  size  file  size  get  local  file  sys  file  size=  exists  hence  won\'t  trigger  this  bug.  try  to  read  the  rest  test  truncated  input  bug  open  mark  conf  seek  system  hadoop-1489   now read the file for iobufsize bytes  asserttrue  test_root_dir  filesystem  getlen  getfilestatus  read   close  writefile   read 4 more bytes before marking   bytes.  read  in   first create a test input file.  io.file.buffer.size  setint  filepos  testfile   seek beyond data buffered by open  marked  iobufsize  filesize  getlocal  filesys   file size=  exists   hence won\'t trigger this bug.   try to read the rest  testtruncatedinputbug  open  mark
__label__flaky check  coord  jobs  <coordinator-app  name=\""  name\""  frequency=\""10\""  start=\""2009-02-01  t01:00  z\""  end=\""2009-02-03  t23:59  z\""  timezone=\""  utc\""  conf  app  path  substring  sc  write  to  file  app  xml  file://  get  test  case  dir  unit_  testing  <controls>  <timeout>10</timeout>  <concurrency>2</concurrency>  xmlns=\""uri:oozie:coordinator:0.2\"">  <configuration>  <property>  <name>input  a</name>  <value>blah</value>  </property>  coordinator.xml  test  submit  no  datasets  set  length  assert  equals  </configuration>  </workflow>  </action>  </coordinator-app>  call  oozie  client  job  id  get  test  user  -  c  <action>  <workflow>  <app-path>hdfs:///tmp/workflows/</app-path>  file  <execution>  lifo</execution>  </controls>  checkcoordjobs  <coordinator-app name=\""name\"" frequency=\""10\"" start=\""2009-02-01t01:00z\"" end=\""2009-02-03t23:59z\"" timezone=\""utc\""   conf  apppath  substring  sc  writetofile  appxml  file://  gettestcasedir  unit_testing  <controls> <timeout>10</timeout> <concurrency>2</concurrency>   xmlns=\""uri:oozie:coordinator:0.2\"">   <configuration> <property> <name>inputa</name> <value>blah</value> </property>   coordinator.xml  testsubmitnodatasets  set  length  assertequals  </configuration> </workflow> </action> </coordinator-app>  call  oozieclient  jobid  gettestuser  -c  <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>   file  <execution>lifo</execution> </controls>
__label__nflaky test  retry  decision  ordering  assert  assert  true  compare  to  retry  policy  testretrydecisionordering  assert  asserttrue  compareto  retrypolicy
__label__flaky dfs  config  keys  test  crc  corruption  with  specific  parameters  util1  conf2  conf1  system  set  int  test  crc  corruption  util2  thistest  test  crc  corruption  test  crc  corruption  with  default  parameters     dfsconfigkeys  testcrccorruption with specific parameters  util1  conf2  conf1  system  setint  testcrccorruption  util2  thistest  testcrccorruption  testcrccorruption with default parameters
__label__nflaky verify  zero  interactions  get  template  then  return  secure  filter  test  unauthenticated  session  session  cookie  ninja  constant  assert  equals  when  filter  chain  result  filter  basic  auth  filter  get  context  get  session  filter  that  verifyzerointeractions  gettemplate  thenreturn  securefilter  testunauthenticatedsession  sessioncookie  ninjaconstant  assertequals  when  filterchain  result  filter  basicauthfilter  get  context  getsession   filter that
__label__flaky application/xml  application/xml;  param=x  application/json  test  content  type  json  cron  my  json  rest  servlet  http  servlet  response  invoke  assert  equals  json=object  call  contains  assert  true  array  response  get  invoke  and  get  response  json=array  run  test  object    application/xml  application/xml; param=x  application/json  testcontenttypejsoncron  myjsonrestservlet  httpservletresponse  invoke  assertequals  json=object  call  contains  asserttrue  array  response  get  invokeandgetresponse  json=array  runtest  object
__label__nflaky add  test  delegation  token  selector  some  user1  some  user2  select  token  job  tracker  unchecked  my-  service1  my-  service2  assert  equals  stop  threads  ds  generate  delegation  token  set  service  creates  a  collection  of  tokens  assert  t  kind  dt  secret  manager  token1  token2  start  threads  tokens  try  to  select  a  token  with  a  given  service  name  (created  earlier)  add  testdelegationtokenselector  someuser1  someuser2  selecttoken  jobtracker  unchecked  my-service1  my-service2  assertequals  stopthreads  ds  generatedelegationtoken  setservice   creates a collection of tokens  assert  t  kind  dtsecretmanager  token1  token2  startthreads  tokens   try to select a token with a given service name (created earlier)
__label__flaky cluster  name  node  to  include  a  port  number.  fs2  ha  test  util  conf  test  dfs  client  failover  with  port  fs  create  file  hdfs://  transition  to  active  assert  true  get  len  get  file  status  get  path  close  dfs  test  util  get  conf  to  uri  assert  equals  get  file  system  configure  failover  fs  shutdown  name  node  /  file_  length_  to_  verify  test_  file  get  logical  hostname  exists  :  cluster  namenode   to include a port number.  fs2  hatestutil  conf  testdfsclientfailover  withport  fs  createfile  hdfs://  transitiontoactive  asserttrue  getlen  getfilestatus  getpath  close  dfstestutil  getconf  touri  assertequals  getfilesystem  configurefailoverfs  shutdownnamenode  /  file_length_to_verify  test_file  getlogicalhostname  exists  :
__label__nflaky null  service  from  stop  service  assert  not  null  launch  service  test  launch  service  get  service  launcher  null service from   stop  service  assertnotnull  launchservice  testlaunchservice  getservice  launcher
__label__flaky action  num  test  coord  action  get  job2  job1  get  id  add  record  to  coord  action  table  _test  coord  action  get  by  last  modified  time  add  record  to  coord  job  table  coordinator  job  job  id2  job  id1  coord-action-get.xml  date  before  action  get  date  before  action  is  created  coordinator  action  add  two  jobs  with  lastmodifiedtime  >  date  before  action  actionnum  testcoordactionget  job2  job1  getid  addrecordtocoordactiontable  _testcoordactiongetbylastmodifiedtime  addrecordtocoordjobtable  coordinatorjob  jobid2  jobid1  coord-action-get.xml  datebeforeaction   get date before action is created  coordinatoraction   add two jobs with lastmodifiedtime > datebeforeaction
__label__nflaky caught  no  exception  was  raised  get  caught  start  cause  get  cause  thread  in  exception  diagnostics.  sleep  assert  assert  true  assert  not  null  test  interrupted  wait  for  proxy  interrupt  join  worker  no  inner  cause   use  outer  exception  as  root  cause.  worker  hasn\'t  started  caught  no exception was raised  getcaught  start  cause  getcause  thread   in exception diagnostics.  sleep  assert  asserttrue  assertnotnull  testinterruptedwaitforproxy  interrupt  join  worker   no inner cause  use outer exception as root cause.  worker hasn\'t started
__label__flaky test  copy  on  write  cluster  get  local  block  conf  dn  get  file  create  file  simulated  storage  .link  get  namenode  hard  link  unlink  block  localhost  test  copy  on  write  detaching  block  get  block  pool  id  get  file  system  stm  size  long  get  name  node  port  simulated  fs  dataset  shutdown  create  hard  link  /filestatus.dat  get  block  locations  get  located  blocks  link  fs  system  should  have  returned  true  assert  true  list  data  nodes  get  should  have  returned  false  client  addr  close  write  file  get  block  b  blocks  f  append  test  util  get  a  handle  to  the  datanode  build  to  creating  hardlink  for  file  to  string  locations  file1  there  should  be  only  one  datanode  but  found  detaching  block  dataset  set  boolean  testcopyonwrite  cluster  getlocalblock  conf  dn  getfile  createfile  simulatedstorage  .link  getnamenode  hardlink  unlinkblock  localhost     testcopyonwrite detaching block   getblockpoolid  getfilesystem  stm  size  long  getnamenodeport  simulatedfsdataset  shutdown  createhardlink  /filestatus.dat  getblocklocations  getlocatedblocks  link  fs  system   should have returned true  asserttrue  listdatanodes  get   should have returned false  client  addr  close  writefile  getblock  b  blocks  f  appendtestutil   get a handle to the datanode  build   to   creating hardlink for file   tostring  locations  file1  there should be only one datanode but found   detaching block   dataset  setboolean
__label__nflaky equals  assert  false  not  equals  test  all  combinations  of  not  equals  result  equals  assertfalse  notequals   test all combinations of not equals  result
__label__flaky get  connection  context  test  coordinator  action  selectors  negative  cae  session  coord  event  listener  conf  parse  date  utc  date  utils  create  session  get  topic  wf-app-name1  on  coordinator  action  event  ca  job  id1  ca  id1  coordinator  action  2012-07-22  t00:00  z  selector  jms  context  =\'  non_matching_user\'  consumer  2011-07-11  t00:00  z  user1  init  nominal  time  receive  print  stack  trace  e  pass  a  selector  which  wont  match  and  assert  for  null  message  get  message  message  fail  assert  null  jms  header  constants  create  consumer  start  date  session  getconnectioncontext  testcoordinatoractionselectorsnegative  cae  session  coordeventlistener  conf  parsedateutc  dateutils  createsession  gettopic  wf-app-name1  oncoordinatoractionevent  cajobid1  caid1  coordinatoraction  2012-07-22t00:00z  selector  jmscontext  =\'non_matching_user\'  consumer  2011-07-11t00:00z  user1  init  nominaltime  receive  printstacktrace  e   pass a selector which wont match and assert for null message  getmessage  message  fail  assertnull  jmsheaderconstants  createconsumer  startdate  session
__label__nflaky test  root  dir  set  get  conf  run  dummyauth  passing  dummy  such  that  it  should  through  iae  ugi  params  should  take  effect  when  we  pass.  common  configuration  keys  public  test  list  with  ugi  -ls  fs  shell  ls  argv  to  string  testrootdir  set  getconf  run  dummyauth   passing dummy such that it should through iae      ugi params should take effect when we pass.     commonconfigurationkeyspublic  testlistwithugi  -ls  fsshell  lsargv  tostring
__label__flaky play  ping  android  play  it  back  header  entries  verify  the  peer  received  what  was  expected  stream_  in_  use  type_  rst_  stream  cola  stream  was  reset:  stream_  in_  use  accept  frame  stream  type_  headers  peer  get  response  headers  round  trip  time  type_  ping  connection  ensure  that  the  2nd  syn  reply  has  been  received.  take  frame  rst  stream  banana  a  b  syn  reply  c  read  expected  get  message  assert  equals  rst_  stream  headers  mode  fail  syn_  stream  send  frame  spdy3  get  source  ping  syn  stream  remote  double  syn  reply  new  stream  play  ping  android   play it back  headerentries   verify the peer received what was expected  stream_in_use  type_rst_stream  cola  stream was reset: stream_in_use  acceptframe  stream  type_headers  peer  getresponseheaders  roundtriptime  type_ping  connection   ensure that the 2nd syn reply has been received.  takeframe  rststream  banana  a  b  synreply  c  read  expected  getmessage  assertequals   rst_stream  headersmode  fail   syn_stream  sendframe  spdy3  getsource   ping  synstream  remotedoublesynreply  newstream
__label__nflaky get  bytes  transferred  a  lot  more  stuff!  rw  stuff;  codec  test  utils  more  stuff;  channel  assert  inbuf  get  channel  pos  test  basic  decoding  file  stuff;  more  stuff;  a  lot  more  stuff!  close  fchannel  is  completed  testfile  standard  charsets  length  bytes  read  create  temp  file  assert  equals  decoder  transfer  read  from  file  metrics  getbytestransferred  a lot more stuff!  rw  stuff;   codectestutils  more stuff;   channel  assert  inbuf  getchannel  pos  testbasicdecodingfile  stuff; more stuff; a lot more stuff!  close  fchannel  iscompleted  testfile  standardcharsets  length  bytesread  createtempfile  assertequals  decoder  transfer  readfromfile  metrics
__label__flaky bundle  job  get  cmd  add  record  to  bundle  job  table  get  id  assert  equals  get  status  execute  call  services  test  bundle  suspend1  assert  not  null  get  job  job  jpa  service  bundlejobgetcmd  addrecordtobundlejobtable  getid  assertequals  getstatus  execute  call  services  testbundlesuspend1  assertnotnull  get  job  job  jpaservice
__label__nflaky test  jvm  metrics  singleton  with  same  process  name  assert  test  jvm  metrics1  init  singleton  should  return  the  singleton  instance  jvm  metrics2  assert  equals  init  singleton  testjvmmetricssingletonwithsameprocessname  assert  test  jvmmetrics1  initsingleton should return the singleton instance  jvmmetrics2  assertequals  initsingleton
__label__flaky coordinator  job  _test  get  job  info  for  user  test  coord  jobs  get  _test  get  jobs  for  app  name  _test  get  jobs  for  status  _test  get  jobs  for  group  add  record  to  coord  job  table  _test  get  jobs  for  user  and  status  coordinatorjob  _testgetjobinfoforuser  testcoordjobsget  _testgetjobsforappname  _testgetjobsforstatus  _testgetjobsforgroup  addrecordtocoordjobtable  _testgetjobsforuserandstatus
__label__nflaky init  queue_  time  cost  provider  lockfree  weight  foo  foo.weighted-cost.lockfree  expected  cost  conf  default_  lockexclusive_  weight  assert  equals  bar.weighted-cost.lockexclusive  lockfree_  time  lockshared_  time  set  int  queue  weight  foo.weighted-cost.queue  processing  details  foo.weighted-cost.lockshared  test  get  cost  configured  weights  lockshared  weight  lockexclusive_  time  get  cost  should  not  apply  actual  cost  init  queue_time  costprovider  lockfreeweight  foo  foo.weighted-cost.lockfree  expectedcost  conf  default_lockexclusive_weight  assertequals  bar.weighted-cost.lockexclusive  lockfree_time  lockshared_time  setint  queueweight  foo.weighted-cost.queue  processingdetails  foo.weighted-cost.lockshared  testgetcostconfiguredweights  locksharedweight  lockexclusive_time  getcost   should not apply  actualcost
__label__flaky server  logger  assert  false  add  init  records  logger  test  log  message  prefix  out  default  add  appender  assert  true  tablename  new  h  cat  dependency    table  populate  table  hcat://  get  logger  appender  action  /  layout  call  action  id2  action  id1  contains  /dt=20120430;country=brazil  reset  to  string  db  server  logger  assertfalse  addinitrecords  logger  testlogmessageprefix  out  default  addappender  asserttrue  tablename  newhcatdependency    table  populatetable  hcat://  getlogger  appender  action  /  layout  call  actionid2  actionid1  contains  /dt=20120430;country=brazil  reset  tostring  db
__label__nflaky prepare  test  coding  direct  buffer_6x3_erasing_d0_p0  test  coding  }  prepare  testcodingdirectbuffer_6x3_erasing_d0_p0  testcoding   }
__label__flaky conn  set  request  method  is_  security_  enabled  test  job  info  put  assert  true  get  /v1/job/*  content-type  50  run  test  mock  coordinator  engine  service  json  tags  rest  constants  open  connection  http  servlet  response  assert  equals  parse  params  get  input  stream  url  json  value  call  1  get  header  field  size  obj  get  get  response  code  reset  create  url  starts  with  conn  setrequestmethod  is_security_enabled  testjobinfo  put  asserttrue  get  /v1/job/*  content-type  50  runtest  mockcoordinatorengineservice  jsontags  restconstants  openconnection  httpservletresponse  assertequals  parse  params  getinputstream  url  jsonvalue  call  1  getheaderfield  size  obj  get  getresponsecode  reset  createurl  startswith
__label__nflaky /foo  *  test  resolve  path(p)  foo  chrooted  to  assert  equals  test  resolve  path  create  file  /  resolve  path  assert  get  default  file  system  file  context  test  helper  fc  /foo       * test resolvepath(p)        foo  chrootedto  assertequals  testresolvepath  createfile  /  resolvepath  assert  getdefaultfilesystem  filecontexttesthelper  fc
__label__flaky case  4:  success  case   where  only  one  instance  is  configured   but  expression  has  a  \"" \""  test  basic  submit  with  multiple  instances  output  event  reader  conf  get  status  app  path  no  child  element  is  expected  at  this  point  get  job  sc  per  data-out  instance  not  expected  to  fail  here  get  error  code  assert  true  file://  get  test  case  dir  case  1:  failure  case  i.e.  multiple  data-out  instances  unit_  testing  get  path  job  coordinator.xml  set  e  coord-multiple-output-instance2.xml  coord-multiple-output-instance3.xml  get  message  assert  equals  call  oozie  client  fail  io  utils  contains  is  empty  get  test  user  coord-multiple-output-instance1.xml  copy  char  stream  coord-multiple-output-instance4.xml  get  resource  as  reader  case  3:  multiple  <instance>  tags  within  data-out  should  fail  coordinator  schema  validation  -  different  error  than  above  is  expected  expected  to  catch  errors  due  to  incorrectly  specified  output  data  set  instances  case  2:  data-out  instance  tag  is  empty.  check  works  for  whitespace  in  the  tag  too  writer  error  code  file   case 4: success case  where only one instance is configured  but expression has a \"" \""  testbasicsubmitwithmultipleinstancesoutputevent  reader  conf  getstatus  apppath  no child element is expected at this point  getjob  sc  per data-out instance  not expected to fail here  geterrorcode  asserttrue  file://  gettestcasedir   case 1: failure case i.e. multiple data-out instances  unit_testing  getpath  job  coordinator.xml  set  e  coord-multiple-output-instance2.xml  coord-multiple-output-instance3.xml  getmessage  assertequals  call  oozieclient  fail  ioutils  contains  is empty  gettestuser  coord-multiple-output-instance1.xml  copycharstream  coord-multiple-output-instance4.xml  getresourceasreader   case 3: multiple <instance> tags within data-out should fail coordinator schema validation - different error than above is expected  expected to catch errors due to incorrectly specified output data set instances   case 2: data-out instance tag is empty. check works for whitespace in the tag too  writer  errorcode  file
__label__nflaky all  is  well  asserts  check  test  expression  check  pass  all is well  asserts  check  testexpressioncheckpass
__label__flaky init  -ve  test  coord  el  functions  set  variable  +ve  test  assert  equals  oozie.dataname.  abcd  data-in  coord-job-submit-data  fail  eval  eval  and  wrap  ${coord:data  in  partition  max(\'  abc\'   \'mypartition\')}  test  data  in  partition  max  ph1  should  throw  exception  because  el  function  requires  2  parameters  expr  oozie.dataname.  abc  ${coord:data  in  partition  max(\'  abcd\')}  init   -ve test  coordelfunctions  setvariable   +ve test  assertequals  oozie.dataname.abcd  data-in  coord-job-submit-data  fail  eval  evalandwrap  ${coord:datainpartitionmax(\'abc\'  \'mypartition\')}  testdatainpartitionmaxph1  should throw exception because el function requires 2 parameters  expr  oozie.dataname.abc  ${coord:datainpartitionmax(\'abcd\')}
__label__nflaky once  resumed   all  results  should  be  returned  immediately  conf  expire  the  cache  two  three  as  list  wait  for  group  counters  advance  timer  cache  groups  add  four  set  get  groups  delay  ms  five  grps  get  groups  3  should  get  queued  and  2  should  be  running  resume  now  run  again   this  time  throwing  exceptions  but  no  delay  common  configuration  keys  clear  black  list  one  g  test  background  refresh  counters  groups  refresh  fake  group  mapping  pause  set  int  set  long  my  groups  populate  the  cache  set  throw  exception  arrays  set  boolean   once resumed  all results should be returned immediately  conf   expire the cache  two  three  aslist  waitforgroupcounters  advance  timer  cachegroupsadd  four  setgetgroupsdelayms  five  grps  getgroups   3 should get queued and 2 should be running  resume   now run again  this time throwing exceptions but no delay  commonconfigurationkeys  clearblacklist  one  g  testbackgroundrefreshcounters  groups  refresh  fakegroupmapping  pause  setint  setlong  mygroups   populate the cache  setthrowexception  arrays  setboolean
__label__flaky get  id  assert  equals  test  coord  suspend  postive  get  status  execute  add  record  to  coord  job  table  call  coordinator  job  services  coord  job  get  cmd  assert  not  null  get  job  jpa  service  getid  assertequals  testcoordsuspendpostive  getstatus  execute  addrecordtocoordjobtable  call  coordinatorjob  services  coordjobgetcmd  assertnotnull  get  job  jpaservice
__label__nflaky request  get  name  get  user  principal  test  filter  get  remote  addr  knox@  example.  com  simple  type  when  put  doas  actual  user  do  filter  proxyuser.knox.hosts  get  parameter  init  chain  then  return  proxyuser.knox.users  testuser  params  assert  that  servlet  request  get  remote  user  mockito  response  mock  config  is  equal  to  127.0.0.1  knox  request  getname  getuserprincipal  testfilter  getremoteaddr  knox@example.com  simple  type  when  put  doas  actualuser  dofilter  proxyuser.knox.hosts  getparameter  init  chain  thenreturn  proxyuser.knox.users  testuser  params  assertthat  servletrequest  getremoteuser  mockito  response  mock  config  isequalto  127.0.0.1  knox
__label__flaky var-app-name  check  coord  jobs  </dataset>  </configuration>  include  path  conf  <action>  file:///tmp/include_xml/workflows/${  year}/${  day}  end=\""2009-02-03  t23:59  z\""  timezone=\""  utc\""  xmlns=\""uri:oozie:coordinator:0.2\"">  <controls>  </input-events>  <app-path>hdfs:///tmp/workflows/</app-path>  dataset  elements  uri_  template_  include_  xml  </datasets>  <property>  <name>input  b</name>  <value>${coord:data  in(\'input  b\')}</value>  </property>  assert  not  null  file://  get  test  case  dir  unit_  testing  processed  job  xml  </include>  <dataset  name=\""  b\""  frequency=\""${coord:days(7)}\""  initial-instance=\""2009-02-01  t01:00  z\""  timezone=\""  utc\"">  </uri-template>  get  child  parse  xml  unchecked  <execution>  lifo</execution>  data-in  uri_  template_  coord_  xml  oozie  client  job  id  get  children  contains  size  get  namespace  <workflow>  -  c  <input-events>  </workflow>  <include>  </coordinator-app>  </controls>  job  file  <data-in  name=\""input  b\""  dataset=\""  b\"">  <instance>${coord:latest(0)}</instance>  </data-in>  <coordinator-app  name=\""${app  name}-foo\""  frequency=\""${coord:days(1)}\""  start=\""2009-02-01  t01:00  z\""  assert  false  app  path  substring  include1.xml  sc  write  to  file  app  xml  get  job  xml  uri-template  <dataset>  should  not  be  duplicate  </action>  assert  true  get  <uri-template>  should  not  contain  one  from  the  include  file  include  xml  coordinator.xml  set  xml  utils  <datasets>  app  name  length  test  duplicate  dataset  name  in  include  file  <uri-template>  assert  equals  <configuration>  file:///tmp/coord_xml/workflows/${  year}/${  day}  input-events  call  get  child  text  get  test  user  namespace  dataset  var-app-name  checkcoordjobs  </dataset>   </configuration>  includepath  conf  <action>  file:///tmp/include_xml/workflows/${year}/${day}  end=\""2009-02-03t23:59z\"" timezone=\""utc\"" xmlns=\""uri:oozie:coordinator:0.2\"">  <controls>   </input-events>   <app-path>hdfs:///tmp/workflows/</app-path>   datasetelements  uri_template_include_xml  </datasets>  <property> <name>inputb</name> <value>${coord:datain(\'inputb\')}</value> </property>   assertnotnull  file://  gettestcasedir  unit_testing  processedjobxml  </include>  <dataset name=\""b\"" frequency=\""${coord:days(7)}\"" initial-instance=\""2009-02-01t01:00z\"" timezone=\""utc\"">  </uri-template>  getchild  parsexml  unchecked  <execution>lifo</execution>  data-in  uri_template_coord_xml  oozieclient  jobid  getchildren  contains  size  getnamespace  <workflow>  -c   <input-events>   </workflow>  <include>   </coordinator-app>  </controls>  job  file  <data-in name=\""inputb\"" dataset=\""b\""> <instance>${coord:latest(0)}</instance> </data-in>    <coordinator-app name=\""${appname}-foo\"" frequency=\""${coord:days(1)}\"" start=\""2009-02-01t01:00z\""   assertfalse  apppath  substring  include1.xml  sc  writetofile  appxml  getjobxml  uri-template  <dataset> should not be duplicate  </action>  asserttrue  get  <uri-template> should not contain one from the include file  includexml  coordinator.xml  set  xmlutils  <datasets>   appname  length  testduplicatedatasetnameinincludefile  <uri-template>  assertequals  <configuration>  file:///tmp/coord_xml/workflows/${year}/${day}  input-events  call  getchildtext  gettestuser  namespace  dataset
__label__nflaky 1  =  01  =  0001  in  4  bits.  "
__label__flaky set  name  ${coord:days  in  month(coord:days  in  month(1))}  2010-10-01  t00:00  z  coord  el  functions  utc  get  time  zone  2009-09-10  t23:59  z  28  coord-action-create  date  utils  feb  test1  set  frequency  parse  date  oozie  tz  ds  eval  and  wrap  end  of  month  ${coord:days  in  month(-1)}  configure  evaluator  ${coord:days  in  month(-3)}  set  time  zone  jan  time  unit  expr  set  end  of  duration  30  31  init  set  nominal  time  set  init  instance  ${coord:days  in  month(2)}  ${coord:days  in  month(3)}  case  1  assert  equals  ${coord:days  in  month(0)}  ${coord:days  in  month(1)}  set  type  set  actual  time  app  inst  america/  los_  angeles  set  time  unit  2009-02-01  t11:00  z  eval  test  days  in  month  2009-01-01  t00:00  z  2009-01-02  t00:00  z  sync  setname  ${coord:daysinmonth(coord:daysinmonth(1))}  2010-10-01t00:00z  coordelfunctions  utc  gettimezone  2009-09-10t23:59z  28  coord-action-create  dateutils   feb  test1  setfrequency  parsedateoozietz  ds  evalandwrap   end of month  ${coord:daysinmonth(-1)}  configureevaluator  ${coord:daysinmonth(-3)}  settimezone   jan  timeunit  expr  setendofduration  30  31  init  setnominaltime  setinitinstance  ${coord:daysinmonth(2)}  ${coord:daysinmonth(3)}   case 1  assertequals  ${coord:daysinmonth(0)}  ${coord:daysinmonth(1)}  settype  setactualtime  appinst  america/los_angeles  settimeunit  2009-02-01t11:00z  eval  testdaysinmonth  2009-01-01t00:00z  2009-01-02t00:00z  sync
__label__nflaky assert  correct  image2string  test  decode  row2string26  (10)5678(11)010101  26.png  assertcorrectimage2string  testdecoderow2string26  (10)5678(11)010101  26.png
__label__flaky cluster  namenode  has  corrupt  files.  expecting  none.  get  name  max  corrupt  file  blocks  conf  verify  that  there  are  no  bad  blocks.  #  of  corrupt  files  is:  removing  files  from  storage  dir  info  dfs  config  keys  get  block  pool  id  log  list  corrupt  file  blocks  iter  get  file  system  cannot  remove  file.  .  set  int  get  name  node  blk_  expected  more  than  util  size  bad  files.  expecting  iterator  should  have  made  more  than  1  call  but  made  cleanup  get  instance  storage  dir  idx  shutdown  create  110  files  with  one  block  each  /srcdat2  datanode  sends  block  reports  get  finalized  dir  bpid  fs  wait  replication  namenode  delete  corrupt  file  blocks  but  got  get  calls  made  sleep  bad  files  corrupt  paths  assert  true  list  files  data_dir  mini  dfs  cluster  blocks  test  max  corrupt  files  namenode  has  bad  files.  j  count  paths  thread  create  files  now  deliberately  blocks  from  all  files  build  fs  namesystem  datanode  scans  directories  get  namesystem  starts  with  cluster  namenode has    corrupt files. expecting none.  getname  maxcorruptfileblocks  conf   verify that there are no bad blocks.  # of corrupt files is:   removing files from   storagedir  info  dfsconfigkeys  getblockpoolid  log  listcorruptfileblocks  iter  getfilesystem  cannot remove file.  .  setint  getnamenode  blk_  expected more than   util  size   bad files. expecting   iterator should have made more than 1 call but made   cleanup  getinstancestoragedir  idx  shutdown   create 110 files with one block each  /srcdat2   datanode sends block reports  getfinalizeddir  bpid  fs  waitreplication  namenode  delete   corrupt file blocks but got   getcallsmade  sleep  badfiles  corruptpaths  asserttrue  listfiles  data_dir  minidfscluster  blocks  testmaxcorruptfiles  namenode has bad files.   j  countpaths  thread  createfiles   now deliberately blocks from all files  build  fsnamesystem   datanode scans directories  getnamesystem  startswith
__label__nflaky get  bytes  transferred  test  coding  fragment  buffering  tiny  fragments2  codec  test  utils  channel  times  assert  flush  verify  more  stuff  dump  stuff---more  stuff  write  argument  matchers  standard  charsets  assert  equals  encoder  -  any  mockito  outbuf  metrics  spy  wrap  stuff  getbytestransferred  testcodingfragmentbufferingtinyfragments2  codectestutils  channel  times  assert  flush  verify  more stuff  dump  stuff---more stuff  write  argumentmatchers  standardcharsets  assertequals  encoder  -  any  mockito  outbuf  metrics  spy  wrap  stuff
__label__flaky c\""  d  \""e  pmml  utils  foo  app  pmml  utils  assert  equals  get  extension  content  as  list  bar  empty  list  build  dummy  model  assert  null  add  extension  content  test  extension  content  reserialized  model  model  baz  to  string  foo1  from  string  arrays  foo2  collections  foo3   c\"" d \""e   pmmlutils  foo  apppmmlutils  assertequals  getextensioncontent  aslist  bar  emptylist  builddummymodel  assertnull  addextensioncontent  testextensioncontent  reserializedmodel  model  baz  tostring  foo1  fromstring  arrays  foo2  collections  foo3
__label__nflaky c:/log/debug-old-2010-08-10.2.log  c:/log/debug-old-\%d{yyyy-  mm-dd}.\%i.log  matching  file  array  c:/log/debug-old-2010-08-10.12.log  see  also  http://jira.qos.ch/browse/  lbcore-164  sa  c:/log/debug-old-2010-08-10.7.log  result  c:/log/debug-old-2010-08-10.1.log  find  highest  counter  test  rexexp  context  file  filter  util  c:/log/debug-old-2010-08-10.6.log  to  regex  for  fixed  date  c:/log/debug-old-2010-08-10.5.log  fnp  assert  equals  c:/log/debug-old-2010-08-10.10.log  parse  c:/log/debug-old-2010-08-10.9.log  2010-08-10  find  highest  counter  stem  regex  c:/log/debug-old-2010-08-10.3.log  sdf  c:/log/debug-old-2010-08-10.0.log  c:/log/debug-old-2010-08-10.11.log  yyyy-  mm-dd  after  last  slash  c:/log/debug-old-2010-08-10.4.log  c:/log/debug-old-2010-08-10.8.log  c:/log/debug-old-2010-08-10.2.log  c:/log/debug-old-\%d{yyyy-mm-dd}.\%i.log  matchingfilearray  c:/log/debug-old-2010-08-10.12.log   see also http://jira.qos.ch/browse/lbcore-164  sa  c:/log/debug-old-2010-08-10.7.log  result  c:/log/debug-old-2010-08-10.1.log  findhighestcountertest  rexexp  context  filefilterutil  c:/log/debug-old-2010-08-10.6.log  toregexforfixeddate  c:/log/debug-old-2010-08-10.5.log  fnp  assertequals  c:/log/debug-old-2010-08-10.10.log  parse  c:/log/debug-old-2010-08-10.9.log  2010-08-10  findhighestcounter  stemregex  c:/log/debug-old-2010-08-10.3.log  sdf  c:/log/debug-old-2010-08-10.0.log  c:/log/debug-old-2010-08-10.11.log  yyyy-mm-dd  afterlastslash  c:/log/debug-old-2010-08-10.4.log  c:/log/debug-old-2010-08-10.8.log
__label__flaky add  node  def  start  assert  equals  kill  workflow  instance  get  status  killed  wf  1  <worklfow-app/>  end  job  test  kill  workflow  addnode  def  start  assertequals  kill  workflowinstance  getstatus  killed  wf  1  <worklfow-app/>  end  job  testkillworkflow
__label__nflaky get  subject  get  name  check  ticket  and  keytab  original  login  user  subject  get  user  user1.keytab  login  user  from  subject  user2.keytab  run  principal2  principal1  not  affected.  login  principal1  with  a  keytab.  assert  remove  user  assert  not  null  relogin  from  keytab  get  path  work  dir  no  login  context  should  be  attached  to  the  user.  user  group  information  user1  user2  ext  login  user  ticket  keytab1  test  relogin  for  login  from  subject  kdc  login  user  from  keytab  verify  the  new  login  user  is  external.  assert  same  get  login  user  keytab2  get  login  login  user  from  keytab  and  return  ugi  do  as  assert  null  assert  not  same  create  principal  ext  login  user  original  login  user  ticket  original  login  user  not  affected.  getsubject  getname  checkticketandkeytab  originalloginuser  subject  getuser  user1.keytab  loginuserfromsubject  user2.keytab  run  principal2  principal1   not affected.   login principal1 with a keytab.  assert  removeuser  assertnotnull  reloginfromkeytab  getpath  workdir   no login context should be attached to the user.  usergroupinformation  user1  user2  extloginuserticket  keytab1  testreloginforloginfromsubject  kdc  loginuserfromkeytab   verify the new login user is external.  assertsame  getloginuser  keytab2  getlogin  loginuserfromkeytabandreturnugi  doas  assertnull  assertnotsame  createprincipal  extloginuser  originalloginuserticket   original login user not affected.
__label__flaky date  if_  simple  set  script  executor  session  given  simple  with  lwt  result  listener  eq  delete  select  *  from  simple  where  id  =  lwt  result  listener  sets  when  of  get  where  id  get  and  set  row  table  execute  script  template  on  error  random  utils  manager  all  columns_  from  base  table  one  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  is  true  new  hash  set  success  then  is  null  long  build  date  key  should_delete_with_equal_condition  dsl  on  success  date  if_simpleset  scriptexecutor  session   given  simple  withlwtresultlistener  eq  delete  select * from simple where id =   lwtresultlistener  sets   when  of  get  where  id  getandset  row  table  executescripttemplate  onerror  randomutils  manager  allcolumns_frombasetable  one  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  istrue  newhashset  success   then  isnull  long  builddatekey  should_delete_with_equal_condition  dsl  onsuccess
__label__nflaky internal  test  serial  test  serial  internaltestserial  testserial
__label__flaky job  conf  get  name  reader  auth  token  get  error  code  get  test  case  dir  /workflow.xml  get  file://  workflow.xml  oozie.service.  action  service.executor.ext.classes  parse  def  app  init  set  destroy  wf-schema-action-name-too-long.xml  assert  equals  services  test  action  name  length  oozie  client  fail  io  utils  get  test  user  ex  copy  char  stream  set  system  property  get  resource  as  reader  writer  wps  error  code  file  jobconf  getname  reader  authtoken  geterrorcode  gettestcasedir  /workflow.xml  get  file://  workflow.xml  oozie.service.actionservice.executor.ext.classes  parsedef  app  init  set  destroy  wf-schema-action-name-too-long.xml  assertequals  services  testactionnamelength  oozieclient  fail  ioutils  gettestuser  ex  copycharstream  setsystemproperty  getresourceasreader  writer  wps  errorcode  file
__label__nflaky content  type  listener  core  matchers  set  exception  callback  get  cause  async  server  bootstrap  listen  instance  of  io  reactor  config  assert  get  duration  create  https  /stuff  set  lookup  registry  requester  localhost  set  stream  listener  logging  exception  callback  logging  http1  stream  listener  set  io  session  listener  result  future1  *  set  so  timeout  method  assert  that  execute  logging  conn  pool  listener  fail  ex  secure  all  ports  strategy  timeout  server  set  io  reactor  config  create  client  ssl  context  cause  test  ssl  disabled  by  default  bootstrap  h2  requester  bootstrap  set  conn  pool  listener  set  tls  strategy  some  stuff  set  io  session  decorator  ss  lv3  create  server  ssl  context  get  execution  exception  expected  get  address  ssl  test  contexts  address  custom  start  ssl  engine  set  enabled  protocols  target  get  time  unit  logging  io  session  decorator  get  port  build  future  logging  io  session  listener  initialize  register  contenttype  listener  corematchers  setexceptioncallback  getcause  asyncserverbootstrap  listen  instanceof  ioreactorconfig  assert  getduration  create  https  /stuff  setlookupregistry  requester  localhost  setstreamlistener  loggingexceptioncallback  logginghttp1streamlistener  setiosessionlistener  resultfuture1  *  setsotimeout  method  assertthat  execute  loggingconnpoollistener  fail  ex  secureallportsstrategy  timeout  server  setioreactorconfig  createclientsslcontext  cause  testssldisabledbydefault  bootstrap  h2requesterbootstrap  setconnpoollistener  settlsstrategy  some stuff  setiosessiondecorator  sslv3  createserversslcontext  get  executionexception expected  getaddress  ssltestcontexts  address  custom  start  sslengine  setenabledprotocols  target  gettimeunit  loggingiosessiondecorator  getport  build  future  loggingiosessionlistener  initialize  register
__label__flaky date  \%msg  -  \%thread\%n  given  simple  crud  consistency  level  prepare  log  level  when  execution  info  id  get  async  with  stats  info  log  asserter  is  not  null  actual  random  utils  with  result  set  async  listener  should_find_by_id_async  assert  that  simple  entity/insert_single_row.cql  immutable  map  assert  contains  _1  _2  then  long  build  date  key  logger  rs  script  executor  async_  logger_  string  contains  exactly  is  up  of  find  by  id  get  await  latch  count  down  table  execute  script  template  get  queried  host  manager  next  long  get  consistency  list  called  is  true  tuple2  called  -  achilles-default-executor  date  \%msg - \%thread\%n   given  simple  crud  consistencylevel  prepareloglevel   when  executioninfo  id  getasyncwithstats  info  logasserter  isnotnull  actual  randomutils  withresultsetasynclistener  should_find_by_id_async  assertthat  simpleentity/insert_single_row.cql  immutablemap  assertcontains  _1  _2   then  long  builddatekey  logger  rs  scriptexecutor  async_logger_string  containsexactly  isup  of  findbyid  get  await  latch  countdown  table  executescripttemplate  getqueriedhost  manager  nextlong  getconsistencylist  called  istrue  tuple2  called - achilles-default-executor
__label__nflaky private  clone  get  all  tokens  get  credentials  get  kind  get  bytes  password  regular-token  ugi  ensure  only  non-private  tokens  are  returned  tokens  privateusers  user  group  information  create  user  for  testing  add  token  token  id  service1  assert  equals  private  user  private-token1  private-token  token  size  now  add  cloned  private  token  service  test  private  token  exclusion  privateclone  getalltokens  getcredentials  getkind  getbytes  password  regular-token  ugi   ensure only non-private tokens are returned  tokens  privateusers  usergroupinformation  createuserfortesting  addtoken  tokenid  service1  assertequals  privateuser  private-token1  private-token  token  size   now add cloned private token  service  testprivatetokenexclusion
__label__flaky r2  get  last  task  time  millis  set  parallel  preprocessing  should  be  about  100\%).  parallel  delta  test  it  only  if  number  there  are  more  than  1  cpu  cores  are  available  available  processors:  {}  sequential  pre  processing  string  processing  details:  sequential  runtime  assert  assert  true  process  and  merge  get  create  victim  get  runtime  info  warm  up  context  init  executor  available  processors  pretty  print  debug  log  resource  start  format  resources  resource  type  message  get  config  \%s  >  \%s  +  \%s  create  resources  stop  watch  pre  processing  in  parallel  is  faster  parallel  pre  processing  create  slow  pre  processor  sequential  execution  config  r1  parallel  execution  r2  getlasttasktimemillis  setparallelpreprocessing   should be about 100\%).   parallel  delta   test it only if number there are more than 1 cpu cores are available  availableprocessors: {}  sequential preprocessing  string  processing details:      sequential  runtime  assert  asserttrue  processandmerge  get  create  victim  getruntime  info   warm up  context  initexecutor  availableprocessors  prettyprint  debug  log  resource  start  format  resources  resourcetype  message  getconfig  \%s  > \%s + \%s  createresources  stop  watch  preprocessinginparallelisfaster  parallel preprocessing  createslowpreprocessor  sequentialexecution  config  r1  parallelexecution
__label__nflaky prepare  item2  item5ca  item1  conf  set  root  expression  when  set  out  out  result  find  in  order  verify  set  options  expr  finish  item1b  item1a  item5e  item5d  item5c  create  directories  item5b  item5a  set  err  fs  check  err  test  in  order  fs  check  apply  then  return  check  process  arguments  check  expressions  are  called  in  the  correct  order  any  set  conf  any  int  verify  no  more  interactions  mock  get  options  item1aa  item4  items  item3  item5  prepare  item2  item5ca  item1  conf  setrootexpression  when  setout  out  result  find  inorder  verify  setoptions  expr  finish  item1b  item1a  item5e  item5d  item5c  createdirectories  item5b  item5a  seterr  fscheck  err  test  inorderfscheck  apply  thenreturn  check  processarguments   check expressions are called in the correct order  any  setconf  anyint  verifynomoreinteractions  mock  getoptions  item1aa  item4  items  item3  item5
__label__flaky dag  el  functions  \""  features\"":\""  unknown\""   action  type  \""  return_  code\"":\""0\""   \""  error_  message\"":null   put  ${hadoop:counters(\'  h\')\'  job_  graph\'}  create  evaluator  ${hadoop:counters(\'  h\')\'  action_  type\'}  split  \""0\""  {\""  action_  type\"":\""  pig\""   \""  error_  code\"":\""-1\""   tmp  context  set  id  action  index  of  \""job_201111300933_0004\""  item  workflow  \""  hadoop_  version\"":\""0.20.2\""   ${hadoop:counters(\'  h\')\'job_201111300933_0004\'}     version  \""  record_  written\"":\""33\""   1  application  type  eval  null  job1  status  res  array  ${hadoop:counters(\'  h\')\'job_201111300933_0004\'\'  map_  input_  records\'}  \""  number_  jobs\"":\""2\""   job1  status  map  :  evaluate  \""  job_  graph\"":\""job_201111300933_0004 job_201111300933_0005\""   \""  min_  reduce_  time\""  \""job_201111300933_0005\""  status  set  name  add  node  \""job_201111300933_0005\"":{\""  map_  input_  records\"":\""37\"" \""  min_  reduce_  time\"":\""0\"" \""  multi_  store_  counters\"":{} \""  error_  message\"":null \""  job_  id\"":\""job_201111300933_0005\""}   0.9.0  generate  id  h  job  status  items  job2  status  map  \""37\""  pig  stats  ${hadoop:counters(\'  h\')\'job_201111300933_0005\'}  \""job_201111300933_0004\"":{\""  map_  input_  records\"":\""33\"" \""  min_  reduce_  time\"":\""0\"" \""  multi_  store_  counters\"":{} \""  error_  message\"":null \""  job_  id\"":\""job_201111300933_0004\""}   substring  \""  error_  message\""  wi  \""  bytes_  written\"":\""1410\""   configure  evaluator  \""  pig_  version\"":\""0.9.0\""   get  <workflow-app/>  map  reduce  action  executor  \""  multi_  store_  counters\""  set  proto  action  conf  set  workflow  instance  a  {}  job2  status  res  array  test  el  functions  returning  pig  stats  set  var  assert  equals  wf  app  \""33\""  services  \""  job_  id\""  last  index  of  <configuration/>  job_201111300933_0004 job_201111300933_0005  ${hadoop:counters(\'  h\')\'  pig_  version\'}  job  graph  \""  map_  input_  records\""  to  string  job2  status  result  job2  status  res  map  }  job1  status  res  map  job1  status  result  dagelfunctions  \""features\"":\""unknown\""   actiontype  \""return_code\"":\""0\""   \""error_message\"":null   put  ${hadoop:counters(\'h\')\'job_graph\'}  createevaluator  ${hadoop:counters(\'h\')\'action_type\'}  split  \""0\""  {\""action_type\"":\""pig\""   \""error_code\"":\""-1\""   tmp  context  setid  action  indexof  \""job_201111300933_0004\""  item  workflow  \""hadoop_version\"":\""0.20.2\""   ${hadoop:counters(\'h\')\'job_201111300933_0004\'}     version  \""record_written\"":\""33\""   1  applicationtype  eval  null  job1statusresarray  ${hadoop:counters(\'h\')\'job_201111300933_0004\'\'map_input_records\'}  \""number_jobs\"":\""2\""   job1statusmap  :  evaluate  \""job_graph\"":\""job_201111300933_0004 job_201111300933_0005\""   \""min_reduce_time\""  \""job_201111300933_0005\""  status  setname  addnode  \""job_201111300933_0005\"":{\""map_input_records\"":\""37\"" \""min_reduce_time\"":\""0\"" \""multi_store_counters\"":{} \""error_message\"":null \""job_id\"":\""job_201111300933_0005\""}   0.9.0  generateid  h  jobstatusitems  job2statusmap  \""37\""  pigstats  ${hadoop:counters(\'h\')\'job_201111300933_0005\'}  \""job_201111300933_0004\"":{\""map_input_records\"":\""33\"" \""min_reduce_time\"":\""0\"" \""multi_store_counters\"":{} \""error_message\"":null \""job_id\"":\""job_201111300933_0004\""}   substring  \""error_message\""  wi  \""bytes_written\"":\""1410\""   configureevaluator  \""pig_version\"":\""0.9.0\""   get  <workflow-app/>  mapreduceactionexecutor  \""multi_store_counters\""  setprotoactionconf  setworkflowinstance  a  {}  job2statusresarray  testelfunctionsreturningpigstats  setvar  assertequals  wfapp  \""33\""  services  \""job_id\""  lastindexof  <configuration/>  job_201111300933_0004 job_201111300933_0005  ${hadoop:counters(\'h\')\'pig_version\'}  jobgraph  \""map_input_records\""  tostring  job2statusresult  job2statusresmap  }  job1statusresmap  job1statusresult
__label__nflaky credential1  has  been  successfully  deleted.  credential1  run  delete  test  prompt  for  credential  password  match  failed  for  credential1.  password  passwords  password  error  create  jceks  provider  -f  p@ssw0rd  add  assert  output  contains  assert  equals  check  set  conf  rc  set  password  reader  -provider  shell  args1  args2  p@ssw0rderr  credential1  has  been  successfully  created.  args3  password  match  success  for  credential1.  credential1 has been successfully deleted.  credential1  run  delete  testpromptforcredential  password match failed for credential1.  password  passwords  passworderror  create  jceksprovider  -f  p@ssw0rd  add  assertoutputcontains  assertequals  check  setconf  rc  setpasswordreader  -provider  shell  args1  args2  p@ssw0rderr  credential1 has been successfully created.  args3  password match success for credential1.
__label__flaky create  client  clear  create  stage  assert  equals  poll  actor.add  reminder(\""bla\""   0   20   time  unit.  milliseconds).join();  actor  1  bind  assert  null  stop  bla  add  reminder  i  actor  time  unit  stage2  join  reminders  received  get  reference  persisted  timer  test  stage1  frontend  createclient  clear  createstage  assertequals  poll   actor.addreminder(\""bla\""  0  20  timeunit.milliseconds).join();  actor  1  bind  assertnull  stop  bla  addreminder  iactor  timeunit  stage2  join  remindersreceived  getreference  persistedtimertest  stage1  frontend
__label__nflaky add  p@ssw0rd  credential1  passwords  don\'t  match  run  assert  equals  set  conf  rc  contains  set  password  reader  -provider  passwords  shell  assert  true  test  prompt  for  credential  with  empty  passwd  args1  create  jceks  provider  to  string  out  content  add  p@ssw0rd  credential1  passwords don\'t match  run  assertequals  setconf  rc  contains  setpasswordreader  -provider  passwords  shell  asserttrue  testpromptforcredentialwithemptypasswd  args1  create  jceksprovider  tostring  outcontent
__label__flaky add  node  def  expected  to  catch  an  exception  but  did  not  encounter  any  test  fork  join  failure  three  two  get  cause  make  sure  the  message  contains  the  nodes  involved  in  the  invalid  transition  to  end  node  end  as  list  we  invoke  fork  join  get  error  code  assert  true  dummy  conf  end  f  one  get  message  j  assert  equals  k  kill  node  three  fail  contains  f->(2 3)  2->j  3->end  ex  parser  test  wf  <worklfow-app/>  error  code  arrays  addnode  def  expected to catch an exception but did not encounter any  testforkjoinfailure  three  two  getcause   make sure the message contains the nodes involved in the invalid transition to end  node end  aslist  we  invokeforkjoin  geterrorcode  asserttrue  dummyconf  end  f  one  getmessage  j  assertequals  k  kill  node three  fail  contains          f->(2 3)        2->j        3->end        ex  parser  testwf  <worklfow-app/>  errorcode  arrays
__label__nflaky store  password  get  resource  to  char  array  server  socket  new  single  thread  executor  executors  server  ssl  context  get  server  socket  factory  assert  bind  assert  not  null  nopassword  client  principal  create  time  unit  ssl  context  builder  /test-client.p12  write  get  peer  principal  localhost  start  handshake  read  local  port  load  trust  material  load  key  material  resource2  input  stream  set  so  timeout  get  input  stream  /test-server.p12  resource1  accept  create  socket  client  ssl  context  timeout  set  need  client  auth  get  local  port  submit  session  client  socket  flush  key  password  test  ssl  handshake  client  authenticated  get  output  stream  close  connect  assert  equals  call  get  socket  factory  build  future  to  milliseconds  int  bound  get  output  stream  socket  get  session  create  server  socket  storepassword  getresource  tochararray  serversocket  newsinglethreadexecutor  executors  serversslcontext  getserversocketfactory  assert  bind  assertnotnull  nopassword  clientprincipal  create  timeunit  sslcontextbuilder  /test-client.p12  write  getpeerprincipal  localhost  starthandshake  read  localport  loadtrustmaterial  loadkeymaterial  resource2  inputstream  setsotimeout  getinputstream  /test-server.p12  resource1  accept  createsocket  clientsslcontext  timeout  setneedclientauth  getlocalport  submit  session  clientsocket  flush  keypassword  testsslhandshakeclientauthenticated  get  outputstream  close  connect  assertequals  call  getsocketfactory  build  future  tomillisecondsintbound  getoutputstream  socket  getsession  createserversocket
__label__flaky <fs/>  dir  fs  create  context  -rwxr-----  path  rwx---r--  test  chmod  rwx-----x  get  file  status  context  rwx------  chmod  fs  permission  set  permission  grandchild  -rwxr----x  -rwx-----x  get  permission  ae  value  of  rwxr-----  assert  equals  get  file  system  rwxr----x  -rwx------  mkdirs  to  string  get  fs  test  case  dir  child  -rwx---r--  <fs/>  dir  fs  createcontext  -rwxr-----  path  rwx---r--  testchmod  rwx-----x  getfilestatus  context  rwx------  chmod  fspermission  setpermission  grandchild  -rwxr----x  -rwx-----x  getpermission  ae  valueof  rwxr-----  assertequals  getfilesystem  rwxr----x  -rwx------  mkdirs  tostring  getfstestcasedir  child  -rwx---r--
__label__nflaky transfer-  encoding  add  header  determine  length  message  len  strategy  whatever  test  entity  with  invalid  transfer  encoding  transfer-encoding  addheader  determinelength  message  lenstrategy  whatever  testentitywithinvalidtransferencoding
__label__flaky cluster  get  write  ops  get  current  user  get  statistics  read  ops  and  large  read  ops  incremented  by  1  or  more  list  status  conf  dir  math  get  status  /test  set  owner  ugi  get  file  status  test  statistics  create  get  user  name  get  file  block  locations  user  group  information  dfs  config  keys  write  ops  in  get  file  system  ceil  list  get  file  checksum  iterations  set  int  get  read  ops  mkdirs  iterative  ls  test  set  times  shutdown  status  get  group  names  ls  limit  get  large  read  ops  large  read  ops  fs  delete  out  get  test  configuration  file  check  statistics  read  ops  set  permission  close  single  iteration  in  list  status  -  no  large  read  operation  done  number  times  list  status  iterates  dfs  test  util  get  content  summary  set  replication  integer  p  build  rename  to  string  file1  open  cluster  getwriteops  getcurrentuser  getstatistics   readops and largereadops incremented by 1 or more  liststatus  conf  dir  math  getstatus  /test  setowner  ugi  getfilestatus  teststatistics  create  getusername  getfileblocklocations  usergroupinformation  dfsconfigkeys  writeops  in  getfilesystem  ceil  list  getfilechecksum  iterations  setint  getreadops  mkdirs   iterative ls test  settimes  shutdown  status  getgroupnames  lslimit  getlargereadops  largereadops  fs  delete  out  gettestconfiguration  file  checkstatistics  readops  setpermission  close   single iteration in liststatus - no large read operation done   number times liststatus iterates  dfstestutil  getcontentsummary  setreplication  integer  p  build  rename  tostring  file1  open
__label__nflaky path  /foo  test  merge  paths  file://fileauthority/bar  /  c:/foo/bar  assert  equals  viewfs:///foo  /  c:/bar  merge  paths  /bar/baz  /  c:/  c:/bar  /  /bar  shell  /foo/bar  viewfs://vfsauthority/foo/bar  /foo/bar/baz  /baz  viewfs:///foo/bar  /  c:/foo  file:///bar  viewfs://vfsauthority/foo  /  c:/foo/  c:/bar  /  c:/  path  /foo  testmergepaths  file://fileauthority/bar  /c:/foo/bar  assertequals  viewfs:///foo  /c:/bar  mergepaths  /bar/baz  /c:/c:/bar  /  /bar  shell  /foo/bar  viewfs://vfsauthority/foo/bar  /foo/bar/baz  /baz  viewfs:///foo/bar  /c:/foo  file:///bar  viewfs://vfsauthority/foo  /c:/foo/c:/bar  /c:/
__label__flaky child_value  script  executor  session  given  simple  eq  delete  when  of  where  id  entity  as  child/insert_single_row.cql  select  *  from  entity_child  where  id  =  row  value  table  another  value  execute  script  template  is  not  null  val  random  utils  manager  one  should_dsl_delete  get  string  next  long  assert  that  execute  immutable  map  is  true  then  is  null  long  from  base  table  dsl  is  equal  to  child_value  scriptexecutor  session   given  simple  eq  delete   when  of  where  id  entityaschild/insert_single_row.cql  select * from entity_child where id =   row  value  table  anothervalue  executescripttemplate  isnotnull  val  randomutils  manager  one  should_dsl_delete  getstring  nextlong  assertthat  execute  immutablemap  istrue   then  isnull  long  frombasetable  dsl  isequalto
__label__nflaky a${k${zero}}b  input  node  transform  node  to  string  transformer  nested  variable  property  container0  make  node  av0b  assert  equals  a${k${zero}}b  input  node  transform  nodetostringtransformer  nestedvariable  propertycontainer0  makenode  av0b  assertequals
__label__flaky ss  scheduler  service  increment  and  get  run  counter  test  instrumentation  services  schedule  assert  true  assert  not  null  get  evaluate  wait  for  ss  schedulerservice  incrementandget  run  counter  testinstrumentation  services  schedule  asserttrue  assertnotnull  get  evaluate  waitfor
__label__nflaky check  fields  unqbbc  stat  fsp  hdfs://yaks:4344/dingos/f  assert  equals  convert  p  stat2  pb  helper  test  utility  serialization  fs  permission  hadoop  create  immutable  checkfields  unqbbc  stat  fsp  hdfs://yaks:4344/dingos/f  assertequals  convert  p  stat2  pbhelper  testutilityserialization  fspermission  hadoop  createimmutable
__label__flaky close  trx  coord  client  get  store  local  oozie  could  not  update  db.  get  status  after  refresh   action  xml=  get  coord  client  e  action  get  test  group  begin  trx  coordinator  action  create  commit  trx  wait  for  bean  action  num  print  stack  trace  store2  store3  parse  xml  get  file  system  job  id  fail  coordinator  job  _  success  add  record  to  action  table  mkdirs  action  id  test  coord  rerun  refresh  evaluate  get  coordinator  action  @  get  time  app  path  fs  system  action  xml  -test  coord  rerun-  c  coord  urls  get  re  run  coord  /coord-input/2010/07/09/01/00  rest  constants  xml  utils  e  store  get  action  xml  urls  input  dir  add  record  to  job  table  integer  services  get  test  user  get  action  xml  get  coord  action  info  assert  not  same  0000000-  to  string  action2  action3  coord-rerun-action1.xml  get  fs  test  case  dir  closetrx  coordclient  getstore  localoozie  could not update db.  getstatus  after refresh  action xml=   getcoordclient  eaction  gettestgroup  begintrx  coordinatoraction  create  committrx  waitfor  bean  actionnum  printstacktrace  store2  store3  parsexml  getfilesystem  jobid  fail  coordinatorjob  _success  addrecordtoactiontable  mkdirs  actionid  testcoordrerunrefresh  evaluate  getcoordinatoraction  @  gettime  apppath  fs  system  actionxml  -testcoordrerun-c  coord  urls  get  reruncoord  /coord-input/2010/07/09/01/00  restconstants  xmlutils  e  store  getactionxmlurls  inputdir  addrecordtojobtable  integer  services  gettestuser  getactionxml  getcoordactioninfo  assertnotsame  0000000-  tostring  action2  action3  coord-rerun-action1.xml  getfstestcasedir
__label__nflaky 101001010010001010001001010000101001010001001001001001000101010100001000100101000010  111010010  b  k  b  o  111010110  101011000  100000  00000  b  u  a  a  101101100  \%  +  c  a  100001010  110001010  101100101101011001101001101100101101100110101011011001011001101001101101001110101000  b  t  100110010  do  test  110101110  c  z  b  f  100010100  100011010  110011010  b  w  d  a  checksum:  12  28  b  v  a  z  000001010111101101010001101001001101000101100101001100100101100010101011010001011001  100100110  100101100  111011010  101011110  111001010  c  l  0  9  001011000101001101001000110101010110001010011001010001101001011001000101101101101001  100111010  abcdefghijklmnopqrstuvwxyz0123456789  test  encode  b  e  space  $  10100111010101000010101011110100000  110101000  110100010  "
__label__flaky push  promise  play  data  stream  id  header  entries  on  reset  as  list  observer  type_  headers  connection  https  events  add  banana  read  last  on  headers  /cached  on  data  200  syn_  stream  request  headers  response  headers  header  size  get  source  get  push  observer  arrays  new  stream  on  request  android  play  it  back  squareup.com  http_20_  draft_09  verify  the  peer  received  what  was  expected  connection  builder  accept  frame  assert  true  peer  get  client  take  frame  expected  response  headers  a  b  syn  reply  expected  request  headers  set  variant  and  client  assert  equals  push  promise  stream  send  frame  build  pushpromise  play  data  streamid  headerentries  onreset  aslist  observer  type_headers  connection  https  events  add  banana  read  last  onheaders  /cached  ondata  200   syn_stream  requestheaders  responseheaders  header  size  getsource  get  pushobserver  arrays  newstream  onrequest  android   play it back  squareup.com  http_20_draft_09   verify the peer received what was expected  connectionbuilder  acceptframe  asserttrue  peer  get  client  takeframe  expectedresponseheaders  a  b  synreply  expectedrequestheaders  setvariantandclient  assertequals  pushpromisestream  sendframe  build
__label__nflaky src  standard  charsets  create  byte  buffer  decode  indexed  header  has  remaining  assert  false  assert  header  equals  dynamic  table  assert  equals  decoder  decoding  completed  assert  :method  test  indexed  header  decoding  rfc7541  examples  get  header  dynamic  length  src  standardcharsets  createbytebuffer  decodeindexedheader  hasremaining  assertfalse  assertheaderequals  dynamictable  assertequals  decoder  decoding completed  assert  :method  testindexedheaderdecodingrfc7541examples  get  header  dynamiclength
__label__flaky fsn  cluster  starting  test  test  cluster  stats  name  node  adapter  write  config  file  conf  check  namenode  stats  for  multiple  datanode  heartbeats  namenode  start  cluster  verify  stats  file  test  cluster  stats  num  datanodes  refresh  nodes  write  file  exclude  file  info  ret  wait  node  state  log  test  cluster  stats.dat  get  datanode  num  name  nodes  get  file  system  get  name  node  admin  states  file  sys  decommission  node  stop  decommissioning  and  verify  stats  get  namesystem  downnode  fsn  cluster  starting test testclusterstats  namenodeadapter  writeconfigfile  conf   check namenode stats for multiple datanode heartbeats  namenode  startcluster  verifystats  file  testclusterstats  numdatanodes  refreshnodes  writefile  excludefile  info  ret  waitnodestate  log  testclusterstats.dat  getdatanode  numnamenodes  getfilesystem  getnamenode  adminstates  filesys  decommissionnode   stop decommissioning and verify stats  getnamesystem  downnode
__label__nflaky apply  mixed  case  item  get  conf  test  a  matching  name  (different  case)  apply  name  setup  /directory/path/  na  me  assert  equals  mock  fs  result  applymixedcase  item  getconf   test a matching name (different case)  apply  name  setup  /directory/path/name  assertequals  mockfs  result
__label__flaky bundle  job  get  executor  test  bundle  rerun2  add  record  to  bundle  action  table  add  record  to  bundle  job  table  get  id  assert  equals  get  status  execute  add  record  to  coord  job  table  call  coordinator  job  services  assert  not  null  get  action1  job  job  action2  jpa  service  bundlejobgetexecutor  testbundlererun2  addrecordtobundleactiontable  addrecordtobundlejobtable  getid  assertequals  getstatus  execute  addrecordtocoordjobtable  call  coordinatorjob  services  assertnotnull  get  action1  job  job  action2  jpaservice
__label__nflaky test  make  qualified  path  qualified  path  har  path  har  path  with  userinfo  har://file-user:passwd@localhost:80  to  uri  format  conf  get  file  system  string  path  the  qualified  path  (\%s)  did  not  match  the  expected  path  (\%s).  assert  true  make  qualified  equals  get  path  to  string  can  correctly  preserve  the  information  for  the  underlying  file  system.  testmakequalifiedpath  qualifiedpath  harpath  harpathwithuserinfo  har://file-user:passwd@localhost:80  touri  format  conf  getfilesystem  string  path  the qualified path (\%s) did not match the expected path (\%s).  asserttrue  makequalified  equals  getpath  tostring   can correctly preserve the information for the underlying file system.
__label__flaky kills  add  node  def  enters  workflow  instance  get  status  three  two  as  list  wf  test  simple  fork  exits  assert  true  four  get  end  fails  f  one  start  j  assert  equals  1  size  <worklfow-app/>  arrays  job  kills  addnode  def  enters  workflowinstance  getstatus  three  two  aslist  wf  testsimplefork  exits  asserttrue  four  get  end  fails  f  one  start  j  assertequals  1  size  <worklfow-app/>  arrays  job
__label__nflaky server  add  suppressed  logging  exceptions  log  exception  verify  zero  interactions  te3  logger  conf  full  stack  trace  should  be  logged  for  other  exceptions.  nothing  should  be  logged  for  a  suppressed  exception.  eq  any  add  terse  exceptions  call  0.0.0.0  times  dummy  call  test  log  exceptions  no  stack  trace  should  be  logged  for  a  terse  exception.  mock  verify  info  server  addsuppressedloggingexceptions  logexception  verifyzerointeractions  te3  logger  conf   full stack trace should be logged for other exceptions.   nothing should be logged for a suppressed exception.  eq  any  addterseexceptions  call  0.0.0.0  times  dummycall  testlogexceptions   no stack trace should be logged for a terse exception.  mock  verify  info
__label__flaky cancel  connectors  validator  jackson  executors  request  received  /test  http://localhost:  executor  time  unit  connection  validation  test  open  connection  new  scheduled  thread  pool  assert  that  get  input  stream  object  mapper  is  open  stop  connector  cleanup  port  is  instance  of  test  graceful  shutdown  http  get  connectors  is  not  empty  server  get  local  port  submit  build  default  validator  factory  set  port  metric  registry  sleep  result  wait  for  server  to  close  the  connectors  cancel  the  cleanup  future  since  everything  succeeded  jersey  get  await  class  loader  shutdown  now  get  validator  server  stopped  count  down  connect  is  stopped  start  future  result  get  system  class  loader  url  new  object  mapper  shutdown  invoked  char  streams  thread  call  schedule  environment  build  to  string  is  equal  to  register  cancel  connectors  validator  jackson  executors  requestreceived  /test  http://localhost:  executor  timeunit  connection  validation  test  openconnection  newscheduledthreadpool  assertthat  getinputstream  objectmapper  isopen  stop  connector  cleanup  port  isinstanceof  testgracefulshutdown  http  getconnectors  isnotempty  server  getlocalport  submit  builddefaultvalidatorfactory  setport  metricregistry  sleep  result   wait for server to close the connectors   cancel the cleanup future since everything succeeded  jersey  get  await  classloader  shutdownnow  getvalidator  serverstopped  countdown  connect  isstopped  start  futureresult  getsystemclassloader  url  newobjectmapper  shutdowninvoked  charstreams  thread  call  schedule  environment  build  tostring  isequalto  register
__label__nflaky apply  glob  mixed  case  item  get  conf  apply  n*e  name  setup  /directory/path/  na  me  assert  equals  mock  fs  result  test  a  matching  glob  pattern  (different  case)  applyglobmixedcase  item  getconf  apply  n*e  name  setup  /directory/path/name  assertequals  mockfs  result   test a matching glob pattern (different case)
__label__flaky test  keepalive  timeouts  cached  socket   and  should  have  an  xceiver  on  the  other  side.  assert  xceiver  count  dn  give  an  eof.  dfs  client  fs  create  file  sleep  peer  assert  not  null  get  clients  that  write  aren\'t  currently  re-used.  dfs  test  util  keepalive_  timeout  read  assert  equals  get  input  stream  thread  test_  file  size  from  it  again.  read  file  and  make  sure  the  xceiver  died.  get  datanode  id  testkeepalivetimeouts   cached socket  and should have an xceiver on the other side.  assertxceivercount  dn   give an eof.  dfsclient  fs  createfile  sleep  peer  assertnotnull  get   clients that write aren\'t currently re-used.  dfstestutil  keepalive_timeout  read  assertequals  getinputstream  thread  test_file  size   from it again.  readfile   and make sure the xceiver died.  getdatanodeid
__label__nflaky new  gauge  standard  deviation  of  time  for  stat  epsilon  int  gauge  ops  mb  s1  s2  info  add  s1  i  max  time  interval  min  time  for  stat  test  add  gauge  g1  long  gauge  g2  g3  number  of  ops  for  stat  eq  c1  c2  s1  i  min  time  new  counter  long  counter  mock  metrics  record  builder  has  increased  to  2   but  interval  number  is  1  for  both  intervals.  snapshot  s1  stdev  time  max  time  for  stat  time  s1  avg  time  s1  min  time  min  time  for  stat  interval  number  of  ops  for  stat  s2  avg  time  add  counter  int  counter  times  float  gauge  get  verify  new  rate  s1  i  num  ops  s2  num  ops  interval  max  time  for  stat  registry  s1  max  time  stat  should  get  new  interval  values  back  new  stat  should  get  the  same  back.  test  snapshot  s1  num  ops  average  time  for  stat  newgauge  standard deviation of time for stat  epsilon  int gauge  ops  mb  s1  s2  info  add  s1imaxtime  interval min time for stat  test  addgauge  g1  long gauge  g2  g3  number of ops for stat  eq  c1  c2  s1imintime  newcounter  long counter  mockmetricsrecordbuilder   has increased to 2  but interval number is 1 for both intervals.  snapshot  s1stdevtime  max time for stat  time  s1avgtime  s1mintime  min time for stat  interval number of ops for stat  s2avgtime  addcounter  int counter  times  float gauge  get  verify  newrate  s1inumops  s2numops  interval max time for stat  registry  s1maxtime  stat   should get new interval values back  newstat   should get the same back.  testsnapshot  s1numops  average time for stat
__label__flaky server  test  protocol  rpc  configure  super  user  ip  addresses  get  proxy  a  method  group_  names  conf  run  ret  val  assert  real_  user_  short_  name  stop  proxy  addr  user  group  information  get  server  ret  proxy  user  ugi  print  stack  trace  e  start  create  remote  user  test  real  user  group  not  specified  get  connect  address  real_  user_  name  proxy  fail  do  as  net  utils  stop  address  proxy_  user_  name  the  rpc  must  have  failed  real  user  ugi  create  proxy  user  for  testing  server  testprotocol  rpc  configuresuperuseripaddresses  getproxy  amethod  group_names  conf  run  retval  assert  real_user_short_name  stopproxy  addr  usergroupinformation  getserver  ret  proxyuserugi  printstacktrace  e  start  createremoteuser  testrealusergroupnotspecified  getconnectaddress  real_user_name  proxy  fail  doas  netutils  stop  address  proxy_user_name  the rpc must have failed   realuserugi  createproxyuserfortesting
__label__nflaky init  get  all  secrets  authentication  filter  get  current  secret  secret  str  assert  equals  secret  secret  provider  props  get  bytes  secret  bytes  assert  array  equals  assert  test  get  secrets  set  property  secret  provider  all  secrets  init  getallsecrets  authenticationfilter  getcurrentsecret  secretstr  assertequals  secret  secretproviderprops  getbytes  secretbytes  assertarrayequals  assert  testgetsecrets  setproperty  secretprovider  allsecrets
__label__flaky <workflow-app  xmlns=\'uri:oozie:workflow:0.1\'  name=\'test-wf\'>  lib  submit  get  job  info  local  oozie  <end  name=\'end\'/>  conf  wc  get  status  fs  app  path  wf  test  workflow  run  </workflow-app>  get  test  group  assert  not  null  create  workflow.xml  workflow  job  write  close  wait  for  app  start  assert  equals  get  file  system  get  client  wf  app  oozie  client  job  id  get  test  user  stop  mkdirs  set  property  create  configuration  <start  to=\'end\'/>  to  string  writer  file  evaluate  get  fs  test  case  dir  <workflow-app xmlns=\'uri:oozie:workflow:0.1\' name=\'test-wf\'>  lib  submit  getjobinfo  localoozie      <end name=\'end\'/>  conf  wc  getstatus  fs  apppath  wf  testworkflowrun  </workflow-app>  gettestgroup  assertnotnull  create  workflow.xml  workflowjob  write  close  waitfor  app  start  assertequals  getfilesystem  getclient  wfapp  oozieclient  jobid  gettestuser  stop  mkdirs  setproperty  createconfiguration      <start to=\'end\'/>  tostring  writer  file  evaluate  getfstestcasedir
__label__nflaky get  name  rename  it  to  what  looks  like  a  directory  assert  false  foo  run  suffix  argv  delete  -put  assert  true  get  file  status  /.  dotdot  dst  is  file  ensure  ..  is  interpreted  as  a  dir  src  path  assert  equals  empty  out  the  directory  and  create  to  make  copy  succeed  /  subdir  dst  path  shell  mkdirs  lfs  exists  to  string  /foo/..  make  copy  fail  dst  path  test  represents  dir  getname   rename it to what looks like a directory  assertfalse  foo  run  suffix  argv  delete  -put  asserttrue  getfilestatus  /.  dotdotdst  isfile   ensure .. is interpreted as a dir  srcpath  assertequals   empty out the directory and create to make copy succeed  /  subdirdstpath  shell  mkdirs  lfs  exists  tostring  /foo/..   make copy fail  dstpath  testrepresentsdir
__label__flaky new_val  script  executor  select  *  from  entitywithstaticcolumn  where  id  =  entity  with  static  column/insert_single_row.cql  session  given  should_insert_static  uui  ds  uuid  crud  new_static  when  of  id  value  static_col  execute  script  template  is  not  null  val  actual  random  utils  manager  one  time  based  get  string  next  long  assert  that  execute  immutable  map  then  long  update  static  is  equal  to  entity  new_val  scriptexecutor  select * from entitywithstaticcolumn where id =   entitywithstaticcolumn/insert_single_row.cql  session   given  should_insert_static  uuids  uuid  crud  new_static   when  of  id  value  static_col  executescripttemplate  isnotnull  val  actual  randomutils  manager  one  timebased  getstring  nextlong  assertthat  execute  immutablemap   then  long  updatestatic  isequalto  entity
__label__nflaky get  class  get  servlet  context  token_  validity_  sec  assert  false  simple  get  validity  when  get  cookie  path  as  list  get  init  parameter  names  get  attribute  assert  assert  true  context  init  authentication  filter  then  return  is  custom  signer  secret  provider  destroy  assert  equals  is  random  secret  get  authentication  handler  filter  assert  null  get  init  parameter  minimal  configuration  &  simple  auth  handler  (  pseudo)  mockito  get  cookie  domain  elements  mock  test  fallback  to  random  secret  provider  to  string  arrays  config  getclass  getservletcontext  token_validity_sec  assertfalse  simple  getvalidity  when  getcookiepath  aslist  getinitparameternames  getattribute  assert  asserttrue  context  init  authenticationfilter  thenreturn  iscustomsignersecretprovider  destroy  assertequals  israndomsecret  getauthenticationhandler  filter  assertnull  getinitparameter   minimal configuration & simple auth handler (pseudo)  mockito  getcookiedomain  elements  mock  testfallbacktorandomsecretprovider  tostring  arrays  config
__label__flaky init  action  num  _test  get  for  info  all  actions  test  get  action  all  columns  destroy  get  id  services  coord  action  get  for  info  jpa  executor  add  record  to  coord  job  table  resource  xml  name  coordinator  job  create  coord  action  sla  xml  coord-action-get.xml  set  system  property  true  coordinator  action  set  sla  xml  action  insert  record  coord  action  job  init  actionnum  _testgetforinfoallactions  testgetactionallcolumns  destroy  getid  services  coordactiongetforinfojpaexecutor  addrecordtocoordjobtable  resourcexmlname  coordinatorjob  createcoordaction  slaxml  coord-action-get.xml  setsystemproperty  true  coordinatoraction  setslaxml  action  insertrecordcoordaction  job
__label__nflaky store  password  trust  strategy  get  resource  to  char  array  get  name  get  issuer  dn  server  socket  new  single  thread  executor  executors  server  ssl  context  get  server  socket  factory  assert  bind  assert  not  null  nopassword  create  time  unit  boolean  ssl  context  builder  write  is  trusted  localhost  read  local  port  load  key  material  load  trust  material  issuer  dn  cn=  test  ca   ou=  http  components  project   o=  apache  software  foundation  input  stream  set  so  timeout  cert2  get  input  stream  /test-server.p12  resource1  accept  cert1  create  socket  client  ssl  context  timeout  get  local  port  submit  cert  chain  ref  emailaddress=dev@hc.apache.org   client  socket  result  cn=  test  server   ou=  http  components  project   o=  apache  software  foundation  flush  key  password  get  get  subject  dn  output  stream  close  connect  test  ssl  handshake  server  custom  trust  strategy  chain  set  assert  equals  certs  call  get  socket  factory  subject  dn2  build  subject  dn1  future  to  milliseconds  int  bound  get  output  stream  socket  create  server  socket  storepassword  truststrategy  getresource  tochararray  getname  getissuerdn  serversocket  newsinglethreadexecutor  executors  serversslcontext  getserversocketfactory  assert  bind  assertnotnull  nopassword  create  timeunit  boolean  sslcontextbuilder  write  istrusted  localhost  read  localport  loadkeymaterial  loadtrustmaterial  issuerdn  cn=test ca  ou=httpcomponents project  o=apache software foundation  inputstream  setsotimeout  cert2  getinputstream  /test-server.p12  resource1  accept  cert1  createsocket  clientsslcontext  timeout  getlocalport  submit  certchainref  emailaddress=dev@hc.apache.org    clientsocket  result  cn=test server  ou=httpcomponents project  o=apache software foundation  flush  keypassword  get  getsubjectdn  outputstream  close  connect  testsslhandshakeservercustomtruststrategy  chain  set  assertequals  certs  call  getsocketfactory  subjectdn2  build  subjectdn1  future  tomillisecondsintbound  getoutputstream  socket  createserversocket
__label__flaky msg  \""db\""  :  \""default\""   \""server\""  :  \""thrift://localhost:1234\""   check  logs  to  see  appropriate  error  message  session  logger  create  text  message  exception  caused  log  msg  logger  h  cat  constants  out  h  cat  message  handler  add  appender  assert  true  localhost  \""table\""  :  \""new  table\""   process  e  get  message  get  logger  appender  \""partitions\""  :  {  \""dt\""  :  \""2012_01_01\""   \""grid\""  :  \""  ab\""  }  h  cat  event  message  layout  fail  \""timestamp\""  :  \""123456\""   contains  hcat  handler  test  drop  event  type  message  to  string  {  }  set  string  property  msg  \""db\"" : \""default\""   \""server\"" : \""thrift://localhost:1234\""    check logs to see appropriate error message  session  logger  createtextmessage  exception caused   logmsg  logger  hcatconstants  out   hcatmessagehandler  addappender  asserttrue  localhost  \""table\"" : \""newtable\""   process  e  getmessage  getlogger  appender  \""partitions\"" : { \""dt\"" : \""2012_01_01\""  \""grid\"" : \""ab\"" }  hcateventmessage  layout  fail  \""timestamp\"" : \""123456\""   contains  hcathandler  testdropeventtypemessage  tostring  {  }  setstringproperty
__label__nflaky handler  request  get  time  jwt  public  key  set  public  key  jwt  redirect  authentication  handler  when  put  bar  service_  url  assert  get  cookies  get  jwt  get  user  name  alternate  authentication  should  not  have  thrown  an  authentication  exception  get  request  url  init  cookie  alternate  authentication  should  not  have  thrown  a  servlet  exception  then  return  get  properties  hadoop-jwt  encode  redirect  url  alternate  authenticate  assert  equals  props  token  fail  private  key  serialize  test  valid  audience  jwt  bob  mockito  response  mock  handler  request  gettime  jwt  publickey  setpublickey  jwtredirectauthenticationhandler  when  put  bar  service_url  assert  getcookies  getjwt  getusername  alternateauthentication should not have thrown an authenticationexception  getrequesturl  init  cookie  alternateauthentication should not have thrown a servletexception  thenreturn  getproperties  hadoop-jwt  encoderedirecturl  alternateauthenticate  assertequals  props  token  fail  privatekey  serialize  testvalidaudiencejwt  bob  mockito  response  mock
__label__flaky server  get  name  fs2  get  hdfs  conf  fs1  conf  dir  as  list  test  dir  helper  sleep  assert  create  hadoop  conf  /tmp/foo  server.services  string  utils  assert  not  null  /tmp/foo2  get  /tmp/foo1  server.hadoop.filesystem.cache.purge.timeout  join  hadoop  get  file  system  configuration  create  file  system  release  file  system  should  be  same  instance  because  of  caching  init  file  system  cache  set  still  around  because  of  caching  get  absolute  path  test  hdfs  helper  get  test  dir  hadoop  conf  destroy  assert  equals  services     should  not  be  around  as  lease  count  is  0  thread  common  configuration  keys  public  1  fail  server.hadoop.filesystem.cache.purge.frequency  u  mkdirs  arrays  still  around  because  of  lease  count  is  1  (fs2  is  out)  server  getname  fs2  gethdfsconf  fs1  conf  dir  aslist  testdirhelper  sleep  assert  createhadoopconf  /tmp/foo  server.services  stringutils  assertnotnull  /tmp/foo2  get  /tmp/foo1  server.hadoop.filesystem.cache.purge.timeout  join  hadoop  getfilesystemconfiguration  createfilesystem  releasefilesystem   should be same instance because of caching  init  filesystemcache  set   still around because of caching  getabsolutepath  testhdfshelper  gettestdir  hadoopconf  destroy  assertequals  services      should not be around as lease count is 0  thread  commonconfigurationkeyspublic  1  fail  server.hadoop.filesystem.cache.purge.frequency  u  mkdirs  arrays   still around because of lease count is 1 (fs2 is out)
__label__nflaky request  by  the  request  handler   and  a  200  should  actually  be  returned.  adapter  assert  equals  response  expectations  execute  put  temp  response  expectations  status  assert  request  handler  framework  run  tests  response  get  new  framework  and  set  adapter  default  uri  add  test  change  response  status  it  is  an  unmodifiable  map.  request   by the request handler  and a 200 should actually be returned.  adapter  assertequals  responseexpectations  execute  put  tempresponseexpectations  status  assert  requesthandler  framework  runtests  response  get  newframeworkandsetadapter  defaulturi  addtest  changeresponsestatus   it is an unmodifiable map.
__label__flaky get  connection  context  get  event  message  error  code  conf  parse  date  utc  date  utils  get  status  wf-app-name1  ca  job  id1  ca  id1  coordinator  action  2012-07-22  t00:00  z  get  start  time  message  type  2011-07-11  t00:00  z  init  print  stack  trace  wf  event  listner  get  text  fail  contains  create  consumer  app  type  test  on  coordinator  action  waiting  event  start  date  get  parent  id  get  app  type  cae  session  assert  false  jms  messaging  utils  get  event  status  get  user  event  status  get  id  create  session  get  topic  on  coordinator  action  event  missing  dep1  jms  context  coord  action  waiting  message  consumer  user1  get  message  type  nominal  time  receive  get  app  name  e  error  message  get  message  assert  equals  message  get  nominal  time  end  time  get  missing  dependency  session  getconnectioncontext  geteventmessage  errorcode  conf  parsedateutc  dateutils  getstatus  wf-app-name1  cajobid1  caid1  coordinatoraction  2012-07-22t00:00z  getstarttime  messagetype  2011-07-11t00:00z  init  printstacktrace  wfeventlistner  gettext  fail  contains  createconsumer  apptype  testoncoordinatoractionwaitingevent  startdate  getparentid  getapptype  cae  session  assertfalse  jmsmessagingutils  geteventstatus  getuser  eventstatus  getid  createsession  gettopic  oncoordinatoractionevent  missingdep1  jmscontext  coordactionwaitingmessage  consumer  user1  getmessagetype  nominaltime  receive  getappname  e  errormessage  getmessage  assertequals  message  getnominaltime  endtime  getmissingdependency  session
__label__nflaky rw  assert  false  channel  header  stuff;more  stuff  test  coding  from  file  flush  buffer  get  bytes  stuff;  assert  get  channel  write  line  more  stuff  dump  chbuffer  close  write  fchannel  is  completed  testfile  standard  charsets  create  temp  file  assert  equals  encoder  transfer  outbuf  header  metrics  append  rw  assertfalse  channel  header  stuff;more stuff  testcodingfromfileflushbuffer  getbytes  stuff;  assert  getchannel  writeline  more stuff  dump  chbuffer  close  write  fchannel  iscompleted  testfile  standardcharsets  createtempfile  assertequals  encoder  transfer  outbuf  header  metrics  append
__label__flaky coord  client  2009-02-02  t23:59  z  local  oozie  coord  action  get  cmd  get  id  date  utils  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  job  get  coord  client  test  coord  rerun  for  backward  support2  rerun  scope  assert  not  null  get  coordinator  action  end  re  run  coord  init  rest  constants  2009-02-01  t01:00  z  start  destroy  assert  equals  services  set  app  namespace  execute  -  add  record  to  coord  job  table  integer  services  coordinator  job  coord  job  get  cmd  schema  service  set  system  property  assert  not  same  true  status  transit  service  to  string  action1  action2  jpa  service  action3  coord-rerun-action1.xml  coordclient  2009-02-02t23:59z  localoozie  coordactiongetcmd  getid  dateutils  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordjob  getcoordclient  testcoordrerunforbackwardsupport2  rerunscope  assertnotnull  get  coordinatoraction  end  reruncoord  init  restconstants  2009-02-01t01:00z  start  destroy  assertequals  services  setappnamespace  execute  -  addrecordtocoordjobtable  integer  services  coordinatorjob  coordjobgetcmd  schemaservice  setsystemproperty  assertnotsame  true  statustransitservice  tostring  action1  action2  jpaservice  action3  coord-rerun-action1.xml
__label__nflaky fencer  test_  target  shell  command  fencer  echo  hello  try  fence  assert  true  mockito  ends  with  echo  hello:  hello  verify  test  stdout  logging  info  fencer  test_target  shellcommandfencer  echo hello  tryfence  asserttrue  mockito  endswith  echo hello: hello  verify  teststdoutlogging  info
__label__flaky after  logout  success  before  login  get  page  get  content  admin  =  true  after  login  url  contains  logout  test  shiro  login  as  feature  admin  user  =  ck  assert  true  user  =  null  login?user=ck  client  login  page  user  admin  =  null  logout  page  afterlogout  success  beforelogin  getpage  getcontent  admin = true  afterlogin  url  contains  logout  testshirologinasfeatureadmin  user = ck  asserttrue  user = null  login?user=ck  client  loginpage  user  admin = null  logoutpage
__label__nflaky headers  get  headers  set  max  empty  line  count  standard  charsets  new  decoder  custom  input  stream  assert  equals  parse  in  buffer  get  bytes  get  reason  phrase  http/1.1  200  ok  httpresponse  test  basic  message  parsing  leading  empty  lines  assert  parser  build  ok  server:  whatever  get  code  http1  config  headers  getheaders  setmaxemptylinecount  standardcharsets  newdecoder  custom  inputstream  assertequals  parse  inbuffer  getbytes  getreasonphrase  http/1.1 200 ok    httpresponse  testbasicmessageparsingleadingemptylines  assert  parser  build  ok      server: whatever    getcode  http1config
__label__flaky do  an  edit  make  sure  runtime.exit(...)  hasn\'t  been  called  at  all  yet.  have  halted  the  nn.  invalidate  both  edits  journals.  assert  true  assert  exit  invocations  test  all  edits  dirs  fail  on  flush  invalidate  edits  dir  at  index  doanedit   make sure runtime.exit(...) hasn\'t been called at all yet.   have halted the nn.   invalidate both edits journals.  asserttrue  assertexitinvocations  testalleditsdirsfailonflush  invalidateeditsdiratindex
__label__nflaky server  server  threads  run  executors  start  the  client  threads  when  they  are  all  ready  system  a:b  c:d  /echo?a=b&c=d  which  is  less  or  equal  than  the  max  =  client  threads  assert  true  executor  ready  await  count  down  read  output  max_  threads  get  thread  pool  new  fixed  thread  pool  run  many  clients  to  make  server  reach  its  maximum  number  of  threads  start  assert  equals  number  of  threads  =  execute  base  url  more  threads  are  started  than  expected   server  threads  count:  test  max  threads  get  threads  server  serverthreads  run  executors   start the client threads when they are all ready  system  a:b  c:d    /echo?a=b&c=d   which is less or equal than the max =   clientthreads  asserttrue  executor  ready  await  countdown  readoutput  max_threads  getthreadpool  newfixedthreadpool   run many clients to make server reach its maximum number of threads  start  assertequals  number of threads =   execute  baseurl  more threads are started than expected  server threads count:   testmaxthreads  getthreads
__label__flaky test  nested  fork  join  failure  add  node  def  f->(2 3 4)  2->j  3->j  4->f2  f2->(5 6)  5-j2  6-j2  j-j2  j2-end  j2  expected  to  catch  an  exception  but  did  not  encounter  any  f2  three  two  get  cause  as  list  we  invoke  fork  join  get  error  code  assert  true  four  dummy  conf  end  five  six  f  one  get  message  j  assert  equals  k  kill  j2  fail  contains  ex  parser  test  wf  <worklfow-app/>  error  code  arrays  testnestedforkjoinfailure  addnode  def         f->(2 3 4)       2->j       3->j       4->f2       f2->(5 6)       5-j2       6-j2       j-j2       j2-end        j2  expected to catch an exception but did not encounter any  f2  three  two  getcause  aslist  we  invokeforkjoin  geterrorcode  asserttrue  four  dummyconf  end  five  six  f  one  getmessage  j  assertequals  k  kill  j2  fail  contains  ex  parser  testwf  <worklfow-app/>  errorcode  arrays
__label__nflaky localhost  uribuilder  assert  equals  uri  /  set  user  info  result  password  param=stuff  assert  build  test  set  user  info  http  user  http://user:password@localhost:80/?param=stuff  localhost  uribuilder  assertequals  uri  /  setuserinfo  result  password  param=stuff  assert  build  testsetuserinfo  http  user  http://user:password@localhost:80/?param=stuff
__label__flaky negative  test  to  test  an  exception.  should  not  be  succeeding!  test  v1  job  servlet  did  not  expect  a  generic  exception.  was  expecting  x  servlet  exception  test  start  for  error  code  start  job  get  resource  name  get  message  assert  equals  xse  check  for  the  error  code  and  the  message  fail  invalid  parameter  value   action  =  start  contains  should  not  get  here!  serial  get  error  code  assert  true  -  c  error  code  negative test to test an exception. should not be succeeding!  testv1jobservlet  did not expect a generic exception. was expecting xservletexception  teststartforerrorcode  startjob  getresourcename  getmessage  assertequals  xse   check for the error code and the message  fail  invalid parameter value  action = start  contains   should not get here!  serial  geterrorcode  asserttrue  -c  errorcode
__label__nflaky http://somehost/./mypath  set  host  assert  build  somehost  http  ./mypath  set  scheme  assert  equals  uri  test  relative  path  with  authority  http://somehost/./mypath  sethost  assert  build  somehost  http  ./mypath  setscheme  assertequals  uri  testrelativepathwithauthority
__label__flaky action  num  test  coord  action  get  _test  get  action  for  check  _  e  get  id  x  data  test  case  add  record  to  coord  job  table  coordinator  job  create  coord  action  coord-action-get.xml  insert  the  action  coordinator  action  set  sla  xml  action  insert  record  coord  action  job  actionnum  testcoordactionget  _testgetactionforcheck  _e  getid  xdatatestcase  addrecordtocoordjobtable  coordinatorjob  createcoordaction  coord-action-get.xml   insert the action  coordinatoraction  setslaxml  action  insertrecordcoordaction  job
__label__nflaky init  text/html   application/json  application/json  then  return  servlet  context  assert  equals  get  accept  content  type  http  servlet  request  when  accept  get  header  result  test  get  accept  content  type  legacy  application/json   text/plain  totally_unknown  context  application/xhtml   application/json  http  servlet  response  text/plain    init  text/html  application/json  application/json  thenreturn  servletcontext  assertequals  getacceptcontenttype  httpservletrequest  when  accept  getheader  result  testgetacceptcontenttypelegacy  application/json  text/plain  totally_unknown  context  application/xhtml  application/json  httpservletresponse  text/plain
__label__flaky end.non-transient  assert  true  _test  non  transient  with  coord  action  update  test  end  non  transient  with  coord  action  update  end  workflow  action  bean  end.non-transient  asserttrue  _testnontransientwithcoordactionupdate  testendnontransientwithcoordactionupdate  end  workflowactionbean
__label__nflaky assert  correct  image2binary  (01)90012345678908(3102)001750(13)100312  ..  xxx.  x.  ........  .  x..  xxx.  x.  x.  x...  xx.  xxxxx  .  xxxx.  x.  ..  xx...  x  .  x.....  x  .  xx.....  xxxx.  x..  xx..  17.png  test  decode  row2binary17  assertcorrectimage2binary   (01)90012345678908(3102)001750(13)100312   ..xxx.x. ........ .x..xxx. x.x.x... xx.xxxxx .xxxx.x. ..xx...x .x.....x .xx..... xxxx.x.. xx..  17.png  testdecoderow2binary17
__label__flaky authorize  for  app  fs  permission  conf  workflow  instance  fs  action  fs  conf  get  test  group  get  test  user2  create  workflow.xml  has  create  file  system  authorize  for  job  app  init  get  test  user3  get  file  system  fail  1  as  ex  mkdirs  job  get  uri  get  id  -invalid  create  job  conf  wf  get  error  code  add  record  to  wf  job  table  get  set  permission  workflow  job  close  ww  file  system  test  errors  assert  equals  services  get  authority  uri  authorize  for  group  set  service  services  get  test  user  w  authorize  for  admin  to  string  error  code  get  fs  test  case  dir  authorizeforapp  fspermission  conf  workflowinstance  fsaction  fsconf  gettestgroup  gettestuser2  create  workflow.xml  has  createfilesystem  authorizeforjob  app  init  gettestuser3  getfilesystem  fail  1  as  ex  mkdirs  job  geturi  getid  -invalid  createjobconf  wf  geterrorcode  addrecordtowfjobtable  get  setpermission  workflowjob  close  ww  filesystem  testerrors  assertequals  services  getauthority  uri  authorizeforgroup  setservice  services  gettestuser  w  authorizeforadmin  tostring  errorcode  getfstestcasedir
__label__nflaky r  next  int  test  short  operations  success  new  call  test  operations  there  is  no  entry  in  cache  expected  when  the  first  operation  starts  r  nextint  testshortoperationssuccess  newcall  testoperations   there is no entry in cache expected when the first operation starts
__label__flaky rest  constants  2009-12-15  t01:00  z  get  id  assert  equals  coord  job  get  executor  get  status  execute  add  record  to  coord  job  table  call  services  fail  test  coord  rerun  in  failed  assert  not  null  get  coordinator  job  is  failed   rerun  should  throw  exception  job  job  jpa  service  restconstants  2009-12-15t01:00z  getid  assertequals  coordjobgetexecutor  getstatus  execute  addrecordtocoordjobtable  call  services  fail  testcoordreruninfailed  assertnotnull  get  coordinator job is failed  rerun should throw exception  job  job  jpaservice
__label__nflaky result  metadata  first  element  of  optional  array  should  be  the  first  field  identifier  assert  false  iso  ch  test  standard  sample1  get  optional  data  sample  codes  assert  equals  deprecation  we  should  never  reach  these  get  segment  index  decode  macro  block  get  file  id  cen  be  get  addressee  is  last  segment  last  element  of  optional  array  should  be  the  last  codeword  of  the  last  field  get  segment  count  decoded  bit  stream  parser  arbx  get  sender  optional  data  resultmetadata  first element of optional array should be the first field identifier  assertfalse  iso ch  teststandardsample1  getoptionaldata  samplecodes  assertequals  deprecation   we should never reach these  getsegmentindex  decodemacroblock  getfileid  cen be  getaddressee  islastsegment  last element of optional array should be the last codeword of the last field  getsegmentcount  decodedbitstreamparser  arbx  getsender  optionaldata
__label__flaky @  get  coord  action  close  trx  get  store  get  time  run  workflows  get  status  no-op/lib  sleep  unit_  testing  get  begin  trx  get  test  case  dir  create  test  case  sub  dir  coordinator  action  action  recovery  runnable  commit  trx  wait  for  bean  action  num  ce  in  store2  store  no-op  test  coord  action  recovery  service  for  submitted  add  record  to  job  table  -test  coord  recovery  service-  c  job  id  services  fail  get  test  user  add  record  to  action  table  action  id  0000000-  evaluate  get  coordinator  action  @  getcoordaction  closetrx  getstore  gettime  run  workflows  getstatus  no-op/lib  sleep  unit_testing  get  begintrx  gettestcasedir  createtestcasesubdir  coordinatoraction  action  recoveryrunnable  committrx  waitfor  bean  actionnum  ce  in  store2  store  no-op  testcoordactionrecoveryserviceforsubmitted  addrecordtojobtable  -testcoordrecoveryservice-c  jobid  services  fail  gettestuser  addrecordtoactiontable  actionid  0000000-  evaluate  getcoordinatoraction
__label__nflaky me=;user1=group1;user2=group1 group2  test  group  lookup  for  static  users  assert  false  conf  group  lookup  done  for  static  user  assert  true  me  get  groups  non-empty  groups  for  static  user  group  lookup  done  for  unprivileged  user  add  user1  user2  set  common  configuration  keys  set  class  expected  is  empty  groups  group2  group1  *  group  lookup  should  not  happen  for  static  users  user  groups  fakeun  privileged  group  mapping  equals  groups  not  correct  me=;user1=group1;user2=group1 group2  testgrouplookupforstaticusers  assertfalse  conf  group lookup done for static user  asserttrue  me  getgroups  non-empty groups for static user  group lookup done for unprivileged user  add  user1  user2  set  commonconfigurationkeys  setclass  expected  isempty  groups  group2  group1       * group lookup should not happen for static users       usergroups  fakeunprivilegedgroupmapping  equals  groups not correct
__label__flaky enable  init  action  executor  test  action  executor  ae  io  start  action  executor  exception  convert  exception  cause  assert  equals  check  get  cause  rmi  not  registered   but  subclass  of  io  exception  reset  init  info  fail  ex  runtime  exception  init  action  type  get  error  code  root  cause  disable  init  get  error  type  enableinit  actionexecutor  testactionexecutor  ae  io  start  actionexecutorexception  convertexception  cause  assertequals  check  getcause  rmi   not registered  but subclass of ioexception  resetinitinfo  fail  ex  runtimeexception  initactiontype  geterrorcode  rootcause  disableinit  geterrortype
__label__nflaky always_  fnfe  intercept  assert  exception  contains  missing  ioe  test  intercept  success  always_fnfe  intercept  assertexceptioncontains  missing  ioe  testinterceptsuccess
__label__flaky assert  false  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  is  pending  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  assert  not  null  get  coordinator  action  end  job  wait  for  start  assert  equals  x  data  test  case  current  dateplus  month  execute  add  record  to  coord  job  table  coordinator  job  job  id  services  runnable  coord-action-get.xml  test  coord  status  transit  service  suspended  by  user  job  jpa  service  evaluate  assertfalse  getcurrentdateafterincrementinginmonths  getid  run  dateutils  ispending  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  assertnotnull  get  coordinatoraction  end  job  waitfor  start  assertequals  xdatatestcase  currentdateplusmonth  execute  addrecordtocoordjobtable  coordinatorjob  jobid  services  runnable  coord-action-get.xml  testcoordstatustransitservicesuspendedbyuser  job  jpaservice  evaluate
__label__nflaky render  thumbnail  test  thumbnail  yuv  source  cols  rows  assert  array  equals  renderthumbnail  testthumbnail  yuv  source  cols  rows  assertarrayequals
__label__flaky get  workflow  instance  add  record  to  wf  action  table  get  id  test  wf  kill  success  after  node  def  upgrade  workflow  instance  get  status  sleep  add  record  to  wf  job  table  assert  not  null  lite  workflow  store  service  get  action  workflow  job  wf  instance  wf  job  get  cmd  init  wf  action  get  cmd  destroy  assert  equals  services  execute  call  1  services  workflow  action  set  system  property  job  jpa  service  getworkflowinstance  addrecordtowfactiontable  getid  testwfkillsuccessafternodedefupgrade  workflowinstance  getstatus  sleep  addrecordtowfjobtable  assertnotnull  liteworkflowstoreservice  get  action  workflowjob  wfinstance  wfjobgetcmd  init  wfactiongetcmd  destroy  assertequals  services  execute  call  1  services  workflowaction  setsystemproperty  job  jpaservice
__label__nflaky get  subject  get  name  get  private  credentials  evaluate  challenge  subject  run  keytab  file  found  should  fail  as  we  send  a  service  ticket  instead  of  tgt  to  kdc.  create  sasl  client  ugi  client  principal  host  the  first  ticket  is  not  tgt  user  group  information  no  service  ticket  for  get  server  add  test  krbtgt  fix  kerberos  ticket  order  props  login  user  from  keytab  and  return  ugi  do  as  intercept  dispose  make  sure  we  can  still  get  new  service  ticket  after  the  fix.  server1  protocol  assert  false  get  mechanism  name  is  present  find  first  remove  check  if  tgt  is  the  first  ticket  after  the  fix.  stream  assert  true  find  any  get  client  make  sure  the  first  ticket  is  not  tgt  map  sasl  get  canonical  path  c  ticket  auth  method  filter  move  tgt  to  the  last  t  the  first  ticket  is  still  tgt   the  implementation  in  jdk  may  have  been  changed   server2  protocol  please  reconsider  the  problem  in  hadoop-13433  starts  with  getsubject  getname  getprivatecredentials  evaluatechallenge  subject  run  keytabfile   found   should fail as we send a service ticket instead of tgt to kdc.  createsaslclient  ugi  clientprincipal  host  the first ticket is not tgt  usergroupinformation  no service ticket for   getserver  add  test  krbtgt  fixkerberosticketorder  props  loginuserfromkeytabandreturnugi  doas  intercept  dispose   make sure we can still get new service ticket after the fix.  server1protocol  assertfalse  getmechanismname  ispresent  findfirst  remove   check if tgt is the first ticket after the fix.  stream  asserttrue  findany  get  client   make sure the first ticket is not tgt  map  sasl  getcanonicalpath  c  ticket  authmethod  filter   move tgt to the last  t  the first ticket is still tgt    the implementation in jdk may have been changed    server2protocol  please reconsider the problem in hadoop-13433  startswith
__label__flaky jms  topic  service  =  workflow   ${username}  setup  services  for  topic  coord  get  init  get  topic  pattern  properties  set  print  stack  trace  get  conf  workflow  e  =coord  get  message  destroy  jms  topic  service  assert  equals  services  props  fail  get  value  services  test  topic  properties2  app  type  jmstopicservice   = workflow   ${username}  setupservicesfortopic  coord  get  init  gettopicpatternproperties  set  printstacktrace  getconf  workflow  e  =coord  getmessage  destroy  jmstopicservice  assertequals  services  props  fail  getvalue  services  testtopicproperties2  apptype
__label__nflaky handler  request  get  time  jwt  foo  public  key  set  public  key  jwt  redirect  authentication  handler  when  put  redirect_  location  alternate  authentication  should  not  have  thrown  a  authentication  exception  service_  url  get  cookies  get  jwt  verify  get  request  url  init  cookie  alternate  authentication  should  not  have  thrown  a  servlet  exception  then  return  get  properties  hadoop-jwt  encode  redirect  url  alternate  authenticate  send  redirect  props  token  fail  private  key  serialize  bob  mockito  response  test  invalid  audience  jwt  mock  handler  request  gettime  jwt  foo  publickey  setpublickey  jwtredirectauthenticationhandler  when  put  redirect_location  alternateauthentication should not have thrown a authenticationexception  service_url  getcookies  getjwt  verify  getrequesturl  init  cookie  alternateauthentication should not have thrown a servletexception  thenreturn  getproperties  hadoop-jwt  encoderedirecturl  alternateauthenticate  sendredirect  props  token  fail  privatekey  serialize  bob  mockito  response  testinvalidaudiencejwt  mock
__label__flaky a  variables  timers  get  all  counters  incr  assert  equals  counter  cron1  samplers  add  cron  add  variable  1  get  value  size  inst  get  get  own  test  all  a  variables  timers  getall  counters  incr  assertequals  counter  cron1  samplers  addcron  addvariable  1  getvalue  size  inst  get  getown  testall
__label__nflaky get  name  get  user  principal  token  signed  token_  validity_  sec  sign  when  as  list  get  init  parameter  names  assert  secret  provider  management.operation.return  signer  http://foo:8080/bar  get  request  url  init  cookie  then  return  string  signer  secret  provider  creator  destroy  invocation  get  init  parameter  new  string  signer  secret  provider  set  property  true  mock  get  arguments  arrays  request  set  expires  secret  system  secret  provider  props  do  answer  do  filter  get  cookies  authenticated  url  chain  authentication  filter  test  do  filter  authenticated  assert  equals  any  token  filter  p  args  get  mocked  servlet  context  with  string  signer  t  answer  mockito  u  get  remote  user  response  elements  current  time  millis  to  string  config  getname  getuserprincipal  tokensigned  token_validity_sec  sign  when  aslist  getinitparameternames  assert  secretprovider  management.operation.return  signer  http://foo:8080/bar  getrequesturl  init  cookie  thenreturn  stringsignersecretprovidercreator  destroy  invocation  getinitparameter  newstringsignersecretprovider  setproperty  true  mock  getarguments  arrays  request  setexpires  secret  system  secretproviderprops  doanswer  dofilter  getcookies  authenticatedurl  chain  authenticationfilter  testdofilterauthenticated  assertequals  any  token  filter  p  args  getmockedservletcontextwithstringsigner  t  answer  mockito  u  getremoteuser  response  elements  currenttimemillis  tostring  config
__label__flaky delete  list  test  delete  coords  rollback  coordinator  action  c2  should  not  have  been  deleted  get  id  action  c1  add  record  to  coord  action  table  action  c2  action  a1  coordinator  job  a  should  not  have  been  deleted  action  a2  deactivate  job  b  job  a  assert  not  null  remove  fault  injection  job  c  get  coordinator  action  c1  should  not  have  been  deleted  coordinator  action  coordinator  action  a2  should  not  have  been  deleted  add  should  have  skipped  commit  for  failover  testing  coordinator  action  a1  should  not  have  been  deleted  skipping  commit  for  failover  testing  coordinator  job  c  should  not  have  been  deleted  get  message  coordinator  action  b2  should  not  have  been  deleted  assert  equals  skip  commit  fault  injection  action  b1  execute  add  record  to  coord  job  table  action  b2  fault  injection  coordinator  job  services  fail  coord-action-get.xml  re  org.apache.oozie.command.  skip  commit  fault  injection  set  system  property  true  coordinator  action  b1  should  not  have  been  deleted  set  fault  injection  to  true   so  transaction  is  roll  backed  coordinator  job  b  should  not  have  been  deleted  jpa  service  deletelist  testdeletecoordsrollback  coordinator action c2 should not have been deleted  getid  actionc1  addrecordtocoordactiontable  actionc2  actiona1  coordinator job a should not have been deleted  actiona2  deactivate  jobb  joba  assertnotnull   remove fault injection  jobc  get  coordinator action c1 should not have been deleted  coordinatoraction  coordinator action a2 should not have been deleted  add  should have skipped commit for failover testing  coordinator action a1 should not have been deleted  skipping commit for failover testing  coordinator job c should not have been deleted  getmessage  coordinator action b2 should not have been deleted  assertequals  skipcommitfaultinjection  actionb1  execute  addrecordtocoordjobtable  actionb2  faultinjection  coordinatorjob  services  fail  coord-action-get.xml  re  org.apache.oozie.command.skipcommitfaultinjection  setsystemproperty  true  coordinator action b1 should not have been deleted   set fault injection to true  so transaction is roll backed  coordinator job b should not have been deleted  jpaservice
__label__nflaky stream  abort  then  return  in  stream  any  when  eofstream  get  wrapped  stream  times  assert  assert  null  mockito  abort  assert  true  test  abort  connection  verify  eofwatcher  boolean  close  is  self  closed  streamabort  thenreturn  instream  any  when  eofstream  getwrappedstream  times  assert  assertnull  mockito  abort  asserttrue  testabortconnection  verify  eofwatcher  boolean  close  isselfclosed
__label__flaky mapreduce.job.cache.files  lm  job  conf  assert  false  user.name  when  there  is  prepare  block  in  workflow  xml  fs  create  job  conf  test  setup  launcher  info  hadoop2_0_2_alpha  workaround  1@a  aa.jar#aa.jar  assert  true  get  get  boolean  get  name  node  uri  set  action  conf  1@a-0  get  conf  action  dir  a.jar aa.jar#aa.jar  assert  equals  get  file  system  get  authority  services  1  get  test  user  new  dir  fs.default.name  setup  launcher  info  setting  up  the  job  configuration  oozie.hadoop-2.0.2-alpha.workaround.for.distributed.cache  get  fs  test  case  dir  set  boolean  mapreduce.job.cache.files    lm  jobconf  assertfalse  user.name   when there is prepare block in workflow xml  fs  createjobconf  testsetuplauncherinfohadoop2_0_2_alphaworkaround  1@a  aa.jar#aa.jar  asserttrue  get  getboolean  getnamenodeuri  set  actionconf  1@a-0  getconf  actiondir  a.jar aa.jar#aa.jar  assertequals  getfilesystem  getauthority  services  1  gettestuser  newdir  fs.default.name  setuplauncherinfo   setting up the job configuration  oozie.hadoop-2.0.2-alpha.workaround.for.distributed.cache  getfstestcasedir  setboolean
__label__nflaky get  encrypted  key  version  get  name  be  the  same  re-encrypting  the  same  eek  with  the  same  ek  should  be  deterministic  ek1  encryption  key  key  provider  crypto  extension  name  of  eek  should  be  encryption  key  name  reencrypt  ek1  ek3  generate  a  new  eek  ek2  roll  new  version  assert  array  equals  reencrypt  encrypted  key  decrypt  encrypted  key  assert  not  null  decrypt  the  new  eek  into  an  ek  and  check  it  generate  encrypted  key  get  encryption  key  name  k1  k2  assert  equals  kp  ext  get  version  name  expected  encrypted  key  material  encryption_  key_  name  get  material  re-encrypting  an  eek  with  the  same  version  ek  should  be  no-op  fail  decrypt  eek  into  an  ek  and  check  it  re-encrypted  eek  should  have  different  material  roll  the  ek  equals  ek2a  test  reencrypt  encrypted  key  arrays  version  name  of  eek  should  be  eek  length  of  encryption  key  material  and  eek  material  should  getencryptedkeyversion  getname  be the same   re-encrypting the same eek with the same ek should be deterministic  ek1  encryptionkey  keyprovidercryptoextension  name of eek should be encryption key name   reencrypt ek1  ek3   generate a new eek  ek2  rollnewversion  assertarrayequals  reencryptencryptedkey  decryptencryptedkey  assertnotnull   decrypt the new eek into an ek and check it  generateencryptedkey  getencryptionkeyname  k1  k2  assertequals  kpext  getversionname  expected encrypted key material  encryption_key_name  getmaterial   re-encrypting an eek with the same version ek should be no-op  fail   decrypt eek into an ek and check it  re-encrypted eek should have different material   roll the ek  equals  ek2a  testreencryptencryptedkey  arrays  version name of eek should be eek  length of encryption key material and eek material should
__label__flaky rows_  one  test  page  filter  test  row  one-2  test  row  one-3  grab  first  2  rows  qualifiers_  one  families  expected  k  vs  grab  all  6  rows  values  grab  first  4  rows  (6  cols  per  row)  expected  keys  k  vs  in  first  6  rows  expected  rows  rows_  two  copy  of  set  filter  test  row  two-0  qualifiers_  two  verify  scan  full  verify  scan  test  row  two-3  arrays  test  row  two-2  grab  first  row  rows_one  testpagefilter   testrowone-2   testrowone-3   grab first 2 rows  qualifiers_one  families  expectedkvs   grab all 6 rows  values   grab first 4 rows (6 cols per row)  expectedkeys   kvs in first 6 rows  expectedrows  rows_two  copyof  setfilter   testrowtwo-0  qualifiers_two  verifyscanfull  verifyscan   testrowtwo-3  arrays   testrowtwo-2   grab first row
__label__nflaky unknown:///  set  e  get  providers  get  message  conf  assert  equals  test  factory  errors  no  key  provider  factory  for  unknown:///  in  assert  true  should  throw!  key  provider  factory  providers  unknown:///  set  e  getproviders  getmessage  conf  assertequals  testfactoryerrors  no keyproviderfactory for unknown:/// in   asserttrue  should throw!  keyproviderfactory  providers
__label__flaky add  record  to  coord  job  table  for  waiting  get  id  run  get  status  /2009/22/  coord  get  cmd  sleep  coord-action-for-action-input-check.xml  /2009/08/  assert  not  null  get  test  case  dir  get  coordinator  action  create  dir  action  coord-job-for-action-input-check.xml  add  record  to  coord  action  table  for  waiting  recovery  runnable  wait  for  /2009/15/  execute  new  action  recovery  waiting  coord  action  failed   action  is  waiting  coordinator  job  services  fail  test  coord  action  recovery  service  for  waiting  /2009/29/  action  id  job  jpa  service  evaluate  addrecordtocoordjobtableforwaiting  getid  run  getstatus  /2009/22/  coordgetcmd  sleep  coord-action-for-action-input-check.xml  /2009/08/  assertnotnull  gettestcasedir  get  coordinatoraction  createdir  action  coord-job-for-action-input-check.xml  addrecordtocoordactiontableforwaiting  recoveryrunnable  waitfor  /2009/15/  execute  newaction  recovery waiting coord action failed  action is waiting  coordinatorjob  services  fail  testcoordactionrecoveryserviceforwaiting  /2009/29/  actionid  job  jpaservice  evaluate
__label__nflaky fbll9  bu  zdkv16  w  xe  w  gq+k  td7  e  te7l0fq  xjq5  enrif  oai0  l/p  xw  vv  s2jr  fk  kq  rl  rx  rgu  nae  ebz2  wy  9a  ty  r+  hgh  cfvwo  cegc9r  a  vw/  d  la  rri  so/jn  e  xz  yk6  xlvkh+hx5  u  xr  j7  oyc7  jj  z  uc3g9k  cwor  th  cx  mzc1x  a==  parse  rsa  public  key  b3  ax  dtal  bg  nvb  as  tbf  rlc3  qx  ej  aq  bg  nvbamtc  wxv  y2  fsa  g9zd  dc  bnz  an  bgkqhki  g9w0  baqefaaob  pem  header  get  message  7  o  puua  hb25  j8isi  oy  a3  ri  wu  jg  ql  x  tdk  c  aw  eaatan  bgkqhki  g9w0  baqufaao  bg  q  ad  r  uy  c  uq  e9sdim  -----  begin  certificate-----  c3  qx  ej  aq  bg  nvbamtc  wxv  y2  fsa  g9zd  d  ae  fw0x  nt  ax  md  iy  mte5  mj  ra  fw0x  nj  ax  md  iy  mte5  mj  ra  mf8x  c25fm  u5  h71  wgoi1  kle5  tf  dm  io+hqh5xqu1  ynr  zz9i6  d94g+2  ay  yr9  bpv  h4  zfd  hs7r9  au7c3kq68  v  fail  miic  oj  cc  aa  og  aw  ib  ag  ijan  xi/o  wxv  j  nz  ma0  gc  sq  gs  ib3  dqebbquamf8x  cz  aj  bg  nvbayt  al  vtmq0w  -----  end  certificate-----  se  contains  cz  aj  bg  nvbayt  al  vtmq0w  cw  ydvqqi  ew  ruzxn0  mq0w  cw  ydvqqh  ew  ruzxn0  mq8w  dqydvqqk  ew  ziyw  rv  assert  true  test  invalid  pem  with  header  and  footer  j  q  awg  yk  cg  ye  awpfp  ldi7d  wth  nz  e  tt+  l7618/d  wuq  fb/  c7o1j  ix  fgb  kovib6d5  ymv  ub  jck5  p  yx  fkz  certificate  util  should  not  have  thrown  servlet  exception  pem  cw  ydvqqi  ew  ruzxn0  mq0w  cw  ydvqqh  ew  ruzxn0  mq8w  dqydvqqk  ew  ziyw  rvb3  ax  dtal  bg  nvb  as  tbf  rl  fbll9buzdkv16wxewgq+ktd7ete7l0fqxjq5enrifoai0l/pxwvvs2jrfkkqrlrxrgunaeebz2wy  9atyr+hghcfvwocegc9ravw/dlarriso/jnexzyk6xlvkh+hx5uxrj7oyc7jjzuc3g9kcworthcx  mzc1xa==  parsersapublickey  b3axdtalbgnvbastbfrlc3qxejaqbgnvbamtcwxvy2fsag9zddcbnzanbgkqhkig9w0baqefaaob  pem header  getmessage  7opuuahb25j8isioya3riwujgqlxtdkcaweaatanbgkqhkig9w0baqufaaobgqadruycuqe9sdim  -----begin certificate-----    c3qxejaqbgnvbamtcwxvy2fsag9zddaefw0xntaxmdiymte5mjrafw0xnjaxmdiymte5mjramf8x  c25fmu5h71wgoi1kle5tfdmio+hqh5xqu1ynrzz9i6d94g+2ayyr9bpvh4zfdhs7r9au7c3kq68v  fail  miicojccaaogawibagijanxi/owxvjnzma0gcsqgsib3dqebbquamf8xczajbgnvbaytalvtmq0w    -----end certificate-----  se  contains  czajbgnvbaytalvtmq0wcwydvqqiewruzxn0mq0wcwydvqqhewruzxn0mq8wdqydvqqkewziywrv  asserttrue  testinvalidpemwithheaderandfooter  jqawgykcgyeawpfpldi7dwthnzett+l7618/dwuqfb/c7o1jixfgbkovib6d5ymvubjck5pyxfkz  certificateutil  should not have thrown servletexception  pem  cwydvqqiewruzxn0mq0wcwydvqqhewruzxn0mq8wdqydvqqkewziywrvb3axdtalbgnvbastbfrl
__label__flaky play  window  update  stream  ids  data  read  sends  window  update  header  entries  math  send  frames  summing  to  window  update  threshold.  type_  headers  variant  connection  buffer  connection  window  update  banana  add  read  connection  in  count  max  frame  size  sent  stream  window  update  contains  syn_  stream  size  get  source  syn  stream  stream  new  stream  android  type_  window_  update  accept  frame  min  stream  assert  true  peer  default_  initial_  window_  size  get  response  headers  take  frame  window  update  threshold  a  window  update  b  syn  reply  set  variant  and  client  assert  equals  j  send  frame  spdy3  play  it  back.  play  windowupdatestreamids  data  readsendswindowupdate  headerentries  math   send frames summing to windowupdatethreshold.  type_headers  variant  connection  buffer   connection window update  banana  add  read   connection  in  count  maxframesize  sent   stream window update  contains   syn_stream  size  getsource  synstream   stream  newstream  android  type_window_update  acceptframe  min  stream  asserttrue  peer  default_initial_window_size  getresponseheaders  takeframe  windowupdatethreshold  a  windowupdate  b  synreply  setvariantandclient  assertequals  j  sendframe  spdy3   play it back.
__label__nflaky get  class  get  name  time  not  an  array:  info  new  line  and  {}  root  node  assert  true  now  outcome  datacenter  problems  date  text  l4j  quoted\""  text  value  e  is  textual  log4  json  test  nested  exception  parse  assert  entry  equals  that  box  caught  fire  3  years  ago  -  time  stamp  node  to  json  contains  not  a  string:  ti  assert  node  contains  no  \'-\'  in  to  string  is  array  :  ioe  and  colon  characters  are  in  the  string.  getclass  getname  time  not an array:   info  new line   and {}  rootnode  asserttrue  now  outcome  datacenter problems  datetext  l4j  quoted\""  textvalue  e  istextual  log4json  testnestedexception  parse  assertentryequals  that box caught fire 3 years ago  -  timestamp  node  tojson  contains  not a string:   ti  assertnodecontains  no \'-\' in   tostring  isarray  :  ioe   and colon characters are in the string.
__label__flaky add  record  to  bundle  action  table  test  purge  bundle  with  coord  child  with  wf  child  with  sub  wf2  add  record  to  wf  action  table  coord  action  get  cmd  get  num  days  to  not  be  purged  date  utils  workflow  instance  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  sub  workflow  job  should  not  have  been  purged  get  end  time  bundle  job  bundle  job  bean  assert  not  null  coordinator  action  job  wf  action  wf  job  get  cmd  bundle  action  should  not  have  been  purged  execute  subwf  action  get  cmd  bundle  job  should  not  have  been  purged  coordinator  job  1  coord  job  get  cmd  fail  workflow  action  coord  action  succeeded  workflow  action  should  not  have  been  purged  subwf  job  get  cmd  bundle  job  get  cmd  get  id  coord  job  sub  workflow  action  should  not  have  been  purged  wf  job  add  record  to  wf  job  table  get  workflow  job  should  not  have  been  purged  workflow  job  subwf  action  get  app  name  bundle  action  wf  action  get  cmd  coordinator  action  should  not  have  been  purged  2011-01-01  t01:00  z  add  record  to  bundle  job  table  assert  equals  get  last  modified  time  add  record  to  coord  job  table  coordinator  job  should  not  have  been  purged  call  services  coord-action-get.xml  subwf  job  jpa  service  bundle  action  get  cmd  addrecordtobundleactiontable  testpurgebundlewithcoordchildwithwfchildwithsubwf2  addrecordtowfactiontable  coordactiongetcmd  getnumdaystonotbepurged  dateutils  workflowinstance  getstatus  addrecordtocoordactiontable  parsedateoozietz  subworkflow job should not have been purged  getendtime  bundlejob  bundlejobbean  assertnotnull  coordinatoraction  job  wfaction  wfjobgetcmd  bundle action should not have been purged  execute  subwfactiongetcmd  bundle job should not have been purged  coordinatorjob  1  coordjobgetcmd  fail  workflowaction  coordaction  succeeded  workflow action should not have been purged  subwfjobgetcmd  bundlejobgetcmd  getid  coordjob  subworkflow action should not have been purged  wfjob  addrecordtowfjobtable  get  workflow job should not have been purged  workflowjob  subwfaction  getappname  bundleaction  wfactiongetcmd  coordinator action should not have been purged  2011-01-01t01:00z  addrecordtobundlejobtable  assertequals  getlastmodifiedtime  addrecordtocoordjobtable  coordinator job should not have been purged  call  services  coord-action-get.xml  subwfjob  jpaservice  bundleactiongetcmd
__label__nflaky lambdas  any  instance  method  reference  apply  get  impl  class  get  impl  method  name  replace  ()  lninja/  result;  get  canonical  name  is  get  kind  serialized  lambda  assert  that  get  functional  interface  method  name  get  captured  arg  count  home  lambda  reflect  kind  get  serialized  lambda  get  impl  method  signature  lambda  info  lambdas  anyinstancemethodreference  apply  getimplclass  getimplmethodname  replace  ()lninja/result;  getcanonicalname  is  getkind  serializedlambda  assertthat  getfunctionalinterfacemethodname  getcapturedargcount  home  lambda  reflect  kind  getserializedlambda  getimplmethodsignature  lambdainfo
__label__flaky init  random  fail  test  configuration  set  system  property  destroy  uuid  service  counter  services  init  random  fail  testconfiguration  setsystemproperty  destroy  uuidservice  counter  services
__label__nflaky cursor  stuff\""\\\""more\\\"";\""stuff;  length  raw  token  parser  assert  equals  create  buffer  result  test  token  parsing  escaped  delimiter  assert  parser  stuff\""more\"";stuff  parse  value  init_  bitset  cursor  stuff\""\\\""more\\\"";\""stuff;  length  raw  tokenparser  assertequals  createbuffer  result  testtokenparsingescapeddelimiter  assert  parser  stuff\""more\"";stuff  parsevalue  init_bitset
__label__flaky set  classes  to  be  excluded  assert  false  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  get  status  is  pending  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  assert  not  null  get  coordinator  action  end  keeping  wait  time  to  20s  to  ensure  status  is  updated  current  date  plus  month  wait  for  init  get  conf  test  coord  status  transit  service  suspended  with  error  false  start  destroy  assert  equals  services  x  data  test  case  execute  add  record  to  coord  job  table  services  coordinator  job  job  id  runnable  coord-action-get.xml  excluded  services  set  system  property  status  transit  service  job  jpa  service  evaluate  setclassestobeexcluded  assertfalse  getcurrentdateafterincrementinginmonths  getid  run  dateutils  getstatus  ispending  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  assertnotnull  get  coordinatoraction  end   keeping wait time to 20s to ensure status is updated  currentdateplusmonth  waitfor  init  getconf  testcoordstatustransitservicesuspendedwitherror  false  start  destroy  assertequals  services  xdatatestcase  execute  addrecordtocoordjobtable  services  coordinatorjob  jobid  runnable  coord-action-get.xml  excludedservices  setsystemproperty  statustransitservice  job  jpaservice  evaluate
__label__nflaky gen  key  pair  handler  request  get  time  jwt  get  public  public  key  set  public  key  when  redirect_  location  alternate  authentication  should  not  have  thrown  a  authentication  exception  service_  url  get  cookies  get  jwt  verify  get  request  url  rsa  init  kpg  cookie  kp  alternate  authentication  should  not  have  thrown  a  servlet  exception  then  return  get  properties  hadoop-jwt  encode  redirect  url  alternate  authenticate  key  pair  generator  send  redirect  ljm  props  token  fail  private  key  serialize  bob  mockito  response  mock  get  instance  initialize  test  unable  to  parse  jwt  genkeypair  handler  request  gettime  jwt  getpublic  publickey  setpublickey  when  redirect_location  alternateauthentication should not have thrown a authenticationexception  service_url  getcookies  getjwt  verify  getrequesturl  rsa  init  kpg  cookie  kp  alternateauthentication should not have thrown a servletexception  thenreturn  getproperties  hadoop-jwt  encoderedirecturl  alternateauthenticate  keypairgenerator  sendredirect  ljm  props  token  fail  privatekey  serialize  bob  mockito  response  mock  getinstance  initialize  testunabletoparsejwt
__label__flaky call  post  my  json  rest  servlet  get  test  multiple  resources  no  resource  http  servlet  response  invoke  assert  equals  /resource1  /resource2  run  test    call  post  myjsonrestservlet  get  testmultipleresourcesnoresource  httpservletresponse  invoke  assertequals  /resource1  /resource2  runtest
__label__nflaky test  no  alias  print  output  kind:  test  alias  print  exit  code  test  legacy  print  exit  code  assert  false  run  token  filename  dt  -alias  assert  true  not-a-serivce  service  test  simple  print  output  kind:  out  content  test  no  alias  print  output  service:  test  simple  print  output  service:  assert  equals  token  legacy  file  test  print  args  rc  print  contains  test  no  alias  print  exit  code  kind  test  simple  print  exit  code  reset  to  string  test no alias print output kind:    test alias print exit code  test legacy print exit code  assertfalse  run  tokenfilename  dt  -alias  asserttrue  not-a-serivce  service  test simple print output kind:    outcontent  test no alias print output service:    test simple print output service:    assertequals  tokenlegacyfile  testprint  args  rc  print  contains  test no alias print exit code  kind  test simple print exit code  reset  tostring
__label__flaky add  assert  grab  annotation  fully  customized  my-type  assert  equals  annotation  node  get  annotations  my-classifier  org.springframework.boot  grab  annotations  1.2.3  size  get  spring-boot-starter-logging  add  assertgrabannotation  fullycustomized  my-type  assertequals  annotationnode  getannotations  my-classifier  org.springframework.boot  grabannotations  1.2.3  size  get  spring-boot-starter-logging
__label__nflaky file_  footer  file_  header  presentation_  footer  header  footer  check  presentation_  header  presentation_  footer  null  presentation  header  file_  header  file_footer  file_header  presentation_footer  headerfootercheck  presentation_header  presentation_footer   nullpresentationheader  file_header
__label__flaky end_  points  rest  constants  is_  security_  enabled  get  context  url  oozie  url  mock  dag  engine  service  run  assert  equals  args  call  1  -oozie  size  job  test  suspend  servlet_  classes  -suspend  run  test  end_points  restconstants  is_security_enabled  getcontexturl  oozieurl  mockdagengineservice  run  assertequals  args  call  1  -oozie  size  job  testsuspend  servlet_classes  -suspend  runtest
__label__nflaky request  conn  resolve  get  request  response  captor  send  response  header  error  when  receive  request  header  request  handler  assert  httpservice  assert  not  null  context  create  for  class  verify  get  code  close  process  argument  captor  http  status  then  return  test  method  not  supported  capture  handle  assert  equals  send  response  entity  assert  same  get  entity  whatever  /  get  value  do  throw  response  factory  mockito  response  http  core  context  new  http  response  httprocessor  handle  request  handler  resolver  request  conn  resolve  getrequest  responsecaptor  sendresponseheader  error  when  receiverequestheader  requesthandler  assert  httpservice  assertnotnull  context  create  forclass  verify  getcode  close  process  argumentcaptor  httpstatus  thenreturn  testmethodnotsupported  capture  handle  assertequals  sendresponseentity  assertsame  getentity  whatever  /  getvalue  dothrow  responsefactory  mockito  response  httpcorecontext  newhttpresponse  httprocessor  handlerequest  handlerresolver
__label__flaky chmod1  chmod2  chmod3  source  create  context  grandchild1  grandchild3  xml  get  path  get  file  status  test  do  operations  mkdir  <root><mkdir  path=\'\'{0}\'\'/>  get  permission  ae  format  parse  xml  <chmod  path=\'\'{4}\'\'  permissions=\'\'-rwxrwxrwx\'\'/>  get  file  system  </root>  str  rwxrwx---  mkdirs  <chmod  path=\'\'{5}\'\'  permissions=\'\'-rwxrwx---\'\'  dir-files=\'\'false\'\'/>  new  file2  <fs/>  new  file1  assert  false  do  operations  <touchz  path=\'\'{7}\'\'/>  child2  fs  delete  child3  child1  assert  true  <move  source=\'\'{2}\'\'  target=\'\'{3}\'\'/>  message  format  xml  utils  <delete  path=\'\'{1}\'\'/>  to  uri  assert  equals  rwxrwxrwx  target  <touchz  path=\'\'{6}\'\'/>  assert  not  same  exists  to  string  create  new  file  get  fs  test  case  dir  <chmod  path=\'\'{8}\'\'  permissions=\'\'-rwxrwx---\'\'>  <recursive/>  </chmod>  chmod1  chmod2  chmod3  source  createcontext  grandchild1  grandchild3  xml  getpath  getfilestatus  testdooperations  mkdir  <root><mkdir path=\'\'{0}\'\'/>  getpermission  ae  format  parsexml  <chmod path=\'\'{4}\'\' permissions=\'\'-rwxrwxrwx\'\'/>  getfilesystem  </root>  str  rwxrwx---  mkdirs  <chmod path=\'\'{5}\'\' permissions=\'\'-rwxrwx---\'\' dir-files=\'\'false\'\'/>  newfile2  <fs/>  newfile1  assertfalse  dooperations  <touchz path=\'\'{7}\'\'/>  child2  fs  delete  child3  child1  asserttrue  <move source=\'\'{2}\'\' target=\'\'{3}\'\'/>  messageformat  xmlutils  <delete path=\'\'{1}\'\'/>  touri  assertequals  rwxrwxrwx  target  <touchz path=\'\'{6}\'\'/>  assertnotsame  exists  tostring  createnewfile  getfstestcasedir  <chmod path=\'\'{8}\'\' permissions=\'\'-rwxrwx---\'\'> <recursive/> </chmod>
__label__nflaky next  @  get  subject  get  class  get  private  credentials  get  name  create  server  config  subject  foo  keytab  create  client  config  kerberos  configuration  principals  get  realm  login  principal  logout  iterator  assert  work  dir  add  test  kerberos  login  is  empty  assert  equals  server  login  kdc  get  principals  login  context  foo.keytab  get  work  dir  size  client  login  create  principal  get  kdc    next  @  getsubject  getclass  getprivatecredentials  getname  createserverconfig  subject  foo  keytab  createclientconfig  kerberosconfiguration  principals  getrealm  login  principal  logout  iterator  assert  workdir  add  testkerberoslogin  isempty  assertequals   server login  kdc  getprincipals  logincontext  foo.keytab  getworkdir  size   client login  createprincipal  getkdc
__label__flaky bundle  job  should  have  been  purged  bundle  action  should  have  been  purged  add  record  to  bundle  action  table  add  record  to  wf  action  table  coord  action  get  cmd  date  utils  workflow  instance  get  status  test  purge  bundle  with  coord  child  with  wf  child3  add  record  to  coord  action  table  parse  date  oozie  tz  bundle  job  bundle  job  bean  assert  not  null  coordinator  action  should  have  been  purged  coordinator  action  job  wf  action  wf  job  get  cmd  execute  coordinator  job  1  coord  job  get  cmd  fail  workflow  action  coord  action  succeeded  je  bundle  job  get  cmd  get  id  coord  job  wf  job  workflow  job  should  have  been  purged  add  record  to  wf  job  table  get  error  code  get  workflow  job  get  app  name  bundle  action  coordinator  job  should  have  been  purged  workflow  action  should  have  been  purged  wf  action  get  cmd  2011-01-01  t01:00  z  add  record  to  bundle  job  table  assert  equals  add  record  to  coord  job  table  call  services  coord-action-get.xml  error  code  jpa  service  bundle  action  get  cmd  bundle job should have been purged  bundle action should have been purged  addrecordtobundleactiontable  addrecordtowfactiontable  coordactiongetcmd  dateutils  workflowinstance  getstatus  testpurgebundlewithcoordchildwithwfchild3  addrecordtocoordactiontable  parsedateoozietz  bundlejob  bundlejobbean  assertnotnull  coordinator action should have been purged  coordinatoraction  job  wfaction  wfjobgetcmd  execute  coordinatorjob  1  coordjobgetcmd  fail  workflowaction  coordaction  succeeded  je  bundlejobgetcmd  getid  coordjob  wfjob  workflow job should have been purged  addrecordtowfjobtable  geterrorcode  get  workflowjob  getappname  bundleaction  coordinator job should have been purged  workflow action should have been purged  wfactiongetcmd  2011-01-01t01:00z  addrecordtobundlejobtable  assertequals  addrecordtocoordjobtable  call  services  coord-action-get.xml  errorcode  jpaservice  bundleactiongetcmd
__label__nflaky compare  result  should  be  1   should  not  match  the  writables  result  should  be  -1   should  not  match  the  writables  writable  comparator  writable3  writable2  writable1  compare  to  should_  not_  match_  with_  result_  one  test  short  writable  comparator  assert  true  get  result  should  be  0   should  match  the  writables  should_  not_  match_  with_  result_  minus_  one  should_  match  compare  result should be 1  should not match the writables  result should be -1  should not match the writables  writablecomparator  writable3  writable2  writable1  compareto  should_not_match_with_result_one  testshortwritablecomparator  asserttrue  get  result should be 0  should match the writables  should_not_match_with_result_minus_one  should_match
__label__flaky _test  get  job  info  for  app  name  coordinator  job1  _test  get  job  info  for  frequency  _test  get  job  info  for  user  and  status  _test  get  job  info  for  status  _test  get  job  info  for  group  _test  get  job  info  for  user  get  id  add  record  to  coord  job  table  _test  get  job  info  for  frequency  and  unit  test  coord  job  get  coordinator  job  _test  get  job  info  for  id  _testgetjobinfoforappname  coordinatorjob1  _testgetjobinfoforfrequency  _testgetjobinfoforuserandstatus  _testgetjobinfoforstatus  _testgetjobinfoforgroup  _testgetjobinfoforuser  getid  addrecordtocoordjobtable  _testgetjobinfoforfrequencyandunit  testcoordjobget  coordinatorjob  _testgetjobinfoforid
__label__nflaky data  active  not  found  exception  expected  then  return  error  getting  active  data  rethrows  keeperexception  assert  equals  get  active  data  eq  elector  keeper  exception.  auth  failed  exception  expected  any  when  zk_  lock_  name  mock  zk  fail  times  assert  mockito  get  valid  active  data  test  get  active  data  active  does  not  exist  verify  get  data  then  throw  data  activenotfoundexception expected  thenreturn   error getting active data rethrows keeperexception  assertequals  getactivedata  eq  elector  keeperexception.authfailedexception expected  any  when  zk_lock_name  mockzk  fail  times  assert  mockito   get valid active data  testgetactivedata   active does not exist  verify  getdata  thenthrow
__label__flaky status  _test  get  sla  events  for  seq  id  test  sla  events  get  for  seq  id  current  add  record  to  sla  event  table  -  test  sla  events  get  jpa  executor-  w  get  time  0000000-  wf  id  status  _testgetslaeventsforseqid  testslaeventsgetforseqid  current  addrecordtoslaeventtable  -testslaeventsgetjpaexecutor-w  gettime  0000000-  wfid
__label__nflaky test  file01  get  path  data  process  path  dir  order  mtime  testfile01  get  time  add  contents  ls  format  line  mtime  out  testfile03  options  compute  line  format  in  order  testfile02  process  options  verify  testfile05  test  file06  set  mtime  testfile04  test  file04  test  file05  testfile06  test  file02  test  file03  set  file  mtime  in  different  order  to  file  names  add  found  6  items  path  data  line  format  -t  set  is  dir  process  arguments  test  dir  test  directory  verify  no  more  interactions  convention  now  test  file  mock    testfile01  getpathdata  processpathdirordermtime  testfile01  gettime  addcontents  ls  formatlinemtime  out  testfile03  options  computelineformat  inorder  testfile02  processoptions  verify  testfile05  testfile06  setmtime  testfile04  testfile04  testfile05  testfile06  testfile02  testfile03   set file mtime in different order to file names  add  found 6 items  pathdata  lineformat  -t  setisdir  processarguments  testdir  testdirectory  verifynomoreinteractions   convention  now  testfile  mock
__label__flaky set  long  dfs  config  keys  f  name  modify  defaul  filesystem  settings  conf  h  flush_03  custom  per  checksum  size  custom  block  size  set  int  do  the  job  setlong  dfsconfigkeys  fname   modify defaul filesystem settings  conf  hflush_03  customperchecksumsize  customblocksize  setint  dothejob
__label__nflaky host5  host4  host1  get  host  name  host3  somehost  host2  assert  equals  test  constructor  fail  assert  get  port  http  https  get  scheme  name  illegal  argument  exception  should  have  been  thrown  host5       host4  host1  gethostname  host3  somehost  host2  assertequals  testconstructor  fail  assert  getport  http  https  getschemename  illegalargumentexception should have been thrown
__label__flaky dfs  test  util  set  both  of  these  to  port  9000   should  fail  dfs  config  keys  set  dfs.namenode.rpc-address  (  e  format  name  node  conf  hdfs://localhost:9000  got  expected  exception:  127.0.0.1:9000  system  fail  contains  assert  set  default  uri  assert  true  should  have  throw  the  exception  since  the  ports  match  file  system  to  string  test  that  matching  rp  cand  http  ports  throw  exception  verify  we\'re  getting  the  right  io  exception  name  node  dfstestutil   set both of these to port 9000  should fail  dfsconfigkeys  set  dfs.namenode.rpc-address (  e  formatnamenode  conf  hdfs://localhost:9000  got expected exception:   127.0.0.1:9000  system  fail  contains  assert  setdefaulturi  asserttrue  should have throw the exception since the ports match  filesystem  tostring  testthatmatchingrpcandhttpportsthrowexception   verify we\'re getting the right ioexception  namenode
__label__nflaky get  parameter  values  violet  enum  array  param  multiple  should  be  parsed  blue  then  return  invoke  when  as  list  param1  rainbow  context  create  verify  enum  array  param  indigo  arrays  mock  controller  getparametervalues  violet  enumarrayparammultipleshouldbeparsed  blue  thenreturn  invoke  when  aslist  param1  rainbow  context  create  verify  enumarrayparam  indigo  arrays  mockcontroller
__label__flaky coord  action  get  cmd  get  id  assert  equals  get  status  add  record  to  coord  action  table  execute  add  record  to  coord  job  table  call  coordinator  job  services  coord  job  get  cmd  coord-action-get.xml  assert  not  null  get  test  coord  kill  failed  on  action  coordinator  action  action  job  jpa  service  coordactiongetcmd  getid  assertequals  getstatus  addrecordtocoordactiontable  execute  addrecordtocoordjobtable  call  coordinatorjob  services  coordjobgetcmd  coord-action-get.xml  assertnotnull  get  testcoordkillfailedonaction  coordinatoraction  action  job  jpaservice
__label__nflaky add  next  val  num_  elems  remove  even  elements.  value  of  assert  false  iterate  through  all  odd  list  elements.  is  empty  iter  iterate  through  all  list  elements.  has  next  assert  equals  list  remove  integer  iterator  assert  size  assert  true  check  that  list  is  now  empty.  test  removals  add  next  val  num_elems   remove even elements.  valueof  assertfalse   iterate through all odd list elements.  isempty  iter   iterate through all list elements.  hasnext  assertequals  list  remove  integer  iterator  assert  size  asserttrue   check that list is now empty.  testremovals
__label__flaky _test  is  main  successful  action  dir  has  output  data  assert  false  running  job  is  main  done  get  file  system  fs  has  id  swap  get  id  swap  path  is  successful  exit0  assert  true  launcher  mapper  get  error  path  exists  get  output  data  path  test  exit0  evaluate  wait  for  get  fs  test  case  dir  is  complete  _test  ismainsuccessful  actiondir  hasoutputdata  assertfalse  runningjob  ismaindone  getfilesystem  fs  hasidswap  getidswappath  issuccessful  exit0  asserttrue  launchermapper  geterrorpath  exists  getoutputdatapath  testexit0  evaluate  waitfor  getfstestcasedir  iscomplete
__label__nflaky encode  rs  java  coder  test  rs  coder  perform  bench  decode  raw  erasure  coder  benchmark  encode   rs java coder  testrscoder  performbench  decode  rawerasurecoderbenchmark
__label__flaky end_  points  is_  security_  enabled  lib  pig  script  file  oozie  url  conf  wc  /test  localhost:9001  pig  lib  path  input=input.txt  assert  true  test  submit  pig  get  test  case  dir  get  servlet_  classes  write  close  run  test  get  context  url  x  oozie  client  mock  dag  engine  service  hdfs://localhost:9000  assert  equals  get  file  system  params  submit  script  language  call  oozie  client  mkdirs  set  property  wf  count  create  configuration  to  string  writer  a  =  load  \'${  input}\';  dump  a;  get  fs  test  case  dir  end_points  is_security_enabled  lib  pigscriptfile  oozieurl  conf  wc  /test  localhost:9001  pig  libpath  input=input.txt  asserttrue  testsubmitpig  gettestcasedir  get  servlet_classes  write  close  runtest  getcontexturl  xoozieclient  mockdagengineservice  hdfs://localhost:9000  assertequals  getfilesystem  params  submitscriptlanguage  call  oozieclient  mkdirs  setproperty  wfcount  createconfiguration  tostring  writer  a = load \'${input}\';   dump a;  getfstestcasedir
__label__nflaky get  bytes  transferred  codec  test  utils  channel  stuff-more  stuff  times  assert  flush  verify  dump  write  more  stuff;  and  a  lot  more  stuff  argument  matchers  standard  charsets  assert  equals  encoder  -  any  never  mockito  outbuf  metrics  spy  wrap  test  coding  fragment  buffering  multiple  fragments  beyond  content  limit  stuff  getbytestransferred  codectestutils  channel  stuff-more stuff  times  assert  flush  verify  dump  write  more stuff; and a lot more stuff  argumentmatchers  standardcharsets  assertequals  encoder  -  any  never  mockito  outbuf  metrics  spy  wrap  testcodingfragmentbufferingmultiplefragmentsbeyondcontentlimit  stuff
__label__flaky action  num  coordinator  job  test  coord  action  get  coord-action-get.xml  _test  get  ready  actions  coordinator  action  get  id  job  clean  up  db  tables  add  record  to  coord  action  table  add  record  to  coord  job  table  actionnum  coordinatorjob  testcoordactionget  coord-action-get.xml  _testgetreadyactions  coordinatoraction  getid  job  cleanupdbtables  addrecordtocoordactiontable  addrecordtocoordjobtable
__label__nflaky get  name  dst  0  foot  chunks  codec  test  utils  channel  er1:  abcde  footer2:  f  convert  key=\""value\""  assert  ghij  inbuf  123456789012345612345abcdef  assert  true  get  123456789012345  test  incomplete  chunk  decoding  is  completed  345  6  read  abcdef  fghij  standard  charsets  footer1  has  remaining  abcde  footer2  clear  bytes  read  assert  equals  decoder  byte  buffer  trailers  6  5  12  get  value  allocate  size  metrics  10;  get  trailers  getname  dst    0  foot  chunks  codectestutils  channel  er1: abcde  footer2: f  convert  key=\""value\""  assert  ghij      inbuf  123456789012345612345abcdef  asserttrue  get    123456789012345  testincompletechunkdecoding  iscompleted  345  6  read    abcdef  fghij  standardcharsets  footer1  hasremaining  abcde  footer2  clear  bytesread  assertequals  decoder  bytebuffer  trailers  6  5  12  getvalue  allocate  size  metrics  10;  gettrailers
__label__flaky get  job  tracker  uri  get  name  sharelib  path  because  it  doesn\'t  have  a  scheme  or  authority  conf  create  context  set  sharelib  to  a  full  path  (i.e.  include  scheme  and  authority)  context  <job-tracker>  e  action  xml  init  ae    no  file  system  for  scheme:  foo  java-action-executor  parse  xml  </job-tracker>  destroy  <name-node>  <main-class>  /user/  </name-node>  from  the  obviously  invalid  app  path)  contains  get  oozie  user  aee  <java>  get  app  path  app  path  create  base  hadoop  conf  get  default  share  lib  name  action  xml  get  error  code  assert  true  get  invalid   and  not  the  sharelib  path  because  it  doesn\'t  have  a  scheme  or  authority  foo://bar:1234/blah  get  name  node  uri  </java>  xml  utils  set  sharelib  to  a  relative  path  (i.e.  no  scheme  nor  authority)  workflow  app  service  test  add  share  lib  scheme  and  authority  </main-class>  get  message  assert  equals  services  e0902  /share/  set  system  property  add  share  lib  getjobtrackeruri  getname   sharelib path because it doesn\'t have a scheme or authority  conf  createcontext   set sharelib to a full path (i.e. include scheme and authority)  context  <job-tracker>  eactionxml  init  ae  no filesystem for scheme: foo  java-action-executor  parsexml  </job-tracker>  destroy  <name-node>  <main-class>  /user/  </name-node>   from the obviously invalid apppath)  contains  getoozieuser  aee  <java>  getapppath  apppath  createbasehadoopconf  getdefaultsharelibname  actionxml  geterrorcode  asserttrue  get   invalid  and not the sharelib path because it doesn\'t have a scheme or authority  foo://bar:1234/blah  getnamenodeuri  </java>  xmlutils   set sharelib to a relative path (i.e. no scheme nor authority)  workflowappservice  testaddsharelibschemeandauthority  </main-class>  getmessage  assertequals  services  e0902  /share/  setsystemproperty  addsharelib
__label__nflaky expected  successful  touch  with  a  specified  access  time  new  file2  verify  if  both  modification  and  access  times  are  recorded  correctly  get  time  test  touch  get  modification  time  new  file  new_status  remains  unchanged).  expected  successful  touch  with  a  specified  timestamp  delete  system  fstatus  -touch  not  expected  successful  touch  with  a  specified  modificatiom  time  str  time  -a  -c  shell  run  get  file  status  parse  timestamp  expected  successful  touch  on  a  non-existent  file  with  -c  option  -m  format  timestamp  ensure  new  file2  does  not  exist  -t  new  file  name  get  access  time  is  assert  that  date  obj  expected  failed  touch  with  a  missing  timestamp  current  time  millis  lfs  exists  expected  successful  touch  on  a  new  file  with  a  specified  timestamp  expected successful touch with a specified access time  newfile2   verify if both modification and access times are recorded correctly  gettime  testtouch  getmodificationtime  newfile  new_status   remains unchanged).  expected successful touch with a specified timestamp  delete  system  fstatus  -touch  not  expected successful touch with a specified modificatiom time  strtime  -a  -c  shellrun  getfilestatus  parsetimestamp  expected successful touch on a non-existent file with -c option  -m  formattimestamp   ensure newfile2 does not exist  -t  newfilename  getaccesstime  is  assertthat  dateobj  expected failed touch with a missing timestamp  currenttimemillis  lfs  exists  expected successful touch on a new file with a specified timestamp
__label__flaky event  status  not  correct  for  map  attempt1  get  class  event  status  not  correct  for  map  attempt2  reduce  task  copy  of  range  get  name  event  status  not  correct  for  reduce  attempt1  map  task  attempt  state  not  correct  conf  get  map  attempt  completion  events  get  status  send  the  done  signal  to  the  second  map  attempt  map  events  get  attempts  assert  array  equals  iterator  assert  at  it  event  reduce  attempt  id  not  correct  send  fetch  failure  wait  for  map  task  state  move  back  to  running  job  state  send  3  fetch  failures  from  reduce  to  trigger  map  re  execution  reduce  attempt  converted  events  events  send  done  to  reduce  app  reduce  task2  map  attempt  must  have  become  failed  get  event  handler  num  completion  events  not  correct  event  map  attempt  id  not  correct  get  id  handle  it  reduce  task3  size  task  attempt  state  send  the  done  signal  to  the  map  attempt  unexpected  map  event  mr  job  config  previous  completion  event  now  becomes  obsolete  unexpected  map  events  job  arrays  next  get  task  attempt  completion  events  phase  submit  values  wait  for  reduce  to  start  running  task  attempt  completion  event  status  wait  for  map  success  we  should  not  re-launch  the  map  task  yet  wait  for  state  num  tasks  not  correct  task  attempt  event  type  all  maps  would  be  running  get  attempt  id  map  attempt1  map  attempt2  from  yarn  map  task  test  fetch  failure  multiple  reduces  sequential   single-task-attempt  approach  in  uber-  am   so  disable:  assert  equals  event  status  not  correct  num  attempts  in  map  task  not  correct  type  converter  reduce  attempt2  get  state  get  tasks  update  status  reduce  attempt3  task  state  get  context  set  boolean  wait  for  task  state  move  to  running  incorrect  number  of  map  events  event status not correct for map attempt1  getclass  event status not correct for map attempt2  reducetask  copyofrange  getname  event status not correct for reduce attempt1  map taskattempt state not correct  conf  getmapattemptcompletionevents  getstatus   send the done signal to the second map attempt  mapevents  getattempts  assertarrayequals  iterator  assert  atit  event reduce attempt id not correct  sendfetchfailure   wait for map task state move back to running  jobstate   send 3 fetch failures from reduce to trigger map re execution  reduceattempt  convertedevents  events   send done to reduce  app  reducetask2   map attempt must have become failed  geteventhandler  num completion events not correct  event map attempt id not correct  getid  handle  it  reducetask3  size  taskattemptstate   send the done signal to the map attempt  unexpected map event  mrjobconfig   previous completion event now becomes obsolete  unexpected map events  job  arrays  next  gettaskattemptcompletionevents  phase  submit  values   wait for reduce to start running  taskattemptcompletioneventstatus   wait for map success   we should not re-launch the map task yet  waitforstate  num tasks not correct  taskattempteventtype   all maps would be running  getattemptid  mapattempt1  mapattempt2  fromyarn  maptask  testfetchfailuremultiplereduces   sequential  single-task-attempt approach in uber-am  so disable:  assertequals  event status not correct  num attempts in map task not correct  typeconverter  reduceattempt2  getstate  gettasks  updatestatus  reduceattempt3  taskstate  getcontext  setboolean   wait for task state move to running  incorrect number of map events
__label__nflaky url  encoded  utils  /this//that/\%2  fthis\%20and\%20that  this  core  matchers  equal  to  test  format  segments  assert  that  /this//that  /  that  assert  /this/that  /this///that//  /this  and  that  format  segments    urlencodedutils  /this//that/\%2fthis\%20and\%20that  this  corematchers  equalto  testformatsegments  assertthat  /this//that  /  that  assert  /this/that  /this///that//  /this and that  formatsegments
__label__flaky get  status  sub  workflow  action  executor  proto  conf  create  base  workflow  get  workflow  client  new  conf  xyz  create  action  </app-path>  workflow.xml  write  get  base  proto  conf  wait  for  workflow  get  file  system  check  child  conf  </configuration>  workflow  action  <propagate-configuration  />  file  evaluate  <sub-workflow  xmlns=\'uri:oozie:workflow:0.1\'  name=\'subwf\'>  <app-path>  <configuration>  get  job  info  <name>a</name>  </property>  get  actions  get  external  id  fs  app1  <value>  a</value>  wf  w  get  end  workflow  job  close  abc  set  get  conf  oozie  client  <property>  start  default  conf  sub  workflow  app  path  sub  workflow  assert  equals  job_  timeout  set  conf  to  xml  string  </sub-workflow>  writer  get  fs  test  case  dir  test  config  propagation  getstatus  subworkflowactionexecutor  protoconf  createbaseworkflow  getworkflowclient  newconf  xyz  create  action  </app-path>  workflow.xml  write  getbaseprotoconf  waitfor  workflow  getfilesystem  check  childconf        </configuration>  workflowaction        <propagate-configuration />  file  evaluate  <sub-workflow xmlns=\'uri:oozie:workflow:0.1\' name=\'subwf\'>        <app-path>        <configuration>  getjobinfo            <name>a</name>          </property>  getactions  getexternalid  fs  app1            <value>a</value>  wf  w  get  end  workflowjob  close  abc  set  getconf  oozieclient          <property>  start  defaultconf  subworkflowapppath  subworkflow  assertequals  job_timeout  setconf  toxmlstring  </sub-workflow>  writer  getfstestcasedir  testconfigpropagation
__label__nflaky test  no  error  clone  pdf417_  test_  with_  ec  received  check  decode  no  errors  testnoerror  clone  pdf417_test_with_ec  received  checkdecode   no errors
__label__flaky bundle  job  get  cmd  add  record  to  bundle  job  table  get  id  assert  equals  get  status  execute  call  services  test  bundle  suspend  with  error2  assert  not  null  get  job  job  jpa  service  bundlejobgetcmd  addrecordtobundlejobtable  getid  assertequals  getstatus  execute  call  services  testbundlesuspendwitherror2  assertnotnull  get  job  job  jpaservice
__label__nflaky ff  get  bytes  transferred  dst  stuf  stu  codec  test  utils  assert  false  channel  convert  stuff;  assert  inbuf  f;  assert  true  test  basic  decoding  small  buffer  more  stuff  is  completed  read  standard  charsets  more  clear  bytes  read  assert  equals  decoder  byte  buffer  allocate  metrics  ff  getbytestransferred  dst  stuf   stu  codectestutils  assertfalse  channel  convert  stuff;  assert  inbuf  f;  asserttrue  testbasicdecodingsmallbuffer  more stuff  iscompleted  read  standardcharsets  more  clear  bytesread  assertequals  decoder  bytebuffer  allocate  metrics
__label__flaky cluster  quota  dir3  quota  dir2  quota  dir1  conf  15:  delete  /nqdir0/qdir1/qdir20/qdir21  /nqdir0  11:  move  /nqdir0/qdir1/qdir20/nqdir30  to  /nqdir0  get  directory  count  get  file  system  set  quota  6:  create  directory  /nqdir0/qdir1/qdir21/nqdir33  dfs  3:  set  the  quota  of  /nqdir0/qdir1/qdir20  to  be  7  nqdir30  14:  move  /nqdir0/qdir1/qdir21  /nqdir0/qdir1/qdir20  num  data  nodes  /nqdir0/qdir1/qdir20/nqdir30  mkdirs  temp  path  /nqdir0/qdir1/qdir20  /nqdir0/qdir1/qdir21  nqdir33  nqdir32  16:  move  /nqdir0/qdir30  /nqdir0/qdir1/qdir20  nqdir31  8:  create  directory  /nqdir0/qdir1/qdir20/nqdir33  qdir21  get  uri  shutdown  /nqdir0/qdir1  10.a:  rename  /nqdir0/qdir1/qdir20/nqdir30  to  /nqdir0/qdir1/qdir21/nqdir32  1:  create  directory  /nqdir0/qdir1/qdir20/nqdir30  test  namespace  commands  hdfs  constants  has  exception  assert  false  fs  delete  get  quota  7:  create  directory  /nqdir0/qdir1/qdir20/nqdir31  4:  create  directory  /nqdir0/qdir1/qdir21  and  set  its  quota  to  2  assert  true  2:  set  the  quota  of  /nqdir0/qdir1  to  be  6  /nqdir0/nqdir30  c  9:  move  /nqdir0/qdir1/qdir21/nqdir32  /nqdir0/qdir1/qdir20/nqdir30  get  content  summary  assert  equals  not  a  hdfs:  13:  move  /nqdir0/nqdir30  /nqdir0/qdir1/qdir20/qdir30  /nqdir0/nqdir30/nqdir33  12:  create  directory  /nqdir0/nqdir30/nqdir33  build  rename  exists  5:  create  directory  /nqdir0/qdir1/qdir21/nqdir32  10:  move  /nqdir0/qdir1/qdir20/nqdir30  to  /nqdir0/qdir1/qdir21  cluster  quotadir3  quotadir2  quotadir1  conf   15: delete /nqdir0/qdir1/qdir20/qdir21  /nqdir0   11: move /nqdir0/qdir1/qdir20/nqdir30 to /nqdir0  getdirectorycount  getfilesystem  setquota   6: create directory /nqdir0/qdir1/qdir21/nqdir33  dfs   3: set the quota of /nqdir0/qdir1/qdir20 to be 7  nqdir30   14: move /nqdir0/qdir1/qdir21 /nqdir0/qdir1/qdir20  numdatanodes  /nqdir0/qdir1/qdir20/nqdir30  mkdirs  temppath  /nqdir0/qdir1/qdir20  /nqdir0/qdir1/qdir21  nqdir33  nqdir32   16: move /nqdir0/qdir30 /nqdir0/qdir1/qdir20  nqdir31   8: create directory /nqdir0/qdir1/qdir20/nqdir33  qdir21  geturi  shutdown  /nqdir0/qdir1   10.a: rename /nqdir0/qdir1/qdir20/nqdir30 to /nqdir0/qdir1/qdir21/nqdir32   1: create directory /nqdir0/qdir1/qdir20/nqdir30  testnamespacecommands  hdfsconstants  hasexception  assertfalse  fs  delete  getquota   7: create directory /nqdir0/qdir1/qdir20/nqdir31   4: create directory /nqdir0/qdir1/qdir21 and set its quota to 2  asserttrue   2: set the quota of /nqdir0/qdir1 to be 6  /nqdir0/nqdir30  c   9: move /nqdir0/qdir1/qdir21/nqdir32 /nqdir0/qdir1/qdir20/nqdir30  getcontentsummary  assertequals  not a hdfs:    13: move /nqdir0/nqdir30 /nqdir0/qdir1/qdir20/qdir30  /nqdir0/nqdir30/nqdir33   12: create directory /nqdir0/nqdir30/nqdir33  build  rename  exists   5: create directory /nqdir0/qdir1/qdir21/nqdir32   10: move /nqdir0/qdir1/qdir20/nqdir30 to /nqdir0/qdir1/qdir21
__label__nflaky optional  integer  param  empty  optional  then  return  invoke  when  param1  empty  context  create  verify  optional  integer  param  mock  controller  get  parameter  optionalintegerparamempty  optional  thenreturn  invoke  when  param1  empty  context  create  verify  optionalintegerparam  mockcontroller  getparameter
__label__flaky conn  set  request  method  is_  security_  enabled  /v0/admin/*  assert  true  json  content-type  collections  run  test  rest  constants  test  configuration  open  connection  contains  key  http  servlet  response  assert  equals  parse  get  input  stream  url  json  value  call  services  get  header  field  get  get  response  code  create  url  starts  with  conn  setrequestmethod  is_security_enabled  /v0/admin/*  asserttrue  json  content-type  collections  runtest  restconstants  testconfiguration  openconnection  containskey  httpservletresponse  assertequals  parse  getinputstream  url  jsonvalue  call  services  getheaderfield  get  getresponsecode  createurl  startswith
__label__nflaky default_  compression_  suffix  no  compression_  file  set_  no  restart_1  first_  phase_  only  toto.log  test1  generic  default_compression_suffix  nocompression_fileset_norestart_1  first_phase_only  toto.log  test1  generic
__label__flaky get  name  oozie.service.  proxy  user  service.proxyuser.foo.groups  test  invalid  proxy  user  foo  conf  as  list  bar  assert  string  utils  assert  not  null  get  join  validate  localhost  init  set  oozie.service.  proxy  user  service.proxyuser.foo.hosts  get  conf  destroy  *  services     services  fail  ex  proxy  user  to  string  arrays  getname  oozie.service.proxyuserservice.proxyuser.foo.groups  testinvalidproxyuser  foo  conf  aslist  bar  assert  stringutils  assertnotnull  get  join  validate  localhost  init  set  oozie.service.proxyuserservice.proxyuser.foo.hosts  getconf  destroy  *  services     services  fail  ex  proxyuser  tostring  arrays
__label__nflaky key1  p1  p2  do  nothing  should  not  throw  exception  since  p2  doesn\'t  throw  exception  get  kms  url  kp  any  string  then  return  key  name  conf  test  warm  up  encrypted  keys  when  one  provider  succeeds  when  warm  up  encrypted  keys  fail  do  throw  times  mockito  mock  verify  key1  p1  p2  donothing  should not throw exception since p2 doesn\'t throw exception  getkmsurl  kp  anystring  thenreturn  keyname  conf  testwarmupencryptedkeyswhenoneprovidersucceeds  when  warmupencryptedkeys  fail  dothrow  times  mockito  mock  verify
__label__flaky conn  rest  constants  bundle=  bundle-  abc  open  connection  /v1/jobs  http  servlet  response  assert  equals  params  put  url  call  1  5  get  response  code  create  url  test  no  records  bulk  request  records  found  for  this  bundle  run  test    conn  restconstants  bundle=bundle-abc  openconnection  /v1/jobs  httpservletresponse  assertequals  params  put  url  call  1  5  getresponsecode  createurl  testnorecords  bulkrequest   records found for this bundle  runtest
__label__nflaky make  a  configuration  file  with  a  final  property  a  adding  same  resource  twice  should  not  cause  logging  event  =  logging  event  get  log  logger  declare  property  conf  add  the  resource  twice  from  a  stream  -  should  not  generate  warnings  logger  get  rendered  message  get  bytes  system  out  remove  appender  make  sure  the  appender  is  removed  add  appender  assert  true  add  resource  prop  the  2  input  streams  both  have  the  same  config  file  get  get  root  logger  test  no  final  warnings  events  is  empty  end  config  attach  our  own  log  appender  so  we  can  verify  output  start  config  appender  assert  equals  in2  in1  bytes  to  string  writer   make a configuration file with a final property  a  adding same resource twice should not cause logging  event =   loggingevent  getlog  logger  declareproperty  conf   add the resource twice from a stream - should not generate warnings  logger  getrenderedmessage  getbytes  system  out  removeappender   make sure the appender is removed  addappender  asserttrue  addresource  prop   the 2 input streams both have the same config file  get  getrootlogger  testnofinalwarnings  events  isempty  endconfig   attach our own log appender so we can verify output  startconfig  appender  assertequals  in2  in1  bytes  tostring  writer
__label__flaky should  have  thrown  jpa  executor  exception  print  stack  trace  e  get  id  error  code  should  be  e1022  add  record  to  coord  action  table  execute  add  record  to  coord  job  table  system  coordinator  job  services  fail  coord-action-get.xml  get  error  code  assert  not  null  get  coordinator  action  action  coord  rmv  cmd  test  running  action  delete  error  code  job  jpa  service  should have thrown jpaexecutorexception  printstacktrace  e  getid  error code should be e1022  addrecordtocoordactiontable  execute  addrecordtocoordjobtable  system  coordinatorjob  services  fail  coord-action-get.xml  geterrorcode  assertnotnull  get  coordinatoraction  action  coordrmvcmd  testrunningactiondelete  errorcode  job  jpaservice
__label__nflaky content  type  listener  core  matchers  ssl_  rsa_  export_  with_  rc2_  cbc_40_  md5  cipher  suite  set  exception  callback  get  cause  async  server  bootstrap  listen  instance  of  io  reactor  config  weak  ciphers  suites  assert  ssl_  dh_anon_  export_  with_  rc4_40_  md5  get  duration  create  https  /stuff  set  lookup  registry  tls_  dh_anon_  with_  aes_128_  cbc_  sha  requester  localhost  set  stream  listener  logging  exception  callback  logging  http1  stream  listener  set  io  session  listener  set  enabled  cipher  suites  result  future1  set  so  timeout  *  method  assert  that  execute  test  weak  ciphers  disabled  by  default  logging  conn  pool  listener  tls_  ecdhe_  ecdsa_  with_  rc4_128_  sha  fail  ex  secure  all  ports  strategy  close  mode  timeout  tls_  rsa_  with_  null_  sha256  server  ssl_  rsa_  with_3  des_  ede_  cbc_  sha  tls_  krb5_  export_  with_  rc4_40_  sha  create  client  ssl  context  set  io  reactor  config  cause  ssl_  rsa_  export_  with_  des40_  cbc_  sha  h2  requester  bootstrap  bootstrap  set  conn  pool  listener  set  tls  strategy  tls_  ecdh_anon_  with_  aes_256_  cbc_  sha  some  stuff  set  io  session  decorator  ssl_  rsa_  export_  with_  rc4_40_  md5  create  server  ssl  context  get  execution  exception  expected  get  address  ssl_  rsa_  with_  rc4_128_  sha  tls_  ecdh_  ecdsa_  with_3  des_  ede_  cbc_  sha  close  ssl  test  contexts  address  ssl_  rsa_  with_  null_  sha  custom  start  ssl  engine  target  get  time  unit  logging  io  session  decorator  get  port  build  future  logging  io  session  listener  initialize  tls_  dh_anon_  with_  aes_256_  gcm_  sha384  register  contenttype  listener  corematchers  ssl_rsa_export_with_rc2_cbc_40_md5  ciphersuite  setexceptioncallback  getcause  asyncserverbootstrap  listen  instanceof  ioreactorconfig  weakcipherssuites  assert  ssl_dh_anon_export_with_rc4_40_md5  getduration  create  https  /stuff  setlookupregistry  tls_dh_anon_with_aes_128_cbc_sha  requester  localhost  setstreamlistener  loggingexceptioncallback  logginghttp1streamlistener  setiosessionlistener  setenabledciphersuites  resultfuture1  setsotimeout  *  method  assertthat  execute  testweakciphersdisabledbydefault  loggingconnpoollistener  tls_ecdhe_ecdsa_with_rc4_128_sha  fail  ex  secureallportsstrategy  closemode  timeout  tls_rsa_with_null_sha256  server  ssl_rsa_with_3des_ede_cbc_sha  tls_krb5_export_with_rc4_40_sha  createclientsslcontext  setioreactorconfig  cause  ssl_rsa_export_with_des40_cbc_sha  h2requesterbootstrap  bootstrap  setconnpoollistener  settlsstrategy  tls_ecdh_anon_with_aes_256_cbc_sha  some stuff  setiosessiondecorator  ssl_rsa_export_with_rc4_40_md5  createserversslcontext  get  executionexception expected  getaddress  ssl_rsa_with_rc4_128_sha  tls_ecdh_ecdsa_with_3des_ede_cbc_sha  close  ssltestcontexts  address  ssl_rsa_with_null_sha  custom  start  sslengine  target  gettimeunit  loggingiosessiondecorator  getport  build  future  loggingiosessionlistener  initialize  tls_dh_anon_with_aes_256_gcm_sha384  register
__label__flaky create  client  add  set  get  unique  activation  id  1000  create  stage  assert  equals  shouldn\'t  collect  anything   since  clock  is  moving  slowly  clock  actor1  bind  cleanup  test  stage  size  cleanup  i  actor  client  time  unit  to  millis  join  get  reference  increment  time  millis  createclient  add  set  getuniqueactivationid  1000  createstage  assertequals   shouldn\'t collect anything  since clock is moving slowly  clock  actor1  bind  cleanuptest  stage  size  cleanup  iactor  client  timeunit  tomillis  join  getreference  incrementtimemillis
__label__nflaky server  get  current  user  rpc  configure  super  user  ip  addresses  group_  names  get  user  new  empty  request  conf  run  ret  val  assert  real_  user_  short_  name  client  set  protocol  engine  addr  set  configuration  user  group  information  proxy  user  ugi  print  stack  trace  e  get  client  create  remote  user  test  real  user  group  not  specified  real_  user_  name  fail  do  as  stop  setup  test  server  proxy_  user_  name  the  rpc  must  have  failed  real  user  ugi  create  proxy  user  for  testing  server  getcurrentuser  rpc  configuresuperuseripaddresses  group_names  getuser  newemptyrequest  conf  run  retval  assert  real_user_short_name  client  setprotocolengine  addr  setconfiguration  usergroupinformation  proxyuserugi  printstacktrace  e  getclient  createremoteuser  testrealusergroupnotspecified  real_user_name  fail  doas  stop  setuptestserver  proxy_user_name  the rpc must have failed   realuserugi  createproxyuserfortesting
__label__flaky action  num  2009-12-15  t01:00  z  get  id  coord  utils  assert  equals  get  coord  actions  from  dates  add  record  to  coord  action  table  add  record  to  coord  job  table  coordinator  job  job  id  coord  actions  size  get  test  retrieval  of  action  corresponding  to  single  date  (date1)  coordinator  action  action1  test  get  coord  actions  from  date  job  coord-rerun-action1.xml  actionnum  2009-12-15t01:00z  getid  coordutils  assertequals  getcoordactionsfromdates  addrecordtocoordactiontable  addrecordtocoordjobtable  coordinatorjob  jobid  coordactions  size  get   test retrieval of action corresponding to single date (date1)  coordinatoraction  action1  testgetcoordactionsfromdate  job  coord-rerun-action1.xml
__label__nflaky cancel  add  delegation  tokens  boom  conf  time  when  fs  get  renew  queue  length  sleep  do  answer  get  renew  token  now  token1  token2  verify  at  most  myservice  get  conf  do  return  renewer  remove  renew  action  assert  equals  eq  add  renew  action  get  service  thread  test  get  new  token  on  renew  failure  do  throw  set  delegation  token  answer  service  mock  at  least  renew  get  delegation  token  renew_  cycle  cancel  adddelegationtokens  boom  conf  time  when  fs  getrenewqueuelength  sleep  doanswer  getrenewtoken  now  token1  token2  verify  atmost  myservice  getconf  doreturn  renewer  removerenewaction  assertequals  eq  addrenewaction  getservice  thread  testgetnewtokenonrenewfailure  dothrow  setdelegationtoken  answer  service  mock  atleast  renew  getdelegationtoken  renew_cycle
__label__flaky get  id  run  workflow  instance  get  status  add  record  to  coord  action  table  test  coord  action  recovery  service  for  resume  coord  job  sleep  wf  job  add  record  to  wf  job  table  assert  not  null  get  coordinator  action  workflow  job  recovery  runnable  wait  for  ret  wf  get  cmd  assert  equals  execute  add  record  to  coord  job  table  coordinator  job  services  wf  job  id  coord-action-get.xml  suspended  jpa  service  evaluate  getid  run  workflowinstance  getstatus  addrecordtocoordactiontable  testcoordactionrecoveryserviceforresume  coordjob  sleep  wfjob  addrecordtowfjobtable  assertnotnull  get  coordinatoraction  workflowjob  recoveryrunnable  waitfor  ret  wfgetcmd  assertequals  execute  addrecordtocoordjobtable  coordinatorjob  services  wfjobid  coord-action-get.xml  suspended  jpaservice  evaluate
__label__nflaky next  assert  false  value2=whatever  hit  without  filter  assert  with  filter   first  &  last  assert  true  way-off  with  filter   no  match  headers  match  test  first  last  one  none  has  next  assert  equals  with  filter   one  match  value3;tag=nil  single  0  1  2  3  mismatch  value1   value1.1  value0  next  assertfalse  value2=whatever  hit   without filter  assert   with filter  first & last  asserttrue  way-off   with filter  no match  headers  match  testfirstlastonenone  hasnext  assertequals   with filter  one match  value3;tag=nil  single  0  1  2  3  mismatch  value1  value1.1  value0
__label__flaky set  name  test  wait  for  a  get  name  start  assert  equals  waited  testcase  tear  down  system  testing  current  time  millis  set  up  end  test  wait  for  time  out  evaluate  wait  for  setname  testwaitfor  a  getname  start  assertequals  waited  testcase  teardown  system  testing  currenttimemillis  setup  end  testwaitfortimeout  evaluate  waitfor
__label__nflaky last  exception  unwrap  exeption  unwrap  remote  exception  get  internal  state  conf  executors  get  cause  setup  decay  rpc  schedulerand  test  server  add  internal  wait  for  the  1st  response  time  update  num  clients  add  res  set  log  level  log  decay  rpc  scheduler  unchecked  generic  test  utils  eq  .  set  int  new  sleep  request  proxy  call  queue  re  stop  level  spy  shutdown  succeeded  server  .0  rpc  submit  executor  service  ns  error  avg  response  time(3s)  exceeds  threshold  (2s).  timeout  last  received  non-  retriable  exception:  sleep  times  retriable  exception  not  received  assert  true  verify  addr  new  fixed  thread  pool  common  configuration  keys  e  test  client  back  off  by  response  time  get  client  any  whitebox  thread  call  start  a  sleep  rpc  call  that  sleeps  3s.  set  internal  state  lastexception  unwrapexeption  unwrapremoteexception  getinternalstate  conf  executors  getcause  setupdecayrpcschedulerandtestserver  addinternal   wait for the 1st response time update  numclients  add  res  setloglevel  log  decayrpcscheduler  unchecked  generictestutils  eq  .  setint  newsleeprequest  proxy  callqueue  re  stop  level  spy  shutdown  succeeded  server  .0  rpc  submit  executorservice  ns  error   avg response time(3s) exceeds threshold (2s).  timeout  last received non-retriableexception:  sleep  times  retriableexception not received  asserttrue  verify  addr  newfixedthreadpool  commonconfigurationkeys  e  testclientbackoffbyresponsetime  getclient  any  whitebox  thread  call   start a sleep rpc call that sleeps 3s.  setinternalstate
__label__flaky get  name  node  uri  list  status  test  fs  dir  get  file  system  test  dir  fs  contains  get  test  user  fs  test  dir  assert  true  assert  not  null  get  test  case  dir  exists  to  string  user  get  uri  get  fs  test  case  dir  name  node  starts  with  getnamenodeuri  liststatus  testfsdir  getfilesystem  testdir  fs  contains  gettestuser  fstestdir  asserttrue  assertnotnull  gettestcasedir  exists  tostring  user  geturi  getfstestcasedir  namenode  startswith
__label__nflaky http://host  request  get  scheme  test  request  with  no  path  assert  equals  method  get  method  get  authority  /  assert  name  get  path  host  http  http://host/  get  uri  http://host  request  getscheme  testrequestwithnopath  assertequals  method  getmethod  getauthority  /  assert  name  getpath  host  http  http://host/  geturi
__label__flaky test  for  the  expected  action  number  get  id  add  coordinator  action  with  nominal  time:  2009-12-15  t01:00  z  add  record  to  coord  action  table  add  record  to  coord  job  table  coordinator  job  coord-action-get.xml  coord-action-for-action-input-check.xml  coordinator  action  _test  get  actions  subset  order  by  action  action1  job  check  the  ordering  of  actions  by  nominal  time  test  coord  action  order  by  add  coordinator  action  with  nominal  time:  2009-02-01  t23:59  z   test for the expected action number  getid   add coordinator action with nominal time: 2009-12-15t01:00z  addrecordtocoordactiontable  addrecordtocoordjobtable  coordinatorjob  coord-action-get.xml  coord-action-for-action-input-check.xml  coordinatoraction  _testgetactionssubsetorderby  action  action1  job   check the ordering of actions by nominal time  testcoordactionorderby   add coordinator action with nominal time: 2009-02-01t23:59z
__label__nflaky dfs.random.key  append  property  by  tag  dfs.replication  get  all  properties  by  tag  dfs.namenode.logging.level  conf  info  get  all  properties  by  tags  hadoop.tags.system  add  is  property  tag  contains  key  end  config  get  property  sources  1  contains  size  cmycustomtag2  file  resource  arrays  yarn   hdfs   namenode  sources  mycustomtag  get  props  read  all  lines  append  property  system  out  assert  eq  test  get  all  properties  by  tags  assert  true  add  resource  get  paths  hadoop.tags.custom  files  close  config_  core  core-site.xml  false  hdfs  start  config  namenode  namenode.host  yarn  debug  tag  list  dfs.cblock.trace.io  xyz  to  string  properties  dfs.random.key  appendpropertybytag  dfs.replication  getallpropertiesbytag  dfs.namenode.logging.level  conf  info  getallpropertiesbytags  hadoop.tags.system  add  ispropertytag  containskey  endconfig  getpropertysources  1  contains  size  cmycustomtag2  fileresource  arrays  yarn hdfs namenode  sources  mycustomtag  getprops  readalllines  appendproperty  system  out  asserteq  testgetallpropertiesbytags  asserttrue  addresource  get  paths  hadoop.tags.custom  files  close  config_core  core-site.xml  false  hdfs  startconfig  namenode  namenode.host  yarn  debug  taglist  dfs.cblock.trace.io  xyz  tostring  properties
__label__flaky cluster  /  force  test  dir  tests  for  copy  from  local  tests  for  put  conf  test  file  for  put  run  testdir  fs  delete  argv  tool  runner  -put  test_  root_  dir  -f  error  -cp  cp  -f  is  not  working  close  write  file  test  copy  commands  with  force  option  hdfs  test  dir  res  success  local  file  cp  command  itself  is  able  to  overwrite  the  file  get  absolute  path  copy  from  local  command  itself  is  able  to  overwrite  the  file  format  localfilepath  assert  equals  get  file  system  put  -f  is  not  working  tests  for  cp  build  shell  num  data  nodes  mkdirs  exists  -copy  from  local  copy  from  local  -f  is  not  working  force  copy  option  is  -f  create  new  file  shutdown  put  command  itself  is  able  to  overwrite  the  file  cluster  /forcetestdir   tests for copyfromlocal   tests for put  conf  testfileforput  run  testdir  fs  delete  argv  toolrunner  -put  test_root_dir  -f  error  -cp  cp -f is not working  close  writefile  testcopycommandswithforceoption  hdfstestdir  res  success  localfile  cp command itself is able to overwrite the file  getabsolutepath  copyfromlocal command itself is able to overwrite the file  format  localfilepath  assertequals  getfilesystem  put -f is not working   tests for cp  build  shell  numdatanodes  mkdirs  exists  -copyfromlocal  copyfromlocal -f is not working   force copy option is -f  createnewfile  shutdown  put command itself is able to overwrite the file
__label__nflaky test  find  byte  data  hello   world!  utf8  byte  array  utils  assert  equals  did  not  find  first  occurrence  of  character  \'o\'  character  \'a\'  does  not  exist  in  string  find  byte  get  bytes  testfindbyte  data  hello  world!  utf8bytearrayutils  assertequals  did not find first occurrence of character \'o\'  character \'a\' does not exist in string  findbyte  getbytes
__label__flaky cluster  file_  size  get  block  locations  get  located  blocks  dn  sockets  insert  a  socket  to  the  nn  conf  dn  dn  addr  get  self  addr  nn  sock  put  assert  true  cache_  size  get  get  namenode  client  block  get  address  close  evicted  socket  closed  localhost  make  a  client  cache  test  socket  cache  lookup  the  dn  socks  assert  equals  assert  same  cache  is  empty  test  file  insert  dn  socks  nn  addr  get  port  create  socket  util  dn  sock  is  closed  size  find  out  the  dn  addr  get  data  node  get  name  node  port  read  the  write  to  string  make  some  sockets  to  the  dn  nn  socket  evicted  retrieve  cached  sockets  cluster  file_size  getblocklocations  getlocatedblocks  dnsockets   insert a socket to the nn  conf  dn  dnaddr  getselfaddr  nnsock  put  asserttrue  cache_size  get  getnamenode  client  block  getaddress  close  evicted socket closed  localhost   make a client  cache  testsocketcache   lookup the dn socks  assertequals  assertsame  cache is empty  testfile   insert dn socks  nnaddr  getport  createsocket  util  dnsock  isclosed  size   find out the dn addr  getdatanode  getnamenodeport  read the write  tostring   make some sockets to the dn  nn socket evicted  retrieve cached sockets
__label__nflaky address  get  local  port  set  socket2  server  max  address2  conf  -  test  range  0.0.0.0  test  bind  bind  min  is  bound  assert  true  socket  close  address  getlocalport  set  socket2  server  max  address2  conf  -  testrange  0.0.0.0  testbind  bind  min  isbound  asserttrue  socket  close
__label__flaky action  num  get  id  get  status  add  record  to  coord  action  table  add  record  to  coord  job  table  _test  coord  action  for  correct  column  values  coordinator  job  job  id  test  coord  actions  running  for  column  values  *  add  a  coordinator  action  with  status  running  and  check  for  expected  column  values  coord-action-get.xml  coordinator  action  action  job  get  pending  actionnum  getid  getstatus  addrecordtocoordactiontable  addrecordtocoordjobtable  _testcoordactionforcorrectcolumnvalues  coordinatorjob  jobid  testcoordactionsrunningforcolumnvalues         * add a coordinator action with status running and check for expected column values         coord-action-get.xml  coordinatoraction  action  job  getpending
__label__nflaky test  with  retriable  and  retry  disabled  get  default  retry  policy  default  retry  policy  enabled  =  false  conf  is  assert  that  test.  no.  such.  key  10000 6  should  retry  action  retry  utils  retry  policy  policy  dummy  exception  testwithretriableandretrydisabled  getdefaultretrypolicy   defaultretrypolicyenabled = false  conf  is  assertthat  test.no.such.key  10000 6  shouldretry  action  retryutils  retrypolicy  policy  dummy exception
__label__flaky conn  set  request  method  is_  security_  enabled  get  id  put  bundle  job  bean  assert  true  get  /v1/job/*  content-type  test  bundle  engine  get  bundle  job  id  job  run  test  mock  coordinator  engine  service  rest  constants  open  connection  add  record  to  bundle  job  table  http  servlet  response  assert  equals  parse  params  get  input  stream  bundle  job  id  url  json  value  call  get  header  field  x  data  test  case  obj  get  get  response  code  reset  create  url  starts  with  conn  setrequestmethod  is_security_enabled  getid  put  bundlejobbean  asserttrue  get  /v1/job/*  content-type  testbundleenginegetbundlejob  id  job  runtest  mockcoordinatorengineservice  restconstants  openconnection  addrecordtobundlejobtable  httpservletresponse  assertequals  parse  params  getinputstream  bundlejobid  url  jsonvalue  call  getheaderfield  xdatatestcase  obj  get  getresponsecode  reset  createurl  startswith
__label__nflaky p  fail  parse  empty    p  fail  parse  empty
__label__flaky play  server  request  c  get  sequence  number  connection  reused.  redirected  by  location:  /b  assert  code  location:  /c  assert  body  /a  /c  test  redirect  from  /b  to  /c  assert  contains  headers  /a  has  moved!  await  client  test:  redirect  from  /b  to  /c  connection  reused  again!  redirect  add  header  receiver  take  request  assert  equals  set  response  code  set  body  /b  has  moved!  url  new  connection.  enqueue  get  url  test:  redirect  from  /a  to  /b  build  redirect  from  /a  to  /b  play  server  request  c  getsequencenumber   connection reused.  redirectedby  location: /b  assertcode  location: /c  assertbody  /a  /c  test  redirect from /b to /c  assertcontainsheaders  /a has moved!  await  client  test: redirect from /b to /c   connection reused again!  redirect  addheader  receiver  takerequest  assertequals  setresponsecode  setbody  /b has moved!  url   new connection.  enqueue  geturl  test: redirect from /a to /b  build  redirect from /a to /b
__label__nflaky principal  name  wo  realm  get  host  name  http/abc.com@  example.  com  get  service  name  http  assert  equals  get  realm  principal  name  full  test  parsing  http@  example.  com  kerb  namewo  realm  kerb  name  full  kerb  name  wo  host  assert  abc.com  http/abc.com  principal  name  wo  host  example.  com  principalnameworealm  gethostname  http/abc.com@example.com  getservicename  http  assertequals  getrealm  principalnamefull  testparsing  http@example.com  kerbnameworealm  kerbnamefull  kerbnamewohost  assert  abc.com  http/abc.com  principalnamewohost  example.com
__label__flaky @  close  trx  coord  client  get  store  get  time  local  oozie  could  not  update  db.  get  status  -test  coord  rerun-  c  get  coord  client  rerun  scope  get  begin  trx  coordinator  action  re  run  coord  action  num2  commit  trx  action  num1  coord-rerun-action2.xml  rest  constants  print  stack  trace  store1  e  store     test  coord  rerun  actions3  action  id2  add  record  to  job  table  integer  job  id  action  id1  services  fail  coordinator  job  add  record  to  action  table  assert  not  same  0000000-  to  string  action1  action2  coord-rerun-action1.xml  get  coordinator  action  @  closetrx  coordclient  getstore  gettime  localoozie  could not update db.  getstatus  -testcoordrerun-c  getcoordclient  rerunscope  get  begintrx  coordinatoraction  reruncoord  actionnum2  committrx  actionnum1  coord-rerun-action2.xml  restconstants  printstacktrace  store1  e  store     testcoordrerunactions3  actionid2  addrecordtojobtable  integer  jobid  actionid1  services  fail  coordinatorjob  addrecordtoactiontable  assertnotsame  0000000-  tostring  action1  action2  coord-rerun-action1.xml  getcoordinatoraction
__label__nflaky compute  slash  count  slash  count  file  name  pattern  max  history  expect  dir  max  daily  rollover  with  cronolog  pattern  simulated  number  of  periods  cp  expected  dir  min  random  output  dir  /\%d{  expected  file  and  dir  count  }/clean.txt.zip  log  over  multiple  periods  daily_  cronolog_  date_  pattern  computeslashcount  slashcount  filenamepattern  maxhistory  expectdirmax  dailyrolloverwithcronologpattern  simulatednumberofperiods  cp  expecteddirmin  randomoutputdir  /\%d{  expectedfileanddircount  }/clean.txt.zip  logovermultipleperiods  daily_cronolog_date_pattern
__label__flaky init  _test  get  for  info  all  actions  destroy  get  id  services  coord  action  get  for  info  jpa  executor  add  record  to  coord  job  table  resource  xml  name  coordinator  job  create  coord  action  coord-action-get.xml  sla  xml  set  system  property  insert  the  action  true  coordinator  action  set  sla  xml  action  insert  record  coord  action  test  coord  action  get  all  columns  job  init  _testgetforinfoallactions  destroy  getid  services  coordactiongetforinfojpaexecutor  addrecordtocoordjobtable  resourcexmlname  coordinatorjob  createcoordaction  coord-action-get.xml  slaxml  setsystemproperty   insert the action  true  coordinatoraction  setslaxml  action  insertrecordcoordaction  testcoordactiongetallcolumns  job
__label__nflaky fifo  linked  list  test  add  remove  cycle  h  h1  h2  assert  equals  h3  h4  assert  same  get  last  remove  last  1  2  3  assert  4  size  get  first  add  first  fifolinkedlist  testaddremovecycle  h  h1  h2  assertequals  h3  h4  assertsame  getlast  removelast  1  2  3  assert  4  size  getfirst  addfirst
__label__flaky play  client  creates  stream  and  server  replies  with  fin  ping  android  play  it  back  header  entries  verify  the  peer  received  what  was  expected  accept  frame  ensure  that  the  syn_  reply  has  been  received.  open  stream  count  type_  headers  peer  round  trip  time  type_  ping  connection  take  frame  banana  a  b  syn  reply  assert  equals  headers  mode  syn_  stream  send  frame  spdy3  ping  syn  stream  new  stream  play  clientcreatesstreamandserverreplieswithfin  ping  android   play it back  headerentries   verify the peer received what was expected  acceptframe   ensure that the syn_reply has been received.  openstreamcount  type_headers  peer  roundtriptime  type_ping  connection  takeframe  banana  a  b  synreply  assertequals  headersmode   syn_stream  sendframe  spdy3   ping  synstream  newstream
__label__nflaky note  the  trailing  \'/\'  in  the  target  path.  /foo  expected  failed  put  to  a  path  without  parent  directory  expected  failed  copy  from  local  to  a  non-existent  directory  src  path  is  assert  that  no  dir  delete  /  not  -put  shell  run  lfs  exists  -copy  from  local  test  copy  no  parent  to  string  no  dir  name   note the trailing \'/\' in the target path.  /foo  expected failed put to a path without parent directory  expected failed copyfromlocal to a non-existent directory  srcpath  is  assertthat  nodir  delete  /  not  -put  shellrun  lfs  exists  -copyfromlocal  testcopynoparent  tostring  nodirname
__label__flaky cancel  token  url  conf  check  query  params  wipe  out  internal  token  to  simulate  auth  always  required  send  user  test-user  set  authentication  method  fake  turning  on  security  so  api  thinks  it  should  use  tokens  file  status  url  set  login  user  ugi  encode  to  url  string  fs  path  to  query  string  set  configuration  user  group  information  get  short  user  name  to  url  get  token  url  webhdfs  create  remote  user  kerberos  /  renew  token  url  get  op  param  set  delegation  token  get  web  hdfs  file  system  send  token  test  secure  auth  params  in  url  security  util  to  string  token  string  get  delegation  token  put  op  param  canceltokenurl  conf  checkqueryparams   wipe out internal token to simulate auth always required   send user  test-user  setauthenticationmethod   fake turning on security so api thinks it should use tokens  filestatusurl  setloginuser  ugi  encodetourlstring  fspath  toquerystring  setconfiguration  usergroupinformation  getshortusername  tourl  gettokenurl  webhdfs  createremoteuser  kerberos  /  renewtokenurl  getopparam  setdelegationtoken  getwebhdfsfilesystem   send token  testsecureauthparamsinurl  securityutil  tostring  tokenstring  getdelegationtoken  putopparam
__label__nflaky int  method  but  different  method  names  have  different  hash  code  hash2  protocol  signature  hash1  str  method  assert  false  larger  number  of  parameter  types  have  different  hash  code  echo  int  echo  hash1  assert  equals  get  method  int  echo  hash  test  hash  code  make  sure  that  overriding  methods  have  different  hashcodes  from  different  declaring  classes  have  the  same  hash  code  echo_alias  string  echo  hash  int  echo  hash  alias  int  echo  hash2  types  have  different  hash  codes  make  sure  that  methods  order  does  not  matter  for  method  array  hash  code  get  fingerprint  string  echo  hash1  intmethod   but different method names have different hash code  hash2  protocolsignature  hash1  strmethod  assertfalse   larger number of parameter types have different hash code  echo  intechohash1  assertequals  getmethod  intechohash  testhashcode   make sure that overriding methods have different hashcodes   from different declaring classes have the same hash code  echo_alias  stringechohash  intechohashalias  intechohash2   types have different hash codes   make sure that methods order does not matter for method array hash code  getfingerprint  stringechohash1
__label__flaky close  trx  lib  reader  conf  run  get  status  get  job  update  action  assert  not  null  get  test  case  dir  /workflow.xml  file://  begin  trx  create  test  case  sub  dir  create  action  workflow.xml  wait  for  commit  trx  bean  running-mode  external-status  action  conf  test  store2  store3  test  workflow  action  recovery  service  assert  equals(  workflow  job.  status.  succeeded   engine.get  job(job  id).get  status());  sync  oozie  client  job  id  todo  check   without  this  we  get  jpa  concurrency  exceptions   odd  get  type  copy  char  stream  get  resource  as  reader  action  id  file  evaluate  actions  submit  job  get  id  replace  all  workflow  action  bean  sleep  engine  get  set  pending  get  workflow  action  ok  workflow  job  recovery  runnable  a  get  actions  for  workflow  set  get  conf  fixed  action  conf  wf-ext-schema-valid.xml  assert  equals  get  action  store  set  conf  set  status  async  services  io  utils  get  test  user  t  signal-value  based_on_action_status  equals  writer  action2  action3  closetrx  lib  reader  conf  run  getstatus  getjob  updateaction  assertnotnull  gettestcasedir  /workflow.xml  file://  begintrx  createtestcasesubdir  create  action  workflow.xml  waitfor  committrx  bean  running-mode  external-status  actionconf  test  store2  store3  testworkflowactionrecoveryservice   assertequals(workflowjob.status.succeeded  engine.getjob(jobid).getstatus());  sync  oozieclient  jobid   todo check  without this we get jpa concurrency exceptions  odd  gettype  copycharstream  getresourceasreader  actionid  file  evaluate  actions  submitjob  getid  replaceall  workflowactionbean  sleep  engine  get  setpending  getworkflowaction  ok  workflowjob  recoveryrunnable  a  getactionsforworkflow  set  getconf  fixedactionconf  wf-ext-schema-valid.xml  assertequals  getaction  store  setconf  setstatus  async  services  ioutils  gettestuser  t  signal-value  based_on_action_status  equals  writer  action2  action3
__label__nflaky add  status  smoke  get  message  assert  equals  get  copy  of  status  list  get  level  status  list  size  assert  not  null  get  bsm  add  status  smoke  getmessage  assertequals  getcopyofstatuslist  getlevel  statuslist  size  assertnotnull  get  bsm
__label__flaky set  classes  to  be  excluded  test  coord  status  transit  service  backward  support  assert  false  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  is  pending  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  assert  not  null  get  coordinator  action  end  current  date  plus  month  job  wait  for  init  get  conf  start  destroy  assert  equals  services  x  data  test  case  execute  add  record  to  coord  job  table  services  coordinator  job  job  id  runnable  coord-action-get.xml  excluded  services  set  system  property  true  status  transit  service  job  jpa  service  evaluate  setclassestobeexcluded  testcoordstatustransitservicebackwardsupport  assertfalse  getcurrentdateafterincrementinginmonths  getid  run  dateutils  ispending  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  job  waitfor  init  getconf  start  destroy  assertequals  services  xdatatestcase  execute  addrecordtocoordjobtable  services  coordinatorjob  jobid  runnable  coord-action-get.xml  excludedservices  setsystemproperty  true  statustransitservice  job  jpaservice  evaluate
__label__nflaky test  delegation  token  authenticated  url  with  no  dt  test  delegation  token  authentication  url  with  no  dt  filter  testdelegationtokenauthenticatedurlwithnodt  testdelegationtokenauthenticationurlwithnodtfilter
__label__flaky 2009-06-24  02:43:19 344  debug  _  l6_:323  -  useroozie  groupoozie  token  m  ytoken  app-  app  lr  job-  action-  number  of  pending  signals  to  check  0  split  get  test  case  dir  14-200904160239--example-  c  job  token  write  see  job  conf(  class)  or  job  conf#set  jar(  string).  test  job14-200904160239--example-  c  action14-200904160239--example-  c@2  use  generic  options  parser  for  2009-06-24  02:43:14 505  info  _  l5_:317  -  useroozie  groupoozie  token-  app-  2009-06-24  02:43:29 151  debug  _  l7_:323  -  user-  group-  token-  app-  job-  matches  test  process  coordinator  log  for  actions  parsing  the  arguments.  _  l3  a_  applications  should  implement  tool  for  the  same.  _  l3  b_  multi  line  contains  /test.log  job14-200904160239--example-  c  action14-200904160239--example-  c@2  reset  job14-200904160239--example-  c  action14-200904160239--example-  c@1  end  workflow  state  change  sb  2009-06-24  02:43:13 958  debug  _  l1_:323  -  useroozie  group-  token-  appexample-forkjoinwf  group  fw  2009-06-24  02:43:13 961  info  _  l2_:317  -  user-  group-  token-  appexample-forkjoinwf  14-200904160239--example-  c@1  org.apache.oozie.core.command.  workflow  runner  callable  released  lock  action-  number  of  pending  actions  0  define  parameter  set  parameter  close  2009-06-24  02:43:14 431  warn  _  l4_:661  -  no  job  jar  file  set.  user  classes  may  not  be  found.  sw  job14-200904160239--example-  c  action14-200904160239--example-  c@1  released  lock  x  log  streamer  assert  equals  user  xf  2009-06-24  02:43:13 986  warn  _  l3_:539  -  user-  group-  token-  appexample-forkjoinwf  action  _  l1_  to  string  _  l5_  process  log  append    2009-06-24 02:43:19 344 debug _l6_:323 - useroozie groupoozie tokenmytoken app-   app  lr  job- action- number of pending signals to check 0      split  gettestcasedir  14-200904160239--example-c  job  token  write  see jobconf(class) or jobconf#setjar(string).  test  job14-200904160239--example-c action14-200904160239--example-c@2 use genericoptionsparser for     2009-06-24 02:43:14 505  info _l5_:317 - useroozie groupoozie token- app-     2009-06-24 02:43:29 151 debug _l7_:323 - user- group- token- app- job-   matches  testprocesscoordinatorlogforactions  parsing the arguments.   _l3a_applications should implement tool for the same.   _l3b_multi line   contains  /test.log  job14-200904160239--example-c action14-200904160239--example-c@2   reset  job14-200904160239--example-c action14-200904160239--example-c@1 end workflow state change  sb  2009-06-24 02:43:13 958 debug _l1_:323 - useroozie group- token- appexample-forkjoinwf   group  fw    2009-06-24 02:43:13 961  info _l2_:317 - user- group- token- appexample-forkjoinwf   14-200904160239--example-c@1  org.apache.oozie.core.command.workflowrunnercallable released lock  action- number of pending actions 0   defineparameter  setparameter  close    2009-06-24 02:43:14 431  warn _l4_:661 - no job jar file set.  user classes may not be found.   sw  job14-200904160239--example-c action14-200904160239--example-c@1 released lock  xlogstreamer  assertequals  user  xf    2009-06-24 02:43:13 986  warn _l3_:539 - user- group- token- appexample-forkjoinwf   action  _l1_  tostring  _l5_  processlog  append
__label__nflaky rpcuser:*:29:  maxint  get_  all_  groups_  cmd  minint:x:2147483648:2147483648:  grid  distributed  file  system:/home/minint:/bin/bash  assume  not  windows  nfsnobody:*:4294967294:  daemon:x:2:2:daemon:/sbin:/sbin/nologin\""  archivebackup:*:1031:4294967294:  archive  backup:/home/users/archivebackup:/bin/sh  hash  bi  map  u  map  |  cut  -d:  -f1 3  maxint:x:2147483647:2147483647:  grid  distributed  file  system:/home/maxint:/bin/bash  maxint:*:2147483647:  assert  true  nfsnobody  get  create  echo  \""  g  map  group  hdfs:*:11501:hrt_hdfs  mapred3:x:498\""  minint  nfsnobody:x:4294967294:4294967294:  anonymous  nfs  user:/var/lib/nfs:/sbin/nologin  get_  all_  users_  cmd  assert  equals  test  id  out  of  integer  range  daemon  mapred3  size  hdfs:x:11501:10787:  grid  distributed  file  system:/home/hdfs:/bin/bash  shell  based  id  mapping  nfsnobody1  hdfs  :  maps  for  id  to  name  map  nfsnobody1:*:4294967295:  user  empty_  pass_  through_  map  archivebackup  nfsnobody1:x:4294967295:4294967295:  anonymous  nfs  user:/var/lib/nfs1:/sbin/nologin  minint:*:2147483648:  update  map  internal  rpcuser  rpcuser:*:29:    maxint  get_all_groups_cmd  minint:x:2147483648:2147483648:grid distributed file system:/home/minint:/bin/bash    assumenotwindows  nfsnobody:*:4294967294:    daemon:x:2:2:daemon:/sbin:/sbin/nologin\""  archivebackup:*:1031:4294967294:archive backup:/home/users/archivebackup:/bin/sh    hashbimap  umap   | cut -d: -f1 3  maxint:x:2147483647:2147483647:grid distributed file system:/home/maxint:/bin/bash    maxint:*:2147483647:    asserttrue  nfsnobody  get  create  echo \""  gmap  group  hdfs:*:11501:hrt_hdfs    mapred3:x:498\""  minint  nfsnobody:x:4294967294:4294967294:anonymous nfs user:/var/lib/nfs:/sbin/nologin    get_all_users_cmd  assertequals  testidoutofintegerrange  daemon  mapred3  size  hdfs:x:11501:10787:grid distributed file system:/home/hdfs:/bin/bash    shellbasedidmapping  nfsnobody1  hdfs  :   maps for id to name map  nfsnobody1:*:4294967295:    user  empty_pass_through_map  archivebackup  nfsnobody1:x:4294967295:4294967295:anonymous nfs user:/var/lib/nfs1:/sbin/nologin    minint:*:2147483648:    updatemapinternal  rpcuser
__label__flaky _test  is  main  successful  action  dir  has  output  data  assert  false  running  job  is  main  done  get  file  system  test  empty  fs  has  id  swap  get  id  swap  path  is  successful  assert  true  launcher  mapper  get  error  path  exists  get  output  data  path  evaluate  wait  for  get  fs  test  case  dir  is  complete  _test  ismainsuccessful  actiondir  hasoutputdata  assertfalse  runningjob  ismaindone  getfilesystem  testempty  fs  hasidswap  getidswappath  issuccessful  asserttrue  launchermapper  geterrorpath  exists  getoutputdatapath  evaluate  waitfor  getfstestcasedir  iscomplete
__label__nflaky guice  this  will  not  work  =>  we  expect  a  runtime  exception...  ninja  constant  thrown  not_existing_implementation  expect  ninja  mode  migration  engine  create  injector  provider  set  property  missing  implementation  throws  exception  on  use  not  create  get  provider  get  instance  ninja  properties  injector  guice   this will not work => we expect a runtime exception...  ninjaconstant  thrown  not_existing_implementation  expect  ninjamode  migrationengine  createinjector  provider  setproperty  missingimplementationthrowsexceptiononusenotcreate  getprovider  getinstance  ninjaproperties  injector
__label__flaky test  pause  unpause1  job1  get  time  pause  start  runnable  add  record  to  bundle  job  table  run  get  id  assert  equals  get  status  execute  set  pause  time  services  job  id  assert  not  null  get  set  kickoff  time  job  job  jpa  service  evaluate  wait  for  testpauseunpause1  job1  gettime  pausestartrunnable  addrecordtobundlejobtable  run  getid  assertequals  getstatus  execute  setpausetime  services  jobid  assertnotnull  get  setkickofftime  job  job  jpaservice  evaluate  waitfor
__label__nflaky get  subject  set  charset  /////////////////////////////////////////////////////////////////////  reply  to2@domain  mail  value2  get  reply  to  value1  subject  mail  impl  test  helper  reply  to1@domain  get  charset  body  text  assert  true  get  ccs  get  get  bccs  body  html  get  mail  impl  with  demo  content  get  from  to1@domain  header2  header1  get  headers  mail  impl  cc2@domain  from1@domain  get  tos  cc1@domain  test  that  mail  impl  works  as  expected  contains  get  body  html  bcc1@domain  bcc2@domain  get  body  text  utf-8  equals  to2@domain  getsubject  setcharset   /////////////////////////////////////////////////////////////////////  replyto2@domain  mail  value2  getreplyto  value1  subject  mailimpltesthelper  replyto1@domain  getcharset  bodytext  asserttrue  getccs  get  getbccs  bodyhtml  getmailimplwithdemocontent  getfrom  to1@domain  header2  header1  getheaders  mailimpl  cc2@domain  from1@domain  gettos  cc1@domain  testthatmailimplworksasexpected  contains  getbodyhtml  bcc1@domain  bcc2@domain  getbodytext  utf-8  equals  to2@domain
__label__flaky get  transitions  job  conf  get  name  reader  auth  token  <fs  start  node  def  <pig  assert  true  assert  not  null  get  get  test  case  dir  /workflow.xml  file://  workflow.xml  test-wf  parse  def  app  init  a  b  set  c  <map-reduce  get  conf  d  wf-schema-valid.xml  e  f  g  destroy  assert  equals  services  test  parsing  kill  oozie  client  io  utils  contains  get  test  user  size  copy  char  stream  get  resource  as  reader  z  wps  writer  get  node  file  starts  with  gettransitions  jobconf  getname  reader  authtoken  <fs  startnodedef  <pig  asserttrue  assertnotnull  get  gettestcasedir  /workflow.xml  file://  workflow.xml  test-wf  parsedef  app  init  a  b  set  c  <map-reduce  getconf  d  wf-schema-valid.xml  e  f  g  destroy  assertequals  services  testparsing  kill  oozieclient  ioutils  contains  gettestuser  size  copycharstream  getresourceasreader  z  wps  writer  getnode  file  startswith
__label__nflaky keep-  alive  expect  add  header  response  converter  header  \'  connection:  keep-  alive\'  is  illegal  for  http/2  messages  connection  thrown  test  convert  from  message  connection  header  convert  expect  message  keep-alive  expect  addheader  response  converter  header \'connection: keep-alive\' is illegal for http/2 messages  connection  thrown  testconvertfrommessageconnectionheader  convert  expectmessage
__label__flaky check  that  /  exists  create  a  new  file  in  the  root   write  data   do  no  close  conf  system  create  file  path  io.bytes.per.checksum  make  sure  a  client  can  read  it  before  it  is  closed  close  file  system  \""  partial  block  size  /unfinished-block  test  file  creation  stm  /  get  int  path  :  \""  write  file  and  sync  write  partial  block  and  sync  check  can  read  to  string  file1  test  unfinished  block  packet  buffer  overrun  bytes  per  checksum   check that / exists   create a new file in the root  write data  do no close  conf  system  createfile  path  io.bytes.per.checksum   make sure a client can read it before it is closed  close  filesystem  \""  partialblocksize  /unfinished-block  testfilecreation  stm  /  getint  path : \""  writefileandsync   write partial block and sync  checkcanread  tostring  file1  testunfinishedblockpacketbufferoverrun  bytesperchecksum
__label__nflaky sasl_  privacy_  props  conf  10.221.103.121  10.222.103.121  variablewhitelist.txt  remove  file  get  by  name  wqr  test  fixed  variable  and  local  white  list  10.222.0.0/16  whitelist  based  resolver  10.119.103.112  set  10.119.103.113  10.113.221.222  10.113.221.221  10.221.102.0/23  get  server  properties  assert  equals  10.221.104.0  set  conf  fixed  ips  create  file  with  entries  set  long  test  file  based  ip  list  variable  ips  get  default  properties  inet  address  fixedwhitelist.txt  127.0.0.1  set  boolean  10.223.104.0  sasl_privacy_props  conf  10.221.103.121  10.222.103.121  variablewhitelist.txt  removefile  getbyname  wqr  testfixedvariableandlocalwhitelist  10.222.0.0/16  whitelistbasedresolver  10.119.103.112  set  10.119.103.113  10.113.221.222  10.113.221.221  10.221.102.0/23  getserverproperties  assertequals  10.221.104.0  setconf  fixedips  createfilewithentries  setlong  testfilebasediplist  variableips  getdefaultproperties  inetaddress  fixedwhitelist.txt  127.0.0.1  setboolean  10.223.104.0
__label__flaky create  exclusion  spring-beans  excludes  unchecked  assert  equals  as  list  put  args  spring-core  org.springframework  spring-jdbc  create  dependency  dependency  resolution  with  exclusions  3.2.4.  release  arrays  grab  get  ur  ls  createexclusion  spring-beans  excludes  unchecked  assertequals  aslist  put  args  spring-core  org.springframework  spring-jdbc  createdependency  dependencyresolutionwithexclusions  3.2.4.release  arrays  grab  geturls
__label__nflaky next  headers  token2   token5     assert  false  has  next  assert  equals  name  token3     hit  assert  ti  assert  true  token0  token1  token1  token2  token3  test  value  end  token4   token4  token5  next  headers  token2   token5     assertfalse  hasnext  assertequals  name  token3    hit  assert  ti  asserttrue  token0  token1   token1  token2  token3  testvalueend  token4    token4  token5
__label__flaky cluster  shutdown  dfs  verify  we  can  get  the  data  back  now  that  it  is  on  disk.  get  log  flush  cache  scan  it  back  both  with  scanning  and  get  h  constants  put.add(  h  constants.  col_  startcode   bytes.to  bytes(  start_  code));  test  scanner  system  put  bytes  store  some  new  information  clean  up  write  information  to  the  meta  table  region_  info  testtabledesc  now  update  the  information  again  write  close  an  older  row  on  disk  and  there  is  a  newer  row  in  the  memstore  add  address  byte  stream  open  closed  region  to  bytes  validate  again  bar.foo.com:4321  flushcache  close  and  delete  create  new  h  region  get  region  info  foo.bar.com:1234  r  current  time  millis  to  byte  array  close  and  re-open  to  string  region  row_  key  close  and  reopen  cluster  shutdowndfs   verify we can get the data back now that it is on disk.  getlog   flush cache  scan   it back both with scanning and get  hconstants   put.add(hconstants.col_startcode  bytes.tobytes(start_code));  testscanner  system  put  bytes   store some new information   clean up   write information to the meta table  region_info  testtabledesc   now update the information again  write  close   an older row on disk and there is a newer row in the memstore  add  address  bytestream  openclosedregion  tobytes   validate again  bar.foo.com:4321  flushcache  closeanddelete  createnewhregion  getregioninfo  foo.bar.com:1234  r  currenttimemillis  tobytearray   close and re-open  tostring  region  row_key   close and reopen
__label__nflaky ninja  mode  is  available  conf/jetty.minimal.conf  get  context  path  null  value  ninja  mode  not  minimal  with  context  host  get  host  random_  port  localhost  is  stopped  external  configuration  path  context  path  standalone  start  is  assert  equals  is  started  assert  that  get  ninja  mode  /mycontext  get  port  port  shutdown  ninjamode  isavailable  conf/jetty.minimal.conf  getcontextpath  nullvalue  ninjamode  not  minimalwithcontext  host  gethost  random_port  localhost  isstopped  externalconfigurationpath  contextpath  standalone  start  is  assertequals  isstarted  assertthat  getninjamode  /mycontext  getport  port  shutdown
__label__flaky play  server  request  def  assert  code  get  header  assert  body  recorded  request  post  text/plain;  charset=utf-8  await  media  type  create  client  content-  length  text/plain  content-  type  abc  receiver  take  request  request  assert  equals  parse  set  body  url  /  get  utf8  body  enqueue  get  url  3  build  play  server  request  def  assertcode  getheader  assertbody  recordedrequest  post  text/plain; charset=utf-8  await  mediatype  create  client  content-length  text/plain  content-type  abc  receiver  takerequest  request  assertequals  parse  setbody  url  /  getutf8body  enqueue  geturl  3  build
__label__nflaky 110.113.221.222  ipl  assert  false  110.113.221.222  is  in  the  list  is  in  test  file  not  specified  110.113.221.222  ipl  assertfalse  110.113.221.222 is in the list  isin  testfilenotspecified
__label__flaky get  name  conf  oozie.service.  proxy  user  service.proxyuser.#  user#.hosts  as  list  bar  assert  assert  true  string  utils  assert  not  null  get  join  test  null  proxy  user  validate  localhost  init  oozie.service.  proxy  user  service.proxyuser.#  user#.groups  set  get  conf  get  message  destroy  services     services  fail  contains  ex  proxy  user  to  string  arrays  getname  conf  oozie.service.proxyuserservice.proxyuser.#user#.hosts  aslist  bar  assert  asserttrue  stringutils  assertnotnull  get  join  testnullproxyuser  validate  localhost  init  oozie.service.proxyuserservice.proxyuser.#user#.groups  set  getconf  getmessage  destroy  services     services  fail  contains  ex  proxyuser  tostring  arrays
__label__nflaky set  range  conf  assert  equals  first  =  34-  second  =  third  =  system  second  -100  third  get  range  4-6 9-10 27  test  integer  ranges  first  is  included  set  range  conf  assertequals  first =   34-  second =   third =   system  second  -100  third  getrange  4-6 9-10 27  testintegerranges  first  isincluded
__label__flaky cluster  tries  get  name  checked  if  node  was  recommissioned  conf  all  datanodes  must  be  alive  num  namenodes  start  cluster  sleep  decommissioned  nodes  wait  for  the  block  to  be  deleted  assert  true  times  before  recommissioned  get  client  num  datanodes  write  file  cleanup  file  info  check  file  add  tried:  get  dfs  client  log  datanode  report  replicas  decom  node  decommission  one  node.  verify  that  node  is  decommissioned.  ensure  decommissioned  datanode  is  not  automatically  shutdown  assert  equals  get  file  system  test  recommission  get  name  node  thread  admin  states  assert  null  recomission  node  file  sys  file1  starting  test  test  recommission  namenode  decom  list  stop  decommission  and  check  if  the  new  replicas  are  removed  times.  decommission  node  shutdown  test  decommission.dat  datanode  report  type  cluster  tries  getname  checked if node was recommissioned   conf  all datanodes must be alive  numnamenodes  startcluster  sleep  decommissionednodes   wait for the block to be deleted  asserttrue   times before recommissioned  get  client  numdatanodes  writefile  cleanupfile  info  checkfile  add  tried:   getdfsclient  log  datanodereport  replicas  decomnode   decommission one node. verify that node is decommissioned.   ensure decommissioned datanode is not automatically shutdown  assertequals  getfilesystem  testrecommission  getnamenode  thread  adminstates  assertnull  recomissionnode  filesys  file1  starting test testrecommission  namenodedecomlist   stop decommission and check if the new replicas are removed   times.  decommissionnode  shutdown  testdecommission.dat  datanodereporttype
__label__nflaky optional  one  default  locale  then  return  ninja  constant  get  string  array  language  get  locale  from  string  or  default  ninja  properties  lang  when  test  get  locale  from  string  or  default  ise  when  no  application  language  defined  empty  optional   one default locale  thenreturn  ninjaconstant  getstringarray  language  getlocalefromstringordefault  ninjaproperties  lang  when  testgetlocalefromstringordefaultisewhennoapplicationlanguagedefined  empty
__label__flaky lm  job  conf  prepare  block  user.name  string  when  there  is  no  prepare  block  in  workflow  xml  or  there  is  one  with  no  prepare  actions  in  it  create  job  conf  oozie.action.prepare.xml  1@a  assert  true  get  get  name  node  uri  test  setup  launcher  info  with  empty  prepare  xml  set  action  conf  1@a-0  action  dir  get  authority  services  1  get  test  user  equals  fs.default.name  setup  launcher  info  setting  up  the  job  configuration  get  fs  test  case  dir    lm  jobconf  prepareblock  user.name   string when there is no prepare block in workflow xml or there is one with no prepare actions in it  createjobconf  oozie.action.prepare.xml  1@a  asserttrue  get  getnamenodeuri  testsetuplauncherinfowithemptypreparexml  set  actionconf  1@a-0  actiondir  getauthority  services  1  gettestuser  equals  fs.default.name  setuplauncherinfo   setting up the job configuration  getfstestcasedir
__label__nflaky check  nothing  changed  in  the  directory  tree  empty  list  create  hard  link  mult  tgt_mult  test  create  hard  link  mult  empty  list  src  test  the  case  of  empty  file  list  validate  setup   check nothing changed in the directory tree  emptylist  createhardlinkmult  tgt_mult  testcreatehardlinkmultemptylist  src   test the case of empty file list  validatesetup
__label__flaky request  test  distribution2  get  id  assert  equals  target  accept  get  value  list_  id_  value_  type  assert  oryx  test  recs  get  x  media  type  y  z  /classification  distribution/  a -5   request  testdistribution2  getid  assertequals  target  accept  getvalue  list_id_value_type  assert  oryxtest  recs  get  x  mediatype  y  z  /classificationdistribution/a -5
__label__nflaky a  a  test  text  contains  blanks  contains  blanks  assert  assert  true  assert  false  text  utils          a  a  testtextcontainsblanks  containsblanks  assert  asserttrue  assertfalse  textutils
__label__flaky actionaction  as  list  job-  dag  x  log  info  service  assert  true  test  dag  command  get  set  parameter  action  wait  for  action-  a  reset  log  info  action  b  c  executed  d  x  log  reset  log  info  workflow  e  f  create  prefix  clear  jobjob  assert  equals  command  call  fail  contains  ex  size  job  arrays  evaluate  actionaction  aslist  job-  dagxloginfoservice  asserttrue  testdagcommand  get  setparameter  action  waitfor  action-  a  resetloginfoaction  b  c  executed  d  xlog  resetloginfoworkflow  e  f  createprefix  clear  jobjob  assertequals  command  call  fail  contains  ex  size  job  arrays  evaluate
__label__nflaky advance  clock  tester  assert  equals  1234567 2345678 3456789 4567890  advance  sys  info  windows  verify  information  has  not  been  refreshed  test  with  12  cores  get  available  physical  memory  size  17177038848 8589467648 15232745472 6400417792 12 2805000 6261812   set  sysinfo  string  get  num  v  cores  used  verify  information  has  been  refreshed  17177038848 8589467648 15232745472 5400417792 12 2805000 6263012   get  cpu  usage  percentage  refresh  and  cpu  usage  multicore   advance clock  tester  assertequals  1234567 2345678 3456789 4567890    advance  sysinfowindows   verify information has not been refreshed   test with 12 cores  getavailablephysicalmemorysize  17177038848 8589467648 15232745472 6400417792 12 2805000 6261812   setsysinfostring  getnumvcoresused   verify information has been refreshed  17177038848 8589467648 15232745472 5400417792 12 2805000 6263012   getcpuusagepercentage  refreshandcpuusagemulticore
__label__flaky select  *  from  entitywithstaticcolumn  where  id  =  session  given  crud  when  id  value  static_col  val  is  not  null  static_val  actual  random  utils  manager  one  get  string  next  long  assert  that  insert  static  execute  should_update_static  is  true  then  is  null  long  is  equal  to  entity  select * from entitywithstaticcolumn where id =   session   given  crud   when  id  value  static_col  val  isnotnull  static_val  actual  randomutils  manager  one  getstring  nextlong  assertthat  insertstatic  execute  should_update_static  istrue   then  isnull  long  isequalto  entity
__label__nflaky save  a  copy  of  the  headers  to  make  sure  they  haven\'t  changed  at  the  end  of  this  test.  headers  copy  deepcopy  failed:  e  deep  map  copy  unchecked  get  message  assert  equals  put  fail  testing  framework  assert  headers  obj  get  headers  map  deep  map  deepcopy  now  make  sure  the  default  headers  have  not  changed  for  some  unexpected  reason.   save a copy of the headers to make sure they haven\'t changed at the end of this test.  headerscopy  deepcopy failed:   e  deepmapcopy  unchecked  getmessage  assertequals  put  fail  testingframework  assert  headers  obj  get  headersmap  deepmap  deepcopy   now make sure the default headers have not changed for some unexpected reason.
__label__flaky @  close  trx  coord  client  get  store  get  time  local  oozie  could  not  update  db.  exception  expected  because  action  is  not  in  terminal  state.  get  status  error  code  should  be  e1018  when  job  is  killed  or  failed.  -test  coord  rerun-  c  get  coord  client  get  error  code  get  begin  trx  coordinator  action  re  run  coord  commit  trx  action  num  rest  constants  print  stack  trace  e  store2  assert  equals  store  add  record  to  job  table  integer  job  id  services  fail  coordinator  job  ex  add  record  to  action  table  equals  action  id  test  coord  rerun  neg  0000000-  to  string  error  code  action2  coord-rerun-action1.xml  get  coordinator  action  @  closetrx  coordclient  getstore  gettime  localoozie  could not update db.  exception expected because action is not in terminal state.  getstatus  error code should be e1018 when job is killed or failed.  -testcoordrerun-c  getcoordclient  geterrorcode  get  begintrx  coordinatoraction  reruncoord  committrx  actionnum  restconstants  printstacktrace  e  store2  assertequals  store  addrecordtojobtable  integer  jobid  services  fail  coordinatorjob  ex  addrecordtoactiontable  equals  actionid  testcoordrerunneg  0000000-  tostring  errorcode  action2  coord-rerun-action1.xml  getcoordinatoraction
__label__nflaky data  assert  false  link  del  test  sym  link  get  bytes  assert  file  write  some  data  to  the  file  len  file  write  close  ensure  that  symlink  length  is  correctly  reported  by  java  read  os  get  absolute  path  in  create  the  symlink  length  sym  link  assert  equals  _link  mkdirs  exists  ensure  that  we  can  read  from  link.  test  symlink  file  util  data  assertfalse  link  del  testsymlink  getbytes  assert  file   write some data to the file  len  file  write  close   ensure that symlink length is correctly reported by java  read  os  getabsolutepath  in   create the symlink  length  symlink  assertequals  _link  mkdirs  exists   ensure that we can read from link.  testsymlink  fileutil
__label__flaky kills  add  node  def  enters  workflow  instance  get  status  as  list  wf  exits  end  signal  fails  a  b  test  wf  kill  with  running  nodes  f  start  j  assert  equals  kill  killed  1  size  <worklfow-app/>  arrays  job  /b/    kills  addnode  def  enters  workflowinstance  getstatus  aslist  wf  exits  end  signal  fails  a  b  testwfkillwithrunningnodes  f  start  j  assertequals  kill  killed  1  size  <worklfow-app/>  arrays  job  /b/
__label__nflaky get  current  user  get  group  names  group_  names  assert  false  make  sure  it  is  not  the  same  as  the  login  user  conf  run  string  assert  true  ugi  percentiles_  interval  set  configuration  make  sure  in  the  scope  of  the  do  as   the  right  user  is  current  user  group  information  create  user  for  testing  cur  ugi  set  user  group  info  value  of  assert  equals  user_  name  get  login  user  test  login  verify  group  metrics  ensure  that  do  as  works  correctly  login  from  unix  do  as  equals  hadoop_  user_  group_  metrics_  percentiles_  intervals  getcurrentuser  getgroupnames  group_names  assertfalse   make sure it is not the same as the login user  conf  run  string  asserttrue  ugi  percentiles_interval  setconfiguration   make sure in the scope of the doas  the right user is current  usergroupinformation  createuserfortesting  curugi  set  usergroupinfo  valueof  assertequals  user_name  getloginuser  testlogin  verifygroupmetrics   ensure that doas works correctly   login from unix  doas  equals  hadoop_user_group_metrics_percentiles_intervals
__label__flaky get  connection  context  get  event  message  session  jms  messaging  utils  get  user  conf  get  status  create  session  get  topic  wf-app-name1  assert  test  workflow  job  selectors  or  ca  id1  selector  wf  id1  workflow  job  jms  context  consumer  message  type  user1  get  message  type  init  receive  print  stack  trace  e  get  message  destroy  assert  equals  message  wf  event  listener  fail  =\'  non_matching_user\'  or  pass  a  selector  using  or  condition  on  workflow  job  event  =\'wf-app-name1\'  jms  header  constants  wfe  create  consumer  wf  fail  message  session  getconnectioncontext  geteventmessage  session  jmsmessagingutils  getuser  conf  getstatus  createsession  gettopic  wf-app-name1  assert  testworkflowjobselectorsor  caid1  selector  wfid1  workflowjob  jmscontext  consumer  messagetype  user1  getmessagetype  init  receive  printstacktrace  e  getmessage  destroy  assertequals  message  wfeventlistener  fail  =\'non_matching_user\' or    pass a selector using or condition  onworkflowjobevent  =\'wf-app-name1\'  jmsheaderconstants  wfe  createconsumer  wffailmessage  session
__label__nflaky simulator  build  scenario  long  test  verify  parameters  simulate  simulator  buildscenario  longtest  verify  parameters  simulate
__label__flaky headers  get  server  address  /_non_existing_url  oops.  not  found.  ninja  test  browser  test  that  not  found  works  new  hash  map  assert  equals  check  that  we  get  a  working  \""not  found\""  template  from  views/system/404not  found.ftl.html  make  request  some  empty  headers  for  now...  get  raw  response  make  sure  the  status  code  is  correct:  content  make  request  and  get  response  contains  maps  get  status  code  assert  true  now  get  the  content  in  another  request...  get  status  line  http  response  headers  getserveraddress  /_non_existing_url  oops. not found.  ninjatestbrowser  testthatnotfoundworks  newhashmap  assertequals   check that we get a working \""not found\"" template from views/system/404notfound.ftl.html  makerequest   some empty headers for now...   get raw response   make sure the status code is correct:  content  makerequestandgetresponse  contains  maps  getstatuscode  asserttrue   now get the content in another request...  getstatusline  httpresponse
__label__nflaky lookup  country  identifier  mo  000000  assert  equals  test  lookup  500000  assert  null  472000  us/  ca  gb  support  958000  509000  lookupcountryidentifier  mo  000000  assertequals  testlookup  500000  assertnull  472000  us/ca  gb  support  958000  509000
__label__flaky next  now  delete  everything.  assert  equals  compaction_  threshold  counter  get  row  flush  delete  flushcache  result  major  compact.  r  get  compact  stores  test  major  compacting  to  no  output  get  scanner  results  create  store  file  next   now delete everything.  assertequals  compaction_threshold  counter  getrow   flush  delete  flushcache  result   major compact.  r  get  compactstores  testmajorcompactingtonooutput  getscanner  results  createstorefile
__label__nflaky expires  token_  max_  inactive_  interval  _test  do  filter  authentication  max  inactive  interval  test  do  filter  authentication  unauthorized  expired  token_  validity_  sec  current  time  millis  authorized  max  inactives  expired  period  is  reached   max  in  active  interval  is  not  reached.  system  expires  token_max_inactive_interval  _testdofilterauthenticationmaxinactiveinterval  testdofilterauthenticationunauthorizedexpired  token_validity_sec  currenttimemillis  authorized  maxinactives   expired period is reached  maxinactiveinterval is not reached.  system
__label__flaky cluster  ncfb  get  name  conf  wait  active  validate  we  get  all  the  corrupt  files  now  get  the  2nd  and  3rd  file  that  is  corrupt  to  array  storage  dir  equals  ignore  case  info  dfs  config  keys  get  block  pool  id  log  deliberately  remove  blocks  from  a  file  and  validate  the  list-corrupt-file-blocks  api  list  corrupt  file  blocks  test  the  paging  here  deliberately  removing  file  count  testlist  corrupt  file  blocks  get  file  system  cannot  remove  file.  set  int  get  name  node  blk_  set  long  test  get  corrupt  files  util  size  cleanup  get  instance  storage  dir  idx  datanode  scans  shutdown  /good  data  get  finalized  dir  bpid  /corrupt  data  fs  namenode  delete  sleep  assert  true  delete  the  blocks  list  files  cfb  data_dir  validate  mini  dfs  cluster  blocks  namenode  has  bad  files.  next  corrupt  file  blocks  get  block  name  j  corrupt  file  blocks  directories  thread  create  files  build  (blocks.length  >  0));  num  corrupt  get  namesystem  starts  with  cluster  ncfb  getname  conf  waitactive   validate we get all the corrupt files   now get the 2nd and 3rd file that is corrupt  toarray  storagedir  equalsignorecase  info  dfsconfigkeys  getblockpoolid  log   deliberately remove blocks from a file and validate the list-corrupt-file-blocks api  listcorruptfileblocks   test the paging here  deliberately removing file   count  testlistcorruptfileblocks  getfilesystem  cannot remove file.  setint  getnamenode  blk_  setlong  testgetcorruptfiles  util  size  cleanup  getinstancestoragedir  idx   datanode scans  shutdown  /gooddata  getfinalizeddir  bpid  /corruptdata  fs  namenode  delete  sleep  asserttrue   delete the blocks  listfiles  cfb  data_dir   validate  minidfscluster  blocks  namenode has bad files.   nextcorruptfileblocks  getblockname  j  corruptfileblocks   directories  thread  createfiles  build   (blocks.length > 0));  numcorrupt  getnamesystem  startswith
__label__nflaky disk  validator  factory  test  get  instance  of  non  exist  class  get  instance  non-exist  diskvalidatorfactory  testgetinstanceofnonexistclass  getinstance  non-exist
__label__flaky check  for  resolved  conf  /2009/22/  e  action  get  test  case  dir  property  action  create  action  element  element  list  dry  run  coord  test  dry  run  pull  deps  print  stack  trace  workflow  get  child  parse  xml  /2009/15/  get  pull  missing  dependencies  test  dir  fail  coordinator  job  get  children  get  namespace  file:// test  dir/2009/29  coord  command  utils  job  add  record  to  coord  job  table  for  waiting  make  sure  conf  is  not  resolved  as  dependencies  are  not  met  configuration  ${coord:data  in(\'  a\')}  app  path  create  coordinator  action  bean  action  xml  sleep  coord  coord-action-for-action-input-check.xml  /2009/08/  get  create  dir  coord-job-for-matd-hcat.xml  value  action  bean  miss  deps  xml  utils  e  newaction  xml  get  message  assert  equals  e1  set  missing  dependencies  e2  ${coord:data  out(\'  local_  a\')}  get  value  make  the  dependencies  available  /2009/29/  config  elem  file:// test  dir/2009/29 file:// test  dir/2009/22 file:// test  dir/2009/15 file:// test  dir/2009/08  get  coord  action  xml  action  xml  only  to  check  whether  coord  conf  got  resolved  or  not  get  fs  test  case  dir   check for resolved conf  /2009/22/  eaction  gettestcasedir  property  action  createactionelement  elementlist  dryruncoord  testdryrunpulldeps  printstacktrace  workflow  getchild  parsexml  /2009/15/  getpullmissingdependencies  testdir  fail  coordinatorjob  getchildren  getnamespace  file:// testdir/2009/29  coordcommandutils  job  addrecordtocoordjobtableforwaiting   make sure conf is not resolved as dependencies are not met  configuration  ${coord:datain(\'a\')}  apppath  createcoordinatoractionbean  actionxml  sleep  coord  coord-action-for-action-input-check.xml  /2009/08/  get  createdir  coord-job-for-matd-hcat.xml  value  actionbean  missdeps  xmlutils  e  newactionxml  getmessage  assertequals  e1  setmissingdependencies  e2  ${coord:dataout(\'local_a\')}  getvalue   make the dependencies available  /2009/29/  configelem  file:// testdir/2009/29 file:// testdir/2009/22 file:// testdir/2009/15 file:// testdir/2009/08  getcoordactionxml   actionxml only to check whether coord conf got resolved or not  getfstestcasedir
__label__nflaky df  filesystem  1  k-blocks  used  available  use\%  mounted  on  expected  exception  with  empty  line!  unexpected  empty  line  fewer  lines  of  output  than  expected  e  reader  generic  test  utils  test  df  malformed  output  19222656  10597036  7649060  59\%  /  system  /  /dev/sda5  19222656  10597036  7649060  59\%  /  fail  filesystem  1  k-blocks  used  available  use\%  mounted  on  assert  exception  contains  could  not  parse  line:  parse  output  to  string  parse  exec  result  expected  exception  with  missing  line!  expected  exception  with  missing  field!     df  filesystem     1k-blocks     used available use\% mounted on  expected exception with empty line!  unexpected empty line  fewer lines of output than expected  e  reader  generictestutils  testdfmalformedoutput         19222656 10597036   7649060  59\% /  system  /  /dev/sda5       19222656 10597036   7649060  59\% /  fail  filesystem     1k-blocks     used available use\% mounted on    assertexceptioncontains  could not parse line:   parseoutput  tostring  parseexecresult  expected exception with missing line!  expected exception with missing field!
__label__flaky mapreduce.jobtracker.kerberos.principal  mapreduce.jobtracker.address  mapred.job.tracker  job  conf  set  yarn.resourcemanager.address  assert  equals  mapred/localhost@  kdc.  domain.  com  rm/server.com@  kdc.  domain.  com  localhost:8032  services  get  mr  token  renewer  internal  mapred/_  host@  kdc.  domain.  com  127.0.0.1:50300  get  test  get  mr  delegation  token  renewer  oozie  mr  token  localhost:50300  has  yarn.resourcemanager.principal  mapreduce.jobtracker.kerberos.principal  mapreduce.jobtracker.address  mapred.job.tracker  jobconf  set  yarn.resourcemanager.address  assertequals  mapred/localhost@kdc.domain.com  rm/server.com@kdc.domain.com  localhost:8032  services  getmrtokenrenewerinternal  mapred/_host@kdc.domain.com  127.0.0.1:50300  get  testgetmrdelegationtokenrenewer  oozie mr token  localhost:50300  has  yarn.resourcemanager.principal
__label__nflaky conn  x  frame  enabled  create  server  get  http  url  connection  conf  http  server  x-  frame-  options  unexpected  x-  frame-  options  in  header  get  header  field  stop  assert  true  xfo  header  to  string  http  server2  test  http  resonse  does  not  contain  x  frame  options  conn  xframeenabled  createserver  gethttpurlconnection  conf  httpserver  x-frame-options  unexpected x-frame-options in header  getheaderfield  stop  asserttrue  xfoheader  tostring  httpserver2  testhttpresonsedoesnotcontainxframeoptions
__label__flaky initial  insert  get  expected  duration  check  updated  +  original  fields  get  actual  end  get  time  test  insert  update  get  event  status  event  status  get  expected  start  set  insert  list  cal  bean1  assert  true  assert  not  null  exp  end  bean2  get  _create  sla  summary  bean  new  date  get  actual  duration  is  start  processed  get  actual  start  set  time  add  act  start  running  get  job  id  _create  sla  calc  bean  is  end  processed  workflow-1  calendar  assert  equals  write  cmd  exp  start  list  read  cmd2  execute  read  cmd1  sc  bean  update  existing  record  get  expected  end  services  set  update  list  jpa  service  wf  id  sd  bean   initial insert  getexpectedduration   check updated + original fields  getactualend  gettime  testinsertupdate  geteventstatus  eventstatus  getexpectedstart  setinsertlist  cal  bean1  asserttrue  assertnotnull  expend  bean2  get  _createslasummarybean  newdate  getactualduration  isstartprocessed  getactualstart  settime  add  actstart  running  getjobid  _createslacalcbean  isendprocessed  workflow-1  calendar  assertequals  writecmd  expstart  list  readcmd2  execute  readcmd1  scbean   update existing record  getexpectedend  services  setupdatelist  jpaservice  wfid  sdbean
__label__nflaky p0  p1  test  insertion  with  failover  ns  check  overflow  exception  ns.  standby  exception  for  client  to  try  another  server.  conf  add  to  first  queue.  3  queues   2  slots  each.  fcq  rpc  status  proto  add  to  first  and  second  full  queue  spills  over  to  third.  add  to  queue  and  verify  add  a  b  common  configuration  keys  unchecked  didn\'t  fail  mock  call  add  to  first  full  queue  spills  over  to  second.  fail  regular  retriable  exception  if  call  queue  is  full.  mockito  reset  ise  add  to  second  queue.  spy  add  to  second  full  queue  spills  over  to  third.  set  boolean  p0  p1  testinsertionwithfailover  ns  checkoverflowexception  ns.   standby exception for client to try another server.  conf   add to first queue.   3 queues  2 slots each.  fcq  rpcstatusproto   add to first and second full queue spills over to third.  addtoqueueandverify  add  a  b  commonconfigurationkeys  unchecked  didn\'t fail  mockcall   add to first full queue spills over to second.  fail   regular retriableexception if call queue is full.  mockito  reset  ise   add to second queue.  spy   add to second full queue spills over to third.  setboolean
__label__flaky /  should  be  a  directory  dfs  client  fs  get  file  info  for  a  non-absolute  path  did  not  throw  io  exception  /no  such  file  path  check  that  /  exists  assert  true  non-existant  file  should  result  in  null  get  file  status  test  get  file  info  throws  the  right  exception  given  a  non-absolute  path.  test  get  file  info  non-absolute  invalid  file  name  file  info  make  sure  get  file  info  returns  null  for  files  which  do  not  exist  assert  equals  /  fail  contains  re  to  string  get  file  info  wrong  exception  for  invalid  file  name  is  directory  / should be a directory  dfsclient  fs  getfileinfo for a non-absolute path did not throw ioexception  /nosuchfile  path   check that / exists  asserttrue  non-existant file should result in null  getfilestatus   test getfileinfo throws the right exception given a non-absolute path.  testgetfileinfo  non-absolute  invalid file name  fileinfo   make sure getfileinfo returns null for files which do not exist  assertequals  /  fail  contains  re  tostring  getfileinfo  wrong exception for invalid file name  isdirectory
__label__nflaky we  still  can  scan  records  in  an  unsorted  t  file  reader  conf  vbuf  get  key  length  now  try  get  value  first  fs  advance  path  test  scan  range  get  len  get  file  status  scanner  value  m  kbuf  get  key  get  value  length  vlen  key  z  is  false  assert  that  create  scanner  value  z  entry  get  value  klen  buf_  size  is  sorted  get  entry  count  key  m  is  equal  to  open  read  key  and  value   we still can scan records in an unsorted tfile  reader  conf  vbuf  getkeylength   now try get value first  fs  advance  path  testscanrange  getlen  getfilestatus  scanner  valuem  kbuf  getkey  getvaluelength  vlen  keyz  isfalse  assertthat  createscanner  valuez  entry  getvalue  klen  buf_size  issorted  getentrycount  keym  isequalto  open   read key and value
__label__flaky cluster  name  node  port  create  cluster  conf  test  file  creation  delete  parent:  fs  system  create  file  wait  active  this  ensures  that  leases  are  persisted  in  fsimage.  sleep  hflush  test  3************************************  assert  true  ipc.client.connection.maxidletime  close  write  file  newfile  2s  dfs  config  keys  format  create  file1.  created  file  dir2  get  file  system  dir1  test  file  creation  test  while  open  rename  to  existent  directory  set  int  thread  persistent  leases  from  fsimage.  check  full  file  max_  idle_  time  dfs.support.append  stm1  build  /user/dir1  rename  nnport  /user/dir2  mkdirs  get  name  node  port  exists  file1  shutdown  set  boolean  cluster  namenodeport   create cluster  conf  testfilecreationdeleteparent:   fs  system  createfile  waitactive   this ensures that leases are persisted in fsimage.  sleep  hflush  test 3************************************  asserttrue  ipc.client.connection.maxidletime  close  writefile  newfile   2s  dfsconfigkeys  format   create file1.  created file   dir2  getfilesystem  dir1  testfilecreation  testwhileopenrenametoexistentdirectory  setint  thread   persistent leases from fsimage.  checkfullfile  max_idle_time  dfs.support.append  stm1  build  /user/dir1  rename  nnport  /user/dir2  mkdirs  getnamenodeport  exists  file1  shutdown  setboolean
__label__nflaky this  must  match  /blah/{id}/{id2}/{id3}/morestuff/at/the/end  build  route  assert  false  matches  /blah/id/id2/id3/morestuff/at/the/end  route  assert  true  this  should  not  match  as  the  last  \""end\""  is  missing  get  route  builder  parameters  dont  cross  slashes  /blah/id/id2/id3/morestuff/at/the   this must match  /blah/{id}/{id2}/{id3}/morestuff/at/the/end  buildroute  assertfalse  matches  /blah/id/id2/id3/morestuff/at/the/end  route  asserttrue   this should not match as the last \""end\"" is missing  get  routebuilder  parametersdontcrossslashes  /blah/id/id2/id3/morestuff/at/the
__label__flaky get  job  tracker  uri  oozie.shell.exec  <exec>  script</exec>  b=  b  conf  verify  the  class  setup  action  conf  proto  conf  create  base  workflow  context  action  test  setup  methods  <job-tracker>  add  ae  pig-action  parse  xml  </job-tracker>  verify  the  launcher  jar  filename  <name-node>  </name-node>  2  script  shell  get  type  get  classes  for  launcher  a=  a  action  excutor  type  is  \'shell\'  classes  oozie.shell.args.1  get  actions  oozie.shell.args.0  create  base  hadoop  conf  wf  action  xml  <shell>  get  get  name  node  uri  set  xml  utils  workflow  app  service  <argument>a=  a</argument>  get  launcher  classes  assert  equals  shell-launcher.jar  set  type  get  launcher  jar  name  </shell>  services  oozie.shell.args.size  get  test  user  add  all  <argument>b=  b</argument>  get  fs  test  case  dir  getjobtrackeruri  oozie.shell.exec  <exec>script</exec>  b=b  conf   verify the class  setupactionconf  protoconf  createbaseworkflow  context  action  testsetupmethods  <job-tracker>  add  ae  pig-action  parsexml  </job-tracker>   verify the launcher jar filename  <name-node>  </name-node>  2  script  shell  gettype  getclassesforlauncher  a=a   actionexcutor type is \'shell\'  classes  oozie.shell.args.1  getactions  oozie.shell.args.0  createbasehadoopconf  wf  actionxml  <shell>  get  getnamenodeuri  set  xmlutils  workflowappservice  <argument>a=a</argument>  getlauncherclasses  assertequals  shell-launcher.jar  settype  getlauncherjarname  </shell>  services  oozie.shell.args.size  gettestuser  addall  <argument>b=b</argument>  getfstestcasedir
__label__nflaky result  test  results  json  with  object  to  render  get  status  code  get  renderable  results  test  object  json  get  content  type  assert  equals  render  result  result  testresultsjsonwithobjecttorender  getstatuscode  getrenderable  results  testobject  json  getcontenttype  assertequals  render  result
__label__flaky cluster  parent  test  chmod  on  dfs  run  cmd  _  hdfs.  user-10:_hadoop.users--  conf  test  file  permissions  :reptiles  path  test  different  characters  in  names  test  chmod  file  system  python:  -chown  /non  existent  file  /tmp  hdfs/hadoop-core@apache.org:asf-projects  python  dfs  config  keys  /tmp/chown  test  chmod  test  test  chown  and  chgrp  on  dfs:  /tmp/chmod  test  hdfs.user  get  file  system  /  mammals  shell  herbivores  num  data  nodes  hdfs/hadoop-core@apache.org  true  -chgrp  shutdown  -  r  reptiles  fs  _hadoop.users--  _  hdfs.  user-10  for  dfs   i  am  the  super  user  and  i  can  change  owner  of  any  file  to  *  anything.  \""-  r\""  option  is  already  tested  by  chmod  test  above.  file  test_  root_  dir  root  /*  hadoop  write  file  set  toys  get  absolute  path  unknown  file  set  conf  confirm  owner  test  chmod  on  local  fs  build  get  local  hadoop-core@apache.org/100  test  dfs  shell  unknown  file*  asf-projects  hadoop:toys  cluster  parent   test chmod on dfs  runcmd  _hdfs.user-10:_hadoop.users--  conf  testfilepermissions  :reptiles  path   test different characters in names  testchmod  filesystem  python:  -chown  /nonexistentfile  /tmp  hdfs/hadoop-core@apache.org:asf-projects  python  dfsconfigkeys  /tmp/chowntest  chmodtest   test chown and chgrp on dfs:  /tmp/chmodtest  hdfs.user  getfilesystem  /  mammals  shell  herbivores  numdatanodes  hdfs/hadoop-core@apache.org  true  -chgrp  shutdown  -r  reptiles  fs  _hadoop.users--  _hdfs.user-10   for dfs  i am the super user and i can change owner of any file to       * anything. \""-r\"" option is already tested by chmod test above.         file  test_root_dir  root  /*  hadoop  writefile  set  toys  getabsolutepath  unknownfile  setconf  confirmowner   test chmod on local fs  build  getlocal  hadoop-core@apache.org/100  testdfsshell  unknownfile*  asf-projects  hadoop:toys
__label__nflaky abc?def  î€€  test  non  printable  characters  ?ab?  xó°€€yô?¿½zá??  ab"
__label__flaky @  close  trx  coord  client  get  store  get  time  local  oozie  could  not  update  db.  get  status  -test  coord  rerun-  c  get  coord  client  assert  true  get  begin  trx  coordinator  action  re  run  coord  commit  trx  wait  for  bean  coord-rerun-action3.xml  action  num  rest  constants  print  stack  trace  e  store2  test  coord  rerun  cleanup  no  output  events  store  add  record  to  job  table  integer  job  id  services  fail  coordinator  job  add  record  to  action  table  get  coord  action  info  assert  not  same  action  id  0000000-  to  string  action2  evaluate  get  coordinator  action  @  closetrx  coordclient  getstore  gettime  localoozie  could not update db.  getstatus  -testcoordrerun-c  getcoordclient  asserttrue  get  begintrx  coordinatoraction  reruncoord  committrx  waitfor  bean  coord-rerun-action3.xml  actionnum  restconstants  printstacktrace  e  store2  testcoordreruncleanupnooutputevents  store  addrecordtojobtable  integer  jobid  services  fail  coordinatorjob  addrecordtoactiontable  getcoordactioninfo  assertnotsame  actionid  0000000-  tostring  action2  evaluate  getcoordinatoraction
__label__nflaky parse  static  map  gid  10  200  uid  10000  10001#  line  without  whitespace  before  comment  #  comment  at  the  beginning  of  a  line  test  static  map  parsing  parsed  map  gid  4294967295  321  uid  10  100  gid  12  202  get  entirely  empty  line.  uid  13  302  ensure  pass-through  of  unmapped  i  ds  works.  uid  4294967294  123  nfs-  uid  12  301  uid  11  201  #  comment  at  the  end  of  a  line  create  temp  file  assert  equals  temp  static  map  file  static  map  file  contents  #  comment  that  starts  late  in  the  line  tabs  instead  of  spaces.  gid  11  201  .map  shell  based  id  mapping  file  create  static  map  file  parsestaticmap  gid 10 200    uid 10000 10001# line without whitespace before comment        # comment at the beginning of a line    teststaticmapparsing  parsedmap  gid 4294967295 321  uid 10 100    gid 12 202    get   entirely empty line.  uid 13 302     ensure pass-through of unmapped ids works.  uid 4294967294 123    nfs-  uid 12 301    uid 11 201 # comment at the end of a line    createtempfile  assertequals  tempstaticmapfile  staticmapfilecontents      # comment that starts late in the line     tabs instead of spaces.  gid\t11\t201    .map  shellbasedidmapping  file  createstaticmapfile
__label__flaky call  optional=true  required=true&optional=true  my  json  rest  servlet  get  http  servlet  response  required=true  invoke  assert  equals  run  test  test  params  required    call  optional=true  required=true&optional=true  myjsonrestservlet  get  httpservletresponse  required=true  invoke  assertequals  runtest  testparamsrequired
__label__nflaky adapter  test  already  checked  response  assert  equals  this  put  should  be  ignored  by  the  framework.  response  expectations  execute  put  status  assert  framework  run  tests  response  get  new  framework  and  set  adapter  add  test  response  deepcopy  of  test  adapter  test  alreadycheckedresponse  assertequals   this put should be ignored by the framework.  responseexpectations  execute  put  status  assert  framework  runtests  response  get  newframeworkandsetadapter  addtest  response  deepcopyoftest
__label__flaky add  record  to  bundle  job  table  get  id  assert  equals  get  status  execute  call  services  bundle  job  size  assert  not  null  get  job  job  test  bundle  job  info1  jpa  service  bundle  job  getjpa  get  coordinators  addrecordtobundlejobtable  getid  assertequals  getstatus  execute  call  services  bundlejob  size  assertnotnull  get  job  job  testbundlejobinfo1  jpaservice  bundlejobgetjpa  getcoordinators
__label__nflaky a${k67:-x${k0}}c  input  node  transform  node  to  string  transformer  property  container0  default  value  nested  as  var  make  node  assert  equals  axv0c  a${k67:-x${k0}}c  input  node  transform  nodetostringtransformer  propertycontainer0  defaultvaluenestedasvar  makenode  assertequals  axv0c
__label__flaky test  rollback  deactivate  bean4  wf  id2  bean1  assert  not  null  bean2  bean3  new  date  wf  id1  is  start  processed  workflow-2  add  running  expected  exception  but  didnt  get  any  workflow-1  write  cmd  list  update  existing  record  and  insert  another  read  cmd2  execute  fault  injection  read  cmd1  fail  jpaee  true  initial  insert  set  job  id  check  whether  transactions  are  rolled  back  or  not  get  actual  end  expected  exception  due  to  commit  failure  but  didn\'t  get  any  assert  false  event  status  is  start  processed  should  not  be  toggled  to  true  get  error  code  get  _create  sla  summary  bean  update  list  insert  list  _create  sla  calc  bean  assert  equals  skip  commit  fault  injection  actual  end  should  be  null  as  before  set  actual  end  sc  bean  services  assert  null  org.apache.oozie.command.  skip  commit  fault  injection  set  system  property  set  fault  injection  to  true   so  transaction  is  roll  backed  error  code  jpa  service  sd  bean  testrollback  deactivate  bean4  wfid2  bean1  assertnotnull  bean2  bean3  newdate  wfid1  isstartprocessed  workflow-2  add  running  expected exception but didnt get any  workflow-1  writecmd  list   update existing record and insert another  readcmd2  execute  faultinjection  readcmd1  fail  jpaee  true   initial insert  setjobid   check whether transactions are rolled back or not  getactualend  expected exception due to commit failure but didn\'t get any  assertfalse  eventstatus   isstartprocessed should not be toggled to true  geterrorcode  get  _createslasummarybean  updatelist  insertlist  _createslacalcbean  assertequals  skipcommitfaultinjection   actualend should be null as before  setactualend  scbean  services  assertnull  org.apache.oozie.command.skipcommitfaultinjection  setsystemproperty   set fault injection to true  so transaction is roll backed  errorcode  jpaservice  sdbean
__label__nflaky request  conn  resolve  get  request  send  response  header  when  receive  request  header  assert  httpservice  flush  context  create  verify  boolean  close  process  keep  alive  http  status  then  return  argument  matchers  set  code  handle  send  response  entity  test  no  content  response  method  assert  same  get  entity  any  /  never  response  factory  mockito  response  http  core  context  new  http  response  httprocessor  conn  reuse  strategy  handle  request  handler  resolver  request  conn  resolve  getrequest  sendresponseheader  when  receiverequestheader  assert  httpservice  flush  context  create  verify  boolean  close  process  keepalive  httpstatus  thenreturn  argumentmatchers  setcode  handle  sendresponseentity  testnocontentresponse  method  assertsame  getentity  any  /  never  responsefactory  mockito  response  httpcorecontext  newhttpresponse  httprocessor  connreusestrategy  handlerequest  handlerresolver
__label__flaky /a/b/ /c/b/ /c/d/  add  ab  el  constants  functions  /a/b/   /c/b/     /c/d/  append  all  /a/b/  add /c/b/  add /c/d/  add  /a/b/  /a/b/  add /c/b/  add   /c/d/  add  assert  equals     /a/b/  add  test  append  all  ad  da  ad  db  add  /a/b/ /c/b/ /c/d/    add  ab  elconstantsfunctions   /a/b/   /c/b/   /c/d/   appendall  /a/b/add /c/b/add /c/d/add  /a/b/   /a/b/  add /c/b/ add  /c/d/ add  assertequals     /a/b/add  testappendall  addaaddbadd
__label__nflaky servlets  should  have  text/plain  with  proper  encoding  by  default  /echo?a=b.css  conn  test  content  types  open  connection  jetty  utils  assert  equals  /static/test.css  base  url  static  css  files  should  have  text/css  servlets  that  specify  text/html  should  get  that  content  type  css  url  get  response  code  ending  in  .css  should  not  change  mime  type  get  content  type  /echo?a=b  servlet  url  media  type  /htmlcontent  ;  text/css  connect   servlets should have text/plain with proper encoding by default  /echo?a=b.css  conn  testcontenttypes  openconnection  jettyutils  assertequals  /static/test.css  baseurl   static css files should have text/css   servlets that specify text/html should get that content type  cssurl  getresponsecode   ending in .css should not change mime type  getcontenttype  /echo?a=b  servleturl  mediatype  /htmlcontent  ;  text/css  connect
__label__flaky end_  points  is_  security_  enabled  submit  oozie  url  assert  false  test  submit  run  app  path  -submit  get  -config  create  workflow.xml  servlet_  classes  close  run  test  app  create  config  file  get  context  url  mock  dag  engine  service  assert  equals  get  file  system  create  properties  file  job  was  not  created   then  how  did  this  extra  job  come  after  reset?  fail!!  args  call  fail  -oozie  mkdirs  wf  count  reset  to  string  job  get  fs  test  case  dir  end_points  is_security_enabled  submit  oozieurl  assertfalse  testsubmit  run  apppath  -submit  get  -config  create  workflow.xml  servlet_classes  close  runtest  app  createconfigfile  getcontexturl  mockdagengineservice  assertequals  getfilesystem  createpropertiesfile   job was not created  then how did this extra job come after reset? fail!!  args  call  fail  -oozie  mkdirs  wfcount  reset  tostring  job  getfstestcasedir
__label__nflaky test  root  dir  f*  assert  false  run  f1  f2  dir  f3  create  file  subdir  empty  create  empty  file  out  f1  f2  f3  -skip-empty-file  root  -getmerge  two  files  fnf  one  file   kind  of  silly  d  glob  three  files  assert  equals  two  files   preserves  order  -nl  df1  test  merge  df3  df1  df2  df3  df2  exit  f1  df1  df2  df3  f2  file   dir   file  test  copy  merge  shell  directory  with  1  empty  +  3  non  empty  files   should  skip  subdir  read  file  lfs  f1f2  f2f1  exists  f1  f2  to  string  f1  f2  f3  testrootdir  f*  assertfalse  run  f1  f2  dir  f3  createfile   subdir  empty  createemptyfile  out  f1  f2  f3    -skip-empty-file  root  -getmerge   two files  fnf   one file  kind of silly  d   glob three files  assertequals   two files  preserves order  -nl  df1  testmerge  df3  df1  df2  df3    df2  exit  f1  df1  df2  df3  f2     file  dir  file  testcopymerge  shell   directory with 1 empty + 3 non empty files  should skip subdir  readfile  lfs  f1f2  f2f1  exists  f1  f2    tostring    f1  f2  f3
__label__flaky do  an  edit  make  sure  runtime.exit(...)  hasn\'t  been  called  at  all  yet.  cluster  test  single  failed  edits  dir  on  flush  assert  true  assert  exit  invocations  invalidate  one  edits  journal.  assert  false  a  single  journal  failure  should  not  result  in  a  call  to  runtime.exit(...).  is  in  safe  mode  invalidate  edits  dir  at  index  get  name  node  doanedit   make sure runtime.exit(...) hasn\'t been called at all yet.  cluster  testsinglefailededitsdironflush  asserttrue  assertexitinvocations   invalidate one edits journal.  assertfalse   a single journal failure should not result in a call to runtime.exit(...).  isinsafemode  invalidateeditsdiratindex  getnamenode
__label__nflaky key1  metadata  value2  value1  append  if  exists  reader  test  append  root_  path  key  class  reader  value1  conf  fs  delete  two  three  verify  the  meta  data  is  not  changed  verify  all4  values  wrong  compress  option  file  sequence  file  four  get  metadata  option  close  delete  on  exit  get  metadata  set  updated  one  assert  equals  key1  fail  create  writer  expected  illegal  argument  exception  for  compression  options  verify  the  meta  data  readable  after  append  verify  failure  if  the  compression  details  are  different  value  class  writer  testseqappend.seq  compression  verify2  values  compression  type  writer  append  key1  metadata  value2  value1  appendifexists  reader  testappend  root_path  keyclass  reader  value1  conf  fs  delete  two  three   verify the meta data is not changed  verifyall4values  wrongcompressoption  file  sequencefile  four  get  metadataoption  close  deleteonexit  getmetadata  set  updated  one  assertequals  key1  fail  createwriter  expected illegalargumentexception for compression options   verify the meta data readable after append   verify failure if the compression details are different  valueclass  writer  testseqappend.seq  compression  verify2values  compressiontype  writer  append
__label__flaky a  a  get  key  b  el  constants  functions  <x>  xml  utils  </x>  e  map2  &  get  text  parse  xml  to  configuration  str  conf  assert  equals  put  str  entry  get  value  test  to  configuration  str  map  a  a  getkey  b  elconstantsfunctions  <x>  xmlutils  </x>  e  map2  &  gettext  parsexml  toconfigurationstr  conf  assertequals  put  str  entry  getvalue  testtoconfigurationstr  map
__label__nflaky data  fake  failure  to  become  active  from  within  the  stat  callback  fail  to  become  active  mock  no  prior  active  should  re-join  when  zk_  lock_  name  times  assert  assert  true  ids  verify  create  verify  exist  call  stat  mock  app  int  value  then  return  count  process  result  assert  equals  elector  code  mock  zk  do  throw  set  ephemeral  owner  create  mode  mockito  become  active  join  election  test  fail  to  become  active  after  zk  disconnect  get  session  id  data   fake failure to become active from within the stat callback  fail to become active  mocknoprioractive   should re-join  when  zk_lock_name  times  assert  asserttrue  ids  verify  create  verifyexistcall  stat  mockapp  intvalue  thenreturn  count  processresult  assertequals  elector  code  mockzk  dothrow  setephemeralowner  createmode  mockito  becomeactive  joinelection  testfailtobecomeactiveafterzkdisconnect  getsessionid
__label__flaky cluster  conf  run  test  hflush  while  closing  fs  close  it  while  the  flushing  threads  are  still  flushing  create  file  hflush  get  /hflush-and-close.dat  join  flusher  close  write  wait  for  the  flushers  to  all  die.  add  set  flushers  start  else.  thrown  get  file  system  stm  p  contains  t  build  to  string  dfs  output  stream  is  closed  write  some  data  shutdown  ioe  cluster  conf  run  testhflushwhileclosing  fs   close it while the flushing threads are still flushing  createfile  hflush  get  /hflush-and-close.dat  join  flusher  close  write   wait for the flushers to all die.  add  set  flushers  start   else.  thrown  getfilesystem  stm  p  contains  t  build  tostring  dfsoutputstream is closed   write some data  shutdown  ioe
__label__nflaky ${  b}  a  ${  a}  b  ${  c}  c  option  helper  put  property  expected  exception  expect  message  expect  detect  circular  references3  context  circular  variable  reference  detected  while  parsing  input  ${  b}  -->  ${  c}  -->  ${  a}  -->  ${  b}  ${  b}  subst  vars  ${b}  a  ${a}  b  ${c}  c  optionhelper  putproperty  expectedexception  expectmessage  expect  detectcircularreferences3  context  circular variable reference detected while parsing input ${b} --> ${c} --> ${a} --> ${b}  ${b}   substvars
__label__flaky request  test  most  popular  assert  equals  target  accept  list_  id_  count_  type  get  value  assert  top  size  assert  true  get  media  type  /most  popular  items  this  count  request  testmostpopular  assertequals  target  accept  list_id_count_type  getvalue  assert  top  size  asserttrue  get  mediatype  /mostpopularitems  thiscount
__label__nflaky content  type  get  mime  type  for  name  standard  charsets  utf-8  charset  assert  equals  get  charset  us-  ascii  assert  with  charset  test  with  charset  name  create  to  string  text/plain;  charset=  utf-8  text/plain;  charset=  us-  ascii  content  type  text/plain  contenttype  getmimetype  forname  standardcharsets  utf-8  charset  assertequals  getcharset  us-ascii  assert  withcharset  testwithcharset  name  create  tostring  text/plain; charset=utf-8  text/plain; charset=us-ascii  contenttype  text/plain
__label__flaky date  script  executor  post  update_pre  update_value  session  given  update  simple  select  *  from  simple  where  id  =  crud  when  of  get  id  row  value  table  execute  script  template  all  random  utils  manager  should_trigger_for_update  get  string  next  long  assert  that  rows  execute  simple  entity/insert_single_row.cql  immutable  map  get  value  has  size  then  long  build  date  key  pre  update_value  is  equal  to  entity  date  scriptexecutor  postupdate_preupdate_value  session   given  update  simple  select * from simple where id =   crud   when  of  get  id  row  value  table  executescripttemplate  all  randomutils  manager  should_trigger_for_update  getstring  nextlong  assertthat  rows  execute  simpleentity/insert_single_row.cql  immutablemap  getvalue  hassize   then  long  builddatekey  preupdate_value  isequalto  entity
__label__nflaky encode  verify  gs1  encoded  data  test  encode  gs1  with  string  type  hint  100001\%11171218  encode  hint  type  qr  code  hints  encoder  true  error  correction  level  put  encode  verifygs1encodeddata  testencodegs1withstringtypehint  100001\%11171218  encodehinttype  qrcode  hints  encoder  true  errorcorrectionlevel  put
__label__flaky reflection  test  utils  -static/**  assert  false  included  deltas  get  field  unchecked  includes  static/**  as  list  contains  resource  matcher  assert  true  templates/**  arrays    reflectiontestutils  -static/**  assertfalse  includeddeltas  getfield  unchecked  includes  static/**  aslist  contains  resourcematcher  asserttrue  templates/**  arrays
__label__nflaky src  codec  test  utils  standard  charsets  channel  assert  equals  test  chunk  exceed  encoder  remaining  4  0123  4  4567  4  89  ab  4  cdef  assert  flush  outbuf  metrics  dump  wrap  write  0123456789  abcdef  src  codectestutils  standardcharsets  channel  assertequals  testchunkexceed  encoder  remaining  4  0123  4  4567  4  89ab  4  cdef    assert  flush  outbuf  metrics  dump  wrap  write  0123456789abcdef
__label__flaky cluster  shutdown  dfs  e  log  failed  get  log  do  a  true  concurrent  background  thread  flush  count  h  constants  assert  equals  error  added:  add  content  test  scan  and  real  concurrent  flush  close  and  delete  create  new  h  region  bytes  r  get  table  desc  region_  info  to  string  close  hri  info  cluster  shutdowndfs  e  log  failed  getlog   do a true concurrent background thread flush  count  hconstants  assertequals  error  added:   addcontent  testscanandrealconcurrentflush  closeanddelete  createnewhregion  bytes  r  gettabledesc  region_info  tostring  close  hri  info
__label__nflaky request  my  name  post  message  should  contain  http  client  name  of  put  get  client  pojo  adapter  make  sure  the  http  client  name  is  in  the  message.  assert  request  handler  http  client  name  assert  true  run  tests  get  default  uri  add  test  get  client  name  web  server  testing  framework  exception  should  have  been  thrown  testing  framework  exception  adapter  test  e  change  the  request  from  what  is  expected.  pojo  adapter  get  message  message  response  expectations  execute  name  fail  contains  framework  ;  message=  request  get  equals  new  framework  and  set  adapter  method  message  should  contain  the  test.  message=  request  method  unexpected  request  myname  post  message should contain httpclientname of   put  getclientpojoadapter   make sure the http client name is in the message.  assert  requesthandler  httpclientname  asserttrue  runtests  get  defaulturi  addtest  getclientname  webservertestingframeworkexception should have been thrown  testingframeworkexception  adapter  test  e   change the request from what is expected.  pojoadapter  getmessage  message  responseexpectations  execute  name  fail  contains  framework  ; message=  request  get  equals  newframeworkandsetadapter  method  message should contain the test. message=  requestmethodunexpected
__label__flaky -timezone  end_  points  rest  constants  is_  security_  enabled  get  context  url  oozie  url  test  job  status  mock  dag  engine  service  run  assert  equals  -localtime  -info  0  args  pst  call  1  2  -oozie  size  reset  job  servlet_  classes  run  test  -timezone  end_points  restconstants  is_security_enabled  getcontexturl  oozieurl  testjobstatus  mockdagengineservice  run  assertequals  -localtime  -info  0  args  pst  call  1  2  -oozie  size  reset  job  servlet_classes  runtest
__label__nflaky get  all  secrets  test  one  seed  simplest  case  system  timeout  assert  array  equals  at  least  once  rand  assert  use  the  same  seed  and  a  \""plain\""  random  so  we  can  predict  the  rng  current  secret  secret  provider  verify  get  dummy  servlet  context  /secret  init  zk  signer  secret  provider  get  connect  string  zk  server  rollover  frequency  get  current  secret  destroy  assert  equals  secret2  secret3  roll  secret  secret1  assert  null  current  time  millis  set  property  real  roll  secret  all  secrets  at  least  generate  new  secret  spy  config  getallsecrets  testone  seed   simplest case  system  timeout  assertarrayequals  atleastonce  rand  assert   use the same seed and a \""plain\"" random so we can predict the rng  currentsecret  secretprovider  verify  getdummyservletcontext  /secret  init  zksignersecretprovider  getconnectstring  zkserver  rolloverfrequency  getcurrentsecret  destroy  assertequals  secret2  secret3  rollsecret  secret1  assertnull  currenttimemillis  setproperty  realrollsecret  allsecrets  atleast  generatenewsecret  spy  config
__label__flaky <execution>  lifo</execution>  </controls>  <datasets>  add  record  to  bundle  action  table  check  coord  jobs  conf  get  id  </input-events>  app  path  substring  coord  job  sc  </property></configuration>  </workflow>  </action>  </coordinator-app>  write  to  file  app  xml  <property>  <name>input  b</name>  <value>${coord:data  out(\'  local_  a\')}</value>  file://  get  test  case  dir  unit_  testing  <output-events>  <data-out  name=\""  local_  a\""  dataset=\""local_a\"">  job  get  bundle  id  timezone=\""  utc\"">  <uri-template>file:///tmp/coord/workflows/${  year}/${  day}</uri-template>  </dataset>  coordinator.xml  get  app  name  set  <configuration>  <property>  <name>input  a</name>  <value>${coord:data  in(\'  a\')}</value>  </property>  uri:oozie:coordinator:0.2  add  record  to  bundle  job  table  length  <dataset  name=\""local_a\""  frequency=\""${coord:days(7)}\""  initial-instance=\""2009-02-01  t01:00  z\""  assert  equals  xmlns=\""uri:oozie:coordinator:0.2\"">  <controls>  <concurrency>2</concurrency>  call  <coordinator-app  name=\""  name\""  frequency=\""${coord:days(1)}\""  start=\""2009-02-01  t01:00  z\""  end=\""2009-02-03  t23:59  z\""  timezone=\""  utc\""  oozie  client  job  id  fail  get  test  user  </datasets>  <input-events>  <instance>${coord:current(-1)}</instance>  </data-out>  </output-events>  <action>  <workflow>  <app-path>hdfs:///tmp/workflows/</app-path>  -  c  get  app  namespace  <data-in  name=\""  a\""  dataset=\""a\"">  <instance>${coord:latest(0)}</instance>  </data-in>  coord-  name  <dataset  name=\""a\""  frequency=\""${coord:days(7)}\""  initial-instance=\""2009-02-01  t01:00  z\""  job  file  test  basic  submit  with  bundle  id  <execution>lifo</execution> </controls> <datasets>   addrecordtobundleactiontable  checkcoordjobs  conf  getid  </input-events>   apppath  substring  coordjob  sc  </property></configuration> </workflow> </action> </coordinator-app>  writetofile  appxml  <property> <name>inputb</name> <value>${coord:dataout(\'local_a\')}</value>   file://  gettestcasedir  unit_testing  <output-events> <data-out name=\""local_a\"" dataset=\""local_a\"">   job  getbundleid  timezone=\""utc\""> <uri-template>file:///tmp/coord/workflows/${year}/${day}</uri-template> </dataset>   coordinator.xml  getappname  set  <configuration> <property> <name>inputa</name> <value>${coord:datain(\'a\')}</value> </property>   uri:oozie:coordinator:0.2  addrecordtobundlejobtable  length  <dataset name=\""local_a\"" frequency=\""${coord:days(7)}\"" initial-instance=\""2009-02-01t01:00z\""   assertequals  xmlns=\""uri:oozie:coordinator:0.2\""> <controls> <concurrency>2</concurrency>   call  <coordinator-app name=\""name\"" frequency=\""${coord:days(1)}\"" start=\""2009-02-01t01:00z\"" end=\""2009-02-03t23:59z\"" timezone=\""utc\""   oozieclient  jobid  fail  gettestuser  </datasets> <input-events>   <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>   -c  getappnamespace  <data-in name=\""a\"" dataset=\""a\""> <instance>${coord:latest(0)}</instance> </data-in>    coord-name  <dataset name=\""a\"" frequency=\""${coord:days(7)}\"" initial-instance=\""2009-02-01t01:00z\""   job  file  testbasicsubmitwithbundleid
__label__nflaky request  http  headers  process  get  first  header  standard  charsets  interceptor  method  set  protocol  version  get  entity  whatever  /  set  entity  test  request  expect  continue  http10  assert  assert  null  http  core  context  context  create  header  http  version  request  httpheaders  process  getfirstheader  standardcharsets  interceptor  method  setprotocolversion  getentity  whatever  /  setentity  testrequestexpectcontinuehttp10  assert  assertnull  httpcorecontext  context  create  header  httpversion
__label__flaky play  user-  agent  baz=baz  put  set  request  property  connection  collections  write  cookie  contains  key  foo  set  default  get  input  stream  /  get  request  properties  get  url  content-type  contains  request  headers  cookie  handler  set  do  output  assert  contains  all  quux  server  request  foo  assert  false  cookie  handler  headers  result  put  all  cookie2  get  empty  map  client  content-  length  close  key  set  quux:  quux  test  headers  sent  to  cookie  handler  get  headers  take  request  cookie:  bar=bar  singleton  list  connection  assert  equals  host  foo:  foo  bar=bar  *  the  api  specifies  that  calling  get  request  properties()  on  a  connected  instance  should  fail  *  with  an  illegal  state  exception   but  the  ri  violates  the  spec  and  returns  a  valid  map.  *  http://www.mail-archive.com/net-dev@openjdk.java.net/msg01768.html  cookie2:  baz=baz  enqueue  quux  get  output  stream  open  play  user-agent  baz=baz  put  setrequestproperty  connection  collections  write  cookie  containskey  foo  setdefault  getinputstream  /  getrequestproperties  geturl  content-type  contains  requestheaders  cookiehandler  setdooutput  assertcontainsall  quux  server  request  foo  assertfalse  cookiehandlerheaders  result  putall  cookie2  get  emptymap  client  content-length  close  keyset  quux: quux  testheaderssenttocookiehandler  getheaders  takerequest  cookie: bar=bar  singletonlist  connection  assertequals  host  foo: foo  bar=bar         * the api specifies that calling getrequestproperties() on a connected instance should fail       * with an illegalstateexception  but the ri violates the spec and returns a valid map.       * http://www.mail-archive.com/net-dev@openjdk.java.net/msg01768.html         cookie2: baz=baz  enqueue  quux  getoutputstream  open
__label__nflaky fail  assert  illegal  argument  exception  must  have  been  thrown  (600)  illegal  argument  exception  must  have  been  thrown  (-1)  english  reason  phrase  catalog  get  reason  test  status  invalid  illegal  argument  exception  must  have  been  thrown  (99)  fail  assert  illegalargumentexception must have been thrown (600)  illegalargumentexception must have been thrown (-1)  englishreasonphrasecatalog  getreason  teststatusinvalid  illegalargumentexception must have been thrown (99)
__label__flaky ${  pb}  ${first  not  null(null   \'b\')}  workflow  ${trim(\'  \')}  ${  mb}  ${concat(\'a\'   \'b\')}  ${  tb}  create  evaluator  services  eval  ${timestamp()}  assert  not  null  ${url  encode(\'abc\')}  get  ${  kb}  test  el  for  workflow  evaluate  ${  gb}  ${pb}  ${firstnotnull(null  \'b\')}  workflow  ${trim(\' \')}  ${mb}  ${concat(\'a\'  \'b\')}  ${tb}  createevaluator  services  eval  ${timestamp()}  assertnotnull  ${urlencode(\'abc\')}  get  ${kb}  testelforworkflow  evaluate  ${gb}
__label__nflaky request  process  context  interceptor  method  test  request  http11  host  header  absent  get  entity  /  request  process  context  interceptor  method  testrequesthttp11hostheaderabsent  getentity  /
__label__flaky add  record  to  wf  action  table  get  id  workflow  instance  add  record  to  coord  action  table  coord  job  wf  job1  wf  job3  coord  action3  add  record  to  wf  job  table  wf  job2  coord  action4  children  assert  not  null  wf  job5  coord  action5  get  wf  job4  coordinator  action  get  the  next  3  (though  there\'s  only  2  more)  coord  action1  coord  action2  workflow  job  get  the  first  3  assert  equals  wf  action1  wf  action2  execute  add  record  to  coord  job  table  wf  action3  wf  action4  wf  action5  check  children  services  coordinator  job  1  2  coord-action-get.xml  size  workflow  action  add  all  succeeded  test  get  workflow  parent  too  many  jpa  service  addrecordtowfactiontable  getid  workflowinstance  addrecordtocoordactiontable  coordjob  wfjob1  wfjob3  coordaction3  addrecordtowfjobtable  wfjob2  coordaction4  children  assertnotnull  wfjob5  coordaction5  get  wfjob4  coordinatoraction   get the next 3 (though there\'s only 2 more)  coordaction1  coordaction2  workflowjob   get the first 3  assertequals  wfaction1  wfaction2  execute  addrecordtocoordjobtable  wfaction3  wfaction4  wfaction5  checkchildren  services  coordinatorjob  1  2  coord-action-get.xml  size  workflowaction  addall  succeeded  testgetworkflowparenttoomany  jpaservice
__label__nflaky line  one  assert  false  in  channel  out  stream  assert  flush  inbuf  assert  true  write  line  four  clear  assert  equals  fill  read  line  two  three  us-  ascii  outbuf  one  two  three  four  to  byte  array  test  write  line  chunks  to  string  one  two  three  new  channel  four  out  channel  line  one  assertfalse  inchannel  outstream  assert  flush  inbuf  asserttrue  writeline  four  clear  assertequals  fill  readline  two  three  us-ascii  outbuf  one  two  three  four    tobytearray  testwritelinechunks  tostring  one  two  three  newchannel    four  outchannel
__label__flaky cluster  test  change  ipc  port  got  heartbeat  conf  wait  until  we  get  a  heartbeat  from  the  new  datanode  restart  datanodes  first  update  after  restart  sleep  restart  data  nodes  get  client  addr  localhost  real  ipc  port  get  data  nodes  datanode  report  never  got  a  heartbeat  from  restarted  datanode.  assert  equals  thread  fail  get  ipc  port  build  now  make  sure  the  reported  ipc  port  is  the  correct  one.  report  get  name  node  port  get  last  update  shutdown  datanode  report  type  cluster  testchangeipcport  gotheartbeat  conf   wait until we get a heartbeat from the new datanode   restart datanodes  firstupdateafterrestart  sleep  restartdatanodes  get  client  addr  localhost  realipcport  getdatanodes  datanodereport  never got a heartbeat from restarted datanode.  assertequals  thread  fail  getipcport  build   now make sure the reported ipc port is the correct one.  report  getnamenodeport  getlastupdate  shutdown  datanodereporttype
__label__nflaky service  principal  handler  get  oid  instance  get  name  base64  get  server  name  create  context  when  request  cred  deleg  set  header  assert  get  user  name  localhost  in  token  do  as  client  then  return  gss_  krb5_  mech_  oid  eq  matches  get  type  gss  context  mock  dispose  create  name  request  authenticate  nt_  gss_  krb5_  principal  auth  token  gss  context  oid  get  header  get  expected  type  gss  manager  kerberos  authenticator  assert  true  gss  manager  verify  init  sec  context  .*  test  request  with  authorization  encode  to  string  http  servlet  response  out  token  assert  equals  kerberos  test  utils  service  name  kerberos  util  set  status  token  call  get  client  principal  request  mutual  auth  mockito  response  get  server  principal  get  instance  starts  with  serviceprincipal  handler  getoidinstance  getname  base64  getservername  createcontext  when  requestcreddeleg  setheader  assert  getusername     localhost  intoken  doasclient  thenreturn  gss_krb5_mech_oid  eq  matches  gettype  gsscontext  mock  dispose  createname  request  authenticate  nt_gss_krb5_principal  authtoken  gsscontext  oid  getheader  getexpectedtype  gssmanager  kerberosauthenticator  asserttrue  gssmanager  verify  initseccontext   .*  testrequestwithauthorization  encodetostring  httpservletresponse  outtoken  assertequals  kerberostestutils  servicename  kerberosutil  setstatus  token  call  getclientprincipal  requestmutualauth  mockito  response  getserverprincipal  getinstance  startswith
__label__flaky 10 11  conf  mockfs://mock/tmp/something.zip#something  local  resources  uri  when  get  raw  file  system  setup  distributed  cache  true true  resolve  path  fs.mockfs.impl  file  mock  uri  distributed  cache  file  system  get  mockfs://mock/  create  set  then  return  set  class  file  path  deprecation  mr  apps  mockfs://mock/tmp/something.txt#something  file2  file2  path  mr  job  config  mock  fs  test  setup  distributed  cache  conflicts  files  add  cache  file  10 11  conf  mockfs://mock/tmp/something.zip#something  localresources  uri  when  getrawfilesystem  setupdistributedcache  true true  resolvepath  fs.mockfs.impl  file  mockuri  distributedcache  filesystem  get  mockfs://mock/  create  set  thenreturn  setclass  filepath  deprecation  mrapps  mockfs://mock/tmp/something.txt#something  file2  file2path  mrjobconfig  mockfs  testsetupdistributedcacheconflictsfiles  addcachefile
__label__nflaky next  reader  assert  false  conf  test  array  file  iteration  fs  seek  test  array  file  writer  construction  error  !!!  assert  true  assert  not  null  file  system  get  close  key  test  array  file  iteration  seek  error  !!!  size  test  array  file  iteration  error  !!!  assert  that  fail  with  fail  message  test_  file  default  progressable  writer  next  writable  compression  type  is  equal  to  append  next  reader  assertfalse  conf  testarrayfileiteration  fs  seek  testarrayfilewriterconstruction error !!!  asserttrue  assertnotnull  filesystem  get  close  key  testarrayfileiteration seek error !!!  size  testarrayfileiteration error !!!  assertthat  fail  withfailmessage  test_file  defaultprogressable  writer  nextwritable  compressiontype  isequalto  append
__label__flaky unexpected  exception  def  add  node  print  stack  trace  test  decisions  to  join  fork  join  e  f  one  j  k  kill  three  two  as  list  f->(2 3)  2->decision  node->{4 j 4}  3->decision  node->{j 5 j}  4->j  5->j  fail  invoke  fork  join  parser  four  name  dummy  conf  end  arrays  five  unexpected exception  def  addnode  printstacktrace  testdecisionstojoinforkjoin  e  f  one  j  k  kill  three  two  aslist        f->(2 3)      2->decision node->{4 j 4}      3->decision node->{j 5 j}      4->j      5->j        fail  invokeforkjoin  parser  four  name  dummyconf  end  arrays  five
__label__nflaky lookup  test  completed  assert  build  reg  create  registry  builder  assert  equals  stuff  register  stuff  miss  lookup  testcompleted  assert  build  reg  create  registrybuilder  assertequals  stuff  register  stuff  miss
__label__flaky init  coord  el  functions  .datain.  abc.unresolved  set  variable  assert  equals  coord-action-start  ${coord:data  in(\'  abc\')}  file:///tmp/coord/  us/2009/1/30 file:///tmp/coord/  us/2009/1/31  eval  eval  and  wrap  test  data  in  .datain.  abc  expr  boolean  init  coordelfunctions  .datain.abc.unresolved  setvariable  assertequals  coord-action-start  ${coord:datain(\'abc\')}  file:///tmp/coord/us/2009/1/30 file:///tmp/coord/us/2009/1/31  eval  evalandwrap  testdatain  .datain.abc  expr  boolean
__label__nflaky next  instances  from  the  code  pool  as  reader1  reader  create  a  reader  which  uses  4  built  in  z  lib  inflater  instances  get  temp  path  assert  false  conf  fs  read  second  value  from  reader2  (this  throws  an  exception)  test1.seq  file1-1  file2-2  returns  the  4  built  in  z  lib  inflater  instances  to  the  codec  pool  file1-2  file2-1  sequence  file  read  first  value  from  reader2  file  system  get  read  first  value  from  reader1  create  a  sequence  file  1  text  test  close  close  test2.seq  read  second  value  from  reader1  generic  test  utils  assert  equals  reader2  reader1  deprecation  null  writable  create  writer  path1  path2  get  local  4  built  in  z  lib  inflater  instances  to  the  codec  pool  again  to  string  writer  compression  type  append  the  first  reader  gets  4  built  in  z  lib  inflater  instances  from  the  codec  pool  next   instances from the codepool as reader1  reader   create a reader which uses 4 builtinzlibinflater instances  gettemppath  assertfalse  conf  fs   read second value from reader2 (this throws an exception)  test1.seq  file1-1  file2-2   returns the 4 builtinzlibinflater instances to the codecpool  file1-2  file2-1  sequencefile   read first value from reader2  filesystem  get   read first value from reader1   create a sequence file 1  text  testclose  close  test2.seq   read second value from reader1  generictestutils  assertequals  reader2  reader1  deprecation  nullwritable  createwriter  path1  path2  getlocal   4 builtinzlibinflater instances to the codecpool again  tostring  writer  compressiontype  append   the first reader gets 4 builtinzlibinflater instances from the codecpool
__label__flaky _test  is  main  successful  action  dir  has  output  data  assert  false  running  job  is  main  done  get  file  system  fs  has  id  swap  get  id  swap  path  is  successful  assert  true  launcher  mapper  get  error  path  exists  get  output  data  path  id  test  new  id  evaluate  wait  for  get  fs  test  case  dir  is  complete  _test  ismainsuccessful  actiondir  hasoutputdata  assertfalse  runningjob  ismaindone  getfilesystem  fs  hasidswap  getidswappath  issuccessful  asserttrue  launchermapper  geterrorpath  exists  getoutputdatapath  id  testnewid  evaluate  waitfor  getfstestcasedir  iscomplete
__label__nflaky curl  verify  zero  interactions  object  under  test  expected_  message  send  error  when  filter  config  get  header  at  least  once  mock  chain  do  filter  verify  mock  res  init  mock  req  then  return  csrf  has  not  been  sent  objects  to  verify  interactions  based  on  request  http  servlet  response  ^  mozilla.* ^  opera.* curl  setup  the  configuration  settings  of  the  server  filter  get  init  parameter  mockito  mock  test  no  header  custom  agent  config  bad  request  rest  csrf  prevention  filter  curl  verifyzerointeractions   object under test  expected_message  senderror  when  filterconfig  getheader  atleastonce  mockchain  dofilter  verify  mockres  init  mockreq  thenreturn   csrf has not been sent   objects to verify interactions based on request  httpservletresponse  ^mozilla.* ^opera.* curl   setup the configuration settings of the server  filter  getinitparameter  mockito  mock  testnoheadercustomagentconfigbadrequest  restcsrfpreventionfilter
__label__flaky @  close  trx  coord  client  get  store  get  time  local  oozie  could  not  update  db.  -test  coord  rerun-  c  get  coord  client  rerun  scope  get  begin  trx  1-3  coordinator  action  re  run  coord  action  num2  commit  trx  action  num1  coord-rerun-action2.xml  rest  constants  print  stack  trace  e  test  coord  rerun  actions  neg1  store  action  id2  add  record  to  job  table  job  id  action  id1  services  fail  coordinator  job  add  record  to  action  table  0000000-  exception  expected  because  one  action  is  missing  from  db.  coord-rerun-action1.xml  @  closetrx  coordclient  getstore  gettime  localoozie  could not update db.  -testcoordrerun-c  getcoordclient  rerunscope  get  begintrx  1-3  coordinatoraction  reruncoord  actionnum2  committrx  actionnum1  coord-rerun-action2.xml  restconstants  printstacktrace  e  testcoordrerunactionsneg1  store  actionid2  addrecordtojobtable  jobid  actionid1  services  fail  coordinatorjob  addrecordtoactiontable  0000000-  exception expected because one action is missing from db.  coord-rerun-action1.xml
__label__nflaky get  bytes  transferred  codec  test  utils  test  coding  fragment  buffering  channel  times  assert  flush  verify  write  line  dump  chbuffer  write  argument  matchers  standard  charsets  assert  equals  encoder  any  never  header  stuff  mockito  outbuf  header  metrics  spy  wrap  append  stuff  getbytestransferred  codectestutils  testcodingfragmentbuffering  channel  times  assert  flush  verify  writeline  dump  chbuffer  write  argumentmatchers  standardcharsets  assertequals  encoder  any  never  header  stuff  mockito  outbuf  header  metrics  spy  wrap  append  stuff
__label__flaky simple  log  log  prefix  assert  false  reset  message  is  warn  enabled  error  get  cause  set  level  fatal  trace  assert  true  set  msg  prefix  is  info  enabled  assert  not  null  is  error  enabled  is  trace  enabled  x  log  debug  debug  info  a  b  debug  x  log  get  message  assert  equals  debug  {0}  is  fatal  enabled  get  msg  prefix  warn  ops  assert  null  test  x  log  functionality  ends  with  is  debug  enabled    simplelog  log  prefix  assertfalse  resetmessage  iswarnenabled  error  getcause  setlevel  fatal  trace  asserttrue  setmsgprefix  isinfoenabled  assertnotnull  iserrorenabled  istraceenabled  xlog  debug debug  info  a  b  debug  xlog  getmessage  assertequals  debug {0}  isfatalenabled  getmsgprefix  warn  ops  assertnull  testxlogfunctionality  endswith  isdebugenabled
__label__nflaky get  distance  cluster  data  nodes  test  get  distance  assert  equals  getdistance  cluster  datanodes  testgetdistance  assertequals
__label__flaky delete  list  add  record  to  bundle  action  table  get  id  action  c1  action  c2  action  a1  action  a2  deactivate  bundle  action  a1  should  not  have  been  deleted  bundle  job  a  should  not  have  been  deleted  bundle  action  a2  should  not  have  been  deleted  bundle  action  c1  should  not  have  been  deleted  job  b  job  a  assert  not  null  remove  fault  injection  job  c  get  test  delete  bundles  rollback  job  get  bundle  id  bundle  job  b  should  not  have  been  deleted  add  should  have  skipped  commit  for  failover  testing  get  coord  name  skipping  commit  for  failover  testing  add  record  to  bundle  job  table  bundle  job  c  should  not  have  been  deleted  get  message  assert  equals  skip  commit  fault  injection  action  b1  execute  action  b2  fault  injection  bundle  action  c2  should  not  have  been  deleted  services  fail  re  org.apache.oozie.command.  skip  commit  fault  injection  set  system  property  true  bundle  action  b1  should  not  have  been  deleted  bundle  action  b2  should  not  have  been  deleted  set  fault  injection  to  true   so  transaction  is  roll  backed  jpa  service  deletelist  addrecordtobundleactiontable  getid  actionc1  actionc2  actiona1  actiona2  deactivate  bundle action a1 should not have been deleted  bundle job a should not have been deleted  bundle action a2 should not have been deleted  bundle action c1 should not have been deleted  jobb  joba  assertnotnull   remove fault injection  jobc  get  testdeletebundlesrollback  job  getbundleid  bundle job b should not have been deleted  add  should have skipped commit for failover testing  getcoordname  skipping commit for failover testing  addrecordtobundlejobtable  bundle job c should not have been deleted  getmessage  assertequals  skipcommitfaultinjection  actionb1  execute  actionb2  faultinjection  bundle action c2 should not have been deleted  services  fail  re  org.apache.oozie.command.skipcommitfaultinjection  setsystemproperty  true  bundle action b1 should not have been deleted  bundle action b2 should not have been deleted   set fault injection to true  so transaction is roll backed  jpaservice
__label__nflaky create  file  jarsdir  test  construct  urls  from  classpath  construct  urls  from  classpath  create  non-jar  file  dir  don\'t  create  nofile  urls  file  assert  true  make  dir  /*  mkdir  non  jar  file  to  url  jars  dir  a.jar  get  absolute  path  make  jars  dir  to  uri  nonjar  assert  equals  create  jar  file  test  dir  cp  jar  file  to  string  create  new  file  nofile  file  append  create file  jarsdir  testconstructurlsfromclasspath  constructurlsfromclasspath  create non-jar file  dir   don\'t create nofile  urls  file  asserttrue  make dir  /*  mkdir  nonjarfile  tourl  jarsdir  a.jar  getabsolutepath  make jarsdir  touri  nonjar  assertequals  create jar file  testdir  cp  jarfile  tostring  createnewfile  nofile  file  append
__label__flaky get  conf  string  <uri-template>file:///  conf  date  utils  parse  date  oozie  tz  2009-09-05  t00:00  z  2009-09-01  t00:00  z  ${coord:latest(0)}  ${coord:latest(-1)}  ${coord:future(1   30)}  actual  time  todo:  create  the  directory  <dataset  name=\""a\""  frequency=\""1440\""  initial-instance=\""2009-01-01  t00:00  z\""  freq_timeunit=\""  minute\""  timezone=\""  utc\""  end_of_duration=\""  none\"">  test  create  lazy  evaluator  get  test  case  dir  create  dir  expr  coord  el  evaluator  future  test  case  dir  nominal  time  create  lazy  evaluator  /  us/2009/1/30|file:///tmp/coord/  us/2009/1/31</uris>  /2009/01/02  xml  utils  2009-01-02  t00:00  z  ${coord:latest(-1)}  parse  xml  /${  year}/${  month}/${  day}</uri-template></dataset></data-in>  /2009/09/04  assert  equals  /2009/09/05  eval  <data-in  name=\""  a\""  dataset=\""a\""><uris>file:///  -1));  data  evnt  xml  evaluate  2009-09-01  t01:00  z  d  event  getconfstring  <uri-template>file:///  conf  dateutils  parsedateoozietz  2009-09-05t00:00z  2009-09-01t00:00z  ${coord:latest(0)} ${coord:latest(-1)}  ${coord:future(1  30)}  actualtime   todo: create the directory  <dataset name=\""a\"" frequency=\""1440\"" initial-instance=\""2009-01-01t00:00z\""  freq_timeunit=\""minute\"" timezone=\""utc\"" end_of_duration=\""none\"">  testcreatelazyevaluator  gettestcasedir  createdir  expr  coordelevaluator   future  testcasedir  nominaltime  createlazyevaluator  /us/2009/1/30|file:///tmp/coord/us/2009/1/31</uris>  /2009/01/02  xmlutils  2009-01-02t00:00z ${coord:latest(-1)}  parsexml  /${year}/${month}/${day}</uri-template></dataset></data-in>  /2009/09/04  assertequals  /2009/09/05  eval  <data-in name=\""a\"" dataset=\""a\""><uris>file:///   -1));  dataevntxml  evaluate  2009-09-01t01:00z  devent
__label__nflaky bindpass  credential  provider  factory  get  credential  conf  our  url  delete  create  credential  entry  assert  array  equals  file  make  sure  we  get  back  the  right  key  assert  storepass  flush  provider  get  create  new  aliases  java  key  store  provider  get  credential  entry  ensure  that  we  get  nulls  when  the  key  isn\'t  there  test.jks  mapping  set  extract  password  print  stack  trace  e  get  test  dir  get  providers  to  uri  generic  test  utils  assert  equals  test  dir  ldap  groups  mapping  jks  path  get  password  assert  null  invalid-alias  ://file  test  conf  get  password  to  string  get  base  conf    bindpass  credentialproviderfactory  getcredential  conf  oururl  delete  createcredentialentry  assertarrayequals  file   make sure we get back the right key  assert  storepass  flush  provider  get   create new aliases  javakeystoreprovider  getcredentialentry   ensure that we get nulls when the key isn\'t there  test.jks  mapping  set   extract password  printstacktrace  e  gettestdir  getproviders  touri  generictestutils  assertequals  testdir  ldapgroupsmapping  jkspath  getpassword  assertnull  invalid-alias  ://file  testconfgetpassword  tostring  getbaseconf
__label__flaky kills  add  node  def  enters  workflow  instance  get  status  as  list  wf  exits  end  signal  fails  test  done  with  running  nodes  a  b  f  start  j  assert  equals  1  size  <worklfow-app/>  arrays  job  /b/    kills  addnode  def  enters  workflowinstance  getstatus  aslist  wf  exits  end  signal  fails  testdonewithrunningnodes  a  b  f  start  j  assertequals  1  size  <worklfow-app/>  arrays  job  /b/
__label__nflaky get  bytes  transferred  test  coding  fragment  buffering  tiny  fragments2  codec  test  utils  channel  times  assert  flush  verify  more  stuff  dump  stuff---more  stuff  write  argument  matchers  standard  charsets  assert  equals  encoder  -  any  mockito  outbuf  metrics  spy  wrap  stuff  getbytestransferred  testcodingfragmentbufferingtinyfragments2  codectestutils  channel  times  assert  flush  verify  more stuff  dump  stuff---more stuff  write  argumentmatchers  standardcharsets  assertequals  encoder  -  any  mockito  outbuf  metrics  spy  wrap  stuff
__label__flaky conn  set  request  method  is_  security_  enabled  get  id  put  bundle  job  bean  /v1/job/*  id  job  run  test  mock  coordinator  engine  service  rest  constants  open  connection  add  record  to  bundle  job  table  http  servlet  response  assert  equals  params  url  call  x  data  test  case  get  get  response  code  reset  create  url  test  bundle  engine  stream  log  conn  setrequestmethod  is_security_enabled  getid  put  bundlejobbean  /v1/job/*  id  job  runtest  mockcoordinatorengineservice  restconstants  openconnection  addrecordtobundlejobtable  httpservletresponse  assertequals  params  url  call  xdatatestcase  get  getresponsecode  reset  createurl  testbundleenginestreamlog
__label__nflaky value5  file  resource1  value2  value1  value4  value3  conf  config2  append  property  out  config  add  resource  get  change  values  in  the  test  file...  test.key3  set  test.key4  end  config  add  a  few  values  via  set.  start  config  assert  equals  reload  configuration  final-value3  overlayed  property  overrides.  final-value1  test  reload  test.key1  file  resource  test.key2  value5  fileresource1  value2  value1  value4  value3  conf  config2  appendproperty  out  config  addresource  get   change values in the test file...  test.key3  set  test.key4  endconfig   add a few values via set.  startconfig  assertequals  reloadconfiguration  final-value3   overlayed property overrides.  final-value1  testreload  test.key1  fileresource  test.key2
__label__flaky app  xf1  xf2  test  log  group  construct  pattern  14-200904160239--example-forkjoinwf  workflow  runner  callable:323  -  get  define  parameter  set  parameter  job  token  test  x  log  fileter  add  init  a  x  log  set  log  level  oozie  create  prefix  destroy  x  log  streamer  example-forkjoinwf  assert  equals  services  user  matches  xf  2009-06-24  02:43:13 958  debug  action  m  ytoken  reset  to  string  |  app  xf1  xf2   test log  group  constructpattern  14-200904160239--example-forkjoinwf   workflowrunnercallable:323 -   get  defineparameter  setparameter  job  token  testxlogfileter  add  init  a  xlog  setloglevel  oozie  createprefix  destroy  xlogstreamer  example-forkjoinwf  assertequals  services  user  matches  xf  2009-06-24 02:43:13 958 debug  action  mytoken  reset  tostring  |
__label__nflaky integer  fail  assert  test  invalid  append  char  array  as  ascii  tmp  buffer  index  out  of  bounds  exception  should  have  been  thrown  append  integer  fail  assert  testinvalidappendchararrayasascii  tmp  buffer  indexoutofboundsexception should have been thrown  append
__label__flaky callable2  add  record  to  coord  job  table  for  waiting  callable3  callables  callable1  tz  /2009/01/29/  get  id  date  utils  /2009/01/15/  parse  date  oozie  tz  as  list  queueservice  coord-action-for-action-input-check.xml  assert  true  2009-02-01  t23:59  get  test  case  dir  get  coordinator  action  create  dir  start  time  coord-job-for-action-input-check.xml  add  record  to  coord  action  table  for  waiting  wait  for  /2009/01/22/  c  /2009/01/08/  services  2009-02-02  t23:59  coordinator  job  1  2  test  coord  action  input  check  x  command  uniqueness  3  end  time  action1  job  arrays  evaluate  queue  callable2  addrecordtocoordjobtableforwaiting  callable3  callables  callable1  tz  /2009/01/29/  getid  dateutils  /2009/01/15/  parsedateoozietz  aslist  queueservice  coord-action-for-action-input-check.xml  asserttrue  2009-02-01t23:59  gettestcasedir  get  coordinatoraction  createdir  starttime  coord-job-for-action-input-check.xml  addrecordtocoordactiontableforwaiting  waitfor  /2009/01/22/  c  /2009/01/08/  services  2009-02-02t23:59  coordinatorjob  1  2  testcoordactioninputcheckxcommanduniqueness  3  endtime  action1  job  arrays  evaluate  queue
__label__nflaky de  date_1970_  jan  ninja  constant  language  when  fr  as  language  empty  result  get  of  en  as  language  lang  das  ist  ein  datum:  01.01.1970  optional  then  return  to  date  en  assert  equals  that\'s  a  date:  jan  1   1970  test  get  with  special  i18n  placeholder  message_with_placeholder_date  messages  get  string  array  test  fallback  to  default  (english  in  that  case)  c\'est  la  date:  1  janv.  1970  de  as  language  fr-  fr  ninja  properties  de  date_1970_jan  ninjaconstant  language  when   fr as language  empty  result  get  of   en as language  lang  das ist ein datum: 01.01.1970  optional  thenreturn  todate  en  assertequals  that\'s a date: jan 1  1970  testgetwithspeciali18nplaceholder  message_with_placeholder_date  messages  getstringarray   test fallback to default (english in that case)  c\'est la date: 1 janv. 1970   de as language  fr-fr  ninjaproperties
__label__flaky _test  transient  test  start  transient  assert  true  start  start.transient  workflow  action  bean  _testtransient  teststarttransient  asserttrue  start  start.transient  workflowactionbean
__label__nflaky request  when  filter  config  set  header  test  default  options  value  do  answer  assert  deny  x_  frame_  options  assert  true  do  filter  options  value  incorrect  should  be  deny  but  is:  add  headers  init  is  one  chain  then  return  assert  that  any  args  filter  x-  frame-  options  count  not  equal  to  1.  invocation  with  fail  message  header  should  be  visible  inside  chain  and  filters.  get  init  parameter  answer  size  mockito  response  equals  mock  get  arguments  x  frame  options  filter  contains  header  request  when  filterconfig  setheader  testdefaultoptionsvalue  doanswer  assert  deny  x_frame_options  asserttrue  dofilter  options value incorrect should be deny but is:   add  headers  init  isone  chain  thenreturn  assertthat  any  args  filter  x-frame-options count not equal to 1.  invocation  withfailmessage  header should be visible inside chain and filters.  getinitparameter  answer  size  mockito  response  equals  mock  getarguments  xframeoptionsfilter  containsheader
__label__flaky job  conf  get  name  reader  auth  token  wf-ext-schema.xsd  assert  not  null  get  test  case  dir  /workflow.xml  get  file://  workflow.xml  test-wf  wf-ext-schema-invalid.xml  oozie.service.  action  service.executor.ext.classes  parse  def  app  test  ext  schema  init  set  destroy  wf-ext-schema-valid.xml  assert  equals  services  oozie  client  fail  io  utils  get  test  user  schema  service  copy  char  stream  set  system  property  get  resource  as  reader  writer  wps  file  jobconf  getname  reader  authtoken  wf-ext-schema.xsd  assertnotnull  gettestcasedir  /workflow.xml  get  file://  workflow.xml  test-wf  wf-ext-schema-invalid.xml  oozie.service.actionservice.executor.ext.classes  parsedef  app  testextschema  init  set  destroy  wf-ext-schema-valid.xml  assertequals  services  oozieclient  fail  ioutils  gettestuser  schemaservice  copycharstream  setsystemproperty  getresourceasreader  writer  wps  file
__label__nflaky null_  str  escaped_  str_  with_  comma  escape  string  assert  equals  test  escape  string  str_  with_  escape  str_  with_  both2  str_  wo_  special_  chars  str_  with_  comma  escaped_  str_  with_  both2  string  utils  empty_  str  escaped_  str_  with_  escape  null_str  escaped_str_with_comma  escapestring  assertequals  testescapestring  str_with_escape  str_with_both2  str_wo_special_chars  str_with_comma  escaped_str_with_both2  stringutils  empty_str  escaped_str_with_escape
__label__flaky add  record  to  bundle  action  table  add  record  to  wf  action  table  coord  action  get  cmd  get  num  days  to  not  be  purged  test  purge  bundle  with  coord  child  with  wf  child2  date  utils  workflow  instance  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  get  end  time  bundle  job  bundle  job  bean  assert  not  null  coordinator  action  job  wf  action  wf  job  get  cmd  bundle  action  should  not  have  been  purged  execute  bundle  job  should  not  have  been  purged  coordinator  job  1  coord  job  get  cmd  fail  workflow  action  coord  action  succeeded  workflow  action  should  not  have  been  purged  bundle  job  get  cmd  get  id  coord  job  wf  job  add  record  to  wf  job  table  get  workflow  job  should  not  have  been  purged  workflow  job  get  app  name  bundle  action  wf  action  get  cmd  coordinator  action  should  not  have  been  purged  2011-01-01  t01:00  z  add  record  to  bundle  job  table  assert  equals  get  last  modified  time  add  record  to  coord  job  table  coordinator  job  should  not  have  been  purged  call  services  coord-action-get.xml  jpa  service  bundle  action  get  cmd  addrecordtobundleactiontable  addrecordtowfactiontable  coordactiongetcmd  getnumdaystonotbepurged  testpurgebundlewithcoordchildwithwfchild2  dateutils  workflowinstance  getstatus  addrecordtocoordactiontable  parsedateoozietz  getendtime  bundlejob  bundlejobbean  assertnotnull  coordinatoraction  job  wfaction  wfjobgetcmd  bundle action should not have been purged  execute  bundle job should not have been purged  coordinatorjob  1  coordjobgetcmd  fail  workflowaction  coordaction  succeeded  workflow action should not have been purged  bundlejobgetcmd  getid  coordjob  wfjob  addrecordtowfjobtable  get  workflow job should not have been purged  workflowjob  getappname  bundleaction  wfactiongetcmd  coordinator action should not have been purged  2011-01-01t01:00z  addrecordtobundlejobtable  assertequals  getlastmodifiedtime  addrecordtocoordjobtable  coordinator job should not have been purged  call  services  coord-action-get.xml  jpaservice  bundleactiongetcmd
__label__nflaky wait  for  the  async  task  to  finish  refill  task  should  add  10  values  to  get  to  a  full  queue  test  sync  generation  policy  k1  failed  in  async  call.  get  at  most  queue  is  empty   sync  will  return  a  single  value  and  trigger  a  refill  assert  equals  get  next  drain  drain  completely   no  further  refills  triggered  the  prefill  to  the  low  watermark   1  consumed  by  get  next())  wait  for  refill  assert  size  get  top  filler  vq  trigger  a  prefill  (3)  and  an  async  refill  (8)  testget  at  most  policy  atleast_  one  shutdown   wait for the async task to finish   refill task should add 10 values to get to a full queue  test  syncgenerationpolicy  k1  failed in async call.  getatmost   queue is empty  sync will return a single value and trigger a refill  assertequals  getnext  drain   drain completely  no further refills triggered   the prefill to the low watermark  1 consumed by getnext())  waitforrefill  assert  size  gettop  filler  vq   trigger a prefill (3) and an async refill (8)  testgetatmostpolicyatleast_one  shutdown
__label__flaky /////////////////////////////////////////////////////////////////////  retrieving  articles  for  a  user  (  json)  replace  contentcontent  get_  articles_  url  post_  article_  url  test  get  and  post  article  via  json  we  are  now  getting  4  articles.  one  new  result:  bob@gmail.com  new  title  new  title  api  response  make  get  request  {username}  article  dto  now  we  are  authenticated  and  expect  the  post  to  succeed...  we  get  back  all  3  articles  of  that  user  posting  a  new  article  is  a  post  request  to  do  login  if  we  now  fetch  the  articles  again  we  are  getting  a  new  article  (the  one  we  have  posted  successfully  build  uri  retrieving  all  articles  of  a  user  is  a  get  request  to  say  user  make  post  request  say  next  section  get  gson  with  long  to  date  parsing  assert  equals  and  say  articles  dto  posting  new  article  (  json)  please  note  that  you  have  to  be  authenticated  in  order  to  be  allowed  to  post.  size  from  json  you  have  to  be  authenticated  in  order  to  post  articles  after  successful  login  we  are  able  to  post  articles   /////////////////////////////////////////////////////////////////////  retrieving articles for a user (json)  replace  contentcontent  get_articles_url  post_article_url  testgetandpostarticleviajson  we are now getting 4 articles.   one new result:  bob@gmail.com  new title new title  apiresponse  makegetrequest  {username}  articledto  now we are authenticated and expect the post to succeed...  we get back all 3 articles of that user  posting a new article is a post request to   dologin  if we now fetch the articles again we are getting a new article (the one we have posted successfully  builduri  retrieving all articles of a user is a get request to   say  user  makepostrequest  saynextsection  getgsonwithlongtodateparsing  assertequalsandsay  articlesdto  posting new article (json)  please note that you have to be authenticated in order to be allowed to post.  size  fromjson  you have to be authenticated in order to post articles  after successful login we are able to post articles
__label__nflaky g-h  ${env.  null_  value}  ${env.  null_  value:}  declare  property  empty3  conf  empty1  empty2  when  config  ${env.  null_  value-}  ${env.  empty_  value-c}  ${env.  some_  value}  ${env.  null_  value:-i:-j}  then  return  edge5  edge3  edge4  end  config  edge1  edge2  props  test  env  default  some1  some2  some3  mock  file  resource  spy  empty_  value  ${env.  some_  value:-f}  i:-j  if  var  is  unbound   literal  ${var}  is  returned  null3  p=  null1  system  out  null2  assert  eq  ${env.  empty_  value}  add  resource  get  null_  value  ${env.  null_  value-g-h}  ${env.  null_  value:-b}  getenv  some  edge  cases  got  val  a  some  value  b  d  start  config  some_  value  ${env.  null_  value-a}  ${env.  null_  value:-}  ${env.  empty_  value:-d}  p  mockito  get  raw  ${env.  some_  value-e}  got  raw  val    g-h  ${env.null_value}  ${env.null_value:}  declareproperty  empty3  conf  empty1  empty2  when  config  ${env.null_value-}  ${env.empty_value-c}  ${env.some_value}  ${env.null_value:-i:-j}  thenreturn  edge5  edge3  edge4  endconfig  edge1  edge2  props  testenvdefault  some1  some2  some3  mock  fileresource  spy  empty_value  ${env.some_value:-f}  i:-j   if var is unbound  literal ${var} is returned  null3  p=  null1  system  out  null2  asserteq  ${env.empty_value}  addresource  get  null_value  ${env.null_value-g-h}  ${env.null_value:-b}  getenv   some edge cases  gotval  a  some value  b  d  startconfig  some_value  ${env.null_value-a}  ${env.null_value:-}  ${env.empty_value:-d}  p  mockito  getraw  ${env.some_value-e}  gotrawval
__label__flaky and  the  approximation  is  not  used  /file-1  nodetype  remove  jcr  constants  folder-2  folder-1  root  merge  builder  /folder-1  /folder-2  commit  info  get  root  oak:index  remove  \""rep:security\""  as  it  interferes  with  tests  mounts  root  state  query  file-1  index  create  filter  assert  equals  store  node  type  check  cursor  filter  entry  count  default  mount  info  provider  rep:security  get  child  node  set  property  add  folder  get  cost  add  file   and the approximation is not used  /file-1  nodetype  remove  jcrconstants  folder-2  folder-1  root  merge  builder  /folder-1  /folder-2  commitinfo  getroot  oak:index   remove \""rep:security\"" as it interferes with tests  mounts  rootstate  query  file-1  index  createfilter  assertequals  store  nodetype  checkcursor  filter  entrycount  defaultmountinfoprovider  rep:security  getchildnode  setproperty  addfolder  getcost  addfile
__label__nflaky test  root  dir  -move  from  local  assert  false  run  assert  equals  delete  target  test  root  exit  shell  assert  true  test  move  dir  from  local  mkdirs  lfs  src  dir  exists  to  string  test  put  dir  target  dir  testrootdir  -movefromlocal  assertfalse  run  assertequals  delete  target  testroot  exit  shell  asserttrue  testmovedirfromlocal  mkdirs  lfs  srcdir  exists  tostring  testputdir  targetdir
__label__flaky log4j  file  test-log4j.properties  init  current  thread  get  test  case  conf  dir  x  log  service  get  resource  as  stream  ls  assert  false  test  custom  log4j  from  config  dir  cl  destroy  is  assert  equals  get  log4j  properties  thread  io  utils  assert  test-oozie-log4j.properties  get  from  classpath  get  context  class  loader  copy  stream  set  system  property  log4jfile  test-log4j.properties  init  currentthread  gettestcaseconfdir  xlogservice  getresourceasstream  ls  assertfalse  testcustomlog4jfromconfigdir  cl  destroy  is  assertequals  getlog4jproperties  thread  ioutils  assert  test-oozie-log4j.properties  getfromclasspath  getcontextclassloader  copystream  setsystemproperty
__label__nflaky horizontal  10111010000.  horizontal  00001011101.  set  apply  mask  penalty  rule3  vertical  00001011101.  test  apply  mask  penalty  rule3  assert  equals  vertical  10111010000.  matrix  mask  util   horizontal 10111010000.   horizontal 00001011101.  set  applymaskpenaltyrule3   vertical 00001011101.  testapplymaskpenaltyrule3  assertequals   vertical 10111010000.  matrix  maskutil
__label__flaky job  conf  bundle  job  get  cmd  log  submit  cmd  get  id  get  status  app  path  configuration  parse  error.  read  from  db  :  get  job  assert  not  null  get  get  auth  token  job  set  get  conf  add  record  to  bundle  job  table  assert  equals  execute  bundle.xml  call  services  warn  oozie  client  test  bundle  kill3  to  string  error  code  job  jpa  service  ioe  jobconf  bundlejobgetcmd  log  submitcmd  getid  getstatus  apppath  configuration parse error. read from db :  getjob  assertnotnull  get  getauthtoken  job  set  getconf  addrecordtobundlejobtable  assertequals  execute  bundle.xml  call  services  warn  oozieclient  testbundlekill3  tostring  errorcode  job  jpaservice  ioe
__label__nflaky spy  fs  get  temp  path  generic  test  utils  conf  test  create  uses  fs  arg.seq  deprecation  fs  p  create  writer  sequence  file  mockito  get  local  get  default  replication  file  system  test  create  uses  fs  arg  verify  writer  spy  close  spyfs  gettemppath  generictestutils  conf  testcreateusesfsarg.seq  deprecation  fs  p  createwriter  sequencefile  mockito  getlocal  getdefaultreplication  filesystem  testcreateusesfsarg  verify  writer  spy  close
__label__flaky regions  value  of  find  memstores  with  edits  older  than  count  assert  equals  l  regions  to  seqids  get  bytes  put  0  bytes  1  2  assert  true  equals  long  regions  returned  are  not  ordered.  to  string  test  find  memstores  with  edits  older  than  h  log  regions  valueof  findmemstoreswitheditsolderthan  count  assertequals  l  regionstoseqids  getbytes  put  0  bytes  1  2  asserttrue  equals  long   regions returned are not ordered.  tostring  testfindmemstoreswitheditsolderthan  hlog
__label__nflaky oopsie  test  expression  check  fail  asserts  check  oopsie  testexpressioncheckfail  asserts  check
__label__flaky get  recovery  path  chmod1  chmod2  source  get  status  create  context  get  path  context  get  file  status  action  mkdir  get  permission  ae  format  <chmod  path=\'\'{4}\'\'  permissions=\'\'-rwxrwxrwx\'\'/>  get  file  system  check  rwxrwx---  workflow  action  mkdirs  <fs><mkdir  path=\'\'{0}\'\'/>  <chmod  path=\'\'{5}\'\'  permissions=\'\'-rwxrwx---\'\'  dir-files=\'\'false\'\'/>  new  file2  new  file1  assert  false  test  submit  <touchz  path=\'\'{7}\'\'/>  child2  fs  delete  child1  action  xml  assert  true  <move  source=\'\'{2}\'\'  target=\'\'{3}\'\'/>  </fs>  end  ok  get  data  message  format  <delete  path=\'\'{1}\'\'/>  to  uri  start  get  action  assert  equals  get  external  status  rwxrwxrwx  target  assert  null  <touchz  path=\'\'{6}\'\'/>  assert  not  same  exists  to  string  create  new  file  get  fs  test  case  dir  getrecoverypath  chmod1  chmod2  source  getstatus  createcontext  getpath  context  getfilestatus  action  mkdir  getpermission  ae  format  <chmod path=\'\'{4}\'\' permissions=\'\'-rwxrwxrwx\'\'/>  getfilesystem  check  rwxrwx---  workflowaction  mkdirs  <fs><mkdir path=\'\'{0}\'\'/>  <chmod path=\'\'{5}\'\' permissions=\'\'-rwxrwx---\'\' dir-files=\'\'false\'\'/>  newfile2  newfile1  assertfalse  testsubmit  <touchz path=\'\'{7}\'\'/>  child2  fs  delete  child1  actionxml  asserttrue  <move source=\'\'{2}\'\' target=\'\'{3}\'\'/>  </fs>  end  ok  getdata  messageformat  <delete path=\'\'{1}\'\'/>  touri  start  getaction  assertequals  getexternalstatus  rwxrwxrwx  target  assertnull  <touchz path=\'\'{6}\'\'/>  assertnotsame  exists  tostring  createnewfile  getfstestcasedir
__label__nflaky set  get  conf  value1  foo  conf  as  list  reconfigurable  assert  null  reconfigure  property  test  conf  is  unset  new  conf  get  property  arrays  make  reconfigurable  set  getconf  value1  foo  conf  aslist  reconfigurable  assertnull  reconfigureproperty  testconfisunset  newconf  get  property  arrays  makereconfigurable
__label__flaky set  classes  to  be  excluded  add  record  to  bundle  action  table  create  bundle  job  get  id  run  date  utils  get  status  parse  date  oozie  tz  set  pause  time  bundle  job  get  test  bundle  status  transit  service  paused  with  error  job  bundle  wait  for  init  get  conf  false  2009-02-01  t01:00  z  bundle  id  destroy  bundle  insertjpa  assert  equals  services  execute  services  runnable  excluded  services  set  system  property  status  transit  service  action1  action2  jpa  service  action3  evaluate  setclassestobeexcluded  addrecordtobundleactiontable  createbundlejob  getid  run  dateutils  getstatus  parsedateoozietz  setpausetime  bundlejob  get  testbundlestatustransitservicepausedwitherror  job  bundle  waitfor  init  getconf  false  2009-02-01t01:00z  bundleid  destroy  bundleinsertjpa  assertequals  services  execute  services  runnable  excludedservices  setsystemproperty  statustransitservice  action1  action2  jpaservice  action3  evaluate
__label__nflaky random  output  dir:  period  duration  in  millis  rolling  calendar  simulated  number  of  periods  diff  in  months  system  start:  get  months_  in_  year  }/clean.txt.zip  start  time  start  time  as  calendar  expected  count  with  folders  compute  slash  count  with  extra  folder  check  file  count  monthly_  cronolog_  date_  pattern  file  name  pattern  calendar  max  history  difference  in  months:  cp  current  time  extra  folder  with  success.     end=  index  of  start  period  difference  in  months  set  time  in  millis  monthly  rollover  over  many  periods  random  output  dir  /\%d{  millis_  in_  month  log  over  multiple  periods  end  time  get  instance  randomoutputdir:  perioddurationinmillis  rollingcalendar  simulatednumberofperiods  diffinmonths  system  start:  get  months_in_year  }/clean.txt.zip  starttime  starttimeascalendar  expectedcountwithfolders  computeslashcount  withextrafolder  checkfilecount  monthly_cronolog_date_pattern  filenamepattern  calendar  maxhistory  differenceinmonths:  cp  currenttime  extrafolder   with success.    end=  indexofstartperiod  differenceinmonths  settimeinmillis  monthlyrolloverovermanyperiods  randomoutputdir  /\%d{  millis_in_month  logovermultipleperiods  endtime  getinstance
__label__flaky read  value  get  server  address  ninja  test  browser  assert  equals  api/person.xml  system  test  post  person  xml  result  j:  person  response  post  xml  zeeess  name  -  and  some  utf8  =>  Ã¶Ã¤Ã¼  readvalue  getserveraddress  ninjatestbrowser  assertequals  api/person.xml  system  testpostpersonxml  result  j:   person  response  postxml  zeeess name - and some utf8 => Ã¶Ã¤Ã¼
__label__nflaky to  char  array  assert  false  length  is  empty  clear  assert  equals  capacity  b1  b2  assert  assert  true  1234  assert  not  null  tmp  to  string  buffer  is  full  test  simple  append  append  char  at  tochararray  assertfalse  length  isempty  clear  assertequals  capacity  b1  b2  assert  asserttrue  1234  assertnotnull  tmp  tostring  buffer  isfull  testsimpleappend  append  charat
__label__flaky fail  test  redirect  read  timeout  read  timed  out  expected  timeout  e  start  single  temporary  redirect  response  thread  get  message  test_  timeout  assert  equals  get  file  checksum  /file  fs  fail  testredirectreadtimeout  read timed out  expected timeout  e  startsingletemporaryredirectresponsethread  getmessage  test_timeout  assertequals  getfilechecksum  /file  fs
__label__nflaky lookup  h  unregister  h1  h2  test  register  unregister  h3  matcher  assert  assert  null  assert  true  assert  not  null  /h1  /h2  /h3  register  lookup  h  unregister  h1  h2  testregisterunregister  h3  matcher  assert  assertnull  asserttrue  assertnotnull  /h1  /h2  /h3  register
__label__flaky on  workflow  action  event  listener  2012-07-22  t01:00  z  parse  date  utc  date  utils  wf-app-name1  ca1  ca  id1  coordinator  action  2012-07-22  t00:00  z  wf  id1  is  start  processed  _create  sla  reg  bean  init  set  expected  end  wa1  since  service  obj  is  removed  from  memory  after  end  stage  is  end  processed  check  that  end  sla  has  been  calculated  cj1  execute  coordinator  job  service  obj  size  on  workflow  job  event  workflow  action  job  2012-07-22  t02:00  z  app  type  actual  start  set  expected  start  add  dummy  registration  events  to  the  sla  service  map  add  registration  event  wf1  cae  get  event  status  event  status  check  that  start  sla  has  been  calculated  on  coordinator  action  event  assert  true  get  test  on  job  event  wae  workflow  job  cje  user1  summary  coord-app-name1  get  conf  actual  end  bj1  assert  equals  services  get  sla  calculator  services  wfe  on  coordinator  job  event  calc  slas  onworkflowactionevent  listener  2012-07-22t01:00z  parsedateutc  dateutils  wf-app-name1  ca1  caid1  coordinatoraction  2012-07-22t00:00z  wfid1  isstartprocessed  _createslaregbean  init  setexpectedend  wa1   since serviceobj is removed from memory after end stage  isendprocessed   check that end sla has been calculated  cj1  execute  coordinatorjob  serviceobj  size  onworkflowjobevent  workflowaction  job  2012-07-22t02:00z  apptype  actualstart  setexpectedstart   add dummy registration events to the slaservice map  addregistrationevent  wf1  cae  geteventstatus  eventstatus   check that start sla has been calculated  oncoordinatoractionevent  asserttrue  get  testonjobevent  wae  workflowjob  cje  user1  summary  coord-app-name1  getconf  actualend  bj1  assertequals  services  getslacalculator  services  wfe  oncoordinatorjobevent  calc  slas
__label__nflaky c  abc  hello  status  printer  test  composite  assert  equals  parse  p  head  result  print  t  compile  converter  map  set  context  context  \%(  abc  \%hello)  write  }  c  abc hello  statusprinter  testcomposite  assertequals  parse  p  head  result  print  t  compile  convertermap  setcontext  context  \%(abc \%hello)  write   }
__label__flaky conf  run  bak  fs  system  out  tmpname  tool  runner  returned  should  be  1  assert  true  tmp  fshell  set  permission  index  of  permission  denied  printed  user  group  information  create  user  for  testing  ret  set  err  /foo  permission  denied  tmp  ugi  test  remote  exception  assert  equals  get  file  system  dfs  p  args  str  mygroup  do  as  -ls  build  num  data  nodes  mkdirs  reset  to  string  shutdown  conf  run  bak  fs  system  out  tmpname  toolrunner  returned should be 1  asserttrue  tmp  fshell  setpermission  indexof  permission denied printed  usergroupinformation  createuserfortesting  ret  seterr  /foo  permission denied  tmpugi  testremoteexception  assertequals  getfilesystem  dfs  p  args  str  mygroup  doas  -ls  build  numdatanodes  mkdirs  reset  tostring  shutdown
__label__nflaky request  options  value  incorrect  should  be  sameorigin  but  is:  when  filter  config  ljm  set  header  test  custom  options  value  and  no  overrides  do  answer  assert  x_  frame_  options  assert  true  do  filter  sure  that  it  doesn\'t  overwrite  the  configured  value  to  array  sameorigin  add  headers  init  is  one  chain  resp  then  return  header  should  be  visible  inside  chain  and  filters.  assert  equals  assert  that  any  args  filter  x-  frame-  options  count  not  equal  to  1.  invocation  with  fail  message  get  init  parameter  answer  size  mockito  response  mock  get  arguments  x  frame  options  filter  contains  header  is  equal  to  request  options value incorrect should be sameorigin but is:   when  filterconfig  ljm  setheader  testcustomoptionsvalueandnooverrides  doanswer  assert  x_frame_options  asserttrue  dofilter   sure that it doesn\'t overwrite the configured value  toarray  sameorigin  add  headers  init  isone  chain  resp  thenreturn  header should be visible inside chain and filters.  assertequals  assertthat  any  args  filter  x-frame-options count not equal to 1.  invocation  withfailmessage  getinitparameter  answer  size  mockito  response  mock  getarguments  xframeoptionsfilter  containsheader  isequalto
__label__flaky get  job  tracker  uri  map-reduce  _test  submit  fs  output  action  xml  <map-reduce>  create  write  close  <job-tracker>  get  map  reduce  config  get  name  node  uri  output  dir  </job-tracker>  dummy  get  file  system  input  dir  <name-node>  </name-node>  </map-reduce>  input  test  map  reduce  w  to  xml  string  to  string  data.txt  get  fs  test  case  dir  getjobtrackeruri  map-reduce  _testsubmit  fs  output  actionxml  <map-reduce>  create  write  close  <job-tracker>  getmapreduceconfig  getnamenodeuri  outputdir  </job-tracker>  dummy    getfilesystem  inputdir  <name-node>  </name-node>  </map-reduce>  input  testmapreduce  w  toxmlstring  tostring  data.txt  getfstestcasedir
__label__nflaky du  not  a  directory  expected  du4  du3  can  read  assert  false  some  target  files  and  containing  directory  are  not  accessible:  partitioned  part-r-00000  system  should  never  happen  since  that  method  never  throws  interrupted  exception.  du  assert  not  a  directory  du  does  not  exist  tmp  does  not  exist  0000  chmod  ie  quick  brown  fox  jumps  over  the  lazy  dog  test_  dir  is  accessible:  get  property  line  separator.  get  absolute  path  expected  length  target  file  is  not  a  directory:  assert  equals  target  file  does  not  exist:  0777  line.separator  assert  null  setup  dirs  test  get  du  get  du  file  util  du  not  a  directory  actual  in  @  after  method:  dunotadirectoryexpected  du4  du3  canread  assertfalse   some target files and containing directory are not accessible:  partitioned  part-r-00000  system   should never happen since that method never throws interruptedexception.  du  assert  notadirectory  dudoesnotexist  tmp  doesnotexist  0000  chmod  ie  quickbrownfoxjumpsoverthelazydog  test_dir   is accessible:  getproperty   line separator.  getabsolutepath  expected  length   target file is not a directory:  assertequals   target file does not exist:  0777  line.separator  assertnull  setupdirs  testgetdu  getdu  fileutil  dunotadirectoryactual   in @after method:
__label__flaky encode  put  value  pb  h  constants  assert  equals  check  value  pb  test  url  encoded  key  table  check  value  xml  column_2  column_1  response  encoded  key  value_1  put  value  xml  url  encoder  get  code  value_2  http://www.google.com/  encode  putvaluepb  hconstants  assertequals  checkvaluepb  testurlencodedkey  table  checkvaluexml  column_2  column_1  response  encodedkey  value_1  putvaluexml  urlencoder  getcode  value_2  http://www.google.com/
__label__nflaky date  https://www.example.com  private  get  dynamic  entry  foo=  asdjkhqkbzxoqweopiuaxqweoiu;  max-age=3600;  version=1  content-encoding  assert  header  equals  dynamic  table  set  max  size  get  current  size  set-cookie  assert  get  :status  cache-control  standard  charsets  mon   21  oct  2013  20:13:22  gmt  create  byte  buffer  mon   21  oct  2013  20:13:21  gmt  assert  equals  headers2  gzip  decoder  headers3  headers1  200  test  response  decoding  with  huffman  rfc7541  examples  size  302  src1  decode  headers  location  307  src3  src2  dynamic  length  date  https://www.example.com  private  getdynamicentry  foo=asdjkhqkbzxoqweopiuaxqweoiu; max-age=3600; version=1  content-encoding  assertheaderequals  dynamictable  setmaxsize  getcurrentsize  set-cookie  assert  get  :status  cache-control  standardcharsets  mon  21 oct 2013 20:13:22 gmt  createbytebuffer  mon  21 oct 2013 20:13:21 gmt  assertequals  headers2  gzip  decoder  headers3  headers1  200  testresponsedecodingwithhuffmanrfc7541examples  size  302  src1  decodeheaders  location  307  src3  src2  dynamiclength
__label__flaky get  time  coord  action  get  cmd  get  id  get  status  add  record  to  coord  action  table  assert  not  null  get  coordinator  action  action  0000001-  -test  coord  kill-  c  assert  equals  job  doesn\'t  exist.  should  fail.  execute  test  coord  kill  failed  add  record  to  coord  job  table  call  coordinator  job  services  coord  job  get  cmd  fail  coord-action-get.xml  test  job  id  job  jpa  service  gettime  coordactiongetcmd  getid  getstatus  addrecordtocoordactiontable  assertnotnull  get  coordinatoraction  action  0000001-  -testcoordkill-c  assertequals  job doesn\'t exist. should fail.  execute  testcoordkillfailed  addrecordtocoordjobtable  call  coordinatorjob  services  coordjobgetcmd  fail  coord-action-get.xml  testjobid  job  jpaservice
__label__nflaky conn  in  stream  assert  false  get  content  assert  equals  create  incoming  entity  message  get  content  length  content  content  length  strategy  assert  is  chunked  mockito  assert  true  assert  not  null  mock  test  create  entity  input  undefined  ok  entity  conn  instream  assertfalse  getcontent  assertequals  createincomingentity  message  getcontentlength  content  contentlengthstrategy  assert  ischunked  mockito  asserttrue  assertnotnull  mock  testcreateentityinputundefined  ok  entity
__label__flaky cluster  fs  home  conf  somewhat/random.txt  delete  assert  true  get  home  directory  else  get  user  name  close  write  file  /somewhere  cleanup  file  subdir2  test  working  directory  get  working  directory  subdir1  assert  equals  get  file  system  /user/  home  set  working  directory  orig_path  build  read  file  make  qualified  file  sys  is  absolute  exists  to  string  file1  test  home  directory  shutdown  cluster  fshome  conf  somewhat/random.txt  delete  asserttrue  gethomedirectory  else  getusername  close  writefile  /somewhere  cleanupfile  subdir2  testworkingdirectory  getworkingdirectory  subdir1  assertequals  getfilesystem  /user/  home  setworkingdirectory  orig_path  build  readfile  makequalified  filesys  isabsolute  exists  tostring  file1   test home directory  shutdown
__label__nflaky get  and  advance  current  index  is  one  1x0  1x1  ipc_  callqueue_  wrrmux_  weights_  key  1x0  3x1  2x2  conf  test.custom.  assert  that  1  mux  2  3  set  strings  is  zero  test.custom  test  custom  pattern  is  equal  to  getandadvancecurrentindex  isone   1x0 1x1  ipc_callqueue_wrrmux_weights_key   1x0 3x1 2x2  conf  test.custom.  assertthat  1  mux  2  3  setstrings  iszero  test.custom  testcustompattern  isequalto
__label__flaky check  for  resolved  conf  /2009/22/  e  action  get  test  case  dir  property  action  create  action  element  element  list  push  deps  are  not  met  dry  run  coord  print  stack  trace  workflow  populate  table  get  child  parse  xml  test  dry  run  pull  and  push  deps  /2009/15/  get  pull  missing  dependencies  test  dir  hcat  dependency  fail  coordinator  job  get  children  get  namespace  file:// test  dir/2009/29  coord  command  utils  job  add  record  to  coord  job  table  for  waiting  set  push  missing  dependencies  configuration  make  only  pull  dependencies  available  ${coord:data  in(\'  a\')}  app  path  create  coordinator  action  bean  action  xml  sleep  coord  default  coord-action-for-action-input-check.xml  /2009/08/  get  create  dir  coord-job-for-matd-hcat.xml  tablename  value  action  bean  table  miss  deps  xml  utils  e  newaction  xml  get  message  assert  equals  e1  set  missing  dependencies  e2  ${coord:data  out(\'  local_  a\')}  get  value  /2009/29/  config  elem  file:// test  dir/2009/29 file:// test  dir/2009/22 file:// test  dir/2009/15 file:// test  dir/2009/08  get  push  missing  dependencies  get  coord  action  xml  action  xml  only  to  check  whether  coord  conf  got  resolved  or  not  db  get  fs  test  case  dir   check for resolved conf  /2009/22/  eaction  gettestcasedir  property  action  createactionelement  elementlist   push deps are not met  dryruncoord  printstacktrace  workflow  populatetable  getchild  parsexml  testdryrunpullandpushdeps  /2009/15/  getpullmissingdependencies  testdir  hcatdependency  fail  coordinatorjob  getchildren  getnamespace  file:// testdir/2009/29  coordcommandutils  job  addrecordtocoordjobtableforwaiting  setpushmissingdependencies  configuration   make only pull dependencies available  ${coord:datain(\'a\')}  apppath  createcoordinatoractionbean  actionxml  sleep  coord  default  coord-action-for-action-input-check.xml  /2009/08/  get  createdir  coord-job-for-matd-hcat.xml  tablename  value  actionbean  table  missdeps  xmlutils  e  newactionxml  getmessage  assertequals  e1  setmissingdependencies  e2  ${coord:dataout(\'local_a\')}  getvalue  /2009/29/  configelem  file:// testdir/2009/29 file:// testdir/2009/22 file:// testdir/2009/15 file:// testdir/2009/08  getpushmissingdependencies  getcoordactionxml   actionxml only to check whether coord conf got resolved or not  db  getfstestcasedir
__label__nflaky key  provider  a  a  get  cipher  set  get  attributes  set  bit  length  description  conf  assert  equals  set  description  set  attributes  get  description  put  set  int  test  options  my  cipher  set  cipher  options  attributes  get  bit  length  your  cipher  keyprovider  a  a  getcipher  set  getattributes  setbitlength  description  conf  assertequals  setdescription  setattributes  getdescription  put  setint  testoptions  mycipher  setcipher  options  attributes  getbitlength  yourcipher
__label__flaky cluster  file_  size  block_  size  conf  when  no  seek;  just  read  do  answer  client  pread  close  info  localhost  any  boolean  read  again  and  verify  that  the  socket  is  the  same  opened  starting  test  read  from  one  dn()  log  in  any  string  test  read  from  one  dn  unchecked  matchers  data  buf  any  object  any  int  test  file  answer  mockito  any  long  get  name  node  port  get  block  reader  initial  read  to  string  spy  open  cluster  file_size  block_size  conf  when   no seek; just read  doanswer  client  pread  close  info  localhost  anyboolean   read again and verify that the socket is the same  opened   starting testreadfromonedn()  log  in  anystring  testreadfromonedn  unchecked  matchers  databuf  anyobject  anyint  testfile  answer  mockito  anylong  getnamenodeport  getblockreader   initial read  tostring  spy  open
__label__nflaky create  injector  service  should  not  be  started  before  lifecycle  service  is  started  equal  to  mock  service  get  instance  assert  that  createinjector  serviceshouldnotbestartedbeforelifecycleserviceisstarted  equalto  mockservice  getinstance  assertthat
__label__flaky date  given  simplemap  select  *  from  simple  where  id  =  as  list  consistency  level  crud  simpleset  when  get  list  id  all  contains  entry  random  utils  get  set  set  simple  map  assert  that  execute  immutable  map  get  map  set  simple  set  set  consistency  list  has  size  new  hash  set  should_insert  then  contains  only  long  arrays  session  insert  two  consistencylist  contains  exactly  sets  get  timestamp  of  get  row  value  each_  quorum  manager  one  get  string  next  long  rows  local_  quorum  get  long  is  equal  to  entity  date   given  simplemap  select * from simple where id =   aslist  consistencylevel  crud  simpleset   when  getlist  id  all  containsentry  randomutils  getset  setsimplemap  assertthat  execute  immutablemap  getmap  setsimpleset  setconsistencylist  hassize  newhashset  should_insert   then  containsonly  long  arrays  session  insert  two  consistencylist  containsexactly  sets  gettimestamp  of  get  row  value  each_quorum  manager  one  getstring  nextlong  rows  local_quorum  getlong  isequalto  entity
__label__nflaky get  secret  key  get  current  user  other  set  get  tokens  the  doctor  get  credentials  run  when  creds  remove  the  tardis  ugi  creds  assert  true  shouldn\'t  be  able  to  modify  token  collection  from  ugi  ugi  ensure  that  the  tokens  are  passed  through  do  as  add  secret  key  user  group  information  create  user  for  testing  shhh  add  token  secret  name  secret  key  add  credentials  number  of  secret  keys  then  return  unchecked  from  mockito  mocks  assert  equals  assert  same  get  service  test  ugi  tokens  fail  contains  do  as  size  mock  z  t1  t2  getsecretkey  getcurrentuser  otherset  gettokens  thedoctor  getcredentials  run  when  creds  remove  thetardis  ugicreds  asserttrue  shouldn\'t be able to modify token collection from ugi  ugi   ensure that the tokens are passed through doas  addsecretkey  usergroupinformation  createuserfortesting  shhh  addtoken  secretname  secretkey  addcredentials  numberofsecretkeys  thenreturn  unchecked   from mockito mocks  assertequals  assertsame  getservice  testugitokens  fail  contains  doas  size  mock  z  t1  t2
__label__flaky @  close  trx  coord  client  get  store  get  time  local  oozie  could  not  update  db.  get  status  -test  coord  rerun-  c  get  coord  client  rerun  scope  get  begin  trx  coordinator  action  re  run  coord  action  num2  commit  trx  action  num1  coord-rerun-action2.xml  rest  constants  print  stack  trace  store1  e  store  -  test  coord  rerun  actions2  action  id2  add  record  to  job  table  integer  job  id  action  id1  services  fail  coordinator  job  add  record  to  action  table  assert  not  same  0000000-  to  string  action1  action2  coord-rerun-action1.xml  get  coordinator  action  @  closetrx  coordclient  getstore  gettime  localoozie  could not update db.  getstatus  -testcoordrerun-c  getcoordclient  rerunscope  get  begintrx  coordinatoraction  reruncoord  actionnum2  committrx  actionnum1  coord-rerun-action2.xml  restconstants  printstacktrace  store1  e  store  -  testcoordrerunactions2  actionid2  addrecordtojobtable  integer  jobid  actionid1  services  fail  coordinatorjob  addrecordtoactiontable  assertnotsame  0000000-  tostring  action1  action2  coord-rerun-action1.xml  getcoordinatoraction
__label__nflaky config  util  /user  file://foo  get  file  context  conf  add  link  test  uri  empty  path  file  context  fs  constants  configutil  /user  file://foo  getfilecontext  conf  addlink  testuriemptypath  filecontext  fsconstants
__label__flaky hcat://hcatserver.blue.server.com:8020  get  jms  connection  info  conn  info1  both  servers  should  connect  to  default  jms  server  hcat  service  test  connection  create  connection  context  jms  service  assert  equals  services  ctxt2  ctxt1  conn  info  assert  true  get  http://unknown:80  is  connection  initialized  close  hcat://hcatserver.blue.server.com:8020  getjmsconnectioninfo  conninfo1   both servers should connect to default jms server  hcatservice  testconnection  createconnectioncontext  jmsservice  assertequals  services  ctxt2  ctxt1  conninfo  asserttrue  get  http://unknown:80  isconnectioninitialized  close
__label__nflaky property  had  invalid  int  value   but  was  read  successfully.  conf  append  property  test.int2  out  test.int1  config  add  resource  test  integer  values  get  long  bytes  end  config  start  config  assert  equals  -20  -20  020  test.int4  get  long  test.int3  get  int  fail  test.int5  file  resource  20  -20xyz  property had invalid int value  but was read successfully.  conf  appendproperty  test.int2  out  test.int1  config  addresource  testintegervalues  getlongbytes  endconfig  startconfig  assertequals  -20   -20   020  test.int4  getlong  test.int3  getint  fail  test.int5  fileresource  20   -20xyz
__label__flaky init  coord  el  functions  ${coord:days(256)}  assert  equals  timeunit  get  variable  1  eval  eval  and  wrap  256  ${coord:days(1)}  time  unit  expr  coord-job-submit-freq  test  day  init  coordelfunctions  ${coord:days(256)}  assertequals  timeunit  getvariable  1  eval  evalandwrap  256  ${coord:days(1)}  timeunit  expr  coord-job-submit-freq  testday
__label__nflaky st  rte  ctx  ms  wait  for  did  not  throw  get  message  time  assert  equals  get  cause  et  fail  my  ioe  add  thread  expected  assert  true  do  work  now  the  thread  throws  faster  than  that  test  thread  throws  checked  exception  start  threads  wait  for  test  took  st  rte  ctx  ms  waitfor did not throw  getmessage  time  assertequals  getcause  et  fail  my ioe  addthread   expected  asserttrue  dowork  now   the thread throws faster than that  testthreadthrowscheckedexception  startthreads  waitfor  test took
__label__flaky assert  deleted.  they  were  deleted.  start_  key  get  store  ttl  in  seconds  h  constants  create  smaller  store  file  get  bytes  bytes  scanner  startrow  delete  family  assert  equals(cell  values.length   3);  second  row  bytes  create  store  file  start_  key_  bytes  contains  start  row  count  compaction_  threshold  get  file  system  get  row  deleted  row.  cell.create  single  cell  array(r.get(  startrow   column_  family_  text   -1   100  /*  too  many*/));  size  add  family  do  a  simple  ttl  test.  get  storefiles  assert  that  the  second  row  is  still  deleted.  next  check  compaction  dir  for  this  regions  is  cleaned  up  add  a  bit  of  data  and  flush.  start  adding  at  \'bbb\'.  assert  false  values  assert  that  i  can  get  3  versions  since  it  is  the  max  i  should  get  delete  system  result  sleep  set  max  versions  assert  true  always  3  versions  if  that  is  what  max  versions  is.  get  fix  column_  family_  text  row  column_  family  get  reader  fam  and  qf  f  increment  the  least  significant  character  so  we  get  to  next  row.  is  empty  assert  equals  store  add  content  check  compaction  dir  is  exists  force  major  compaction.  flushcache  seek  to  thread  r  assert  ==  3  when  we  ask  for  versions.  compact  stores  current  time  millis  equals  exists  get  key  value  to  string  test  compaction  file.  get  scanner   assert deleted.   they were deleted.  start_key  getstore  ttlinseconds  hconstants  createsmallerstorefile  getbytes  bytes  scanner  startrow  deletefamily   assertequals(cellvalues.length  3);  secondrowbytes  createstorefile  start_key_bytes  containsstartrow  count  compaction_threshold  getfilesystem  getrow   deleted row.   cell.createsinglecellarray(r.get(startrow  column_family_text  -1  100 /*too many*/));  size  addfamily   do a simple ttl test.  getstorefiles   assert that the second row is still deleted.  next   check compaction dir for this regions is cleaned up   add a bit of data and flush.  start adding at \'bbb\'.  assertfalse  values   assert that i can get 3 versions since it is the max i should get  delete  system  result  sleep  setmaxversions  asserttrue   always 3 versions if that is what max versions is.  get   fix  column_family_text  row  column_family  getreader  famandqf  f   increment the least significant character so we get to next row.  isempty  assertequals  store  addcontent   check compaction dir is exists   force major compaction.  flushcache  seekto  thread  r   assert == 3 when we ask for versions.  compactstores  currenttimemillis  equals  exists  getkeyvalue  tostring  testcompaction   file.  getscanner
__label__nflaky parse  exception  should  have  been  thrown  :  blah  clear  header  :  blah  parse  header  fail  assert  test  invalid  header  parsing  :  :  buffer  :  blah  append  blah    parseexception should have been thrown   : blah  clear  header : blah  parseheader  fail  assert  testinvalidheaderparsing     :  :  buffer  : blah  append  blah
__label__flaky server  server  conf  run  get  class  loader  set  call  id  and  retry  count  test  invocation  handler  10000  times  runs  about  6s  on  a  core  i7  machine  proxy  assert  test  retry  proxy  retry  policies  client  get  call  retry  count  create  client  dummy  run  retry  count  new  proxy  instance  start  assert  equals  retry  proxy  proxy  total  retry  stop  retry  proxy  server  server  conf  run  getclassloader  setcallidandretrycount  testinvocationhandler   10000 times runs about 6s on a core i7 machine  proxy  assert  testretryproxy  retrypolicies  client  getcallretrycount  create  client  dummyrun  retrycount  newproxyinstance  start  assertequals  retryproxy  proxy  totalretry  stop  retryproxy
__label__nflaky /storage  policy  storage  policy  path  chroot  fs  unset  storage  policy  set  class  mockfs://foo/a/b  /a/b/storage  policy  conf  uri  ch  rooted  storage  policy  path  get  raw  file  system  test  unset  storage  policy  fs.mockfs.impl  chroot  uri  create  verify  mock  fs  /storagepolicy  storagepolicypath  chrootfs  unsetstoragepolicy  setclass  mockfs://foo/a/b  /a/b/storagepolicy  conf  uri  chrootedstoragepolicypath  getrawfilesystem  testunsetstoragepolicy  fs.mockfs.impl  chrooturi  create  verify  mockfs
__label__flaky conn  set  request  method  is_  security_  enabled  id-valid  put  external-valid  assert  true  array  assert  not  null  get  name=x  json  content-type  /v0/jobs  run  test(\""/jobs\""   base  jobs  servlet.class   is_  security_  enabled   new  callable<  void>()  {  run  test  json  tags  rest  constants  open  connection  test  jobs  mock  dag  engine  service  http  servlet  response  assert  equals  parse  params  get  input  stream  url  json  value  call  100  get  header  field  2  assert  null  size  obj  get  get  response  code  wf  count  reset  create  url  external-invalid  starts  with    conn  setrequestmethod  is_security_enabled  id-valid  put  external-valid  asserttrue  array  assertnotnull  get  name=x  json  content-type  /v0/jobs   runtest(\""/jobs\""  basejobsservlet.class  is_security_enabled  new callable<void>() {  runtest  jsontags  restconstants  openconnection  testjobs  mockdagengineservice  httpservletresponse  assertequals  parse  params  getinputstream  url  jsonvalue  call  100  getheaderfield  2  assertnull  size  obj  get  getresponsecode  wfcount  reset  createurl  external-invalid  startswith
__label__nflaky has  data  core  matchers  equal  to  length  clear  expandable  buffer  assert  that  put  capacity  mode  assert  set  input  mode  test  basics  buffer  ensure  capacity  hasdata  corematchers  equalto  length  clear  expandablebuffer  assertthat  put  capacity  mode  assert  setinputmode  testbasics  buffer  ensurecapacity
__label__flaky format  date  expires:  last-  modified:  headers  add  header  get  headers  last  modified  date  if-  modified-  since:  contains  assert  true  time  unit  cache  control  no  cache  and  expiration  date  in  the  future  assert  conditionally  cached  conditional  request  cache-  control:  no-cache  formatdate  expires:   last-modified:   headers  addheader  getheaders  lastmodifieddate  if-modified-since:   contains  asserttrue  timeunit  cachecontrolnocacheandexpirationdateinthefuture  assertconditionallycached  conditionalrequest  cache-control: no-cache
__label__nflaky get  name  content  type  core  matchers  equal  to  set  ssl  context  request1  set  entity  assert  set  socket  config  context  create  https  /stuff  get  code  cn=localhost   ou=  apache  http  components   o=  apache  software  foundation  set  exception  listener  get  peer  principal  requester  localhost  socket  config  set  stream  listener  http  status  tls  version  logging  http1  stream  listener  ssl  session  *  set  so  timeout  method  assert  that  execute  server  bootstrap  entity  utils  logging  conn  pool  listener  logging  exception  listener  greater  equals  requester  bootstrap  timeout  response1  server  test  tls  success  get  local  port  create  client  ssl  context  bootstrap  set  conn  pool  listener  ssl  session  ref  some  stuff  create  server  ssl  context  body1  verify  tls  get  and  set  set  ssl  session  verifier  ssl  test  contexts  set  custom  start  get  protocol  parse  get  entity  target  build  to  string  register  getname  contenttype  corematchers  equalto  setsslcontext  request1  setentity  assert  setsocketconfig  context  create  https  /stuff  getcode  cn=localhost ou=apache httpcomponents o=apache software foundation  setexceptionlistener  getpeerprincipal  requester  localhost  socketconfig  setstreamlistener  httpstatus  tlsversion  logginghttp1streamlistener  sslsession  *  setsotimeout  method  assertthat  execute  serverbootstrap  entityutils  loggingconnpoollistener  loggingexceptionlistener  greaterequals  requesterbootstrap  timeout  response1  server  testtlssuccess  getlocalport  createclientsslcontext  bootstrap  setconnpoollistener  sslsessionref  some stuff  createserversslcontext  body1  verify  tls  getandset  setsslsessionverifier  ssltestcontexts  set  custom  start  getprotocol  parse  getentity  target  build  tostring  register
__label__flaky random  port  topic.topic1  is  topic  in  retry  list  tcp://localhost:  publisher  authority  register  for  notification  exception  expected  init  get  jms  connection  info  hcat  service  hcat.server.com:5080  create  connection  context  test  connection  retry  exception  listener  destroy  jms  service  jms  accessor  service  active  mq  conn  factory  1  fail  conn  ctxt  3  java.naming.provider.url#  conn  info  stop  is  listening  to  topic  topic  ;  assert  false  create  session  sleep  random  connection  factory  is  connection  in  retry  list  h  cat  accessor  service  assert  true  connection  factory  names#  get  services  conf  java.naming.factory.initial#  jndi  properties  string  set  get  conf  start  services  next  int  hcat://hcat.server.com:8020  broker  add  connector  thread  broker  url  services  start  the  broker  setup  services  for  h  catalog  default=  session  randomport  topic.topic1  istopicinretrylist  tcp://localhost:  publisherauthority  registerfornotification  exception expected  init  getjmsconnectioninfo  hcatservice  hcat.server.com:5080  createconnectioncontext  testconnectionretryexceptionlistener  destroy  jmsservice  jmsaccessorservice  activemqconnfactory  1  fail  connctxt  3  java.naming.provider.url#  conninfo  stop  islisteningtotopic  topic  ;  assertfalse  createsession  sleep  random  connectionfactory  isconnectioninretrylist  hcataccessorservice  asserttrue  connectionfactorynames#  get  servicesconf  java.naming.factory.initial#  jndipropertiesstring  set  getconf  start  services  nextint  hcat://hcat.server.com:8020  broker  addconnector  thread  brokerurl  services   start the broker  setupservicesforhcatalog  default=  session
__label__nflaky t123  t  test  encode2  do  test  0110010101  0101011001  00000  01011001001  1011001001  0101001011  t123t  testencode2  dotest  0110010101  0101011001  00000  01011001001  1011001001  0101001011
__label__flaky test  recovery  of  1  corrupt  replica  log  test  block  corruption  recovery  policy1  block  corruption  recovery  policy  testing  corrupt  replica  recovery  for  one  corrupt  replica  info   test recovery of 1 corrupt replica  log  testblockcorruptionrecoverypolicy1  blockcorruptionrecoverypolicy  testing corrupt replica recovery for one corrupt replica  info
__label__nflaky p1  p2  p3  get  name  p4  get  kms  url  this  should  be  retried  conf  exceptions  other  than  io  exceptions  will  not  be  retried  when  test1  assert  true  test  load  balancing  with  failure  then  throw  this  should  not  be  retried  should  fail  since  its  not  an  io  exception  kp  e  any  string  then  return  create  key  assert  equals  any  test4  fail  test2  test3  mockito  io  exception  will  trigger  retry  in  next  provider  mock  v1  v3  p1  p2  p3  getname  p4  getkmsurl   this should be retried  conf   exceptions other than ioexceptions will not be retried  when  test1  asserttrue  testloadbalancingwithfailure  thenthrow   this should not be retried  should fail since its not an ioexception  kp  e  anystring  thenreturn  createkey  assertequals  any  test4  fail  test2  test3  mockito   ioexception will trigger retry in next provider  mock  v1  v3
__label__flaky date  script  executor  session  given  simple  simplemap  0  am  eq  delete  select  *  from  simple  where  id  =  consistencylist  simpleset  when  of  where  id  row  value  table  execute  script  template  is  not  null  random  utils  manager  get  set  one  should_dsl_delete  simple  map  get  string  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  is  true  then  is  null  contains  only  long  build  date  key  consistency  list  from  base  table  dsl  is  equal  to  date  scriptexecutor  session   given  simple  simplemap  0 am  eq  delete  select * from simple where id =   consistencylist  simpleset   when  of  where  id  row  value  table  executescripttemplate  isnotnull  randomutils  manager  getset  one  should_dsl_delete  simplemap  getstring  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  istrue   then  isnull  containsonly  long  builddatekey  consistencylist  frombasetable  dsl  isequalto
__label__nflaky de  franÃ§ais  en-  us  en-  ca  ninja  constant  defaultlanguage  language  fr  a_non_existing_key  when  da fr-  fr;q=0.8  empty  that  will  refer  to  messages_fr-  fr.properties:  test  get  with  language  of  get  deutsch  english  lang  de-  de  optional  that  will  refer  to  messages_de.properties:  then  return  de;q=0.9   fr-  fr;  q=0.8  en  assert  equals  that  will  refer  to  messages_en.properties:  messages  get  string  array  en-  uk  fr-  fr  ninja  properties  de fr-  fr;q=0.8  da;q=0.9   fr-  fr;  q=0.8  de  franÃ§ais  en-us  en-ca  ninjaconstant  defaultlanguage  language  fr  a_non_existing_key  when  da fr-fr;q=0.8  empty   that will refer to messages_fr-fr.properties:  testgetwithlanguage  of  get  deutsch  english  lang  de-de  optional   that will refer to messages_de.properties:  thenreturn  de;q=0.9  fr-fr; q=0.8  en  assertequals   that will refer to messages_en.properties:  messages  getstringarray  en-uk  fr-fr  ninjaproperties  de fr-fr;q=0.8  da;q=0.9  fr-fr; q=0.8
__label__flaky add  record  to  bundle  action  table  get  current  dateafter  incrementing  in  months  run  date  utils  workflow  instance  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  bundle  job  assert  not  null  coordinator  action  current  date  plus  month  job  wait  for  init  bundle  action1  bundle  action2  destroy  x  data  test  case  execute  add  record  to  coord  job  table  with  bundle  coord  job2  coordinator  job  coord  job1  evaluate  set  classes  to  be  excluded  assert  false  get  id  get  external  id  is  pending  wf  job  add  record  to  wf  job  table  assert  true  get  end  coord  action1_3  workflow  job  coord  action1_4  bundle  coord  action1_1  coord  action1_2  get  conf  false  add  record  to  bundle  job  table  bundle  id  start  assert  equals  services  test  bundle  status  transit  service  running  with  error  call  services  runnable  coord-action-get.xml  excluded  services  set  system  property  equals  status  transit  service  action1  action2  jpa  service  addrecordtobundleactiontable  getcurrentdateafterincrementinginmonths  run  dateutils  workflowinstance  getstatus  addrecordtocoordactiontable  parsedateoozietz  bundlejob  assertnotnull  coordinatoraction  currentdateplusmonth  job  waitfor  init  bundleaction1  bundleaction2  destroy  xdatatestcase  execute  addrecordtocoordjobtablewithbundle  coordjob2  coordinatorjob  coordjob1  evaluate  setclassestobeexcluded  assertfalse  getid  getexternalid  ispending  wfjob  addrecordtowfjobtable  asserttrue  get  end  coordaction1_3  workflowjob  coordaction1_4  bundle  coordaction1_1  coordaction1_2  getconf  false  addrecordtobundlejobtable  bundleid  start  assertequals  services  testbundlestatustransitservicerunningwitherror  call  services  runnable  coord-action-get.xml  excludedservices  setsystemproperty  equals  statustransitservice  action1  action2  jpaservice
__label__nflaky increment  and  get  content  type  test  consume  data  get  content  count  consume  assert  equals  completed  failed  byte  buffer  long  value  assert  stream  end  cancelled  12345  stream  start  wrap  consumer  incrementandget  contenttype  testconsumedata  getcontent  count  consume  assertequals  completed  failed  bytebuffer  longvalue  assert  streamend  cancelled  12345  streamstart  wrap  consumer
__label__flaky cluster  fs2  fs1  waiting  for  close  to  get  to  latch...  opening  file  for  append  from  new  fs  conf  run  when  wait  active  wait  for  call  assert  not  null  appender  stream  delayer  create  join  write  write  1/2  block  info  lease  mismatch  proceed  log  any  string  /test  complete  other  lease  interrupt  and  join  waiting  for  close  to  finish.  get  file  system  any  object  stm  killing  lease  checker  pre  spy  nn  contains  num  data  nodes  test  complete  other  lease  holders  file  spy  shutdown  recover  file  do  answer  assert  true  get  client  error.  close  lose  the  leases  set  err  get  conf  start  recovering  file  get  message  get  name  node  rpc  telling  old  close  to  proceed.  delay  complete  file  append  test  util  t  build  spy  nn  create  hdfs  with  different  username  close  finished.  writing  some  data  from  new  appender  thrown  by  close  file1  complete  append  the  appender  should  be  able  to  close  properly  cluster  fs2  fs1  waiting for close to get to latch...  opening file for append from new fs  conf  run  when  waitactive  waitforcall  assertnotnull  appenderstream  delayer  create  join  write   write 1/2 block  info  lease mismatch  proceed  log  anystring  /testcompleteotherlease  interruptandjoin  waiting for close to finish.  getfilesystem  anyobject  stm  killing lease checker  prespynn  contains  numdatanodes  testcompleteotherleaseholdersfile  spy  shutdown  recoverfile  doanswer  asserttrue  get  client   error.  close   lose the leases  set  err  getconf  start  recovering file  getmessage  getnamenoderpc  telling old close to proceed.   delay completefile  appendtestutil  t  build  spynn  createhdfswithdifferentusername  close finished.  writing some data from new appender  thrownbyclose  file1  complete  append   the appender should be able to close properly
__label__nflaky server  get  local  port  content  type  create  client  ssl  context  set  ssl  context  consume  test  ssl  disabled  by  default  bootstrap  set  conn  pool  listener  request1  some  stuff  set  entity  ss  lv3  set  protocols  create  server  ssl  context  set  socket  config  ssl  parameters  context  create  https  /stuff  requester  localhost  ssl  test  contexts  socket  config  set  stream  listener  custom  start  logging  http1  stream  listener  set  so  timeout  method  get  entity  execute  set  ssl  setup  handler  server  bootstrap  target  entity  utils  logging  conn  pool  listener  build  requester  bootstrap  timeout  response1  server  getlocalport  contenttype  createclientsslcontext  setsslcontext  consume  testssldisabledbydefault  bootstrap  setconnpoollistener  request1  some stuff  setentity  sslv3  setprotocols  createserversslcontext  setsocketconfig  sslparameters  context  create  https  /stuff  requester  localhost  ssltestcontexts  socketconfig  setstreamlistener  custom  start  logginghttp1streamlistener  setsotimeout  method  getentity  execute  setsslsetuphandler  serverbootstrap  target  entityutils  loggingconnpoollistener  build  requesterbootstrap  timeout  response1
__label__flaky conn  set  request  method  is_  security_  enabled  assert  true  json  content-type  /v1/admin/*  collections  run  test  rest  constants  open  connection  contains  key  http  servlet  response  assert  equals  parse  user  get  input  stream  url  json  value  call  test  os  env  get  header  field  get  get  response  code  create  url  starts  with  conn  setrequestmethod  is_security_enabled  asserttrue  json  content-type  /v1/admin/*  collections  runtest  restconstants  openconnection  containskey  httpservletresponse  assertequals  parse  user  getinputstream  url  jsonvalue  call  testosenv  getheaderfield  get  getresponsecode  createurl  startswith
__label__nflaky mock  res  init  mock  req  object  under  test  then  return  browser_  agent  csrf  has  not  been  sent  objects  to  verify  interactions  based  on  request  setup  the  configuration  settings  of  the  server  get  method  when  filter  config  get  header  filter  mock  chain  get  init  parameter  mockito  do  filter  get  test  missing  header  ignore  get  method  config  good  request  mock  verify  rest  csrf  prevention  filter  mockres  init  mockreq   object under test  thenreturn  browser_agent   csrf has not been sent   objects to verify interactions based on request   setup the configuration settings of the server  getmethod  when  filterconfig  getheader  filter  mockchain  getinitparameter  mockito  dofilter  get  testmissingheaderignoregetmethodconfiggoodrequest  mock  verify  restcsrfpreventionfilter
__label__flaky ce  create  coordinator  engine  get  filter  params  assert  equals  stream  log  services  run  jobs  impl  filter  job  id  dag  x  log  info  service  service  get  test  stream  log4  null  null  ce  createcoordinatorengine  getfilterparams  assertequals  streamlog  services  runjobsimpl  filter  jobid  dagxloginfoservice  service  get  teststreamlog4nullnull
__label__nflaky value5  file  resource1  get  resource  configuration  value2  value1  value4  value3  conf  jconf  put  config  get  key  get  properties  end  config  test  dump  configuration  dump  configuration  new  value1  new  value2  get  is  final  efficient  retrieval  out  writer  file  resource  check  for  consistency  in  the  number  of  properties  parsed  in  json  format.  default  length  json  str  mapper  config2  append  property  check  if  the  value  and  resource  of  test.key1  is  changed  out  add  3  keys  to  the  existing  configuration  properties  add  resource  prop  get  close  check  for  other  keys  which  are  not  modified  later  test.key5  read  value  test.key6  test.key3  conf  dump  test.key4  set  length  programmatically  start  config  assert  equals  change  few  keys  in  another  resource  file  get  value  ${test.key5}  to  string  loaded  as  final  parameter  test.key1  and  expansion  of  properties  test.key2  value5  fileresource1  getresource  configuration  value2  value1  value4  value3  conf  jconf  put  config  getkey  getproperties  endconfig  testdumpconfiguration  dumpconfiguration  newvalue1  newvalue2  getisfinal   efficient retrieval  outwriter  fileresource   check for consistency in the number of properties parsed in json format.  defaultlength  jsonstr  mapper  config2  appendproperty   check if the value and resource of test.key1 is changed  out   add 3 keys to the existing configuration properties  addresource  prop  get  close   check for other keys which are not modified later  test.key5  readvalue  test.key6  test.key3  confdump  test.key4  set  length  programmatically  startconfig  assertequals   change few keys in another resource file  getvalue  ${test.key5}  tostring   loaded as final parameter  test.key1   and expansion of properties  test.key2
__label__flaky bundle  job  get  executor  add  record  to  bundle  action  table  get  time  add  record  to  bundle  job  table  with  paused  time  assert  false  test  bundle  rerun  in  paused  with  error  get  id  get  status  is  pending  pause  time  assert  not  null  get  curr  job  init  false  destroy  assert  equals  services  execute  add  record  to  coord  job  table  call  get  pause  time  services  coordinator  job  set  system  property  status  transit  service  action1  job  action2  jpa  service  bundlejobgetexecutor  addrecordtobundleactiontable  gettime  addrecordtobundlejobtablewithpausedtime  assertfalse  testbundlereruninpausedwitherror  getid  getstatus  ispending  pausetime  assertnotnull  get  curr  job  init  false  destroy  assertequals  services  execute  addrecordtocoordjobtable  call  getpausetime  services  coordinatorjob  setsystemproperty  statustransitservice  action1  job  action2  jpaservice
__label__nflaky get  current  user  zksm  new  dtinfo  conf  good  cancel  one  token   verify  it\'s  gone  assert  assert  not  null  fake  a  restart  which  launches  a  new  tm  canceled  dt  should  be  gone!  id  wait  for  user  group  information  info  init  id  cancelled  zk  server  log  the  cancelled  token  should  be  gone   and  not  loaded.  unchecked  generic  test  utils  destroy  create  token  cancel  token  zksm1  set  long  waiting  for  the  cancelled  token  to  be  removed  cancelled  connect  string  good  dt  should  be  in  memory!  delegation  token  manager  set  the  remove  scan  interval  to  remove  expired  tokens  verify  token  get  token  info  waiting  for  the  expired  token  to  be  removed...  wait  for  the  good  token  to  expire.  sleep  bla  get  get  delegation  token  secret  manager  sm  remove  scan  get  secret  conf  is  hard-coded  to  sleep  at  least  5  seconds.  sm  new  get  connect  string  the  good  token  should  be  loaded  on  startup   and  removed  after  expiry.  get  token  info  from  memory  token  thread  test  nodes  loaded  after  restart  zksm  assert  null  id1  tm  set  token  expire  time  to  5  seconds.  decode  token  identifier  getcurrentuser  zksmnew  dtinfo  conf  good   cancel one token  verify it\'s gone  assert  assertnotnull   fake a restart which launches a new tm  canceled dt should be gone!  id  waitfor  usergroupinformation  info  init  idcancelled  zkserver  log   the cancelled token should be gone  and not loaded.  unchecked  generictestutils  destroy  createtoken  canceltoken  zksm1  setlong  waiting for the cancelled token to be removed  cancelled  connectstring  good dt should be in memory!  delegationtokenmanager   set the remove scan interval to remove expired tokens  verifytoken  gettokeninfo  waiting for the expired token to be removed...   wait for the good token to expire.  sleep  bla  get  getdelegationtokensecretmanager  sm  removescan  getsecretconf   is hard-coded to sleep at least 5 seconds.  smnew  getconnectstring   the good token should be loaded on startup  and removed after expiry.  gettokeninfofrommemory  token  thread  testnodesloadedafterrestart  zksm  assertnull  id1  tm   set token expire time to 5 seconds.  decodetokenidentifier
__label__flaky coord  job10  test  count  add  record  to  bundle  action  table  get  num  days  to  not  be  purged  2009-07-01  t01:00  z  coord  job14  coord  job13  coord  job12  coord  job11  coord10  coord11  coord12  coord13  bundle  job  assert  not  null  2009-11-01  t01:00  z  job  coord1  2009-03-01  t01:00  z  coord14  coord2  coord3  coord4  coord5  2009-04-01  t01:00  z  coord6  coord7  coord8  coord9  coord  job8  coord  job9  execute  coord  job2  coordinator  job  coord  job3  coord  job1  coord  job6  coord  job7  coord  job4  coord  job5  2009-10-01  t01:00  z  2009-05-01  t01:00  z  test  purge  x  command  get  id  2009-01-01  t01:00  z  2009-08-01  t01:00  z  get  2008-11-01  t01:00  z  get  app  name  set  app  name  add  record  to  bundle  job  table  2009-02-01  t01:00  z  2009-06-01  t01:00  z  assert  equals  set  last  modified  time  get  last  modified  time  bundle  job  id  add  record  to  coord  job  table  services  2008-12-01  t01:00  z  2009-12-01  t01:00  z  days  jpa  service  2009-09-01  t01:00  z  coordjob10  testcount  addrecordtobundleactiontable  getnumdaystonotbepurged  2009-07-01t01:00z  coordjob14  coordjob13  coordjob12  coordjob11  coord10  coord11  coord12  coord13  bundlejob  assertnotnull  2009-11-01t01:00z  job  coord1  2009-03-01t01:00z  coord14  coord2  coord3  coord4  coord5  2009-04-01t01:00z  coord6  coord7  coord8  coord9  coordjob8  coordjob9  execute  coordjob2  coordinatorjob  coordjob3  coordjob1  coordjob6  coordjob7  coordjob4  coordjob5  2009-10-01t01:00z  2009-05-01t01:00z  testpurgexcommand  getid  2009-01-01t01:00z  2009-08-01t01:00z  get  2008-11-01t01:00z  getappname  setappname  addrecordtobundlejobtable  2009-02-01t01:00z  2009-06-01t01:00z  assertequals  setlastmodifiedtime  getlastmodifiedtime  bundlejobid  addrecordtocoordjobtable  services  2008-12-01t01:00z  2009-12-01t01:00z  days  jpaservice  2009-09-01t01:00z
__label__nflaky p1  p2  p3  get  name  p4  get  kms  url  kp  e  any  string  then  return  create  key  conf  any  when  fail  test3  mockito  assert  true  test  load  balancing  with  all  bad  nodes  mock  should  fail  since  all  providers  threw  an  io  exception  then  throw  p1  p2  p3  getname  p4  getkmsurl  kp  e  anystring  thenreturn  createkey  conf  any  when  fail  test3  mockito  asserttrue  testloadbalancingwithallbadnodes  mock  should fail since all providers threw an ioexception  thenthrow
__label__flaky test  caching  of  feature  state  features?user=ck  get  page  get  content  start  system  url  duration  contains  assert  true  current  time  millis  client  page  f1  =  false  without  cache:  500ms  *  10  =  5000ms  testcachingoffeaturestate  features?user=ck  getpage  getcontent  start  system  url  duration  contains  asserttrue  currenttimemillis  client  page  f1 = false   without cache: 500ms * 10 = 5000ms
__label__nflaky request  handler  assert  false  try  get  a  new  token  using  the  fetched  token   should  get  401.  get  method  when  token  str  assert  verify  test  cannot  get  token  using  token  op  pwriter  then  return  &  delegation  token  authenticator  get  query  string  http  servlet  response  set  status  management  operation  mockito  response  get  writer  get  token  mock  reset  get  http  method  to  string  writer  =  request  handler  assertfalse   try get a new token using the fetched token  should get 401.  getmethod  when  tokenstr  assert  verify  testcannotgettokenusingtoken  op  pwriter  thenreturn  &  delegationtokenauthenticator  getquerystring  httpservletresponse  setstatus  managementoperation  mockito  response  getwriter  gettoken  mock  reset  gethttpmethod  tostring  writer  =
__label__flaky /invoker.sh  system  duration  process  completed  in  is  family  unix  add  argument  sh  -c  executor  os.name  start  time  set  stream  handler  cmd  line  get  property  os  even  if  command  we\'ll  invoke  will  terminate  immediately.  set  stop  timeout  test  exec_57  test  dir  execute  the  test  \'test  sync  invocation  of  background  process\'  does  not  support  the  following  os  :  pump  stream  handler  millis;  above  is  its  output  fail  executing  current  time  millis  expecting  an  execute  exception  /invoker.sh  system  duration  process completed in   isfamilyunix  addargument  sh  -c  executor  os.name  starttime  setstreamhandler  cmdline  getproperty  os   even if command we\'ll invoke will terminate immediately.  setstoptimeout  testexec_57  testdir  execute  the test \'testsyncinvocationofbackgroundprocess\' does not support the following os :   pumpstreamhandler   millis; above is its output  fail  executing   currenttimemillis  expecting an executeexception
__label__nflaky get  dynamic  entry  assert  header  equals  no-cache  dynamic  table  custom-value  as  list  assert  array  equals  get  current  size  encode  headers  assert  :scheme  create  byte  array  https  cache-control  :authority  test  request  encoding  without  huffman  rfc7541  examples  custom-key  standard  charsets  clear  assert  equals  headers2  headers3  encoder  www.example.com  headers1  /  expected1  buf  expected3  expected2  :method  get  to  byte  array  http  :path  /index.html  arrays  dynamic  length  getdynamicentry  assertheaderequals  no-cache  dynamictable  custom-value  aslist  assertarrayequals  getcurrentsize  encodeheaders  assert  :scheme  createbytearray  https  cache-control  :authority  testrequestencodingwithouthuffmanrfc7541examples  custom-key  standardcharsets  clear  assertequals  headers2  headers3  encoder  www.example.com  headers1  /  expected1  buf  expected3  expected2  :method  get  tobytearray  http  :path  /index.html  arrays  dynamiclength
__label__flaky test  data  in  partition  min  init  res  hcat://hcat.server.com:5080/mydb/clicks/datastamp=10;region=us  coord  el  functions  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us   hcat://hcat.server.com:5080/mydb/clicks/datastamp=13;region=us   .datain.  abc.unresolved  set  variable  coord-action-start  eval  eval  and  wrap  assert  true  equals  .datain.  abc  expr  boolean  ${coord:data  in  partition  min(\'  abc\' \'datastamp\')}  10  testdatainpartitionmin  init  res  hcat://hcat.server.com:5080/mydb/clicks/datastamp=10;region=us  coordelfunctions  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us   hcat://hcat.server.com:5080/mydb/clicks/datastamp=13;region=us   .datain.abc.unresolved  setvariable  coord-action-start  eval  evalandwrap  asserttrue  equals  .datain.abc  expr  boolean  ${coord:datainpartitionmin(\'abc\' \'datastamp\')}  10
__label__nflaky io  exception  expected.  get  temp  path  create  an  empty  file  (which  is  not  a  valid  sequence  file)  expected  generic  test  utils  conf  fs  path  fail  file  sequence  file  assert  true  get  local  zerolength.seq  file  system  create  test  init  zero  length  sequence  file  close  ioexception expected.  gettemppath   create an empty file (which is not a valid sequence file)  expected  generictestutils  conf  fs  path  fail  file  sequencefile  asserttrue  getlocal  zerolength.seq  filesystem  create  testinitzerolengthsequencefile  close
__label__flaky unsupported  fs  layout  version  output  of  file  distribution  visitor  the  fsimage  file  once  and  use  it  for  multiple  tests.  delete  truncated  fs  image  original  fsimage  original  fs  image  shouldn\'t  be  null  output  of  ls  visitor  assert  not  null  exists  tests:  test  oiv  init  fsimage  unsupportedfslayoutversion  outputoffiledistributionvisitor   the fsimage file once and use it for multiple tests.  delete  truncatedfsimage  originalfsimage  originalfsimage shouldn\'t be null  outputoflsvisitor  assertnotnull  exists   tests:  testoiv  initfsimage
__label__nflaky transfer-  encoding  add  header  keep  alive  assert  false  connection  chunked  connection  takes  precedence  over  proxy-  connection  keep-alive  assert  yadda   close   dumdy  response  context  test  connection  tokens4  use  http  1.1  reuse  strategy  ok  proxy-  connection  transfer-encoding  addheader  keepalive  assertfalse  connection  chunked   connection takes precedence over proxy-connection  keep-alive  assert  yadda  close  dumdy  response  context  testconnectiontokens4   use http 1.1  reusestrategy  ok  proxy-connection
__label__flaky action  should  be  purged.  should  fail.  job  should  be  purged.  should  fail.  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  coord  job  get  executor  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  test  purge  service  for  coordinator  coord  action  get  executor  engine  assert  not  null  get  coordinator  action  action  purge  runnable  end  current  date  plus  month  wait  for  get  coord  job  a  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  coordinator  job  job  id  services  fail  coord-action-get.xml  u  job  jpa  service  evaluate  action should be purged. should fail.  job should be purged. should fail.  getcurrentdateafterincrementinginmonths  getid  run  dateutils  coordjobgetexecutor  getstatus  addrecordtocoordactiontable  parsedateoozietz  testpurgeserviceforcoordinator  coordactiongetexecutor  engine  assertnotnull  get  coordinatoraction  action  purgerunnable  end  currentdateplusmonth  waitfor  getcoordjob  a  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  coordinatorjob  jobid  services  fail  coord-action-get.xml  u  job  jpaservice  evaluate
__label__nflaky next  get  subject  get  current  user  set  last  login  assert  false  invoke  conf  has  sufficient  time  elapsed  30  seconds  before  \""now\""  system  2  minutes  before  \""now\""  iterator  assert  true  ugi  now  test  has  sufficient  time  elapsed  set  configuration  user  group  information  method  set  accessible  get  declared  method  conf2  get  principals  restore  original  conf  to  ugi  common  configuration  keys  public  15  minutes  before  \""now\""  make  has  sufficient  time  elapsed  public  set  long  restore  has  sufficient  tim  elapsed  back  to  private  current  time  millis  using  relogin  time  of  10  minutes  6  minutes  before  \""now\""  user  next  getsubject  getcurrentuser  setlastlogin  assertfalse  invoke  conf  hassufficienttimeelapsed   30 seconds before \""now\""  system   2 minutes before \""now\""  iterator  asserttrue  ugi  now  testhassufficienttimeelapsed  setconfiguration  usergroupinformation  method  setaccessible  getdeclaredmethod  conf2  getprincipals   restore original conf to ugi  commonconfigurationkeyspublic   15 minutes before \""now\""   make hassufficienttimeelapsed public  setlong   restore hassufficienttimelapsed back to private  currenttimemillis   using relogin time of 10 minutes   6 minutes before \""now\""  user
__label__flaky date  script  executor  session  given  update  simple  simplemap  eq  should_dsl_update_map_add  all  when  of  where  id  row  ten  table  execute  script  template  contains  entry  random  utils  manager  simple  map_  add  all  to  one  new_twenty  simple  map  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  get  map  has  size  then  long  build  date  key  from  base  table  dsl  select  simplemap  from  simple  where  id  =  thirty  date  scriptexecutor  session   given  update  simple  simplemap  eq  should_dsl_update_map_addall   when  of  where  id  row  ten  table  executescripttemplate  containsentry  randomutils  manager  simplemap_addallto  one  new_twenty  simplemap  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  getmap  hassize   then  long  builddatekey  frombasetable  dsl  select simplemap from simple where id =   thirty
__label__nflaky test  multi  threaded  decompressor  pool  submit  return  decompressor  executors  threadpool  put  time  unit  await  termination  lease_  count_  err  consumer  codec  pool  c  new  fixed  thread  pool  assert  equals  iterations  call  get  decompressor  take  codec  producer  wait  for  completion  get  leased  decompressors  count  queue  shutdown  dc  testmultithreadeddecompressorpool  submit  returndecompressor  executors  threadpool  put  timeunit  awaittermination  lease_count_err  consumer  codecpool  c  newfixedthreadpool  assertequals  iterations  call  getdecompressor  take  codec  producer   wait for completion  getleaseddecompressorscount  queue  shutdown  dc
__label__flaky fs001  fs002  viewfs  is  a  supported  scheme.  this  should  not  throw  exception  get  error  code  assert  true  bla  get  hdfs viewfs  testing  schemes  supported  hdfs://x/bla  init  ae  test  validate  path  destroy  get  message  assert  equals  validate  path  viewfs://bla  hadoop  accessor  service  fail  services  e0904  contains  ex  file://bla  set  system  property  file  is  not  a  supported  scheme.  this  should  throw  exception  fs001  fs002  viewfs is a supported scheme. this should not throw exception  geterrorcode  asserttrue  bla  get  hdfs viewfs   testing schemes supported  hdfs://x/bla  init  ae  testvalidatepath  destroy  getmessage  assertequals  validatepath  viewfs://bla  hadoopaccessorservice  fail  services  e0904  contains  ex  file://bla  setsystemproperty  file is not a supported scheme. this should throw exception
__label__nflaky json  document  then  return  format  body  parser  engine  json  equal  to  test  form  is  invoke  {\""first  name\"":\""\%s\""   \""last  name\"":\""\%s\""}  string  json  obj  mapper  assert  that  get  input  stream  when  get  bytes  mockito  assert  true  context  body  parser  engine  json  test  close  test  json  body  with  missing  variables  jsondocument  thenreturn  format  bodyparserenginejson  equalto  testform  is  invoke  {\""firstname\"":\""\%s\""  \""lastname\"":\""\%s\""}  string  jsonobjmapper  assertthat  getinputstream  when  getbytes  mockito  asserttrue  context  bodyparserenginejsontest  close  testjsonbodywithmissingvariables
__label__flaky cluster  set  security  manager  move  from  local  file  conf  run  f1  f2  as  list  check  permission  get  stack  trace  copy  multiple  files  to  destination  directory  data  node  should  not  be  here   must  got  io  exception  get  path  join  copy2nd  file  thread  mkdir  current  thread  create  local  file  destmultiple2  copy  local  destmultiple  stringify  exception  .f1.crc  get  file  system  test  put  done  get  security  manager  dfs  contains  num  data  nodes  use  security  manager  to  pause  the  copying  of  f1  and  begin  copying  f2  srcs  arrays  begin  get  uri  shutdown  copy  from  local  file  /test/putmultiple  dst  assert  false  show  move  multiple  files  to  destination  directory  fs  delete  system  sleep  remove  left  over  crc  files:  assert  true  test_  root_  dir  string  utils  to  remote  root  sm  file  util.copy  content  good  close  .f2.crc  /test/put  /test/movemultiple  start  pause  at  file  util.copy  content  not  a  hdfs:  thread  first  time  t  build  security  manager  =  exists  to  string  ioe    cluster  setsecuritymanager  movefromlocalfile  conf  run  f1  f2  aslist  checkpermission  getstacktrace   copy multiple files to destination directory  datanode   should not be here  must got ioexception  getpath  join  copy2ndfilethread  mkdir  currentthread  createlocalfile  destmultiple2  copy local   destmultiple  stringifyexception  .f1.crc  getfilesystem  testput  done  getsecuritymanager  dfs  contains  numdatanodes   use securitymanager to pause the copying of f1 and begin copying f2  srcs  arrays  begin  geturi  shutdown  copyfromlocalfile  /test/putmultiple  dst  assertfalse  show   move multiple files to destination directory  fs  delete  system  sleep   remove left over crc files:  asserttrue  test_root_dir  stringutils   to remote   root  sm  fileutil.copycontent  good   close  .f2.crc  /test/put  /test/movemultiple  start   pause at fileutil.copycontent  not a hdfs:   thread  firsttime  t  build  securitymanager =   exists  tostring  ioe
__label__nflaky check  the  header  quota  rem_  quota  space_  quota  test  get  header  header  assert  equals  rem_  space_  quota  quota  usage  get  header   check the header         quota       rem_quota     space_quota   testgetheader  header  assertequals  rem_space_quota   quotausage  getheader
__label__flaky prep  get  id  workflow  instance  action  get  cmd  coord  job  wf  bean  add  record  to  wf  job  table  assert  not  null  get  add  two  jobs  to  update  list  workflow  job  job  test  bulk  insert  updates  update  list  add  get  status  str  insert  list  running  wf  get  cmd  assert  equals  add  two  actions  to  insert  list  execute  add  record  to  coord  job  table  set  status  coordinator  job  1  services  2  workflow  action  bulk  update  cmd  succeeded  create  workflow  action  action1  job  action2  jpa  service  prep  getid  workflowinstance  actiongetcmd  coordjob  wfbean  addrecordtowfjobtable  assertnotnull  get   add two jobs to update list  workflowjob  job  testbulkinsertupdates  updatelist  add  getstatusstr  insertlist  running  wfgetcmd  assertequals   add two actions to insert list  execute  addrecordtocoordjobtable  setstatus  coordinatorjob  1  services  2  workflowaction  bulkupdatecmd  succeeded  createworkflowaction  action1  job  action2  jpaservice
__label__nflaky host4  assert  test  to  host  string  host1  to  host  string  host3  somehost  host2  somehost:8888  assert  equals  host4  assert  testtohoststring  host1  tohoststring  host3  somehost  host2  somehost:8888  assertequals
__label__flaky cluster  get  zkfc  proxy  start  conf  assert  equals  wait  for  active  lock  holder  get  service  thread  sleep  allow  to  quiesce  stop  graceful  failover  test  graceful  failover  cluster  getzkfcproxy  start  conf  assertequals  waitforactivelockholder  getservice  thread  sleep   allow to quiesce  stop  gracefulfailover  testgracefulfailover
__label__nflaky check  fatals  and  reset  test  handle  session  expiration  server  factory  ==========================  expiring  session  app  data  timeout  sleep  ensure  parent  z  node  verify  should  re-join  the  election  and  regain  active  close  session  wait  for  active  lock  data  ==========================  quitting  election  cb  info  get  server  due  to  receiving  the  \""expired\""  event.  let  the  first  elector  become  active  should  enter  neutral  mode  when  disconnected  zks  log  get  zk  session  id  for  tests  enter  neutral  mode  elector  active  standby  elector  test  util  quit  election  thread  never  cbs  mockito  become  active  join  election  electors  app  datas  parent_  dir  checkfatalsandreset  testhandlesessionexpiration  serverfactory  ========================== expiring session  appdata  timeout  sleep  ensureparentznode  verify   should re-join the election and regain active  closesession  waitforactivelockdata  ========================== quitting election  cb  info  getserver   due to receiving the \""expired\"" event.   let the first elector become active   should enter neutral mode when disconnected  zks  log  getzksessionidfortests  enterneutralmode  elector  activestandbyelectortestutil  quitelection  thread  never  cbs  mockito  becomeactive  joinelection  electors  appdatas  parent_dir
__label__flaky get  job  tracker  uri  launcher  id  get  name  get  job  id  <java>  conf  get  external  id  get  status  create  context  create  base  hadoop  conf  action  xml  is  successful  launcher  mapper  assert  true  context  end  wait  for  <job-tracker>  get  data  get  name  node  uri  </java>  ae  xml  utils  </main-class>  parse  xml  </job-tracker>  running  job  get  action  assert  equals  check  get  external  status  <name-node>  <main-class>  </name-node>  assert  null  workflow  action  test  recovery  running  job2  succeeded  submit  action  to  string  get  recovery  id  evaluate  get  action  dir  is  complete  getjobtrackeruri  launcherid  getname  getjobid  <java>  conf  getexternalid  getstatus  createcontext  createbasehadoopconf  actionxml  issuccessful  launchermapper  asserttrue  context  end  waitfor  <job-tracker>  getdata  getnamenodeuri  </java>  ae  xmlutils  </main-class>  parsexml  </job-tracker>  runningjob  getaction  assertequals  check  getexternalstatus  <name-node>  <main-class>  </name-node>  assertnull  workflowaction  testrecovery  runningjob2  succeeded  submitaction  tostring  getrecoveryid  evaluate  getactiondir  iscomplete
__label__nflaky get  value  get  name  assert  param  name  assert  equals  test  constructor  value  getvalue  getname  assert  param  name  assertequals  testconstructor  value
__label__flaky cluster  now  verify  that  it  shows  up  on  webui  http://  start  a  cluster  with  single  datanode  conf  warning  :  there  are  get  block  manager  get  under  replicated  blocks  count  create  file  wait  active  hdfs  front  page  does  not  contain  expected  warning  read  fully  1  missing  blocks  block  info  /dfshealth.jsp  dfs  config  keys  in  log  waiting  for  missing  blocks  count  to  be  zero...  dfs  front  page  get  file  system  waiting  for  missing  blocks  count  to  increase...  set  int  dfs  contains  hdfs  front  page  contains  unexpected  warning  read  the  file  so  that  the  corrupt  block  is  reported  to  nn  test  datanode  block  scanner  get  first  block  shutdown  get  under  replicated  not  missing  blocks  assert  false  bm  corrupt  file  delete  /test  missing  blocks  alert/file1  warn  str  test  missing  blocks  alert  sleep  get  missing  blocks  count  assert  true  get  corrupt  the  block  close  dfs  test  util  /test  missing  blocks/corrupt  file  assert  equals  minimize  test  delay  corrupt  replica  url  thread  file  len  build  url  get  blocks  to  go  to  zero  open  get  namesystem  create  a  normal  file  cluster   now verify that it shows up on webui  http://   start a cluster with single datanode  conf  warning : there are   getblockmanager  getunderreplicatedblockscount  createfile  waitactive  hdfs front page does not contain expected warning  readfully  1 missing blocks  block  info  /dfshealth.jsp  dfsconfigkeys  in  log  waiting for missing blocks count to be zero...  dfsfrontpage  getfilesystem  waiting for missing blocks count to increase...  setint  dfs  contains  hdfs front page contains unexpected warning   read the file so that the corrupt block is reported to nn  testdatanodeblockscanner  getfirstblock  shutdown  getunderreplicatednotmissingblocks  assertfalse  bm  corruptfile  delete  /testmissingblocksalert/file1  warnstr  testmissingblocksalert  sleep  getmissingblockscount  asserttrue  get   corrupt the block  close  dfstestutil  /testmissingblocks/corruptfile  assertequals   minimize test delay  corruptreplica  url  thread  filelen  build  urlget   blocks to go to zero  open  getnamesystem   create a normal file
__label__nflaky get  payload  content  read  payload1  payload2  frame1  value  of  frame2  get  stream  id  assert  equals  in  buffer  readable  channel  byte  buffer  test  read  frame  multiple  remaining  frame  flag  assert  allocate  get  type  assert  not  null  frame  type  get  of  get  flags  getpayloadcontent  read  payload1  payload2  frame1  valueof  frame2  getstreamid  assertequals  inbuffer  readablechannel  bytebuffer  testreadframemultiple  remaining  frameflag  assert  allocate  gettype  assertnotnull  frametype  get  of  getflags
__label__flaky i  nodes  in  path  ignore  \"".snapshot\""  get  name  resolve  inodes  get  modification  time  the  modification  time  of  the  i  node  for  file3  should  have  been  changed  create  file  ss  nodes  in  path  ss  inodes  assert  create  snapshot  nodes  in  path  get  path  names  s3  s4  modify  file1  allow  snapshot  last  the  last  i  node  should  be  associated  with  file1  pointing  to  a  snapshot  file  snapshot  file  node  test  snapshot  path  i  nodes  after  modification  first  check  the  i  node  for  /  test  snapshot/sub1/file1  new  inodes  i  node  get  path  components  components  append  file  get  path  snapshot  seed  sub1  /.snapshot/s3/file1  assert  false  file1  was  deleted   create  it  again.  check  the  i  nodes  for  snapshot  of  file1  the  content  for  appending  original  i  node  before  modification  replication  assert  snapshot  assert  true  dfs  test  util  check  the  i  node  for  /  test  snapshot/sub1/file1  again  new  nodes  in  path  assert  equals  the  number  of  inodes  should  be  equal  to  components.length  get  snapshot  get  full  path  name  snapshot  path  names  fsdir  get  local  name  hdfs  to  string  check  the  i  node  for  snapshot  of  file1  file1  get  i  nodes  inodesinpath   ignore \"".snapshot\""  getname  resolve  inodes  getmodificationtime   the modification time of the inode for file3 should have been changed  createfile  ssnodesinpath  ssinodes  assert  createsnapshot  nodesinpath  getpathnames  s3  s4   modify file1  allowsnapshot  last   the last inode should be associated with file1   pointing to a snapshot file  snapshotfilenode  testsnapshotpathinodesaftermodification   first check the inode for /testsnapshot/sub1/file1  newinodes  inode  getpathcomponents  components  appendfile  getpathsnapshot  seed  sub1  /.snapshot/s3/file1  assertfalse   file1 was deleted  create it again.   check the inodes for snapshot of file1  the content for appending   original inode before modification  replication  assertsnapshot  asserttrue  dfstestutil   check the inode for /testsnapshot/sub1/file1 again  newnodesinpath  assertequals   the number of inodes should be equal to components.length  getsnapshot  getfullpathname  snapshotpath  names  fsdir  getlocalname  hdfs  tostring   check the inode for snapshot of file1  file1  getinodes
__label__nflaky request  core  matchers  equal  to  test  mode  works.  assert  that  make  request  url  test  test  mode  index  path  assert  /base/middle/app/mode/test  response  get  test  server  url  request  corematchers  equalto  test mode works.  assertthat  makerequest  url  testtestmodeindex  path  assert  /base/middle/app/mode/test  response  get  testserverurl
__label__flaky nn  cluster  name  node  adapter  assert  false  /test-  set  the  cluster  to  leave  safemode  quickly  on  its  own.  fs  create  file  secret  manager  should  start  when  safe  mode  is  exited  enter  safe  mode  get  configuration  assert  true  secret  manager  should  not  run  in  safe  mode  is  running  is  manually  entered  startup  option  sm  info  get  dt  secret  manager  dfs  test  util  start  data  nodes  dfs  config  keys  log  restart  name  node  get  file  system  is  in  safe  mode  set  int  get  name  node  =========  entering  safemode  again  test  dt  manager  in  safe  mode  leave  safe  mode  config  set  wait  safe  mode  secret  manager  should  stop  again  when  safe  mode  get  namesystem  nn  cluster  namenodeadapter  assertfalse  /test-   set the cluster to leave safemode quickly on its own.  fs  createfile  secret manager should start when safe mode is exited  entersafemode  getconfiguration  asserttrue  secret manager should not run in safe mode  isrunning  is manually entered  startupoption  sm  info  getdtsecretmanager  dfstestutil  startdatanodes  dfsconfigkeys  log  restartnamenode  getfilesystem  isinsafemode  setint  getnamenode  ========= entering safemode again  testdtmanagerinsafemode  leavesafemode  config  setwaitsafemode  secret manager should stop again when safe mode   getnamesystem
__label__nflaky 00  01  02  03  04  05  06  07  08  09  hit  assert  maroon  1   6   7   8   10  has  next  oran  ge  0  0a  1  0b  2  0c  3  0d  4  0e  5  yellow  6  7  8  9  next  assert  false  yellow  without  filter  assert  true  headers  a  b  c  d  e  assert  equals  test  interspersed  yellow  0   5   9   11   13  orange  orange  2   3   4   12   14  maroon  mar  o  on  00  01  02  03  04  05  06  07  08  09  hit  assert   maroon 1  6  7  8  10  hasnext  orange  0  0a  1  0b  2  0c  3  0d  4  0e  5  yellow  6  7  8  9  next  assertfalse  yellow   without filter  asserttrue  headers  a  b  c  d  e  assertequals  testinterspersed   yellow 0  5  9  11  13  orange   orange 2  3  4  12  14  maroon  maroon
__label__flaky new  simple  statement  exception  select  *  from  entity_with_clusterings  where  id  =  :id  manager  session  query  given  expect  message  expect  the  typed  query  select  *  from  entity_with_clusterings  where  id  =  :id  should  contain  the  table  name  \'simple\'  if  the  entity  type  is  \'info.archinnov.achilles.internals.entities.  simple  entity\'  when  typed  query  for  select  get  list  statement  should_fail_regular_typed_query_if_table_not_correspond  newsimplestatement  exception  select * from entity_with_clusterings where id = :id  manager  session  query   given  expectmessage  expect  the typed query select * from entity_with_clusterings where id = :id should contain the table name \'simple\' if the entity type is \'info.archinnov.achilles.internals.entities.simpleentity\'   when  typedqueryforselect  getlist  statement  should_fail_regular_typed_query_if_table_not_correspond
__label__nflaky read  dst  standard  charsets  has  remaining  channel  10  1234567890123456  decoder  byte  buffer  5  12345  5  12345  test  missing  last  crlf  allocate  inbuf  metrics  is  completed  read  dst  standardcharsets  hasremaining  channel  10  1234567890123456    decoder  bytebuffer  5  12345  5  12345  testmissinglastcrlf  allocate  inbuf  metrics  iscompleted
__label__flaky write  some  more  data  and  flush  cluster  init  buffer  still  have  interrupted  status.  assert  false  got  expected  exception  during  flush  conf  /hflush-interrupted  test  h  flush  interrupted  p=  fs  system  create  file  hflush  assert  true  interrupt  failed  to  deal  with  thread  interruptions  create  a  new  file.  write  close  current  thread  try  again  to  flush  should  succeed  since  we  no  longer  have  interrupt  status  got  expected  exception  during  close  get  file  system  interrupted  file  contents  stm  append  test  util  thread  check  full  file  verify  that  entire  file  is  good  file  len  p  now  do  a  successful  close.  build  num  data  nodes  datanode_  num  if  we  got  the  exception   we  shouldn\'t  have  interrupted  status  anymore.  write  some  data  and  close  while  interrupted  shutdown   write some more data and flush  cluster  initbuffer   still have interrupted status.  assertfalse  got expected exception during flush  conf  /hflush-interrupted  testhflushinterrupted  p=  fs  system  createfile  hflush  asserttrue  interrupt  failed to deal with thread interruptions   create a new file.  write  close  currentthread   try again to flush should succeed since we no longer have interrupt status  got expected exception during close  getfilesystem  interrupted  filecontents  stm  appendtestutil  thread  checkfullfile   verify that entire file is good  filelen  p   now do a successful close.  build  numdatanodes  datanode_num   if we got the exception  we shouldn\'t have interrupted status anymore.   write some data and close while interrupted  shutdown
__label__nflaky server  server  assert  return  values  start  conf  assert  equals  run  override  client  to  store  the  call  id  side  we  should  see  retry  count  as  0  test  initial  call  retry  count  get  connect  address  attach  a  listener  that  tracks  every  call  id  received  by  the  server.  caller  assert  net  utils  stop  client  get  call  retry  count  addr  server  server  assertreturnvalues  start  conf  assertequals  run   override client to store the call id   side we should see retry count as 0  testinitialcallretrycount  getconnectaddress   attach a listener that tracks every call id received by the server.  caller  assert  netutils  stop  client  getcallretrycount  addr
__label__flaky init  ${coord:tz  offset()}  test  tz  offset  eval.set  variable(\""resolve_tz  offset\""   \""true\"");  coord  el  functions  get  time  zone  america/  new_  york  -180  assert  equals  coord-action-create  date  utils  app  inst  ds  0  eval  eval  and  wrap  configure  evaluator  set  time  zone  expr  init  ${coord:tzoffset()}  testtzoffset   eval.setvariable(\""resolve_tzoffset\""  \""true\"");  coordelfunctions  gettimezone  america/new_york  -180  assertequals  coord-action-create  dateutils  appinst  ds  0  eval  evalandwrap  configureevaluator  settimezone  expr
__label__nflaky server  http://  conn  get  log  cookies  /echo  get  host  port  string  get  connector  address  assert  assert  true  get  set-  cookie  ;  expires=  info  test  persistent  cookie  print  stack  trace  e  log  open  connection  is  empty  parse  auto-generated  catch  block  token  get  value  get  header  field  contains  net  utils  start  server  equals  header  http  cookie  base  server  http://  conn  getlog  cookies  /echo  gethostportstring  getconnectoraddress  assert  asserttrue  get  set-cookie  ; expires=  info  testpersistentcookie  printstacktrace  e  log  openconnection  isempty  parse   auto-generated catch block  token  getvalue  getheaderfield  contains  netutils  startserver  equals  header  httpcookie  base
__label__flaky assert  false  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  get  external  id  workflow  instance  get  status  is  pending  add  record  to  coord  action  table  parse  date  oozie  tz  coord  job  sleep  add  record  to  wf  job  table  assert  not  null  get  coordinator  action  end  current  date  plus  month  workflow  job  job  wait  for  coord  action1_1  coord  action1_2  coord  job  id  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  call  services  coordinator  job  coord  job  get  cmd  runnable  coord-action-get.xml  coord  job1  equals  test  coord  status  transit  service  suspend  and  resume  job  jpa  service  evaluate  assertfalse  getcurrentdateafterincrementinginmonths  getid  run  dateutils  getexternalid  workflowinstance  getstatus  ispending  addrecordtocoordactiontable  parsedateoozietz  coordjob  sleep  addrecordtowfjobtable  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  workflowjob  job  waitfor  coordaction1_1  coordaction1_2  coordjobid  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  call  services  coordinatorjob  coordjobgetcmd  runnable  coord-action-get.xml  coordjob1  equals  testcoordstatustransitservicesuspendandresume  job  jpaservice  evaluate
__label__nflaky result  get  invocation  count  test  eventually  once  lambda  eventually  assert  equals  retry  result  getinvocationcount  testeventuallyoncelambda  eventually  assertequals  retry
__label__flaky add  record  to  bundle  action  table  get  id  coord  action  b  add  record  to  coord  action  table  bundle  job  a  bundle  job  b  children  assert  not  null  bundle  action  b  get  coordinator  action  something_different  job  coord  job  b  get  app  name  set  app  name  add  record  to  bundle  job  table  execute  add  record  to  coord  job  table  check  children  services  coordinator  job  coord  action  a2  coord-action-get.xml  test  get  bundle  parent  coord  action  a1  add  all  bundle  action  a1  bundle  action  a2  jpa  service  coord  job  a2  coord  job  a1  addrecordtobundleactiontable  getid  coordactionb  addrecordtocoordactiontable  bundlejoba  bundlejobb  children  assertnotnull  bundleactionb  get  coordinatoraction  something_different  job  coordjobb  getappname  setappname  addrecordtobundlejobtable  execute  addrecordtocoordjobtable  checkchildren  services  coordinatorjob  coordactiona2  coord-action-get.xml  testgetbundleparent  coordactiona1  addall  bundleactiona1  bundleactiona2  jpaservice  coordjoba2  coordjoba1
__label__nflaky conn  log  assert  false  is  empty  get  connection  with  ssl  socket  factory  excluded  cipher  list  is  empty  no  ciphers  in  common   ssl  handshake  must  fail.  url  read  from  connection  fail  base  url  ex  servlet_  path_  echo  test  excluded  ciphers  excluded_  ciphers  ?a=b&c=d  no  ciphers  in  common   expected  successful  test  result.  info  conn  log  assertfalse  isempty  getconnectionwithsslsocketfactory  excludedcipher list is empty  no ciphers in common  sslhandshake must fail.  url  readfromconnection  fail  baseurl  ex  servlet_path_echo  testexcludedciphers  excluded_ciphers  ?a=b&c=d  no ciphers in common  expected successful test result.  info
__label__flaky cluster  .  meta.  get  region  server  threads  conf  test  info  servers  are  up  master  get  region  server  assert  has  expected  content  regionserver  get  port  http://localhost:  port  get  /index.html  get  master  get  info  server  give  the  cluster  time  to  start  up  cluster  .meta.  getregionserverthreads  conf  testinfoserversareup  master  getregionserver  asserthasexpectedcontent  regionserver  getport  http://localhost:  port  get  /index.html  getmaster  getinfoserver   give the cluster time to start up
__label__nflaky test  splitable  codec  test  splitable  codecs  testsplitablecodec  testsplitablecodecs
__label__flaky next  submit  values  get  report  no  of  attempts  is  not  correct  wait  for  state  get  attempts  get  task  attempt  state  blocked  iterator  assert  job  state  get  task  state  latch  count  down  tasks  wait  and  vailidate  for  job  to  become  running  attempts  app  job  event  type  get  event  handler  send  the  kill  signal  to  job  test  kill  job  get  id  handle  assert  equals  it  attempt  state  not  correct  unblock  task  task  task  state  not  correct  size  task  attempt  state  wait  and  validate  for  job  to  be  killed  get  tasks  job  no  of  tasks  is  not  correct  get  context  task  state  next  submit  values  getreport  no of attempts is not correct  waitforstate  getattempts  gettaskattemptstate   blocked  iterator  assert  jobstate  gettaskstate  latch  countdown  tasks   wait and vailidate for job to become running  attempts  app  jobeventtype  geteventhandler   send the kill signal to job  testkilljob  getid  handle  assertequals  it  attempt state not correct   unblock task  task  task state not correct  size  taskattemptstate   wait and validate for job to be killed  gettasks  job  no of tasks is not correct  getcontext  taskstate
__label__nflaky add  token  one  duplicate  with  different  value   one  new  get  secret  key  number  of  secret  keys  new  token  &  secret  should  be  added  assert  equals  secret  creds  non-duplicate  token  &  secret  should  be  present  get  bytes  token  add  all  number  of  tokens  service  creds  to  add  get  token  add  secret  key  existing  token  &  secret  should  be  overwritten  addtoken   one duplicate with different value  one new  getsecretkey  numberofsecretkeys   new token & secret should be added  assertequals  secret  creds   non-duplicate token & secret should be present  getbytes  token  addall  numberoftokens  service  credstoadd  gettoken  addsecretkey   existing token & secret should be overwritten
__label__flaky test  feature  reflection  equals  set  strategy  id  user1   user2   user3  is  assert  that  get  feature  state  feature  state  without  strategy  loaded  feature  state  saved  feature  state  set  parameter  set  feature  state  save  same  feature   but  without  activation  strategy.  should  remove  an  existing  one  username  activation  strategy  state  repository  test  removing  of  activation  strategy  testfeature  reflectionequals  setstrategyid  user1  user2  user3  is  assertthat  getfeaturestate  featurestatewithoutstrategy  loadedfeaturestate  savedfeaturestate  setparameter  setfeaturestate   save same feature  but without activation strategy. should remove an existing one  usernameactivationstrategy  staterepository  testremovingofactivationstrategy
__label__nflaky server  server  conf  run  get  class  loader  set  call  id  and  retry  count  test  invocation  handler  10000  times  runs  about  6s  on  a  core  i7  machine  proxy  assert  test  retry  proxy  retry  policies  client  get  call  retry  count  create  client  dummy  run  retry  count  new  proxy  instance  start  assert  equals  retry  proxy  proxy  total  retry  stop  retry  proxy  server  server  conf  run  getclassloader  setcallidandretrycount  testinvocationhandler   10000 times runs about 6s on a core i7 machine  proxy  assert  testretryproxy  retrypolicies  client  getcallretrycount  create  client  dummyrun  retrycount  newproxyinstance  start  assertequals  retryproxy  proxy  totalretry  stop  retryproxy
__label__flaky exec_  order  callable2  test  queue  uniqueness  with  diff  key  in  composite  callable3  callables  callable1  c  type  queue  serial  as  list  queueservice  queue  uniqueness  with  diff  key  in  composite3  services  queue  uniqueness  with  diff  key  in  composite  assert  true  queue  uniqueness  with  diff  key  in  composite2  queue  uniqueness  with  diff  key  in  composite1  get  arrays  evaluate  wait  for  exec_order  callable2  testqueueuniquenesswithdiffkeyincomposite  callable3  callables  callable1  c  type  queueserial  aslist  queueservice  queueuniquenesswithdiffkeyincomposite3  services  queueuniquenesswithdiffkeyincomposite  asserttrue  queueuniquenesswithdiffkeyincomposite2  queueuniquenesswithdiffkeyincomposite1  get  arrays  evaluate  waitfor
__label__nflaky bytes  get  text  ascii  double  digit  (00  -  99)  numeric  value  +  130  decoded  bit  stream  parser  00019899  assert  equals  decode  decoded  string  test  ascii  double  digit  decode  bytes  gettext   ascii double digit (00 - 99) numeric value + 130  decodedbitstreamparser  00019899  assertequals  decode  decodedstring  testasciidoubledigitdecode
__label__flaky coord  job  bean  coord  action  get  cmd  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  workflow  instance  get  status  is  pending  add  record  to  coord  action  table  parse  date  oozie  tz  coord  job  wf  job  wf  bean  add  record  to  wf  job  table  assert  not  null  get  coordinator  action  end  current  date  plus  month  workflow  job  wait  for  killed  get  status  str  running  wf  get  cmd  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  call  services  coordinator  job  coord  job  get  cmd  runnable  wf  job  id  coord-action-get.xml  coord  action  equals  in  following  assertion  not  failing.  test  coord  status  transit  service  killed  by  user1  jpa  service  evaluate  coordjobbean  coordactiongetcmd  getcurrentdateafterincrementinginmonths  getid  run  dateutils  workflowinstance  getstatus  ispending  addrecordtocoordactiontable  parsedateoozietz  coordjob  wfjob  wfbean  addrecordtowfjobtable  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  workflowjob  waitfor  killed  getstatusstr  running  wfgetcmd  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  call  services  coordinatorjob  coordjobgetcmd  runnable  wfjobid  coord-action-get.xml  coordaction  equals   in following assertion not failing.  testcoordstatustransitservicekilledbyuser1  jpaservice  evaluate
__label__nflaky rw  assert  false  channel  get  bytes  head  assert  get  channel  write  line  dump  chbuffer  close  write  fchannel  test  coding  from  file  channel  saturated  is  completed  testfile  standard  charsets  create  temp  file  assert  equals  encoder  transfer  outbuf  header  metrics  append  stuff  rw  assertfalse  channel  getbytes  head  assert  getchannel  writeline  dump  chbuffer  close  write  fchannel  testcodingfromfilechannelsaturated  iscompleted  testfile  standardcharsets  createtempfile  assertequals  encoder  transfer  outbuf  header  metrics  append  stuff
__label__flaky headers  get  server  address  test  that  meta  inf  integration  works  ninja  test  browser  new  hash  map  assert  equals  assets/webjars/bootstrap/3.0.0/css/bootstrap.min.css  some  empty  headers  for  now...  make  request  and  get  response  maps  /redirect  will  send  a  location:  redirect  in  the  headers  get  status  code  get  status  line  http  response  headers  getserveraddress  testthatmetainfintegrationworks  ninjatestbrowser  newhashmap  assertequals  assets/webjars/bootstrap/3.0.0/css/bootstrap.min.css   some empty headers for now...  makerequestandgetresponse  maps   /redirect will send a location: redirect in the headers  getstatuscode  getstatusline  httpresponse
__label__nflaky get  value  from  unix  milliseconds  assert  current  time  millis  deadline  now  plus  one  min  assert  equals  deadline  system  test  value  getvalue  fromunixmilliseconds  assert  currenttimemillis  deadline  nowplusonemin  assertequals  deadline  system  testvalue
__label__flaky bundle  job  get  executor  c  job1  add  record  to  bundle  action  table  get  time  pause  start  runnable  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  get  status  parse  date  oozie  tz  test  pause  bundle  and  coordinator  set  pause  time  pause  time  assert  not  null  get  set  bundle  id  end  current  date  plus  month  job  wait  for  b  job1  bundle  action1  bundle  action2  add  record  to  bundle  job  table  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  coord  job2  services  coordinator  job  job  id  coord  job1  coord  job  id1  coord  job  id2  action1  job  action2  jpa  service  evaluate  bundlejobgetexecutor  cjob1  addrecordtobundleactiontable  gettime  pausestartrunnable  getcurrentdateafterincrementinginmonths  getid  run  dateutils  getstatus  parsedateoozietz  testpausebundleandcoordinator  setpausetime  pausetime  assertnotnull  get  setbundleid  end  currentdateplusmonth  job  waitfor  bjob1  bundleaction1  bundleaction2  addrecordtobundlejobtable  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  coordjob2  services  coordinatorjob  jobid  coordjob1  coordjobid1  coordjobid2  action1  job  action2  jpaservice  evaluate
__label__nflaky bin:x:2:2:bin:/bin:/bin/sh  get_  all_  groups_  cmd  bin  assume  not  windows  hdfs:x:11502:10788:  grid  distributed  file  system:/home/hdfs:/bin/bash  daemon:x:2:2:daemon:/sbin:/sbin/nologin\""  hdfs2:x:11502:10787:  grid  distributed  file  system:/home/hdfs:/bin/bash  hash  bi  map  u  map  |  cut  -d:  -f1 3  echo  \""hdfs:*:11501:hrt_hdfs  daemon:x:1:1:daemon:/usr/sbin:/bin/sh  mapred:x:497  assert  true  root  get  create  g  map  echo  \""root:x:0:0:root:/root:/bin/bash  group  mapred3:x:498\""  test  duplicates  hdfs2  hdfs1:x:11501:10787:  grid  distributed  file  system:/home/hdfs:/bin/bash  get_  all_  users_  cmd  assert  equals  daemon  bin:x:1:1:bin:/bin:/sbin/nologin  mapred3  mapred:x:498  size  hdfs:x:11501:10787:  grid  distributed  file  system:/home/hdfs:/bin/bash  shell  based  id  mapping  hdfs  :  mapred2:x:497  maps  for  id  to  name  map  user  empty_  pass_  through_  map  mapred  update  map  internal  bin:x:2:2:bin:/bin:/bin/sh    get_all_groups_cmd  bin  assumenotwindows  hdfs:x:11502:10788:grid distributed file system:/home/hdfs:/bin/bash    daemon:x:2:2:daemon:/sbin:/sbin/nologin\""  hdfs2:x:11502:10787:grid distributed file system:/home/hdfs:/bin/bash    hashbimap  umap   | cut -d: -f1 3  echo \""hdfs:*:11501:hrt_hdfs    daemon:x:1:1:daemon:/usr/sbin:/bin/sh    mapred:x:497    asserttrue  root  get  create  gmap  echo \""root:x:0:0:root:/root:/bin/bash    group  mapred3:x:498\""  testduplicates  hdfs2  hdfs1:x:11501:10787:grid distributed file system:/home/hdfs:/bin/bash    get_all_users_cmd  assertequals  daemon  bin:x:1:1:bin:/bin:/sbin/nologin    mapred3  mapred:x:498    size  hdfs:x:11501:10787:grid distributed file system:/home/hdfs:/bin/bash    shellbasedidmapping  hdfs  :  mapred2:x:497     maps for id to name map  user  empty_pass_through_map  mapred  updatemapinternal
__label__flaky test  coord  suspend  with  error  and  resume  with  error  for  running  get  id  assert  equals  get  status  execute  add  record  to  coord  job  table  call  coordinator  job  services  coord  job  get  cmd  assert  not  null  get  job  jpa  service  testcoordsuspendwitherrorandresumewitherrorforrunning  getid  assertequals  getstatus  execute  addrecordtocoordjobtable  call  coordinatorjob  services  coordjobgetcmd  assertnotnull  get  job  jpaservice
__label__nflaky byte  at  assert  false  length  is  empty  clear  assert  equals  capacity  b1  b2  assert  assert  true  assert  not  null  tmp  to  byte  array  buffer  is  full  test  simple  append  append  byteat  assertfalse  length  isempty  clear  assertequals  capacity  b1  b2  assert  asserttrue  assertnotnull  tmp  tobytearray  buffer  isfull  testsimpleappend  append
__label__flaky wf  get  cmd  get  id  workflow  instance  first  update;  test  workflow  job  delete  execute  set  status  jpa  executor  exception  should  be  thrown  because  job  has  been  deleted.  services  fail  wf  bean  add  record  to  wf  job  table  assert  not  null  get  wf  delete  cmd1  workflow  job  job  jpa  service  wfgetcmd  getid  workflowinstance   first update;  testworkflowjobdelete  execute  setstatus  jpaexecutorexception should be thrown because job has been deleted.  services  fail  wfbean  addrecordtowfjobtable  assertnotnull  get  wfdeletecmd1  workflowjob  job  jpaservice
__label__nflaky srowen@example.org  do  test  mailto:bob@example.org?cc=foo@example.org&bcc=srowen@example.org&subject=baz&body=buzz  foo@example.org  test  all  baz  buzz  bob@example.org  srowen@example.org  dotest  mailto:bob@example.org?cc=foo@example.org&bcc=srowen@example.org&subject=baz&body=buzz  foo@example.org  testall  baz  buzz  bob@example.org
__label__flaky get  time  conf  date  utils  app  path  cal  write  to  file  nominal  for  start_miss  assert  not  null  get  workflow.xml  set  time  nominal_time  add  nominal  time  set  sla_  xml_1  calendar  services  _test  workflow  job  commands  ehs  oozie  client  get  test  user  format  date  oozie  tz  to  string  test  sla  schema1  backward  compatibility  slas  get  fs  test  case  dir  gettime  conf  dateutils  apppath  cal  writetofile  nominal   for start_miss  assertnotnull  get  workflow.xml  settime  nominal_time  add  nominaltime  set  sla_xml_1  calendar  services  _testworkflowjobcommands  ehs  oozieclient  gettestuser  formatdateoozietz  tostring  testslaschema1backwardcompatibility  slas  getfstestcasedir
__label__nflaky format  date  dtend:20080505  end:  vevent  begin:  vevent  summary:foo  dtstart:20080504  t123456  start  time  only  parsed  result  type  begin:  veventsummary:  event  dtstart:20081030  t122030  zdtend:20081030  t132030  zend:  vevent  begin:  vevent  dtend:20080505  t  end:  vevent  dtend:20080505  t234555  z  end:  vevent  local  times  begin:  vevent  summary:foo  dtstart:20080504  t123456  z  end:  vevent  dtend:20080505  t234555  end:  vevent  make  sure  illegal  entries  without  newlines  don\'t  crash  format  time  do  test  result  utc  times  begin:  vevent  summary:foo  dtstart:20080504  end:  vevent  test  v  event  foo  begin:  vevent  summary:foo  dtstart:20080504  t123456  z  begin:  vevent  summary:foo  dtstart:20080504  begin:  vevent  summary:foo  dtstart:20080504  t123456  end:  vevent  date  only  (all  day  event)  dtend:20080505  t234555  z  end:  vevent  end:  vcalendar  begin:  vcalendar  begin:  vevent  summary:foo  dtstart:20080504  t123456  z  formatdate  dtend:20080505  end:vevent  begin:vevent  summary:foo  dtstart:20080504t123456     start time only  parsedresulttype      begin:veventsummary:eventdtstart:20081030t122030zdtend:20081030t132030zend:vevent  begin:vevent  dtend:20080505t  end:vevent  dtend:20080505t234555z  end:vevent   local times  begin:vevent  summary:foo  dtstart:20080504t123456z  end:vevent  dtend:20080505t234555  end:vevent   make sure illegal entries without newlines don\'t crash  formattime  dotestresult   utc times  begin:vevent  summary:foo  dtstart:20080504  end:vevent  testvevent  foo    begin:vevent  summary:foo  dtstart:20080504t123456z    begin:vevent  summary:foo  dtstart:20080504    begin:vevent  summary:foo  dtstart:20080504t123456  end:vevent   date only (all day event)  dtend:20080505t234555z  end:vevent  end:vcalendar  begin:vcalendar  begin:vevent  summary:foo  dtstart:20080504t123456z
__label__flaky action  num  coordinator  job  job  id  coord-action-get.xml  test  coord  actions  not  completeted  for  size  coordinator  action  _test  coord  actions  not  completed  size  get  id  job  add  record  to  coord  action  table  *  add  2  coordinator  actions  which  are  not  completed  (status  as  running  and  waiting)  and  add  2  coordinator  actions  *  which  are  completed  (status  as  failed  and  killed).  then  check  for  expected  number  of  actions  retrieved.  add  record  to  coord  job  table  actionnum  coordinatorjob  jobid  coord-action-get.xml  testcoordactionsnotcompletetedforsize  coordinatoraction  _testcoordactionsnotcompletedsize  getid  job  addrecordtocoordactiontable         * add 2 coordinator actions which are not completed (status as running and waiting) and add 2 coordinator actions       * which are completed (status as failed and killed). then check for expected number of actions retrieved.         addrecordtocoordjobtable
__label__nflaky test  delegation  token  authenticator  calls  with  header  test  delegation  token  authenticator  calls  testdelegationtokenauthenticatorcallswithheader  testdelegationtokenauthenticatorcalls
__label__flaky test  coord  action  get  get  coord  conf  get  id  conf  date  utils  replace  all  app  path  parse  date  oozie  tz  resource  xml  name  action  xml  coord  action  nominal  time  pass  the  expected  values  get  test  case  dir  coordinator  action  action  set  created  time  miss  deps  action  num  pretty  print  xml  utils  #test  dir  get  action  nominal  time  test  dir  set  missing  dependencies  add  record  to  coord  job  table  add  miss  deps  attribute  to  action  coordinator  job  create  coord  action  coord-action-get.xml  file://#test  dir/2009/29/_  success#file://#test  dir/2009/22/_  success#file://#test  dir/2009/15/_  success#file://#test  dir/2009/08/_  success  _test  get  for  input  check  x  dummy  creation  time  insert  the  action  insert  record  coord  action  to  string  job  get  coord  action  xml  get  fs  test  case  dir  testcoordactionget  getcoordconf  getid  conf  dateutils  replaceall  apppath  parsedateoozietz  resourcexmlname  actionxml  coord  actionnominaltime   pass the expected values  gettestcasedir  coordinatoraction  action  setcreatedtime  missdeps  actionnum  prettyprint  xmlutils  #testdir  getactionnominaltime  testdir  setmissingdependencies  addrecordtocoordjobtable   add missdeps attribute to action  coordinatorjob  createcoordaction  coord-action-get.xml  file://#testdir/2009/29/_success#file://#testdir/2009/22/_success#file://#testdir/2009/15/_success#file://#testdir/2009/08/_success  _testgetforinputcheckx  dummycreationtime   insert the action  insertrecordcoordaction  tostring  job  getcoordactionxml  getfstestcasedir
__label__nflaky tel:212  555  1212  +15551212  parsed  result  type  do  test  result  telephone  212  555  1212  2125551212  tel:+15551212  212-555-1212  tel  tel:+15551212  tel:2125551212  tel:212-555-1212  test  tel  tel:212 555 1212  +15551212  parsedresulttype  dotestresult  telephone  212 555 1212  2125551212  tel:+15551212  212-555-1212  tel  tel:+15551212  tel:2125551212  tel:212-555-1212  testtel
__label__flaky action  dir  delete  the  file  if  it  is  already  there  </prepare>  do  operations  conf  get  file  system  fs  delete  prepare  block  that  contains  mkdir  action  create  job  conf  test  for  mkdir  as  prepare  action  launcher  mapper  assert  true  new  dir  <prepare>  <mkdir  path=\'  \'/>  prepare  xml  exists  test  mkdir  setup  launcher  uri  handler  conf  prepare  actions  driver  get  fs  test  case  dir  actiondir   delete the file if it is already there  </prepare>  dooperations  conf  getfilesystem  fs  delete   prepare block that contains mkdir action  createjobconf   test for mkdir as prepare action  launchermapper  asserttrue  newdir  <prepare>  <mkdir path=\'  \'/>  preparexml  exists  testmkdir  setuplauncherurihandlerconf  prepareactionsdriver  getfstestcasedir
__label__nflaky file  resource1  keys  (both  deprecated  and  new)  j1  conf  f1  b1  config  add  the  corresponding  old/new  keys  of  those  added  to  config1  add  deprecation  to  configuration  end  config  g1  c1  file  resource  a  b  c  d  e  f  g  h  i  h1  j  config2  config3  d1  append  property  out  add  resource  get  5.new  key  which  is  final  and  has  null  value.  a  b  c  d  e  f  g  h  i1  start  config  assert  equals  e1  a1  assert  null  test  deprecation  for  final  parameters    fileresource1   keys (both deprecated and new)  j1  conf  f1  b1  config   add the corresponding old/new keys of those added to config1  adddeprecationtoconfiguration  endconfig  g1  c1  fileresource  a  b  c  d  e  f  g  h  i  h1  j  config2  config3  d1  appendproperty  out  addresource  get   5.new key which is final and has null value.  a  b  c  d  e  f  g  h  i1  startconfig  assertequals  e1  a1  assertnull  testdeprecationforfinalparameters
__label__flaky file  system  partial  block  size  /unfinished-block  create  a  new  file  in  the  root   write  data   do  no  close  test  unfinished  block  read  test  file  creation  stm  create  file  block  size  write  file  and  sync  write  partial  block  and  sync  make  sure  a  client  can  read  it  before  it  is  closed  check  can  read  file1  close  filesystem  partialblocksize  /unfinished-block   create a new file in the root  write data  do no close  testunfinishedblockread  testfilecreation  stm  createfile  blocksize  writefileandsync   write partial block and sync   make sure a client can read it before it is closed  checkcanread  file1  close
__label__nflaky path  request  add  request.  query  map  text/html;  charset=us-ascii  )  put  status  headers  param  run  tests  content_  type  <  html>42</  html>  add  test  /stuff  response  more-stuff  response  header3  header2  request  headers  map  header1  test  method  what  is  the  meaning  of  life?  response  headers  map  something  testing  framework  framework  request  query  response  method  text/plain;  charset=us-ascii  header_stuff  body  add  test  no  mocks  stuff  path  request   add request.  querymap  text/html; charset=us-ascii   )  put  status  headers  param  runtests  content_type  <html>42</html>  addtest  /stuff  response  more-stuff   response  header3  header2  requestheadersmap  header1  test  method  what is the meaning of life?  responseheadersmap  something  testingframework  framework  request  query  response  method  text/plain; charset=us-ascii  header_stuff  body  addtestnomocks  stuff
__label__flaky get  name  get  status  sub  workflow  action  executor  proto  conf  create  base  workflow  get  workflow  client  create  action  </app-path>  set  id  workflow.xml  write  get  base  proto  conf  wait  for  workflow  get  file  system  check  </configuration>  workflow  action  file  evaluate  get  parent  id  set  name  <app-path>  <configuration>  get  job  info  <name>a</name>  </property>  get  actions  get  id  get  external  id  fs  app1  <value>  a</value>  w  get  end  ext  id  workflow  job  close  <sub-workflow  xmlns=\'uri:oozie:workflow:0.1\'>  oozie  client  <property>  start  sub  workflow  app  path  sub  workflow  assert  equals  job_  timeout  set  conf  <app-path>wrong  app  path</app-path>  </sub-workflow>  writer  action1  test  sub  workflow  recovery  get  fs  test  case  dir  getname  getstatus  subworkflowactionexecutor  protoconf  createbaseworkflow  getworkflowclient  create  action  </app-path>  setid  workflow.xml  write  getbaseprotoconf  waitfor  workflow  getfilesystem  check        </configuration>  workflowaction  file  evaluate  getparentid  setname        <app-path>        <configuration>  getjobinfo            <name>a</name>          </property>  getactions  getid  getexternalid  fs  app1            <value>a</value>  w  get  end  extid  workflowjob  close  <sub-workflow xmlns=\'uri:oozie:workflow:0.1\'>  oozieclient          <property>  start  subworkflowapppath  subworkflow  assertequals  job_timeout  setconf        <app-path>wrongapppath</app-path>  </sub-workflow>  writer  action1  testsubworkflowrecovery  getfstestcasedir
__label__nflaky 23  mapping  contains  size  assert  true  groups  zzz  test  get  numeric  groups  resolvable  user  groupname  get  groups  23  mapping  contains  size  asserttrue  groups  zzz  testgetnumericgroupsresolvable  user  groupname  getgroups
__label__flaky from  row  m1  m2  utf-8  foo  test  blob  and  diff  assert  equals  _foo  {\""m1\"":2   \""m2\"":2}  get  bytes  bar  get  collection  doc  \""blob\""   \""=\""   \""foo\""   \""bar\"" \""  m\""   \""m1\""   1 \""  m\""   \""m2\""   3  row  fromrow  m1  m2  utf-8  foo  testblobanddiff  assertequals  _foo  {\""m1\"":2  \""m2\"":2}  getbytes  bar  get  collection  doc  \""blob\""  \""=\""  \""foo\""  \""bar\"" \""m\""  \""m1\""  1 \""m\""  \""m2\""  3  row
__label__nflaky \""else\""  case:  \""  b\""  is  encoded  as  ascii  aimaimaimÃ«  aimaimaimÃ«  visualized  66  74  78  66  74  66  99  129  \""else\""  case:  \""b\""  is  encoded  as  ascii  assert  equals  aimaiab  aimai  ab  encoded  as  ascii  activate  when  additional  rectangulars  are  available  230  91  11  90  255  254  67  129  \""else\""  case  230  91  11  91  11  91  11  254  235  108  encode  high  level  230  91  11  91  11  91  11  254  235  76  test  c40  encodation  basic2   \""else\"" case: \""b\"" is encoded as ascii  aimaimaimÃ«  aimaimaimÃ«  visualized  66 74 78 66 74 66 99 129   \""else\"" case: \""b\"" is encoded as ascii  assertequals  aimaiab  aimaiab   encoded as ascii   activate when additional rectangulars are available  230 91 11 90 255 254 67 129   \""else\"" case  230 91 11 91 11 91 11 254 235 108  encodehighlevel  230 91 11 91 11 91 11 254 235 76  testc40encodationbasic2
__label__flaky <execution>  lifo</execution>  </controls>  <datasets>  test  done  flag  conf  <data-in  name=\""  a\""  dataset=\""local_a\"">  <instance>${coord:current(0)}</instance>  </data-in>  /workflows/2009/01/_  success  </input-events>  get  status  action  status  file://  get  test  case  dir  unit_  testing  coordinator  action  action  missing  deps  wait  for  <coordinator-app  name=\""  name\""  frequency=\""${coord:days(1)}\""  start=\""2009-02-01  t01:00  z\""  end=\""2009-02-01  t02:00  z\""  timezone=\""  utc\""  <configuration>  <property>  <name>input  a</name>  <value>${coord:data  in(\'  a\')}</value>  </property>  <action>  <workflow>  <app-path>hdfs:///tmp/workflows2/</app-path>  /workflows/${  year}/${  day}</uri-template>  oozie  client  job  id  size  </datasets>  <input-events>  file  actions  evaluate  submit  job  get  missing  dependencies  get  actions  app  path  </dataset>  system  write  to  file  app  xml  <dataset  name=\""local_a\""  frequency=\""${coord:days(1)}\""  initial-instance=\""2009-02-01  t01:00  z\""  assert  true  get  xmlns=\""uri:oozie:coordinator:0.1\"">  <controls>  <timeout>10</timeout>  <concurrency>2</concurrency>  timezone=\""  utc\"">  <uri-template>file://  get  coord  job  missing  deps=  coordinator.xml  ce  set  done  flag  is  not  added  to  the  missing  dependency  list  assert  equals  </configuration>  </workflow>  </action>  </coordinator-app>  get  test  user  <execution>lifo</execution> </controls> <datasets>   testdoneflag  conf  <data-in name=\""a\"" dataset=\""local_a\""> <instance>${coord:current(0)}</instance> </data-in>    /workflows/2009/01/_success  </input-events>   getstatus  actionstatus  file://  gettestcasedir  unit_testing  coordinatoraction  action  missingdeps  waitfor  <coordinator-app name=\""name\"" frequency=\""${coord:days(1)}\"" start=\""2009-02-01t01:00z\"" end=\""2009-02-01t02:00z\"" timezone=\""utc\""   <configuration> <property> <name>inputa</name> <value>${coord:datain(\'a\')}</value> </property>   <action> <workflow> <app-path>hdfs:///tmp/workflows2/</app-path>   /workflows/${year}/${day}</uri-template>   oozieclient  jobid  size  </datasets> <input-events>   file  actions  evaluate  submitjob  getmissingdependencies  getactions  apppath  </dataset>  system  writetofile  appxml  <dataset name=\""local_a\"" frequency=\""${coord:days(1)}\"" initial-instance=\""2009-02-01t01:00z\""   asserttrue  get  xmlns=\""uri:oozie:coordinator:0.1\""> <controls> <timeout>10</timeout> <concurrency>2</concurrency>   timezone=\""utc\""> <uri-template>file://  getcoordjob  missing deps=  coordinator.xml  ce  set   done flag is not added to the missing dependency list  assertequals  </configuration> </workflow> </action> </coordinator-app>  gettestuser
__label__nflaky ffs  check  fs  conf  lfs  create  assert  equals  conf  initialize  uri  get  raw  file  system  filter:/  test  init  filter  fs  sets  embed  conf  ffs  checkfsconf  lfs  create  assertequals  conf  initialize  uri  getrawfilesystem  filter:/  testinitfilterfssetsembedconf
__label__flaky action  num  test  coord  action  get  _  e  _test  get  action  by  external  id  get  id  x  data  test  case  add  record  to  coord  job  table  coordinator  job  create  coord  action  coord-action-get.xml  insert  the  action  coordinator  action  set  sla  xml  action  insert  record  coord  action  job  actionnum  testcoordactionget  _e  _testgetactionbyexternalid  getid  xdatatestcase  addrecordtocoordjobtable  coordinatorjob  createcoordaction  coord-action-get.xml   insert the action  coordinatoraction  setslaxml  action  insertrecordcoordaction  job
__label__nflaky create  the  framework  without  deleting  the  default  tests.  adapter  framework  run  tests  set  adapter  default  tests   create the framework without deleting the default tests.  adapter  framework  runtests  setadapter  defaulttests
__label__flaky b  from  row  string  utf-8  get  id  assert  equals  _foo  {\""s\"":\""string\""   \""b\"":true   \""i\"":1}  get  bytes  long  value  test  simple  blob2  get  mod  count  get  collection  doc  row  boolean  has  binary  \""blob\""  b  fromrow  string  utf-8  getid  assertequals  _foo  {\""s\"":\""string\""  \""b\"":true  \""i\"":1}  getbytes  longvalue  testsimpleblob2  getmodcount  get  collection  doc  row  boolean  hasbinary  \""blob\""
__label__nflaky request  new  token  get  name  token  signed  token_  validity_  sec  set  expires  sign  secret  when  as  list  get  init  parameter  names  system  assert  get  cookies  dummy  authentication  handler  secret  provider  management.operation.return  signer  authenticated  url  init  cookie  authentication  filter  then  return  destroy  assert  equals  token  filter  p  get  mocked  servlet  context  with  string  signer  get  init  parameter  mockito  u  elements  current  time  millis  get  token  true  mock  to  string  arrays  config  test  get  token  request  newtoken  getname  tokensigned  token_validity_sec  setexpires  sign  secret  when  aslist  getinitparameternames  system  assert  getcookies  dummyauthenticationhandler  secretprovider  management.operation.return  signer  authenticatedurl  init  cookie  authenticationfilter  thenreturn  destroy  assertequals  token  filter  p  getmockedservletcontextwithstringsigner  getinitparameter  mockito  u  elements  currenttimemillis  gettoken  true  mock  tostring  arrays  config  testgettoken
__label__flaky cluster  locs  racks  conf  wait  for  replication  get  block  manager  dir  create  file  file  system  get  path  get  file  status  exclude  get  file  block  locations  get  working  directory  working  dir  dfs.hosts.exclude  get  file  system  ie  we  didn\'t  remove  the  replica  on  the  host  on  /rack1.  get  name  node  be  impossible  to  respect  the  rack  policy).  num  data  nodes  mkdirs  long  name  configure  an  excludes  file  test  node  decomission  with  overreplication  respects  rack  policy  get  first  block  wait  for  decommission  shutdown  ns  lower  the  replication  factor  so  the  blocks  are  over  replicated  /rack2  /rack1  fs  substring  top  get  datanode  manager  assert  true  get  topology  paths  *  test  that  rack  policy  is  still  respected  when  blocks  are  replicated  *  due  to  node  decommissioning   when  the  blocks  are  over-replicated.  refresh  nodes  exclude  file  write  file  build/test/data/temp/decommission  dfs  test  util  b  set  all  hosts  are  on  two  racks   only  one  host  on  /rack2  get  conf  file  path  to  uri  length  set  replication  replication_  factor  /test  file  build  get  local  local  file  sys  get  namesystem  starts  with    cluster  locs  racks  conf  waitforreplication  getblockmanager  dir  createfile  filesystem  getpath  getfilestatus  exclude  getfileblocklocations  getworkingdirectory  workingdir  dfs.hosts.exclude  getfilesystem   ie we didn\'t remove the replica on the host on /rack1.  getnamenode   be impossible to respect the rack policy).  numdatanodes  mkdirs  long  name   configure an excludes file  testnodedecomissionwithoverreplicationrespectsrackpolicy  getfirstblock  waitfordecommission  shutdown  ns   lower the replication factor so the blocks are over replicated  /rack2  /rack1  fs  substring  top  getdatanodemanager  asserttrue  gettopologypaths       * test that rack policy is still respected when blocks are replicated     * due to node decommissioning  when the blocks are over-replicated.       refreshnodes  excludefile  writefile  build/test/data/temp/decommission  dfstestutil  b  set   all hosts are on two racks  only one host on /rack2  getconf  filepath  touri  length  setreplication  replication_factor  /testfile  build  getlocal  localfilesys  getnamesystem  startswith
__label__nflaky test  bloom  map  file  constructors  error  !!!  test  file  name  default  progress  default  codec  log  writable  comparator  conf  deprecation  cleanup  with  logger  test  bloom  map  file  constructors  fail  io  utils  test_  file  assert  not  null  file  system  get  to  string  writer  compression  type  close  ts  testbloommapfileconstructors error !!!  testfilename  defaultprogress  defaultcodec  log  writablecomparator  conf  deprecation  cleanupwithlogger  testbloommapfileconstructors  fail  ioutils  test_file  assertnotnull  filesystem  get  tostring  writer  compressiontype  close  ts
__label__flaky src  conf  set  assert  equals  target  conf  x  configuration  test  parameter1  test  parameter2  test  parameter3  value  from  target  get  test  copy  copy  value  from  source  srcconf  set  assertequals  targetconf  xconfiguration  testparameter1  testparameter2  testparameter3  valuefromtarget  get  testcopy  copy  valuefromsource
__label__nflaky has  field  violation  then  return  short  param  invoke  when  param1  short  validation  should  work  assert  true  context  create  verify  mock  controller  validation  blah  get  parameter  hasfieldviolation  thenreturn  shortparam  invoke  when  param1  shortvalidationshouldwork  asserttrue  context  create  verify  mockcontroller  validation  blah  getparameter
__label__flaky a  fail  test  not  empty  elements  name  not  empty  elements  arrays  param  checker  as  list  a  fail  testnotemptyelements  name  notemptyelements  arrays  paramchecker  aslist
__label__nflaky brings  back  the  backend  user-group  mapping  service.  it  should  still  get  groups  from  the  negative  cache.  groups  for  the  user  is  fetched.  failed  to  obtain  groups  from  fake  group  mapping.  in  the  first  attempt   the  user  will  be  put  in  the  negative  cache.  negcache  conf  put  into  the  negative  cache  as  list  advance  timer  cache  groups  add  let  the  elements  in  the  negative  cache  expire.  get  groups  no  groups  found  for  user  common  configuration  keys  e  clear  black  list  groups  refresh  generic  test  utils  fake  group  mapping  assert  equals  test  negative  group  caching  fail  message  the  second  time   the  user  is  in  the  negative  cache.  fail  set  long  the  user  is  still  in  the  negative  cache   even  my  groups  add  to  black  list  assert  exception  contains  the  user  is  in  the  negative  cache.  fake  group  mapping  has  resumed.  arrays  user  did  not  throw  io  exception:   brings back the backend user-group mapping service.   it should still get groups from the negative cache.   groups for the user is fetched.  failed to obtain groups from fakegroupmapping.   in the first attempt  the user will be put in the negative cache.  negcache  conf   put into the negative cache  aslist  advance  timer  cachegroupsadd   let the elements in the negative cache expire.  getgroups  no groups found for user  commonconfigurationkeys  e  clearblacklist  groups  refresh  generictestutils  fakegroupmapping  assertequals  testnegativegroupcaching  failmessage   the second time  the user is in the negative cache.  fail  setlong  the user is still in the negative cache  even   mygroups  addtoblacklist  assertexceptioncontains  the user is in the negative cache.  fakegroupmapping has resumed.  arrays  user  did not throw ioexception:
__label__flaky test  time  uuid  with  clock  resolution  than  the  first  one.  assert  equals  clock  compare  to  time  uuid  utils  second  create  clock  create  time  test  improved  algorithm.  assert  true  get  time  uuid  uuid  gen  get  clock  seq  and  node  to  string  time  from  string  first  testtimeuuidwithclockresolution   than the first one.  assertequals  clock  compareto  timeuuidutils  second  createclock  createtime   test improved algorithm.  asserttrue  gettimeuuid  uuidgen  getclockseqandnode  tostring  time  fromstring  first
__label__nflaky server  server  threads  server  call  ids  conf  run  contains  every  expected  value.  it.  start  id  get  client  synchronized  list  join  per  caller  call  count  collections  addr  get  call  id  caller  count  add  assert  return  values  int  value  test  unique  sequential  call  ids  start  assert  equals  sort  get  connect  address  net  utils  stop  size  callers  expected  call  count  server  serverthreads  server  callids  conf  run   contains every expected value.   it.  startid  get  client  synchronizedlist  join  percallercallcount  collections  addr  getcallid  callercount  add  assertreturnvalues  intvalue  testuniquesequentialcallids  start  assertequals  sort  getconnectaddress  netutils  stop  size  callers  expectedcallcount
__label__flaky aa  a  a  x  log  create  prefix  aa  start  assert  equals  run  a-  t  test  info  thread  local  get  define  parameter  set  parameter  join  aa  a  a  xlog  createprefix  aa  start  assertequals  run  a-  t  testinfothreadlocal  get  defineparameter  setparameter  join
__label__nflaky test-new.mapfile  error_  message  new_  file_  name  map  file  conf  fs  when  could  not  rename  cleanup  with  logger  assert  true  file  system  close  test_  dir  spy  fs  test  rename  with  exception  no  exception  error  !!!  log  test  rename  with  false  invalid  io  exception  message  error  !!!  then  return  get  message  old  dir  fail  io  utils  create  writer  ex  test-old.mapfile  rename  test  rename  with  false  get  local  new  dir  old_  file_  name  to  string  writer  spy  starts  with  test-new.mapfile  error_message  new_file_name  mapfile  conf  fs  when  could not rename  cleanupwithlogger  asserttrue  filesystem  close  test_dir  spyfs  testrenamewithexception no exception error !!!  log  testrenamewithfalse invalid ioexceptionmessage error !!!  thenreturn  getmessage  olddir  fail  ioutils  createwriter  ex  test-old.mapfile  rename  testrenamewithfalse  getlocal  newdir  old_file_name  tostring  writer  spy  startswith
__label__flaky date  session  given  insert  select  *  from  simple  where  id  =  crud  when  get  id  row  value  all  post  insert_pre  insert_value  random  utils  manager  should_trigger_for_insert  get  string  next  long  assert  that  rows  execute  pre  insert_value  get  value  has  size  then  long  is  equal  to  entity  date  session   given  insert  select * from simple where id =   crud   when  get  id  row  value  all  postinsert_preinsert_value  randomutils  manager  should_trigger_for_insert  getstring  nextlong  assertthat  rows  execute  preinsert_value  getvalue  hassize   then  long  isequalto  entity
__label__nflaky next  then  build  route  test  that  global  filters  in  route  replace  global  filters  in  conf  filters  ninja  constant  equal  to  get  filter  chain  when  filter  chain  result  get  context  get  provider  verify  injector  when  then  return  filter  provider  matchers  assert  that  ninja  base  directory  resolver  /  with  never  different  setup  that  uses  com.example  packages  and  thus  reads  the  filters  there  route  mockito  expected  result  get  dummy  filter2  mock  route  builder  com.example  ninja  properties  global  filters  next   then  buildroute  testthatglobalfiltersinroutereplaceglobalfiltersinconffilters  ninjaconstant  equalto  getfilterchain  when  filterchain  result  get  context  getprovider  verify  injector   when  thenreturn  filterprovider  matchers  assertthat  ninjabasedirectoryresolver  /  with  never   different setup that uses com.example packages and thus reads the filters there  route  mockito  expectedresult  get  dummyfilter2  mock  routebuilder  com.example  ninjaproperties  globalfilters
__label__flaky get  job  tracker  uri  map-reduce  conf  get  status  create  context  get  job  hadoop.counters  will  always  be  set  in  case  of  mr  action.  output  counter  get  execution  stats  assert  not  null  <map-reduce>  context  create  write  wait  for  <job-tracker>  group  group.name  ae  counters  parse  xml  </job-tracker>  dummy  get  file  system  check  <name-node>  stats  write  property  as  false.  assert  for  stats  info  stored  in  the  context.  </name-node>  configuration.  input  contains  workflow  action  succeeded  get  oozie  action  external  stats  write  property  submit  action  get  external  child  i  ds  test  set  execution  stats_when_user_has_specified_stats_write_  false  data.txt  evaluate  job  id  launcher  id  external  child  i  ds  will  always  be  null  in  case  of  mr  action.  assert  false  user.name  get  external  id  fs  has  id  swap  create  base  hadoop  conf  action  xml  is  successful  assert  true  launcher  mapper  get  end  close  get  data  get  name  node  uri  output  dir  launcher  job  xml  utils  for  name  false  get  action  assert  equals  mr  job  hadoop.counters  input  dir  get  external  status  </map-reduce>  services  create  job  client  assert  null  w  to  xml  string  equals  get  var  to  string  job  client  user  get  fs  test  case  dir  is  complete  getjobtrackeruri  map-reduce  conf  getstatus  createcontext  getjob   hadoop.counters will always be set in case of mr action.  output  counter  getexecutionstats  assertnotnull  <map-reduce>  context  create  write  waitfor  <job-tracker>  group  group.name  ae  counters  parsexml  </job-tracker>  dummy    getfilesystem  check  <name-node>   stats write property as false.   assert for stats info stored in the context.  </name-node>   configuration.  input  contains  workflowaction  succeeded  getoozieactionexternalstatswriteproperty  submitaction  getexternalchildids  testsetexecutionstats_when_user_has_specified_stats_write_false  data.txt  evaluate  jobid  launcherid   external child ids will always be null in case of mr action.  assertfalse  user.name  getexternalid  fs  hasidswap  createbasehadoopconf  actionxml  issuccessful  asserttrue  launchermapper  get  end  close  getdata  getnamenodeuri  outputdir  launcherjob  xmlutils  forname  false  getaction  assertequals  mrjob  hadoop.counters  inputdir  getexternalstatus  </map-reduce>  services  createjobclient  assertnull  w  toxmlstring  equals  getvar  tostring  jobclient  user  getfstestcasedir  iscomplete
__label__nflaky server  /test2/  curator  framework  factory  reaper  session  reaper  closeable  utils  /test3  /test1  /test2  sleep  a  bit  client  create  creating  parents  if  needed  is  zero  connection  for  path  /test3/  stat  get  connect  string  /test1/  check  exists  timing  start  assert  that  add  path  new  client  integer  for  waiting  test  multi  path  to  string  close  quietly  get  num  children  is  equal  to  server  /test2/  curatorframeworkfactory  reaper  session  reaper  closeableutils  /test3  /test1  /test2  sleepabit  client  create  creatingparentsifneeded  iszero  connection  forpath  /test3/  stat  getconnectstring  /test1/  checkexists  timing  start  assertthat  addpath  newclient  integer  forwaiting  testmultipath  tostring  closequietly  getnumchildren  isequalto
__label__flaky get  coord  action  recovered  action  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  workflow  instance  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  sleep  wf  job  add  record  to  wf  job  table  unit_  testing  get  coordinator  action  action  end  current  date  plus  month  workflow  job  wait  for  action  check  runnable  action  num  ce  test  action  checker  service  coord  running  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  coordinator  job  services  get  test  user  coord-action-get.xml  job  evaluate  jpa  service  getcoordaction  recoveredaction  getcurrentdateafterincrementinginmonths  getid  run  dateutils  workflowinstance  getstatus  addrecordtocoordactiontable  parsedateoozietz  sleep  wfjob  addrecordtowfjobtable  unit_testing  get  coordinatoraction  action  end  currentdateplusmonth  workflowjob  waitfor  actioncheckrunnable  actionnum  ce  testactioncheckerservicecoord  running  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  coordinatorjob  services  gettestuser  coord-action-get.xml  job  evaluate  jpaservice
__label__nflaky get  bytes  transferred  test  coding  fragment  buffering  tiny  fragments3  codec  test  utils  channel  times  assert  flush  verify  more  stuff  dump  write  --  argument  matchers  standard  charsets  assert  equals  encoder  -  any  stuff------more  stuff  mockito  outbuf  metrics  spy  wrap  stuff  getbytestransferred  testcodingfragmentbufferingtinyfragments3  codectestutils  channel  times  assert  flush  verify  more stuff  dump  write  --  argumentmatchers  standardcharsets  assertequals  encoder  -  any  stuff------more stuff  mockito  outbuf  metrics  spy  wrap  stuff
__label__flaky test  bundle  jobs  get  _test  get  job  info  for  user  add  record  to  bundle  job  table  _test  get  jobs  for  app  name  _test  get  jobs  for  status  job  _test  get  jobs  for  group  _test  get  jobs  for  user  and  status  testbundlejobsget  _testgetjobinfoforuser  addrecordtobundlejobtable  _testgetjobsforappname  _testgetjobsforstatus  job  _testgetjobsforgroup  _testgetjobsforuserandstatus
__label__nflaky should  fail  real  policy  retry  decision  construct  reason  string  should  retry  +=  1  should  retry  +=  2  times  should  retry  other  exception  other  than  unreliable  exception  should  also  get  retry  up  to  maximum  count  with  fixed  sleep  time  unit  create  verify  unreliable  impl  policy  retry  up  to  maximum  count  with  fixed  sleep  test  retry  up  to  maximum  count  with  fixed  sleep  any  boolean  fails  once  then  succeeds  fails  ten  times  then  succeeds  setup  mock  policy  assert  equals  failed.  retry  proxy  always  succeeds  any  any  int  should  retry  +=  (max  retries  -1)  (just  failed  once  above)  fail  max  retries  expected  unreliable  mock  caught  retry  action  should fail  realpolicy  retrydecision  constructreasonstring   shouldretry += 1   shouldretry += 2  times  shouldretry  other exception other than unreliableexception should also get   retryuptomaximumcountwithfixedsleep  timeunit  create  verify  unreliableimpl  policy  retryuptomaximumcountwithfixedsleep  testretryuptomaximumcountwithfixedsleep  anyboolean  failsoncethensucceeds  failstentimesthensucceeds  setupmockpolicy  assertequals  failed.  retryproxy  alwayssucceeds  any  anyint   shouldretry += (maxretries -1) (just failed once above)  fail  maxretries   expected  unreliable  mock  caughtretryaction
__label__flaky release  set  max  total  when  times  assert  assert  true  assert  not  null  create  set  max  per  route  verify  join  get  entry  close  entry2  get  leased  entry3  conn3  conn2  entry1  test  stateful  connection  redistribution  on  per  route  max  limit  conn1  grace_  period  then  return  somehost  pool  start  assert  equals  some-other-stuff  conn  factory  totals  eq  future3  is  done  some-stuff  never  future1  future2  mockito  mock  set  state  lease  get  pending  t1  get  total  stats  get  available  t2  t3  release  setmaxtotal  when  times  assert  asserttrue  assertnotnull  create  setmaxperroute  verify  join  getentry  close  entry2  getleased  entry3  conn3  conn2  entry1  teststatefulconnectionredistributiononperroutemaxlimit  conn1  grace_period  thenreturn  somehost  pool  start  assertequals  some-other-stuff  connfactory  totals  eq  future3  isdone  some-stuff  never  future1  future2  mockito  mock  setstate  lease  getpending  t1  gettotalstats  getavailable  t2  t3
__label__nflaky get  bytes  transferred  codec  test  utils  channel  stuff-stuff  times  assert  flush  verify  dump  write  argument  matchers  standard  charsets  length  assert  equals  test  coding  fragment  buffering  buffer  flush  encoder  any  -stuff  mockito  outbuf  metrics  spy  wrap  stuff  getbytestransferred  codectestutils  channel  stuff-stuff  times  assert  flush  verify  dump  write  argumentmatchers  standardcharsets  length  assertequals  testcodingfragmentbufferingbufferflush  encoder  any  -stuff  mockito  outbuf  metrics  spy  wrap  stuff
__label__flaky cluster  dst  block  size  =  show  conf  f1  /test/zero  size  file  f2  fs  delete  copy  to  local  file  assert  true  get  block  size  test_  root_  dir  to  remote  root  get  path  get  file  status  create  a  zero  size  file  close  mkdir  test  zero  size  file  is  file  copy  local  length  assert  equals  get  file  system  not  a  hdfs:  dfs  get  block  size()  should  not  throw  exception  remotef  build  num  data  nodes  copy  to  remote  exists  create  new  file  get  uri  shutdown  copy  from  local  file  copy  back  cluster  dst  block size =   show  conf  f1  /test/zerosizefile  f2  fs  delete  copytolocalfile  asserttrue  getblocksize  test_root_dir   to remote   root  getpath  getfilestatus   create a zero size file  close  mkdir  testzerosizefile  isfile  copy local   length  assertequals  getfilesystem  not a hdfs:   dfs   getblocksize() should not throw exception  remotef  build  numdatanodes   copy to remote  exists  createnewfile  geturi  shutdown  copyfromlocalfile   copy back
__label__nflaky integer  test  compute  capacity  r  test  capacity  compute  capacity  for  some  100  random  max  memory  and  percentage  next  int  tests  for  boundary  conditions  where  percent  or  memory  are  zero  max  memory  percent  integer  testcomputecapacity  r  testcapacity   compute capacity for some 100 random max memory and percentage  nextint   tests for boundary conditions where percent or memory are zero  maxmemory  percent
__label__flaky recovery  service  get  name  coord  el  functions  add  init  records  run  get  waiting  actions  get  status  /dt=20120430;country=usa  coordinator  action  new  h  cat  dependency  init  get  jms  connection  info  hcat  service  waiting  actions  populate  table  destroy  jms  service     dep1  is  not  available  and  dep2  is  available  register  the  missing  dependencies  to  pdms  assuming  coord  push  dependency  check  command  did  this.  pdms  .  /  set  long  contains  size  is  listening  to  topic  /dt=20120430;country=brazil  action  id  server  assert  false  sleep  default  assert  true  uri  handler  service  get  tablename  recovery  runnable  table  ca  add  missing  dependency  set  get  conf  new  h  cat  dependency2  new  h  cat  dependency1  hcat://  hcat.  assert  equals  services  and  new  h  cat  dependency1  should  be  in  pdms  waiting  list  assert  null  setup  services  for  h  catalog  check  coord  action  dependencies  db  test  coord  action  recovery  service  for  waiting  register  partition  recoveryservice  getname  coordelfunctions  addinitrecords  run  getwaitingactions  getstatus  /dt=20120430;country=usa  coordinatoraction  newhcatdependency  init  getjmsconnectioninfo  hcatservice  waitingactions  populatetable  destroy  jmsservice      dep1 is not available and dep2 is available   register the missing dependencies to pdms assuming coordpushdependencycheckcommand did this.  pdms  .  /  setlong  contains  size  islisteningtotopic  /dt=20120430;country=brazil  actionid  server  assertfalse  sleep  default  asserttrue  urihandlerservice  get  tablename  recoveryrunnable  table  ca  addmissingdependency  set  getconf  newhcatdependency2  newhcatdependency1  hcat://  hcat.  assertequals  services   and newhcatdependency1 should be in pdms waiting list  assertnull  setupservicesforhcatalog  checkcoordactiondependencies  db  testcoordactionrecoveryserviceforwaitingregisterpartition
__label__nflaky method  dir  set  writable  publish  the  metrics  ms  to  uri  no  exception  was  generated  while  writing  metrics  even  though  the  target  directory  was  not  writable  path  mock  sink  stop  assert  true  make  sure  the  dir  is  writable  again  so  we  can  delete  it  at  the  end  to  string  publish  metrics  now  init  metrics  system  file  util  register  with  shutdown  test  failed  write  methoddir  setwritable   publish the metrics  ms  touri  no exception was generated while writing metrics   even though the target directory was not writable  path  mocksink  stop  asserttrue   make sure the dir is writable again so we can delete it at the end  tostring  publishmetricsnow  initmetricssystem  fileutil  registerwith  shutdown  testfailedwrite
__label__flaky init  wf-schema-valid.xml  reader  auth  token  destroy  conf  wf  def  services  io  utils  get  test  user  test  read  definition  copy  char  stream  assert  not  null  get  test  case  dir  /workflow.xml  get  file://  get  resource  as  reader  workflow.xml  to  string  writer  wps  read  definition  file  init  wf-schema-valid.xml  reader  authtoken  destroy  conf  wfdef  services  ioutils  gettestuser  testreaddefinition  copycharstream  assertnotnull  gettestcasedir  /workflow.xml  get  file://  getresourceasreader  workflow.xml  tostring  writer  wps  readdefinition  file
__label__nflaky ..  create  flag  foo  fq  wd  /existing  dir  cd  using  a  absolute  path  fq  absolute  dir  go  back  to  our  test  root  relative  dir  /test  wd  assert  file  context  test  helper  try  a  uri  assert  true  of  absolute  path  create  work  dir  mkdir  close  get  test  root  path  get  parent  test  working  directory  get  working  directory  enum  set  absolute  dir  cd  to  non  existing  dir  should  have  failed  assert  equals  local_  fs_  root_  uri  now  open  a  file  relative  to  the  wd  we  just  set  above.  .  set  working  directory  existing  dir1  fail  /test/existing  dir2  new  dir  make  qualified  file:///tmp/test  fc  file  context  first  we  cd  to  our  test  root  open  now  mkdir  relative  to  the  dir  we  cd\'ed  to  nonexisting  path  is  dir  ..  createflag  foo  fqwd  /existingdir   cd using a absolute path  fqabsolutedir   go back to our test root  relativedir  /testwd  assert  filecontexttesthelper   try a uri  asserttrue  of  absolutepath  create  workdir  mkdir  close  gettestrootpath  getparent  testworkingdirectory  getworkingdirectory  enumset  absolutedir  cd to non existing dir should have failed  assertequals  local_fs_root_uri   now open a file relative to the wd we just set above.  .  setworkingdirectory  existingdir1  fail  /test/existingdir2  newdir  makequalified  file:///tmp/test  fc  filecontext   first we cd to our test root  open   now mkdir relative to the dir we cd\'ed to  nonexistingpath  isdir
__label__flaky next  no  such  element  exception  expected.  assert  false  local  oozie  h  has  next  set  header  get  header  remove  header  fail  get  coord  client  hit  assert  null  v  get  header  names  client  test  header  methods  next  nosuchelementexception expected.  assertfalse  localoozie  h  hasnext  setheader  getheader  removeheader  fail  getcoordclient  hit  assertnull  v  getheadernames  client  testheadermethods
__label__nflaky check  if  dummy  run  called  only  once  server  handler  is  one  dummy  run  new  proxy  instance  start  conf  get  class  loader  set  call  id  and  retry  count  assert  that  retry  proxy  proxy  proxy  test  no  retry  on  invalid  token  stop  provider  retry  policies  client  create  failover  on  network  exception  retry  proxy  client   check if dummyrun called only once  server  handler  isone  dummyrun  newproxyinstance  start  conf  getclassloader  setcallidandretrycount  assertthat  retryproxy  proxy  proxy  testnoretryoninvalidtoken  stop  provider  retrypolicies  client  create  failoveronnetworkexception  retryproxy  client
__label__flaky get  time  pausetime=  get  id  error  code  should  be  e1022  date  utils  add  record  to  coord  action  table  pause  time  get  error  code  coordinator  action  end  4  hrs  e  should  not  reach  here.  start  2  hrs  call  pause  time  change  str  coordinator  job  fail  coord-action-get.xml  test  coord  action  delete  format  date  oozie  tz  add  record  to  coord  job  table  for  pause  time  test  error  code  job  checks  that  running  coord  action  is  not  deleted  gettime  pausetime=  getid  error code should be e1022  dateutils  addrecordtocoordactiontable  pausetime  geterrorcode  coordinatoraction  end   4 hrs  e  should not reach here.  start   2 hrs  call  pausetimechangestr  coordinatorjob  fail  coord-action-get.xml  testcoordactiondelete  formatdateoozietz  addrecordtocoordjobtableforpausetimetest  errorcode  job   checks that running coord action is not deleted
__label__nflaky some  non  existent  file  test  token  file  cat_  token  set  kdiag  failure  keylen  hadoop_  token_  files  arg_  keylen  conf  unset  somenonexistentfile  testtokenfile  cat_token  set  kdiagfailure  keylen  hadoop_token_files  arg_keylen  conf  unset
__label__flaky play  bogus  data  ping  play  it  back  verify  the  peer  received  what  was  expected  assert  equals  invalid_  stream  rst_  stream  type_  rst_  stream  bogus  data  frame  does  not  disrupt  connection  accept  frame  send  frame  peer  spdy3  write  the  mocking  script  ping  connection  write  utf8  take  frame  rst  stream  play  bogus  data  ping   play it back   verify the peer received what was expected  assertequals  invalid_stream   rst_stream  type_rst_stream  bogusdataframedoesnotdisruptconnection  acceptframe  sendframe  peer  spdy3   write the mocking script   ping  connection  writeutf8  takeframe  rststream
__label__nflaky sys_prop_does_not_exist  standalones  add  default_does_not_exist  standalone  helper  e  then  return  contains  string  resolve  standalone  class  get  message  new  instance  try  to  resolve  using  default  assert  that  when  instance  of  resolved  standalone  class  fail  service  loader  iterator  mock  try  to  resolve  system  property  mock  the  service  loader  sys_prop_does_not_exist  standalones  add  default_does_not_exist  standalonehelper  e  thenreturn  containsstring  resolvestandaloneclass  getmessage  newinstance   try to resolve using default  assertthat  when  instanceof  resolvedstandaloneclass  fail  serviceloader  iterator  mock   try to resolve system property   mock the service loader
__label__flaky wf-schema-invalid-global-ext-no-global.xml  validate  and  parse  test  parser  global  extension  actions  no  global  or  the  handle  global()  method  will  throw  an  exception  assert  equals  fail  io  utils  ex  parser  get  error  code  get  resource  as  reader  error  code  wf-schema-valid-global-ext-no-global.xml  wf-schema-invalid-global-ext-no-global.xml  validateandparse  testparserglobalextensionactionsnoglobal   or the handleglobal() method will throw an exception  assertequals  fail  ioutils  ex  parser  geterrorcode  getresourceasreader  errorcode  wf-schema-valid-global-ext-no-global.xml
__label__nflaky http  headers  conn  response  captor  when  set  entity  assert  executor  assert  not  null  context  create  boolean  get  code  then  return  argument  matchers  get  all  values  capture  method  eq  execute  /  any  int  size  info1  mock  receive  response  header  send  request  header  info2  request  header  elements  continue  times  is  data  available  flush  get  verify  for  class  ok  post  process  add  header  process  argument  captor  huh?  assert  equals  get  entity  test  execution  entity  enclosing  request  with  expect  continue  multiple1xx  responses  mockito  response  http  core  context  httprocessor  callback  pre  process  entity  send  request  entity  infos  receive  response  entity  httpheaders  conn  responsecaptor  when  setentity  assert  executor  assertnotnull  context  create  boolean  getcode  thenreturn  argumentmatchers  getallvalues  capture  method  eq  execute  /  anyint  size  info1  mock  receiveresponseheader  sendrequestheader  info2  request  headerelements  continue  times  isdataavailable  flush  get  verify  forclass  ok  postprocess  addheader  process  argumentcaptor  huh?  assertequals  getentity  testexecutionentityenclosingrequestwithexpectcontinuemultiple1xxresponses  mockito  response  httpcorecontext  httprocessor  callback  preprocess  entity  sendrequestentity  infos  receiveresponseentity
__label__flaky get  conf  string  <frequency=120  coord  el  functions  create  el  evaluator  for  group  replace  conf  coord  el  functions.evaluate  function(eval   expr));  eval  and  wrap  ${coord:hours(12)}  get  expr  end  coord-job-submit-freq  reply  frequency=${coord:hours  in  day(2)}  coord  el  evaluator  ${start}  ${coord:months(1)}  frequency=${coord:days(2)}  start  frequency=${coord:tz  offset()}  assert  equals  frequency=\""${coord:months(1)}\""><data-in  name=\""  a\""  dataset=\""a\""></data-in>  ${coord:days(7)}  1  fail  test  create  freq  el  valuator  eval  720  frequency=60  7  frequency=\""${coord:hours(12)}\""><data-in  name=\""  a\""  dataset=\""a\""></data-in>  ${end}  -1));  frequency=${coord:days  in  month(2)}  <coordinator-app  name=\""mycoordinator-app\""  start=\""${start}\""  end=\""${end}\""  frequency=\""${coord:days(7)}\""><data-in  name=\""  a\""  dataset=\""a\""></data-in>  getconfstring  <frequency=120  coordelfunctions  createelevaluatorforgroup  replace  conf   coordelfunctions.evaluatefunction(eval  expr));  evalandwrap  ${coord:hours(12)}  get  expr  end  coord-job-submit-freq  reply  frequency=${coord:hoursinday(2)}  coordelevaluator  ${start}  ${coord:months(1)}  frequency=${coord:days(2)}  start  frequency=${coord:tzoffset()}  assertequals   frequency=\""${coord:months(1)}\""><data-in name=\""a\"" dataset=\""a\""></data-in>  ${coord:days(7)}  1  fail  testcreatefreqelvaluator  eval  720  frequency=60  7   frequency=\""${coord:hours(12)}\""><data-in name=\""a\"" dataset=\""a\""></data-in>  ${end}   -1));  frequency=${coord:daysinmonth(2)}  <coordinator-app name=\""mycoordinator-app\"" start=\""${start}\"" end=\""${end}\""   frequency=\""${coord:days(7)}\""><data-in name=\""a\"" dataset=\""a\""></data-in>
__label__nflaky test  tail  match  rule  element  selector  *  assert  equals  p  test  tail  matching  /a  /  a  /a/b  get  tail  match  length  /a/  b  */b/c  /a/b/c  */a  */  a  */b  testtailmatch  ruleelementselector  *  assertequals  p   test tail matching  /a  /a  /a/b  gettailmatchlength  /a/b  */b/c  /a/b/c  */a  */a  */b
__label__flaky bundle  job  get  executor  bundle  job  should  have  been  purged  bundle  action  should  have  been  purged  add  record  to  bundle  action  table  get  id  date  utils  get  status  parse  date  oozie  tz  test  kill  bundle  purge  x  command  get  error  code  assert  not  null  get  job  2011-01-01  t01:00  z  add  record  to  bundle  job  table  assert  equals  execute  call  services  fail  bundle  action  get  executor1  bundle  action  get  executor2  action1  error  code  je  job  action2  jpa  service  bundlejobgetexecutor  bundle job should have been purged  bundle action should have been purged  addrecordtobundleactiontable  getid  dateutils  getstatus  parsedateoozietz  testkillbundlepurgexcommand  geterrorcode  assertnotnull  get  job  2011-01-01t01:00z  addrecordtobundlejobtable  assertequals  execute  call  services  fail  bundleactiongetexecutor1  bundleactiongetexecutor2  action1  errorcode  je  job  action2  jpaservice
__label__nflaky validation  with  optional  failed  with  two  annotations  validate  jsr303  with  optional  length  build  dto  context  regex!!!  which  is  also  too  long  do  validation  failed  with  two  annotations  validationwithoptionalfailedwithtwoannotations  validatejsr303withoptional  length  builddto  context  regex!!! which is also too long  dovalidationfailedwithtwoannotations
__label__flaky play  data  play  it  back  android  assert  false  assert  stream  data  header  entries  verify  the  peer  received  what  was  expected  source  accept  frame  stream  open  stream  count  type_  headers  assert  true  peer  connection  write  utf8  take  frame  banana  a  b  syn  reply  server  closes  client  input  stream  assert  equals  headers  mode  square  syn_  stream  send  frame  spdy3  get  source  syn  stream  new  stream  play  data   play it back  android  assertfalse  assertstreamdata  headerentries   verify the peer received what was expected  source  acceptframe  stream  openstreamcount  type_headers  asserttrue  peer  connection  writeutf8  takeframe  banana  a  b  synreply  serverclosesclientinputstream  assertequals  headersmode  square   syn_stream  sendframe  spdy3  getsource  synstream  newstream
__label__nflaky server  get  local  port  content  type  create  client  ssl  context  set  ssl  context  consume  bootstrap  set  conn  pool  listener  request1  some  stuff  set  entity  create  server  ssl  context  set  socket  config  ssl  parameters  context  create  https  /stuff  set  exception  listener  requester  localhost  ssl  test  contexts  socket  config  set  stream  listener  custom  logging  http1  stream  listener  start  *  set  so  timeout  method  get  entity  execute  set  ssl  setup  handler  server  bootstrap  test  tls  client  auth  failure  target  entity  utils  logging  conn  pool  listener  build  logging  exception  listener  requester  bootstrap  timeout  response1  set  need  client  auth  register  server  getlocalport  contenttype  createclientsslcontext  setsslcontext  consume  bootstrap  setconnpoollistener  request1  some stuff  setentity  createserversslcontext  setsocketconfig  sslparameters  context  create  https  /stuff  setexceptionlistener  requester  localhost  ssltestcontexts  socketconfig  setstreamlistener  custom  logginghttp1streamlistener  start  *  setsotimeout  method  getentity  execute  setsslsetuphandler  serverbootstrap  testtlsclientauthfailure  target  entityutils  loggingconnpoollistener  build  loggingexceptionlistener  requesterbootstrap  timeout  response1  setneedclientauth  register
__label__flaky app  end_  points  is_  security_  enabled  get  context  url  oozie  url  sla  run  assert  equals  get  file  system  app  path  args  call  1  -oozie  mkdirs  servlet_  classes  -len  run  test  get  fs  test  case  dir  test  sla  events  app  end_points  is_security_enabled  getcontexturl  oozieurl  sla  run  assertequals  getfilesystem  apppath  args  call  1  -oozie  mkdirs  servlet_classes  -len  runtest  getfstestcasedir  testslaevents
__label__nflaky get  resource  configuration  value2  value1  json  str  add  2  keys  test  dump  configuratio  without  defaults  mapper  jconf  append  property  put  out  check  the  final  tag  config  add  resource  prop  get  check  for  case  when  default  resources  are  not  loaded  close  check  the  resource  for  each  property  read  value  get  key  ensure  that  no  properties  are  loaded.  conf  dump  get  properties  end  config  assert  equals  start  config  dump  configuration  ensure  the  values  are  consistent  ensure  only  2  keys  are  loaded  get  value  get  is  final  out  writer  to  string  test.key1  file  resource  config  test.key2  getresource  configuration  value2  value1  jsonstr   add 2 keys  testdumpconfiguratiowithoutdefaults  mapper  jconf  appendproperty  put  out   check the final tag  config  addresource  prop  get   check for case when default resources are not loaded  close   check the resource for each property  readvalue  getkey   ensure that no properties are loaded.  confdump  getproperties  endconfig  assertequals  startconfig  dumpconfiguration   ensure the values are consistent   ensure only 2 keys are loaded  getvalue  getisfinal  outwriter  tostring  test.key1  fileresource  config  test.key2
__label__flaky <name>a</name>  <job-tracker>foo</job-tracker>  expected  e  <param>x</param>  test  parser  global  local  already  exists  validate  and  parse  </prepare>  </property>  replace  all  </pig>  <configuration>  wf-schema-valid-global.xml  </configuration>  app  <file>/tmp</file>  <mkdir  path=\""/tmp\""  />  <value>  a2</value>  get  conf  e  <pig  xmlns=\""uri:oozie:workflow:0.4\"">  <prepare>  <name>b</name>  assert  equals  <value>  b</value>  io  utils  <script>/tmp</script>  parser  get  resource  as  reader  <property>  get  node  <delete  path=\""/tmp\""  />  <name-node>bar</name-node>          <name>a</name>      <job-tracker>foo</job-tracker>    expectede    <param>x</param>    testparsergloballocalalreadyexists  validateandparse    </prepare>        </property>    replaceall  </pig>    <configuration>    wf-schema-valid-global.xml    </configuration>    app       <file>/tmp</file>        <mkdir path=\""/tmp\"" />          <value>a2</value>    getconf  e  <pig xmlns=\""uri:oozie:workflow:0.4\"">      <prepare>          <name>b</name>    assertequals        <value>b</value>    ioutils    <script>/tmp</script>    parser  getresourceasreader      <property>    getnode      <delete path=\""/tmp\"" />      <name-node>bar</name-node>
__label__nflaky to  \%s  for  test.time.warn  23h  1441m  days  string  log  deprecation  hchk  warn  format  get  time  duration  get  check  warn  for  possible  loss  of  precision  add  wconf  no  warning  set  test.time.warn  warnchk  seconds  format  clear  set  time  duration  10us  assert  equals  message  dchk  30m  conv  days  hours  size  test  time  duration  warning  40s  wchk  minutes  possible  loss  of  precision  converting  \%s  40000ms   to \%s for test.time.warn  23h  1441m  days  string  logdeprecation  hchk  warnformat  gettimeduration  get   check warn for possible loss of precision  add  wconf   no warning  set  test.time.warn  warnchk  seconds  format  clear  settimeduration  10us  assertequals  message  dchk  30m  convdays  hours  size  testtimedurationwarning  40s  wchk  minutes  possible loss of precision converting \%s  40000ms
__label__flaky end_  points  rest  constants  is_  security_  enabled  get  context  url  oozie  url  mock  dag  engine  service  run  assert  equals  0  args  call  -oozie  reset  job  -definition  servlet_  classes  test  job  definition  run  test  end_points  restconstants  is_security_enabled  getcontexturl  oozieurl  mockdagengineservice  run  assertequals  0  args  call  -oozie  reset  job  -definition  servlet_classes  testjobdefinition  runtest
__label__nflaky get  and  advance  current  index  -----5-7-9  --2-456789  ns  conf  poll  current  index  set  multiplexer  fcq  get  num  queues  schedulable  calls  =  new  schedulablenum  calls;  add  set  0123456789  assert  same  -----5-789  ----------  mock  call  call  assert  null  calls  u  test  prioritization  getandadvancecurrentindex   -----5-7-9   --2-456789  ns  conf  poll  currentindex  setmultiplexer  fcq  get  numqueues   schedulable calls = new schedulablenumcalls;  add  set   0123456789  assertsame   -----5-789   ----------  mockcall  call  assertnull  calls  u  testprioritization
__label__flaky a  fail  b  c  resolve  function  test  context  functions  add  function  function  c  function  b  function  a  assert  equals  support  a  fail  b  c  resolvefunction  testcontextfunctions  addfunction  functionc  functionb  functiona  assertequals  support
__label__nflaky check  bad  translation  check  translation  test  anti  patterns  set  rule  mechanism  owen/owen/owen@  foo.  com  check  bad  name  root/joe@  foo.  com  owen@foo/bar.com  kerberos  name  foo@  acme.  com  checkbadtranslation  checktranslation  testantipatterns  setrulemechanism  owen/owen/owen@foo.com  checkbadname  root/joe@foo.com  owen@foo/bar.com  kerberosname  foo@acme.com
__label__flaky cluster  stop  a  datanode   it  should  have  least  recover.  test  client  triggered  lease  recovery  conf  dir  fs  system  sleep  let  the  slow  writer  writes  a  few  more  seconds  /wrwelkj  wait  a  few  seconds  replication  file  get  len  close  stream  interrupt  get  file  status  join  let  writers  get  started  verify  the  file  stop  data  node  dfs  config  keys  read  slowwriters  in  start  j  assert  equals  get  file  system  next  int  append  test  util  :  length=  set  int  thread  io  utils  build  num  data  nodes  verify  the  file  shutdown  open  cluster   stop a datanode  it should have least recover.  testclienttriggeredleaserecovery  conf  dir  fs  system  sleep   let the slow writer writes a few more seconds  /wrwelkj  wait a few seconds  replication  file  getlen  closestream  interrupt  getfilestatus  join   let writers get started  verify the file  stopdatanode  dfsconfigkeys  read  slowwriters  in  start  j  assertequals  getfilesystem  nextint  appendtestutil  : length=  setint  thread  ioutils  build  numdatanodes   verify the file  shutdown  open
__label__nflaky check  fatals  and  reset  wait  for  elector  state  server  factory  timeout  sleep  ensure  parent  z  node  let  elector  1  be  standby  verify  close  session  wait  for  active  lock  data  ==========================  quitting  election  info  get  server  due  to  receiving  the  \""expired\""  event.  should  enter  neutral  mode  when  disconnected  zks  log  by  quitting  elector  0  and  ensuring  elector  1  doesn\'t  become  active  get  zk  session  id  for  tests  should  re-join  the  election  and  go  back  to  standby  enter  neutral  mode  active  standby  elector  test  util  ==========================  expiring  standby\'s  session  quit  election  thread  never  test  handle  session  expiration  of  standby  cbs  mockito  become  active  state  join  election  electors  let  elector  0  be  active  app  datas  parent_  dir  checkfatalsandreset  waitforelectorstate  serverfactory  timeout  sleep  ensureparentznode   let elector 1 be standby  verify  closesession  waitforactivelockdata  ========================== quitting election  info  getserver   due to receiving the \""expired\"" event.   should enter neutral mode when disconnected  zks  log   by quitting elector 0 and ensuring elector 1 doesn\'t become active  getzksessionidfortests   should re-join the election and go back to standby  enterneutralmode  activestandbyelectortestutil  ========================== expiring standby\'s session  quitelection  thread  never  testhandlesessionexpirationofstandby  cbs  mockito  becomeactive  state  joinelection  electors   let elector 0 be active  appdatas  parent_dir
__label__flaky coordinator  action  should  not  have  been  purged  get  id  assert  equals  coord  job  get  executor  get  status  add  record  to  coord  action  table  execute  add  record  to  coord  job  table  coordinator  job  should  not  have  been  purged  coord  action  get  executor  call  coordinator  job  services  fail  coord-action-get.xml  assert  not  null  get  test  coord  purge  x  command  failed  coordinator  action  action  job  jpa  service  coordinator action should not have been purged  getid  assertequals  coordjobgetexecutor  getstatus  addrecordtocoordactiontable  execute  addrecordtocoordjobtable  coordinator job should not have been purged  coordactiongetexecutor  call  coordinatorjob  services  fail  coord-action-get.xml  assertnotnull  get  testcoordpurgexcommandfailed  coordinatoraction  action  job  jpaservice
__label__nflaky backoff  is  enabled   add  +  scheduler  backoff  =  overflow  exception.  call  queue  overflow  exception  backoff  is  enabled   put  +  scheduler  backoff  =  overflow  exception.  when  get  cause  should  back  off  put  scheduler  times  assert  true  call  queue  exceptions  passed  threw  as-is  test  call  queue  overflow  exceptions  cqm  trigger  failover  verify  didn\'t  throw  backoff  enabled   put  is  add  to  queue.  boolean  exception.  add  set  client  backoff  enabled  do  return  unchecked  call  queue  exceptions  that  trigger  failover  get  message  assert  equals  didn\'t  fail  assert  same  call  fail  do  throw  ex  mockito  backoff  disabled   put  is  put  to  queue.  cqe  mock  reset  to  string  spy  queue  cqm   backoff is enabled  add + scheduler backoff = overflow exception.  callqueueoverflowexception   backoff is enabled  put + scheduler backoff = overflow exception.  when  getcause  shouldbackoff  put  scheduler  times  asserttrue   call queue exceptions passed threw as-is  testcallqueueoverflowexceptions  cqmtriggerfailover  verify  didn\'t throw   backoff enabled  put is add to queue.  boolean   exception.  add  setclientbackoffenabled  doreturn  unchecked   call queue exceptions that trigger failover  getmessage  assertequals  didn\'t fail  assertsame  call  fail  dothrow  ex  mockito   backoff disabled  put is put to queue.  cqe  mock  reset  tostring  spy  queue  cqm
__label__flaky bundle  job  get  cmd  add  record  to  bundle  job  table  get  id  assert  equals  get  status  execute  call  services  test  bundle  pause  unpause3  assert  not  null  get  job  job  jpa  service  bundlejobgetcmd  addrecordtobundlejobtable  getid  assertequals  getstatus  execute  call  services  testbundlepauseunpause3  assertnotnull  get  job  job  jpaservice
__label__nflaky session  then  return  invoke  session  param  when  param1  get  context  create  verify  session  param  annotated  argument  should  be  passed  value  mock  controller  session  thenreturn  invoke  sessionparam  when  param1  get  context  create  verify  sessionparamannotatedargumentshouldbepassed  value  mockcontroller
__label__flaky get  id  assert  equals  get  status  execute  add  record  to  coord  job  table  call  coordinator  job  services  coord  job  get  cmd  assert  not  null  get  job  jpa  service  test  coord  suspend  and  resume  for  running  getid  assertequals  getstatus  execute  addrecordtocoordjobtable  call  coordinatorjob  services  coordjobgetcmd  assertnotnull  get  job  jpaservice  testcoordsuspendandresumeforrunning
__label__nflaky test  put  without  p  to  string  run  from  to  assert  attributes  changed  testputwithoutp  tostring  run  from  to  assertattributeschanged
__label__flaky put  value  pb  row_1  assert  equals  check  value  pb  table  delete  row  test  single  cell  get  put  pb  column_1  get  value  pb  response  value_1  put  value  xml  get  code  value_2  putvaluepb  row_1  assertequals  checkvaluepb  table  deleterow  testsinglecellgetputpb  column_1  getvaluepb  response  value_1  putvaluexml  getcode  value_2
__label__nflaky server  request  bytes  start  server  address  await  response  timeout  generate  random  bytes  client  callable  conf  send  response  assert  equals  get  connect  address  client  thread  net  utils  assert  stop  await  invocation  future  response  get  test  deferred  response  server  requestbytes  start  serveraddress  awaitresponsetimeout  generaterandombytes  clientcallable  conf  sendresponse  assertequals  getconnectaddress  clientthread  netutils  assert  stop  awaitinvocation  future  response  get  testdeferredresponse
__label__flaky end_  points  is_  security_  enabled  oozie  url  assert  false  run  app  path  test  coord  re  run  neg3  get  -config  create  servlet_  classes  close  run  test  app  mock  coordinator  engine  service  coordinator.xml  create  config  file  get  context  url  assert  equals  get  file  system  -rerun  0  args  call  -oozie  assert  null  mkdirs  to  string  job  get  fs  test  case  dir  end_points  is_security_enabled  oozieurl  assertfalse  run  apppath  testcoordrerunneg3  get  -config  create  servlet_classes  close  runtest  app  mockcoordinatorengineservice  coordinator.xml  createconfigfile  getcontexturl  assertequals  getfilesystem  -rerun  0  args  call  -oozie  assertnull  mkdirs  tostring  job  getfstestcasedir
__label__nflaky generate  certificate  truststore  location  basedir  put  sleep  wait  so  that  the  file  modification  time  is  different  password  jks  get  sha1with  rsa  wait  for  rsa  init  kp  create  trust  store  get  reload  interval  destroy  generic  test  utils  assert  equals  cert2  certs  generate  key  pair  cert1  thread  cn=  cert2  /testreload.jks  add  another  cert  cn=  cert1  tm  get  accepted  issuers  test  reload  generatecertificate  truststorelocation  basedir  put  sleep   wait so that the file modification time is different  password  jks  get  sha1withrsa  waitfor  rsa  init  kp  createtruststore  getreloadinterval  destroy  generictestutils  assertequals  cert2  certs  generatekeypair  cert1  thread  cn=cert2  /testreload.jks   add another cert  cn=cert1  tm  getacceptedissuers  testreload
__label__flaky is  meta  region  get  filenum  reader  conf  compare  to  dir  get  region  name  table  name  bytes  info  add  val  log  seq  id  get  key  to  bytes  get  row  1  entry  filename  assert  only  one  more  row...  the  meta  flushed  row.  start  cache  flush  compute  filename  next  log  region  name  fs  system  get  key  values  get  tablename  assert  true  test  edit  add  get  row  tablename  close  cols  key  timestamp  now  open  a  reader  on  the  log  and  assert  append  worked.  col_  count  entry  in  the  below...  thats  why  we  have  \'1\'.  get  reader  column  1   2   3...  complete  cache  flush  assert  equals  kv  close  and  delete  integer  get  value  get  family  current  time  millis  equals  to  string  h  log  append  get  edit  ismetaregion  getfilenum  reader  conf  compareto  dir  getregionname  tablename  bytes  info  add  val     logseqid  getkey  tobytes  getrow  1  entry  filename   assert only one more row... the meta flushed row.  startcacheflush  computefilename  next  log  regionname  fs  system  getkeyvalues  gettablename  asserttrue  testeditadd  get  row  tablename  close  cols  key  timestamp   now open a reader on the log and assert append worked.  col_count   entry in the below... thats why we have \'1\'.  getreader  column   1  2  3...  completecacheflush  assertequals  kv  closeanddelete  integer  getvalue  getfamily  currenttimemillis  equals  tostring  hlog  append  getedit
__label__nflaky previous  warnings.  monotonic  now  increment  and  get  log  warning  t  =  0  get  lock  t  =  2800  suppressed  t  =  2400  wsuppresed  t  =  1100  set  unlock  get  method  name  wlogged  log  mclock  mlock  assert  equals  test  lock  long  holding  report  testname  t  =  700  name  mock  time  t  =  200   previous warnings.  monotonicnow  incrementandget  logwarning   t = 0  get  lock   t = 2800  suppressed   t = 2400  wsuppresed   t = 1100  set  unlock  getmethodname  wlogged  log  mclock  mlock  assertequals  testlocklongholdingreport  testname   t = 700  name  mock  time   t = 200
__label__flaky rows_  one  expect  all  keys  in  all  but  two  rows  test  row  one-2  test  row  one-3  bytes  qualifiers_  one  families  should  see  all  keys  in  all  rows  but  test  row  two-2  values  expected  keys  verify  scan  no  early  out  expect  all  keys  in  two  rows  match  a  two  rows   one  from  each  group   using  regex  expected  rows  f  test  row.+-2  rows_  two  to  bytes  kvs  expect  all  keys  in  all  but  one  row  set  filter  test  row  two-0  qualifiers_  two  verify  scan  full  .+-2  match  a  single  row   all  keys  test  row  filter  compare  op  expect  all  keys  in  one  row  test  row  two-3  test  row  two-2  rows_one   expect all keys in all but two rows  testrowone-2   testrowone-3  bytes  qualifiers_one  families   should see all keys in all rows but testrowtwo-2  values  expectedkeys  verifyscannoearlyout   expect all keys in two rows   match a two rows  one from each group  using regex  expectedrows  f  testrow.+-2  rows_two  tobytes  kvs   expect all keys in all but one row  setfilter   testrowtwo-0  qualifiers_two  verifyscanfull  .+-2   match a single row  all keys  testrowfilter  compareop   expect all keys in one row   testrowtwo-3   testrowtwo-2
__label__nflaky avro  test  util  {\""type\"":\""string\"" \""java-class\"":\""org.apache.hadoop.io.  text\""}  test  reflect  foo  test  avro  reflect  avrotestutil  {\""type\"":\""string\"" \""java-class\"":\""org.apache.hadoop.io.text\""}  testreflect  foo  testavroreflect
__label__flaky cluster  locs  racks  conf  wait  for  replication  get  block  manager  dir  create  file  file  system  get  path  get  file  status  exclude  get  file  block  locations  get  working  directory  working  dir  dfs.hosts.exclude  test  node  decomission  respects  rack  policy  get  file  system  get  name  node  num  data  nodes  mkdirs  long  name  configure  an  excludes  file  create  a  file  with  one  block  get  first  block  wait  for  decommission  shutdown  otherwise  the  rack  policy  is  violated.  ns  *  test  that  rack  policy  is  still  respected  when  blocks  are  replicated  *  due  to  node  decommissioning.  /rack2  get  names  /rack1  fs  get  datanode  manager  assert  true  refresh  nodes  exclude  file  write  file  build/test/data/temp/decommission  dfs  test  util  b  set  get  conf  file  path  to  uri  replication_  factor  /test  file  build  get  local  local  file  sys  two  blocks  and  four  racks  check  the  block  still  has  sufficient  #  replicas  across  racks  get  namesystem    cluster  locs  racks  conf  waitforreplication  getblockmanager  dir  createfile  filesystem  getpath  getfilestatus  exclude  getfileblocklocations  getworkingdirectory  workingdir  dfs.hosts.exclude  testnodedecomissionrespectsrackpolicy  getfilesystem  getnamenode  numdatanodes  mkdirs  long  name   configure an excludes file   create a file with one block  getfirstblock  waitfordecommission  shutdown   otherwise the rack policy is violated.  ns       * test that rack policy is still respected when blocks are replicated     * due to node decommissioning.       /rack2  getnames  /rack1  fs  getdatanodemanager  asserttrue  refreshnodes  excludefile  writefile  build/test/data/temp/decommission  dfstestutil  b  set  getconf  filepath  touri  replication_factor  /testfile  build  getlocal  localfilesys   two blocks and four racks   check the block still has sufficient # replicas across racks  getnamesystem
__label__nflaky ninja  cache  parse  duration  cache  10s  time  util  verify  expiration  safe  add  test  safe  add  value  key  ninjacache  parseduration  cache  10s  timeutil  verify  expiration  safeadd  testsafeadd  value  key
__label__flaky is  original  tgt  returns  correct  values  /@  is  tgs  principal  assert  true  krbtgt/foo@foo  krbtgt/foo.bar.bat@foo.bar.bat  assert  false  krbtgt/foo@  foo  krbtgt/hello  security  util  blah    isoriginaltgtreturnscorrectvalues  /@  istgsprincipal  asserttrue  krbtgt/foo@foo  krbtgt/foo.bar.bat@foo.bar.bat  assertfalse  krbtgt/foo@foo  krbtgt/hello  securityutil  blah
__label__nflaky add  a:b:c  a  b  sub  list  c  a:b  assert  equals  string  utils  :  join  test  join  add    a:b:c  a  b  sublist  c  a:b  assertequals  stringutils  :  join  testjoin
__label__flaky delete  list  check  whether  transactions  are  rolled  back  or  not  expected  exception  due  to  commit  failure  but  didn\'t  get  any  add  record  to  wf  action  table  prep  get  id  workflow  instance  status  should  not  be  running  deactivate  wf  bean  add  record  to  wf  job  table  assert  not  null  wf  update  cmd1  get  test  bulk  updates  deletes  rollback  workflow  job  update  list  add  get  status  str  add  two  actions  to  delete  list  wf  get  cmd  assert  equals  skip  commit  fault  injection  execute  set  status  fault  injection  1  services  fail  2  workflow  action  org.apache.oozie.command.  skip  commit  fault  injection  set  system  property  true  action1  set  fault  injection  to  true   so  transaction  is  roll  backed  job  action2  add  to  update  list  wf  action  should  not  be  removed  due  to  rollback  but  was  not  found  jpa  service  deletelist   check whether transactions are rolled back or not  expected exception due to commit failure but didn\'t get any  addrecordtowfactiontable  prep  getid  workflowinstance   status should not be running  deactivate  wfbean  addrecordtowfjobtable  assertnotnull  wfupdatecmd1  get  testbulkupdatesdeletesrollback  workflowjob  updatelist  add  getstatusstr   add two actions to delete list  wfgetcmd  assertequals  skipcommitfaultinjection  execute  setstatus  faultinjection  1  services  fail  2  workflowaction  org.apache.oozie.command.skipcommitfaultinjection  setsystemproperty  true  action1   set fault injection to true  so transaction is roll backed  job  action2   add to update list  wf action should not be removed due to rollback but was not found  jpaservice
__label__nflaky test  prod  and  test  mode012  server  runs  in  test  mode.  this  route  is  prod  &  test.  request  core  matchers  equal  to  prod  and  test  works.  assert  that  make  request  url  path  assert  response  get  /0/1/2/mode/prod/and/test  test  server  url  testprodandtestmode012   server runs in test mode. this route is prod & test.  request  corematchers  equalto  prod and test works.  assertthat  makerequest  url  path  assert  response  get  /0/1/2/mode/prod/and/test  testserverurl
__label__flaky init  get  topic  pattern  properties  print  stack  trace  e  get  message  destroy  jms  topic  service  ${username}  assert  equals  services  setup  services  for  topic  props  fail  services  test  topic  properties1  get  app  type  init  gettopicpatternproperties  printstacktrace  e  getmessage  destroy  jmstopicservice  ${username}  assertequals  services  setupservicesfortopic  props  fail  services  testtopicproperties1  get  apptype
__label__nflaky test  parse  utf8  string  test  parse  utf8  ampersand2  string  testparseutf8string  testparseutf8ampersand2string
__label__flaky check  coord  actions  get  id  date  utils  get  status  parse  date  oozie  tz  add  record  to  coord  job  table  2009-03-06  t10:00  z  call  coordinator  job  2009-03-06  t09:58  z  pause  time  start  time  end  time  job  evaluate  wait  for  2009-03-06  t10:14  z  test  action  mater  with  pause  time3  checkcoordactions  getid  dateutils  getstatus  parsedateoozietz  addrecordtocoordjobtable  2009-03-06t10:00z  call  coordinatorjob  2009-03-06t09:58z  pausetime  starttime  endtime  job  evaluate  waitfor  2009-03-06t10:14z  testactionmaterwithpausetime3
__label__nflaky address  factory  address  host4  host_  list  address  mock  host4  address  mock  host5  assert  false  test  for  exclusion  with  an  unknown  ip  test  for  inclusion  with  an  known  ip  when  address  host1  assert  true  string  utils  get  by  name  get  trimmed  string  collection  1.2.3.1  ml  host5  different  name  host4  host1  1.2.3.4  get  canonical  host  name  then  return  1.2.3.5  includes  create  machine  list  with  a  list  of  of  hostnames  mockito  mock  test  host  names  inet  address  addressfactory  addresshost4  host_list  addressmockhost4  addressmockhost5  assertfalse   test for exclusion with an unknown ip   test for inclusion with an known ip  when  addresshost1  asserttrue  stringutils  getbyname  gettrimmedstringcollection  1.2.3.1  ml  host5  differentname  host4  host1  1.2.3.4  getcanonicalhostname  thenreturn  1.2.3.5  includes   create machinelist with a list of of hostnames  mockito  mock  testhostnames  inetaddress
__label__flaky verify  fsck  health  file  name  file  path  dfs  client  read  file  from  position  dfs  client  read  file  corrupted  replicas  to  the  name  node.  test  corrupt  all  of  three  replicas  located  block  should  not  have  the  block  marked  as  corrupted.  expected  replicas  returned  ask  dfs  client  to  read  the  file  verify  first  block  corrupted  create  a  file  with  corrupted  block  replicas  /tmp/test  client  report  bad  block/test  corrupt  all  replicas  create  a  file  verify  corrupted  block  count  repl  test  fsck  list  corrupt  files  blocks  corrupt  block  number    verifyfsckhealth  filename  filepath  dfsclientreadfilefromposition  dfsclientreadfile   corrupted replicas to the name node.  testcorruptallofthreereplicas   locatedblock should not have the block marked as corrupted.  expectedreplicasreturned   ask dfs client to read the file  verifyfirstblockcorrupted  createafilewithcorruptedblockreplicas  /tmp/testclientreportbadblock/testcorruptallreplicas   create a file  verifycorruptedblockcount  repl  testfscklistcorruptfilesblocks  corruptblocknumber
__label__nflaky a  ${  a}  expect  circular  variable  reference  detected  while  parsing  input  ${  a}  -->  ${  a}  option  helper  context  detect  circular  references0  put  property  expected  exception  expect  message  subst  vars  a  ${a}  expect  circular variable reference detected while parsing input ${a} --> ${a}  optionhelper  context  detectcircularreferences0  putproperty  expectedexception  expectmessage  substvars
__label__flaky object  writer  then  fill  up  deque  when  timeout  deque  offer  verify  write  when  adds  info  message  when  event  is  being  dropped  because  of  connection  problem  and  deque  capacity  limit  reached  given  max  start  appender  add  info  any  object  some  event  do  throw  reset  dropping  event  due  to  socket  connection  error  and  maxed  out  deque  capacity  timeout  await  start  of  event  dispatching  remaining  capacity  append    objectwriter   then   fill up deque  when  timeout  deque  offer  verify  write   when  addsinfomessagewheneventisbeingdroppedbecauseofconnectionproblemanddequecapacitylimitreached   given  max  start  appender  addinfo  anyobject  some event  dothrow  reset  dropping event due to socket connection error and maxed out deque capacity  timeout  awaitstartofeventdispatching  remainingcapacity  append
__label__nflaky assert  correct  image2binary  test  decode  row2binary19  19.png  ..  xxxx..  ........  .  x..  xxx.  x.  x.  x...  xx.  xxxxx  .  xxxx.  x.  ..  xx...  x  .  x.....  x  .  xx.....  xxxx.  x..  xx..  (01)90012345678908(3102)001750(15)100312  assertcorrectimage2binary  testdecoderow2binary19  19.png   ..xxxx.. ........ .x..xxx. x.x.x... xx.xxxxx .xxxx.x. ..xx...x .x.....x .xx..... xxxx.x.. xx..   (01)90012345678908(3102)001750(15)100312
__label__flaky add  create  lists  for  status  filter  running  test  coord  action  filter  get  id  add  coordinator  action  with  nominal  time:  2009-12-15  t01:00  z  add  record  to  coord  action  table  add  record  to  coord  job  table  coordinator  job  check  status  filters  for  coordinator  actions  coord-action-get.xml  _test  get  actions  subset  filter  coordinator  action  job  filter  list  killed  add  coordinator  action  with  nominal  time:  2009-02-01  t23:59  z  add   create lists for status filter  running  testcoordactionfilter  getid   add coordinator action with nominal time: 2009-12-15t01:00z  addrecordtocoordactiontable  addrecordtocoordjobtable  coordinatorjob   check status filters for coordinator actions  coord-action-get.xml  _testgetactionssubsetfilter  coordinatoraction  job  filterlist  killed   add coordinator action with nominal time: 2009-02-01t23:59z
__label__nflaky headers  custom  converter  multiple  \':method\'  request  headers  are  illegal  thrown  convert  www.example.com  as  list  expect  message  /  expect  :method  :scheme  get  test  convert  from  fields  multiple  method  http  :path  arrays  value  :authority  headers  custom  converter  multiple \':method\' request headers are illegal  thrown  convert  www.example.com  aslist  expectmessage  /  expect  :method  :scheme  get  testconvertfromfieldsmultiplemethod  http  :path  arrays  value  :authority
__label__flaky inner  filter  context  should  not  leak  context  for  nested  request  init  res  chain  mock  filter  config  assert  equals  count  active  mock  filter  chain  mock  request  mock  response  do  filter  victim  req  innerfilter  context  shouldnotleakcontextfornestedrequest  init  res  chain  mockfilterconfig  assertequals  countactive  mockfilterchain  mockrequest  mockresponse  dofilter  victim  req
__label__nflaky fs.localfs1.impl  set  get  name  print  stack  trace  e  initialize  forever  file  system  start  conf  run  get  file  system  class  acquire  test  cache  enabled  with  initialize  forever  fs  org.apache.hadoop.fs.  fs.cachedfile.impl  file  cachedfile://a  t  test  file  system  caching$  initialize  forever  file  system  localfs1://a  wait  for  initialize  forever  file  system  to  start  initialization  file  system  get  interrupt  join  fs.localfs1.impl  set  getname  printstacktrace  e  initializeforeverfilesystem  start  conf  run  getfilesystemclass  acquire  testcacheenabledwithinitializeforeverfs  org.apache.hadoop.fs.  fs.cachedfile.impl  file  cachedfile://a  t  testfilesystemcaching$initializeforeverfilesystem  localfs1://a   wait for initializeforeverfilesystem to start initialization  filesystem  get  interrupt  join
__label__flaky unexpected  exception  def  add  node  print  stack  trace  f  one  test  transition2  j  k  kill  three  two  as  list  fail  ex  invoke  fork  join  parser  f->(2 3)  2->fail->3  2->ok->j  3->ok->j  3->fail->k  j->end  name  dummy  conf  end  arrays  unexpected exception  def  addnode  printstacktrace  f  one  testtransition2  j  k  kill  three  two  aslist  fail  ex  invokeforkjoin  parser        f->(2 3)      2->fail->3      2->ok->j      3->ok->j      3->fail->k      j->end       name  dummyconf  end  arrays
__label__nflaky test  unknown  length  constructor  assert  empty  input  stream  assert  equals  get  content  length  entity  testunknownlengthconstructor  assert  emptyinputstream  assertequals  getcontentlength  entity
__label__flaky get  job  tracker  uri  root  archive  root  so  so  file.so.1  with  leading  and  trailing  spaces  create  context  setup  action  conf  files  in  cache  context  get  path  create  jar  root  jar  get  cache  files  <main-class>  class</main-class>  <job-tracker>  e  action  xml  <file>  ae  </file>  parse  xml  </job-tracker>  archive  get  file  system        archive  </name-node>  set  lib  files  archives  found  in  classpath  so  file.so  root  so  file.so  not  found  in  cache  job  conf  archive.tar  <archive>  <java>  assert  false  get  app  path  app  path  create  base  hadoop  conf  action  xml  root  so1  root  jar.jar  file  found  so1  distributed  cache  assert  true  root  so  files  in  classpath  close  get  name  node  uri  get  file  class  paths  root  archive.tar  c  </java>  xml  utils  root  so  file.so.1  </archive>  to  uri  test  comma  separated  files  and  archives  archives  in  cache  file  get  symlink  not  found  in  classpath  p  get  cache  archives     equals  root  file  to  string  <name-node>  get  fs  test  case  dir  jar.jar  getjobtrackeruri  rootarchive  rootso  sofile.so.1   with leading and trailing spaces  createcontext  setupactionconf  filesincache  context  getpath  create  jar  rootjar  getcachefiles        <main-class>class</main-class>        <job-tracker>  eactionxml        <file>  ae  </file>    parsexml  </job-tracker>  archive  getfilesystem          archive   </name-node>  setlibfilesarchives   found in classpath  sofile.so  rootsofile.so   not found in cache  jobconf  archive.tar        <archive>  <java>  assertfalse  getapppath  apppath  createbasehadoopconf  actionxml  rootso1  rootjar.jar  file  found  so1  distributedcache  asserttrue  root  so  filesinclasspath  close  getnamenodeuri  getfileclasspaths  rootarchive.tar  c  </java>  xmlutils  rootsofile.so.1   </archive>    touri  testcommaseparatedfilesandarchives  archivesincache  file   getsymlink   not found in classpath  p  getcachearchives      equals  rootfile  tostring        <name-node>  getfstestcasedir  jar.jar
__label__nflaky init  application/json  then  return  servlet  context  text/*;q=0.3   text/html;q=0.7   text/html;level=1   text/html;level=2;q=0.4   */*;q=0.5  assert  equals  get  accept  content  type  test  get  accept  content  type  http  servlet  request  text/html;q=1   application/json;q=0.9  when  application/json;q=0.9   text/plain;q=0.5  accept  get  header  result  application/protobuf;q=1   application/json;q=0.7  application/protobuf  totally_unknown  context  application/xhtml;q=1   application/json;q=0.9  http  servlet  response  text/plain    init  application/json  thenreturn  servletcontext  text/*;q=0.3  text/html;q=0.7  text/html;level=1  text/html;level=2;q=0.4  */*;q=0.5  assertequals  getacceptcontenttype  testgetacceptcontenttype  httpservletrequest  text/html;q=1  application/json;q=0.9  when  application/json;q=0.9  text/plain;q=0.5  accept  getheader  result  application/protobuf;q=1  application/json;q=0.7  application/protobuf  totally_unknown  context  application/xhtml;q=1  application/json;q=0.9  httpservletresponse  text/plain
__label__flaky unexpected  exception  f->(2 3)  2->ok->j  2->fail->4  3->ok->4  3->fail->k  4->ok->j  4->fail->k  j->end  def  add  node  print  stack  trace  f  one  j  k  kill  three  two  as  list  test  transition3  fail  ex  invoke  fork  join  parser  four  name  dummy  conf  end  arrays  unexpected exception       f->(2 3)     2->ok->j     2->fail->4     3->ok->4     3->fail->k     4->ok->j     4->fail->k     j->end      def  addnode  printstacktrace  f  one  j  k  kill  three  two  aslist  testtransition3  fail  ex  invokeforkjoin  parser  four  name  dummyconf  end  arrays
__label__nflaky fail  assert  test  invalid  construction  illegal  argument  exception  should  have  been  thrown  fail  assert  testinvalidconstruction  illegalargumentexception should have been thrown
__label__flaky cluster  write  into  hosts  file  write  config  file  conf  dir  heartbeat_  interval  wait  active  setup  conf  assert  assert  not  null  file  system  get  path  exclude  info  add  hosts  file  get  working  directory  dfs  config  keys  get  host  name  hosts  working  dir  restart  name  node  stringify  exception  num  name  nodes  list  fail  num  data  nodes  get  by  address  number  of  live  nodes  should  be  inet  address  shutdown  nn  setup  hosts  file  get  datanode  report  test  nn  restart  set  up  the  hosts/exclude  files.  sleep  build/test/data/work-dir/restartnn  assert  true  string  utils  num  datanodes  exclude  file  cleanup  file  b  get  parent  is  data  node  up  set  e  to  uri  heartbeat  interval  in  seconds  assert  equals  get  name  node  rpc  thread  inet  address  build  get  local  local  file  sys  datanode  report  type  cluster   write into hosts file  writeconfigfile  conf  dir  heartbeat_interval  waitactive   setup conf  assert  assertnotnull  filesystem  getpath  exclude  info  add  hostsfile  getworkingdirectory  dfsconfigkeys  gethostname  hosts  workingdir  restartnamenode  stringifyexception  numnamenodes  list  fail  numdatanodes  getbyaddress  number of live nodes should be   inetaddress  shutdown  nn  setuphostsfile  getdatanodereport  testnnrestart   set up the hosts/exclude files.  sleep  build/test/data/work-dir/restartnn  asserttrue  stringutils  numdatanodes  excludefile  cleanupfile  b  getparent  isdatanodeup  set  e  touri   heartbeat interval in seconds  assertequals  getnamenoderpc  thread  inetaddress  build  getlocal  localfilesys  datanodereporttype
__label__nflaky request  conn  resolve  get  request  test  protocol  exception  response  captor  send  response  header  error  when  receive  request  header  oh   this  world  is  wrong  request  handler  assert  httpservice  assert  not  null  context  create  for  class  verify  get  code  close  process  argument  captor  http  status  then  return  capture  handle  assert  equals  send  response  entity  assert  same  get  entity  whatever  /  get  value  do  throw  response  factory  mockito  response  http  core  context  new  http  response  httprocessor  handle  request  handler  resolver  request  conn  resolve  getrequest  testprotocolexception  responsecaptor  sendresponseheader  error  when  receiverequestheader  oh  this world is wrong  requesthandler  assert  httpservice  assertnotnull  context  create  forclass  verify  getcode  close  process  argumentcaptor  httpstatus  thenreturn  capture  handle  assertequals  sendresponseentity  assertsame  getentity  whatever  /  getvalue  dothrow  responsefactory  mockito  response  httpcorecontext  newhttpresponse  httprocessor  handlerequest  handlerresolver
__label__flaky shutdown  dfs  ab  bbc  test  filters  get  log  prefix  to  bytes  scan  h  constants  new  filter  add  content  close  and  delete  create  new  h  region  set  filter  bytes  row  prefix  filter  row  inclusive  stop  filter  get  table  desc  stop  row  region_  info  close  shutdowndfs  ab  bbc  testfilters  getlog  prefix  tobytes  scan  hconstants  newfilter  addcontent  closeanddelete  createnewhregion  setfilter  bytes  rowprefixfilter  rowinclusivestopfilter  gettabledesc  stoprow  region_info  close
__label__nflaky set  depth  first  prepare  item2  item5ca  item1  conf  set  root  expression  when  set  out  out  result  find  in  order  verify  set  options  expr  finish  item1b  item1a  item5e  item5d  item5c  create  directories  item5b  process  arguments  depth  first  item5a  set  err  fs  check  err  test  in  order  fs  check  apply  then  return  check  process  arguments  any  set  conf  any  int  verify  no  more  interactions  mock  get  options  check  that  directories  are  descended  correctly  when  -depth  is  specified  item1aa  item4  items  item3  item5  setdepthfirst  prepare  item2  item5ca  item1  conf  setrootexpression  when  setout  out  result  find  inorder  verify  setoptions  expr  finish  item1b  item1a  item5e  item5d  item5c  createdirectories  item5b  processargumentsdepthfirst  item5a  seterr  fscheck  err  test  inorderfscheck  apply  thenreturn  check  processarguments  any  setconf  anyint  verifynomoreinteractions  mock  getoptions   check that directories are descended correctly when -depth is specified  item1aa  item4  items  item3  item5
__label__flaky /////////////////////////////////////////////////////////////////////  ninja  test  browser  assert  false  api/bob@gmail.com/article.xml  contentcontent  system  set  default  use  wrapper  one  new  result:  assert  true  new  title  new  title  api/bob@gmail.com/articles.xml  article  dto  read  value  get  server  address  do  login  module  response  xml:  test  get  and  post  article  via  xml  assert  equals  and  then  configure   for  example:  articles  dto  error.  forbidden.  make  xml  request  contains  size  response  post  xml  xml  mapper   /////////////////////////////////////////////////////////////////////  ninjatestbrowser  assertfalse  api/bob@gmail.com/article.xml  contentcontent  system  setdefaultusewrapper   one new result:  asserttrue  new title new title  api/bob@gmail.com/articles.xml  articledto  readvalue  getserveraddress  dologin  module  response xml:   testgetandpostarticleviaxml  assertequals   and then configure  for example:  articlesdto  error. forbidden.  makexmlrequest  contains  size  response  postxml  xmlmapper
__label__nflaky verify  paths  fs  ips  authorities  test  full  authority  with  default  port  myfs://host.a.b:123  get  verified  fs  verifypaths  fs  ips  authorities  testfullauthoritywithdefaultport  myfs://host.a.b:123  getverifiedfs
__label__flaky cluster  block  size  is  1  mb.  write  byte  get  data  nodes  hdfs  constants  src  set  quota  fs  /  test_quota1  dfs  setting  diskspace  quota  to  3  mb  shutdown  one  datanode   causing  the  block  abandonment.  fail  test  quota  updated  when  block  abandoned  get  file_  name_  prefix  fout  create  unexpected  quota  exception  when  closing  fout  close  close  the  file   new  block  will  be  allocated  with  2  mb  pending  size.  shutdown  cluster   block size is 1mb.  writebyte  getdatanodes  hdfsconstants  src  setquota  fs  /  test_quota1  dfs   setting diskspace quota to 3mb   shutdown one datanode  causing the block abandonment.  fail  testquotaupdatedwhenblockabandoned  get  file_name_prefix  fout  create  unexpected quota exception when closing fout  close   close the file  new block will be allocated with 2mb pending size.  shutdown
__label__nflaky request  conn  get  request  when  assert  flush  executor  context  create  verify  ok  post  process  process  then  return  get  response  method  get  entity  assert  same  execute  test  basic  execution  /  mockito  response  http  core  context  httprocessor  mock  pre  process  receive  response  header  send  request  header  receive  response  entity  request  conn  getrequest  when  assert  flush  executor  context  create  verify  ok  postprocess  process  thenreturn  getresponse  method  getentity  assertsame  execute  testbasicexecution  /  mockito  response  httpcorecontext  httprocessor  mock  preprocess  receiveresponseheader  sendrequestheader  receiveresponseentity
__label__flaky hive  end_  points  is_  security_  enabled  lib  oozie  url  conf  wc  /test  system  localhost:9001  lib  path  assert  true  get  test  case  dir  get  create  external  table  ${  name}  (a  int);  servlet_  classes  write  close  run  test  get  context  url  hive  script  file  x  oozie  client  mock  dag  engine  service  hdfs://localhost:9000  assert  equals  get  file  system  params  submit  script  language  call  oozie  client  name=test  mkdirs  set  property  wf  count  create  configuration  to  string  writer  test  submit  hive  get  fs  test  case  dir  hive  end_points  is_security_enabled  lib  oozieurl  conf  wc  /test  system  localhost:9001  libpath  asserttrue  gettestcasedir  get  create external table ${name} (a int);  servlet_classes  write  close  runtest  getcontexturl  hivescriptfile  xoozieclient  mockdagengineservice  hdfs://localhost:9000  assertequals  getfilesystem  params  submitscriptlanguage  call  oozieclient  name=test  mkdirs  setproperty  wfcount  createconfiguration  tostring  writer  testsubmithive  getfstestcasedir
__label__nflaky get  parsed  type  no  null  form  primitives  parse  parameter  asdfasdf  is  test  primitive  double  param  parser  matchers  assert  that  param1  double  param  parser  0  000  -123  123  0.1  123.1  -123.1  validation    getparsedtype   no null form primitives  parseparameter  asdfasdf  is  testprimitivedoubleparamparser  matchers  assertthat  param1  doubleparamparser  0  000  -123  123  0.1  123.1  -123.1  validation
__label__flaky initial  callable  callables  *  testing  an  interrupt  commands  inside  a  composite  callable  assuring  it  is  *  executed  before  the  others  type  queue  serial  queueservice  initial  key  assert  true  get  initial  type  lock  key  wait  for  key  exec_  order  add  init  c  initial  lock  key  ret  value  callable  queue  service  destroy  services  1  test  kill  set  system  property  evaluate  test  interrupts  in  composite  callable  queue  initialcallable  callables         * testing an interrupt commands inside a composite callable assuring it is       * executed before the others         type  queueserial  queueservice  initialkey  asserttrue  get  initialtype  lockkey  waitfor  key  exec_order  add  init  c  initiallockkey  retvalue  callablequeueservice  destroy  services  1  testkill  setsystemproperty  evaluate  testinterruptsincompositecallable  queue
__label__nflaky credential  provider  factory  conf  our  url  test  local  jks  provider  delete  fs  local  java  key  store  provider  tmp  dir  path  file  assert  true  777  get  file  status  set  permission  check  permission  retention  after  explicit  change  rw-------  test.jks  unnest  uri  set  get  permission  check  specific  provider  is  file  to  uri  assert  equals  get  file  system  should  exist  unexpected  permissions:  jks  path  ://file  check  permission  retention  to  string  provider  utils  credentialproviderfactory  conf  oururl  testlocaljksprovider  delete  fs  localjavakeystoreprovider  tmpdir  path  file  asserttrue  777  getfilestatus  setpermission   check permission retention after explicit change  rw-------  test.jks  unnesturi  set  getpermission  checkspecificprovider  isfile  touri  assertequals  getfilesystem   should exist  unexpected permissions:   jkspath  ://file  checkpermissionretention  tostring  providerutils
__label__flaky request  get  id  assert  equals  test  distribution  target  accept  get  value  list_  id_  value_  type  assert  oryx  test  recs  get  x  media  type  y  z  /classification  distribution/  b 0   request  getid  assertequals  testdistribution  target  accept  getvalue  list_id_value_type  assert  oryxtest  recs  get  x  mediatype  y  z  /classificationdistribution/b 0
__label__nflaky create  user  for  testing  test  proxy  users  with  provider  override  set  proxy  users  proxy  user  ugi  refresh  super  user  groups  configuration  assert  authorized  group_  names  1.2.3.4  1.2.3.5  conf  now  try  proxying  a  group  that\'s  not  allowed  sudo_  group_  names  real_  user_  name  common  configuration  keys  public  assert  not  authorized  from  good  ip  org.apache.hadoop.security.authorize.  test  proxy  users$  test  dummy  impersonation  provider  proxy_  user_  name  from  bad  ip  user  group  information  real  user  ugi  first  try  proxying  a  group  that\'s  allowed  create  proxy  user  for  testing  createuserfortesting  testproxyuserswithprovideroverride  set  proxyusers  proxyuserugi  refreshsuperusergroupsconfiguration  assertauthorized  group_names  1.2.3.4  1.2.3.5  conf   now try proxying a group that\'s not allowed  sudo_group_names  real_user_name  commonconfigurationkeyspublic  assertnotauthorized   from good ip  org.apache.hadoop.security.authorize.testproxyusers$testdummyimpersonationprovider  proxy_user_name   from bad ip  usergroupinformation  realuserugi   first try proxying a group that\'s allowed  createproxyuserfortesting
__label__flaky src  conf  set  test  inject  defaults  assert  equals  target  conf  x  configuration  test  parameter1  test  parameter2  assert  null  test  parameter3  inject  defaults  original  value  from  target  get  value  from  source  srcconf  set  testinjectdefaults  assertequals  targetconf  xconfiguration  testparameter1  testparameter2  assertnull  testparameter3  injectdefaults  originalvaluefromtarget  get  valuefromsource
__label__nflaky data  become  standby  mock  no  prior  active  should  not  call  neutral  mode/standby/active  when  zk_  lock_  name  no  new  monitor  called  times  verify  ids  create  verify  exist  call  test  create  node  result  become  active  mock  app  stat  int  value  then  return  another  join  election  not  called.  enter  neutral  mode  process  result  elector  code  not  call  become  active  since  its  already  active  mock  zk  set  ephemeral  owner  create  mode  mockito  become  active  join  election  get  session  id  data  becomestandby  mocknoprioractive   should not call neutral mode/standby/active  when  zk_lock_name   no new monitor called  times  verify  ids  create  verifyexistcall  testcreatenoderesultbecomeactive  mockapp  stat  intvalue  thenreturn   another joinelection not called.  enterneutralmode  processresult  elector  code   not call becomeactive since its already active  mockzk  setephemeralowner  createmode  mockito  becomeactive  joinelection  getsessionid
__label__flaky select  *  from  entitywithstaticcolumn  where  id  =  session  given  another_static_col  crud  another_static_val1  another_static_val2  when  with  insert  strategy  id  static_col  insert  strategy  is  not  null  actual  random  utils  manager  one  static_val1  get  string  next  long  assert  that  insert  static  execute  entity1  entity2  should_insert_static_with_insert_strategy  then  long  is  equal  to  select * from entitywithstaticcolumn where id =   session   given  another_static_col  crud  another_static_val1  another_static_val2   when  withinsertstrategy  id  static_col  insertstrategy  isnotnull  actual  randomutils  manager  one  static_val1  getstring  nextlong  assertthat  insertstatic  execute  entity1  entity2  should_insert_static_with_insert_strategy   then  long  isequalto
__label__nflaky assert  service  creation  fails  self  test  not  a  service  assertservicecreationfails  self  testnotaservice
__label__flaky test  async  close_read  write  lock  got  async  close  exception  channel  executors  handler  latch  get  cause  sleep  uninterruptibly  write  cause  another  thread  trying  to  read  to  block  exc  assert  true  executor  get  await  lock  count  down  close  milliseconds  read  set  new  fixed  thread  pool  expected  store  completed  failed  give  enough  time  to  ensure  both  reads  start  blocking  byte  store  byte  buffer  read  fail  allocate  future  uninterruptibles  shutdown  testasyncclose_read  writelock  gotasynccloseexception  channel  executors  handlerlatch  getcause  sleepuninterruptibly  write   cause another thread trying to read to block  exc  asserttrue  executor  get  await  lock  countdown  close  milliseconds  read  set  newfixedthreadpool  expected  store  completed  failed   give enough time to ensure both reads start blocking  bytestore  bytebuffer  read  fail  allocate  future  uninterruptibles  shutdown
__label__nflaky _test  do  filter  authentication  test  do  filter  authentication  with  domain  path  _testdofilterauthentication  testdofilterauthenticationwithdomainpath
__label__flaky test  coord  actions  running  for  size  action  num  coordinator  job  job  id  *  add  2  coordinator  actions  with  status  running   1  action  with  status  failed  and  1  with  killed.  check  for  expected  *  number  of  actions  retrieved  coord-action-get.xml  _test  coord  actions  running  size  coordinator  action  get  id  job  add  record  to  coord  action  table  add  record  to  coord  job  table  testcoordactionsrunningforsize  actionnum  coordinatorjob  jobid         * add 2 coordinator actions with status running  1 action with status failed and 1 with killed. check for expected       * number of actions retrieved         coord-action-get.xml  _testcoordactionsrunningsize  coordinatoraction  getid  job  addrecordtocoordactiontable  addrecordtocoordjobtable
__label__nflaky java.version  env  util  assert  true  set  property  assert  false  is  jdk6  or  higher  is  jdk5  1.6.xx  test  java1_6  system  is  jdk7  or  higher  java.version  envutil  asserttrue  setproperty  assertfalse  isjdk6orhigher  isjdk5  1.6.xx  testjava1_6  system  isjdk7orhigher
__label__flaky get  coord  action  add  record  to  coord  job  table  for  waiting  get  missing  dependencies  coord  el  functions  get  id  date  utils  parse  date  oozie  tz  get  2009-03-11  t10:00  z  coord-job-for-matd-hcat.xml  start  time  action  bean  init  destroy  assert  equals  services  hcat://dummyhcat:1000/db1/table1/ds=2009-12  ${coord:latest  range(-1 0)}  call  file://dummyhdfs/2009/05/_  success  services  coordinator  job  @1  hcat://dummyhcat:1000/db3/table3/ds=2009-05  hcat://dummyhcat:1000/db3/table3/ds=2009-26  2009-03-06  t010:00  z  setup  services  for  h  catalog  test  action  mater  for  hcatalog  coord  command  utils  get  push  missing  dependencies  end  time  job  getcoordaction  addrecordtocoordjobtableforwaiting  getmissingdependencies  coordelfunctions  getid  dateutils  parsedateoozietz  get  2009-03-11t10:00z  coord-job-for-matd-hcat.xml  starttime  actionbean  init  destroy  assertequals  services  hcat://dummyhcat:1000/db1/table1/ds=2009-12  ${coord:latestrange(-1 0)}  call  file://dummyhdfs/2009/05/_success  services  coordinatorjob  @1  hcat://dummyhcat:1000/db3/table3/ds=2009-05  hcat://dummyhcat:1000/db3/table3/ds=2009-26  2009-03-06t010:00z  setupservicesforhcatalog  testactionmaterforhcatalog  coordcommandutils  getpushmissingdependencies  endtime  job
__label__nflaky =>  same  timestamp  =>  not  modified  assert  false  when  get  header  =>  strange  timestamp  =>  modified  is  modified  thu   01  jan  1970  00:00:00  gmt  assert  true  thu   01  jan  1971  00:00:00  gmt  of  context  =>  no  if  modified  since  request  =>  null  optional  then  return  etag_xyz  strange_  timestamp  test  etag  support:  http  cache  toolkit  remove  etag  to  test  modified  timestamp  caching:  =>  older  timestamp  =>  modified  etag_xyz_modified  same  etag  =>  not  modified  ninja  properties  new  etag  =>  modified  =>  newer  timestamp  =>  not  modified  test  is  modified  http  header  constants   => same timestamp => not modified  assertfalse  when  getheader   => strange timestamp => modified  ismodified  thu  01 jan 1970 00:00:00 gmt  asserttrue  thu  01 jan 1971 00:00:00 gmt  of  context   => no if modified since request => null  optional  thenreturn  etag_xyz  strange_timestamp   test etag support:  httpcachetoolkit   remove etag to test modified timestamp caching:   => older timestamp => modified  etag_xyz_modified   same etag => not modified  ninjaproperties   new etag => modified   => newer timestamp => not modified  testismodified  httpheaderconstants
__label__flaky hdfs foo  hae  allow  all  schemes  giving  no  scheme  should  skip  the  check  get  error  code  file://localhost:1234/blah  get  has  hdfs://localhost:1234/blah  init  set  get  conf  /blah  only  allow  hdfs  and  foo  schemes  assert  equals  *  test  check  supported  filesystem  should  have  thrown  an  exception  because  \'file\'  scheme  isn\'t  allowed  services  fail  check  supported  filesystem  h  conf  foo://localhost:1234/blah  oozie.service.  hadoop  accessor  service.supported.filesystems  error  code  hdfs foo  hae   allow all schemes   giving no scheme should skip the check  geterrorcode  file://localhost:1234/blah  get  has  hdfs://localhost:1234/blah  init  set  getconf  /blah   only allow hdfs and foo schemes  assertequals  *  testchecksupportedfilesystem  should have thrown an exception because \'file\' scheme isn\'t allowed  services  fail  checksupportedfilesystem  hconf  foo://localhost:1234/blah  oozie.service.hadoopaccessorservice.supported.filesystems  errorcode
__label__nflaky test  data  kerala  recor  standard  charsets  line  assert  equals  read  line  get  bytes  bangalore  core  assert  delimiter  test  custom  delimiter2  record  ~  eof  with  \'re\'  line  reader  north  korea  to  string  test  string  builder  guantanamo  close  append  ecord    testdata  kerala   recor  standardcharsets  line  assertequals  readline  getbytes  bangalore  core  assert  delimiter  testcustomdelimiter2  record   ~eof with \'re\'  linereader   north korea  tostring  teststringbuilder  guantanamo  close  append  ecord
__label__flaky @  no  file  system  for  scheme  time  out  creation  time  check  coord  action  timeout.  tz  add  init  records  substring  system  sleep  test  timeout  with  exception  assert  true  coordinator  action  missing  deps  index  of  set  coord  action  creation  time  e  get  message  thread  call  fail  contains  current  time  millis  nofs:///dirx/filex  action  id  @  no filesystem for scheme  timeoutcreationtime  checkcoordaction   timeout.  tz  addinitrecords  substring  system  sleep  testtimeoutwithexception  asserttrue  coordinatoraction  missingdeps  indexof  setcoordactioncreationtime  e  getmessage  thread  call  fail  contains  currenttimemillis  nofs:///dirx/filex  actionid
__label__nflaky server  rpc  new  reflective  blocking  service  get  proxy  ping  set  protocol  conf  echo  set  rpc  engine  to  protobuf  rpc  engine  set  port  empty  request  client  and  server.  expected  an  exception  to  occur  as  version  mismatch.  test  protocol  version  mismatch  empty  request  proto  set  protocol  engine  addr  new  protobuf  rpc  proto  get  rpc  server  for  server  side  implementation  version  mismatch  set  bind  address  common  configuration  keys  port  e  server  impl  verify  that  missing  of  optional  field  is  still  compatible  in  rpc  call.  start  get  message  new  proxy  new  builder  set  int  get  connect  address  proxy  fail  contains  exception  type  is  not  what  we  expected   re-throw  it.  net  utils  build  service  address  create  server  side  implementation  set  instance  server  rpc  newreflectiveblockingservice  getproxy  ping  setprotocol  conf  echo   set rpc engine to protobuf rpc engine  setport  emptyrequest   client and server.  expected an exception to occur as version mismatch.  testprotocolversionmismatch  emptyrequestproto  setprotocolengine  addr  newprotobufrpcproto   get rpc server for server side implementation  version mismatch  setbindaddress  commonconfigurationkeys  port  e  serverimpl   verify that missing of optional field is still compatible in rpc call.  start  getmessage  newproxy  newbuilder  setint  getconnectaddress  proxy  fail  contains   exception type is not what we expected  re-throw it.  netutils  build  service  address   create server side implementation  setinstance
__label__flaky subwf  job  get  cmd  add  record  to  wf  action  table  get  id  workflow  instance  get  status  sub  workflow  action  should  have  been  purged  wf  job  workflow  job  should  have  been  purged  add  record  to  wf  job  table  get  error  code  assert  not  null  get  workflow  job  wf  action  subwf  action  wf  job  get  cmd  test  purge  wf  with  sub  wf3  workflow  action  should  have  been  purged  sub  workflow  job  should  have  been  purged  wf  action  get  cmd  assert  equals  execute  subwf  action  get  cmd  call  services  1  fail  workflow  action  subwf  job  error  code  je  jpa  service  subwfjobgetcmd  addrecordtowfactiontable  getid  workflowinstance  getstatus  subworkflow action should have been purged  wfjob  workflow job should have been purged  addrecordtowfjobtable  geterrorcode  assertnotnull  get  workflowjob  wfaction  subwfaction  wfjobgetcmd  testpurgewfwithsubwf3  workflow action should have been purged  subworkflow job should have been purged  wfactiongetcmd  assertequals  execute  subwfactiongetcmd  call  services  1  fail  workflowaction  subwfjob  errorcode  je  jpaservice
__label__nflaky assert  equals  parse  p  head  result  xyz  helloworld  xyz  \%hello\\_world  t  compile  converter  map  context  set  context  write  test  with  nop  escape  assertequals  parse  p  head  result  xyz helloworld  xyz \%hello\\_world  t  compile  convertermap  context  setcontext  write  testwithnopescape
__label__flaky init  get  class  test  services  ext  loading  services  assert  false  destroy  assert  equals  s1  ext  services  services  services_  ext  assert  true  set  system  property  get  s1  init  getclass  testservicesextloading  services  assertfalse  destroy  assertequals  s1ext  services  services  services_ext  asserttrue  setsystemproperty  get  s1
__label__nflaky monotonic  now  increment  and  get  log  warning  t  =  0  read  write  lock  get  lock  suppressed  wsuppresed  set  unlock  get  method  name  wlogged  log  mclock  read  lock  assert  equals  test  read  lock  long  holding  report  testname  t  =  900  name  t  =  500  time  t  =  100  t  =  3000  monotonicnow  incrementandget  logwarning   t = 0  readwritelock  get  lock  suppressed  wsuppresed  set  unlock  getmethodname  wlogged  log  mclock  readlock  assertequals  testreadlocklongholdingreport  testname   t = 900  name   t = 500  time   t = 100   t = 3000
__label__flaky coord  el  functions  tz  action-actual-time=\""  test  action  input  check  latest  action  creation  time  date  utils  sleep  for  sometime  as  it  gets  requeued  with  10ms  delay  on  failure  to  acquire  write  lock  ${coord:latest  range(-3 0)}  before  and  after  action  creation  time  parse  date  oozie  tz  actual:  get  test  case  dir  file://  action  set  created  time  index  of  /2009/01/22  /2009/01/08/  resolved  list  execute  set  action  xml  job  id  contains  coord  command  utils  /2009/02/19/  job  get  missing  dependencies  expected:  get  time  get  id  2009-02-16  t23:59  </uris>  replace  all  /2009/02/05  system  substring  action  xml  sleep  /2009/02/12/  <uris>  assert  true  get  create  dir  start  time  update  action  creation  time  \"">  latest  2009-02-15  t23:59  action-actual-time=\""2009-02-15  t01:00  /2009/03/05/  /2009/01/22/  /2009/02/12  get  conf  action-actual-time=\"".*\"">  /2009/01/08  assert  equals  -  test  coord  action  input  check  x  command-  c  add  record  to  coord  job  table  thread  datasets  only  before  action  creation/actual  time  should  be  picked  up.  call  services  @1  get  action  xml  0000000-  end  time  2009-02-15  t01:00  action  creation  time  jpa  service  set  boolean  /2009/02/05/    coordelfunctions  tz  action-actual-time=\""  testactioninputchecklatestactioncreationtime  dateutils   sleep for sometime as it gets requeued with 10ms delay on failure to acquire write lock  ${coord:latestrange(-3 0)}   before and after action creation time  parsedateoozietz  actual:   gettestcasedir  file://  action  setcreatedtime  indexof  /2009/01/22  /2009/01/08/  resolvedlist  execute  setactionxml  jobid  contains  coordcommandutils  /2009/02/19/  job  getmissingdependencies  expected:   gettime  getid  2009-02-16t23:59  </uris>  replaceall  /2009/02/05  system  substring  actionxml  sleep  /2009/02/12/  <uris>  asserttrue  get  createdir  starttime   update action creation time  \"">  latest  2009-02-15t23:59  action-actual-time=\""2009-02-15t01:00  /2009/03/05/  /2009/01/22/  /2009/02/12  getconf  action-actual-time=\"".*\"">  /2009/01/08  assertequals  -testcoordactioninputcheckxcommand-c  addrecordtocoordjobtable  thread   datasets only before action creation/actual time should be picked up.  call  services  @1  getactionxml  0000000-  endtime  2009-02-15t01:00  actioncreationtime  jpaservice  setboolean  /2009/02/05/
__label__nflaky test  c40  encodation  spec  example  example  in  figure  1  in  the  spec  visualized  assert  equals  a1  b2  c3  d4  e5  f6  g7  h8  i9  j0  k1  l2  230  88  88  40  8  107  147  59  67  126  206  78  126  144  121  35  47  254  encode  high  level  testc40encodationspecexample   example in figure 1 in the spec  visualized  assertequals  a1b2c3d4e5f6g7h8i9j0k1l2  230 88 88 40 8 107 147 59 67 126 206 78 126 144 121 35 47 254  encodehighlevel
__label__flaky args  dependency  resolution  with  custom  class  loader  class  loader  org.springframework  spring-jdbc  create  dependency  3.2.4.  release  assert  equals  custom  class  loader  grab  put  get  ur  ls  args  dependencyresolutionwithcustomclassloader  classloader  org.springframework  spring-jdbc  createdependency  3.2.4.release  assertequals  customclassloader  grab  put  geturls
__label__nflaky key1  key2  value2  value1  keys  value3  values  compare  to  b  value  in  map  get  bytes  put  assert  true  get  key  set  key  this  will  work  because  we  know  what  we  put  into  each  set  get  key  a  b  maps  e  entry  set  map2  contains  key  map1  copy  of  map  of  maps  unchecked  assert  equals  get  value  size  map  of  maps  test  map  writable  key3  now  for  something  a  little  harder...  out  map  a  value  key1  key2  value2  value1  keys  value3  values  compareto  bvalue  inmap  getbytes  put  asserttrue  get  keyset  key   this will work because we know what we put into each set  getkey  a  b  maps  e  entryset  map2  containskey  map1  copyofmapofmaps  unchecked  assertequals  getvalue  size  mapofmaps  testmapwritable  key3   now for something a little harder...  outmap  avalue
__label__flaky get  job  tracker  uri  get  name  <java>  test  simpest  sle  submit  ok  get  status  create  context  action  xml  is  successful  assert  true  context  end  wait  for  <job-tracker>  get  data  get  name  node  uri  </java>  ae  </main-class>  </job-tracker>  running  job  get  action  assert  equals  check  get  external  status  <name-node>  <main-class>  </name-node>  assert  null  workflow  action  succeeded  submit  action  evaluate  is  complete  getjobtrackeruri  getname  <java>  testsimpestslesubmitok  getstatus  createcontext  actionxml  issuccessful  asserttrue  context  end  waitfor  <job-tracker>  getdata  getnamenodeuri  </java>  ae  </main-class>  </job-tracker>  runningjob  getaction  assertequals  check  getexternalstatus  <name-node>  <main-class>  </name-node>  assertnull  workflowaction  succeeded  submitaction  evaluate  iscomplete
__label__nflaky test  existing  files  case  assert  false  partitioned  delete  assert  assert  true  tmp  get  path  test  list  api  mkdir  failed  to  create  test  dir  failed  to  delete  test  dir  io  exception  expected  on  list()  for  non-existent  dir  test  test  existing  directory  with  no  files  case  assert  equals  list  unexpected  number  of  pre-existing  files  fail  new  dir  files  exists  setup  dirs  new  directory  unexpectedly  contains  files  to  string  file  util  io  exception   test existing files case  assertfalse  partitioned  delete  assert  asserttrue  tmp  getpath  testlistapi  mkdir  failed to create test dir  failed to delete test dir  ioexception expected on list() for non-existent dir   test   test existing directory with no files case  assertequals  list  unexpected number of pre-existing files  fail  newdir  files  exists  setupdirs  new directory unexpectedly contains files  tostring  fileutil   ioexception
__label__flaky reader  conf  run  get  status  get  job  get  test  group  assert  not  null  get  test  case  dir  /workflow.xml  file://  action  workflow.xml  wait  for  actions2  bean  action  check  runnable  running-mode  action  check  delay  external-status  test  test  action  checker  service  delay  execute  oozie  client  job  id  get  type  copy  char  stream  get  resource  as  reader  set  last  check  time  file  evaluate  actions  submit  job  workflow  action  bean  sleep  actions  get  executor  engine  set  strings  get  ok  workflow  job  a  set  workflow  app  service  wf-ext-schema-valid.xml  assert  equals  async  services  io  utils  get  test  user  t  signal-value  u  based_on_action_status  equals  writer  action2  jpa  service  reader  conf  run  getstatus  getjob  gettestgroup  assertnotnull  gettestcasedir  /workflow.xml  file://  action  workflow.xml  waitfor  actions2  bean  actioncheckrunnable  running-mode  actioncheckdelay  external-status  test  testactioncheckerservicedelay  execute  oozieclient  jobid  gettype  copycharstream  getresourceasreader  setlastchecktime  file  evaluate  actions  submitjob  workflowactionbean  sleep  actionsgetexecutor  engine  setstrings  get  ok  workflowjob  a  set  workflowappservice  wf-ext-schema-valid.xml  assertequals  async  services  ioutils  gettestuser  t  signal-value  u  based_on_action_status  equals  writer  action2  jpaservice
__label__nflaky http://myserver.com:80  and  application.conf:  (full  server  name=${server  name}:${server  port})  ninja  mode  test  referencining  of  properties  works  instantiate  the  properties:  get  full  server  name  assert  equals  ninja  properties  http://myserver.com:80   and application.conf: (fullservername=${servername}:${serverport})  ninjamode  testreferenciningofpropertiesworks   instantiate the properties:  get  fullservername  assertequals  ninjaproperties
__label__flaky job2  job1  check  workflows  job3  job3  shouldn\'t  be  in  the  list  because  it  has  a  parent  get  id  workflow  instance  list  execute  services  add  record  to  wf  job  table  add  all  assert  not  null  get  set  parent  id  test  wf  jobs  get  for  purge  with  parent  workflow  job  jpa  service  job2  job1  checkworkflows  job3   job3 shouldn\'t be in the list because it has a parent  getid  workflowinstance  list  execute  services  addrecordtowfjobtable  addall  assertnotnull  get  setparentid  testwfjobsgetforpurgewithparent  workflowjob  jpaservice
__label__nflaky /foo  is  file  /new  dir/new  dir2/foo  foo  assert  false  chrooted  to  new  dir/foo  test  create  delete  fc  target  delete  create  file  create  file  with  a  2  component  dirs  recursively  assert  file  context  test  helper  create  file  assert  true  create  file  with  recursive  dir  exists  create  file  non  recursive  /new  dir/foo  fc  delete  the  created  file  new  dir/new  dir2/foo  /foo  isfile  /newdir/newdir2/foo  foo  assertfalse  chrootedto  newdir/foo  testcreatedelete  fctarget  delete  createfile   create file with a 2 component dirs recursively  assert  filecontexttesthelper   create file  asserttrue   create file with recursive dir  exists  createfilenonrecursive  /newdir/foo  fc   delete the created file  newdir/newdir2/foo
__label__flaky service  init  time  result  /service  init  time  get  server  address  the  response  information  must  match  the  internal  application  state  we  know  that  this  service  is  a  singleton  and  it  provides  the  application  initialization  time.  ninja  test  browser  make  json  request  get  injector  assert  equals  service  initialization  time  test  that  injector  accessible  from  ninja  test  is  the  application  injector  this  is  the  application  guice  injector  provide  a  json  with  information  about  the  application  initialization  time.  get  instance  injector  {\""init  time\"":  }  get  service  initialization  time  serviceinittimeresult  /serviceinittime  getserveraddress   the response information must match the internal application state   we know that this service is a singleton and it provides the application initialization time.  ninjatestbrowser  makejsonrequest  getinjector  assertequals  serviceinitializationtime  testthatinjectoraccessiblefromninjatestistheapplicationinjector   this is the application guice injector   provide a json with information about the application initialization time.  getinstance  injector  {\""inittime\"":  }  getserviceinitializationtime
__label__nflaky test  empty  testempty
__label__flaky init  get  property  get  conf  oozie-site2.xml  prepare  oozie  conf  dir  oozie-  cl  user.name  destroy  assert  equals  system  test  missing  site  assert  null  oozie-site-missing.xml  oozie.system.id  oozie.dummy  set  system  property  get  configuration  service  init  getproperty  getconf  oozie-site2.xml  prepareoozieconfdir  oozie-  cl  user.name  destroy  assertequals  system  testmissingsite  assertnull  oozie-site-missing.xml  oozie.system.id  oozie.dummy  setsystemproperty  get  configurationservice
__label__nflaky rb1  rb2  priority.1.  completed  call  volume  decay  rpc  scheduler  metrics2.  conf  unique  caller1  decayed  call  volume  unique  callers  setup  decay  rpc  schedulerand  test  server  get  long  gauge  unique  caller:  {}  call  volume:  {}  priority.0.  completed  call  volume  wait  for  info  priority.1.  completed  call  volume:  {}  get  int  counter  priority.0.  avg  response  time  raw  call  volume1  log  generic  test  utils  lets  metric  system  update  latest  metrics  .  new  sleep  request  proxy  decayed  call  volume:  {}  stop  server  .0  ns  priority.1.  avg  response  time:  {}  get  metrics  get  long  counter  begin  decayed  call  volume  sleep  call  volume  priority1  call  volume  priority0  avg  resp  time  priority0  begin  unique  caller  avg  resp  time  priority1  addr  common  configuration  keys  test  decay  rpc  scheduler  metrics  get  client  call  volume  decayed  call  volume1  priority.0.  avg  response  time:  {}  begin  raw  call  volume  priority.0.  completed  call  volume:  {}  metrics  asserts  get  double  gauge  priority.1.  avg  response  time  rb1  rb2  priority.1.completedcallvolume  decayrpcschedulermetrics2.  conf  uniquecaller1  decayedcallvolume  uniquecallers  setupdecayrpcschedulerandtestserver  getlonggauge  uniquecaller: {}  callvolume: {}  priority.0.completedcallvolume  waitfor  info  priority.1.completedcallvolume: {}  getintcounter  priority.0.avgresponsetime  rawcallvolume1  log  generictestutils   lets metric system update latest metrics  .  newsleeprequest  proxy  decayedcallvolume: {}  stop  server  .0  ns  priority.1.avgresponsetime: {}  getmetrics  getlongcounter  begindecayedcallvolume  sleep  callvolumepriority1  callvolumepriority0  avgresptimepriority0  beginuniquecaller  avgresptimepriority1  addr  commonconfigurationkeys  testdecayrpcschedulermetrics  getclient  callvolume  decayedcallvolume1  priority.0.avgresponsetime: {}  beginrawcallvolume  priority.0.completedcallvolume: {}  metricsasserts  getdoublegauge  priority.1.avgresponsetime
__label__flaky test  bundle  suspend  with  error  bundle  job  get  cmd  add  record  to  bundle  job  table  get  id  assert  equals  get  status  execute  call  services  assert  not  null  get  job  job  jpa  service  testbundlesuspendwitherror  bundlejobgetcmd  addrecordtobundlejobtable  getid  assertequals  getstatus  execute  call  services  assertnotnull  get  job  job  jpaservice
__label__nflaky tmparchives  test  zero  file  list  length  -  it  should  create  an  exception  tmpfile2  tmpfile1  tmp  file  one  \%s    \%s  due  to  uri  syntax  error  args  and  conf  names  -libjars  conf  string  uri  syntax  exception  test  empty  filenames  expect  to  receive  an  illegal  argument  exception  \%s  \%s  working  directory  being  added  to  \""tmpjars\""  (or  equivalent)  tmp  path  one  get  first  arg  create  tmpjars  add  arg  and  conf  name  empty  string  -archives  e  to  uri  expected  exception  for  empty  filename  format  tmp  file  two  tmp  path  two  generic  test  utils  expected  exception  for  zero  file  list  length  test  dir  args  fail  expected  exception  for  filename  with  space  character  -files  local  fs  assert  exception  contains  to  string  tmpfiles  file  name  can\'t  be      tmparchives   test zero file list length - it should create an exception  tmpfile2  tmpfile1  tmpfileone  \%s   \%s   due to uri syntax error  argsandconfnames  -libjars  conf  string  urisyntaxexception  testemptyfilenames   expect to receive an illegalargumentexception  \%s  \%s   working directory being added to \""tmpjars\"" (or equivalent)  tmppathone  getfirst  arg  create  tmpjars  add  argandconfname   empty string  -archives  e  touri  expected exception for empty filename  format  tmpfiletwo  tmppathtwo  generictestutils  expected exception for zero file list length  testdir  args  fail  expected exception for filename with space character  -files  localfs  assertexceptioncontains  tostring  tmpfiles  file name can\'t be
__label__flaky _test  get  job  info  for  app  name  bundle  job1  _test  get  job  info  for  user  and  status  _test  get  job  info  for  id  _test  get  job  info  for  status  _test  get  job  info  for  group  _test  get  job  info  for  user  add  record  to  bundle  job  table  get  id  job  test  bundle  job  info  get  _testgetjobinfoforappname  bundlejob1  _testgetjobinfoforuserandstatus  _testgetjobinfoforid  _testgetjobinfoforstatus  _testgetjobinfoforgroup  _testgetjobinfoforuser  addrecordtobundlejobtable  getid  job  testbundlejobinfoget
__label__nflaky get  name  be  the  same  encryption  key  key  provider  crypto  extension  assert  array  equals  ekv  decrypt  encrypted  key  assert  not  null  get  encrypted  key  iv  generate  1  new  eek  @v2  add  to  the  list.  add  generate  encrypted  key  get  encryption  key  name  ekvs  orig  roll  the  ek  again  re-encrypted  eek  should  have  same  material  kv1  get  version  name  expected  encrypted  key  material  generate  1  new  eek  @v1  add  to  the  list.  encryption_  key_  name  verify  each  ekv  get  material  test  reencrypt  encrypted  keys  size  roll  the  ek  get  encryption  key  version  name  arrays  reencrypt  ekvs  get  encrypted  key  version  assert  false  reencrypt  encrypted  keys  ekvs  roll  new  version  assert  true  get  version  name  should  be  eek  decrypt  the  new  eek  into  an  ek  and  check  it  leave  a  deep  copy  of  the  original   for  verification  purpose.  assert  equals  same  kv.  kp  ext  kv  decrypt  it  again  and  it  should  be  the  same  orig  kv  generate  2  new  ee  ks  @v0  and  add  to  the  list  encrypted  key  material  should  not  equal  encryption  key  material  re-encrypted  eek  should  have  different  material  verify  decrypting  the  new  eek  and  orig  eek  gives  the  same  material.  orig  equals  returned  eek  and  original  eek  should  both  decrypt  to  the  encryption  key  name  should  be  length  of  encryption  key  material  and  eek  material  should  getname  be the same  encryptionkey  keyprovidercryptoextension  assertarrayequals  ekv  decryptencryptedkey  assertnotnull  getencryptedkeyiv   generate 1 new eek @v2 add to the list.  add  generateencryptedkey  getencryptionkeyname  ekvsorig   roll the ek again  re-encrypted eek should have same material  kv1  getversionname  expected encrypted key material   generate 1 new eek @v1 add to the list.  encryption_key_name   verify each ekv  getmaterial  testreencryptencryptedkeys  size   roll the ek  getencryptionkeyversionname  arrays   reencrypt ekvs  getencryptedkeyversion  assertfalse  reencryptencryptedkeys  ekvs  rollnewversion  asserttrue  get  version name should be eek   decrypt the new eek into an ek and check it   leave a deep copy of the original  for verification purpose.  assertequals  same kv.  kpext  kv   decrypt it again and it should be the same  origkv   generate 2 new eeks @v0 and add to the list  encrypted key material should not equal encryption key material  re-encrypted eek should have different material   verify decrypting the new eek and orig eek gives the same material.  orig  equals  returned eek and original eek should both decrypt to the   encryption key name should be   length of encryption key material and eek material should
__label__flaky cluster  parent  4:  count  -q  /test  15a:  clear  quota  on  a  file  get  current  user  try  setting  space  quota  with  a  \'binary  prefix\'  14b:  set  quota  on  a  file  check  disk  space  consumed  create  a  file  that  is  greater  than  the  size  of  space  quota  conf  string  need  final  ref  for  do  as  block  create  file  9:  clear  quota  /test/data0  6:  create  a  directory  /test/data1  ugi  child  file0  fout  child  file1  child  file2  child  file3  child  file4  write  child  file5  user  group  information  userxx  test  quota  commands  in  get  file  system  /  dfs  0  1  do  as  3  child  dir0  clear  space  quota  mkdirs  hadoop-5872  -  we  can  set  quota  even  if  it  is  immediately  violated  18:  clr  quota  by  a  non-administrator  has  exception  19:  clr  quota  on  the  root  directory  (\""/\"")  should  fail  2:  create  directory  /test/data0  not  running  as  new  user  16a:  set  the  quota  of  /test  to  be  0  2:  create  directory  /test/data2  33aa1.5  8:  clear  quota  /test  delete  the  file  assert  true  get  file  count  1g  space  quota  get  space  consumed  close  default_  block_  size  replication  dfs  test  util  c  1t  is  file  data2  data1  data0  assert  equals  m  1:  create  a  directory  /test  and  set  its  quota  to  be  3  io  utils  datafile3  exists  args2  datafile2  to  string  args3  9.s:  clear  diskspace  quota  file  len2  datafile1  set  boolean  datafile0  16c:  set  the  quota  of  /test  to  be  long.  max_  value+1  2t  17:  set  quota  by  a  non-administrator  get  space  quota  non  existent  path  run  16d:  set  the  quota  of  /test  to  be  a  non  integer  /test  -clr  quota  14a:  set  quota  on  a  non-existent  directory  16b:  set  the  quota  of  /test  to  be  -1  create  now  test  the  same  for  root  -clr  space  quota  now  set  space  quota  again.  this  should  succeed  set  diskspace  quota  to  10000  create  user  for  testing  groupyy  20:  set  quota  on  the  root  directory  (\""/\"")  should  succeed  dfs  config  keys  16e:  set  space  quota  with  a  value  larger  than  long.  max_  value  -1  get  directory  count  set  long  15b:  clear  quota  on  a  non-existent  directory  num  data  nodes  now  creating  child  file1  should  succeed  -set  space  quota  long  get  uri  shutdown  set  space  quota  to  a  real  low  value  -set  quota  10.s:  but  writing  file  len  bytes  should  result  in  an  quota  exception  1000000  12:  set  the  quota  of  /test/data0  to  be  1  5:  count  -q  /test/data0  assert  false  admin  7:  create  a  file  /test/datafile1  user  admin  child  dir1  fs  delete  child  dir2  get  quota  same  for  space  quota  /test1  close  stream  run  command  get  short  user  name  value  of  10:  create  a  file  /test/datafile1  get  content  summary  not  a  hdfs:  file  len  args  integer  100  dfs.support.append  space  quota2  build  3:  create  a  file  /test/datafile0  for  space  quota  13:  not  able  create  a  directory  under  data0  clone  space  quotas  username  cluster  parent   4: count -q /test   15a: clear quota on a file  getcurrentuser   try setting space quota with a \'binary prefix\'   14b: set quota on a file   check disk space consumed   create a file that is greater than the size of space quota  conf  string   need final ref for doas block  createfile   9: clear quota /test/data0   6: create a directory /test/data1  ugi  childfile0  fout  childfile1  childfile2  childfile3  childfile4  write  childfile5  usergroupinformation  userxx  testquotacommands  in  getfilesystem  /  dfs  0  1  doas  3  childdir0   clear space quota  mkdirs   hadoop-5872 - we can set quota even if it is immediately violated   18: clrquota by a non-administrator  hasexception   19: clrquota on the root directory (\""/\"") should fail   2: create directory /test/data0  not running as new user   16a: set the quota of /test to be 0   2: create directory /test/data2  33aa1.5   8: clear quota /test   delete the file  asserttrue  getfilecount  1g  spacequota  getspaceconsumed  close  default_block_size  replication  dfstestutil  c  1t  isfile  data2  data1  data0  assertequals  m   1: create a directory /test and set its quota to be 3  ioutils  datafile3  exists  args2  datafile2  tostring  args3   9.s: clear diskspace quota  filelen2  datafile1  setboolean  datafile0   16c: set the quota of /test to be long.max_value+1  2t   17:  setquota by a non-administrator  getspacequota  nonexistentpath  run   16d: set the quota of /test to be a non integer  /test  -clrquota   14a: set quota on a non-existent directory   16b: set the quota of /test to be -1  create   now test the same for root  -clrspacequota   now set space quota again. this should succeed   set diskspace quota to 10000  createuserfortesting  groupyy   20: setquota on the root directory (\""/\"") should succeed  dfsconfigkeys   16e: set space quota with a value larger than long.max_value  -1  getdirectorycount  setlong   15b: clear quota on a non-existent directory  numdatanodes   now creating childfile1 should succeed  -setspacequota  long  geturi  shutdown   set space quota to a real low value  -setquota   10.s: but writing filelen bytes should result in an quota exception  1000000   12: set the quota of /test/data0 to be 1   5: count -q /test/data0  assertfalse  admin   7: create a file /test/datafile1  useradmin  childdir1  fs  delete  childdir2  getquota   same for space quota  /test1  closestream  runcommand  getshortusername  valueof   10: create a file /test/datafile1  getcontentsummary  not a hdfs:   filelen  args  integer  100  dfs.support.append  spacequota2  build   3: create a file /test/datafile0   for space quota   13: not able create a directory under data0  clone   space quotas  username
__label__nflaky set  test  to  string  time  unit  processing  time=0  lockfree  time=0  lockwait  time=0  lockshared  time=0  details  lockexclusive  time=0  response  time=0  to  string  assert  equals  timing  enqueue  time=10  queue  time=20000  handler  time=0  set  testtostring  timeunit  processingtime=0 lockfreetime=0 lockwaittime=0 locksharedtime=0   details  lockexclusivetime=0 responsetime=0  tostring  assertequals  timing  enqueuetime=10 queuetime=20000 handlertime=0
__label__flaky date  script  executor  session  local_  one  given  update  simple  eq  consistencylist  contains  exactly  when  get  list  of  where  id  row  table  execute  script  template  random  utils  manager  consistency  list_  remove  at  index  one  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  select  consistencylist  from  simple  where  id  =  then  should_dsl_update_list_remove  at  index  long  build  date  key  from  base  table  consistency  list  dsl  date  scriptexecutor  session  local_one   given  update  simple  eq  consistencylist  containsexactly   when  getlist  of  where  id  row  table  executescripttemplate  randomutils  manager  consistencylist_removeatindex  one  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  select consistencylist from simple where id =    then  should_dsl_update_list_removeatindex  long  builddatekey  frombasetable  consistencylist  dsl
__label__nflaky integer  fail  assert  tmp  test  invalid  char  array  append  buffer  index  out  of  bounds  exception  should  have  been  thrown  append  integer  fail  assert  tmp  testinvalidchararrayappend  buffer  indexoutofboundsexception should have been thrown  append
__label__flaky dag  el  functions  action  type  test  el  functions  returning  map  reduce  stats  \""  reduce_  input_  records\"":2}}  create  evaluator  {\""g\"":{\""c\"":10} \""org.apache.hadoop.mapred.  job  in  progress$  counter\"":  ${hadoop:counters(\'  h\')\'  action_  type\'}  context  set  id  action  group  counters  workflow  \""  reduce_  output_  records\"":2 \""  spilled_  records\"":4 \""  map_  output_  bytes\"":28   \'}  ${hadoop:counters(\'  h\')\'  1  application  type  ${hadoop:counters(\'  h\')  records  map_  out}  eval  \""  file_  bytes_  written\"":146 \""  hdfs_  bytes_  written\"":16}   name  {\""  total_  launched_  reduces\"":1 \""  total_  launched_  maps\"":2 \""  data_  local_  maps\"":2} \""  action_  type\"":\""  map_  reduce\""   evaluate  set  name  add  node  \""  file  system  counters\"":{\""  file_  bytes_  read\"":38 \""  hdfs_  bytes_  read\"":19   generate  id  h  \'\'  wi  configure  evaluator  get  \""  combine_  output_  records\"":0 \""  map_  input_  records\"":2 \""  reduce_  shuffle_  bytes\"":22   <workflow-app/>  map  reduce  action  executor  ${hadoop:counters(\'  h\')  records  reduce_  out}  set  proto  action  conf  set  workflow  instance  ${hadoop:counters(\'  h\')  records  reduce_  in}  a  c  ${hadoop:counters(\'  h\')  records  groups}  ${hadoop:counters(\'  h\')  records  map_  in}  set  var  g  assert  equals  \""org.apache.hadoop.mapred.  task$  counter\"":{\""  reduce_  input_  groups\"":2   wf  app  services  <configuration/>  \""  map_  input_  bytes\"":12 \""  map_  output_  records\"":2 \""  combine_  input_  records\"":0   to  string  dagelfunctions  actiontype  testelfunctionsreturningmapreducestats  \""reduce_input_records\"":2}}  createevaluator  {\""g\"":{\""c\"":10} \""org.apache.hadoop.mapred.jobinprogress$counter\"":  ${hadoop:counters(\'h\')\'action_type\'}  context  setid  action  group  counters  workflow  \""reduce_output_records\"":2 \""spilled_records\"":4 \""map_output_bytes\"":28   \'}  ${hadoop:counters(\'h\')\'  1  applicationtype  ${hadoop:counters(\'h\')recordsmap_out}  eval  \""file_bytes_written\"":146 \""hdfs_bytes_written\"":16}   name  {\""total_launched_reduces\"":1 \""total_launched_maps\"":2 \""data_local_maps\"":2} \""action_type\"":\""map_reduce\""   evaluate  setname  addnode  \""filesystemcounters\"":{\""file_bytes_read\"":38 \""hdfs_bytes_read\"":19   generateid  h  \'\'  wi  configureevaluator  get  \""combine_output_records\"":0 \""map_input_records\"":2 \""reduce_shuffle_bytes\"":22   <workflow-app/>  mapreduceactionexecutor  ${hadoop:counters(\'h\')recordsreduce_out}  setprotoactionconf  setworkflowinstance  ${hadoop:counters(\'h\')recordsreduce_in}  a  c  ${hadoop:counters(\'h\')recordsgroups}  ${hadoop:counters(\'h\')recordsmap_in}  setvar  g  assertequals  \""org.apache.hadoop.mapred.task$counter\"":{\""reduce_input_groups\"":2   wfapp  services  <configuration/>  \""map_input_bytes\"":12 \""map_output_records\"":2 \""combine_input_records\"":0   tostring
__label__nflaky /blah/my\%2fid/and/some/more/stuff  entry  set  build  route  decoded  this  would  be  /blah/my/id/and/some/more/stuff  get  path  parameters  encoded  assert  equals  my\%2fid  route  from  server  matches  route  with  url  encoded  slash  gets  chopped  correctly  route  size  assert  true  get  get  route  builder  id  /blah/{id}/.*  /blah/my\%2fid/and/some/more/stuff  entryset  buildroute   decoded this would be /blah/my/id/and/some/more/stuff  getpathparametersencoded  assertequals  my\%2fid  routefromserver  matches  routewithurlencodedslashgetschoppedcorrectly  route  size  asserttrue  get  get  routebuilder  id  /blah/{id}/.*
__label__flaky map-reduce-launcher.jar  same  for  launcher  assert  equals(classes   ae.get  launcher  classes());  /app/job.jar  action  executor  exception  conf  absolute  path  with  namenode  setup  action  conf  mr003  proto  conf  original  uber  jar  disabled  context  action  launcher  job  conf  if  <job-tracker>  oozie.action.mapreduce.uber.jar.enable  serv  ae  in  oozie.pipes.inputformat  oozie.pipes.partitioner  get  file  system  oozie.pipes.program  <name-node>  action  executor  exception  expected  because  uber  jars  are  disabled  fail  enable  uber  jars  to  test  that  map  reduce  action  executor  picks  up  the  oozie.mapreduce.uber.jar  property  correctly  contains  2  <streaming>  get  type  <env>ee=  ee</env>  <map>  m</map>  <writer>  w</writer>  oozie.streaming.record-reader  rr  get  classes  for  launcher  get  actions  <streaming></streaming>  <inputformat>  if</inputformat>  m  oozie.pipes.reduce  create  base  hadoop  conf  mr-action  p  r  job.jar  get  error  code  assert  true  get  w  get  boolean  <program>  pp</program>  <record-reader-mapping>  rrm2=2</record-reader-mapping>  set  xml  utils  get  message  oozie.pipes.map  assert  equals  get  jar  get  launcher  jar  name  /  pp  </map-reduce>  services  get  test  user  assert  null  add  all  <property><name>mapred.input.dir</name><value>  in</value></property>  <env>e=  e</env>  set  boolean  get  job  tracker  uri  map-reduce  oozie.streaming.mapper  oozie.streaming.reducer  <pipes>  </configuration>  create  base  workflow  <reduce>  r</reduce>  <map-reduce>  doesn\'t  resolve  if  not  set  mapred.input.dir  relative  path  test  setup  methods  oozie.pipes.writer  add  <record-reader-mapping>  rrm1=1</record-reader-mapping>  parse  xml  </job-tracker>  create  launcher  conf  </pipes>  same  for  launcher  conf  same  for  launcher  conf  (not  set)  </name-node>  absolute  path  without  namenode  </streaming>  get  error  type  create  uber  jar  action  xml  aee  <record-reader>  rr</record-reader>  ignored  for  streaming  classes  /job.jar  <reducer>  r</reducer>  wf  action  xml  <partitioner>  p</partitioner>  <mapper>  m</mapper>  get  name  node  uri  ignored  for  pipes  <property><name>mapred.output.dir</name><value>  out</value></property>  get  conf  workflow  app  service  disable  uber  jars  to  test  that  map  reduce  action  executor  won\'t  allow  the  oozie.mapreduce.uber.jar  property  oozie.streaming.env.size  <configuration>  set  type  oozie.streaming.record-reader-mapping.size  oozie.mapreduce.uber.jar  <pipes></pipes>  get  fs  test  case  dir    map-reduce-launcher.jar   same for launcher   assertequals(classes  ae.getlauncherclasses());  /app/job.jar  actionexecutorexception  conf   absolute path with namenode  setupactionconf  mr003  protoconf  originaluberjardisabled  context  action  launcherjobconf  if  <job-tracker>  oozie.action.mapreduce.uber.jar.enable  serv  ae  in  oozie.pipes.inputformat  oozie.pipes.partitioner  getfilesystem  oozie.pipes.program  <name-node>  actionexecutorexception expected because uber jars are disabled  fail   enable uber jars to test that mapreduceactionexecutor picks up the oozie.mapreduce.uber.jar property correctly  contains  2  <streaming>  gettype  <env>ee=ee</env>  <map>m</map>  <writer>w</writer>  oozie.streaming.record-reader  rr  getclassesforlauncher  getactions  <streaming></streaming>  <inputformat>if</inputformat>  m  oozie.pipes.reduce  createbasehadoopconf  mr-action  p  r  job.jar  geterrorcode  asserttrue  get  w  getboolean  <program>pp</program>  <record-reader-mapping>rrm2=2</record-reader-mapping>  set  xmlutils  getmessage  oozie.pipes.map  assertequals  getjar  getlauncherjarname  /pp  </map-reduce>  services  gettestuser  assertnull  addall  <property><name>mapred.input.dir</name><value>in</value></property>  <env>e=e</env>  setboolean  getjobtrackeruri  map-reduce  oozie.streaming.mapper  oozie.streaming.reducer  <pipes>  </configuration>  createbaseworkflow  <reduce>r</reduce>  <map-reduce>   doesn\'t resolve if not set  mapred.input.dir   relative path  testsetupmethods  oozie.pipes.writer  add  <record-reader-mapping>rrm1=1</record-reader-mapping>  parsexml  </job-tracker>  createlauncherconf  </pipes>   same for launcher conf   same for launcher conf (not set)  </name-node>   absolute path without namenode  </streaming>  geterrortype  createuberjaractionxml  aee  <record-reader>rr</record-reader>   ignored for streaming  classes  /job.jar  <reducer>r</reducer>  wf  actionxml  <partitioner>p</partitioner>  <mapper>m</mapper>  getnamenodeuri   ignored for pipes  <property><name>mapred.output.dir</name><value>out</value></property>  getconf  workflowappservice   disable uber jars to test that mapreduceactionexecutor won\'t allow the oozie.mapreduce.uber.jar property  oozie.streaming.env.size  <configuration>  settype  oozie.streaming.record-reader-mapping.size  oozie.mapreduce.uber.jar  <pipes></pipes>  getfstestcasedir
__label__nflaky get  bytes  transferred  a  lot  more  stuff!  beginning  rw  stuff;  codec  test  utils  more  stuff;  channel  test  decoding  file  with  offset  and  buffered  session  data  get  bytes  assert  inbuf  get  channel  pos  beginning;  stuff;  more  stuff;  a  lot  more  stuff!  close  write  fchannel  is  completed  testfile  beginning;  standard  charsets  length  bytes  read  assert  equals  create  temp  file  decoder  fill  set  length  transfer  count  everything  except  the  initial  7  bytes  that  went  to  the  session  buffer  read  from  file  metrics  getbytestransferred  a lot more stuff!  beginning  rw  stuff;   codectestutils  more stuff;   channel  testdecodingfilewithoffsetandbufferedsessiondata  getbytes  assert  inbuf  getchannel  pos  beginning; stuff; more stuff; a lot more stuff!  close  write  fchannel  iscompleted  testfile  beginning;   standardcharsets  length  bytesread  assertequals  createtempfile  decoder  fill  setlength  transfer   count everything except the initial 7 bytes that went to the session buffer  readfromfile  metrics
__label__flaky ${coord:data  in  partition  filter(\'  abc\'   \'java\')}  coord  el  functions  *  type=java  (datastamp==\'12\'  and  region==\'us\')  coord-action-start  eval  and  wrap  assert  true  (region==\'us\'  and  datastamp==\'12\')  or  (region==\'us\'  and  datastamp==\'13\')  .datain.  abc  expr  hcat://hcat.server.com:5080/mydb/clicks/datastamp=13;region=us  boolean  (datastamp=\'12\'  and  region=\'us\')  (region=\'us\'  and  datastamp=\'12\')  testdata  in  partition  filter  init  res  (region==\'us\'  and  datastamp==\'12\')  or  (datastamp==\'13\'  and  region==\'us\')  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us   .datain.  abc.unresolved  set  variable  ${coord:data  in  partition  filter(\'  abc\'   \'pig\')}  *  type=pig  (datastamp==\'12\'  and  region==\'us\')  or  (region==\'us\'  and  datastamp==\'13\')  (region==\'us\'  and  datastamp==\'12\')  (datastamp==\'12\'  and  region==\'us\')  or  (datastamp==\'13\'  and  region==\'us\')  eval  equals  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us  ${coord:datainpartitionfilter(\'abc\'  \'java\')}  coordelfunctions             * type=java             (datastamp==\'12\' and region==\'us\')  coord-action-start  evalandwrap  asserttrue  (region==\'us\' and datastamp==\'12\') or (region==\'us\' and datastamp==\'13\')  .datain.abc  expr  hcat://hcat.server.com:5080/mydb/clicks/datastamp=13;region=us  boolean  (datastamp=\'12\' and region=\'us\')  (region=\'us\' and datastamp=\'12\')  testdatainpartitionfilter  init  res  (region==\'us\' and datastamp==\'12\') or (datastamp==\'13\' and region==\'us\')  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us   .datain.abc.unresolved  setvariable  ${coord:datainpartitionfilter(\'abc\'  \'pig\')}             * type=pig             (datastamp==\'12\' and region==\'us\') or (region==\'us\' and datastamp==\'13\')  (region==\'us\' and datastamp==\'12\')  (datastamp==\'12\' and region==\'us\') or (datastamp==\'13\' and region==\'us\')  eval  equals  hcat://hcat.server.com:5080/mydb/clicks/datastamp=12;region=us
__label__nflaky allow-append  was  not  set  correctly  ignore-error  was  not  set  correctly  sink.source  conf  path  the  roll  interval  was  not  set  correctly  builder  sink.roll-offset-interval-millis  the  source  was  not  set  correctly  sink.basepath  add  init  test  init  src  sink  sink.ignore-error  assert  equals  10m  the  roll  offset  interval  was  not  set  correctly  1  sink.roll-interval  true  the  base  path  was  not  set  correctly  sink.allow-append  subset  allow-append was not set correctly  ignore-error was not set correctly  sink.source  conf  path  the roll interval was not set correctly  builder  sink.roll-offset-interval-millis  the source was not set correctly  sink.basepath  add  init  testinit  src  sink  sink.ignore-error  assertequals  10m  the roll offset interval was not set correctly  1  sink.roll-interval  true  the base path was not set correctly  sink.allow-append  subset
__label__flaky next  shutdown  dfs  get  log  scan  we  don\'t  want  anything  more   we  should  be  failing  test  race  between  client  and  timeout  h  constants  add  content  close  and  delete  create  new  h  region  fail  r  ok!  get  table  desc  region_  info  get  scanner  close  results  next  shutdowndfs  getlog  scan  we don\'t want anything more  we should be failing  testracebetweenclientandtimeout  hconstants  addcontent  closeanddelete  createnewhregion  fail  r   ok!  gettabledesc  region_info  getscanner  close  results
__label__nflaky test  mock  domain  name  resolver  can  be  created  resolver  common  configuration  keys  addrs  domain  name  resolver  factory  conf  new  instance  assert  equals  get  host  address  mock  domain  name  resolver  get  all  by  domain  name  testmockdomainnameresolvercanbecreated  resolver  commonconfigurationkeys  addrs  domainnameresolverfactory  conf  newinstance  assertequals  gethostaddress  mockdomainnameresolver  getallbydomainname
__label__flaky <execution>  lifo</execution>  </controls>  <datasets>  check  coord  jobs  <coordinator-app  name=\""  name\""  frequency=\""10\""  start=\""2009-02-01  t01:00  z\""  end=\""2009-02-03  t23:59  z\""  timezone=\""  utc\""  xmlns=\""uri:oozie:coordinator:0.2\"">  <controls>  <timeout>10</timeout>  <concurrency>2</concurrency>  conf  </input-events>  app  path  test  submit  fixed  values  substring  sc  </property></configuration>  </workflow>  </action>  </coordinator-app>  write  to  file  app  xml  <property>  <name>input  b</name>  <value>${coord:data  out(\'  local_  a\')}</value>  file://  get  test  case  dir  unit_  testing  <dataset  name=\""local_a\""  frequency=\""120\""  initial-instance=\""2009-02-01  t01:00  z\""  <output-events>  <data-out  name=\""  local_  a\""  dataset=\""local_a\"">  timezone=\""  utc\"">  <uri-template>file:///tmp/coord/workflows/${  year}/${  day}</uri-template>  </dataset>  coordinator.xml  set  <configuration>  <property>  <name>input  a</name>  <value>${coord:data  in(\'  a\')}</value>  </property>  length  assert  equals  <dataset  name=\""a\""  frequency=\""60\""  initial-instance=\""2009-02-01  t01:00  z\""  call  oozie  client  job  id  get  test  user  </datasets>  <input-events>  <instance>${coord:current(-1)}</instance>  </data-out>  </output-events>  <action>  <workflow>  <app-path>hdfs:///tmp/workflows/</app-path>  -  c  <data-in  name=\""  a\""  dataset=\""a\"">  <instance>${coord:latest(0)}</instance>  </data-in>  file  <execution>lifo</execution> </controls> <datasets>   checkcoordjobs  <coordinator-app name=\""name\"" frequency=\""10\"" start=\""2009-02-01t01:00z\"" end=\""2009-02-03t23:59z\"" timezone=\""utc\""   xmlns=\""uri:oozie:coordinator:0.2\""> <controls> <timeout>10</timeout> <concurrency>2</concurrency>   conf  </input-events>   apppath  testsubmitfixedvalues  substring  sc  </property></configuration> </workflow> </action> </coordinator-app>  writetofile  appxml  <property> <name>inputb</name> <value>${coord:dataout(\'local_a\')}</value>   file://  gettestcasedir  unit_testing  <dataset name=\""local_a\"" frequency=\""120\"" initial-instance=\""2009-02-01t01:00z\""   <output-events> <data-out name=\""local_a\"" dataset=\""local_a\"">   timezone=\""utc\""> <uri-template>file:///tmp/coord/workflows/${year}/${day}</uri-template> </dataset>   coordinator.xml  set  <configuration> <property> <name>inputa</name> <value>${coord:datain(\'a\')}</value> </property>   length  assertequals  <dataset name=\""a\"" frequency=\""60\"" initial-instance=\""2009-02-01t01:00z\""   call  oozieclient  jobid  gettestuser  </datasets> <input-events>   <instance>${coord:current(-1)}</instance> </data-out> </output-events> <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>   -c  <data-in name=\""a\"" dataset=\""a\""> <instance>${coord:latest(0)}</instance> </data-in>    file
__label__nflaky exception  get  forbidden  result  get  localized  message  ninja  constant  equal  to  when  result  result  get  renderable  assert  true  verify  not  important  get  template  argument  matchers  then  return  get  with  default  get  message  eq  real  test:  assert  that  any  ninja  default  get  status  code  context  impl  test  get  forbidden  request  messages  ninja  properties  exception  getforbiddenresult  getlocalizedmessage  ninjaconstant  equalto  when  result  result  getrenderable  asserttrue  verify  not important  gettemplate  argumentmatchers  thenreturn  getwithdefault  getmessage  eq   real test:  assertthat  any  ninjadefault  getstatuscode  contextimpl  testgetforbiddenrequest  messages  ninjaproperties
__label__flaky get  current  dateafter  incrementing  in  months  test  coord  status  transit  service  succeeded  get  id  run  date  utils  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  sleep  get  coordinator  action  end  current  date  plus  month  start  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  coordinator  job  services  runnable  coord-action-get.xml  job  jpa  service  getcurrentdateafterincrementinginmonths  testcoordstatustransitservicesucceeded  getid  run  dateutils  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  sleep  get  coordinatoraction  end  currentdateplusmonth  start  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  coordinatorjob  services  runnable  coord-action-get.xml  job  jpaservice
__label__nflaky timer  should  log  test  basic  logging  helper  assert  true  record  assert  false  log_  period  advance  timer  shouldlog  testbasiclogging  helper  asserttrue  record  assertfalse  log_period  advance
__label__flaky set  classes  to  be  excluded  add  record  to  bundle  action  table  create  bundle  job  get  id  run  date  utils  get  status  parse  date  oozie  tz  set  pause  time  bundle  job  get  job  bundle  wait  for  init  get  conf  false  2009-02-01  t01:00  z  bundle  id  destroy  bundle  insertjpa  assert  equals  services  execute  services  runnable  test  bundle  status  transit  service  paused  excluded  services  set  system  property  status  transit  service  action1  action2  jpa  service  action3  evaluate  setclassestobeexcluded  addrecordtobundleactiontable  createbundlejob  getid  run  dateutils  getstatus  parsedateoozietz  setpausetime  bundlejob  get  job  bundle  waitfor  init  getconf  false  2009-02-01t01:00z  bundleid  destroy  bundleinsertjpa  assertequals  services  execute  services  runnable  testbundlestatustransitservicepaused  excludedservices  setsystemproperty  statustransitservice  action1  action2  jpaservice  action3  evaluate
__label__nflaky core  matchers  equal  to  parse  assert  that  impl  test  parse  basic  tl  sv22.356  assert  tl  sv1  tl  sv1.3  tl  sv1.2  tls  tl  sv1.1  corematchers  equalto  parse  assertthat  impl  testparsebasic  tlsv22.356  assert  tlsv1  tlsv1.3  tlsv1.2  tls  tlsv1.1
__label__flaky server  test  for  single  dependency  which  is  already  in  the  hcat  server  check  coord  action  populate  table  hcat://  add  init  records  /  call  default  /dt=20120430;country=usa  test  update  coord  table  single  dep  coordinator  action  action  id  tablename  new  h  cat  dependency  db  table    server   test for single dependency which is already in the hcat server  checkcoordaction  populatetable  hcat://  addinitrecords  /  call  default  /dt=20120430;country=usa  testupdatecoordtablesingledep  coordinatoraction  actionid  tablename  newhcatdependency  db  table
__label__nflaky hello\%(  \%child  \\(\%h\\)  )  \%m  node  (  hello\%(\%child  )  hello\%(\%child  \%h)  composite  )  hello\%(\%child)  c  h  test  composite  assert  equals  parse  bare  system.out.println(\""test  recursive  part  2\"");  m  set  child  node  p  witness  t  system.out.println(t);  hello\%(\%child  \%h)  \%m  child  hello\%( \%child \\(\%h\\) ) \%m  node   (  hello\%(\%child )  hello\%(\%child \%h)  composite  )   hello\%(\%child)     c  h  testcomposite  assertequals  parse  bare   system.out.println(\""testrecursive part 2\"");  m  setchildnode  p  witness  t   system.out.println(t);  hello\%(\%child \%h) \%m  child
__label__flaky cluster  namenode  has  fetch  bad  file  list  from  namenode.  there  should  be  one  file.  get  name  length  fetch  bad  file  list  from  namenode.  there  should  be  none.  check  that  we  are  still  in  safe  mode  .meta  channel  conf  now  leave  safe  mode  so  that  we  can  clean  up  get  channel  bad  files.  expecting  1.  storage  dir  buffer  /srcdat10  write  is  populating  repl  queues  info  deliberately  corrupting  file  dfs  config  keys  get  block  pool  id  read  all  files  to  trigger  detection  of  corrupted  replica  log  list  corrupt  file  blocks  restart  name  node  stringify  exception  waiting  for  replication  queues  get  file  system  blocks  do  not  exist  in  data-dir  is  in  safe  mode  set  int  test  list  corrupt  file  blocks  in  safe  mode  /  get  name  node  blk_  wait  until  replication  queues  have  been  initialized  util  size  expecting  block  missing  exception  cleanup  corrupted  replicas  not  handled  properly.  namenode  is  not  in  safe  mode  wait  safe  mode  ends  with  position  get  instance  storage  dir  idx  shutdown  datanode  sends  block  reports  get  finalized  dir  hdfs  constants  rw  error  fs  system  next  bytes  sleep  random  bad  files  file  assert  true  string  utils  list  files  close  data_dir  set  float  restart  namenode  never  leave  safemode  automatically  mini  dfs  cluster  e  start  populating  repl  queues  immediately  blocks  now  deliberately  corrupt  one  block  at  offset  length  namenode  has  bad  files.  set  safe  mode  get  name  node  rpc  byte  buffer  corrupt  files.  expecting  none.  data  directory  does  not  exist  thread  create  files  build  exists  check  files  but  received  io  exception  received  block  missing  exception  as  expected.  wrap  create  two  files  with  one  block  each  datanode  scans  directories  get  namesystem  starts  with  cluster  namenode has    fetch bad file list from namenode. there should be one file.  getname   length    fetch bad file list from namenode. there should be none.   check that we are still in safe mode  .meta  channel  conf   now leave safe mode so that we can clean up  getchannel   bad files. expecting 1.  storagedir  buffer  /srcdat10  write  ispopulatingreplqueues  info     deliberately corrupting file   dfsconfigkeys  getblockpoolid   read all files to trigger detection of corrupted replica  log  listcorruptfileblocks  restartnamenode  stringifyexception  waiting for replication queues  getfilesystem  blocks do not exist in data-dir  isinsafemode  setint  testlistcorruptfileblocksinsafemode  /  getnamenode  blk_   wait until replication queues have been initialized  util  size  expecting blockmissingexception   cleanup  corrupted replicas not handled properly.   namenode is not in safe mode  waitsafemode  endswith  position  getinstancestoragedir  idx  shutdown   datanode sends block reports  getfinalizeddir  hdfsconstants  rw  error  fs  system  nextbytes  sleep  random  badfiles  file  asserttrue  stringutils  listfiles  close  data_dir  setfloat   restart namenode   never leave safemode automatically  minidfscluster  e   start populating repl queues immediately  blocks   now deliberately corrupt one block   at offset   length  namenode has bad files.   setsafemode  getnamenoderpc  bytebuffer   corrupt files. expecting none.  data directory does not exist  thread  createfiles  build  exists  checkfiles   but received ioexception   received blockmissingexception as expected.  wrap   create two files with one block each   datanode scans directories  getnamesystem  startswith
__label__nflaky get  subject  verify  login  user  got  a  new  ticket.  get  name  check  ticket  and  keytab  user1.keytab  user2.keytab  verify  subject  ugi  relogin  did  not  affect  the  login  user.  run  principal2  principal1  login  user  assert  remove  user  ext  subject  user  relogin  from  keytab  get  path  test  relogin  for  ugi  from  subject  work  dir  assert  not  equals  user  group  information  user1  user2  get  ugi  from  subject  ticket  login  ticket  keytab1  kdc  login  user  from  keytab  assert  same  get  login  user  keytab2  login  user  from  keytab  and  return  ugi  verify  an  \""external\""  subject  ticket  does  not  change.  do  as  ext  subject  \""external\""  subject.  get  auth  time  get  the  ugi  for  the  previously  logged  in  subject.  create  principal  login  another  user.  new  login  ticket  getsubject   verify login user got a new ticket.  getname  checkticketandkeytab  user1.keytab  user2.keytab   verify subject ugi relogin did not affect the login user.  run  principal2  principal1  loginuser  assert  removeuser  extsubjectuser  reloginfromkeytab  getpath  testreloginforugifromsubject  workdir  assertnotequals  usergroupinformation  user1  user2  getugifromsubject  ticket  loginticket  keytab1  kdc  loginuserfromkeytab  assertsame  getloginuser  keytab2  loginuserfromkeytabandreturnugi   verify an \""external\"" subject ticket does not change.  doas  extsubject   \""external\"" subject.  getauthtime   get the ugi for the previously logged in subject.  createprincipal   login another user.  newloginticket
__label__flaky date  script  executor  session  given  update  simple  eq  select  simpleset  from  simple  where  id  =  simpleset  contains  exactly  when  of  where  id  row  table  execute  script  template  should_dsl_update_set_remove  simple  set_  remove  from  random  utils  manager  get  set  one  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  simple  set  then  long  build  date  key  from  base  table  dsl  date  scriptexecutor  session   given  update  simple  eq  select simpleset from simple where id =   simpleset  containsexactly   when  of  where  id  row  table  executescripttemplate  should_dsl_update_set_remove  simpleset_removefrom  randomutils  manager  getset  one  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  simpleset   then  long  builddatekey  frombasetable  dsl
__label__nflaky directory  count  expected  length  assert  equals  space  consumed  test  to  string  no  show  quota  file  count  check  the  to  string  method  with  quotas  build  33333  22222  11111  quota  to  string  space  quota  content  summary  directorycount  expected  length  assertequals  spaceconsumed  testtostringnoshowquota  filecount   check the tostring method with quotas  build         33333        22222              11111   quota  tostring  spacequota  contentsummary
__label__flaky log  files  start  and  write  data  server  get  name  regions  e  log  log  get  online  regions  now  roll  the  log  get  num  log  files  count  actual  count:  unexpected  exception  test  log  rolling  flushcache  after  flushing  all  regions  and  rolling  logs  there  are  fatal  r  flush  all  regions  assert  true  roll  writer  after  writing  there  are  info   log files  startandwritedata  server  getname  regions  e  log  log  getonlineregions   now roll the log  getnumlogfiles  count  actual count:   unexpected exception  testlogrolling  flushcache  after flushing all regions and rolling logs there are   fatal  r   flush all regions  asserttrue  rollwriter  after writing there are   info
__label__nflaky get  parsed  type  parse  parameter  asdfasdf  is  matchers  assert  that  null  value  param1  0  000  -123  123  0.1  float  param  parser  123.1  -123.1  test  float  param  parser  validation    getparsedtype  parseparameter  asdfasdf  is  matchers  assertthat  nullvalue  param1  0  000  -123  123  0.1  floatparamparser  123.1  -123.1  testfloatparamparser  validation
__label__flaky test  timeout  get  id  date  utils  parse  date  oozie  tz  add  record  to  coord  job  table  2009-03-06  t10:00  z  call  coordinator  job  @1  pause  time  start  time  end  time  job  check  coord  actions  timeout  2009-03-06  t10:14  z  testtimeout  getid  dateutils  parsedateoozietz  addrecordtocoordjobtable  2009-03-06t10:00z  call  coordinatorjob  @1  pausetime  starttime  endtime  job  checkcoordactionstimeout  2009-03-06t10:14z
__label__nflaky #  dfs-  hosts-excluded  excludes  file  excludes  len  assert  false  includes  file  assert  equals  get  excluded  hosts  *  check  if  only  comments  can  be  written  to  hosts  file  contains  hfp  size  efw  somehost5  #  hosts-in-  dfs  ifw  test  host  file  reader  with  comments  only  write  close  get  hosts  includes  len  #dfs-hosts-excluded    excludesfile  excludeslen  assertfalse  includesfile  assertequals  getexcludedhosts       * check if only comments can be written to hosts file       contains  hfp  size  efw  somehost5  #hosts-in-dfs    ifw  testhostfilereaderwithcommentsonly  write  close  gethosts  includeslen
__label__flaky 22  ab  with  \""quotes\""  c\""  d  \""e  a  b  \""  c\\\""  d  \\\""e  \""  \""  c\\\""  d  \\\""e  \""  join  pmml  delimited  text  utils  assert  equals  test  join  pmml  delimited  as  list  ab  \""a  b\""  \""with  \\\""quotes\\\""  \""  1  3  1  22  3  arrays  22  ab  with \""quotes\""    c\"" d \""e   a b  \"" c\\\"" d \\\""e \"" \"" c\\\"" d \\\""e \""  joinpmmldelimited  textutils  assertequals  testjoinpmmldelimited  aslist  ab \""a b\"" \""with \\\""quotes\\\"" \""  1  3  1 22 3  arrays
__label__nflaky server  get  current  user  rpc  some  super  user  group_  names  get  user  the  user  returned  by  server  must  be  the  one  in  the  token.  new  empty  request  conf  run  master  conf  authentication  method  (auth:  token)  via  some  super  user  (auth:  simple)  ret  val  set  authentication  method  test  proxy  with  token  current  assert  refresh  conf  get  user  name  client  sm  set  protocol  engine  addr  set  configuration  user  group  information  add  token  proxy  user  ugi  token  id  print  stack  trace  e  assert  equals  get  client  *  tests  the  scenario  when  token  authorization  is  used.  *  the  server  sees  only  the  the  owner  of  the  token  as  the  *  user.  create  remote  user  set  token  service  real_  user_  name  token  do  as  stop  security  util  setup  test  server  proxy_  user_  name  create  proxy  user  for  testing  server  getcurrentuser  rpc  somesuperuser  group_names  getuser   the user returned by server must be the one in the token.  newemptyrequest  conf  run  masterconf  authenticationmethod   (auth:token) via somesuperuser (auth:simple)  retval  setauthenticationmethod  testproxywithtoken  current  assert  refreshconf  getusername  client  sm  setprotocolengine  addr  setconfiguration  usergroupinformation  addtoken  proxyuserugi  tokenid  printstacktrace  e  assertequals  getclient       *  tests the scenario when token authorization is used.     *  the server sees only the the owner of the token as the     *  user.       createremoteuser  settokenservice  real_user_name  token  doas  stop  securityutil  setuptestserver  proxy_user_name  createproxyuserfortesting
__label__flaky test  mat  lookup  command2  2099-02-01  t01:00  z  check  coord  jobs  get  id  date  utils  parse  date  oozie  tz  add  record  to  coord  job  table  call  coordinator  job  2099-02-03  t23:59  z  start  time  end  time  job  testmatlookupcommand2  2099-02-01t01:00z  checkcoordjobs  getid  dateutils  parsedateoozietz  addrecordtocoordjobtable  call  coordinatorjob  2099-02-03t23:59z  starttime  endtime  job
__label__nflaky =38=38=20=4  c=79=6  e=62=72=6  f=6  f=6  b=0  d=0  a=43=  =4  f=20=36=39=39=  test  quoted  printable  do  test  88  lynbrook  co  69999  =39=39;;;  end:  vcard  begin:  vcard  adr;  home;  charset=  utf-8;  encoding=  quoted-  printable:;;  =38=38=20=4c=79=6e=62=72=6f=6f=6b=0d=0a=43=    =4f=20=36=39=39=    testquotedprintable  dotest  88 lynbrook  co 69999  =39=39;;;  end:vcard  begin:vcard  adr;home;charset=utf-8;encoding=quoted-printable:;;
__label__flaky cluster  create  cluster  good!  conf  system  create  file  wait  active  /foo.txt  add  block  close  stream  file  system  client  create  a  new  file.  info  f  test  file  creation  error3  successful  get  file  system  get  name  node  rpc  test  file  creation  error3  start  dfs  fail  test  file  creation  error3  io  utils  build  num  data  nodes  to  string  shutdown  ioe  cluster   create cluster  good!  conf  system  createfile  waitactive  /foo.txt  addblock  closestream  filesystem  client   create a new file.  info  f  testfilecreationerror3 successful  getfilesystem  getnamenoderpc  testfilecreationerror3 start  dfs  fail  testfilecreationerror3  ioutils  build  numdatanodes  tostring  shutdown  ioe
__label__nflaky class  arg  argument  extractor  custom  argument  extractor  with  class  arg  should  be  instantiated  context  create  verify  invoke  java.lang.  string  mock  controller  classargargumentextractor  customargumentextractorwithclassargshouldbeinstantiated  context  create  verify  invoke  java.lang.string  mockcontroller
__label__flaky value2  value1  val3  </prepare>  </configuration>  cred  properties  <workflow-app  xmlns=\'uri:oozie:workflow:0.2.5\'  name=\'pig-wf\'>  conf  launcher  conf  <name>mapred.compress.map.output</name>  <param>  output=${output  dir}/pig-output</param>  property2  <message>  pig  failed   error  message${wf:error  message(wf:last  error  node())}</message>  property1  </workflow-app>  <value>value2</value>  <prepare>  assert  not  null  credentials  conf  set  cred  context  action  action  conf  ae  abc=org.apache.oozie.action.hadoop.  insert  test  token  set  credential  property  to  action  conf  <error  to=\'fail\'  />  <value>${queue  name}</value>  get  properties  <name>property2</name>  parse  xml  setting  the  credential  properties  in  launcher  conf  <end  name=\'end\'  />  test  credentials  module  <pig>  <script>org/apache/oozie/examples/pig/id.pig</script>  <start  to=\'pig1\'  />  </kill>  <ok  to=\'end\'  />  get  type  adding  if  action  need  to  set  more  credential  tokens  <value>true</value>  <param>  input=${input  dir}</param>  set  credential  tokens  </credentials>  <job-tracker>${job  tracker}</job-tracker>  <action  name=\'pig1\'  cred=\'abcname\'>  get  credentials  get  actions  action  job  configuration  test1  </pig>  create  base  hadoop  conf  oozie.credentials.credentialclasses  action  xml  <delete  path=\'outputdir\'  />  <value>value1</value>  <name>${property3}</name>  wf  bean  <credential  name=\'abcname\'  type=\'abc\'>  </action>  add  record  to  wf  job  table  <name>mapred.job.queue.name</name>  get  prop  copy  <credentials>  <name-node>${name  node}</name-node>  set  get  conf  xml  utils  abc  token  <property>  <name>property1</name>  <kill  name=\'fail\'>  assert  equals  set  type  <configuration>  set  conf  action  xmlconf  prop3  abcname  services  x  configuration  actionxml  </property>  get  token  tk  </credential>  <value>${value3}</value>  value2  value1  val3  </prepare>  </configuration>  credproperties  <workflow-app xmlns=\'uri:oozie:workflow:0.2.5\' name=\'pig-wf\'>  conf  launcherconf  <name>mapred.compress.map.output</name>  <param>output=${outputdir}/pig-output</param>  property2  <message>pig failed  error message${wf:errormessage(wf:lasterrornode())}</message>  property1  </workflow-app>  <value>value2</value>  <prepare>  assertnotnull  credentialsconf  setcred  context  action  actionconf  ae  abc=org.apache.oozie.action.hadoop.inserttesttoken  setcredentialpropertytoactionconf  <error to=\'fail\' />  <value>${queuename}</value>  getproperties  <name>property2</name>  parsexml   setting the credential properties in launcher conf  <end name=\'end\' />  testcredentialsmodule  <pig>  <script>org/apache/oozie/examples/pig/id.pig</script>  <start to=\'pig1\' />  </kill>  <ok to=\'end\' />  gettype   adding if action need to set more credential tokens  <value>true</value>  <param>input=${inputdir}</param>  setcredentialtokens  </credentials>  <job-tracker>${jobtracker}</job-tracker>  <action name=\'pig1\' cred=\'abcname\'>  getcredentials  getactions   action job configuration  test1  </pig>  createbasehadoopconf  oozie.credentials.credentialclasses  actionxml  <delete path=\'outputdir\' />  <value>value1</value>  <name>${property3}</name>  wfbean  <credential name=\'abcname\' type=\'abc\'>  </action>  addrecordtowfjobtable  <name>mapred.job.queue.name</name>  get  prop  copy  <credentials>  <name-node>${namenode}</name-node>  set  getconf  xmlutils  abc token  <property>  <name>property1</name>  <kill name=\'fail\'>  assertequals  settype  <configuration>  setconf  actionxmlconf  prop3  abcname  services  xconfiguration  actionxml  </property>  gettoken  tk  </credential>  <value>${value3}</value>
__label__nflaky fail  process  assert  http  status  response  test  response  conn  control  host  invalid  input  interceptor  ok  illegal  argument  exception  should  have  been  thrown  fail  process  assert  httpstatus  response  testresponseconncontrolhostinvalidinput  interceptor  ok  illegalargumentexception should have been thrown
__label__flaky start.error  assert  true  test  start  error  based_on_action_status  error  _test  error  start.error  asserttrue  teststarterror  based_on_action_status  error  _testerror
__label__nflaky should  enqueue  e  expected  should  not  enqueue  assert  equals  run  consume  trigger  capacity  test  consume  all  q  enqueue  times  consume  all  assert  true  mock  verify  arbitrary  element  should enqueue  e  expected  should not enqueue  assertequals  run  consume  trigger  capacity  testconsumeall  q  enqueue  times  consumeall  asserttrue  mock  verify   arbitrary  element
__label__flaky end_  points  is_  security_  enabled  oozie  url  run  create  mr  properties  app  path  assert  true  get  -config  servlet_  classes  run  test  app  test  submit  map  reduce  get  context  url  mock  dag  engine  service  assert  equals  get  file  system  args  call  submit  mr  -oozie  mapreduce  mkdirs  wf  count  to  string  get  fs  test  case  dir  end_points  is_security_enabled  oozieurl  run  createmrproperties  apppath  asserttrue  get  -config  servlet_classes  runtest  app  testsubmitmapreduce  getcontexturl  mockdagengineservice  assertequals  getfilesystem  args  call  submitmr  -oozie  mapreduce  mkdirs  wfcount  tostring  getfstestcasedir
__label__nflaky path  method  dir  assert  metrics  contents  to  uri  to  string  test  silent  existing  write  do  append  test  path  methoddir  assertmetricscontents  touri  tostring  testsilentexistingwrite  doappendtest
__label__flaky dag  el  functions  ${wf:callback(\'  xx\')}  def  b=  b  ${wf:id()}  conf  ${wf:run()}  get  status  create  evaluator  workflow  instance  ${to  properties  str(wf:action  data(\'action  name\'))}  set  id  action  set  user  ${wf:last  error  node()}  ec  ${wf:conf(\'a\')}  group  ext  test  functions  ${wf:error  code(\'action  name\')}  workflow  expected  em  oozie  client  set  group  contains  eval  ${wf:app  path()}  workflow  action  ${wf:action  external  id(\'action  name\')}  name  action  id  ${wf:action  external  status(\'action  name\')}  job  evaluate  action  name  set  name  a  ${a}  b  add  node  get  workflow  instance  set  action  info  get  id  set  run  app  path  set  app  path  set  tracker  uri  system  wf  ${wf:action  tracker  uri(\'action  name\')}  status=  xx  assert  true  configure  evaluator  get  tracker  <workflow-app/>  ${wf:group()}  end  set  external  id  wf  instance  set  proto  action  conf  ${wf:user()}  set  workflow  instance  a  ${to  json  str(wf:action  data(\'action  name\'))}  set  app  name  b  set  ${wf:error  message(\'action  name\')}  pretty  print  xml  utils  set  data  id=action  id  ${wf:action  data(\'action  name\')\'b\'}  escape  chars  for  xml  set  external  status  assert  equals  set  status  services  set  error  info  ${wf:name()}  to  xml  string  to  string  external  status  {\""b\"":\""  b\""}  user  wf  id  ${to  configuration  str(wf:action  data(\'action  name\'))}  dagelfunctions  ${wf:callback(\'xx\')}  def  b=b  ${wf:id()}  conf  ${wf:run()}  getstatus  createevaluator  workflowinstance   ${topropertiesstr(wf:actiondata(\'actionname\'))}  setid  action  setuser  ${wf:lasterrornode()}  ec  ${wf:conf(\'a\')}  group  ext  testfunctions  ${wf:errorcode(\'actionname\')}  workflow  expected  em  oozieclient  setgroup  contains  eval  ${wf:apppath()}  workflowaction  ${wf:actionexternalid(\'actionname\')}  name  actionid  ${wf:actionexternalstatus(\'actionname\')}  job  evaluate  actionname  setname  a  ${a}  b  addnode  getworkflowinstance  setactioninfo  getid  setrun  apppath  setapppath  settrackeruri  system  wf  ${wf:actiontrackeruri(\'actionname\')}  status=xx  asserttrue  configureevaluator  get  tracker  <workflow-app/>  ${wf:group()}  end  setexternalid  wfinstance  setprotoactionconf  ${wf:user()}  setworkflowinstance  a  ${tojsonstr(wf:actiondata(\'actionname\'))}  setappname  b  set  ${wf:errormessage(\'actionname\')}  prettyprint  xmlutils  setdata  id=actionid  ${wf:actiondata(\'actionname\')\'b\'}  escapecharsforxml  setexternalstatus  assertequals  setstatus  services  seterrorinfo  ${wf:name()}  toxmlstring  tostring  externalstatus  {\""b\"":\""b\""}  user  wfid  ${toconfigurationstr(wf:actiondata(\'actionname\'))}
__label__nflaky conf  test  exception  on  background  refresh  handled  as  list  wait  for  group  counters  advance  timer  cache  groups  add  pause  the  get  groups  operation  and  this  will  delay  the  cache  refresh  add  another  group  me  get  groups  grp3  resume  the  get  groups  operation  and  the  cache  can  get  refreshed  resume  a  on  failure  callback  gets  called  and  the  counter  for  failure  is  1  exception   we  now  expect  the  counter  for  success  is  1.  get  request  count  common  configuration  keys  clear  black  list  groups  refresh  fake  group  mapping  assert  equals  then  expire  that  entry  assert  that  a  request  to  get  groups  yet.  second  call  pause  set  long  my  groups  size  we  make  an  initial  request  to  populate  the  cache  set  throw  exception  starting  request  count  arrays  is  equal  to  set  boolean  conf  testexceptiononbackgroundrefreshhandled  aslist  waitforgroupcounters  advance  timer  cachegroupsadd   pause the getgroups operation and this will delay the cache refresh   add another group  me  getgroups  grp3   resume the getgroups operation and the cache can get refreshed  resume   a onfailure callback gets called and the counter for failure is 1   exception  we now expect the counter for success is 1.  getrequestcount  commonconfigurationkeys  clearblacklist  groups  refresh  fakegroupmapping  assertequals   then expire that entry  assertthat   a request to getgroups yet.   second call  pause  setlong  mygroups  size   we make an initial request to populate the cache  setthrowexception  startingrequestcount  arrays  isequalto  setboolean
__label__flaky add  record  to  bundle  action  table  add  record  to  wf  action  table  coord  action  get  cmd  get  num  days  to  not  be  purged  test  purge  bundle  with  coord  child  with  wf  child  with  sub  wf1  date  utils  workflow  instance  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  sub  workflow  job  should  not  have  been  purged  bundle  job  bundle  job  bean  assert  not  null  coordinator  action  job  wf  action  wf  job  get  cmd  bundle  action  should  not  have  been  purged  execute  subwf  action  get  cmd  bundle  job  should  not  have  been  purged  coordinator  job  1  coord  job  get  cmd  fail  workflow  action  coord  action  succeeded  workflow  action  should  not  have  been  purged  subwf  job  get  cmd  bundle  job  get  cmd  get  id  coord  job  sub  workflow  action  should  not  have  been  purged  wf  job  add  record  to  wf  job  table  get  workflow  job  should  not  have  been  purged  workflow  job  subwf  action  get  app  name  bundle  action  wf  action  get  cmd  coordinator  action  should  not  have  been  purged  2011-01-01  t01:00  z  add  record  to  bundle  job  table  assert  equals  get  last  modified  time  add  record  to  coord  job  table  coordinator  job  should  not  have  been  purged  call  services  coord-action-get.xml  subwf  job  jpa  service  bundle  action  get  cmd  addrecordtobundleactiontable  addrecordtowfactiontable  coordactiongetcmd  getnumdaystonotbepurged  testpurgebundlewithcoordchildwithwfchildwithsubwf1  dateutils  workflowinstance  getstatus  addrecordtocoordactiontable  parsedateoozietz  subworkflow job should not have been purged  bundlejob  bundlejobbean  assertnotnull  coordinatoraction  job  wfaction  wfjobgetcmd  bundle action should not have been purged  execute  subwfactiongetcmd  bundle job should not have been purged  coordinatorjob  1  coordjobgetcmd  fail  workflowaction  coordaction  succeeded  workflow action should not have been purged  subwfjobgetcmd  bundlejobgetcmd  getid  coordjob  subworkflow action should not have been purged  wfjob  addrecordtowfjobtable  get  workflow job should not have been purged  workflowjob  subwfaction  getappname  bundleaction  wfactiongetcmd  coordinator action should not have been purged  2011-01-01t01:00z  addrecordtobundlejobtable  assertequals  getlastmodifiedtime  addrecordtocoordjobtable  coordinator job should not have been purged  call  services  coord-action-get.xml  subwfjob  jpaservice  bundleactiongetcmd
__label__nflaky executor  service  test  get  formatted  time  with  diff  get  formatted  time  with  diff  run  executors  system  method  returned  inconsistent  results  indicative  of  assert  true  string  utils  a  race  condition  await  time  unit  await  termination  end  fast_  date_  format  new  fixed  thread  pool  start  cyclic  barrier  multithreaded  test  get  formatted  time  with  diff()  execute  current  time  millis  equals  formatted  time2  formatted  time1  shutdown  executorservice  testgetformattedtimewithdiff  getformattedtimewithdiff  run  executors  system  method returned inconsistent results indicative of  asserttrue  stringutils   a race condition  await  timeunit  awaittermination  end  fast_date_format  newfixedthreadpool  start  cyclicbarrier   multithreaded test getformattedtimewithdiff()  execute  currenttimemillis  equals  formattedtime2  formattedtime1  shutdown
__label__flaky connection  factory  names#dynamic  factories/hcat.prod.${1}  ctx1  java.naming.factory.initial#org.apache.activemq.jndi.  active  mq  initial  context  factory;java.naming.provider.url#  conf  org.apache.activemq.jndi.  active  mq  initial  context  factory  h  cat  accessor  service  get  get  jndi  properties  string  vm://localhost?broker.persistent=false;connection  factory  names#dynamic  factories/hcat.prod.hcatserver  javax.management.  instance  already  exists  exception:  org.apache.activemq:  broker  name=localhost   type=  broker  init  set  hcat://hcatserver.blue.server.com:8020  get  jms  connection  info  print  stack  trace  get  conf  e  set  the  connection  factory  name  hcat  service  jms  url  test  connection  context  destroy  create  connection  assert  equals  services  broker  get  jndi  properties  fail  hcat://${1}.${2}.server.com:8020=java.naming.factory.initial#  ;java.naming.provider.url#vm://localhost?broker.persistent=false;  conn  info  stop  setup  services  for  h  catalog  unexpected  exception  connectionfactorynames#dynamicfactories/hcat.prod.${1}  ctx1  java.naming.factory.initial#org.apache.activemq.jndi.activemqinitialcontextfactory;java.naming.provider.url#  conf  org.apache.activemq.jndi.activemqinitialcontextfactory  hcataccessorservice  get  getjndipropertiesstring  vm://localhost?broker.persistent=false;connectionfactorynames#dynamicfactories/hcat.prod.hcatserver   javax.management.instancealreadyexistsexception: org.apache.activemq:brokername=localhost type=broker  init  set  hcat://hcatserver.blue.server.com:8020  getjmsconnectioninfo  printstacktrace  getconf  e   set the connection factory name  hcatservice  jmsurl  testconnectioncontext  destroy  createconnection  assertequals  services  broker  getjndiproperties  fail  hcat://${1}.${2}.server.com:8020=java.naming.factory.initial#  ;java.naming.provider.url#vm://localhost?broker.persistent=false;  conninfo  stop  setupservicesforhcatalog  unexpected exception
__label__nflaky assert  host1  test  to  string  host3  somehost  host2  somehost:8888  to  string  assert  equals  assert  host1  testtostring  host3  somehost  host2  somehost:8888  tostring  assertequals
__label__flaky write  file  and  start  second  node  to  be  \""older\""  than  the  original  bc  cluster  start  up  cluster  shut  down  cluster  reset  configuration  get  pending  replication  blocks  dn  r  conf  bl  dn  wait  for  temp  replica  find  block  dn_  n0  block  report  get  bytes  chk  sum  dn_  n1  join  write  file  block  report_09  block  dfs  config  keys  return  the  initial  state  of  the  configuration  get  data  nodes  get  block  pool  id  get  method  name  all  blocks  belong  to  the  same  file   hence  same  bp  blocks  get  block  list  as  longs  file  path  start  generic  test  utils  corrupt  block  len  assert  equals  get  name  node  rpc  wrong  number  of  pending  replication  blocks  /  set  int  corrupt  block  gs  print  stats  set  long  pool  id  method_  name  .dat  get  namesystem  get  dn  registration  for  bp   write file and start second node to be \""older\"" than the original  bc  cluster  startupcluster  shutdowncluster  resetconfiguration  getpendingreplicationblocks  dnr  conf  bl  dn  waitfortempreplica  findblock  dn_n0  blockreport  get  byteschksum  dn_n1  join  writefile  blockreport_09   block  dfsconfigkeys   return the initial state of the configuration  getdatanodes  getblockpoolid  getmethodname   all blocks belong to the same file  hence same bp  blocks  getblocklistaslongs  filepath  start  generictestutils  corruptblocklen  assertequals  getnamenoderpc  wrong number of pendingreplication blocks  /  setint  corruptblockgs  printstats  setlong  poolid  method_name  .dat  getnamesystem  getdnregistrationforbp
__label__nflaky add  a  b  set  format  info  assert  equals  parse  p  integer  witness  t  set  options  \%45x{a   b}  test  options1  ol  add  a  b  setformatinfo  assertequals  parse  p  integer  witness  t  setoptions  \%45x{a  b}  testoptions1  ol
__label__flaky cluster  get  name  conf  wait  active  validate  we  get  all  the  corrupt  files  storage  dir  info  dfs  config  keys  get  block  pool  id  log  list  corrupt  file  blocks  deliberately  removing  file  count  get  file  system  cannot  remove  file.  set  int  dfs  blk_  set  long  test  get  corrupt  files  util  for  loop  through  number  of  datadirectories  per  datanode  (2)  cleanup  get  instance  storage  dir  idx  datanode  scans  shutdown  /good  data  get  finalized  dir  bpid  /corrupt  data  fs  delete  testlist  corrupt  file  blocks  dfs  sleep  assert  true  delete  the  blocks  list  files  data_dir  mini  dfs  cluster  blocks  namenode  has  bad  files.  corrupt  file  blocks  directories  count  paths  thread  create  files  build  (blocks.length  >  0));  num  corrupt  get  namesystem  starts  with  cluster  getname  conf  waitactive   validate we get all the corrupt files  storagedir  info  dfsconfigkeys  getblockpoolid  log  listcorruptfileblocks  deliberately removing file   count  getfilesystem  cannot remove file.  setint  dfs  blk_  setlong  testgetcorruptfiles  util   for loop through number of datadirectories per datanode (2)  cleanup  getinstancestoragedir  idx   datanode scans  shutdown  /gooddata  getfinalizeddir  bpid  /corruptdata  fs  delete  testlistcorruptfileblocksdfs  sleep  asserttrue   delete the blocks  listfiles  data_dir  minidfscluster  blocks  namenode has bad files.   corruptfileblocks   directories  countpaths  thread  createfiles  build   (blocks.length > 0));  numcorrupt  getnamesystem  startswith
__label__nflaky init  then  return  servlet  context  content  types  http  servlet  request  test  is  json  works  when  is  request  json  assert  true  context  get  content  type  http  servlet  response  init  the  context  from  a  (mocked)  servlet  init  thenreturn  servletcontext  contenttypes  httpservletrequest  testisjsonworks  when  isrequestjson  asserttrue  context  getcontenttype  httpservletresponse   init the context from a (mocked) servlet
__label__flaky _test  is  main  successful  action  dir  has  output  data  assert  false  test  security  manager  running  job  is  main  done  get  file  system  fs  has  id  swap  get  id  swap  path  is  successful  assert  true  launcher  mapper  get  error  path  exists  get  output  data  path  security  manager  evaluate  wait  for  get  fs  test  case  dir  is  complete  _test  ismainsuccessful  actiondir  hasoutputdata  assertfalse  testsecuritymanager  runningjob  ismaindone  getfilesystem  fs  hasidswap  getidswappath  issuccessful  asserttrue  launchermapper  geterrorpath  exists  getoutputdatapath  securitymanager  evaluate  waitfor  getfstestcasedir  iscomplete
__label__nflaky get  version  for  number  <<  >>  test  to  string2  matrix  ec  level:  h  qr  code  version  0  1  0  1  0  1  0  1  0  1  0  1  0  1  0  1  0  1  0  1  0  set  matrix  set  mask  pattern  1  0  1  0  1  0  1  0  1  0  1  0  1  0  1  0  1  0  1  0  1  set  ec  level  set  set  version  matrix:  mode  expected  set  mode  assert  equals  mask  pattern:  3  version:  1  mode:  byte  y  to  string  error  correction  level  getversionfornumber  <<    >>    testtostring2  matrix   eclevel: h    qrcode  version   0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0    setmatrix  setmaskpattern   1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1    seteclevel  set  setversion   matrix:    mode  expected  setmode  assertequals   maskpattern: 3     version: 1     mode: byte    y  tostring  errorcorrectionlevel
__label__flaky conn  set  request  method  is_  security_  enabled  assert  true  get  json  content-type  /v1/admin/*  collections  run  test  get  build  info  json  tags  rest  constants  get  property  open  connection  test  version  http  servlet  response  assert  equals  parse  get  input  stream  url  json  value  call  get  header  field  get  get  response  code  build  info  create  url  starts  with  conn  setrequestmethod  is_security_enabled  asserttrue  get  json  content-type  /v1/admin/*  collections  runtest  getbuildinfo  jsontags  restconstants  getproperty  openconnection  testversion  httpservletresponse  assertequals  parse  getinputstream  url  jsonvalue  call  getheaderfield  get  getresponsecode  buildinfo  createurl  startswith
__label__nflaky aimaimaimaim12345678  visualized  239  91  11  91  11  91  11  91  11  254  142  164  186  208  129  237  test  unlatching  from  text  assert  equals  encode  high  level  aimaimaimaim12345678  visualized  239 91 11 91 11 91 11 91 11 254 142 164 186 208 129 237  testunlatchingfromtext  assertequals  encodehighlevel
__label__flaky fs1  reader  fs1 fs2 dec3  local  oozie  conf  get  status  get  cause  path  get  test  case  dir  /workflow.xml  file://  get  path  create  workflow.xml  wait  for  rerun-wf.xml  wf  client  get  file  system  failed  re  run  oozie  client  contains  copy  char  stream  set  property  get  resource  as  reader  create  configuration  file  evaluate  p2  submit  get  job  info  delete  job  id1  assert  true  workflow  job  nnbase  skip  executed  nodes  e  to  uri  start  get  message  assert  equals  get  client  test  rerun  io  utils  get  test  user  to  string  skip  a  non-executed  node  writer  error  code  get  fs  test  case  dir  base  fs1  reader  fs1 fs2 dec3  localoozie  conf  getstatus  getcause  path  gettestcasedir  /workflow.xml  file://  getpath  create  workflow.xml  waitfor  rerun-wf.xml  wfclient  getfilesystem  failed  rerun  oozieclient  contains  copycharstream  setproperty  getresourceasreader  createconfiguration  file  evaluate  p2  submit  getjobinfo  delete  jobid1  asserttrue  workflowjob  nnbase   skip executed nodes  e  touri  start  getmessage  assertequals  getclient  testrerun  ioutils  gettestuser  tostring   skip a non-executed node  writer  errorcode  getfstestcasedir  base
__label__nflaky abc  then  return  context  character  param  create  verify  invoke  character  param  should  be  parsed  to  character  when  param1  mock  controller  get  parameter  abc  thenreturn  context  characterparam  create  verify  invoke  characterparamshouldbeparsedtocharacter  when  param1  mockcontroller  getparameter
__label__flaky test  retrieval  of  range  of  actions  (action  1-2)  get  id  coord  utils  assert  equals  add  record  to  coord  action  table  -  add  record  to  coord  job  table  integer  get  coord  actions  from  ids  test  get  coord  actions  from  ids  range  coordinator  job  job  id  coord-action-get.xml  rerun  scope  coord  actions  size  coordinator  action  to  string  action  num2  job  action  num1   test retrieval of range of actions (action 1-2)  getid  coordutils  assertequals  addrecordtocoordactiontable  -  addrecordtocoordjobtable  integer  getcoordactionsfromids  testgetcoordactionsfromidsrange  coordinatorjob  jobid  coord-action-get.xml  rerunscope  coordactions  size  coordinatoraction  tostring  actionnum2  job  actionnum1
__label__nflaky bring  down  tm2  get  current  user  verify  token  expected  invalid  token  boo  foo  conf  start  second  node  after  some  time..  sleep  create  a  new  token  thru  the  new  zkdtsm  bar  assert  bla  assert  not  null  token1  tm2  xyz  tm1  token2  token3  token4  tm3  get  secret  conf  user  group  information  init  cancel  one  token  get  connect  string  zk  server  unchecked  create  token  cancel  token  thread  fail  verify  destroy  verify  token  fail  start  third  node  after  some  time..  test_  retries  connect  string  test  node  up  afer  a  while   bring down tm2  getcurrentuser  verifytoken  expected invalidtoken  boo  foo  conf   start second node after some time..  sleep   create a new token thru the new zkdtsm  bar  assert  bla  assertnotnull  token1  tm2  xyz  tm1  token2  token3  token4  tm3  getsecretconf  usergroupinformation  init   cancel one token  getconnectstring  zkserver  unchecked  createtoken  canceltoken  thread  fail  verifydestroy  verifytokenfail   start third node after some time..  test_retries  connectstring  testnodeupaferawhile
__label__flaky test  two  step  write  connect  timeout  os  expected  timeout  e  log  connect  timed  out  get  message  test_  timeout  assert  equals  /file  fs  fail  io  utils  cleanup  start  single  temporary  redirect  response  thread  create  testtwostepwriteconnecttimeout  os  expected timeout  e  log  connect timed out  getmessage  test_timeout  assertequals  /file  fs  fail  ioutils  cleanup  startsingletemporaryredirectresponsethread  create
__label__nflaky has  field  violation  assert  true  validation  should  fail  when  bad  request  context  create  verify  invoke  mock  controller  required  param1  validation  hasfieldviolation  asserttrue  validationshouldfailwhenbadrequest  context  create  verify  invoke  mockcontroller  required  param1  validation
__label__flaky get  name  expected  exception  did  not  contain  helpful  message  successfully  got  proxy  provider  for  misconfigured  fs  conf  logical  host  /test  hdfs://  assert  true  string  utils  file  system  get  got  expected  exception  info  set  log  stringify  exception  could  not  find  any  configured  addresses  for  uri  uri  .  fail  contains  exists  test  failure  with  misconfigured  ha  n  ns  misconfigured-ha-uri  dfs_  client_  failover_  proxy_  provider_  key_  prefix  ioe  getname  expected exception did not contain helpful message  successfully got proxy provider for misconfigured fs  conf  logicalhost  /test  hdfs://  asserttrue  stringutils  filesystem  get  got expected exception  info  set  log  stringifyexception  could not find any configured addresses for uri   uri  .  fail  contains  exists  testfailurewithmisconfiguredhanns  misconfigured-ha-uri  dfs_client_failover_proxy_provider_key_prefix  ioe
__label__nflaky scheme  specials  set  scheme  /abcd!$&*()_-+. =:;\'~@?<>|#^\%\""{}\\Â£`Â¬Â¦xyz  assert  set  custom  query  host  get  path  get  loopback  address  https  get  host  address  bld  get  host  get  query  loopback  address  n.  b.  excludes  space  set  fragment  set  path  assert  equals  check  that  the  uri  generated  by  uri  builder  agrees  with  that  generated  by  using  uri  directly  uri  uri  builder  set  user  info  test  loopback  address  build  get  fragment  get  user  info  inet  address  scheme  specials  setscheme  /abcd!$&*()_-+. =:;\'~@?<>|#^\%\""{}\\Â£`Â¬Â¦xyz  assert  setcustomquery  host  getpath  getloopbackaddress  https  gethostaddress  bld  gethost  getquery  loopbackaddress   n.b. excludes space  setfragment  setpath  assertequals   check that the uri generated by uri builder agrees with that generated by using uri directly  uri  uribuilder  setuserinfo  testloopbackaddress  build  getfragment  getuserinfo  inetaddress
__label__flaky get  name  the  candidate  be  in  memory.  get  log  put  into  a  different  column  family.  should  make  it  so  i  still  get  t10  delete  put  create  table  descriptor  bytes  t20  t00  assert  true  htd  columns  ask  for  a  value  off  the  end  of  the  file.  should  return  t10.  close  add  in  memory;  make  sure  we  get  back  t10  again.  print  stack  trace  d  e  test  get  closest  row  before3  get  row  c0  c1  close  and  delete  flushcache  create  new  h  region  p  t30  try  finding  \""010\""  after  flush  t10  get  closest  row  before  r  t31  t12  t11  equals  region  delete  column  getname   the candidate be in memory.  getlog   put into a different column family.  should make it so i still get t10  delete  put  createtabledescriptor  bytes  t20  t00  asserttrue  htd  columns   ask for a value off the end of the file.  should return t10.  close  add   in memory; make sure we get back t10 again.  printstacktrace  d  e  testgetclosestrowbefore3  getrow  c0  c1  closeanddelete  flushcache  createnewhregion  p  t30   try finding \""010\"" after flush  t10  getclosestrowbefore  r  t31  t12  t11  equals  region  deletecolumn
__label__nflaky unknown.domain.  test  resolver  get  by  name  qualified  with  domain  verify  get  by  name  unknown.domain.  testresolvergetbynamequalifiedwithdomain  verifygetbyname
__label__flaky .valid  {color:  red}  @mixin  rounded($side   $radius:  10px)  {  border-#{$side}-radius:  $radius;  -moz-border-radius-#{$side}:  $radius;  -webkit-border-#{$side}-radius:  $radius;}#navbar  li  {  @include  rounded(top);  }  should  succeed  after  a  failure  fail  process  $base=  #f938ab;  sass  processor  should  have  failed  .valid {color: red}  @mixin rounded($side  $radius: 10px) { border-#{$side}-radius: $radius; -moz-border-radius-#{$side}: $radius; -webkit-border-#{$side}-radius: $radius;}#navbar li { @include rounded(top); }  shouldsucceedafterafailure  fail  process  $base= #f938ab;  sass  processor  should have failed
__label__nflaky prepare  set  test  coding  direct  buffer  with  conf_10x4_erasing_d0  codec  util  rs  raw  erasure  coder  factory  conf  test  coding  prepare  set  testcodingdirectbufferwithconf_10x4_erasing_d0  codecutil  rsrawerasurecoderfactory  conf  testcoding
__label__flaky cluster  *  creates  a  block  with  all  datanodes  on  the  same  rack   though  the  block  *  is  sufficiently  replicated.  adds  an  additional  datanode  on  a  new  rack.  *  the  block  should  be  replicated  to  the  new  rack.  test  sufficiently  repl  blocks  uses  new  rack  racks  conf  wait  for  replication  /rack2  /rack1  fs  create  file  wait  active  create  a  file  with  one  block  with  a  replication  factor  of  3  all  datanodes  are  on  the  same  rack  dfs  test  util  b  start  data  nodes  get  conf  new  racks  add  a  new  datanode  on  a  different  rack  file  path  get  file  system  replication_  factor  /test  file  build  num  data  nodes  get  first  block  shutdown  cluster       * creates a block with all datanodes on the same rack  though the block     * is sufficiently replicated. adds an additional datanode on a new rack.      * the block should be replicated to the new rack.       testsufficientlyreplblocksusesnewrack  racks  conf  waitforreplication  /rack2  /rack1  fs  createfile  waitactive   create a file with one block with a replication factor of 3   all datanodes are on the same rack  dfstestutil  b  startdatanodes  getconf  newracks   add a new datanode on a different rack  filepath  getfilesystem  replication_factor  /testfile  build  numdatanodes  getfirstblock  shutdown
__label__nflaky .a.b.  test  resolver  get  by  name  unqualified  host  .c.  .b.  .  verify  get  by  name  unknown  .a.b.  testresolvergetbynameunqualified  host  .c.  .b.  .  verifygetbyname  unknown
__label__flaky ${coord:future  range(0 3 \'5\')}  action  id  coord  el  functions  tz  date  utils  /2009/02/26  parse  date  oozie  tz  /2009/03/26/  get  test  case  dir  file://  action  index  of  providing  some  of  the  dataset  dirs  required  as  per  coordinator  specification  with  holes  /2009/02/26/  limit  is  5.  so  this  should  be  ignored  resolved  list  execute  /2009/03/05  job  id  fail  coord  command  utils  job  /2009/03/12  get  missing  dependencies  get  time  get  id  2009-02-16  t23:59  </uris>  /2009/03/12/  substring  action  xml  /2009/02/12/  <uris>  get  create  dir  start  time  2009-02-15  t23:59  /2009/03/05/  /2009/02/12  test  action  input  check  future  assert  equals  -  test  coord  action  input  check  x  command-  c  add  record  to  coord  job  table  call  @1  services  was  not  stored  properly  in  db  get  action  xml  future  0000000-  end  time  jpa  service  ${coord:futurerange(0 3 \'5\')}    action id   coordelfunctions  tz  dateutils  /2009/02/26  parsedateoozietz  /2009/03/26/  gettestcasedir  file://  action  indexof   providing some of the dataset dirs required as per coordinator specification with holes  /2009/02/26/   limit is 5. so this should be ignored  resolvedlist  execute  /2009/03/05  jobid  fail  coordcommandutils  job  /2009/03/12  getmissingdependencies  gettime  getid  2009-02-16t23:59  </uris>  /2009/03/12/  substring  actionxml  /2009/02/12/  <uris>  get  createdir  starttime  2009-02-15t23:59  /2009/03/05/  /2009/02/12  testactioninputcheckfuture  assertequals  -testcoordactioninputcheckxcommand-c  addrecordtocoordjobtable  call  @1  services   was not stored properly in db  getactionxml  future  0000000-  endtime  jpaservice
__label__nflaky test  writable  test  byte  writable  testwritable  testbytewritable
__label__flaky init  -ve  test  coord  el  functions  testdata  in  partition  filter  ph1  set  variable  +ve  test  assert  equals  ${coord:data  in  partition  filter(\'  abc\'   \'pig\')}  oozie.dataname.  abcd  data-in  coord-job-submit-data  fail  eval  eval  and  wrap  ${coord:data  in  partition  filter(\'  abcd\')}  should  throw  exception  because  data  in  partition  filter()  requires  2  parameters  expr  oozie.dataname.  abc  init   -ve test  coordelfunctions  testdatainpartitionfilterph1  setvariable   +ve test  assertequals  ${coord:datainpartitionfilter(\'abc\'  \'pig\')}  oozie.dataname.abcd  data-in  coord-job-submit-data  fail  eval  evalandwrap  ${coord:datainpartitionfilter(\'abcd\')}  should throw exception because datainpartitionfilter() requires 2 parameters  expr  oozie.dataname.abc
__label__nflaky set  write  lock  get  method  name  log  release  read  lock  assert  false  start  run  testname  test  write  lock  acquire  try  lock  remove  read  write  lock  get  name  competing  write  thread  lock  competing  read  thread  join  locked  boolean  set  writelock  getmethodname  log  release  readlock  assertfalse  start  run  testname  testwritelock  acquire  trylock  remove  readwritelock  get  name  competingwritethread  lock  competingreadthread  join  locked  boolean
__label__flaky request  bulkjpa  bundle=  bundle-  abc;actionstatus=  failed  bundle  engine  get  message  execute  fail  contains  test  java  no  records  assert  true  no  bundle  entries  found  parse  bulk  filter  exception  expected  due  to  no  records  found  for  this  jex  jpa  service  request  bulkjpa  bundle=bundle-abc;actionstatus=failed  bundleengine  getmessage  execute  fail  contains  testjavanorecords  asserttrue  no bundle entries found  parsebulkfilter   exception expected due to no records found for this  jex  jpaservice
__label__nflaky header  \':scheme\'  must  not  be  set  for  connect  request  headers  custom  converter  thrown  connect  convert  www.example.com  as  list  expect  message  expect  test  convert  from  fields  connect  present  scheme  :method  :scheme  http  arrays  value  :authority  header \':scheme\' must not be set for connect request  headers  custom  converter  thrown  connect  convert  www.example.com  aslist  expectmessage  expect  testconvertfromfieldsconnectpresentscheme  :method  :scheme  http  arrays  value  :authority
__label__flaky job1  get  time  pause  start  runnable  add  record  to  bundle  job  table  run  get  id  assert  equals  get  status  execute  services  job  id  test  start1  assert  not  null  get  set  kickoff  time  job  job  jpa  service  evaluate  wait  for  job1  gettime  pausestartrunnable  addrecordtobundlejobtable  run  getid  assertequals  getstatus  execute  services  jobid  teststart1  assertnotnull  get  setkickofftime  job  job  jpaservice  evaluate  waitfor
__label__nflaky 20080504  t123456  z  test  location  do  test  location:  miami  begin:  vcalendar  begin:  vevent  dtstart:20080504  t123456  z  end:  vevent  end:  vcalendar  miami  20080504t123456z  testlocation  dotest  location:miami    begin:vcalendar  begin:vevent    dtstart:20080504t123456z    end:vevent  end:vcalendar  miami
__label__flaky play  def  okio  go  away  util  header  entries  stream  was  reset:  refused_  stream  get  sink  get  bytes  type_  headers  variant  type_  ping  connection  buffer  protocol_  error  banana  expected  utf-8  ensure  that  the  go_  away  has  been  received.  fail  arrays  new  stream  shutdown  ping  play  it  back  android  type_  data  verify  the  peer  received  what  was  expected  syn_  stream  3  syn_  stream  1  cola  accept  frame  flush  open  stream  count  assert  true  receive  go  away  peer  round  trip  time  write  utf8  close  take  frame  a  data  stream  1  b  abc  c  set  variant  and  client  stream1  stream2  data1  get  message  assert  equals  syn  stream1  syn  stream2  send  frame  spdy3  equals  ping  sink2  abcdef  sink1  play  def  okio  goaway  util  headerentries  stream was reset: refused_stream  getsink  getbytes  type_headers  variant  type_ping  connection  buffer  protocol_error  banana  expected  utf-8   ensure that the go_away has been received.  fail  arrays  newstream  shutdown  ping   play it back  android  type_data   verify the peer received what was expected   syn_stream 3   syn_stream 1  cola  acceptframe  flush  openstreamcount  asserttrue  receivegoaway  peer  roundtriptime  writeutf8  close  takeframe  a   data stream 1  b  abc  c  setvariantandclient  stream1  stream2  data1  getmessage  assertequals  synstream1  synstream2  sendframe  spdy3  equals   ping  sink2  abcdef  sink1
__label__nflaky hadoop_  shell_  missing_  default_  fs_  warning_  key  assert  illegal  arguments  chgrp  enable  warning  :gr#oup  group  with  spaces  conf  run  the  following  are  valid  only  on  windows.  the  following  are  invalid  (exception  expected).  set  conf  the  following  are  valid  (no  exception  expected).  :gr\%oup  test  chgrp  group  validity  /path  assert  valid  arguments  on  windows  set  boolean  group  hadoop_shell_missing_default_fs_warning_key  assertillegalarguments  chgrp  enablewarning  :gr#oup  group with spaces  conf  run   the following are valid only on windows.   the following are invalid (exception expected).  setconf   the following are valid (no exception expected).  :gr\%oup  testchgrpgroupvalidity  /path  assertvalidargumentsonwindows  setboolean  group
__label__flaky coordinator.xml  set  coord  job  submission  should  fail  with  reserved  variable  definitions.  <coordinator-app  name=\""  name\""  frequency=\""10\""  start=\""2009-02-01  t01:00  z\""  end=\""2009-02-03  t23:59  z\""  timezone=\""  utc\""  conf  app  path  </configuration>  </workflow>  </action>  </coordinator-app>  sc  call  write  to  file  oozie  client  1  fail  app  xml  get  test  user  file://  get  test  case  dir  unit_  testing  test  submit  reserved  vars  <action>  <workflow>  <app-path>hdfs:///tmp/workflows/</app-path>  minutes  file  xmlns=\""uri:oozie:coordinator:0.2\"">  <configuration>  <property>  <name>input  a</name>  <value>blah</value>  </property>  coordinator.xml  set  coord job submission should fail with reserved variable definitions.  <coordinator-app name=\""name\"" frequency=\""10\"" start=\""2009-02-01t01:00z\"" end=\""2009-02-03t23:59z\"" timezone=\""utc\""   conf  apppath  </configuration> </workflow> </action> </coordinator-app>  sc  call  writetofile  oozieclient  1  fail  appxml  gettestuser  file://  gettestcasedir  unit_testing  testsubmitreservedvars  <action> <workflow> <app-path>hdfs:///tmp/workflows/</app-path>   minutes  file  xmlns=\""uri:oozie:coordinator:0.2\"">   <configuration> <property> <name>inputa</name> <value>blah</value> </property>
__label__nflaky test  file01  get  path  data  process  path  dir  order  mtime  years  testfile01  get  time  add  contents  ls  format  line  mtime  out  overflow  issues)  testfile03  options  compute  line  format  in  order  testfile02  process  options  verify  testfile05  test  file06  set  mtime  testfile04  test  file04  test  file05  testfile06  test  file02  test  file03  set  file  mtime  in  different  order  to  file  names  add  found  6  items  path  data  line  format  -t  set  is  dir  process  arguments  test  dir  integer  test  directory  verify  no  more  interactions  now  test  file  mock    testfile01  getpathdata  processpathdirordermtimeyears  testfile01  gettime  addcontents  ls  formatlinemtime  out   overflow issues)  testfile03  options  computelineformat  inorder  testfile02  processoptions  verify  testfile05  testfile06  setmtime  testfile04  testfile04  testfile05  testfile06  testfile02  testfile03   set file mtime in different order to file names  add  found 6 items  pathdata  lineformat  -t  setisdir  processarguments  testdir  integer  testdirectory  verifynomoreinteractions  now  testfile  mock
__label__flaky a  l1  l2  start  assert  equals  sb  thread  sleep  a:1-  l  a:1-  u  a:2-  l  a:2-  u  trim  finish  to  string  test  timeout  waiting  write  lock    a  l1  l2  start  assertequals  sb  thread  sleep  a:1-l a:1-u a:2-l a:2-u  trim  finish  tostring  testtimeoutwaitingwritelock
__label__nflaky test  compress  decompress  tester  compression  test  strategy  size  with  test  cases  test  compressor  decompressor  generic  test  utils  raw  data  with  compress  decompress  pair  no  more  for  this  data  ex  immutable  set  of  assert  exception  contains  test  compressor  decompressor  error  !!!  generate  test  compressdecompresstester  compressionteststrategy  size  withtestcases  testcompressordecompressor  generictestutils  rawdata  withcompressdecompresspair   no more for this data  ex  immutableset  of  assertexceptioncontains  testcompressordecompressor error !!!  generate
__label__flaky init  ${coord:user()}  coord  el  functions  coord-job-submit-instances  assert  equals  coord-sla-create  coord-action-create  coord-action-start  coord-job-submit-data  test_user  eval  eval  and  wrap  coord-action-create-inst  expr  test  user  coord-job-submit-freq  coord-sla-submit  init  ${coord:user()}  coordelfunctions  coord-job-submit-instances  assertequals  coord-sla-create  coord-action-create  coord-action-start  coord-job-submit-data  test_user  eval  evalandwrap  coord-action-create-inst  expr  testuser  coord-job-submit-freq  coord-sla-submit
__label__nflaky types  test  content  types  new  array  list  lists  get  content  types  equal  to  application/json   application/x-www-form-urlencoded   application/xml  to  string  sort  collections  assert  that  create  body  parser  engine  manager  types  testcontenttypes  newarraylist  lists  getcontenttypes  equalto  application/json  application/x-www-form-urlencoded  application/xml  tostring  sort  collections  assertthat  createbodyparserenginemanager
__label__flaky issue  the  kill  command  get  current  dateafter  incrementing  in  months  create  a  coordinator  job  with  running  status  get  id  test  coord  kill  waiting  date  utils  workflow  instance  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  job  action  kill  should  be  false  wf  job1  create  a  coordinator  job  with  waiting  status  add  record  to  wf  job  table  assert  not  null  get  coordinator  action  end  current  date  plus  month  workflow  job  kill  should  be  true  running  coord  action  get  cmd2  check  the  status  and  pending  flag  after  kill  command  is  issued  coord  action  get  cmd1  start  make  sure  the  status  is  updated  assert  equals  x  data  test  case  execute  add  record  to  coord  job  table  call  coordinator  job  services  coord  job  get  cmd  coord-action-get.xml  create  a  workflow  job  with  running  status  action1  action2  get  pending  jpa  service   issue the kill command  getcurrentdateafterincrementinginmonths   create a coordinator job with running status  getid  testcoordkillwaiting  dateutils  workflowinstance  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordjob   action kill should be false  wfjob1   create a coordinator job with waiting status  addrecordtowfjobtable  assertnotnull  get  coordinatoraction  end  currentdateplusmonth  workflowjob   kill should be true  running  coordactiongetcmd2   check the status and pending flag after kill command is issued  coordactiongetcmd1  start   make sure the status is updated  assertequals  xdatatestcase  execute  addrecordtocoordjobtable  call  coordinatorjob  services  coordjobgetcmd  coord-action-get.xml   create a workflow job with running status  action1  action2  getpending  jpaservice
__label__nflaky is  null  for  inexistent  property  should  evaluate  to  true  build  and  assert  true  is  null  script  str  isnullforinexistentpropertyshouldevaluatetotrue  buildandasserttrue  isnullscriptstr
__label__flaky a  test  write  read  lock  l1  l2  start  assert  equals  sb  thread  sleep  a:1-  l  a:1-  u  a:2-  l  a:2-  u  trim  finish  to  string    a  testwritereadlock  l1  l2  start  assertequals  sb  thread  sleep  a:1-l a:1-u a:2-l a:2-u  trim  finish  tostring
__label__nflaky msg  set  native  zlib  loaded  this  is  the  message  in  the  file!  test  gzip  codec  read.txt.gz  ensure  that  the  codec  pool  has  a  built  in  zlib  inflater  in  it.  line  return  decompressor  get  temp  path  ccf  conf  fs  br  didn\'t  get  the  same  message  back!  test  gzip  codec  read  zlib  factory  get  zlib  decompressor  assert  true  bw  assert  not  null  file  system  zlib  factory  returned  unexpected  inflator  write  close  codec  pool  decompressor  get  codec  f  zlib  decompressor  generic  test  utils  is  assert  equals  read  line  create  input  stream  get  decompressor  now  create  a  g  zip  text  file.  codec  don\'t  use  native  libs  for  this  test.  decompressor  to  use.  get  local  to  string  zlib  decompressor  is  null!  open  msg  setnativezlibloaded  this is the message in the file!  testgzipcodecread.txt.gz   ensure that the codecpool has a builtinzlibinflater in it.  line  returndecompressor  gettemppath  ccf  conf  fs  br  didn\'t get the same message back!  testgzipcodecread  zlibfactory  getzlibdecompressor  asserttrue  bw  assertnotnull  filesystem  zlibfactory returned unexpected inflator  write  close  codecpool  decompressor  getcodec  f  zlibdecompressor  generictestutils  is  assertequals  readline  createinputstream  getdecompressor   now create a gzip text file.  codec   don\'t use native libs for this test.   decompressor to use.  getlocal  tostring  zlibdecompressor is null!  open
__label__flaky cluster  shutdown  dfs  do  a  sync  flush.  test  scan  and  sync  flush  e  log  failed  get  log  count  h  constants  assert  equals  error  added:  add  content  close  and  delete  create  new  h  region  bytes  r  get  table  desc  region_  info  to  string  close  hri  info  cluster  shutdowndfs   do a sync flush.  testscanandsyncflush  e  log  failed  getlog  count  hconstants  assertequals  error  added:   addcontent  closeanddelete  createnewhregion  bytes  r  gettabledesc  region_info  tostring  close  hri  info
__label__nflaky assert  false  channel  out  stream  get  bytes  assert  flush  inbuf  buffer  write  chbuffer  s1  s2  s3  a  standard  charsets  clear  assert  equals  fill  read  line  byte  buffer  set  length  outbuf  to  byte  array  to  string  test  complex  read  write  line  wrap  new  channel  append  out  channel    assertfalse  channel  outstream    getbytes  assert  flush  inbuf  buffer  write      chbuffer  s1  s2  s3  a  standardcharsets  clear  assertequals  fill  readline  bytebuffer  setlength  outbuf  tobytearray  tostring  testcomplexreadwriteline  wrap  newchannel  append  outchannel
__label__flaky -start  end_  points  is_  security_  enabled  oozie  url  run  contains  value  test  header  propagation  assert  true  oozie  cli  servlet_  classes  run  test  rest  constants  test  get  context  url  header  testing  version  servlet  contains  key  clear  mock  dag  engine  service  assert  equals  args  call  1  -oozie  set  system  property  header  job  -start  end_points  is_security_enabled  oozieurl  run  containsvalue  testheaderpropagation  asserttrue  ooziecli  servlet_classes  runtest  restconstants  test  getcontexturl  headertestingversionservlet  containskey  clear  mockdagengineservice  assertequals  args  call  1  -oozie  setsystemproperty  header  job
__label__nflaky item  get  conf  /one/two/test  apply  assert  equals  test  the  full  path  is  printed  to  stdout  set  out  out  result  test  print  print  filename  verify  no  more  interactions  options  mock  set  options  verify  mock  fs  item  getconf  /one/two/test  apply  assertequals   test the full path is printed to stdout  setout  out  result  testprint  print  filename  verifynomoreinteractions  options  mock  setoptions  verify  mockfs
__label__flaky add  record  to  wf  action  table  get  id  workflow  instance  get  status  update  the  list  for  doing  bulk  writes  coord  job  wf  job  add  record  to  wf  job  table  assert  not  null  get  action  workflow  job  update  list  add  get  status  str  update  the  status  check  for  expected  status  after  running  bulk  update  jpa  running  assert  equals  execute  add  record  to  coord  job  table  set  status  coordinator  job  1  services  set  update  list  workflow  action  bulk  update  cmd  succeeded  test  updates  action2  jpa  service  addrecordtowfactiontable  getid  workflowinstance  getstatus   update the list for doing bulk writes  coordjob  wfjob  addrecordtowfjobtable  assertnotnull  get  action  workflowjob  updatelist  add  getstatusstr   update the status   check for expected status after running bulkupdatejpa  running  assertequals  execute  addrecordtocoordjobtable  setstatus  coordinatorjob  1  services  setupdatelist  workflowaction  bulkupdatecmd  succeeded  testupdates  action2  jpaservice
__label__nflaky next  next  key  should  be  always  equal  or  more  value:  reader  prev  assert  false  conf  test  iteration  merge  all  5  files  path  iterator  assert  true  merge  get  start  value  collections  value  test_  dir  key  add  test_  method_  key  test  merge  set  test  merge.mapfile  in  sort  expected  values  create  reader  int  value  size  expected  start  j  assert  equals  inputs  should  be  deleted  sort  get  file  system  .  create  writer  inputs  should  be  deleted  iterations  expected  iterator  reset  exists  writer  append  merger  next  next key should be always equal or more  value:  reader  prev  assertfalse  conf   test iteration   merge all 5 files  path  iterator  asserttrue  merge  get  startvalue  collections  value  test_dir  key  add  test_method_key  testmerge  set  testmerge.mapfile  in   sort expected values  createreader  intvalue  size  expected  start  j  assertequals  inputs should be deleted  sort  getfilesystem  .  createwriter   inputs should be deleted  iterations  expectediterator  reset  exists  writer  append  merger
__label__flaky get  current  user  new  record  instance  conf  run  staging  dir  fs  delete  when  staging  dir  exists  system  jobid  hook  assert  true  app  id  verify  no  retry  test  deletionof  staging  on  kill  last  try  user  group  information  attempt  id  get  short  user  name  mock  alloc  mr  app  master  isn\'t  stopped  any  boolean  init  set  then  return  service  new  instance  application  attempt  id  is  last  am  retry  any  set  app  id  app  master.is  last  am  retry()  is  false  mr  apps  staging  job  path  record  factory  simulate  the  process  being  killed  current  time  millis  mock  exists  mr  job  config  application  id  user  get  staging  area  dir  app  master  is  in  state  staging  job  dir  getcurrentuser  newrecordinstance  conf  run  stagingdir  fs  delete  when   staging dir exists  system  jobid  hook  asserttrue  appid  verify   no retry  testdeletionofstagingonkilllasttry  usergroupinformation  attemptid  getshortusername  mockalloc  mrappmaster isn\'t stopped  anyboolean  init  set  thenreturn  service  newinstance  applicationattemptid  islastamretry  any  setappid  appmaster.islastamretry() is false  mrapps  stagingjobpath  recordfactory   simulate the process being killed  currenttimemillis  mock  exists  mrjobconfig  applicationid  user  getstagingareadir  appmaster  isinstate  stagingjobdir
__label__nflaky de  en-  us  en-  ca  ninja  constant  this  is  the  placeholder:  test_parameter  when  get  cookie  result  of  get  context  builder  torÃ¶Ã¶Ã¶Ã¶  -  das  ist  der  platzhalter:  test_parameter  lang  ok  cookie  test_parameter  de-  de  optional  message_with_placeholder  that  will  refer  to  messages_de.properties:  then  return  any  string  en  assert  equals  c\'est  le  placeholder:  test_parameter  and  the  result  overwrites  it  again...  that  will  refer  to  messages_en.properties:  results  build  mockito  test  with  context  accept  header  name  messages  test  get  with  default  and  context  and  result  get  string  array  en-  uk  fr-  fr  ninja  properties  get  accept  language  that  forced  language  from  context  works  with  empty  result  set  language  de  en-us  en-ca  ninjaconstant  this is the placeholder: test_parameter  when  getcookie  result  of  get  context  builder  torÃ¶Ã¶Ã¶Ã¶ - das ist der platzhalter: test_parameter  lang  ok  cookie  test_parameter  de-de  optional  message_with_placeholder   that will refer to messages_de.properties:  thenreturn  anystring  en  assertequals  c\'est le placeholder: test_parameter   and the result overwrites it again...   that will refer to messages_en.properties:  results  build  mockito   test with context accept header  name  messages  testgetwithdefaultandcontextandresult  getstringarray  en-uk  fr-fr  ninjaproperties  getacceptlanguage   that forced language from context works with empty result  setlanguage
__label__flaky test  basic  submit  with  multiple  instances  input  event  coord-multiple-input-instance1.xml  case  3:  success  case  i.e.  multiple  data-in  instances  specified  correctly  as  separate  <instance>  tags  reader  per  data-in  instance  conf  get  status  app  path  get  job  sc  case  4:  success  case  i.e.  single  instances  for  input  and  single  instance  for  output   but  both  with  \"" \""  get  error  code  assert  true  expected  to  catch  errors  due  to  incorrectly  specified  input  data  set  instances  file://  get  test  case  dir  unit_  testing  get  path  job  coordinator.xml  coord-multiple-input-instance4.xml  set  e  case  2:  multiple  data-in  instances  specified  as  separate  <instance>  tags   but  one  or  more  tags  are  empty.  check  works  for  whitespace  in  the  tags  too  get  message  assert  equals  coord-multiple-input-instance3.xml  call  case  1:  failure  case  i.e.  multiple  data-in  instances  oozie  client  fail  io  utils  contains  is  empty  get  test  user  copy  char  stream  unexpected  failure:  get  resource  as  reader  coord-multiple-input-instance2.xml  writer  error  code  file  testbasicsubmitwithmultipleinstancesinputevent  coord-multiple-input-instance1.xml   case 3: success case i.e. multiple data-in instances specified correctly as separate <instance> tags  reader  per data-in instance  conf  getstatus  apppath  getjob  sc   case 4: success case i.e. single instances for input and single instance for output  but both with \"" \""  geterrorcode  asserttrue  expected to catch errors due to incorrectly specified input data set instances  file://  gettestcasedir  unit_testing  getpath  job  coordinator.xml  coord-multiple-input-instance4.xml  set  e   case 2: multiple data-in instances specified as separate <instance> tags  but one or more tags are empty. check works for whitespace in the tags too  getmessage  assertequals  coord-multiple-input-instance3.xml  call   case 1: failure case i.e. multiple data-in instances  oozieclient  fail  ioutils  contains  is empty  gettestuser  copycharstream  unexpected failure:   getresourceasreader  coord-multiple-input-instance2.xml  writer  errorcode  file
__label__nflaky gid  name  map  get  user  name()  get  gid  conf  <username>  is  numerical   remove  them  from  the  map  for  testing  purpose.  get  gid  name  map  tid  get  uid  uid  name  map  ref  id  mapping  me  get  user  name  id  clear  name  maps  get  key  get  uid  name  map  entry  set  get  gid()  incr  id  mapping  tname  assert  equals  get  value  get  group  name  test  update  map  incr  id  mapping  constant  set  long  size  get  uid()  name  get  group  name()  gidnamemap   getusername()  getgid  conf   <username> is numerical  remove them from the map for testing purpose.  getgidnamemap  tid  getuid  uidnamemap  refidmapping  me  getusername  id  clearnamemaps  getkey  getuidnamemap  entryset   getgid()  incridmapping  tname  assertequals  getvalue  getgroupname  testupdatemapincr  idmappingconstant  setlong  size   getuid()  name   getgroupname()
__label__flaky play  assert  contains  all  test  cookies  sent  ignores  case  server  request  assert  false  baz=baz  put  result  get  cookie:  bar=bar  collections  coo  kie2  quux:  quux  get  headers  take  request  singleton  list  bar=bar  set  default  /  enqueue  contains  cookie  cookie  handler  coo  kie2:  baz=baz  play  assertcontainsall  testcookiessentignorescase  server  request  assertfalse  baz=baz  put  result  get  cookie: bar=bar  collections  cookie2  quux: quux  getheaders  takerequest  singletonlist  bar=bar  setdefault  /  enqueue  contains  cookie  cookiehandler  cookie2: baz=baz
__label__nflaky thu   01  jan  1970  00:00:00  gmt  date  util  test  parse  http  date  format  to  string  assert  equals  wed   05  sep  2012  09:57:57  gmt  some  simple  tests:  parse  http  date  format  thu  01 jan 1970 00:00:00 gmt  dateutil  testparsehttpdateformat  tostring  assertequals  wed  05 sep 2012 09:57:57 gmt   some simple tests:  parsehttpdateformat
__label__flaky <property><name>hello</name><value>world</value></property>  set  xml  utils  planet  parse  xml  conf  assert  equals  <root  xmlns=\""uri:oozie:workflow:0.4\""><parameters>  str  test  verify  parameters  defined  size  <property><name>hello</name></property>  get  parameter  verifier  verify  parameters  </parameters></root>  <property><name>hello</name><value>world</value></property>  set  xmlutils  planet  parsexml  conf  assertequals  <root xmlns=\""uri:oozie:workflow:0.4\""><parameters>  str  testverifyparametersdefined  size  <property><name>hello</name></property>  get  parameterverifier  verifyparameters  </parameters></root>
__label__nflaky src  file  partitioned  conf  del  copy  a  dir:  dest  fs  delete  content  create  file  get  bytes  system  result  should  be  deleted  assert  true  tmp  file  system  copy  list  files  get  property  *  test  method  copy(  file  system  src  fs   path  src   file  dst   boolean  delete  source   configuration  conf)  src  f  to  uri  some-content  src  path  length  new  instance  assert  equals  uri  copy  regular  file:  line.separator  test  copy5  exists  files  setup  dirs  file  util  copy  regular  file   delete  src:  is  directory  should  not  be  deleted  srcfile  partitioned  conf  del   copy a dir:  dest  fs  delete  content  createfile  getbytes  system  result   should be deleted  asserttrue  tmp  filesystem  copy  listfiles  getproperty       * test method copy(filesystem srcfs  path src  file dst  boolean deletesource  configuration conf)       src  f  touri  some-content  srcpath  length  newinstance  assertequals  uri   copy regular file:  line.separator  testcopy5  exists  files  setupdirs  fileutil   copy regular file  delete src:  isdirectory   should not be deleted
__label__flaky /test/mkdirs  file  does  not  exist  get  message  list  status  does  not  exist.  assert  equals  get  file  status  of  non-existent  path  should  fail  dir  fs  file  fail  exception  doesn\'t  indicate  non-existant  path  list  status  of  non-existent  path  should  fail  assert  true  get  file  status  fc  test  get  file  status  on  non  existant  file  dir  fe  starts  with  /test/mkdirs  file does not exist  getmessage  liststatus   does not exist.  assertequals  getfilestatus of non-existent path should fail  dir  fs  file   fail  exception doesn\'t indicate non-existant path  liststatus of non-existent path should fail  asserttrue  getfilestatus  fc  testgetfilestatusonnonexistantfiledir  fe  startswith
__label__nflaky app.callback  app.callback(123)  jsonp  test  correct  flow  then  return  finalize  headers  utf-8  invoke  assert  equals  when  result  object  mapper  to  byte  array  context  callback  verify  output  stream  template  engine  json  p  properties  jsonp  engine  get  parameter  app.callback  app.callback(123)  jsonp  testcorrectflow  thenreturn  finalizeheaders  utf-8  invoke  assertequals  when  result  objectmapper  tobytearray  context  callback  verify  outputstream  templateenginejsonp  properties  jsonpengine  getparameter
__label__flaky bulk  insert  cmd  create  workflow  add  node  auth  get  app  path  prep  conf  get  id  test  token  workflow  instance  action  get  cmd  set  insert  list  assert  not  null  get  test  app  <workflow-app/>  end  workflow.xml  workflow  job  app  add  get  status  str  set  check  for  expected  status  after  running  bulk  update  jpa  insert  list  wf  get  cmd  test  inserts  assert  equals  execute  app  uri  oozie  client  1  services  2  get  test  user  workflow  action  to  string  create  workflow  action  action1  insert  one  workflow  job  and  two  actions  job  action2  jpa  service  bulkinsertcmd  createworkflow  addnode  auth  getapppath  prep  conf  getid  testtoken  workflowinstance  actiongetcmd  setinsertlist  assertnotnull  get  testapp  <workflow-app/>  end  workflow.xml  workflowjob  app  add  getstatusstr  set   check for expected status after running bulkupdatejpa  insertlist  wfgetcmd  testinserts  assertequals  execute  appuri  oozieclient  1  services  2  gettestuser  workflowaction  tostring  createworkflowaction  action1   insert one workflow job and two actions  job  action2  jpaservice
__label__nflaky get  bytes  transferred  read  dst  standard  charsets  codec  test  utils  assert  false  channel  clear  bytes  read  assert  equals  decoder  convert  byte  buffer  content  length:  16;  pos:  16;  completed:  true  stuff;  assert  allocate  inbuf  assert  true  test  basic  decoding  to  string  more  stuff  metrics  is  completed  getbytestransferred  read  dst  standardcharsets  codectestutils  assertfalse  channel  clear  bytesread  assertequals  decoder  convert  bytebuffer  content length: 16; pos: 16; completed: true  stuff;  assert  allocate  inbuf  asserttrue  testbasicdecoding  tostring  more stuff  metrics  iscompleted
__label__flaky exception  end_  points  lib  set  fs.default  fs  instead  java.lang.  runtime  exception:  namenode  is  not  specified  in  conf  conf  submit  client  without  libpath  should  throw  exception  start  position  localhost:9001  test  submit  mr  lib  path  set  fs.default.name  get  path  local  path  servlet_  classes  index  of  lib  path  can  not  be  relative  get  context  url  get  file  system  submit  map  reduce  fail  oozie  client  java.lang.  runtime  exception:  libpath  should  be  absolute  mkdirs  set  property  create  configuration  submit  client  without  jt  should  throw  exception  submit  client  without  nn  should  throw  exception  nn  is_  security_  enabled  oozie  url  wc  substring  remove  assert  true  get  run  test  e  to  uri  x  oozie  client  mock  dag  engine  service  assert  equals  java.lang.  runtime  exception:  jobtracker  is  not  specified  in  conf  call  wf  count  to  string  try  to  submit  without  jt  and  nn  get  fs  test  case  dir  java.lang.  runtime  exception:  libpath  is  not  specified  in  conf  exception  end_points  lib   set fs.defaultfs instead  java.lang.runtimeexception: namenode is not specified in conf  conf  submit client without libpath should throw exception  startposition  localhost:9001  testsubmitmr  libpath   set fs.default.name  getpath  localpath  servlet_classes  indexof  lib path can not be relative  getcontexturl  getfilesystem  submitmapreduce  fail  oozieclient  java.lang.runtimeexception: libpath should be absolute  mkdirs  setproperty  createconfiguration  submit client without jt should throw exception  submit client without nn should throw exception  nn  is_security_enabled  oozieurl  wc  substring  remove  asserttrue  get  runtest  e  touri  xoozieclient  mockdagengineservice  assertequals  java.lang.runtimeexception: jobtracker is not specified in conf  call  wfcount  tostring   try to submit without jt and nn  getfstestcasedir  java.lang.runtimeexception: libpath is not specified in conf
__label__nflaky get  name  out  path  mm1  $ \\r*^\\d+\\s+test1.test  record2:\\s+  context=test1   out  file  test.sink.mysink0.class  compile  get  test  filename  add  test  ms  utf-8  get  test  temp  file  is  note  that  in  the  below  expression  we  allow  tags  and  metrics  to  go  in  arbitrary  order.  matcher  matches  stop  cleanup  *.period  test  metrics  config  register  with  shutdown  (test  tag1=test  tag  value1 \\s+test  tag2=test  tag  value2|test  tag2=test  tag  value2 \\s+test  tag1=test  tag  value1)   expected  content  pattern  publish  the  metrics  \\s+  hostname=.* \\s+(test  metric1=1 \\s+test  metric2=2|test  metric2=2 \\s+test  metric1=1)  save  test.sink.mysink0.filename  test1  baos  line  #1:  line  #2:  assert  true  test.sink.mysink0.context  \\s+test  tag22=test  tag  value22 \\s+  hostname=.*$ \\r*  test  file  sink  hadoop-metrics2-test  copy  bytes  ^\\d+\\s+test1.test  record1:\\s+  context=test1 \\s+  pattern  get  absolute  path  incr  start  length  io  utils  .out  nb:  specify  large  period  to  avoid  multiple  metrics  snapshotting:  test-file-sink-  out  file  content  to  byte  array  publish  metrics  now  getname  outpath  mm1  $ \\r*^\\d+\\s+test1.testrecord2:\\s+context=test1   outfile  test.sink.mysink0.class  compile  gettestfilename  add  test  ms  utf-8  gettesttempfile  is   note that in the below expression we allow tags and metrics to go in arbitrary order.  matcher  matches  stop  cleanup  *.period  testmetricsconfig  registerwith  shutdown  (testtag1=testtagvalue1 \\s+testtag2=testtagvalue2|testtag2=testtagvalue2 \\s+testtag1=testtagvalue1)   expectedcontentpattern   publish the metrics  \\s+hostname=.* \\s+(testmetric1=1 \\s+testmetric2=2|testmetric2=2 \\s+testmetric1=1)  save  test.sink.mysink0.filename  test1  baos   line #1:   line #2:  asserttrue  test.sink.mysink0.context  \\s+testtag22=testtagvalue22 \\s+hostname=.*$ \\r*  testfilesink  hadoop-metrics2-test  copybytes  ^\\d+\\s+test1.testrecord1:\\s+context=test1 \\s+  pattern  getabsolutepath  incr  start  length  ioutils  .out   nb: specify large period to avoid multiple metrics snapshotting:  test-file-sink-  outfilecontent  tobytearray  publishmetricsnow
__label__flaky app2  dir  before2000  secs  list  status  now lets  change  the  confs  conf  suffix  when  mockfs://foo/  get  raw  file  system  set  time  last  modified  of  app1  dir  directory  and  its  files  to  before2000  secs  fs.mockfs.impl  assert  root  fs  me  application_1_1  application_1_2  50  logs  app1  dir  init  we  have  not  called  refresh  log  settings hence  don\'t  expect  to  see  the  changed  conf  values  then  return  app2  dir  status  root  path  get  file  system  time  before  2000  sec  remote  root  log  dir  1  app2  log1  2  app1  dir  status  user  dir  status  stop  true  mock  fs  app1  log1  refresh  log  retention  settings  before50  secs  remote  root  log  path  app1  log1  status  app2  log1  status  delete  system  timeout  app1  dir  would  be  deleted  since  its  done  above  log  retention  period  tmp/logs  times  app2  dir  is  not  expected  to  be  deleted  since  its  below  the  threshold  create  conf  yarn  configuration  assert  true  get  check  interval  msecs  now  root  set  time  last  modified  of  app1  dir  directory  and  its  files  to  before50  secs  verify  test  refresh  log  retention  settings  set  host1  deletion  svc  set  class  start  1800  time  before  50  sec  current  time  millis  user  dir  refresh  the  log  settings  check  interval  time  should  reflect  the  new  value  app2  dir  should  be  deleted  since  it  falls  above  the  threshold  user  log  dir  app2dir  before2000secs  liststatus   now lets change the confs  conf  suffix  when  mockfs://foo/  getrawfilesystem   set time last modified of app1dir directory and its files to before2000secs  fs.mockfs.impl  assert  rootfs  me  application_1_1  application_1_2  50  logs  app1dir  init   we have not called refreshlogsettings hence don\'t expect to see the changed conf values  thenreturn  app2dirstatus  rootpath  getfilesystem   time before 2000 sec  remoterootlogdir  1  app2log1  2  app1dirstatus  userdirstatus  stop  true  mockfs  app1log1  refreshlogretentionsettings  before50secs  remoterootlogpath  app1log1status  app2log1status  delete  system  timeout   app1dir would be deleted since its done above log retention period  tmp/logs  times   app2dir is not expected to be deleted since its below the threshold  createconf  yarnconfiguration  asserttrue  getcheckintervalmsecs  now  root   set time last modified of app1dir directory and its files to before50secs  verify  testrefreshlogretentionsettings  set  host1  deletionsvc  setclass  start  1800   time before 50 sec  currenttimemillis  userdir   refresh the log settings   check interval time should reflect the new value   app2dir should be deleted since it falls above the threshold  userlogdir
__label__nflaky test  bad  ec  level  for  bits  error  correction  level  testbadeclevel  forbits  errorcorrectionlevel
__label__flaky def  add  node  expected  to  catch  an  exception  but  did  not  encounter  any  three  two  get  cause  make  sure  the  message  contains  the  nodes  involved  in  the  invalid  transition  to  end  node  end  as  list  we  invoke  fork  join  get  error  code  assert  true  four  node  two  dummy  conf  end  test  decision  to  end  fork  join  failure  *f->(2 3)  *2->decision  node->{4 end}  *3->ok->j  *3->fail->k  *4->ok->j  *4->fail->k  *j->end  f  one  get  message  j  assert  equals  k  kill  fail  contains  ex  parser  name  error  code  arrays  def  addnode  expected to catch an exception but did not encounter any  three  two  getcause   make sure the message contains the nodes involved in the invalid transition to end  node end  aslist  we  invokeforkjoin  geterrorcode  asserttrue  four  node two  dummyconf  end  testdecisiontoendforkjoinfailure         *f->(2 3)       *2->decision node->{4 end}       *3->ok->j       *3->fail->k       *4->ok->j       *4->fail->k       *j->end         f  one  getmessage  j  assertequals  k  kill  fail  contains  ex  parser  name  errorcode  arrays
__label__nflaky test  using  weighted  time  cost  provider  with  zero  cost  calls  ignored  add  response  time  get  scheduler  with  weighted  time  cost  provider  assert  equals  empty  details  mock  call  scheduler  time  unit  few  since  the  calls  are  all  \""free\""   they  should  have  the  same  priority  many  get  priority  level  testusingweightedtimecostproviderwithzerocostcalls  ignored  addresponsetime  getschedulerwithweightedtimecostprovider  assertequals  emptydetails  mockcall  scheduler  timeunit  few   since the calls are all \""free\""  they should have the same priority  many  getprioritylevel
__label__flaky get  connection  context  get  event  message  session  jms  messaging  utils  get  user  conf  get  status  create  session  get  topic  wf-app-name1  assert  =\'  job\'  test  workflow  job  selectors  and  ca  id1  =\'  failure\'  and  selector  wf  id1  workflow  job  jms  context  consumer  message  type  user1  get  message  type  init  receive  =\'  workflow_  job\'  and  print  stack  trace  e  get  message  destroy  pass  a  selector  using  and  condition  assert  equals  message  wf  event  listener  fail  on  workflow  job  event  jms  header  constants  wfe  create  consumer  wf  fail  message  session  getconnectioncontext  geteventmessage  session  jmsmessagingutils  getuser  conf  getstatus  createsession  gettopic  wf-app-name1  assert  =\'job\'  testworkflowjobselectorsand  caid1  =\'failure\' and   selector  wfid1  workflowjob  jmscontext  consumer  messagetype  user1  getmessagetype  init  receive  =\'workflow_job\' and   printstacktrace  e  getmessage  destroy   pass a selector using and condition  assertequals  message  wfeventlistener  fail  onworkflowjobevent  jmsheaderconstants  wfe  createconsumer  wffailmessage  session
__label__nflaky header  annotated  argument  should  be  passed  then  return  context  header  create  verify  invoke  value  when  param1  mock  controller  get  header  headerannotatedargumentshouldbepassed  thenreturn  context  header  create  verify  invoke  value  when  param1  mockcontroller  getheader
__label__flaky test  hard  lease  recovery  after  name  node  restart  hard  lease  recovery  restart  helper  testhardleaserecoveryafternamenoderestart  hardleaserecoveryrestarthelper
__label__nflaky hello_dep  array2  hello_dep  array1  and  test:  body  parser  engine  post  hello_dep1  get  validation  assert  false  equal  to  has  violations  invoke  when  dep  put  dep  list1  dep  list2  hello_dep  list1  hello_dep  list2  dep  array1  assert  not  null  test  object  get  context  dep  array2  dep  list  map  validation  then  return  some  setup  for  this  method:  test  body  parser  with  custom  needing  injection  param  parser  do  dep1  assert  that  size  mockito  get  parameters  dep  array  hello_deparray2  hello_deparray1   and test:  bodyparserenginepost  hello_dep1  getvalidation  assertfalse  equalto  hasviolations  invoke  when  dep  put  deplist1  deplist2  hello_deplist1  hello_deplist2  deparray1  assertnotnull  testobject  get  context  deparray2  deplist  map  validation  thenreturn   some setup for this method:  testbodyparserwithcustomneedinginjectionparamparser   do  dep1  assertthat  size  mockito  getparameters  deparray
__label__flaky job  conf  get  name  reader  auth  token  test  schema  assert  not  null  get  test  case  dir  /workflow.xml  get  file://  workflow.xml  test-wf  parse  def  app  init  set  wf-schema-valid.xml  destroy  assert  equals  services  wf-schema-invalid.xml  oozie  client  fail  io  utils  get  test  user  copy  char  stream  get  resource  as  reader  writer  wps  file  jobconf  getname  reader  authtoken  testschema  assertnotnull  gettestcasedir  /workflow.xml  get  file://  workflow.xml  test-wf  parsedef  app  init  set  wf-schema-valid.xml  destroy  assertequals  services  wf-schema-invalid.xml  oozieclient  fail  ioutils  gettestuser  copycharstream  getresourceasreader  writer  wps  file
__label__nflaky increment  and  get  content  type  test  consume  data  get  content  count  consume  assert  equals  completed  failed  byte  buffer  long  value  assert  array  equals  assert  stream  end  cancelled  stream  start  wrap  consumer  incrementandget  contenttype  testconsumedata  getcontent  count  consume  assertequals  completed  failed  bytebuffer  longvalue  assertarrayequals  assert  streamend  cancelled  streamstart  wrap  consumer
__label__flaky add  record  to  bundle  action  table  get  id  add  record  to  coord  action  table  bundle  job  coord  action3  coord  action4  children  assert  not  null  coord  action5  get  coordinator  action  get  the  next  3  (though  there\'s  only  2  more)  coord  action1  coord  action2  job  bundle  action4  get  app  name  bundle  action5  get  the  first  3  set  app  name  bundle  action1  bundle  action2  bundle  action3  add  record  to  bundle  job  table  assert  equals  execute  add  record  to  coord  job  table  coord  job2  check  children  services  coordinator  job  coord  job3  coord  job1  coord-action-get.xml  size  add  all  coord  job4  test  get  bundle  parent  too  many  coord  job5  jpa  service  addrecordtobundleactiontable  getid  addrecordtocoordactiontable  bundlejob  coordaction3  coordaction4  children  assertnotnull  coordaction5  get  coordinatoraction   get the next 3 (though there\'s only 2 more)  coordaction1  coordaction2  job  bundleaction4  getappname  bundleaction5   get the first 3  setappname  bundleaction1  bundleaction2  bundleaction3  addrecordtobundlejobtable  assertequals  execute  addrecordtocoordjobtable  coordjob2  checkchildren  services  coordinatorjob  coordjob3  coordjob1  coord-action-get.xml  size  addall  coordjob4  testgetbundleparenttoomany  coordjob5  jpaservice
__label__nflaky add  child  to  service  parent  init  add  sibling  service  stop  start  assert  in  state  state  test  add  started  child  in  init  child  addchildtoservice  parent  init  addsiblingservice  stop  start  assertinstate  state  testaddstartedchildininit  child
__label__flaky row_1  assert  equals  table  get  value  xml  check  value  xml  delete  row  test  delete  column_2  column_1  response  value_1  put  value  xml  delete  value  get  code  value_2  row_1  assertequals  table  getvaluexml  checkvaluexml  deleterow  testdelete  column_2  column_1  response  value_1  putvaluexml  deletevalue  getcode  value_2
__label__nflaky bad  conf  file:  bais  conf  conf  test  assert  equals  get  bytes  size  assert  true  check  conf  get  test  empty  input  errors  starts  with    bad conf file:   bais  conf  conftest  assertequals  getbytes  size  asserttrue  checkconf  get  testemptyinput  errors  startswith
__label__flaky no  of  millisecondsin  one  hour  lenient  date  bad  testing  for  the  number  of  coordinator  actions  in  a  date  range  that  spans  from  half  an  hour  prior  to  the  nominal  time  to  1  hour  after  the  nominal  time  get  coord  action  ids  from  dates  test  a  bad  scope.  like  date2  but  with  the  50th  day  of  the  month  date  utils  add  record  to  coord  action  table  no  of  actions  ^-*  t  coordinator  action  bad  date  50  t  bad  scope  coord  actions  in  date  range  accepted  bad  range  scope:  action  num  print  stack  trace  fail  coordinator  job  action  id1  test  coord  actions  in  date  range  size  nominal  time  milliseconds  format  date  oozie  tz  pass  job  test  inverted  start  and  end  dates.  accepted  lenient  date:  ::  test  a  lenient  date  get  time  accepted  inverted  dates:    start::  end  =  get  id  replace  all  accepted  badly  formatted  date:  get  error  code  0xbad5c09e  testing  for  the  number  of  coordinator  actions  in  a  date  range  that  spans  from  half  an  hour  after  the  nominal  time  to  1  hour  after  the  nominal  time  nominal  time  e  test  a  bad  date  format.  assert  equals  date2  get  nominal  time  date1  add  record  to  coord  job  table  coord-action-get.xml  to  string  error  code  noofmillisecondsinonehour  lenientdate  bad   testing for the number of coordinator actions in a date range that spans from half an hour prior to the nominal time to 1 hour after the nominal time  getcoordactionidsfromdates   test a bad scope.   like date2 but with the 50th day of the month  dateutils  addrecordtocoordactiontable  noofactions  ^-*t  coordinatoraction  baddate  50t  badscope  coordactionsindaterange  accepted bad range scope:   actionnum  printstacktrace  fail  coordinatorjob  actionid1  testcoordactionsindaterange  size  nominaltimemilliseconds  formatdateoozietz   pass  job   test inverted start and end dates.  accepted lenient date:   ::   test a lenient date  gettime  accepted inverted dates: start::end =   getid  replaceall  accepted badly formatted date:   geterrorcode  0xbad5c09e   testing for the number of coordinator actions in a date range that spans from half an hour after the nominal time to 1 hour after the nominal time  nominaltime  e   test a bad date format.  assertequals  date2  getnominaltime  date1  addrecordtocoordjobtable  coord-action-get.xml  tostring  errorcode
__label__nflaky get  bytes  transferred  test  coding  fragment  buffering  tiny  fragments3  codec  test  utils  channel  times  assert  flush  verify  more  stuff  dump  write  --  argument  matchers  standard  charsets  assert  equals  encoder  -  any  stuff------more  stuff  mockito  outbuf  metrics  spy  wrap  stuff  getbytestransferred  testcodingfragmentbufferingtinyfragments3  codectestutils  channel  times  assert  flush  verify  more stuff  dump  write  --  argumentmatchers  standardcharsets  assertequals  encoder  -  any  stuff------more stuff  mockito  outbuf  metrics  spy  wrap  stuff
__label__flaky cluster  setup  hosts  file  write  config  file  conf  heartbeat_  interval  wait  active  sleep  waiting  for  datanode  to  be  marked  dead  get  path  client  test  hosts  file  num  datanodes  refresh  nodes  info  add  dfs  config  keys  hosts  file  set  get  dfs  client  datanode  report  log  invalidhost  test  for  a  single  namenode  cluster  to  uri  number  of  live  nodes  should  be  0  j  assert  equals  num  name  nodes  list  get  name  node  thread  build  num  data  nodes  from  talking  to  namenode   resulting  in  it\'s  shutdown.  get  namesystem  datanode  report  type  cluster  setuphostsfile  writeconfigfile  conf  heartbeat_interval  waitactive  sleep  waiting for datanode to be marked dead  getpath  client  testhostsfile  numdatanodes  refreshnodes  info  add  dfsconfigkeys  hostsfile  set  getdfsclient  datanodereport  log  invalidhost   test for a single namenode cluster  touri  number of live nodes should be 0  j  assertequals  numnamenodes  list  getnamenode  thread  build  numdatanodes   from talking to namenode  resulting in it\'s shutdown.  getnamesystem  datanodereporttype
__label__nflaky *  java  8  examples  go  below  this  line.  intercept  assert  not  null  expected  assert  exception  contains  test  intercept  failure  ioe       * java 8 examples go below this line.       intercept  assertnotnull  expected  assertexceptioncontains  testinterceptfailure  ioe
__label__flaky test/hadoop  assert  false  f  sys  test  dir  create  file  test/hadoop/file/subdir  fail  assert  test/hadoop/file  assert  true  mkdirs  should  throw  io  exception.  exists  test  deep  sub  dir  test/hadoop/file/deep/sub/dir  get  test  root  path  test  mkdirs  fails  for  subdirectory  of  existing  file  test  sub  dir  test/hadoop  assertfalse  fsys  testdir  createfile  test/hadoop/file/subdir  fail  assert  test/hadoop/file  asserttrue  mkdirs  should throw ioexception.  exists  testdeepsubdir  test/hadoop/file/deep/sub/dir  gettestrootpath  testmkdirsfailsforsubdirectoryofexistingfile  testsubdir
__label__nflaky assert  correct  image2string  test  decode  row2string13  (01)90012345678908(3922)795  13.png  assertcorrectimage2string  testdecoderow2string13  (01)90012345678908(3922)795  13.png
__label__flaky cron  interval  get  start  tolerance  start  assert  equals  get  end  system  thread  sleep  stop  real  own  delay  current  time  millis  now  get  own  get  total  test  cron  real  total  delay  cron    interval  getstart  tolerance  start  assertequals  getend  system  thread  sleep  stop  realowndelay  currenttimemillis  now  getown  gettotal  testcron  realtotaldelay
__label__nflaky let  half  the  threads  continue  with  more  metrics  and  let  half  die  op  total  time  seed  the  totals  are  as  expected  second  snapshots  finished  run  snapshot  to  complete;  else  their  metrics  may  be  lost  to  gc  sleep  total  await  snapshot  mutable  rates  with  aggregation  count  down  initialize  so  that  the  get  long  counter()  method  doesn\'t  complain  t  idx  first  adds  finished  info  add  test  mutable  rates  with  aggregation  many  threads  log  rates  start  threads  random  seed  =  assert  equals  next  int  sleep  so  additions  can  be  interleaved  with  snapshots  next  long  count  n  thread  op  count  /  op  total  time  thread  idx  t  metric  op  count  add  metrics  correctly  and  that  snapshot  occurs  correctly  sleep  random  first  snapshots  finished  second  adds  finished   let half the threads continue with more metrics and let half die  optotaltime  seed   the totals are as expected  secondsnapshotsfinished  run   snapshot to complete; else their metrics may be lost to gc  sleep   total  await  snapshotmutablerateswithaggregation  countdown   initialize so that the getlongcounter() method doesn\'t complain  tidx  firstaddsfinished  info  add  testmutablerateswithaggregationmanythreads  log  rates  start  threads  random seed =   assertequals  nextint   sleep so additions can be interleaved with snapshots  nextlong   count  n  thread   opcount / optotaltime  threadidx  t  metric  opcount   add metrics correctly and that snapshot occurs correctly  sleeprandom  firstsnapshotsfinished  secondaddsfinished
__label__flaky resume  end_  points  rest  constants  is_  security_  enabled  get  context  url  oozie  url  mock  dag  engine  service  conf  assert  equals  wc  test  resume  call  oozie  client  1  set  property  create  configuration  servlet_  classes  run  test  resume  end_points  restconstants  is_security_enabled  getcontexturl  oozieurl  mockdagengineservice  conf  assertequals  wc  testresume  call  oozieclient  1  setproperty  createconfiguration  servlet_classes  runtest
__label__nflaky set  native  zlib  loaded  zlib  factory  don\'t  use  native  libs  test  gzip  codec  write  java  test  gzip  codec  write  setnativezlibloaded  zlibfactory   don\'t use native libs  testgzipcodecwritejava  testgzipcodecwrite
__label__flaky now  delete  all...  then  test  i  can  add  stuff  back  get  name  serverinfo  reference_  a  reference_  b  assert  some  things:  table_name  delete  put  table  name  result  sleep  bytes  fam  delete  columns  ok  now  delete  a  split:  get  row  info  add  add  column  test  delete_mixed  assert  that  after  a  delete   i  can  put.  method  print  stack  trace  e  to  bytes  add  some  data:  assert  equals  ip_address  families  init  h  region  thread  split  b  testtable  size  column  names  region  split  a   now delete all... then test i can add stuff back  getname  serverinfo  reference_a  reference_b   assert some things:  table_name  delete  put  tablename  result  sleep  bytes  fam  deletecolumns   ok now delete a split:  get  row  info  add  addcolumn  testdelete_mixed   assert that after a delete  i can put.  method  printstacktrace  e  tobytes   add some data:  assertequals  ip_address  families  inithregion  thread  splitb  testtable  size   column names  region  splita
__label__nflaky cancel  is  cancelled  assert  false  core  matchers  is  assert  that  dependency2  test  cancelled  dependency1  is  done  assert  future  set  dependency  cancel  iscancelled  assertfalse  corematchers  is  assertthat  dependency2  testcancelled  dependency1  isdone  assert  future  setdependency
__label__flaky play  server  add  header  get  sequence  number  take  request  same  connection  redirect  and  reuse  set  socket  policy  assert  content  assert  equals  set  response  code  set  body  location:  /foo  /  enqueue  get  url  shutdown_  input_  at_  end  this  is  the  new  page!  http  url  connection  client  open  play  server  addheader  getsequencenumber  takerequest  sameconnectionredirectandreuse  setsocketpolicy  assertcontent  assertequals  setresponsecode  setbody  location: /foo  /  enqueue  geturl  shutdown_input_at_end  this is the new page!  httpurlconnection  client  open
__label__nflaky get  resource  hdfs7067.keystore  other  non-  hadoop  method  get  current  key  should  have  thrown  an  exception  getting  testkey5@0  should  have  thrown  an  exception  getting  testkey2  conf  keystore  dir  absolute  path  key  version  wrong  key  name  format  our  url  should  have  thrown  an  exception  no  version  in  key  path  no  version  in  key  path  testkey2/  provider  get  sanity  check  that  we  are  using  the  right  keystore  get  path  org.apache.hadoop.crypto.key.  java  key  store  provider$  key  metadata  java  key  store  provider  test  jks  provider  with  keytool  keys  ://file@/  get  key  version  key  version  current  key  not  really  set  e  key  version  current  key  not  wrong  key  name  format  get  providers  testkey5@0  generic  test  utils  testkey2  fail  key  version  assert  exception  contains  unused  key  provider  factory  getresource  hdfs7067.keystore  other non-hadoop method  getcurrentkey  should have thrown an exception getting testkey5@0  should have thrown an exception getting testkey2  conf  keystoredirabsolutepath  keyversionwrongkeynameformat  oururl  should have thrown an exception  no version in key path   no version in key path testkey2/  provider  get   sanity check that we are using the right keystore  getpath   org.apache.hadoop.crypto.key.javakeystoreprovider$keymetadata  javakeystoreprovider  testjksproviderwithkeytoolkeys  ://file@/  getkeyversion  keyversioncurrentkeynotreally  set  e  keyversioncurrentkeynotwrongkeynameformat  getproviders  testkey5@0  generictestutils  testkey2  fail  keyversion  assertexceptioncontains  unused  keyproviderfactory
__label__flaky /scripts/myscript.sh  job  conf  lib  reader  auth  token  ref2  f1  ref1  f2  /lib/reduceutil.so  test  createproto  conf  create  proto  action  conf  assert  proto  conf  assert  true  get  test  case  dir  /workflow.xml  get  file://  create  test  case  sub  dir  workflow.xml  bla  bla  scripts  write  close  /lib/maputil.jar  init  set  wf-schema-valid.xml  workflow  app  service  destroy  assert  equals  services  get  strings  services  oozie  client  io  utils  get  test  user  copy  char  stream  equals  get  resource  as  reader  writer  wps  file  /scripts/myscript.sh  jobconf  lib  reader  authtoken  ref2  f1  ref1  f2  /lib/reduceutil.so  testcreateprotoconf  createprotoactionconf  assert  protoconf  asserttrue  gettestcasedir  /workflow.xml  get  file://  createtestcasesubdir  workflow.xml  bla bla  scripts  write  close  /lib/maputil.jar  init  set  wf-schema-valid.xml  workflowappservice  destroy  assertequals  services  getstrings  services  oozieclient  ioutils  gettestuser  copycharstream  equals  getresourceasreader  writer  wps  file
__label__nflaky wait  await  run  state  assert  false  listener  get  waiter  execute  retries  short_  delay  test  start  stop  stop  is  closed  is  running  assert  true  executor  assert  not  null  runner  delay  wait  awaitrunstate  assertfalse  listener  getwaiter  execute  retries  short_delay  teststartstop  stop  isclosed  isrunning  asserttrue  executor  assertnotnull  runner  delay
__label__flaky init  set  sla  service  get  conf  assert  false  test  basic  service  destroy  conf  services  services  assert  true  assert  not  null  get  is  enabled  slas    init  set  slaservice  getconf  assertfalse  testbasicservice  destroy  conf  services  services  asserttrue  assertnotnull  get  isenabled  slas
__label__nflaky p1  p2  p3  p4  get  kms  url  provider  p4  should  have  answered  the  request.  conf  when  test  client  retries  with  timeouts  exception  times  verify  then  throw  kp  any  string  then  return  create  key  eq  any  set  int  common  configuration  keys  public  fail  test3  mockito  mock  v1  p1  p2  p3  p4  getkmsurl  provider p4 should have answered the request.  conf  when  testclientretrieswithtimeoutsexception  times  verify  thenthrow  kp  anystring  thenreturn  createkey  eq  any  setint  commonconfigurationkeyspublic  fail  test3  mockito  mock  v1
__label__flaky script  executor  entity  with  static  column/insert_single_row.cql  session  given  select  static_col  from  entitywithstaticcolumn  where  id  =  eq  uui  ds  uuid  delete  static  when  of  static  col  where  id  static_col  execute  script  template  is  not  null  actual  random  utils  manager  one  time  based  next  long  assert  that  execute  immutable  map  is  true  should_dsl_delete_static  then  is  null  long  from  base  table  dsl  scriptexecutor  entitywithstaticcolumn/insert_single_row.cql  session   given  select static_col from entitywithstaticcolumn where id =   eq  uuids  uuid  deletestatic   when  of  staticcol  where  id  static_col  executescripttemplate  isnotnull  actual  randomutils  manager  one  timebased  nextlong  assertthat  execute  immutablemap  istrue  should_dsl_delete_static   then  isnull  long  frombasetable  dsl
__label__nflaky get  class  get  controller  class  ninja  constant  bootstrap  when  instance  of  ninja  mode  router  ninja  properties  impl  get  get  route  for  boot  conf.  routes  initialized  properly.  we  get  back  the  class  we  defined  by  the  route.  ninja  boostrap  process  picks  up  user  supplied  conf.  ninja  definition  then  return  get  injector  is  assert  that  /  route  mockito  get  com.example  get  instance  test  initialize  with  all  user  specified  things  in  shifted  conf  directory  spy  ninja  boostrap  process  picks  up  user  supplied  guice  module  in  conf.  module  getclass  getcontrollerclass  ninjaconstant  bootstrap  when  instanceof  ninjamode  router  ninjapropertiesimpl  get  getroutefor  boot  conf.routes initialized properly. we get back the class we defined by the route.  ninja boostrap process picks up user supplied conf.ninja definition  thenreturn  getinjector  is  assertthat  /  route  mockito  get  com.example  getinstance  testinitializewithalluserspecifiedthingsinshiftedconfdirectory  spy  ninja boostrap process picks up user supplied guice module in conf.module
__label__flaky play  window  update  stream  ids  data  read  sends  window  update  header  entries  math  send  frames  summing  to  window  update  threshold.  type_  headers  connection  buffer  connection  window  update  banana  add  read  connection  in  count  max  frame  size  sent  stream  window  update  contains  syn_  stream  size  get  source  syn  stream  stream  new  stream  android  type_  window_  update  accept  frame  min  stream  assert  true  peer  default_  initial_  window_  size  get  response  headers  take  frame  window  update  threshold  a  window  update  b  syn  reply  set  variant  and  client  assert  equals  j  send  frame  spdy3  play  it  back.  play  windowupdatestreamids  data  readsendswindowupdate  headerentries  math   send frames summing to windowupdatethreshold.  type_headers  connection  buffer   connection window update  banana  add  read   connection  in  count  maxframesize  sent   stream window update  contains   syn_stream  size  getsource  synstream   stream  newstream  android  type_window_update  acceptframe  min  stream  asserttrue  peer  default_initial_window_size  getresponseheaders  takeframe  windowupdatethreshold  a  windowupdate  b  synreply  setvariantandclient  assertequals  j  sendframe  spdy3   play it back.
__label__nflaky first  valid  input  num  inputs  allocate  put  int  array  coder  util  inputs  find  first  valid  input  assert  equals  byte  buffer  test  find  first  valid  input  firstvalidinput  numinputs  allocate  putint  array  coderutil  inputs  findfirstvalidinput  assertequals  bytebuffer  testfindfirstvalidinput
__label__flaky jms  topic  service  bab  add  record  to  bundle  action  table  =bundle  cab  =coord   add  record  to  wf  action  table  get  id  workflow  instance  get  topic  add  record  to  coord  action  table  setup  services  for  topic  coord  coord-action-for-action-input-check.xml  add  record  to  wf  job  table  get  test  topic  as  fixed  string  coordinator  action  wab  cjb  bjb  workflow  job  job  bundle  init  set  get  bundle  action  id  print  stack  trace  get  conf  workflow  e  =workflow   add  record  to  bundle  job  table  get  message  destroy  jms  topic  service  assert  equals  services  add  record  to  coord  job  table  fail  get  value  services  1  coordinator  job  workflow  action  wfj  jmstopicservice  bab  addrecordtobundleactiontable  =bundle  cab  =coord   addrecordtowfactiontable  getid  workflowinstance  gettopic  addrecordtocoordactiontable  setupservicesfortopic  coord  coord-action-for-action-input-check.xml  addrecordtowfjobtable  get  testtopicasfixedstring  coordinatoraction  wab  cjb  bjb  workflowjob  job  bundle  init  set  getbundleactionid  printstacktrace  getconf  workflow  e   =workflow   addrecordtobundlejobtable  getmessage  destroy  jmstopicservice  assertequals  services  addrecordtocoordjobtable  fail  getvalue  services  1  coordinatorjob  workflowaction  wfj
__label__nflaky decrypt  it  manually  get  encrypted  key  version  manual  material  get  name  decrypted  key  aes/  ctr/  no  padding  derive  iv  eek  encryption  key  key  provider  crypto  extension  do  final  assert  array  equals  create  for  decryption  test  encrypt  decrypt  encrypted  key  version  decrypt  encrypted  key  get  encrypted  key  iv  encrypted  key  iv  cipher  generate  encrypted  key  init  get  encryption  key  name  encrypted  key  material  eek2  test  the  create  for  decryption  factory  method  api  material  wrong  key  material  from  decrypt  encrypted  key  get  an  eek  kp  ext  aes  get  material  cipher  get  instance  get  encryption  key  version  name  decrypt  it  with  the  api   decrypt it manually  getencryptedkeyversion  manualmaterial  getname  decryptedkey  aes/ctr/nopadding  deriveiv  eek  encryptionkey  keyprovidercryptoextension  dofinal  assertarrayequals  createfordecryption  testencryptdecrypt  encryptedkeyversion  decryptencryptedkey  getencryptedkeyiv  encryptedkeyiv  cipher  generateencryptedkey  init  getencryptionkeyname  encryptedkeymaterial  eek2   test the createfordecryption factory method  apimaterial  wrong key material from decryptencryptedkey   get an eek  kpext  aes  getmaterial  cipher  getinstance  getencryptionkeyversionname   decrypt it with the api
__label__flaky date  script  executor  session  given  update  simple  eq  select  simpleset  from  simple  where  id  =  simpleset  should_dsl_update_set_add  all  contains  exactly  sets  when  of  where  id  row  simple  set_  add  all  to  table  execute  script  template  random  utils  manager  get  set  one  next  long  assert  that  execute  simple  entity/insert_single_row.cql  immutable  map  simple  set  new  hash  set  then  long  build  date  key  from  base  table  dsl  date  scriptexecutor  session   given  update  simple  eq  select simpleset from simple where id =   simpleset  should_dsl_update_set_addall  containsexactly  sets   when  of  where  id  row  simpleset_addallto  table  executescripttemplate  randomutils  manager  getset  one  nextlong  assertthat  execute  simpleentity/insert_single_row.cql  immutablemap  simpleset  newhashset   then  long  builddatekey  frombasetable  dsl
__label__nflaky then  return  enum  csv  param  single  should  be  parsed  invoke  when  param1  red  enum  csv  param  rainbow  context  create  verify  mock  controller  get  parameter  thenreturn  enumcsvparamsingleshouldbeparsed  invoke  when  param1  red  enumcsvparam  rainbow  context  create  verify  mockcontroller  getparameter
__label__flaky _test  get  recovery  actions  group  by  job  id  _test  get  action  _test  get  action  for  job  -  test  coordinator  store-  c  _test  get  action  for  job  in  exec  order  get  time  test  coord  store  _test  insert  action  _test  update  coord  action  min  _test  update  coord  action  job  id  _1  _test  get  job  _test  update  coord  job  _test  get  mat  job  lists  _test  get  action  running  count  _test  get  action  for  job  in  last  only  action  id  00000-  _test  insert  job  _testgetrecoveryactionsgroupbyjobid  _testgetaction  _testgetactionforjob  -testcoordinatorstore-c  _testgetactionforjobinexecorder  gettime  testcoordstore  _testinsertaction  _testupdatecoordactionmin  _testupdatecoordaction  jobid  _1  _testgetjob  _testupdatecoordjob  _testgetmatjoblists  _testgetactionrunningcount  _testgetactionforjobinlastonly  actionid  00000-  _testinsertjob
__label__nflaky init  data  written  size  create  file  du  size  thread  sleep  du  file  test  du  get  used  invalid  on-disk  size  assert  true  slack  writing  32  k  that  may  store  additional  file  metadata  (eg  ext  attrs).  test  without  launching  thread  du_  dir  let  the  metadata  updater  catch  up  close  test  with  0  interval   will  not  launch  thread  init  data  writtensize  createfile  dusize  thread  sleep  du  file  testdu  getused  invalid on-disk size  asserttrue  slack   writing 32k   that may store additional file metadata (eg ext attrs).   test without launching thread  du_dir   let the metadata updater catch up  close   test with 0 interval  will not launch thread
__label__flaky headers  get  server  address  from  the  index  screen:  upload  ninja  test  browser  new  hash  map  please  specify  file  to  upload:  test  html  escaping  in  teamplate  works  make  request  some  empty  headers  for  now...  result  contains  maps  /redirect  will  send  a  location:  redirect  in  the  headers  assert  true  headers  getserveraddress   from the index screen:  upload  ninjatestbrowser  newhashmap  please specify file to upload:  testhtmlescapinginteamplateworks  makerequest   some empty headers for now...  result  contains  maps   /redirect will send a location: redirect in the headers  asserttrue
__label__nflaky some  nada  foo  ms  info  .  num  active  sources=foo.  num  active  sinks=bar.  num  all  sinks=haa  haa  none  test  tags  for  prefix  .sink.ganglia  sb  bar  record  host  num  active  sinks   cb  add  all  init  set  append  prefix  sink  .sink.ganglia.tags  for  prefix.none  *  assert  equals  .sink.ganglia.tags  for  prefix.some  tags  test  name  prefix  .sink.ganglia.tags  for  prefix.all  to  string  num  active  sources  metrics  .  num  active  sources=foo.  num  active  sinks=bar  subset    some  nada  foo  msinfo  .numactivesources=foo.numactivesinks=bar.numallsinks=haa  haa  none  testtagsforprefix  .sink.ganglia  sb  bar  record  host  numactivesinks    cb  add  all  init  set  appendprefix  sink  .sink.ganglia.tagsforprefix.none  *  assertequals  .sink.ganglia.tagsforprefix.some  tags  testnameprefix  .sink.ganglia.tagsforprefix.all  tostring  numactivesources  metrics  .numactivesources=foo.numactivesinks=bar  subset
__label__flaky get  id  assert  equals  get  status  execute  add  record  to  coord  job  table  call  coordinator  job  services  coord  job  get  cmd  assert  not  null  get  test  coord  suspend  with  error  postive2  job  jpa  service  getid  assertequals  getstatus  execute  addrecordtocoordjobtable  call  coordinatorjob  services  coordjobgetcmd  assertnotnull  get  testcoordsuspendwitherrorpostive2  job  jpaservice
__label__nflaky test  conf  based  and  api  based  set  u  mask  explicit  set  u  mask  is  done.  file://mydfs:50070/  conf  umask  for  fc2  is  incorrect  umask  for  fc1  is  incorrect  011  077  fc2  default  u  mask  changed!  fc1  get  defaultl  u  mask  fs  permission  set  common  configuration  keys  get  file  context  assert  equals  022  uri2  066  uri1  file://tmp  get  u  mask  configuration  should  be  reflected..  create  immutable  file  context  to  short  set  u  mask  testconfbasedandapibasedsetumask   explicit setumask is done.  file://mydfs:50070/  conf  umask for fc2 is incorrect  umask for fc1 is incorrect  011  077  fc2  default umask changed!  fc1  get  defaultlumask  fspermission  set  commonconfigurationkeys  getfilecontext  assertequals  022  uri2  066  uri1  file://tmp  getumask   configuration should be reflected..  createimmutable  filecontext  toshort  setumask
__label__flaky end_  points  is_  security_  enabled  submit  oozie  url  run  conf  app  path  -submit  assert  not  null  get  -config  create  workflow.xml  create  properties  file  with  trailing  spaces  test  properties  with  trailing  spaces  servlet_  classes  close  conf  str  run  test  app  get  context  url  get  conf  mock  dag  engine  service  assert  equals  get  file  system  args  call  oozie  client  node  -oozie  mkdirs  reset  to  string  job  get  fs  test  case  dir  end_points  is_security_enabled  submit  oozieurl  run  conf  apppath  -submit  assertnotnull  get  -config  create  workflow.xml  createpropertiesfilewithtrailingspaces  testpropertieswithtrailingspaces  servlet_classes  close  confstr  runtest  app  getcontexturl  getconf  mockdagengineservice  assertequals  getfilesystem  args  call  oozieclient  node  -oozie  mkdirs  reset  tostring  job  getfstestcasedir
__label__nflaky assert  home  resolve  failed  e_  is_  relative  ./target  test  hadoop  home  relative  asserthomeresolvefailed  e_is_relative  ./target  testhadoophomerelative
__label__flaky 2009-02-02  t23:59  z  get  id  run  date  utils  workflow  instance  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  job  sleep  wf  job  add  record  to  wf  job  table  assert  not  null  get  coordinator  action  end  test  coord  action  recovery  service  for  killed  workflow  job  recovery  runnable  wait  for  ret  running  wf  get  cmd  2009-02-01  t01:00  z  start  assert  equals  execute  add  record  to  coord  job  table  coordinator  job  services  wf  job  id  coord-action-get.xml  jpa  service  evaluate  2009-02-02t23:59z  getid  run  dateutils  workflowinstance  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordjob  sleep  wfjob  addrecordtowfjobtable  assertnotnull  get  coordinatoraction  end  testcoordactionrecoveryserviceforkilled  workflowjob  recoveryrunnable  waitfor  ret  running  wfgetcmd  2009-02-01t01:00z  start  assertequals  execute  addrecordtocoordjobtable  coordinatorjob  services  wfjobid  coord-action-get.xml  jpaservice  evaluate
__label__nflaky conn  arg  that  in  stream  response  captor  send  response  header  when  set  entity  receive  request  header  assert  assert  not  null  context  create  boolean  get  code  test  execution  entity  enclosing  request  http  status  then  return  argument  matchers  capture  method  eq  matches  /  never  response  factory  new  http  response  mock  conn  reuse  strategy  request  get  request  httpservice  flush  for  class  verify  close  process  keep  alive  argument  captor  assert  equals  send  response  entity  assert  same  get  entity  error  response  get  value  mockito  response  http  core  context  httprocessor  handle  request  entity  conn  argthat  instream  responsecaptor  sendresponseheader  when  setentity  receiverequestheader  assert  assertnotnull  context  create  boolean  getcode  testexecutionentityenclosingrequest  httpstatus  thenreturn  argumentmatchers  capture  method  eq  matches  /  never  responsefactory  newhttpresponse  mock  connreusestrategy  request  getrequest  httpservice  flush  forclass  verify  close  process  keepalive  argumentcaptor  assertequals  sendresponseentity  assertsame  getentity  errorresponse  getvalue  mockito  response  httpcorecontext  httprocessor  handlerequest  entity
__label__flaky next  get  block  locations  stat  is  file  assert  false  file1  get  default  has  next  assert  equals  file_  len  test  file  util  assert  true  get  len  make  qualified  get  path  fs  permission  fc  mkdir  write  file  list  files  test_  dir  itor  next  getblocklocations  stat  isfile  assertfalse  file1  getdefault  hasnext  assertequals  file_len  testfile  util  asserttrue  getlen  makequalified  getpath  fspermission  fc  mkdir  writefile  listfiles  test_dir  itor
__label__nflaky check  initial  position  check  a  seek  +  read  ostream  foo  tell  conf  dir  fs  delete  seek  check  a  read  from  that  position.  file  system  create  test  afs  input  write  close  create  the  stream  read  file  path  get  file  context  length  assert  equals  get  input  path  0123456789  buf  avro  fs  in  get  local  mkdirs  w  exists  fc  file  context   check initial position   check a seek + read  ostream  foo  tell  conf  dir  fs  delete  seek   check a read from that position.  filesystem  create  testafsinput  write  close   create the stream  read  filepath  getfilecontext  length  assertequals  getinputpath  0123456789  buf  avrofsin  getlocal  mkdirs  w  exists  fc  filecontext
__label__flaky server  proxy  users  test  protocol  rpc  test  real  user  setup  get  proxy  superuser  group  conf  key  configure  super  user  ip  addresses  get  proxy  a  method  group_  names  via  conf  run  ret  val  assert  set  strings  real_  user_  short_  name  refresh  conf  stop  proxy  addr  user  group  information  get  server  ret  proxy  user  ugi  print  stack  trace  e  start  assert  equals  create  remote  user  group1  get  connect  address  real_  user_  name  fail  proxy  do  as  net  utils  stop  address  proxy_  user_  name  real  user  ugi  create  proxy  user  for  testing  server  proxyusers  testprotocol  rpc  testrealusersetup  getproxysuperusergroupconfkey  configuresuperuseripaddresses  getproxy  amethod  group_names   via   conf  run  retval  assert  setstrings  real_user_short_name  refreshconf  stopproxy  addr  usergroupinformation  getserver  ret  proxyuserugi  printstacktrace  e  start  assertequals  createremoteuser  group1  getconnectaddress  real_user_name  fail  proxy  doas  netutils  stop  address  proxy_user_name  realuserugi  createproxyuserfortesting
__label__nflaky proxy  users  refresh  super  user  groups  configuration  get  proxy  superuser  group  conf  key  assert  authorized  test  netgroups  default  impersonation  provider  test  proxy  users  group  mapping  conf  system  as  list  proxy_  ip  netgroup_  names  string  utils  groups  get  user  to  groups  mapping  service  to  array  not  testing  netgroups   join  try  proxying  a  group  that\'s  allowed  get  groups  info  user  group  information  get  property  set  proxy  user  ugi  group  mapping  class  (must  implement  group  mapping  service  provider  log  interface  and  support  netgroups)  groups  not  testing  netgroups   no  group  mapping  class  specified      create  remote  user  native  code  loader  is  native  code  loaded  this  test  only  runs  when  native  code  is  compiled  real_  user_  name  common  configuration  keys  public  use  -  d  test  proxy  users  group  mapping=$class  name  to  specify  get  test  provider  size  group  mapping  class  name  arrays  get  proxy  superuser  ip  conf  key  proxy_  user_  name  testing  netgroups  using:  real  user  ugi  create  proxy  user  for  testing  proxyusers  refreshsuperusergroupsconfiguration  getproxysuperusergroupconfkey  assertauthorized  testnetgroups  defaultimpersonationprovider  testproxyusersgroupmapping  conf  system  aslist  proxy_ip  netgroup_names  stringutils  groups  getusertogroupsmappingservice  toarray  not testing netgroups    join   try proxying a group that\'s allowed  getgroups  info  usergroupinformation  getproperty  set  proxyuserugi  group mapping class (must implement groupmappingserviceprovider   log  interface and support netgroups)  groups  not testing netgroups  no group mapping class specified       createremoteuser  nativecodeloader  isnativecodeloaded  this test only runs when native code is compiled  real_user_name  commonconfigurationkeyspublic  use -dtestproxyusersgroupmapping=$classname to specify   gettestprovider  size  groupmappingclassname  arrays  getproxysuperuseripconfkey  proxy_user_name  testing netgroups using:   realuserugi  createproxyuserfortesting
__label__flaky action  dir  test  do  operations  with  valid  xml  </prepare>  delete  the  file  if  it  is  already  there  do  operations  conf  get  file  system  fs  delete  create  job  conf  launcher  mapper  assert  true  new  dir  <prepare>  <mkdir  path=\'  \'/>  prepare  xml  exists  test  to  check  if  prepare  action  is  performed  as  expected  when  the  prepare  xml  block  is  a  valid  one  setup  launcher  uri  handler  conf  prepare  actions  driver  get  fs  test  case  dir  actiondir  testdooperationswithvalidxml  </prepare>   delete the file if it is already there  dooperations  conf  getfilesystem  fs  delete  createjobconf  launchermapper  asserttrue  newdir  <prepare>  <mkdir path=\'  \'/>  preparexml  exists   test to check if prepare action is performed as expected when the prepare xml block is a valid one  setuplauncherurihandlerconf  prepareactionsdriver  getfstestcasedir
__label__nflaky /assets/css/app.css  /assets/javascripts/main.js  /  john/photos/2201  build  route  assert  false  john  /assets/{file:  .*}  robots.txt  file  assert  true  2201  get  javascripts/main.js  id  map  john/photos/first  /assets/robots.txt  entry  set  get  path  parameters  encoded  assert  equals  matches  regex  expressions...  path  under  test  ninja  base  directory  resolver  /{name:  .+}/photos/{id:  0-9+}  multiple  parameter  parsing  with  regex  expressions  route  size  css/app.css  basic  placeholers  parameters  and  regex  inside  variable  parts  get  name  route  builder  ninja  properties  /assets/css/app.css  /assets/javascripts/main.js  /john/photos/2201  buildroute  assertfalse  john  /assets/{file: .*}  robots.txt  file  asserttrue  2201  get  javascripts/main.js  id  map  john/photos/first  /assets/robots.txt  entryset  getpathparametersencoded  assertequals  matches   regex expressions...  pathundertest  ninjabasedirectoryresolver  /{name: .+}/photos/{id: 0-9+}   multiple parameter parsing with regex expressions  route  size  css/app.css  basicplaceholersparametersandregexinsidevariableparts  get  name  routebuilder  ninjaproperties
__label__flaky test  jobs  status  end_  points  is_  security_  enabled  -jobtype  oozie  url  run  -localtime  coord  name=x  servlet_  classes  -len  run  test  -timezone  rest  constants  get  context  url  -filter  jobs  mock  dag  engine  service  assert  equals  -offset  args  pst  call  2  3  -oozie  status=  failed  testjobsstatus  end_points  is_security_enabled  -jobtype  oozieurl  run  -localtime  coord  name=x  servlet_classes  -len  runtest  -timezone  restconstants  getcontexturl  -filter  jobs  mockdagengineservice  assertequals  -offset  args  pst  call  2  3  -oozie  status=failed
__label__nflaky get  forbidden  result  then  return  session  foo  ninja  constant  when  filter  chain  test  authenticity  fail  get  authenticity  token  filter  bar  ninja  default  mockito  context  verify  get  session  get  parameter  getforbiddenresult  thenreturn  session  foo  ninjaconstant  when  filterchain  testauthenticityfail  getauthenticitytoken  filter  bar  ninjadefault  mockito  context  verify  getsession  getparameter
__label__flaky select  child_value  from  entity_child  where  id  =  child_value  set  script  executor  session  given  update  simple  eq  should_dsl_update_child_value  when  of  where  id  entity  as  child/insert_single_row.cql  row  table  another  value  execute  script  template  is  not  null  random  utils  manager  one  get  string  next  long  assert  that  another_child_val  execute  immutable  map  then  long  from  base  table  dsl  is  equal  to  select child_value from entity_child where id =   child_value  set  scriptexecutor  session   given  update  simple  eq  should_dsl_update_child_value   when  of  where  id  entityaschild/insert_single_row.cql  row  table  anothervalue  executescripttemplate  isnotnull  randomutils  manager  one  getstring  nextlong  assertthat  another_child_val  execute  immutablemap   then  long  frombasetable  dsl  isequalto
__label__nflaky 00  reader  conf  write  the  file  fs  delete  cleanup  with  logger  system  assert  true  file  system  value  close  false  positives:  test_  dir  key  check  false  positives  rate  set  log  assert  equals  deprecation  false  neg  set  int  false  negatives:  test  membership  test  io.mapfile.bloom.size  io  utils  false  pos  get  local  make  qualified  qualified  dir  name  exists  to  string  writer  probably  has  key  append  00  reader  conf   write the file  fs  delete  cleanupwithlogger  system  asserttrue  filesystem  value  close  false positives:   test_dir  key   check false positives rate  set  log  assertequals  deprecation  falseneg  setint  false negatives:   testmembershiptest  io.mapfile.bloom.size  ioutils  falsepos  getlocal  makequalified  qualifieddirname  exists  tostring  writer  probablyhaskey  append
__label__flaky test  jobs  status  filter  end_  points  is_  security_  enabled  get  context  url  oozie  url  get  jobs  info  group=x  name=  wc  user=x  call  fail  x=x  status=  x  status=  running  name=x  name=x;name=y  servlet_  classes  run  test  testjobsstatusfilter  end_points  is_security_enabled  getcontexturl  oozieurl  getjobsinfo  group=x  name=  wc  user=x  call  fail  x=x  status=x  status=running  name=x  name=x;name=y  servlet_classes  runtest
__label__nflaky should  log  bar  test  named  loggers  without  specified  primary  helper  assert  true  foo  record  assert  false  log_  period  shouldlog  bar  testnamedloggerswithoutspecifiedprimary  helper  asserttrue  foo  record  assertfalse  log_period
__label__flaky x-  timestamp  get  location  get  a  cell  get  name  set  batch  x-  column  delete  put  test  simple  scanner  binary  table  new  scanner  bytes  /scanner  mimetype_  binary  assert  true  assert  not  null  get  client  model  get  code  found  timestamp  header  add  column  scanner  uri  found  row  header  get  headers  get  body  to  bytes  found  column  header  x-  row  assert  equals  delete  the  scanner  /  verify  that  data  was  returned  mimetype_  protobuf  column_1  response  create  protobuf  output  equals  header  verify  that  the  expected  x-headers  are  present  x-timestamp  getlocation   get a cell  getname  setbatch  x-column  delete  put  testsimplescannerbinary  table   new scanner  bytes  /scanner  mimetype_binary  asserttrue  assertnotnull  get  client  model  getcode  foundtimestampheader  addcolumn  scanneruri  foundrowheader  getheaders  getbody  tobytes  foundcolumnheader  x-row  assertequals   delete the scanner  /   verify that data was returned  mimetype_protobuf  column_1  response  createprotobufoutput  equals  header   verify that the expected x-headers are present
__label__nflaky a  check  consistency  in  get  of  old  and  new  keys  b  file  resource1  c  d  conf  test  deprecation  the  corresponding  new  keys.  config2  m  append  property  n  out  config  p  q  set  new  keys  to  different  values  add  deprecation  to  configuration  r  load  an  old  key  and  a  new  key.  add  resource  get  load  an  old  key  with  multiple  new-key  mappings  x  y  z  set  old  key  and  then  get  new  key(s).  a  b  c  set  d  end  config  start  config  assert  equals  load  the  old/new  keys  corresponding  to  the  keys  loaded  before.  m  n  p  get  old  key  set  new  key  y  z  file  resource  a   check consistency in get of old and new keys  b  fileresource1  c  d  conf  testdeprecation   the corresponding new keys.  config2  m  appendproperty  n  out  config  p  q   set new keys to different values  adddeprecationtoconfiguration  r   load an old key and a new key.  addresource  get   load an old key with multiple new-key mappings  x  y  z   set old key and then get new key(s).  a  b  c  set  d  endconfig  startconfig  assertequals   load the old/new keys corresponding to the keys loaded before.  m  n  p   get old key   set new key  y  z  fileresource
__label__flaky hcat  uri1  server  add  record  to  coord  job  table  for  waiting  hcatserver  coord  el  functions  hcat  uri3  hcat  uri2  get  id  get  waiting  actions  default  /dt=20120430;country=usa  coord-action-for-action-input-check.xml  assert  true  get  coordinator  action  coord-job-for-action-input-check.xml  z  add  record  to  coord  action  table  for  waiting  test  coord  kill  remove  push  missing  deps  tablename  table  init  add  missing  dependency  print  stack  trace  new  h  cat  dependency2  e  new  h  cat  dependency1  new  h  cat  dependency3  hcat://  get  message  destroy  services  pdms  /  push  missing  deps  call  fail  services  coordinator  job  contains  assert  null  setup  services  for  h  catalog  /dt=20120430;country=russia  /dt=20120430;country=brazil  action1  job  action2  db  hcaturi1  server  addrecordtocoordjobtableforwaiting  hcatserver  coordelfunctions  hcaturi3  hcaturi2  getid  getwaitingactions  default  /dt=20120430;country=usa  coord-action-for-action-input-check.xml  asserttrue  get  coordinatoraction  coord-job-for-action-input-check.xml  z  addrecordtocoordactiontableforwaiting  testcoordkillremovepushmissingdeps  tablename  table  init  addmissingdependency  printstacktrace  newhcatdependency2  e  newhcatdependency1  newhcatdependency3  hcat://  getmessage  destroy  services  pdms  /  pushmissingdeps  call  fail  services  coordinatorjob  contains  assertnull  setupservicesforhcatalog  /dt=20120430;country=russia  /dt=20120430;country=brazil  action1  job  action2  db
__label__nflaky get  class  fail  due  to  insufficient  number  of  arguments  get  name  validate  command  test  command  options  assert  false  foo.bar:8080  class  name  debug  -foo  fail  due  to  the  extra  argument  -getlevel  assert  true  -protocol  -setlevel  http  https  valid  command  arguments  blah  getclass   fail due to insufficient number of arguments  getname  validatecommand  testcommandoptions  assertfalse  foo.bar:8080  classname  debug  -foo   fail due to the extra argument  -getlevel  asserttrue  -protocol  -setlevel  http  https   valid command arguments  blah
__label__flaky wf  action  get  cmd  get  workflow  instance  add  record  to  wf  action  table  get  id  assert  equals  test  wf  kill  success1  workflow  instance  get  status  execute  call  1  services  add  record  to  wf  job  table  workflow  action  assert  not  null  get  action  workflow  job  job  wf  instance  jpa  service  wf  job  get  cmd  wfactiongetcmd  getworkflowinstance  addrecordtowfactiontable  getid  assertequals  testwfkillsuccess1  workflowinstance  getstatus  execute  call  1  services  addrecordtowfjobtable  workflowaction  assertnotnull  get  action  workflowjob  job  wfinstance  jpaservice  wfjobgetcmd
__label__nflaky the  -x  option  excludes  snapshots  from  being  calculated.  storage  types.  get  description  count.get  description  the  -u  option  shows  the  quota  and  otherwise  it  will  be  ignored.  check  the  correct  description  is  returned  it  displays  the  quota  and  usage  for  the  specified  types.  types  that  support  quota.  the  list  of  possible  storage  the  -h  option  shows  file  sizes  in  human  readable  format.  dir_  count  file_  count  content_  size  pathname  it  can  also  pass  the  value  \'\'   \'all\'  or  \'  all\'  to  specify  all  the  the  usage  against  the  quota  without  the  detailed  content  summary.  the  -t  option  displays  quota  by  storage  types.  count  the  number  of  directories   files  and  bytes  under  the  paths  types(case  insensitive):  actual  the  -v  option  displays  a  header  line.  that  match  the  specified  file  pattern.  the  output  columns  are:  expected  count  assert  equals  quota  rem_  quota  space_  quota  rem_  space_  quota  it  should  be  used  with  -q  or  -u  option   otherwise   it  displays  the  quota  and  usage  for  all  the  storage  the  -e  option  shows  the  erasure  coding  policy.  if  a  comma-separated  list  of  storage  types  is  given  after  the  -t  option   or   with  the  -q  option:  ram_disk   ssd   disk  and  archive.  dir_  count  file_  count  content_  size  pathname  the -x option excludes snapshots from being calculated.     storage types.    getdescription  count.getdescription  the -u option shows the quota and     otherwise it will be ignored.     check the correct description is returned  it displays the quota and usage for the specified types.     types that support quota. the list of possible storage   the -h option shows file sizes in human readable format.    dir_count file_count content_size pathname    it can also pass the value \'\'  \'all\' or \'all\' to specify all the   the usage against the quota without the detailed content summary.  the -t option displays quota by storage types.    count the number of directories  files and bytes under the paths    types(case insensitive):    actual  the -v option displays a header line.    that match the specified file pattern.  the output columns are:    expected  count  assertequals  quota rem_quota space_quota rem_space_quota    it should be used with -q or -u option    otherwise  it displays the quota and usage for all the storage     the -e option shows the erasure coding policy.  if a comma-separated list of storage types is given after the -t option      or  with the -q option:    ram_disk  ssd  disk and archive.          dir_count file_count content_size pathname
__label__flaky do  multithreaded  writes  cluster  write_  size  test  multiple  hflushers  conf  get  file  system  num_  writes_  per_  thread  fs  p  num_  threads  build  close  /multiple-hflushers.dat  shutdown  domultithreadedwrites  cluster  write_size  testmultiplehflushers  conf  getfilesystem  num_writes_per_thread  fs  p  num_threads  build  close  /multiple-hflushers.dat  shutdown
__label__nflaky reader  skip  conf  key  x  create  scanner  fs  get  bytes  path  fail  close  output  assert  get  len  get  file  status  scanner  lower  bound  close  error  on  handling  negative  offset.  test  failure  negative  offset_2  open  reader  skip  conf  keyx  createscanner  fs  getbytes  path  fail  closeoutput  assert  getlen  getfilestatus  scanner  lowerbound  close  error on handling negative offset.  testfailurenegativeoffset_2  open
__label__flaky action  num  get  id  get  status  add  record  to  coord  action  table  add  record  to  coord  job  table  coordinator  job  job  id  coord-action-get.xml  _test  coord  actions  for  correct  column  values  coordinator  action  test  coord  actions  suspended  for  column  values  action  *  add  a  coordinator  action  with  status  suspended  and  check  for  expected  column  values  job  get  pending  actionnum  getid  getstatus  addrecordtocoordactiontable  addrecordtocoordjobtable  coordinatorjob  jobid  coord-action-get.xml  _testcoordactionsforcorrectcolumnvalues  coordinatoraction  testcoordactionssuspendedforcolumnvalues  action         * add a coordinator action with status suspended and check for expected column values         job  getpending
__label__nflaky address  e  random  expected  an  exception  to  have  been  thrown  get  message  conf  next  long  when  mock  factory  call  fail  do  throw  contains  create  socket  stop  assert  true  mock  client  injected  fault  test  socket  factory  exception  127.0.0.1  address  e  random  expected an exception to have been thrown  getmessage  conf  nextlong  when  mockfactory  call  fail  dothrow  contains  createsocket  stop  asserttrue  mock  client  injected fault  testsocketfactoryexception  127.0.0.1
__label__flaky still  works   but  leaves  the  breadcrumb  in  place.  cluster  get  zkfc  proxy  check  that  the  old  node  was  fenced  start  conf  assert  equals  wait  for  active  lock  holder  set  fail  to  become  standby  get  service  stop  graceful  failover  test  graceful  failover  fail  becoming  standby   still works  but leaves the breadcrumb in place.  cluster  getzkfcproxy   check that the old node was fenced  start  conf  assertequals  waitforactivelockholder  setfailtobecomestandby  getservice  stop  gracefulfailover  testgracefulfailoverfailbecomingstandby
__label__nflaky touched  get  canonical  path  method  dir  assert  home  resolve  failed  e_  not_  directory  file  utils  touch  delete  quietly  test  hadoop  home  not  a  dir  touched  getcanonicalpath  methoddir  asserthomeresolvefailed  e_not_directory  fileutils  touch  deletequietly  testhadoophomenotadir
__label__flaky end_  points  test  coord  re  run1  is_  security_  enabled  -action  oozie  url  run  app  path  assert  true  get  create  servlet_  classes  close  run  test  app  mock  coordinator  engine  service  coordinator.xml  rest  constants  get  context  url  assert  equals  get  file  system  -rerun  args  call  1  -oozie  mkdirs  job  get  fs  test  case  dir  end_points  testcoordrerun1  is_security_enabled  -action  oozieurl  run  apppath  asserttrue  get  create  servlet_classes  close  runtest  app  mockcoordinatorengineservice  coordinator.xml  restconstants  getcontexturl  assertequals  getfilesystem  -rerun  args  call  1  -oozie  mkdirs  job  getfstestcasedir
__label__nflaky we  expect  that  no  websocket  class  has  been  configured  in  guice  for  name  class  available  from  injector  assert  false  context  initialized  get  injector  exception  triggered  by  test  servlet  context  event  mock  static  eq  ninja  servlet  listener  any  when  power  mockito  when  mockito  make  sure  context  initialized  works  when  jetty  throws  exception  class  javax.websocket.server.  server  container  injector  then  throw  on  the  classpath.   we expect that no websocket class has been configured in guice  forname  classavailablefrominjector  assertfalse  contextinitialized  getinjector  exception triggered by test  servletcontextevent  mockstatic  eq  ninjaservletlistener  any  when  powermockito   when  mockito  makesurecontextinitializedworkswhenjettythrowsexception  class  javax.websocket.server.servercontainer  injector  thenthrow   on the classpath.
__label__flaky reader  local  oozie  conf  get  status  workflow  success  reflects  that  rerun  configuration  contained  correctly  resolved  variable  values.  *  test  to  ensure  parameterized  configuration  variables  get  resolved  in  workflow  rerun  ${base}/p1  path  get  test  case  dir  /workflow.xml  file://  ${base}/p2  workflow.xml  wait  for  wf  client  dst  dir  setting  the  variables  \""src  dir\""  and  \""dst  dir\""   used  as  a  file  paths  in  the  workflow   to  parameterized  expressions  to  test  resolution.  get  file  system  re  run  oozie  client  rerun-varsub-wf.xml  copy  char  stream  set  property  get  resource  as  reader  src  dir  create  configuration  file  evaluate  p2  submit  get  job  info  delete  job  id1  test  rerun  variable  sub  workflow  job  nnbase  get  property  skip  executed  nodes  start  false  assert  equals  get  client  kill  io  utils  get  test  user  to  string  writer  get  fs  test  case  dir  base  reader  localoozie  conf  getstatus   workflow success reflects that rerun configuration contained correctly resolved variable values.         * test to ensure parameterized configuration variables get resolved in workflow rerun         ${base}/p1  path  gettestcasedir  /workflow.xml  file://  ${base}/p2  workflow.xml  waitfor  wfclient  dstdir   setting the variables \""srcdir\"" and \""dstdir\""  used as a file paths in the workflow  to parameterized expressions to test resolution.  getfilesystem  rerun  oozieclient  rerun-varsub-wf.xml  copycharstream  setproperty  getresourceasreader  srcdir  createconfiguration  file  evaluate  p2  submit  getjobinfo  delete  jobid1  testrerunvariablesub  workflowjob  nnbase  getproperty   skip executed nodes  start  false  assertequals  getclient  kill  ioutils  gettestuser  tostring  writer  getfstestcasedir  base
__label__nflaky headers  copy  put  status  assert  headers  run  tests  return  different  headers  than  expected.  get  to  array  add  test  deepcopy  key  set  changed  header  check  web  server  testing  framework  exception  should  have  been  thrown  header  name  adapter  unchecked  change  a  header  to  force  an  error  assert  equals  response  expectations  execute  fail  testing  framework  framework  response  new  framework  and  set  adapter  junk  body  headerscopy  put  status  assert  headers  runtests   return different headers than expected.  get  toarray  addtest  deepcopy  keyset  changedheadercheck  webservertestingframeworkexception should have been thrown  headername  adapter  unchecked   change a header to force an error  assertequals  responseexpectations  execute  fail  testingframework  framework  response  newframeworkandsetadapter  junk  body
__label__flaky set  classes  to  be  excluded  assert  false  get  current  dateafter  incrementing  in  months  get  id  run  date  utils  is  pending  get  status  add  record  to  coord  action  table  parse  date  oozie  tz  coord  get  cmd  coord  job  set  pause  time  get  coordinator  action  end  current  date  plus  month  wait  for  set  some  pause  time  explicity  to  make  sure  the  job  is  not  unpaused  create  coord  job  init  test  coord  status  transit  service  paused  get  conf  coord  insert  cmd  false  start  2009-02-01  t01:00  z  destroy  assert  equals  services  x  data  test  case  execute  services  coordinator  job  job  id  runnable  coord-action-get.xml  excluded  services  set  system  property  status  transit  service  jpa  service  evaluate  setclassestobeexcluded  assertfalse  getcurrentdateafterincrementinginmonths  getid  run  dateutils  ispending  getstatus  addrecordtocoordactiontable  parsedateoozietz  coordgetcmd  coordjob  setpausetime  get  coordinatoraction  end  currentdateplusmonth  waitfor   set some pause time explicity to make sure the job is not unpaused  createcoordjob  init  testcoordstatustransitservicepaused  getconf  coordinsertcmd  false  start  2009-02-01t01:00z  destroy  assertequals  services  xdatatestcase  execute  services  coordinatorjob  jobid  runnable  coord-action-get.xml  excludedservices  setsystemproperty  statustransitservice  jpaservice  evaluate
__label__nflaky gen  key  pair  handler  request  get  time  jwt  get  public  public  key  set  public  key  when  redirect_  location  alternate  authentication  should  not  have  thrown  a  authentication  exception  service_  url  verify  the  signature  -  in  order  to  make  it  fail  verification...  get  cookies  get  jwt  verify  get  request  url  rsa  init  kpg  cookie  kp  alternate  authentication  should  not  have  thrown  a  servlet  exception  then  return  get  properties  hadoop-jwt  encode  redirect  url  alternate  authenticate  key  pair  generator  test  failed  signature  validation  jwt  send  redirect  props  token  fail  private  key  serialize  bob  mockito  response  mock  get  instance  initialize  genkeypair  handler  request  gettime  jwt  getpublic  publickey  setpublickey  when  redirect_location  alternateauthentication should not have thrown a authenticationexception  service_url   verify the signature - in order to make it fail verification...  getcookies  getjwt  verify  getrequesturl  rsa  init  kpg  cookie  kp  alternateauthentication should not have thrown a servletexception  thenreturn  getproperties  hadoop-jwt  encoderedirecturl  alternateauthenticate  keypairgenerator  testfailedsignaturevalidationjwt  sendredirect  props  token  fail  privatekey  serialize  bob  mockito  response  mock  getinstance  initialize
__label__flaky add  record  to  wf  action  table  get  id  workflow  instance  get  status  update  the  list  for  doing  bulk  writes  coord  job  wf  job  add  record  to  wf  job  table  assert  not  null  get  action  workflow  job  update  list  add  get  status  str  update  the  status  check  for  expected  status  after  running  bulk  update  jpa  running  assert  equals  execute  add  record  to  coord  job  table  set  status  coordinator  job  1  services  set  update  list  workflow  action  bulk  update  cmd  succeeded  test  updates  action2  jpa  service  addrecordtowfactiontable  getid  workflowinstance  getstatus   update the list for doing bulk writes  coordjob  wfjob  addrecordtowfjobtable  assertnotnull  get  action  workflowjob  updatelist  add  getstatusstr   update the status   check for expected status after running bulkupdatejpa  running  assertequals  execute  addrecordtocoordjobtable  setstatus  coordinatorjob  1  services  setupdatelist  workflowaction  bulkupdatecmd  succeeded  testupdates  action2  jpaservice
__label__nflaky +15551212  foo  bar  test  sms  sms:+15551212  +15551212  sms:+15551212;via=999333  +15551212  +12124440101  parsed  result  type  sms:+15551212  do  test  result  sms:+15551212 +12124440101  sms:+15551212?subject=foo&body=bar  +15551212  foo  bar  testsms  sms:+15551212  +15551212  sms:+15551212;via=999333  +15551212  +12124440101  parsedresulttype  sms:+15551212  dotestresult  sms:+15551212 +12124440101  sms:+15551212?subject=foo&body=bar
__label__flaky file  permission  generator  next  ancestor_  name  test  permission  checking  per  user  dir  permission  generator  ancestor  permissions  create  ancestor  directory  parent  paths  test  permission  checking  ancestor  paths  has  a  different  permission  conf  create  a  directory  hierarchy  and  sets  random  permission  for  each  inode  file  owner  change  parent  directory\'s  ownership  to  be  user1  fs  file_  name  set  owner  user1  user2  permissions  parent_  name  file  system  get  create  set  permission  user1_  name  user3  close  check  if  namenode  performs  permission  checking  correctly  for  *  superuser   file  owner   group  owner   and  other  users  dir_  name  dir  paths  ancestor  permission  generator  group  owner  other  owner  parent  permissions  group2_  name  /  r  set  the  permission  of  the  root  to  be  world-wide  rwx  num_  test_  permissions  superuser  op  type  file  paths  super  owner  create  parent  directory  filepermissiongenerator  next  ancestor_name  testpermissioncheckingperuser  dirpermissiongenerator  ancestorpermissions   create ancestor directory  parentpaths  testpermissionchecking  ancestorpaths   has a different permission  conf   create a directory hierarchy and sets random permission for each inode   file owner    change parent directory\'s ownership to be user1  fs  file_name  setowner  user1  user2  permissions  parent_name  filesystem  get  create  setpermission  user1_name  user3  close   check if namenode performs permission checking correctly for     * superuser  file owner  group owner  and other users   dir_name  dirpaths  ancestorpermissiongenerator   group owner    other owner   parentpermissions  group2_name  /  r   set the permission of the root to be world-wide rwx  num_test_permissions  superuser  optype  filepaths   super owner    create parent directory
