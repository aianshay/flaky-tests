{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    'test  partial  frame  write  assert  false  i...\n",
       "1    'inherit  wf  false  parent  libs2  parent  li...\n",
       "2    'nn_host/  get  default  uri  set  tet  get  d...\n",
       "3    'end_  points  is_  security_  enabled  get  c...\n",
       "4    'p1  p2  should  fail  test  client  retries  ...\n",
       "5    'action  num  test  coord  action  get  pretty...\n",
       "6    'standard  charsets  get  content  assert  fal...\n",
       "7    'get  id  assert  equals  get  status  execute...\n",
       "8    'byte  param  should  handle  null  byte  para...\n",
       "9    '<property><name>hello</name><value>world</val...\n",
       "Name: token, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msr_data = pd.read_csv('../msr_results/tokenslockeywordskeywordcount.csv', encoding = 'ANSI')\n",
    "\n",
    "msr_data['token'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95       283\n",
      "           1       0.98      0.91      0.94       278\n",
      "\n",
      "    accuracy                           0.95       561\n",
      "   macro avg       0.95      0.95      0.95       561\n",
      "weighted avg       0.95      0.95      0.95       561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_msr = msr_data['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(msr_data['token'], \n",
    "                                                    y_msr, train_size=0.8, \n",
    "                                                    random_state=33, shuffle=True)\n",
    "\n",
    "msr_vectorizer = CountVectorizer()\n",
    "tf = TfidfTransformer()\n",
    "\n",
    "X_train_cv = msr_vectorizer.fit_transform(X_train)\n",
    "X_train_tf = tf.fit_transform(X_train_cv)\n",
    "\n",
    "X_test_cv = msr_vectorizer.transform(X_test)\n",
    "X_test_tf = tf.transform(X_test_cv)\n",
    "\n",
    "msr_model = RandomForestClassifier()\n",
    "msr_model.fit(X_train_tf, y_train)\n",
    "preds = msr_model.predict(X_test_tf)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.90      0.65       724\n",
      "           1       0.62      0.16      0.26       737\n",
      "\n",
      "    accuracy                           0.53      1461\n",
      "   macro avg       0.57      0.53      0.46      1461\n",
      "weighted avg       0.57      0.53      0.45      1461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.read_csv('../new_data/dataset.csv')\n",
    "y_new = new_data['class']\n",
    "\n",
    "X_new_cv = msr_vectorizer.transform(new_data['token'])\n",
    "X_new_tf = tf.transform(X_new_cv)\n",
    "\n",
    "new_preds = msr_model.predict(X_new_tf)\n",
    "print(classification_report(y_new, new_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with MultinomialNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       283\n",
      "           1       0.89      0.95      0.92       278\n",
      "\n",
      "    accuracy                           0.92       561\n",
      "   macro avg       0.92      0.92      0.92       561\n",
      "weighted avg       0.92      0.92      0.92       561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tf, y_train)\n",
    "preds = nb_model.predict(X_test_tf)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.43      0.52       724\n",
      "           1       0.58      0.77      0.66       737\n",
      "\n",
      "    accuracy                           0.60      1461\n",
      "   macro avg       0.62      0.60      0.59      1461\n",
      "weighted avg       0.62      0.60      0.59      1461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_preds = nb_model.predict(X_new_tf)\n",
    "print(classification_report(y_new, new_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       283\n",
      "           1       0.89      0.95      0.92       278\n",
      "\n",
      "    accuracy                           0.92       561\n",
      "   macro avg       0.92      0.92      0.92       561\n",
      "weighted avg       0.92      0.92      0.92       561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_model = SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)\n",
    "sgd_model.fit(X_train_tf, y_train)\n",
    "preds = nb_model.predict(X_test_tf)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.81      0.64       724\n",
      "           1       0.60      0.27      0.37       737\n",
      "\n",
      "    accuracy                           0.54      1461\n",
      "   macro avg       0.56      0.54      0.51      1461\n",
      "weighted avg       0.56      0.54      0.50      1461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_preds = sgd_model.predict(X_new_tf)\n",
    "print(classification_report(y_new, new_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
